Loading configuration... done.
***Starting server on port 35817 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
/home/tahiti/桌面/sumo-0.32.0/tools
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_map_feature (InputLayer)  (None, 150, 150, 1)  0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 38, 38, 32)   2048        input_map_feature[0][0]          
__________________________________________________________________________________________________
bn1 (BatchNormalization)        (None, 38, 38, 32)   96          conv1[0][0]                      
__________________________________________________________________________________________________
act1 (Activation)               (None, 38, 38, 32)   0           bn1[0][0]                        
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 19, 19, 32)   0           act1[0][0]                       
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 19, 19, 32)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2 (Conv2D)                  (None, 10, 10, 16)   8192        dropout_1[0][0]                  
__________________________________________________________________________________________________
bn2 (BatchNormalization)        (None, 10, 10, 16)   48          conv2[0][0]                      
__________________________________________________________________________________________________
act2 (Activation)               (None, 10, 10, 16)   0           bn2[0][0]                        
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 16)     0           act2[0][0]                       
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 5, 5, 16)     0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
input_cur_phase (InputLayer)    (None, 1)            0                                            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 400)          0           dropout_2[0][0]                  
__________________________________________________________________________________________________
input_next_phase (InputLayer)   (None, 1)            0                                            
__________________________________________________________________________________________________
input_num_of_vehicles (InputLay (None, 8)            0                                            
__________________________________________________________________________________________________
input_queue_length (InputLayer) (None, 8)            0                                            
__________________________________________________________________________________________________
input_waiting_time (InputLayer) (None, 8)            0                                            
__________________________________________________________________________________________________
all_flatten_feature (Concatenat (None, 426)          0           input_cur_phase[0][0]            
                                                                 flatten_1[0][0]                  
                                                                 input_next_phase[0][0]           
                                                                 input_num_of_vehicles[0][0]      
                                                                 input_queue_length[0][0]         
                                                                 input_waiting_time[0][0]         
__________________________________________________________________________________________________
hidden_shared_1 (Dense)         (None, 20)           8540        all_flatten_feature[0][0]        
__________________________________________________________________________________________________
hidden_separate_branch_0_1 (Den (None, 20)           420         hidden_shared_1[0][0]            
__________________________________________________________________________________________________
hidden_separate_branch_1_1 (Den (None, 20)           420         hidden_shared_1[0][0]            
__________________________________________________________________________________________________
q_values_separate_branch_0 (Den (None, 2)            42          hidden_separate_branch_0_1[0][0] 
__________________________________________________________________________________________________
selector_0 (Selector)           (None, 1)            0           input_cur_phase[0][0]            
__________________________________________________________________________________________________
q_values_separate_branch_1 (Den (None, 2)            42          hidden_separate_branch_1_1[0][0] 
__________________________________________________________________________________________________
selector_1 (Selector)           (None, 1)            0           input_cur_phase[0][0]            
__________________________________________________________________________________________________
multiply_0 (Multiply)           (None, 2)            0           q_values_separate_branch_0[0][0] 
                                                                 selector_0[0][0]                 
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 2)            0           q_values_separate_branch_1[0][0] 
                                                                 selector_1[0][0]                 
__________________________________________________________________________________________________
add_1 (Add)                     (None, 2)            0           multiply_0[0][0]                 
                                                                 multiply_1[0][0]                 
==================================================================================================
Total params: 19,848
Trainable params: 19,752
Non-trainable params: 96
__________________________________________________________________________________________________
Could not connect to TraCI server at localhost:35817 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 1	current_phase = 1	next_phase = 0	reward = -1.623190	array([[1.0410463, 0.5828052]], dtype=float32)
time = 51	action = 0	current_phase = 0	next_phase = 1	reward = -0.701349	array([[-0.9804924 , -0.18058875]], dtype=float32)
time = 56	action = 1	current_phase = 0	next_phase = 1	reward = -2.003345	array([[-0.98511714, -0.1824498 ]], dtype=float32)
time = 64	action = 0	current_phase = 1	next_phase = 0	reward = -0.022476	array([[1.0396333, 0.5592303]], dtype=float32)
time = 69	action = 1	current_phase = 1	next_phase = 0	reward = -1.788284	array([[1.0144538 , 0.57775044]], dtype=float32)
time = 77	action = 0	current_phase = 0	next_phase = 1	reward = -0.844532	array([[-0.9436986 , -0.17055047]], dtype=float32)
time = 82	action = 1	current_phase = 0	next_phase = 1	reward = -1.534409	array([[-0.9368408 , -0.17525299]], dtype=float32)
time = 90	action = 0	current_phase = 1	next_phase = 0	reward = -0.023568	array([[1.01795   , 0.58197147]], dtype=float32)
time = 95	action = 1	current_phase = 1	next_phase = 0	reward = -0.982184	array([[0.97750705, 0.5977851 ]], dtype=float32)
time = 103	action = 0	current_phase = 0	next_phase = 1	reward = -0.052410	array([[-0.9514084 , -0.12663874]], dtype=float32)
time = 108	action = 1	current_phase = 0	next_phase = 1	reward = -2.540724	array([[-0.9217575 , -0.14054981]], dtype=float32)
time = 116	action = 0	current_phase = 1	next_phase = 0	reward = -0.492535	array([[0.9925161, 0.5777867]], dtype=float32)
time = 121	action = 1	current_phase = 1	next_phase = 0	reward = -1.675973	array([[0.9633208, 0.6055496]], dtype=float32)
time = 129	action = 0	current_phase = 0	next_phase = 1	reward = -0.955347	array([[-0.9810122 , -0.09360666]], dtype=float32)
time = 134	action = 1	current_phase = 0	next_phase = 1	reward = -2.275768	array([[-0.94523185, -0.11591058]], dtype=float32)
time = 142	action = 0	current_phase = 1	next_phase = 0	reward = -0.527158	array([[0.9822975 , 0.57925653]], dtype=float32)
time = 147	action = 1	current_phase = 1	next_phase = 0	reward = -1.625722	array([[0.94823986, 0.6070329 ]], dtype=float32)
time = 155	action = 0	current_phase = 0	next_phase = 1	reward = -0.543708	array([[-0.9945503 , -0.12219197]], dtype=float32)
time = 160	action = 1	current_phase = 0	next_phase = 1	reward = -1.926907	array([[-0.93284947, -0.1426435 ]], dtype=float32)
time = 168	action = 0	current_phase = 1	next_phase = 0	reward = -1.075800	array([[1.0171669, 0.5880109]], dtype=float32)
time = 173	action = 1	current_phase = 1	next_phase = 0	reward = -2.027209	array([[0.9838789, 0.6077923]], dtype=float32)
time = 181	action = 0	current_phase = 0	next_phase = 1	reward = -0.875918	array([[-0.9693139 , -0.12175206]], dtype=float32)
time = 186	action = 1	current_phase = 0	next_phase = 1	reward = -2.399272	array([[-0.9795853 , -0.15347192]], dtype=float32)
time = 194	action = 0	current_phase = 1	next_phase = 0	reward = -1.039718	array([[1.0228075 , 0.57285273]], dtype=float32)
time = 199	action = 1	current_phase = 1	next_phase = 0	reward = -1.582636	array([[1.0015705 , 0.59247774]], dtype=float32)
time = 207	action = 0	current_phase = 0	next_phase = 1	reward = -0.296649	array([[-0.91671145, -0.15512225]], dtype=float32)
time = 212	action = 1	current_phase = 0	next_phase = 1	reward = -1.202176	array([[-0.9181545 , -0.17957862]], dtype=float32)
time = 220	action = 0	current_phase = 1	next_phase = 0	reward = 0.201472	array([[1.0527053 , 0.54629964]], dtype=float32)
time = 225	action = 1	current_phase = 1	next_phase = 0	reward = -1.781699	array([[1.0239177 , 0.57903326]], dtype=float32)
time = 233	action = 0	current_phase = 0	next_phase = 1	reward = -0.960858	array([[-0.9966931 , -0.13624588]], dtype=float32)
time = 238	action = 1	current_phase = 0	next_phase = 1	reward = -1.564083	array([[-0.9940438 , -0.14567164]], dtype=float32)
time = 246	action = 0	current_phase = 1	next_phase = 0	reward = -0.997512	array([[1.0544748, 0.582225 ]], dtype=float32)
time = 251	action = 1	current_phase = 1	next_phase = 0	reward = -1.897834	array([[1.0179459 , 0.59723324]], dtype=float32)
time = 259	action = 0	current_phase = 0	next_phase = 1	reward = -0.153093	array([[-0.950594  , -0.13654262]], dtype=float32)
time = 264	action = 1	current_phase = 0	next_phase = 1	reward = -1.269915	array([[-0.95309836, -0.14949754]], dtype=float32)
time = 272	action = 0	current_phase = 1	next_phase = 0	reward = -0.675935	array([[1.0235158, 0.5813189]], dtype=float32)
time = 277	action = 1	current_phase = 1	next_phase = 0	reward = -1.428991	array([[0.9973802, 0.5981575]], dtype=float32)
time = 285	action = 0	current_phase = 0	next_phase = 1	reward = 0.031446	array([[-0.9256771 , -0.14383179]], dtype=float32)
time = 290	action = 1	current_phase = 0	next_phase = 1	reward = -1.162175	array([[-0.9446195 , -0.16079287]], dtype=float32)
time = 298	action = 0	current_phase = 1	next_phase = 0	reward = -0.502285	array([[1.0273038, 0.5689624]], dtype=float32)
time = 303	action = 1	current_phase = 1	next_phase = 0	reward = -1.684013	array([[0.97911507, 0.5943037 ]], dtype=float32)
time = 311	action = 0	current_phase = 0	next_phase = 1	reward = -0.637300	array([[-0.94323725, -0.11773539]], dtype=float32)
time = 316	action = 1	current_phase = 0	next_phase = 1	reward = -1.983840	array([[-0.93962556, -0.14543203]], dtype=float32)
time = 324	action = 0	current_phase = 1	next_phase = 0	reward = -0.012240	array([[1.0063314, 0.5649841]], dtype=float32)
time = 329	action = 1	current_phase = 1	next_phase = 0	reward = -2.539505	array([[0.9834689, 0.5776441]], dtype=float32)
time = 337	action = 0	current_phase = 0	next_phase = 1	reward = -1.931164	array([[-0.9731651, -0.1254741]], dtype=float32)
time = 342	action = 1	current_phase = 0	next_phase = 1	reward = -2.840938	array([[-0.9534234 , -0.12445911]], dtype=float32)
time = 350	action = 0	current_phase = 1	next_phase = 0	reward = -0.847122	array([[0.9856292, 0.5882712]], dtype=float32)
time = 355	action = 1	current_phase = 1	next_phase = 0	reward = -1.653012	array([[0.9735266, 0.5964912]], dtype=float32)
time = 363	action = 0	current_phase = 0	next_phase = 1	reward = -0.079915	array([[-1.0219221 , -0.13338047]], dtype=float32)
time = 368	action = 1	current_phase = 0	next_phase = 1	reward = -2.201865	array([[-0.9815388 , -0.16960233]], dtype=float32)
time = 376	action = 0	current_phase = 1	next_phase = 0	reward = -0.674761	array([[1.0333729 , 0.55937755]], dtype=float32)
time = 381	action = 1	current_phase = 1	next_phase = 0	reward = -1.644882	array([[1.0377911, 0.5643452]], dtype=float32)
time = 389	action = 0	current_phase = 0	next_phase = 1	reward = -0.917451	array([[-0.9545744 , -0.17850834]], dtype=float32)
time = 394	action = 1	current_phase = 0	next_phase = 1	reward = -2.144849	array([[-0.95083046, -0.18761164]], dtype=float32)
time = 402	action = 0	current_phase = 1	next_phase = 0	reward = 0.071557	array([[1.0303023, 0.5712636]], dtype=float32)
time = 407	action = 1	current_phase = 1	next_phase = 0	reward = -1.162089	array([[0.9979429 , 0.59516853]], dtype=float32)
time = 415	action = 0	current_phase = 0	next_phase = 1	reward = -0.789835	array([[-0.97681165, -0.15363432]], dtype=float32)
time = 420	action = 1	current_phase = 0	next_phase = 1	reward = -1.737875	array([[-0.96854585, -0.16999424]], dtype=float32)
time = 428	action = 0	current_phase = 1	next_phase = 0	reward = -1.138110	array([[1.0155721 , 0.57750225]], dtype=float32)
time = 433	action = 1	current_phase = 1	next_phase = 0	reward = -1.639748	array([[0.99741894, 0.5848606 ]], dtype=float32)
time = 441	action = 0	current_phase = 0	next_phase = 1	reward = -0.319622	array([[-0.9924562 , -0.16744319]], dtype=float32)
time = 446	action = 1	current_phase = 0	next_phase = 1	reward = -1.965022	array([[-0.9816582 , -0.16991475]], dtype=float32)
time = 454	action = 0	current_phase = 1	next_phase = 0	reward = -1.135092	array([[1.014082  , 0.56386423]], dtype=float32)
time = 459	action = 1	current_phase = 1	next_phase = 0	reward = -1.615922	array([[1.0251614, 0.5611497]], dtype=float32)
time = 467	action = 0	current_phase = 0	next_phase = 1	reward = -0.471024	array([[-0.9759493 , -0.18422352]], dtype=float32)
time = 472	action = 1	current_phase = 0	next_phase = 1	reward = -1.627636	array([[-0.9721049 , -0.18436164]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -0.465967	array([[1.0683501 , 0.55442536]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -2.518197	array([[1.0353309 , 0.56806713]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -1.001144	array([[-0.94850177, -0.1701968 ]], dtype=float32)
time = 498	action = 1	current_phase = 0	next_phase = 1	reward = -1.449169	array([[-0.9437067 , -0.14083418]], dtype=float32)
time = 506	action = 0	current_phase = 1	next_phase = 0	reward = -0.615835	array([[1.0226704, 0.6010139]], dtype=float32)
time = 511	action = 1	current_phase = 1	next_phase = 0	reward = -2.138832	array([[0.9971541 , 0.61405104]], dtype=float32)
time = 519	action = 0	current_phase = 0	next_phase = 1	reward = 0.141087	array([[-0.9522208 , -0.12147436]], dtype=float32)Simulation ended at time: 676.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2410ms
 Real time factor: 280.498
 UPS: 4064.730290
Vehicles: 
 Inserted: 261 (Loaded: 313)
 Running: 16
 Waiting: 0

DijkstraRouter answered 467 queries and explored 3.25 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 55771 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 524	action = 1	current_phase = 0	next_phase = 1	reward = -2.216058	array([[-0.96588635, -0.14261094]], dtype=float32)
time = 532	action = 0	current_phase = 1	next_phase = 0	reward = -1.377885	array([[1.0194851, 0.5550538]], dtype=float32)
time = 537	action = 1	current_phase = 1	next_phase = 0	reward = -1.662845	array([[0.9637526, 0.591439 ]], dtype=float32)
time = 545	action = 0	current_phase = 0	next_phase = 1	reward = -0.718307	array([[-0.9492421 , -0.13210806]], dtype=float32)
time = 550	action = 1	current_phase = 0	next_phase = 1	reward = -1.762079	array([[-0.9099612 , -0.14553633]], dtype=float32)
time = 558	action = 0	current_phase = 1	next_phase = 0	reward = -0.422404	array([[0.9986144, 0.5956917]], dtype=float32)
time = 563	action = 1	current_phase = 1	next_phase = 0	reward = -1.954023	array([[0.9886951 , 0.60226035]], dtype=float32)
time = 571	action = 0	current_phase = 0	next_phase = 1	reward = -0.035374	array([[-0.9802515 , -0.14398725]], dtype=float32)
time = 576	action = 1	current_phase = 0	next_phase = 1	reward = -1.339348	array([[-0.96042645, -0.17424199]], dtype=float32)
time = 584	action = 0	current_phase = 1	next_phase = 0	reward = -0.736799	array([[1.036372 , 0.5628834]], dtype=float32)
time = 589	action = 1	current_phase = 1	next_phase = 0	reward = -1.222594	array([[0.9971162, 0.5876984]], dtype=float32)
time = 597	action = 0	current_phase = 0	next_phase = 1	reward = -0.405593	array([[-0.9492106 , -0.14377236]], dtype=float32)
time = 602	action = 1	current_phase = 0	next_phase = 1	reward = -1.386637	array([[-0.94355464, -0.14651006]], dtype=float32)
time = 610	action = 0	current_phase = 1	next_phase = 0	reward = -0.339512	array([[1.0202068, 0.5813718]], dtype=float32)
time = 615	action = 1	current_phase = 1	next_phase = 0	reward = -1.271780	array([[1.0021361, 0.5893558]], dtype=float32)
time = 623	action = 0	current_phase = 0	next_phase = 1	reward = -0.180813	array([[-0.9662743 , -0.13818423]], dtype=float32)
time = 628	action = 1	current_phase = 0	next_phase = 1	reward = -1.872497	array([[-0.95860296, -0.15374103]], dtype=float32)
time = 636	action = 0	current_phase = 1	next_phase = 0	reward = -1.482339	array([[1.0285597 , 0.56592363]], dtype=float32)
time = 641	action = 1	current_phase = 1	next_phase = 0	reward = -2.181077	array([[0.9904763, 0.5742807]], dtype=float32)
time = 649	action = 0	current_phase = 0	next_phase = 1	reward = -0.775146	array([[-0.9817187, -0.1435084]], dtype=float32)
time = 654	action = 1	current_phase = 0	next_phase = 1	reward = -1.770167	array([[-0.9586174 , -0.16905558]], dtype=float32)
time = 662	action = 0	current_phase = 1	next_phase = 0	reward = -0.761266	array([[1.0014648 , 0.58155984]], dtype=float32)
time = 667	action = 1	current_phase = 1	next_phase = 0	reward = -1.146996	array([[1.0076619, 0.5864609]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:55771 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.062850	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.700355	array([[1.0599525, 0.566923 ]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -1.604073	array([[1.0460906 , 0.56634283]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.887003	array([[-0.9746271 , -0.17608705]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.564281	array([[-0.9782698 , -0.17801575]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.985911	array([[-0.966682  , -0.15401919]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.214064	array([[1.0316117 , 0.56680924]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.079915	array([[1.0056111, 0.5908176]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.379958	array([[-0.9332555 , -0.14782557]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.212051	array([[-0.94407886, -0.1506073 ]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.662442	array([[-0.96389264, -0.12211952]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.721835	array([[0.96641755, 0.5906266 ]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.862137	array([[0.9379138, 0.6063921]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.873256	array([[-0.94894725, -0.1135268 ]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.842350	array([[-0.903769  , -0.12688127]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -3.097361	array([[-0.89113426, -0.10757428]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.231526	array([[0.9704615, 0.5954067]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.655362	array([[0.9386593 , 0.60787565]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.932556	array([[-0.96805984, -0.08979902]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.289053	array([[-0.9216998 , -0.13024095]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.673172	array([[-0.8882945, -0.1350668]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.466230	array([[1.0037777, 0.5870342]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.901679	array([[0.9785979 , 0.60349035]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.651505	array([[-0.9566929 , -0.11070218]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.081846	array([[-0.962103  , -0.13587058]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.805376	array([[-0.94468594, -0.13989788]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.307591	array([[1.0258493 , 0.56545407]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.899653	array([[0.9809464, 0.5940021]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.308382	array([[-0.936112 , -0.1560443]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.957883	array([[-0.95350796, -0.16792062]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -2.468436	array([[-0.94977814, -0.16138934]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = 0.244533	array([[1.0174512 , 0.57927287]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.611840	array([[0.9994411, 0.5983316]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.534783	array([[-0.97690356, -0.14746228]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -1.419881	array([[-0.9526404 , -0.17935213]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.773055	array([[-0.9534976 , -0.14956456]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.895378	array([[1.020482 , 0.5900695]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.939611	array([[0.9881904, 0.5958555]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 0.053216	array([[-0.9413118 , -0.12350785]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.981611	array([[-0.9281404 , -0.13532624]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2295ms
 Real time factor: 291.503
 UPS: 4385.185185
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 460 queries and explored 3.39 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 35083 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.941212	array([[-0.91065896, -0.1364434 ]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -0.891427	array([[1.002965 , 0.5710634]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.572573	array([[0.97044504, 0.5881612 ]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.876981	array([[-0.9314986 , -0.11349407]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -1.169664	array([[-0.9044084 , -0.12397712]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -2.767375	array([[-0.922579  , -0.13121513]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.059995	array([[1.0029125, 0.5559779]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.419203	array([[0.9692894 , 0.57708603]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -1.918668	array([[-0.96898496, -0.12134786]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -2.396534	array([[-0.93570167, -0.12166689]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -3.346320	array([[-0.96451783, -0.11429971]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.393560	array([[0.9960294, 0.5803363]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -2.037986	array([[0.9812039 , 0.59287626]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.323420	array([[-0.9945855 , -0.14310697]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.712778	array([[-0.9475452 , -0.16584231]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.743212	array([[-0.92820376, -0.16971034]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.465246	array([[1.0319703 , 0.55555737]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.141184	array([[1.0130775, 0.5737023]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.258359	array([[-0.9599314 , -0.18704444]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -1.456049	array([[-0.9655982 , -0.16072686]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -2.046047	array([[-0.956505  , -0.15225118]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.516536	array([[1.03933  , 0.5732972]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.146977	array([[1.0228872 , 0.58206815]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.522485	array([[-0.9509927 , -0.17078361]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -1.302962	array([[-0.95490026, -0.17352721]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.932747	array([[-0.9739242 , -0.15997662]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.130556	array([[1.0401497, 0.5604199]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.300942	array([[1.0214461, 0.5732412]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.183517	array([[-0.9785968 , -0.18495518]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.393973	array([[-0.95775914, -0.19937578]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -1.354490	array([[-0.94188815, -0.19330168]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.220252	array([[1.059515  , 0.55765843]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.510614	array([[1.0440385 , 0.58070403]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.939128	array([[-0.9569876 , -0.17713538]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.601425	array([[-0.9692025 , -0.15340483]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -1.634128	array([[-0.9572559 , -0.15144151]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.491899	array([[1.0245906, 0.5894611]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.151624	array([[1.0077106 , 0.59921527]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.558119	array([[-0.9420663 , -0.12443876]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -1.343938	array([[-0.9505171 , -0.14783682]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -2.600415	array([[-0.9188948 , -0.14398137]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -0.874263	array([[0.985568  , 0.58541805]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.930070	array([[0.9679656 , 0.60299873]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -1.596395	array([[-0.9789239, -0.1142027]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -1.617989	array([[-0.9525733 , -0.13170329]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -2.353553	array([[-0.950678  , -0.14069504]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -0.515094	array([[1.009331 , 0.5669268]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.892262	array([[0.98724926, 0.5819426 ]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.968028	array([[-1.0031953 , -0.14832202]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -1.563176	array([[-0.9797875 , -0.16093911]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -2.331855	array([[-0.9655907 , -0.15722029]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.947931	array([[1.0278327, 0.5873589]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -0.919976	array([[0.98714226, 0.60927963]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.420918	array([[-0.9686692 , -0.14178379]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 0.136938	array([[-0.9635395, -0.1559265]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -2.045577	array([[-0.95840514, -0.15554969]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.712433	array([[1.0093904, 0.5816644]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.698678	array([[1.0190605 , 0.56814253]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.022518	array([[-0.9878262, -0.1646603]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.109406	array([[-0.9795076 , -0.15605065]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -2.026198	array([[-0.959044 , -0.1747967]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.737719	array([[1.0361651 , 0.57951576]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:35083 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.062850	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.700355	array([[1.0599525, 0.566923 ]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -1.604073	array([[1.0460906 , 0.56634283]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.887003	array([[-0.9746271 , -0.17608705]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.564281	array([[-0.9782698 , -0.17801575]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.985911	array([[-0.966682  , -0.15401919]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.214064	array([[1.0316117 , 0.56680924]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.079915	array([[1.0056111, 0.5908176]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.379958	array([[-0.9332555 , -0.14782557]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.212051	array([[-0.94407886, -0.1506073 ]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.662442	array([[-0.96389264, -0.12211952]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.721835	array([[0.96641755, 0.5906266 ]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.862137	array([[0.9379138, 0.6063921]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.873256	array([[-0.94894725, -0.1135268 ]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.842350	array([[-0.903769  , -0.12688127]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -3.097361	array([[-0.89113426, -0.10757428]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.231526	array([[0.9704615, 0.5954067]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.655362	array([[0.9386593 , 0.60787565]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.932556	array([[-0.96805984, -0.08979902]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.289053	array([[-0.9216998 , -0.13024095]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.673172	array([[-0.8882945, -0.1350668]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.466230	array([[1.0037777, 0.5870342]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.901679	array([[0.9785979 , 0.60349035]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.651505	array([[-0.9566929 , -0.11070218]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.081846	array([[-0.962103  , -0.13587058]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.805376	array([[-0.94468594, -0.13989788]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.307591	array([[1.0258493 , 0.56545407]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.899653	array([[0.9809464, 0.5940021]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.308382	array([[-0.936112 , -0.1560443]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.957883	array([[-0.95350796, -0.16792062]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -2.468436	array([[-0.94977814, -0.16138934]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = 0.244533	array([[1.0174512 , 0.57927287]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.611840	array([[0.9994411, 0.5983316]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.534783	array([[-0.97690356, -0.14746228]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -1.419881	array([[-0.9526404 , -0.17935213]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.773055	array([[-0.9534976 , -0.14956456]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.895378	array([[1.020482 , 0.5900695]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.939611	array([[0.9881904, 0.5958555]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 0.053216	array([[-0.9413118 , -0.12350785]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.981611	array([[-0.9281404 , -0.13532624]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.941212	array([[-0.91065896, -0.1364434 ]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -0.891427	array([[1.002965 , 0.5710634]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.572573	array([[0.97044504, 0.5881612 ]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.876981	array([[-0.9314986 , -0.11349407]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -1.169664	array([[-0.9044084 , -0.12397712]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -2.767375	array([[-0.922579  , -0.13121513]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.059995	array([[1.0029125, 0.5559779]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.419203	array([[0.9692894 , 0.57708603]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -1.918668	array([[-0.96898496, -0.12134786]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -2.396534	array([[-0.93570167, -0.12166689]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -3.346320	array([[-0.96451783, -0.11429971]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.393560	array([[0.9960294, 0.5803363]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -2.037986	array([[0.9812039 , 0.59287626]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.323420	array([[-0.9945855 , -0.14310697]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.712778	array([[-0.9475452 , -0.16584231]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.743212	array([[-0.92820376, -0.16971034]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.465246	array([[1.0319703 , 0.55555737]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.141184	array([[1.0130775, 0.5737023]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.258359	array([[-0.9599314 , -0.18704444]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -1.456049	array([[-0.9655982 , -0.16072686]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -2.046047	array([[-0.956505  , -0.15225118]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.516536	array([[1.03933  , 0.5732972]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.146977	array([[1.0228872 , 0.58206815]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.522485	array([[-0.9509927 , -0.17078361]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -1.302962	array([[-0.95490026, -0.17352721]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.932747	array([[-0.9739242 , -0.15997662]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.130556	array([[1.0401497, 0.5604199]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.300942	array([[1.0214461, 0.5732412]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2279ms
 Real time factor: 293.55
 UPS: 4415.971918
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 460 queries and explored 3.39 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 32985 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.183517	array([[-0.9785968 , -0.18495518]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.393973	array([[-0.95775914, -0.19937578]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -1.354490	array([[-0.94188815, -0.19330168]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.220252	array([[1.059515  , 0.55765843]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.510614	array([[1.0440385 , 0.58070403]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.939128	array([[-0.9569876 , -0.17713538]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.601425	array([[-0.9692025 , -0.15340483]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -1.634128	array([[-0.9572559 , -0.15144151]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.491899	array([[1.0245906, 0.5894611]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.151624	array([[1.0077106 , 0.59921527]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.558119	array([[-0.9420663 , -0.12443876]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -1.343938	array([[-0.9505171 , -0.14783682]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -2.600415	array([[-0.9188948 , -0.14398137]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -0.874263	array([[0.985568  , 0.58541805]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.930070	array([[0.9679656 , 0.60299873]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -1.596395	array([[-0.9789239, -0.1142027]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -1.617989	array([[-0.9525733 , -0.13170329]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -2.353553	array([[-0.950678  , -0.14069504]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -0.515094	array([[1.009331 , 0.5669268]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.892262	array([[0.98724926, 0.5819426 ]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.968028	array([[-1.0031953 , -0.14832202]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -1.563176	array([[-0.9797875 , -0.16093911]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -2.331855	array([[-0.9655907 , -0.15722029]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.947931	array([[1.0278327, 0.5873589]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -0.919976	array([[0.98714226, 0.60927963]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.420918	array([[-0.9686692 , -0.14178379]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 0.136938	array([[-0.9635395, -0.1559265]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -2.045577	array([[-0.95840514, -0.15554969]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.712433	array([[1.0093904, 0.5816644]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.698678	array([[1.0190605 , 0.56814253]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.022518	array([[-0.9878262, -0.1646603]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.109406	array([[-0.9795076 , -0.15605065]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -2.026198	array([[-0.959044 , -0.1747967]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.737719	array([[1.0361651 , 0.57951576]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:32985 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.062850	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.700355	array([[1.0599525, 0.566923 ]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -1.604073	array([[1.0460906 , 0.56634283]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.887003	array([[-0.9746271 , -0.17608705]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.564281	array([[-0.9782698 , -0.17801575]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.985911	array([[-0.966682  , -0.15401919]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.214064	array([[1.0316117 , 0.56680924]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.079915	array([[1.0056111, 0.5908176]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.379958	array([[-0.9332555 , -0.14782557]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.212051	array([[-0.94407886, -0.1506073 ]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.662442	array([[-0.96389264, -0.12211952]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.721835	array([[0.96641755, 0.5906266 ]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.862137	array([[0.9379138, 0.6063921]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.873256	array([[-0.94894725, -0.1135268 ]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.842350	array([[-0.903769  , -0.12688127]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -3.097361	array([[-0.89113426, -0.10757428]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.231526	array([[0.9704615, 0.5954067]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.655362	array([[0.9386593 , 0.60787565]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.932556	array([[-0.96805984, -0.08979902]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.289053	array([[-0.9216998 , -0.13024095]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.673172	array([[-0.8882945, -0.1350668]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.466230	array([[1.0037777, 0.5870342]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.901679	array([[0.9785979 , 0.60349035]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.651505	array([[-0.9566929 , -0.11070218]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.081846	array([[-0.962103  , -0.13587058]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.805376	array([[-0.94468594, -0.13989788]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.307591	array([[1.0258493 , 0.56545407]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.899653	array([[0.9809464, 0.5940021]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.308382	array([[-0.936112 , -0.1560443]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.957883	array([[-0.95350796, -0.16792062]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -2.468436	array([[-0.94977814, -0.16138934]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = 0.244533	array([[1.0174512 , 0.57927287]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.611840	array([[0.9994411, 0.5983316]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.534783	array([[-0.97690356, -0.14746228]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -1.419881	array([[-0.9526404 , -0.17935213]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.773055	array([[-0.9534976 , -0.14956456]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.895378	array([[1.020482 , 0.5900695]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.939611	array([[0.9881904, 0.5958555]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 0.053216	array([[-0.9413118 , -0.12350785]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.981611	array([[-0.9281404 , -0.13532624]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.941212	array([[-0.91065896, -0.1364434 ]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -0.891427	array([[1.002965 , 0.5710634]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.572573	array([[0.97044504, 0.5881612 ]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.876981	array([[-0.9314986 , -0.11349407]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -1.169664	array([[-0.9044084 , -0.12397712]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -2.767375	array([[-0.922579  , -0.13121513]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.059995	array([[1.0029125, 0.5559779]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.419203	array([[0.9692894 , 0.57708603]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -1.918668	array([[-0.96898496, -0.12134786]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -2.396534	array([[-0.93570167, -0.12166689]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -3.346320	array([[-0.96451783, -0.11429971]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.393560	array([[0.9960294, 0.5803363]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -2.037986	array([[0.9812039 , 0.59287626]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.323420	array([[-0.9945855 , -0.14310697]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.712778	array([[-0.9475452 , -0.16584231]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.743212	array([[-0.92820376, -0.16971034]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.465246	array([[1.0319703 , 0.55555737]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.141184	array([[1.0130775, 0.5737023]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.258359	array([[-0.9599314 , -0.18704444]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -1.456049	array([[-0.9655982 , -0.16072686]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -2.046047	array([[-0.956505  , -0.15225118]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.516536	array([[1.03933  , 0.5732972]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.146977	array([[1.0228872 , 0.58206815]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.522485	array([[-0.9509927 , -0.17078361]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -1.302962	array([[-0.95490026, -0.17352721]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.932747	array([[-0.9739242 , -0.15997662]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.130556	array([[1.0401497, 0.5604199]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.300942	array([[1.0214461, 0.5732412]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.183517	array([[-0.9785968 , -0.18495518]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.393973	array([[-0.95775914, -0.19937578]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -1.354490	array([[-0.94188815, -0.19330168]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.220252	array([[1.059515  , 0.55765843]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.510614	array([[1.0440385 , 0.58070403]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.939128	array([[-0.9569876 , -0.17713538]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.601425	array([[-0.9692025 , -0.15340483]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -1.634128	array([[-0.9572559 , -0.15144151]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.491899	array([[1.0245906, 0.5894611]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.151624	array([[1.0077106 , 0.59921527]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.558119	array([[-0.9420663 , -0.12443876]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -1.343938	array([[-0.9505171 , -0.14783682]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -2.600415	array([[-0.9188948 , -0.14398137]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -0.874263	array([[0.985568  , 0.58541805]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.930070	array([[0.9679656 , 0.60299873]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -1.596395	array([[-0.9789239, -0.1142027]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -1.617989	array([[-0.9525733 , -0.13170329]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -2.353553	array([[-0.950678  , -0.14069504]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -0.515094	array([[1.009331 , 0.5669268]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.892262	array([[0.98724926, 0.5819426 ]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.968028	array([[-1.0031953 , -0.14832202]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -1.563176	array([[-0.9797875 , -0.16093911]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -2.331855	array([[-0.9655907 , -0.15722029]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.947931	array([[1.0278327, 0.5873589]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -0.919976	array([[0.98714226, 0.60927963]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.420918	array([[-0.9686692 , -0.14178379]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 0.136938	array([[-0.9635395, -0.1559265]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -2.045577	array([[-0.95840514, -0.15554969]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2279ms
 Real time factor: 293.55
 UPS: 4415.971918
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 460 queries and explored 3.39 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 37793 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.712433	array([[1.0093904, 0.5816644]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.698678	array([[1.0190605 , 0.56814253]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.022518	array([[-0.9878262, -0.1646603]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.109406	array([[-0.9795076 , -0.15605065]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -2.026198	array([[-0.959044 , -0.1747967]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.737719	array([[1.0361651 , 0.57951576]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:37793 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.062850	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.700355	array([[1.0599525, 0.566923 ]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -1.604073	array([[1.0460906 , 0.56634283]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.887003	array([[-0.9746271 , -0.17608705]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.564281	array([[-0.9782698 , -0.17801575]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.985911	array([[-0.966682  , -0.15401919]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.214064	array([[1.0316117 , 0.56680924]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.079915	array([[1.0056111, 0.5908176]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.379958	array([[-0.9332555 , -0.14782557]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.212051	array([[-0.94407886, -0.1506073 ]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.662442	array([[-0.96389264, -0.12211952]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.721835	array([[0.96641755, 0.5906266 ]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.862137	array([[0.9379138, 0.6063921]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.873256	array([[-0.94894725, -0.1135268 ]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.842350	array([[-0.903769  , -0.12688127]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -3.097361	array([[-0.89113426, -0.10757428]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.231526	array([[0.9704615, 0.5954067]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.655362	array([[0.9386593 , 0.60787565]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.932556	array([[-0.96805984, -0.08979902]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.289053	array([[-0.9216998 , -0.13024095]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.673172	array([[-0.8882945, -0.1350668]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.466230	array([[1.0037777, 0.5870342]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.901679	array([[0.9785979 , 0.60349035]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.651505	array([[-0.9566929 , -0.11070218]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.081846	array([[-0.962103  , -0.13587058]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.805376	array([[-0.94468594, -0.13989788]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.307591	array([[1.0258493 , 0.56545407]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.899653	array([[0.9809464, 0.5940021]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.308382	array([[-0.936112 , -0.1560443]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.957883	array([[-0.95350796, -0.16792062]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -2.468436	array([[-0.94977814, -0.16138934]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = 0.244533	array([[1.0174512 , 0.57927287]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.611840	array([[0.9994411, 0.5983316]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.534783	array([[-0.97690356, -0.14746228]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -1.419881	array([[-0.9526404 , -0.17935213]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.773055	array([[-0.9534976 , -0.14956456]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.895378	array([[1.020482 , 0.5900695]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.939611	array([[0.9881904, 0.5958555]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 0.053216	array([[-0.9413118 , -0.12350785]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.981611	array([[-0.9281404 , -0.13532624]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.941212	array([[-0.91065896, -0.1364434 ]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -0.891427	array([[1.002965 , 0.5710634]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.572573	array([[0.97044504, 0.5881612 ]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.876981	array([[-0.9314986 , -0.11349407]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -1.169664	array([[-0.9044084 , -0.12397712]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -2.767375	array([[-0.922579  , -0.13121513]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.059995	array([[1.0029125, 0.5559779]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.419203	array([[0.9692894 , 0.57708603]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -1.918668	array([[-0.96898496, -0.12134786]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -2.396534	array([[-0.93570167, -0.12166689]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -3.346320	array([[-0.96451783, -0.11429971]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.393560	array([[0.9960294, 0.5803363]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -2.037986	array([[0.9812039 , 0.59287626]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.323420	array([[-0.9945855 , -0.14310697]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.712778	array([[-0.9475452 , -0.16584231]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.743212	array([[-0.92820376, -0.16971034]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.465246	array([[1.0319703 , 0.55555737]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2298ms
 Real time factor: 291.123
 UPS: 4379.460400
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 460 queries and explored 3.39 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 42713 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.141184	array([[1.0130775, 0.5737023]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.258359	array([[-0.9599314 , -0.18704444]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -1.456049	array([[-0.9655982 , -0.16072686]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -2.046047	array([[-0.956505  , -0.15225118]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.516536	array([[1.03933  , 0.5732972]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.146977	array([[1.0228872 , 0.58206815]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.522485	array([[-0.9509927 , -0.17078361]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -1.302962	array([[-0.95490026, -0.17352721]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.932747	array([[-0.9739242 , -0.15997662]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.130556	array([[1.0401497, 0.5604199]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.300942	array([[1.0214461, 0.5732412]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.183517	array([[-0.9785968 , -0.18495518]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.393973	array([[-0.95775914, -0.19937578]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -1.354490	array([[-0.94188815, -0.19330168]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.220252	array([[1.059515  , 0.55765843]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.510614	array([[1.0440385 , 0.58070403]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.939128	array([[-0.9569876 , -0.17713538]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.601425	array([[-0.9692025 , -0.15340483]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -1.634128	array([[-0.9572559 , -0.15144151]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.491899	array([[1.0245906, 0.5894611]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.151624	array([[1.0077106 , 0.59921527]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.558119	array([[-0.9420663 , -0.12443876]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -1.343938	array([[-0.9505171 , -0.14783682]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -2.600415	array([[-0.9188948 , -0.14398137]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -0.874263	array([[0.985568  , 0.58541805]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.930070	array([[0.9679656 , 0.60299873]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -1.596395	array([[-0.9789239, -0.1142027]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -1.617989	array([[-0.9525733 , -0.13170329]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -2.353553	array([[-0.950678  , -0.14069504]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -0.515094	array([[1.009331 , 0.5669268]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.892262	array([[0.98724926, 0.5819426 ]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.968028	array([[-1.0031953 , -0.14832202]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -1.563176	array([[-0.9797875 , -0.16093911]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -2.331855	array([[-0.9655907 , -0.15722029]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.947931	array([[1.0278327, 0.5873589]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -0.919976	array([[0.98714226, 0.60927963]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.420918	array([[-0.9686692 , -0.14178379]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 0.136938	array([[-0.9635395, -0.1559265]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -2.045577	array([[-0.95840514, -0.15554969]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.712433	array([[1.0093904, 0.5816644]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.698678	array([[1.0190605 , 0.56814253]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.022518	array([[-0.9878262, -0.1646603]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.109406	array([[-0.9795076 , -0.15605065]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -2.026198	array([[-0.959044 , -0.1747967]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.737719	array([[1.0361651 , 0.57951576]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:42713 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.062850	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.700355	array([[1.0599525, 0.566923 ]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -1.604073	array([[1.0460906 , 0.56634283]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.887003	array([[-0.9746271 , -0.17608705]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.564281	array([[-0.9782698 , -0.17801575]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.985911	array([[-0.966682  , -0.15401919]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.214064	array([[1.0316117 , 0.56680924]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.079915	array([[1.0056111, 0.5908176]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.379958	array([[-0.9332555 , -0.14782557]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.212051	array([[-0.94407886, -0.1506073 ]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.662442	array([[-0.96389264, -0.12211952]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.721835	array([[0.96641755, 0.5906266 ]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.862137	array([[0.9379138, 0.6063921]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.873256	array([[-0.94894725, -0.1135268 ]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.842350	array([[-0.903769  , -0.12688127]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -3.097361	array([[-0.89113426, -0.10757428]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.231526	array([[0.9704615, 0.5954067]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.655362	array([[0.9386593 , 0.60787565]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.932556	array([[-0.96805984, -0.08979902]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.289053	array([[-0.9216998 , -0.13024095]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.673172	array([[-0.8882945, -0.1350668]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.466230	array([[1.0037777, 0.5870342]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.901679	array([[0.9785979 , 0.60349035]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.651505	array([[-0.9566929 , -0.11070218]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.081846	array([[-0.962103  , -0.13587058]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.805376	array([[-0.94468594, -0.13989788]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.307591	array([[1.0258493 , 0.56545407]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.899653	array([[0.9809464, 0.5940021]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.308382	array([[-0.936112 , -0.1560443]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.957883	array([[-0.95350796, -0.16792062]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -2.468436	array([[-0.94977814, -0.16138934]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = 0.244533	array([[1.0174512 , 0.57927287]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.611840	array([[0.9994411, 0.5983316]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.534783	array([[-0.97690356, -0.14746228]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -1.419881	array([[-0.9526404 , -0.17935213]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.773055	array([[-0.9534976 , -0.14956456]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.895378	array([[1.020482 , 0.5900695]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.939611	array([[0.9881904, 0.5958555]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 0.053216	array([[-0.9413118 , -0.12350785]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.981611	array([[-0.9281404 , -0.13532624]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.941212	array([[-0.91065896, -0.1364434 ]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -0.891427	array([[1.002965 , 0.5710634]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.572573	array([[0.97044504, 0.5881612 ]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.876981	array([[-0.9314986 , -0.11349407]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -1.169664	array([[-0.9044084 , -0.12397712]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -2.767375	array([[-0.922579  , -0.13121513]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.059995	array([[1.0029125, 0.5559779]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.419203	array([[0.9692894 , 0.57708603]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -1.918668	array([[-0.96898496, -0.12134786]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -2.396534	array([[-0.93570167, -0.12166689]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -3.346320	array([[-0.96451783, -0.11429971]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.393560	array([[0.9960294, 0.5803363]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -2.037986	array([[0.9812039 , 0.59287626]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.323420	array([[-0.9945855 , -0.14310697]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.712778	array([[-0.9475452 , -0.16584231]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.743212	array([[-0.92820376, -0.16971034]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.465246	array([[1.0319703 , 0.55555737]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.141184	array([[1.0130775, 0.5737023]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.258359	array([[-0.9599314 , -0.18704444]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -1.456049	array([[-0.9655982 , -0.16072686]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -2.046047	array([[-0.956505  , -0.15225118]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.516536	array([[1.03933  , 0.5732972]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.146977	array([[1.0228872 , 0.58206815]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.522485	array([[-0.9509927 , -0.17078361]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -1.302962	array([[-0.95490026, -0.17352721]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.932747	array([[-0.9739242 , -0.15997662]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.130556	array([[1.0401497, 0.5604199]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.300942	array([[1.0214461, 0.5732412]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.183517	array([[-0.9785968 , -0.18495518]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.393973	array([[-0.95775914, -0.19937578]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -1.354490	array([[-0.94188815, -0.19330168]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.220252	array([[1.059515  , 0.55765843]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.510614	array([[1.0440385 , 0.58070403]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.939128	array([[-0.9569876 , -0.17713538]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.601425	array([[-0.9692025 , -0.15340483]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -1.634128	array([[-0.9572559 , -0.15144151]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.491899	array([[1.0245906, 0.5894611]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.151624	array([[1.0077106 , 0.59921527]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.558119	array([[-0.9420663 , -0.12443876]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -1.343938	array([[-0.9505171 , -0.14783682]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -2.600415	array([[-0.9188948 , -0.14398137]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -0.874263	array([[0.985568  , 0.58541805]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.930070	array([[0.9679656 , 0.60299873]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -1.596395	array([[-0.9789239, -0.1142027]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -1.617989	array([[-0.9525733 , -0.13170329]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2241ms
 Real time factor: 298.527
 UPS: 4490.852298
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 460 queries and explored 3.39 edges on average.
DijkstraRouter spent 1ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 59283 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -2.353553	array([[-0.950678  , -0.14069504]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -0.515094	array([[1.009331 , 0.5669268]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.892262	array([[0.98724926, 0.5819426 ]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.968028	array([[-1.0031953 , -0.14832202]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -1.563176	array([[-0.9797875 , -0.16093911]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -2.331855	array([[-0.9655907 , -0.15722029]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.947931	array([[1.0278327, 0.5873589]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -0.919976	array([[0.98714226, 0.60927963]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.420918	array([[-0.9686692 , -0.14178379]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 0.136938	array([[-0.9635395, -0.1559265]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -2.045577	array([[-0.95840514, -0.15554969]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.712433	array([[1.0093904, 0.5816644]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.698678	array([[1.0190605 , 0.56814253]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.022518	array([[-0.9878262, -0.1646603]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.109406	array([[-0.9795076 , -0.15605065]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -2.026198	array([[-0.959044 , -0.1747967]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.737719	array([[1.0361651 , 0.57951576]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:59283 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -0.619296	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 40	action = 1	current_phase = 0	next_phase = 1	reward = -1.897609	array([[-0.9542076 , -0.16660476]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -1.065417	array([[1.0505183 , 0.56242007]], dtype=float32)
time = 53	action = 1	current_phase = 1	next_phase = 0	reward = -1.938885	array([[1.014507 , 0.5784839]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.303795	array([[-0.9594916 , -0.17368269]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -1.194378	array([[-0.95840496, -0.16386126]], dtype=float32)
time = 71	action = 0	current_phase = 0	next_phase = 1	reward = -1.908283	array([[-0.94425106, -0.14991367]], dtype=float32)
time = 76	action = 1	current_phase = 0	next_phase = 1	reward = -1.819985	array([[-0.96815723, -0.13421485]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = 0.905740	array([[1.0324385, 0.5600534]], dtype=float32)
time = 89	action = 1	current_phase = 1	next_phase = 0	reward = -1.344118	array([[0.99733293, 0.59752667]], dtype=float32)
time = 97	action = 0	current_phase = 0	next_phase = 1	reward = -0.669165	array([[-0.9654049 , -0.12336343]], dtype=float32)
time = 102	action = 0	current_phase = 0	next_phase = 1	reward = -0.761386	array([[-0.9240983 , -0.14199066]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -1.148912	array([[-0.92567784, -0.13691556]], dtype=float32)
time = 112	action = 1	current_phase = 0	next_phase = 1	reward = -2.226307	array([[-0.914116  , -0.13984871]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = 0.438851	array([[1.0061624, 0.5692864]], dtype=float32)
time = 125	action = 1	current_phase = 1	next_phase = 0	reward = -1.755178	array([[0.96443164, 0.60037327]], dtype=float32)
time = 133	action = 0	current_phase = 0	next_phase = 1	reward = -0.847448	array([[-0.9570796, -0.0772469]], dtype=float32)
time = 138	action = 0	current_phase = 0	next_phase = 1	reward = -1.704191	array([[-0.9255921 , -0.11289863]], dtype=float32)
time = 143	action = 0	current_phase = 0	next_phase = 1	reward = -1.868586	array([[-0.9269494 , -0.11675015]], dtype=float32)
time = 148	action = 1	current_phase = 0	next_phase = 1	reward = -4.314300	array([[-0.9233949 , -0.11828225]], dtype=float32)
time = 156	action = 0	current_phase = 1	next_phase = 0	reward = -0.698763	array([[0.97269106, 0.57683384]], dtype=float32)
time = 161	action = 1	current_phase = 1	next_phase = 0	reward = -2.720003	array([[0.93028957, 0.60364765]], dtype=float32)
time = 169	action = 0	current_phase = 0	next_phase = 1	reward = -1.694838	array([[-0.9597538 , -0.10048388]], dtype=float32)
time = 174	action = 0	current_phase = 0	next_phase = 1	reward = -2.479516	array([[-0.90992767, -0.11949296]], dtype=float32)
time = 179	action = 0	current_phase = 0	next_phase = 1	reward = -2.769651	array([[-0.90936524, -0.13275541]], dtype=float32)
time = 184	action = 1	current_phase = 0	next_phase = 1	reward = -3.179933	array([[-0.9478097 , -0.12955093]], dtype=float32)
time = 192	action = 0	current_phase = 1	next_phase = 0	reward = -0.146003	array([[0.99756676, 0.57542646]], dtype=float32)
time = 197	action = 1	current_phase = 1	next_phase = 0	reward = -2.344087	array([[0.9884511 , 0.58832264]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -0.637521	array([[-0.93922347, -0.14389625]], dtype=float32)
time = 210	action = 0	current_phase = 0	next_phase = 1	reward = -2.048113	array([[-0.9073961 , -0.18398604]], dtype=float32)
time = 215	action = 0	current_phase = 0	next_phase = 1	reward = -2.488735	array([[-0.9268266 , -0.14996576]], dtype=float32)
time = 220	action = 1	current_phase = 0	next_phase = 1	reward = -3.319396	array([[-0.94903064, -0.14295915]], dtype=float32)
time = 228	action = 0	current_phase = 1	next_phase = 0	reward = 0.291201	array([[1.012421  , 0.57310855]], dtype=float32)
time = 233	action = 1	current_phase = 1	next_phase = 0	reward = -1.618413	array([[0.97268087, 0.6059248 ]], dtype=float32)
time = 241	action = 0	current_phase = 0	next_phase = 1	reward = -1.289932	array([[-0.96559626, -0.14608651]], dtype=float32)
time = 246	action = 0	current_phase = 0	next_phase = 1	reward = -1.692851	array([[-0.93763685, -0.16624147]], dtype=float32)
time = 251	action = 0	current_phase = 0	next_phase = 1	reward = -1.985974	array([[-0.93769854, -0.15098026]], dtype=float32)
time = 256	action = 1	current_phase = 0	next_phase = 1	reward = -2.596941	array([[-0.9640266 , -0.12201642]], dtype=float32)
time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -0.370225	array([[1.0078992 , 0.57552254]], dtype=float32)
time = 269	action = 1	current_phase = 1	next_phase = 0	reward = -1.052614	array([[0.97464633, 0.6057832 ]], dtype=float32)
time = 277	action = 0	current_phase = 0	next_phase = 1	reward = 0.436523	array([[-0.9844354 , -0.12030577]], dtype=float32)
time = 282	action = 0	current_phase = 0	next_phase = 1	reward = -0.580155	array([[-0.9391693 , -0.14098157]], dtype=float32)
time = 287	action = 0	current_phase = 0	next_phase = 1	reward = -0.114450	array([[-0.9160868 , -0.15522073]], dtype=float32)
time = 292	action = 1	current_phase = 0	next_phase = 1	reward = -1.481578	array([[-0.9219645 , -0.15096149]], dtype=float32)
time = 300	action = 0	current_phase = 1	next_phase = 0	reward = -0.199086	array([[0.99378467, 0.5864732 ]], dtype=float32)
time = 305	action = 1	current_phase = 1	next_phase = 0	reward = -1.232714	array([[0.9760256, 0.5966535]], dtype=float32)Simulation ended at time: 674.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2279ms
 Real time factor: 295.744
 UPS: 4452.830189
Vehicles: 
 Inserted: 259 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 472 queries and explored 3.22 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 32911 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00

time = 313	action = 0	current_phase = 0	next_phase = 1	reward = -0.665669	array([[-0.9804613 , -0.11910447]], dtype=float32)
time = 318	action = 0	current_phase = 0	next_phase = 1	reward = -1.318437	array([[-0.9347987, -0.1460003]], dtype=float32)
time = 323	action = 0	current_phase = 0	next_phase = 1	reward = -1.248970	array([[-0.92806476, -0.14726833]], dtype=float32)
time = 328	action = 1	current_phase = 0	next_phase = 1	reward = -2.366568	array([[-0.90603244, -0.15516497]], dtype=float32)
time = 336	action = 0	current_phase = 1	next_phase = 0	reward = 0.528270	array([[1.0076077 , 0.57229125]], dtype=float32)
time = 341	action = 1	current_phase = 1	next_phase = 0	reward = -2.036276	array([[0.98691237, 0.5861113 ]], dtype=float32)
time = 349	action = 0	current_phase = 0	next_phase = 1	reward = -1.283380	array([[-0.96531385, -0.12264487]], dtype=float32)
time = 354	action = 0	current_phase = 0	next_phase = 1	reward = -1.260331	array([[-0.93472415, -0.15214717]], dtype=float32)
time = 359	action = 0	current_phase = 0	next_phase = 1	reward = -1.826250	array([[-0.93406445, -0.15416366]], dtype=float32)
time = 364	action = 1	current_phase = 0	next_phase = 1	reward = -2.345477	array([[-0.9416187 , -0.15966812]], dtype=float32)
time = 372	action = 0	current_phase = 1	next_phase = 0	reward = -0.170650	array([[1.0231925, 0.5698714]], dtype=float32)
time = 377	action = 1	current_phase = 1	next_phase = 0	reward = -1.246395	array([[0.9753118, 0.5996175]], dtype=float32)
time = 385	action = 0	current_phase = 0	next_phase = 1	reward = -0.893480	array([[-0.96512264, -0.1528163 ]], dtype=float32)
time = 390	action = 0	current_phase = 0	next_phase = 1	reward = -1.471184	array([[-0.95291346, -0.16640896]], dtype=float32)
time = 395	action = 0	current_phase = 0	next_phase = 1	reward = -1.678937	array([[-0.9519497 , -0.16854925]], dtype=float32)
time = 400	action = 1	current_phase = 0	next_phase = 1	reward = -2.291212	array([[-0.9553368 , -0.16048566]], dtype=float32)
time = 408	action = 0	current_phase = 1	next_phase = 0	reward = 0.293431	array([[1.0161529 , 0.57556766]], dtype=float32)
time = 413	action = 1	current_phase = 1	next_phase = 0	reward = -1.660285	array([[0.99077773, 0.60119635]], dtype=float32)
time = 421	action = 0	current_phase = 0	next_phase = 1	reward = -0.835133	array([[-0.9903211, -0.1689904]], dtype=float32)
time = 426	action = 0	current_phase = 0	next_phase = 1	reward = -1.048008	array([[-0.9595278, -0.1759557]], dtype=float32)
time = 431	action = 0	current_phase = 0	next_phase = 1	reward = -1.699468	array([[-0.9689772 , -0.17617396]], dtype=float32)
time = 436	action = 1	current_phase = 0	next_phase = 1	reward = -2.000130	array([[-0.9763214 , -0.15455905]], dtype=float32)
time = 444	action = 0	current_phase = 1	next_phase = 0	reward = 0.074281	array([[1.0301921, 0.5681766]], dtype=float32)
time = 449	action = 1	current_phase = 1	next_phase = 0	reward = -0.998485	array([[0.9824483 , 0.59028834]], dtype=float32)
time = 457	action = 0	current_phase = 0	next_phase = 1	reward = 0.054689	array([[-0.965782  , -0.18217903]], dtype=float32)
time = 462	action = 0	current_phase = 0	next_phase = 1	reward = -0.258841	array([[-0.9484338, -0.2078276]], dtype=float32)
time = 467	action = 0	current_phase = 0	next_phase = 1	reward = -1.007243	array([[-0.9514095 , -0.18654542]], dtype=float32)
time = 472	action = 1	current_phase = 0	next_phase = 1	reward = -1.726984	array([[-0.97298205, -0.18727991]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -0.095228	array([[1.0542293 , 0.56512535]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -1.239773	array([[1.0271361, 0.5945997]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -0.123639	array([[-0.93227595, -0.15310745]], dtype=float32)
time = 498	action = 0	current_phase = 0	next_phase = 1	reward = -0.430497	array([[-0.933109 , -0.1705433]], dtype=float32)
time = 503	action = 0	current_phase = 0	next_phase = 1	reward = -1.290912	array([[-0.9546903 , -0.15443997]], dtype=float32)
time = 508	action = 1	current_phase = 0	next_phase = 1	reward = -1.928724	array([[-0.96011305, -0.12986498]], dtype=float32)
time = 516	action = 0	current_phase = 1	next_phase = 0	reward = -0.735935	array([[0.9908556, 0.5946367]], dtype=float32)
time = 521	action = 1	current_phase = 1	next_phase = 0	reward = -1.482967	array([[0.9841244 , 0.59279233]], dtype=float32)
time = 529	action = 0	current_phase = 0	next_phase = 1	reward = -0.100159	array([[-0.9506768 , -0.13739058]], dtype=float32)
time = 534	action = 0	current_phase = 0	next_phase = 1	reward = -0.905063	array([[-0.91362816, -0.15590602]], dtype=float32)
time = 539	action = 0	current_phase = 0	next_phase = 1	reward = -1.546540	array([[-0.9049535 , -0.16163737]], dtype=float32)
time = 544	action = 1	current_phase = 0	next_phase = 1	reward = -1.898898	array([[-0.9266848, -0.1412594]], dtype=float32)
time = 552	action = 0	current_phase = 1	next_phase = 0	reward = 0.163909	array([[1.0060008, 0.592757 ]], dtype=float32)
time = 557	action = 1	current_phase = 1	next_phase = 0	reward = -1.624222	array([[0.9830914 , 0.60312384]], dtype=float32)
time = 565	action = 0	current_phase = 0	next_phase = 1	reward = -0.657122	array([[-0.9502561 , -0.12440009]], dtype=float32)
time = 570	action = 0	current_phase = 0	next_phase = 1	reward = -1.160830	array([[-0.9266071 , -0.16545017]], dtype=float32)
time = 575	action = 0	current_phase = 0	next_phase = 1	reward = -2.007170	array([[-0.9344143 , -0.15727645]], dtype=float32)
time = 580	action = 1	current_phase = 0	next_phase = 1	reward = -2.923991	array([[-0.951557  , -0.14587846]], dtype=float32)
time = 588	action = 0	current_phase = 1	next_phase = 0	reward = -0.200296	array([[0.99872077, 0.58221453]], dtype=float32)
time = 593	action = 1	current_phase = 1	next_phase = 0	reward = -1.130983	array([[0.9815273, 0.5933925]], dtype=float32)
time = 601	action = 0	current_phase = 0	next_phase = 1	reward = -0.904061	array([[-0.97644913, -0.12985505]], dtype=float32)
time = 606	action = 0	current_phase = 0	next_phase = 1	reward = -0.890813	array([[-0.94685507, -0.14373821]], dtype=float32)
time = 611	action = 0	current_phase = 0	next_phase = 1	reward = -1.039701	array([[-0.9416824 , -0.14012468]], dtype=float32)
time = 616	action = 1	current_phase = 0	next_phase = 1	reward = -1.891106	array([[-0.980121  , -0.15197656]], dtype=float32)
time = 624	action = 0	current_phase = 1	next_phase = 0	reward = -0.344362	array([[1.0022122, 0.5709685]], dtype=float32)
time = 629	action = 1	current_phase = 1	next_phase = 0	reward = -1.168404	array([[0.99254733, 0.5866661 ]], dtype=float32)
time = 637	action = 0	current_phase = 0	next_phase = 1	reward = 0.382078	array([[-0.9867462 , -0.15735614]], dtype=float32)
time = 642	action = 0	current_phase = 0	next_phase = 1	reward = -0.711861	array([[-0.96391225, -0.18756859]], dtype=float32)
time = 647	action = 0	current_phase = 0	next_phase = 1	reward = -1.009996	array([[-0.97116905, -0.16237271]], dtype=float32)
time = 652	action = 1	current_phase = 0	next_phase = 1	reward = -1.905930	array([[-0.9751793, -0.1716026]], dtype=float32)
time = 660	action = 0	current_phase = 1	next_phase = 0	reward = -0.374460	array([[1.0173631, 0.5741918]], dtype=float32)
time = 665	action = 1	current_phase = 1	next_phase = 0	reward = -1.233168	array([[0.9890403, 0.5915079]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:32911 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -0.619296	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 40	action = 0	current_phase = 0	next_phase = 1	reward = -0.532205	array([[-0.9542076 , -0.16660476]], dtype=float32)
time = 45	action = 1	current_phase = 0	next_phase = 1	reward = -2.186602	array([[-0.96046305, -0.17138572]], dtype=float32)
time = 53	action = 0	current_phase = 1	next_phase = 0	reward = -0.980823	array([[1.0101825 , 0.57813996]], dtype=float32)
time = 58	action = 1	current_phase = 1	next_phase = 0	reward = -1.490829	array([[1.0157781, 0.5780937]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -0.482468	array([[-0.9617208 , -0.16286236]], dtype=float32)
time = 71	action = 0	current_phase = 0	next_phase = 1	reward = -1.431129	array([[-0.94427896, -0.16756925]], dtype=float32)
time = 76	action = 0	current_phase = 0	next_phase = 1	reward = -1.365787	array([[-0.948204  , -0.15072191]], dtype=float32)
time = 81	action = 0	current_phase = 0	next_phase = 1	reward = -1.999956	array([[-0.94617945, -0.14853701]], dtype=float32)
time = 86	action = 1	current_phase = 0	next_phase = 1	reward = -2.869992	array([[-0.9565499 , -0.13392346]], dtype=float32)
time = 94	action = 0	current_phase = 1	next_phase = 0	reward = 0.237719	array([[0.99067664, 0.5783307 ]], dtype=float32)
time = 99	action = 1	current_phase = 1	next_phase = 0	reward = -1.443854	array([[0.9705504 , 0.60248846]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -0.854192	array([[-0.91723514, -0.12391463]], dtype=float32)
time = 112	action = 0	current_phase = 0	next_phase = 1	reward = -1.718811	array([[-0.8996801 , -0.15317887]], dtype=float32)
time = 117	action = 0	current_phase = 0	next_phase = 1	reward = -2.229265	array([[-0.8876721 , -0.12606144]], dtype=float32)
time = 122	action = 0	current_phase = 0	next_phase = 1	reward = -2.666207	array([[-0.89215004, -0.1085209 ]], dtype=float32)
time = 127	action = 1	current_phase = 0	next_phase = 1	reward = -3.979487	array([[-0.90595084, -0.09417126]], dtype=float32)
time = 135	action = 0	current_phase = 1	next_phase = 0	reward = -0.859396	array([[0.95529544, 0.5980736 ]], dtype=float32)
time = 140	action = 1	current_phase = 1	next_phase = 0	reward = -2.008768	array([[0.91860396, 0.60550606]], dtype=float32)
time = 148	action = 0	current_phase = 0	next_phase = 1	reward = -1.465069	array([[-0.9345187 , -0.08204646]], dtype=float32)
time = 153	action = 0	current_phase = 0	next_phase = 1	reward = -2.169342	array([[-0.88610685, -0.11685602]], dtype=float32)
time = 158	action = 0	current_phase = 0	next_phase = 1	reward = -2.888981	array([[-0.8642335 , -0.12325042]], dtype=float32)
time = 163	action = 0	current_phase = 0	next_phase = 1	reward = -3.423289	array([[-0.8801642 , -0.10353994]], dtype=float32)
time = 168	action = 1	current_phase = 0	next_phase = 1	reward = -5.518797	array([[-0.90300214, -0.11596999]], dtype=float32)
time = 176	action = 0	current_phase = 1	next_phase = 0	reward = -0.691302	array([[0.9720107 , 0.59436613]], dtype=float32)
time = 181	action = 1	current_phase = 1	next_phase = 0	reward = -1.805512	array([[0.9586817 , 0.61808646]], dtype=float32)
time = 189	action = 0	current_phase = 0	next_phase = 1	reward = -1.573209	array([[-0.92835844, -0.09538998]], dtype=float32)
time = 194	action = 0	current_phase = 0	next_phase = 1	reward = -2.397253	array([[-0.9049271 , -0.12221847]], dtype=float32)
time = 199	action = 0	current_phase = 0	next_phase = 1	reward = -2.721609	array([[-0.89674884, -0.13714188]], dtype=float32)
time = 204	action = 0	current_phase = 0	next_phase = 1	reward = -3.050415	array([[-0.8998193 , -0.13365623]], dtype=float32)
time = 209	action = 1	current_phase = 0	next_phase = 1	reward = -4.642990	array([[-0.905792  , -0.13969302]], dtype=float32)
time = 217	action = 0	current_phase = 1	next_phase = 0	reward = -0.093850	array([[0.9939205, 0.5598273]], dtype=float32)
time = 222	action = 1	current_phase = 1	next_phase = 0	reward = -1.812393	array([[0.9569089, 0.5926905]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = -1.710074	array([[-0.9252536 , -0.10512695]], dtype=float32)
time = 235	action = 0	current_phase = 0	next_phase = 1	reward = -2.675754	array([[-0.9312317 , -0.11973497]], dtype=float32)
time = 240	action = 0	current_phase = 0	next_phase = 1	reward = -2.796450	array([[-0.92586696, -0.12661213]], dtype=float32)
time = 245	action = 0	current_phase = 0	next_phase = 1	reward = -4.000630	array([[-0.9327862 , -0.14095704]], dtype=float32)
time = 250	action = 1	current_phase = 0	next_phase = 1	reward = -4.585669	array([[-0.928723 , -0.1277704]], dtype=float32)
time = 258	action = 0	current_phase = 1	next_phase = 0	reward = 0.153852	array([[0.9768792, 0.5961895]], dtype=float32)
time = 263	action = 1	current_phase = 1	next_phase = 0	reward = -2.185923	array([[0.95562327, 0.6084965 ]], dtype=float32)
time = 271	action = 0	current_phase = 0	next_phase = 1	reward = -0.460633	array([[-0.9191451 , -0.08866761]], dtype=float32)
time = 276	action = 0	current_phase = 0	next_phase = 1	reward = -2.074462	array([[-0.8966198 , -0.13435084]], dtype=float32)
time = 281	action = 0	current_phase = 0	next_phase = 1	reward = -2.364247	array([[-0.87992895, -0.10912093]], dtype=float32)
time = 286	action = 0	current_phase = 0	next_phase = 1	reward = -2.269857	array([[-0.8844454 , -0.11845737]], dtype=float32)
time = 291	action = 1	current_phase = 0	next_phase = 1	reward = -3.982931	array([[-0.8923804 , -0.12046682]], dtype=float32)
time = 299	action = 0	current_phase = 1	next_phase = 0	reward = 0.001150	array([[0.95008427, 0.5915207 ]], dtype=float32)
time = 304	action = 1	current_phase = 1	next_phase = 0	reward = -2.005830	array([[0.9334813, 0.6047112]], dtype=float32)
time = 312	action = 0	current_phase = 0	next_phase = 1	reward = -1.217379	array([[-0.9391651 , -0.08043521]], dtype=float32)
time = 317	action = 0	current_phase = 0	next_phase = 1	reward = -2.667743	array([[-0.9016497 , -0.11576634]], dtype=float32)
time = 322	action = 0	current_phase = 0	next_phase = 1	reward = -2.907082	array([[-0.8919397 , -0.12718946]], dtype=float32)
time = 327	action = 0	current_phase = 0	next_phase = 1	reward = -3.736778	array([[-0.88346845, -0.13223769]], dtype=float32)
time = 332	action = 1	current_phase = 0	next_phase = 1	reward = -5.735027	array([[-0.8896415, -0.1205712]], dtype=float32)
time = 340	action = 0	current_phase = 1	next_phase = 0	reward = -0.702996	array([[0.95437163, 0.58216345]], dtype=float32)
time = 345	action = 1	current_phase = 1	next_phase = 0	reward = -2.059595	array([[0.9474367 , 0.59722954]], dtype=float32)
time = 353	action = 0	current_phase = 0	next_phase = 1	reward = -1.186180	array([[-0.94415617, -0.09760118]], dtype=float32)
time = 358	action = 0	current_phase = 0	next_phase = 1	reward = -2.505630	array([[-0.9032059 , -0.11207261]], dtype=float32)
time = 363	action = 0	current_phase = 0	next_phase = 1	reward = -2.657877	array([[-0.9032569 , -0.12196133]], dtype=float32)
time = 368	action = 0	current_phase = 0	next_phase = 1	reward = -3.110671	array([[-0.8998438 , -0.13528365]], dtype=float32)
time = 373	action = 1	current_phase = 0	next_phase = 1	reward = -4.006766	array([[-0.91068894, -0.13350928]], dtype=float32)
time = 381	action = 0	current_phase = 1	next_phase = 0	reward = 0.025113	array([[0.9912949, 0.5694617]], dtype=float32)
time = 386	action = 1	current_phase = 1	next_phase = 0	reward = -2.231580	array([[0.98061836, 0.57774293]], dtype=float32)
time = 394	action = 0	current_phase = 0	next_phase = 1	reward = -2.011335	array([[-0.9269499, -0.1406146]], dtype=float32)
time = 399	action = 0	current_phase = 0	next_phase = 1	reward = -2.845401	array([[-0.8980179 , -0.14742556]], dtype=float32)
time = 404	action = 0	current_phase = 0	next_phase = 1	reward = -3.571859	array([[-0.9176129 , -0.13212696]], dtype=float32)
time = 409	action = 0	current_phase = 0	next_phase = 1	reward = -3.739816	array([[-0.9233936 , -0.11929714]], dtype=float32)
time = 414	action = 1	current_phase = 0	next_phase = 1	reward = -4.857241	array([[-0.947457  , -0.11517038]], dtype=float32)
time = 422	action = 0	current_phase = 1	next_phase = 0	reward = 0.182427	array([[1.0172591 , 0.54811203]], dtype=float32)
time = 427	action = 1	current_phase = 1	next_phase = 0	reward = -1.727460	array([[0.9716501, 0.5933599]], dtype=float32)
time = 435	action = 0	current_phase = 0	next_phase = 1	reward = -1.640097	array([[-0.9568537 , -0.12173417]], dtype=float32)
time = 440	action = 0	current_phase = 0	next_phase = 1	reward = -2.453869	array([[-0.93556863, -0.14605644]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2495ms
 Real time factor: 268.136
 UPS: 4729.859719
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 406 queries and explored 3.28 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 60627 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00

time = 445	action = 0	current_phase = 0	next_phase = 1	reward = -2.803182	array([[-0.944046 , -0.1376768]], dtype=float32)
time = 450	action = 0	current_phase = 0	next_phase = 1	reward = -2.869929	array([[-0.96979725, -0.13403502]], dtype=float32)
time = 455	action = 1	current_phase = 0	next_phase = 1	reward = -3.612430	array([[-0.9730495 , -0.14602172]], dtype=float32)
time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -0.068148	array([[1.0039482, 0.5545615]], dtype=float32)
time = 468	action = 1	current_phase = 1	next_phase = 0	reward = -1.886643	array([[0.98003775, 0.5821807 ]], dtype=float32)
time = 476	action = 0	current_phase = 0	next_phase = 1	reward = -0.943841	array([[-0.9831843 , -0.15508835]], dtype=float32)
time = 481	action = 0	current_phase = 0	next_phase = 1	reward = -1.862117	array([[-0.9364276 , -0.16289777]], dtype=float32)
time = 486	action = 0	current_phase = 0	next_phase = 1	reward = -2.094810	array([[-0.94855845, -0.14305308]], dtype=float32)
time = 491	action = 0	current_phase = 0	next_phase = 1	reward = -2.177476	array([[-0.9517276 , -0.14846253]], dtype=float32)
time = 496	action = 1	current_phase = 0	next_phase = 1	reward = -3.063607	array([[-0.9781977 , -0.14080426]], dtype=float32)
time = 504	action = 0	current_phase = 1	next_phase = 0	reward = 0.077117	array([[1.0270478, 0.5761902]], dtype=float32)
time = 509	action = 1	current_phase = 1	next_phase = 0	reward = -1.986546	array([[0.97332895, 0.6180862 ]], dtype=float32)
time = 517	action = 0	current_phase = 0	next_phase = 1	reward = -0.648995	array([[-0.99088883, -0.11861207]], dtype=float32)
time = 522	action = 0	current_phase = 0	next_phase = 1	reward = -1.016919	array([[-0.97029305, -0.14193127]], dtype=float32)
time = 527	action = 0	current_phase = 0	next_phase = 1	reward = -1.512462	array([[-0.95710796, -0.16653466]], dtype=float32)
time = 532	action = 0	current_phase = 0	next_phase = 1	reward = -1.459612	array([[-0.92807055, -0.1474743 ]], dtype=float32)
time = 537	action = 1	current_phase = 0	next_phase = 1	reward = -1.419126	array([[-0.91537964, -0.14715439]], dtype=float32)
time = 545	action = 0	current_phase = 1	next_phase = 0	reward = 0.363935	array([[1.0315378, 0.5752774]], dtype=float32)
time = 550	action = 1	current_phase = 1	next_phase = 0	reward = -1.831974	array([[1.0100223, 0.5919739]], dtype=float32)
time = 558	action = 0	current_phase = 0	next_phase = 1	reward = -0.721548	array([[-0.9736557 , -0.10899168]], dtype=float32)
time = 563	action = 0	current_phase = 0	next_phase = 1	reward = -1.234479	array([[-0.9596805, -0.1494106]], dtype=float32)
time = 568	action = 0	current_phase = 0	next_phase = 1	reward = -1.746828	array([[-0.9652403, -0.1508864]], dtype=float32)
time = 573	action = 0	current_phase = 0	next_phase = 1	reward = -1.801722	array([[-0.94696075, -0.14144239]], dtype=float32)
time = 578	action = 1	current_phase = 0	next_phase = 1	reward = -3.024748	array([[-0.9705158 , -0.15760507]], dtype=float32)
time = 586	action = 0	current_phase = 1	next_phase = 0	reward = 0.028799	array([[1.0053656, 0.5780989]], dtype=float32)
time = 591	action = 1	current_phase = 1	next_phase = 0	reward = -1.262654	array([[0.97432774, 0.6005615 ]], dtype=float32)
time = 599	action = 0	current_phase = 0	next_phase = 1	reward = -0.574974	array([[-0.97085446, -0.13750702]], dtype=float32)
time = 604	action = 0	current_phase = 0	next_phase = 1	reward = -1.092675	array([[-0.93963754, -0.15008086]], dtype=float32)
time = 609	action = 0	current_phase = 0	next_phase = 1	reward = -0.993680	array([[-0.93760884, -0.13087676]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -1.228252	array([[-0.9708143 , -0.14317322]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.946678	array([[-0.9762876 , -0.14851227]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.540125	array([[1.0163221 , 0.57088035]], dtype=float32)
time = 632	action = 1	current_phase = 1	next_phase = 0	reward = -0.780356	array([[1.0001268 , 0.58550507]], dtype=float32)
time = 640	action = 0	current_phase = 0	next_phase = 1	reward = -0.205290	array([[-0.9889432 , -0.16936013]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.223891	array([[-0.96172535, -0.17554286]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.204564	array([[-0.9729392 , -0.15276554]], dtype=float32)
time = 655	action = 0	current_phase = 0	next_phase = 1	reward = -1.779215	array([[-0.9770183, -0.1615885]], dtype=float32)
time = 660	action = 1	current_phase = 0	next_phase = 1	reward = -2.458546	array([[-1.0105659 , -0.15657863]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:60627 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.154288	array([[1.0186824, 0.5857945]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.671490	array([[-0.9665299 , -0.16870281]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -1.575596	array([[-0.9743375 , -0.18299115]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.055419	array([[1.038988 , 0.5620096]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.237352	array([[1.0247917, 0.5804895]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.016446	array([[1.0266252 , 0.58742684]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.443110	array([[-0.93261683, -0.14644809]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.012227	array([[-0.96724576, -0.12643695]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.215970	array([[0.9896348 , 0.58204395]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.283480	array([[0.9522838 , 0.60149616]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.040891	array([[0.9523947, 0.608362 ]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.977593	array([[-0.9307659, -0.1208716]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.883918	array([[-0.9117373 , -0.13243294]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = 0.286657	array([[0.997843 , 0.5845383]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.582469	array([[0.9639263 , 0.60724354]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.463147	array([[0.93206966, 0.6148259 ]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.670579	array([[-0.9605349, -0.1144904]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -2.175688	array([[-0.9312997 , -0.14776543]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.500865	array([[1.0043056 , 0.57488203]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.869957	array([[0.99170566, 0.596291  ]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.565694	array([[0.97493887, 0.6129831 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.598299	array([[-0.9549776 , -0.13879357]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -2.046704	array([[-0.97632277, -0.1564456 ]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.903490	array([[1.0148947 , 0.57730097]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.206850	array([[1.0178757 , 0.58762157]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -2.385158	array([[1.0291884 , 0.58050954]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.924469	array([[-0.92429096, -0.14293228]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.927054	array([[-0.9781265 , -0.15951791]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = 0.524192	array([[1.0483445 , 0.55052745]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.141082	array([[1.0072646, 0.5962632]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.153674	array([[1.002711  , 0.60035646]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.351354	array([[-0.99024737, -0.14973105]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.521358	array([[-0.97443014, -0.178325  ]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.269246	array([[1.0534906, 0.5724657]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.910557	array([[1.032094 , 0.5896538]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.851775	array([[1.0076883, 0.5870092]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.217784	array([[-0.9448881 , -0.11792953]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -2.115930	array([[-0.928639  , -0.12537992]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -1.184492	array([[1.0177798, 0.5721651]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -1.533233	array([[0.95663756, 0.5994168 ]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.712496	array([[0.9500864 , 0.60278124]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.307295	array([[-0.93763655, -0.11037044]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -2.443216	array([[-0.9032067 , -0.13576388]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.424342	array([[0.991735 , 0.5641668]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -0.754622	array([[0.9675661, 0.5851645]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -2.045729	array([[0.9401987, 0.5985634]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.748921	array([[-0.99016863, -0.14691934]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.629664	array([[-0.9520756, -0.1451788]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.422136	array([[1.0153811, 0.5775811]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.044042	array([[1.0120432 , 0.58710116]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.363074	array([[1.0026907 , 0.58526385]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.030510	array([[-0.96487   , -0.15574525]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.927751	array([[-0.9469114 , -0.17888647]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.907515	array([[1.0352211, 0.5634943]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -1.311643	array([[1.0201592, 0.5715707]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.384423	array([[1.0132005 , 0.57394946]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.151676	array([[-0.98204005, -0.17403717]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.783955	array([[-0.94778   , -0.17380527]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -0.407497	array([[1.0258694, 0.5744817]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -1.042190	array([[1.0056291 , 0.59481853]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.679479	array([[1.0105898, 0.5874685]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.325726	array([[-0.9789344 , -0.16462117]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.194196	array([[-0.95090306, -0.17209628]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -0.631407	array([[1.0489587 , 0.56619173]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.533807	array([[1.0001627, 0.5841137]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.511808	array([[1.0043209, 0.584891 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.211420	array([[-0.9983081 , -0.18220231]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.370356	array([[-0.95675975, -0.19167879]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -0.164275	array([[1.0373532, 0.5620906]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.063042	array([[1.0653077, 0.5606356]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.404625	array([[1.0539479, 0.5774778]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.880935	array([[-0.96996254, -0.1737552 ]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.895481	array([[-0.961079  , -0.15615302]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -0.660003	array([[1.0390666, 0.5782738]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.752343	array([[1.015147 , 0.6019701]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.357758	array([[1.0009956, 0.6023215]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.495662	array([[-0.9922424 , -0.10726675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -2.757643	array([[-0.95147586, -0.14306787]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -1.300101	array([[0.99538374, 0.56759804]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.893400	array([[0.95338076, 0.6020456 ]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.799074	array([[0.965493  , 0.60511327]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.934318	array([[-0.964518  , -0.13962105]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -2.074900	array([[-0.96281403, -0.13520518]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -1.335287	array([[1.0176188, 0.5740967]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.524769	array([[0.9879667, 0.5937983]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -2.468569	array([[0.9814966 , 0.59268284]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.646649	array([[-0.9905778, -0.1435135]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -1.282693	array([[-0.96777093, -0.17546725]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -0.104404	array([[1.0604949 , 0.56527436]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.829113	array([[1.0173751 , 0.59880525]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2255ms
 Real time factor: 296.674
 UPS: 4277.161863
Vehicles: 
 Inserted: 257 (Loaded: 313)
 Running: 15
 Waiting: 2

DijkstraRouter answered 440 queries and explored 3.41 edges on average.
DijkstraRouter spent 2ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 36441 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.668408	array([[1.0063326, 0.6073818]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.063598	array([[-0.9523895 , -0.13429481]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.356038	array([[-0.9572207 , -0.14993215]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.340797	array([[1.0436794 , 0.55491024]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.282400	array([[1.0298508 , 0.57055926]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.546743	array([[1.0177245 , 0.57545775]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.244718	array([[-0.972192  , -0.17120421]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.882899	array([[-0.98493993, -0.15153742]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.051064	array([[1.0154796, 0.5780237]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.688491	array([[0.9954733, 0.5916623]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:36441 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.154288	array([[1.0186824, 0.5857945]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.671490	array([[-0.9665299 , -0.16870281]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -1.575596	array([[-0.9743375 , -0.18299115]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.055419	array([[1.038988 , 0.5620096]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.237352	array([[1.0247917, 0.5804895]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.016446	array([[1.0266252 , 0.58742684]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.443110	array([[-0.93261683, -0.14644809]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.012227	array([[-0.96724576, -0.12643695]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.215970	array([[0.9896348 , 0.58204395]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.283480	array([[0.9522838 , 0.60149616]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.040891	array([[0.9523947, 0.608362 ]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.977593	array([[-0.9307659, -0.1208716]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.883918	array([[-0.9117373 , -0.13243294]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = 0.286657	array([[0.997843 , 0.5845383]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.582469	array([[0.9639263 , 0.60724354]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.463147	array([[0.93206966, 0.6148259 ]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.670579	array([[-0.9605349, -0.1144904]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -2.175688	array([[-0.9312997 , -0.14776543]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.500865	array([[1.0043056 , 0.57488203]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.869957	array([[0.99170566, 0.596291  ]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.565694	array([[0.97493887, 0.6129831 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.598299	array([[-0.9549776 , -0.13879357]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -2.046704	array([[-0.97632277, -0.1564456 ]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.903490	array([[1.0148947 , 0.57730097]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.206850	array([[1.0178757 , 0.58762157]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -2.385158	array([[1.0291884 , 0.58050954]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.924469	array([[-0.92429096, -0.14293228]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.927054	array([[-0.9781265 , -0.15951791]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = 0.524192	array([[1.0483445 , 0.55052745]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.141082	array([[1.0072646, 0.5962632]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.153674	array([[1.002711  , 0.60035646]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.351354	array([[-0.99024737, -0.14973105]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.521358	array([[-0.97443014, -0.178325  ]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.269246	array([[1.0534906, 0.5724657]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.910557	array([[1.032094 , 0.5896538]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.851775	array([[1.0076883, 0.5870092]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.217784	array([[-0.9448881 , -0.11792953]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -2.115930	array([[-0.928639  , -0.12537992]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -1.184492	array([[1.0177798, 0.5721651]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -1.533233	array([[0.95663756, 0.5994168 ]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.712496	array([[0.9500864 , 0.60278124]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.307295	array([[-0.93763655, -0.11037044]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -2.443216	array([[-0.9032067 , -0.13576388]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.424342	array([[0.991735 , 0.5641668]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -0.754622	array([[0.9675661, 0.5851645]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -2.045729	array([[0.9401987, 0.5985634]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.748921	array([[-0.99016863, -0.14691934]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.629664	array([[-0.9520756, -0.1451788]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.422136	array([[1.0153811, 0.5775811]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.044042	array([[1.0120432 , 0.58710116]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.363074	array([[1.0026907 , 0.58526385]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2208ms
 Real time factor: 302.989
 UPS: 4368.206522
Vehicles: 
 Inserted: 257 (Loaded: 313)
 Running: 15
 Waiting: 2

DijkstraRouter answered 440 queries and explored 3.41 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 51087 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.030510	array([[-0.96487   , -0.15574525]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.927751	array([[-0.9469114 , -0.17888647]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.907515	array([[1.0352211, 0.5634943]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -1.311643	array([[1.0201592, 0.5715707]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.384423	array([[1.0132005 , 0.57394946]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.151676	array([[-0.98204005, -0.17403717]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.783955	array([[-0.94778   , -0.17380527]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -0.407497	array([[1.0258694, 0.5744817]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -1.042190	array([[1.0056291 , 0.59481853]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.679479	array([[1.0105898, 0.5874685]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.325726	array([[-0.9789344 , -0.16462117]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.194196	array([[-0.95090306, -0.17209628]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -0.631407	array([[1.0489587 , 0.56619173]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.533807	array([[1.0001627, 0.5841137]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.511808	array([[1.0043209, 0.584891 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.211420	array([[-0.9983081 , -0.18220231]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.370356	array([[-0.95675975, -0.19167879]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -0.164275	array([[1.0373532, 0.5620906]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.063042	array([[1.0653077, 0.5606356]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.404625	array([[1.0539479, 0.5774778]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.880935	array([[-0.96996254, -0.1737552 ]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.895481	array([[-0.961079  , -0.15615302]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -0.660003	array([[1.0390666, 0.5782738]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.752343	array([[1.015147 , 0.6019701]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.357758	array([[1.0009956, 0.6023215]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.495662	array([[-0.9922424 , -0.10726675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -2.757643	array([[-0.95147586, -0.14306787]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -1.300101	array([[0.99538374, 0.56759804]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.893400	array([[0.95338076, 0.6020456 ]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.799074	array([[0.965493  , 0.60511327]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.934318	array([[-0.964518  , -0.13962105]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -2.074900	array([[-0.96281403, -0.13520518]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -1.335287	array([[1.0176188, 0.5740967]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.524769	array([[0.9879667, 0.5937983]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -2.468569	array([[0.9814966 , 0.59268284]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.646649	array([[-0.9905778, -0.1435135]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -1.282693	array([[-0.96777093, -0.17546725]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -0.104404	array([[1.0604949 , 0.56527436]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.829113	array([[1.0173751 , 0.59880525]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.668408	array([[1.0063326, 0.6073818]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.063598	array([[-0.9523895 , -0.13429481]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.356038	array([[-0.9572207 , -0.14993215]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.340797	array([[1.0436794 , 0.55491024]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.282400	array([[1.0298508 , 0.57055926]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.546743	array([[1.0177245 , 0.57545775]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.244718	array([[-0.972192  , -0.17120421]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.882899	array([[-0.98493993, -0.15153742]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.051064	array([[1.0154796, 0.5780237]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.688491	array([[0.9954733, 0.5916623]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:51087 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.154288	array([[1.0186824, 0.5857945]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.671490	array([[-0.9665299 , -0.16870281]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -1.575596	array([[-0.9743375 , -0.18299115]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.055419	array([[1.038988 , 0.5620096]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.237352	array([[1.0247917, 0.5804895]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.016446	array([[1.0266252 , 0.58742684]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.443110	array([[-0.93261683, -0.14644809]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.012227	array([[-0.96724576, -0.12643695]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.215970	array([[0.9896348 , 0.58204395]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.283480	array([[0.9522838 , 0.60149616]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.040891	array([[0.9523947, 0.608362 ]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.977593	array([[-0.9307659, -0.1208716]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.883918	array([[-0.9117373 , -0.13243294]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = 0.286657	array([[0.997843 , 0.5845383]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.582469	array([[0.9639263 , 0.60724354]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.463147	array([[0.93206966, 0.6148259 ]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.670579	array([[-0.9605349, -0.1144904]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -2.175688	array([[-0.9312997 , -0.14776543]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.500865	array([[1.0043056 , 0.57488203]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.869957	array([[0.99170566, 0.596291  ]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.565694	array([[0.97493887, 0.6129831 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.598299	array([[-0.9549776 , -0.13879357]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -2.046704	array([[-0.97632277, -0.1564456 ]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.903490	array([[1.0148947 , 0.57730097]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.206850	array([[1.0178757 , 0.58762157]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -2.385158	array([[1.0291884 , 0.58050954]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.924469	array([[-0.92429096, -0.14293228]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.927054	array([[-0.9781265 , -0.15951791]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = 0.524192	array([[1.0483445 , 0.55052745]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.141082	array([[1.0072646, 0.5962632]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.153674	array([[1.002711  , 0.60035646]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.351354	array([[-0.99024737, -0.14973105]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.521358	array([[-0.97443014, -0.178325  ]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.269246	array([[1.0534906, 0.5724657]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.910557	array([[1.032094 , 0.5896538]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.851775	array([[1.0076883, 0.5870092]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.217784	array([[-0.9448881 , -0.11792953]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -2.115930	array([[-0.928639  , -0.12537992]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -1.184492	array([[1.0177798, 0.5721651]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -1.533233	array([[0.95663756, 0.5994168 ]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.712496	array([[0.9500864 , 0.60278124]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.307295	array([[-0.93763655, -0.11037044]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -2.443216	array([[-0.9032067 , -0.13576388]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.424342	array([[0.991735 , 0.5641668]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -0.754622	array([[0.9675661, 0.5851645]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -2.045729	array([[0.9401987, 0.5985634]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.748921	array([[-0.99016863, -0.14691934]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.629664	array([[-0.9520756, -0.1451788]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.422136	array([[1.0153811, 0.5775811]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.044042	array([[1.0120432 , 0.58710116]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.363074	array([[1.0026907 , 0.58526385]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.030510	array([[-0.96487   , -0.15574525]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.927751	array([[-0.9469114 , -0.17888647]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.907515	array([[1.0352211, 0.5634943]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -1.311643	array([[1.0201592, 0.5715707]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.384423	array([[1.0132005 , 0.57394946]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.151676	array([[-0.98204005, -0.17403717]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.783955	array([[-0.94778   , -0.17380527]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -0.407497	array([[1.0258694, 0.5744817]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -1.042190	array([[1.0056291 , 0.59481853]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.679479	array([[1.0105898, 0.5874685]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.325726	array([[-0.9789344 , -0.16462117]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.194196	array([[-0.95090306, -0.17209628]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -0.631407	array([[1.0489587 , 0.56619173]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.533807	array([[1.0001627, 0.5841137]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.511808	array([[1.0043209, 0.584891 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.211420	array([[-0.9983081 , -0.18220231]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.370356	array([[-0.95675975, -0.19167879]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -0.164275	array([[1.0373532, 0.5620906]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.063042	array([[1.0653077, 0.5606356]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.404625	array([[1.0539479, 0.5774778]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.880935	array([[-0.96996254, -0.1737552 ]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.895481	array([[-0.961079  , -0.15615302]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -0.660003	array([[1.0390666, 0.5782738]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.752343	array([[1.015147 , 0.6019701]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.357758	array([[1.0009956, 0.6023215]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.495662	array([[-0.9922424 , -0.10726675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -2.757643	array([[-0.95147586, -0.14306787]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -1.300101	array([[0.99538374, 0.56759804]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2244ms
 Real time factor: 298.128
 UPS: 4298.128342
Vehicles: 
 Inserted: 257 (Loaded: 313)
 Running: 15
 Waiting: 2

DijkstraRouter answered 440 queries and explored 3.41 edges on average.
DijkstraRouter spent 2ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 56349 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.893400	array([[0.95338076, 0.6020456 ]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.799074	array([[0.965493  , 0.60511327]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.934318	array([[-0.964518  , -0.13962105]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -2.074900	array([[-0.96281403, -0.13520518]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -1.335287	array([[1.0176188, 0.5740967]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.524769	array([[0.9879667, 0.5937983]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -2.468569	array([[0.9814966 , 0.59268284]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.646649	array([[-0.9905778, -0.1435135]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -1.282693	array([[-0.96777093, -0.17546725]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -0.104404	array([[1.0604949 , 0.56527436]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.829113	array([[1.0173751 , 0.59880525]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.668408	array([[1.0063326, 0.6073818]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.063598	array([[-0.9523895 , -0.13429481]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.356038	array([[-0.9572207 , -0.14993215]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.340797	array([[1.0436794 , 0.55491024]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.282400	array([[1.0298508 , 0.57055926]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.546743	array([[1.0177245 , 0.57545775]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.244718	array([[-0.972192  , -0.17120421]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.882899	array([[-0.98493993, -0.15153742]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.051064	array([[1.0154796, 0.5780237]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.688491	array([[0.9954733, 0.5916623]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:56349 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.154288	array([[1.0186824, 0.5857945]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.671490	array([[-0.9665299 , -0.16870281]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -1.575596	array([[-0.9743375 , -0.18299115]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.055419	array([[1.038988 , 0.5620096]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.237352	array([[1.0247917, 0.5804895]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.016446	array([[1.0266252 , 0.58742684]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.443110	array([[-0.93261683, -0.14644809]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.012227	array([[-0.96724576, -0.12643695]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.215970	array([[0.9896348 , 0.58204395]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.283480	array([[0.9522838 , 0.60149616]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.040891	array([[0.9523947, 0.608362 ]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.977593	array([[-0.9307659, -0.1208716]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.883918	array([[-0.9117373 , -0.13243294]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = 0.286657	array([[0.997843 , 0.5845383]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.582469	array([[0.9639263 , 0.60724354]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.463147	array([[0.93206966, 0.6148259 ]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.670579	array([[-0.9605349, -0.1144904]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -2.175688	array([[-0.9312997 , -0.14776543]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.500865	array([[1.0043056 , 0.57488203]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.869957	array([[0.99170566, 0.596291  ]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.565694	array([[0.97493887, 0.6129831 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.598299	array([[-0.9549776 , -0.13879357]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -2.046704	array([[-0.97632277, -0.1564456 ]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.903490	array([[1.0148947 , 0.57730097]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.206850	array([[1.0178757 , 0.58762157]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -2.385158	array([[1.0291884 , 0.58050954]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.924469	array([[-0.92429096, -0.14293228]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.927054	array([[-0.9781265 , -0.15951791]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = 0.524192	array([[1.0483445 , 0.55052745]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.141082	array([[1.0072646, 0.5962632]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.153674	array([[1.002711  , 0.60035646]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.351354	array([[-0.99024737, -0.14973105]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.521358	array([[-0.97443014, -0.178325  ]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.269246	array([[1.0534906, 0.5724657]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.910557	array([[1.032094 , 0.5896538]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.851775	array([[1.0076883, 0.5870092]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.217784	array([[-0.9448881 , -0.11792953]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -2.115930	array([[-0.928639  , -0.12537992]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -1.184492	array([[1.0177798, 0.5721651]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -1.533233	array([[0.95663756, 0.5994168 ]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2195ms
 Real time factor: 304.784
 UPS: 4394.077449
Vehicles: 
 Inserted: 257 (Loaded: 313)
 Running: 15
 Waiting: 2

DijkstraRouter answered 440 queries and explored 3.41 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 40485 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (1ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.712496	array([[0.9500864 , 0.60278124]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.307295	array([[-0.93763655, -0.11037044]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -2.443216	array([[-0.9032067 , -0.13576388]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.424342	array([[0.991735 , 0.5641668]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -0.754622	array([[0.9675661, 0.5851645]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -2.045729	array([[0.9401987, 0.5985634]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.748921	array([[-0.99016863, -0.14691934]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.629664	array([[-0.9520756, -0.1451788]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.422136	array([[1.0153811, 0.5775811]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.044042	array([[1.0120432 , 0.58710116]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.363074	array([[1.0026907 , 0.58526385]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.030510	array([[-0.96487   , -0.15574525]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.927751	array([[-0.9469114 , -0.17888647]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.907515	array([[1.0352211, 0.5634943]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -1.311643	array([[1.0201592, 0.5715707]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.384423	array([[1.0132005 , 0.57394946]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.151676	array([[-0.98204005, -0.17403717]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.783955	array([[-0.94778   , -0.17380527]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -0.407497	array([[1.0258694, 0.5744817]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -1.042190	array([[1.0056291 , 0.59481853]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.679479	array([[1.0105898, 0.5874685]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.325726	array([[-0.9789344 , -0.16462117]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.194196	array([[-0.95090306, -0.17209628]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -0.631407	array([[1.0489587 , 0.56619173]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.533807	array([[1.0001627, 0.5841137]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.511808	array([[1.0043209, 0.584891 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.211420	array([[-0.9983081 , -0.18220231]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.370356	array([[-0.95675975, -0.19167879]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -0.164275	array([[1.0373532, 0.5620906]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.063042	array([[1.0653077, 0.5606356]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.404625	array([[1.0539479, 0.5774778]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.880935	array([[-0.96996254, -0.1737552 ]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.895481	array([[-0.961079  , -0.15615302]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -0.660003	array([[1.0390666, 0.5782738]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.752343	array([[1.015147 , 0.6019701]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.357758	array([[1.0009956, 0.6023215]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.495662	array([[-0.9922424 , -0.10726675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -2.757643	array([[-0.95147586, -0.14306787]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -1.300101	array([[0.99538374, 0.56759804]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.893400	array([[0.95338076, 0.6020456 ]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.799074	array([[0.965493  , 0.60511327]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.934318	array([[-0.964518  , -0.13962105]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -2.074900	array([[-0.96281403, -0.13520518]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -1.335287	array([[1.0176188, 0.5740967]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.524769	array([[0.9879667, 0.5937983]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -2.468569	array([[0.9814966 , 0.59268284]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.646649	array([[-0.9905778, -0.1435135]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -1.282693	array([[-0.96777093, -0.17546725]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -0.104404	array([[1.0604949 , 0.56527436]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.829113	array([[1.0173751 , 0.59880525]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.668408	array([[1.0063326, 0.6073818]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.063598	array([[-0.9523895 , -0.13429481]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.356038	array([[-0.9572207 , -0.14993215]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.340797	array([[1.0436794 , 0.55491024]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.282400	array([[1.0298508 , 0.57055926]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.546743	array([[1.0177245 , 0.57545775]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.244718	array([[-0.972192  , -0.17120421]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.882899	array([[-0.98493993, -0.15153742]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.051064	array([[1.0154796, 0.5780237]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.688491	array([[0.9954733, 0.5916623]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:40485 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.154288	array([[1.0186824, 0.5857945]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.671490	array([[-0.9665299 , -0.16870281]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -1.575596	array([[-0.9743375 , -0.18299115]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.055419	array([[1.038988 , 0.5620096]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.237352	array([[1.0247917, 0.5804895]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.016446	array([[1.0266252 , 0.58742684]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.443110	array([[-0.93261683, -0.14644809]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.012227	array([[-0.96724576, -0.12643695]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.215970	array([[0.9896348 , 0.58204395]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.283480	array([[0.9522838 , 0.60149616]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.040891	array([[0.9523947, 0.608362 ]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.977593	array([[-0.9307659, -0.1208716]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.883918	array([[-0.9117373 , -0.13243294]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = 0.286657	array([[0.997843 , 0.5845383]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.582469	array([[0.9639263 , 0.60724354]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.463147	array([[0.93206966, 0.6148259 ]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.670579	array([[-0.9605349, -0.1144904]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -2.175688	array([[-0.9312997 , -0.14776543]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.500865	array([[1.0043056 , 0.57488203]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.869957	array([[0.99170566, 0.596291  ]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.565694	array([[0.97493887, 0.6129831 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.598299	array([[-0.9549776 , -0.13879357]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -2.046704	array([[-0.97632277, -0.1564456 ]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.903490	array([[1.0148947 , 0.57730097]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.206850	array([[1.0178757 , 0.58762157]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -2.385158	array([[1.0291884 , 0.58050954]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.924469	array([[-0.92429096, -0.14293228]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.927054	array([[-0.9781265 , -0.15951791]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = 0.524192	array([[1.0483445 , 0.55052745]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.141082	array([[1.0072646, 0.5962632]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.153674	array([[1.002711  , 0.60035646]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.351354	array([[-0.99024737, -0.14973105]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.521358	array([[-0.97443014, -0.178325  ]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.269246	array([[1.0534906, 0.5724657]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.910557	array([[1.032094 , 0.5896538]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.851775	array([[1.0076883, 0.5870092]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.217784	array([[-0.9448881 , -0.11792953]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -2.115930	array([[-0.928639  , -0.12537992]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -1.184492	array([[1.0177798, 0.5721651]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -1.533233	array([[0.95663756, 0.5994168 ]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.712496	array([[0.9500864 , 0.60278124]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.307295	array([[-0.93763655, -0.11037044]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -2.443216	array([[-0.9032067 , -0.13576388]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.424342	array([[0.991735 , 0.5641668]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -0.754622	array([[0.9675661, 0.5851645]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -2.045729	array([[0.9401987, 0.5985634]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.748921	array([[-0.99016863, -0.14691934]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.629664	array([[-0.9520756, -0.1451788]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.422136	array([[1.0153811, 0.5775811]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.044042	array([[1.0120432 , 0.58710116]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.363074	array([[1.0026907 , 0.58526385]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.030510	array([[-0.96487   , -0.15574525]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.927751	array([[-0.9469114 , -0.17888647]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.907515	array([[1.0352211, 0.5634943]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -1.311643	array([[1.0201592, 0.5715707]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.384423	array([[1.0132005 , 0.57394946]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.151676	array([[-0.98204005, -0.17403717]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.783955	array([[-0.94778   , -0.17380527]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -0.407497	array([[1.0258694, 0.5744817]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -1.042190	array([[1.0056291 , 0.59481853]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.679479	array([[1.0105898, 0.5874685]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.325726	array([[-0.9789344 , -0.16462117]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.194196	array([[-0.95090306, -0.17209628]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -0.631407	array([[1.0489587 , 0.56619173]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.533807	array([[1.0001627, 0.5841137]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.511808	array([[1.0043209, 0.584891 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.211420	array([[-0.9983081 , -0.18220231]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.370356	array([[-0.95675975, -0.19167879]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2216ms
 Real time factor: 301.895
 UPS: 4352.436823
Vehicles: 
 Inserted: 257 (Loaded: 313)
 Running: 15
 Waiting: 2

DijkstraRouter answered 440 queries and explored 3.41 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 58103 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -0.164275	array([[1.0373532, 0.5620906]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.063042	array([[1.0653077, 0.5606356]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.404625	array([[1.0539479, 0.5774778]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.880935	array([[-0.96996254, -0.1737552 ]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.895481	array([[-0.961079  , -0.15615302]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -0.660003	array([[1.0390666, 0.5782738]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.752343	array([[1.015147 , 0.6019701]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.357758	array([[1.0009956, 0.6023215]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.495662	array([[-0.9922424 , -0.10726675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -2.757643	array([[-0.95147586, -0.14306787]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -1.300101	array([[0.99538374, 0.56759804]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.893400	array([[0.95338076, 0.6020456 ]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.799074	array([[0.965493  , 0.60511327]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.934318	array([[-0.964518  , -0.13962105]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -2.074900	array([[-0.96281403, -0.13520518]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -1.335287	array([[1.0176188, 0.5740967]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.524769	array([[0.9879667, 0.5937983]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -2.468569	array([[0.9814966 , 0.59268284]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.646649	array([[-0.9905778, -0.1435135]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -1.282693	array([[-0.96777093, -0.17546725]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -0.104404	array([[1.0604949 , 0.56527436]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.829113	array([[1.0173751 , 0.59880525]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.668408	array([[1.0063326, 0.6073818]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.063598	array([[-0.9523895 , -0.13429481]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.356038	array([[-0.9572207 , -0.14993215]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.340797	array([[1.0436794 , 0.55491024]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.282400	array([[1.0298508 , 0.57055926]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.546743	array([[1.0177245 , 0.57545775]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.244718	array([[-0.972192  , -0.17120421]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.882899	array([[-0.98493993, -0.15153742]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.051064	array([[1.0154796, 0.5780237]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.688491	array([[0.9954733, 0.5916623]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:58103 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -1.464864	array([[1.0186824, 0.5857945]], dtype=float32)
time = 53	action = 1	current_phase = 1	next_phase = 0	reward = -2.081809	array([[1.030314 , 0.5716908]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -0.822916	array([[-0.9535487 , -0.16692029]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.976022	array([[-0.9479691 , -0.17448172]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.460478	array([[1.0278696 , 0.56884265]], dtype=float32)
time = 79	action = 0	current_phase = 1	next_phase = 0	reward = -0.899778	array([[1.0061188, 0.5907462]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -0.040525	array([[0.9867847, 0.5931876]], dtype=float32)
time = 89	action = 1	current_phase = 1	next_phase = 0	reward = -1.355617	array([[0.9891726 , 0.60422045]], dtype=float32)
time = 97	action = 0	current_phase = 0	next_phase = 1	reward = -0.332306	array([[-0.9643329 , -0.13019153]], dtype=float32)
time = 102	action = 1	current_phase = 0	next_phase = 1	reward = -1.194997	array([[-0.9320884 , -0.13558027]], dtype=float32)
time = 110	action = 0	current_phase = 1	next_phase = 0	reward = -0.603855	array([[1.0020437, 0.5741681]], dtype=float32)
time = 115	action = 0	current_phase = 1	next_phase = 0	reward = -0.882754	array([[0.99329525, 0.58063745]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -0.848062	array([[0.9703238 , 0.59835553]], dtype=float32)
time = 125	action = 1	current_phase = 1	next_phase = 0	reward = -1.243356	array([[0.97670245, 0.5953479 ]], dtype=float32)
time = 133	action = 0	current_phase = 0	next_phase = 1	reward = -0.731979	array([[-0.9359127, -0.1125283]], dtype=float32)
time = 138	action = 1	current_phase = 0	next_phase = 1	reward = -2.104732	array([[-0.91670036, -0.1341905 ]], dtype=float32)
time = 146	action = 0	current_phase = 1	next_phase = 0	reward = -0.099592	array([[0.9938011 , 0.57483506]], dtype=float32)
time = 151	action = 0	current_phase = 1	next_phase = 0	reward = -0.956237	array([[0.9636718 , 0.60042477]], dtype=float32)
time = 156	action = 0	current_phase = 1	next_phase = 0	reward = -0.879210	array([[0.93981487, 0.6103729 ]], dtype=float32)
time = 161	action = 1	current_phase = 1	next_phase = 0	reward = -1.404462	array([[0.9673165, 0.6025795]], dtype=float32)
time = 169	action = 0	current_phase = 0	next_phase = 1	reward = -0.160919	array([[-0.96271807, -0.12936246]], dtype=float32)
time = 174	action = 1	current_phase = 0	next_phase = 1	reward = -1.387627	array([[-0.93974775, -0.15766287]], dtype=float32)
time = 182	action = 0	current_phase = 1	next_phase = 0	reward = -0.669411	array([[1.0524868, 0.5841116]], dtype=float32)
time = 187	action = 0	current_phase = 1	next_phase = 0	reward = -1.200179	array([[1.0088414 , 0.60150135]], dtype=float32)
time = 192	action = 0	current_phase = 1	next_phase = 0	reward = -1.666191	array([[1.0088447, 0.6047199]], dtype=float32)
time = 197	action = 1	current_phase = 1	next_phase = 0	reward = -2.339187	array([[1.018753 , 0.5905136]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -0.108308	array([[-0.9303938 , -0.13674715]], dtype=float32)
time = 210	action = 1	current_phase = 0	next_phase = 1	reward = -1.785185	array([[-0.91941977, -0.15836675]], dtype=float32)
time = 218	action = 0	current_phase = 1	next_phase = 0	reward = -0.370667	array([[1.0437459, 0.555338 ]], dtype=float32)
time = 223	action = 0	current_phase = 1	next_phase = 0	reward = -0.513086	array([[0.99947166, 0.5949062 ]], dtype=float32)
time = 228	action = 0	current_phase = 1	next_phase = 0	reward = -0.634568	array([[1.0107776 , 0.59944355]], dtype=float32)
time = 233	action = 1	current_phase = 1	next_phase = 0	reward = -1.398134	array([[1.0070829, 0.6090052]], dtype=float32)
time = 241	action = 0	current_phase = 0	next_phase = 1	reward = 0.088454	array([[-0.96883655, -0.16343956]], dtype=float32)
time = 246	action = 1	current_phase = 0	next_phase = 1	reward = -2.092104	array([[-0.96551204, -0.16960768]], dtype=float32)
time = 254	action = 0	current_phase = 1	next_phase = 0	reward = -0.456998	array([[1.0568444, 0.5714742]], dtype=float32)
time = 259	action = 0	current_phase = 1	next_phase = 0	reward = -1.042343	array([[1.0259038 , 0.59881467]], dtype=float32)
time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -1.357449	array([[1.0151157 , 0.59398407]], dtype=float32)
time = 269	action = 1	current_phase = 1	next_phase = 0	reward = -1.610479	array([[0.9923633, 0.6048394]], dtype=float32)
time = 277	action = 0	current_phase = 0	next_phase = 1	reward = 0.466744	array([[-0.97846925, -0.09763331]], dtype=float32)
time = 282	action = 1	current_phase = 0	next_phase = 1	reward = -1.776223	array([[-0.93584627, -0.12175222]], dtype=float32)
time = 290	action = 0	current_phase = 1	next_phase = 0	reward = -1.176552	array([[1.0403779 , 0.57387555]], dtype=float32)
time = 295	action = 0	current_phase = 1	next_phase = 0	reward = -1.176320	array([[0.9892364, 0.59568  ]], dtype=float32)
time = 300	action = 0	current_phase = 1	next_phase = 0	reward = -1.442817	array([[0.96699715, 0.61063313]], dtype=float32)
time = 305	action = 1	current_phase = 1	next_phase = 0	reward = -2.158645	array([[0.9542488 , 0.61496925]], dtype=float32)
time = 313	action = 0	current_phase = 0	next_phase = 1	reward = -0.172867	array([[-0.95729566, -0.10078695]], dtype=float32)
time = 318	action = 1	current_phase = 0	next_phase = 1	reward = -1.463892	array([[-0.929786  , -0.14254314]], dtype=float32)
time = 326	action = 0	current_phase = 1	next_phase = 0	reward = -0.124144	array([[1.0524998, 0.5344359]], dtype=float32)
time = 331	action = 0	current_phase = 1	next_phase = 0	reward = -0.330165	array([[0.9756384 , 0.58064294]], dtype=float32)
time = 336	action = 0	current_phase = 1	next_phase = 0	reward = -0.486747	array([[0.964453 , 0.5954306]], dtype=float32)
time = 341	action = 1	current_phase = 1	next_phase = 0	reward = -1.471416	array([[0.969419  , 0.60072213]], dtype=float32)
time = 349	action = 0	current_phase = 0	next_phase = 1	reward = -0.448426	array([[-0.9945353 , -0.14111961]], dtype=float32)
time = 354	action = 1	current_phase = 0	next_phase = 1	reward = -1.961596	array([[-0.96057   , -0.16693547]], dtype=float32)
time = 362	action = 0	current_phase = 1	next_phase = 0	reward = -1.254123	array([[1.0237525, 0.5739975]], dtype=float32)
time = 367	action = 0	current_phase = 1	next_phase = 0	reward = -1.415122	array([[0.9929553, 0.5863067]], dtype=float32)
time = 372	action = 0	current_phase = 1	next_phase = 0	reward = -0.965051	array([[1.0233603, 0.5826424]], dtype=float32)
time = 377	action = 1	current_phase = 1	next_phase = 0	reward = -1.585315	array([[1.0083057 , 0.58625793]], dtype=float32)
time = 385	action = 0	current_phase = 0	next_phase = 1	reward = -0.263630	array([[-0.94469297, -0.14323425]], dtype=float32)
time = 390	action = 1	current_phase = 0	next_phase = 1	reward = -1.275270	array([[-0.94827473, -0.18519364]], dtype=float32)
time = 398	action = 0	current_phase = 1	next_phase = 0	reward = -0.151833	array([[1.0597866, 0.5500082]], dtype=float32)
time = 403	action = 0	current_phase = 1	next_phase = 0	reward = -0.482964	array([[1.012841 , 0.5895686]], dtype=float32)
time = 408	action = 0	current_phase = 1	next_phase = 0	reward = -0.474822	array([[1.0034523 , 0.59508985]], dtype=float32)
time = 413	action = 1	current_phase = 1	next_phase = 0	reward = -1.081777	array([[1.0214086, 0.587407 ]], dtype=float32)
time = 421	action = 0	current_phase = 0	next_phase = 1	reward = -0.335145	array([[-0.96119404, -0.17322013]], dtype=float32)
time = 426	action = 1	current_phase = 0	next_phase = 1	reward = -1.621627	array([[-0.94336265, -0.17209904]], dtype=float32)
time = 434	action = 0	current_phase = 1	next_phase = 0	reward = -0.454727	array([[1.0201101 , 0.57154644]], dtype=float32)
time = 439	action = 0	current_phase = 1	next_phase = 0	reward = -0.280016	array([[1.0066053 , 0.58600384]], dtype=float32)
time = 444	action = 0	current_phase = 1	next_phase = 0	reward = -0.389172	array([[1.0185723, 0.5740898]], dtype=float32)
time = 449	action = 1	current_phase = 1	next_phase = 0	reward = -1.385520	array([[1.0108737 , 0.57725567]], dtype=float32)
time = 457	action = 0	current_phase = 0	next_phase = 1	reward = 0.030448	array([[-0.9861815 , -0.17961034]], dtype=float32)
time = 462	action = 1	current_phase = 0	next_phase = 1	reward = -1.333875	array([[-0.96017605, -0.1878137 ]], dtype=float32)
time = 470	action = 0	current_phase = 1	next_phase = 0	reward = -0.542812	array([[1.0474155 , 0.55458754]], dtype=float32)
time = 475	action = 0	current_phase = 1	next_phase = 0	reward = -0.026837	array([[1.041973 , 0.5639874]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -0.778999	array([[1.0458142, 0.5747511]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -2.075456	array([[1.028568 , 0.5910314]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = 0.054654	array([[-0.948789  , -0.14131075]], dtype=float32)
time = 498	action = 1	current_phase = 0	next_phase = 1	reward = -1.187276	array([[-0.9274431 , -0.15881121]], dtype=float32)
time = 506	action = 0	current_phase = 1	next_phase = 0	reward = -0.484889	array([[1.0244795, 0.5820891]], dtype=float32)
time = 511	action = 0	current_phase = 1	next_phase = 0	reward = -0.896011	array([[1.0006695, 0.6066574]], dtype=float32)
time = 516	action = 0	current_phase = 1	next_phase = 0	reward = -1.083394	array([[1.0013692 , 0.59400576]], dtype=float32)
time = 521	action = 1	current_phase = 1	next_phase = 0	reward = -1.300690	array([[0.98185325, 0.5991367 ]], dtype=float32)
time = 529	action = 0	current_phase = 0	next_phase = 1	reward = 0.717990	array([[-0.99003214, -0.12475694]], dtype=float32)
time = 534	action = 1	current_phase = 0	next_phase = 1	reward = -1.198146	array([[-0.9360502 , -0.15460812]], dtype=float32)
time = 542	action = 0	current_phase = 1	next_phase = 0	reward = -0.306278	array([[1.064664  , 0.55412716]], dtype=float32)
time = 547	action = 0	current_phase = 1	next_phase = 0	reward = -0.119555	array([[1.0319064, 0.5867545]], dtype=float32)
time = 552	action = 0	current_phase = 1	next_phase = 0	reward = -0.648558	array([[1.021909  , 0.59898865]], dtype=float32)
time = 557	action = 1	current_phase = 1	next_phase = 0	reward = -1.281717	array([[0.9971318, 0.6020954]], dtype=float32)
time = 565	action = 0	current_phase = 0	next_phase = 1	reward = 0.253753	array([[-0.94413006, -0.13864961]], dtype=float32)
time = 570	action = 1	current_phase = 0	next_phase = 1	reward = -1.271048	array([[-0.9503745 , -0.17254803]], dtype=float32)
time = 578	action = 0	current_phase = 1	next_phase = 0	reward = -0.355952	array([[1.0585262 , 0.54781365]], dtype=float32)
time = 583	action = 0	current_phase = 1	next_phase = 0	reward = -0.607764	array([[0.9998368, 0.5953316]], dtype=float32)
time = 588	action = 0	current_phase = 1	next_phase = 0	reward = -0.276969	array([[1.0203471, 0.5877792]], dtype=float32)
time = 593	action = 1	current_phase = 1	next_phase = 0	reward = -1.159395	array([[1.0313631 , 0.58486044]], dtype=float32)
time = 601	action = 0	current_phase = 0	next_phase = 1	reward = -0.551673	array([[-0.95387197, -0.1351144 ]], dtype=float32)
time = 606	action = 1	current_phase = 0	next_phase = 1	reward = -1.355076	array([[-0.9632653 , -0.15257332]], dtype=float32)
time = 614	action = 0	current_phase = 1	next_phase = 0	reward = -0.852329	array([[1.0280496, 0.5827707]], dtype=float32)
time = 619	action = 0	current_phase = 1	next_phase = 0	reward = -1.107012	array([[1.0108296, 0.5877906]], dtype=float32)Simulation ended at time: 674.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2187ms
 Real time factor: 308.185
 UPS: 4322.816644
Vehicles: 
 Inserted: 260 (Loaded: 313)
 Running: 13
 Waiting: 0

DijkstraRouter answered 419 queries and explored 3.37 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 56761 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00

time = 624	action = 0	current_phase = 1	next_phase = 0	reward = -1.219890	array([[1.0041856, 0.5896324]], dtype=float32)
time = 629	action = 1	current_phase = 1	next_phase = 0	reward = -1.738851	array([[1.000605  , 0.58747005]], dtype=float32)
time = 637	action = 0	current_phase = 0	next_phase = 1	reward = 0.446905	array([[-0.9885179, -0.1376834]], dtype=float32)
time = 642	action = 1	current_phase = 0	next_phase = 1	reward = -0.838345	array([[-0.9672396 , -0.18302092]], dtype=float32)
time = 650	action = 0	current_phase = 1	next_phase = 0	reward = -0.279756	array([[1.063403 , 0.5437303]], dtype=float32)
time = 655	action = 0	current_phase = 1	next_phase = 0	reward = -0.210224	array([[1.0007871 , 0.58733714]], dtype=float32)
time = 660	action = 0	current_phase = 1	next_phase = 0	reward = -0.551729	array([[1.0394225, 0.5746259]], dtype=float32)
time = 665	action = 1	current_phase = 1	next_phase = 0	reward = -1.201016	array([[1.0118414 , 0.58078045]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:56761 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -1.464864	array([[1.0186824, 0.5857945]], dtype=float32)
time = 53	action = 0	current_phase = 1	next_phase = 0	reward = -1.350947	array([[1.030314 , 0.5716908]], dtype=float32)
time = 58	action = 1	current_phase = 1	next_phase = 0	reward = -1.882620	array([[1.0234663 , 0.57444066]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -0.244194	array([[-0.96543884, -0.14850274]], dtype=float32)
time = 71	action = 1	current_phase = 0	next_phase = 1	reward = -1.454673	array([[-0.94001734, -0.17267393]], dtype=float32)
time = 79	action = 0	current_phase = 1	next_phase = 0	reward = -0.490887	array([[1.0446188, 0.5656597]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -0.228979	array([[1.005272 , 0.5877036]], dtype=float32)
time = 89	action = 0	current_phase = 1	next_phase = 0	reward = -0.471892	array([[0.99710363, 0.5982112 ]], dtype=float32)
time = 94	action = 0	current_phase = 1	next_phase = 0	reward = -0.555205	array([[0.98506624, 0.59762764]], dtype=float32)
time = 99	action = 1	current_phase = 1	next_phase = 0	reward = -1.191559	array([[0.98909754, 0.60159755]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = 0.157487	array([[-0.96823317, -0.11327797]], dtype=float32)
time = 112	action = 1	current_phase = 0	next_phase = 1	reward = -1.266474	array([[-0.9184522 , -0.15165927]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = 0.076227	array([[1.032893  , 0.56311363]], dtype=float32)
time = 125	action = 0	current_phase = 1	next_phase = 0	reward = 0.472959	array([[0.9890868 , 0.59491056]], dtype=float32)
time = 130	action = 0	current_phase = 1	next_phase = 0	reward = -0.034452	array([[0.9675605 , 0.61484635]], dtype=float32)
time = 135	action = 0	current_phase = 1	next_phase = 0	reward = -0.596316	array([[0.97903347, 0.6099147 ]], dtype=float32)
time = 140	action = 1	current_phase = 1	next_phase = 0	reward = -1.379378	array([[0.9799279 , 0.59476477]], dtype=float32)
time = 148	action = 0	current_phase = 0	next_phase = 1	reward = -0.551633	array([[-0.9633648 , -0.12760746]], dtype=float32)
time = 153	action = 1	current_phase = 0	next_phase = 1	reward = -1.942353	array([[-0.93540007, -0.14602613]], dtype=float32)
time = 161	action = 0	current_phase = 1	next_phase = 0	reward = -0.846608	array([[1.0108377, 0.575307 ]], dtype=float32)
time = 166	action = 0	current_phase = 1	next_phase = 0	reward = -0.745976	array([[0.9736936 , 0.60488474]], dtype=float32)
time = 171	action = 0	current_phase = 1	next_phase = 0	reward = -0.760779	array([[0.99161744, 0.60718715]], dtype=float32)
time = 176	action = 0	current_phase = 1	next_phase = 0	reward = -0.943581	array([[0.9993845 , 0.60840845]], dtype=float32)
time = 181	action = 1	current_phase = 1	next_phase = 0	reward = -1.766620	array([[1.0069716, 0.6120336]], dtype=float32)
time = 189	action = 0	current_phase = 0	next_phase = 1	reward = -0.076282	array([[-0.9505502 , -0.13350543]], dtype=float32)
time = 194	action = 1	current_phase = 0	next_phase = 1	reward = -2.985877	array([[-0.94725895, -0.13521828]], dtype=float32)
time = 202	action = 0	current_phase = 1	next_phase = 0	reward = -1.832859	array([[1.0331501 , 0.56533015]], dtype=float32)
time = 207	action = 0	current_phase = 1	next_phase = 0	reward = -2.019205	array([[0.9909307, 0.5914899]], dtype=float32)
time = 212	action = 0	current_phase = 1	next_phase = 0	reward = -2.044269	array([[0.99047124, 0.5901984 ]], dtype=float32)
time = 217	action = 0	current_phase = 1	next_phase = 0	reward = -1.207141	array([[0.9749608, 0.5953853]], dtype=float32)
time = 222	action = 1	current_phase = 1	next_phase = 0	reward = -2.317739	array([[0.9835642 , 0.60132474]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = -0.413167	array([[-0.9490673 , -0.13328809]], dtype=float32)
time = 235	action = 1	current_phase = 0	next_phase = 1	reward = -1.662034	array([[-0.9605173 , -0.17927133]], dtype=float32)
time = 243	action = 0	current_phase = 1	next_phase = 0	reward = -0.966920	array([[1.0708784 , 0.55465287]], dtype=float32)
time = 248	action = 0	current_phase = 1	next_phase = 0	reward = -1.120358	array([[0.9954965 , 0.59996974]], dtype=float32)
time = 253	action = 0	current_phase = 1	next_phase = 0	reward = -0.899967	array([[1.0164156, 0.6025807]], dtype=float32)
time = 258	action = 0	current_phase = 1	next_phase = 0	reward = -1.088224	array([[1.023762 , 0.5965471]], dtype=float32)
time = 263	action = 1	current_phase = 1	next_phase = 0	reward = -2.546787	array([[1.0124869, 0.5969035]], dtype=float32)
time = 271	action = 0	current_phase = 0	next_phase = 1	reward = 0.004413	array([[-0.9486795 , -0.09992527]], dtype=float32)
time = 276	action = 1	current_phase = 0	next_phase = 1	reward = -2.163371	array([[-0.9283985 , -0.12027957]], dtype=float32)
time = 284	action = 0	current_phase = 1	next_phase = 0	reward = -1.097781	array([[1.017253  , 0.58020717]], dtype=float32)
time = 289	action = 0	current_phase = 1	next_phase = 0	reward = -1.407136	array([[0.9709351, 0.608238 ]], dtype=float32)
time = 294	action = 0	current_phase = 1	next_phase = 0	reward = -1.801041	array([[0.9591462, 0.607097 ]], dtype=float32)
time = 299	action = 0	current_phase = 1	next_phase = 0	reward = -1.573317	array([[0.96262085, 0.608699  ]], dtype=float32)
time = 304	action = 1	current_phase = 1	next_phase = 0	reward = -2.691964	array([[0.9630796, 0.6093923]], dtype=float32)
time = 312	action = 0	current_phase = 0	next_phase = 1	reward = -0.248190	array([[-0.93637955, -0.0987798 ]], dtype=float32)
time = 317	action = 1	current_phase = 0	next_phase = 1	reward = -2.414097	array([[-0.92241293, -0.13492098]], dtype=float32)
time = 325	action = 0	current_phase = 1	next_phase = 0	reward = -0.862676	array([[1.0317127, 0.5515288]], dtype=float32)
time = 330	action = 0	current_phase = 1	next_phase = 0	reward = -0.976521	array([[0.9559051 , 0.59532386]], dtype=float32)
time = 335	action = 0	current_phase = 1	next_phase = 0	reward = -1.222754	array([[0.9449673, 0.6098228]], dtype=float32)
time = 340	action = 0	current_phase = 1	next_phase = 0	reward = -0.694170	array([[0.9628986, 0.6067971]], dtype=float32)
time = 345	action = 1	current_phase = 1	next_phase = 0	reward = -1.338640	array([[0.99023676, 0.59770906]], dtype=float32)
time = 353	action = 0	current_phase = 0	next_phase = 1	reward = 0.735659	array([[-1.0019554 , -0.14482453]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2241ms
 Real time factor: 298.527
 UPS: 4337.795627
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 411 queries and explored 3.42 edges on average.
DijkstraRouter spent 1ms answering queries (0.00ms on average).

time = 358	action = 1	current_phase = 0	next_phase = 1	reward = -1.488473	array([[-0.9673326, -0.1919243]], dtype=float32)
time = 366	action = 0	current_phase = 1	next_phase = 0	reward = -0.789002	array([[1.0519208, 0.5607999]], dtype=float32)
time = 371	action = 0	current_phase = 1	next_phase = 0	reward = -1.027331	array([[1.0493958, 0.5694804]], dtype=float32)
time = 376	action = 0	current_phase = 1	next_phase = 0	reward = -0.825770	array([[1.0136341, 0.5827043]], dtype=float32)
time = 381	action = 0	current_phase = 1	next_phase = 0	reward = -1.327381	array([[1.0223937 , 0.57630885]], dtype=float32)
time = 386	action = 1	current_phase = 1	next_phase = 0	reward = -1.890273	array([[0.9974451, 0.5834677]], dtype=float32)
time = 394	action = 0	current_phase = 0	next_phase = 1	reward = -0.576038	array([[-0.9748116 , -0.16649836]], dtype=float32)
time = 399	action = 1	current_phase = 0	next_phase = 1	reward = -1.757112	array([[-0.9372603 , -0.17635253]], dtype=float32)
time = 407	action = 0	current_phase = 1	next_phase = 0	reward = -0.224859	array([[1.039324  , 0.56901777]], dtype=float32)
time = 412	action = 0	current_phase = 1	next_phase = 0	reward = -0.363485	array([[1.0000482 , 0.59855354]], dtype=float32)
time = 417	action = 0	current_phase = 1	next_phase = 0	reward = -0.831549	array([[1.0238537 , 0.59118825]], dtype=float32)
time = 422	action = 0	current_phase = 1	next_phase = 0	reward = -1.075437	array([[1.0378903 , 0.57538885]], dtype=float32)
time = 427	action = 1	current_phase = 1	next_phase = 0	reward = -2.100966	array([[1.0061704 , 0.59032524]], dtype=float32)
time = 435	action = 0	current_phase = 0	next_phase = 1	reward = -0.288711	array([[-0.989254  , -0.15607738]], dtype=float32)
time = 440	action = 1	current_phase = 0	next_phase = 1	reward = -1.331768	array([[-0.99247587, -0.17393355]], dtype=float32)
time = 448	action = 0	current_phase = 1	next_phase = 0	reward = -0.417553	array([[1.045374 , 0.5521038]], dtype=float32)
time = 453	action = 0	current_phase = 1	next_phase = 0	reward = -0.452603	array([[1.0301545 , 0.56909823]], dtype=float32)
time = 458	action = 0	current_phase = 1	next_phase = 0	reward = -0.597094	array([[1.0599624, 0.55591  ]], dtype=float32)
time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -0.577293	array([[1.0676689 , 0.54863065]], dtype=float32)
time = 468	action = 1	current_phase = 1	next_phase = 0	reward = -1.887543	array([[1.0368354 , 0.56545955]], dtype=float32)
time = 476	action = 0	current_phase = 0	next_phase = 1	reward = -0.732592	array([[-1.0056233 , -0.18909472]], dtype=float32)
time = 481	action = 1	current_phase = 0	next_phase = 1	reward = -1.847841	array([[-0.9695118 , -0.17753626]], dtype=float32)
time = 489	action = 0	current_phase = 1	next_phase = 0	reward = -0.400895	array([[1.0697149, 0.562748 ]], dtype=float32)
time = 494	action = 0	current_phase = 1	next_phase = 0	reward = -0.243858	array([[1.0371083 , 0.59315836]], dtype=float32)
time = 499	action = 0	current_phase = 1	next_phase = 0	reward = -0.475717	array([[1.050038 , 0.5955685]], dtype=float32)
time = 504	action = 0	current_phase = 1	next_phase = 0	reward = -0.984537	array([[1.0400896 , 0.59366745]], dtype=float32)
time = 509	action = 1	current_phase = 1	next_phase = 0	reward = -2.460871	array([[1.005443  , 0.61000663]], dtype=float32)
time = 517	action = 0	current_phase = 0	next_phase = 1	reward = -0.251245	array([[-0.9727203 , -0.10668743]], dtype=float32)
time = 522	action = 1	current_phase = 0	next_phase = 1	reward = -2.098313	array([[-0.9585789, -0.1183358]], dtype=float32)
time = 530	action = 0	current_phase = 1	next_phase = 0	reward = -1.575586	array([[1.0037661 , 0.55841863]], dtype=float32)
time = 535	action = 0	current_phase = 1	next_phase = 0	reward = -1.277429	array([[0.9491214, 0.5956546]], dtype=float32)
time = 540	action = 0	current_phase = 1	next_phase = 0	reward = -1.197406	array([[0.9490231, 0.6072118]], dtype=float32)
time = 545	action = 0	current_phase = 1	next_phase = 0	reward = -1.397865	array([[1.0104376 , 0.58814216]], dtype=float32)
time = 550	action = 1	current_phase = 1	next_phase = 0	reward = -1.583028	array([[0.97112846, 0.606862  ]], dtype=float32)
time = 558	action = 0	current_phase = 0	next_phase = 1	reward = 0.431608	array([[-0.98186964, -0.1152465 ]], dtype=float32)
time = 563	action = 1	current_phase = 0	next_phase = 1	reward = -1.209380	array([[-0.94642735, -0.1507208 ]], dtype=float32)
time = 571	action = 0	current_phase = 1	next_phase = 0	reward = -0.586343	array([[1.0645038, 0.5421642]], dtype=float32)
time = 576	action = 0	current_phase = 1	next_phase = 0	reward = -0.599887	array([[1.0131842, 0.5722208]], dtype=float32)
time = 581	action = 0	current_phase = 1	next_phase = 0	reward = -0.634449	array([[1.019365  , 0.57916254]], dtype=float32)
time = 586	action = 0	current_phase = 1	next_phase = 0	reward = -0.388601	array([[1.0319432, 0.5795092]], dtype=float32)
time = 591	action = 1	current_phase = 1	next_phase = 0	reward = -1.149695	array([[1.0342541, 0.5804479]], dtype=float32)
time = 599	action = 0	current_phase = 0	next_phase = 1	reward = -0.195765	array([[-0.96946657, -0.14310236]], dtype=float32)
time = 604	action = 1	current_phase = 0	next_phase = 1	reward = -1.193298	array([[-0.9541074 , -0.15359072]], dtype=float32)
time = 612	action = 0	current_phase = 1	next_phase = 0	reward = -0.639180	array([[1.0317338, 0.5788067]], dtype=float32)
time = 617	action = 0	current_phase = 1	next_phase = 0	reward = -1.047909	array([[1.0035722, 0.5886292]], dtype=float32)
time = 622	action = 0	current_phase = 1	next_phase = 0	reward = -1.134265	array([[1.0166618, 0.5899118]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -1.073513	array([[1.0074987, 0.5888192]], dtype=float32)
time = 632	action = 1	current_phase = 1	next_phase = 0	reward = -1.890676	array([[1.0170408 , 0.58962107]], dtype=float32)
time = 640	action = 0	current_phase = 0	next_phase = 1	reward = -0.271323	array([[-0.9613206 , -0.14280921]], dtype=float32)
time = 645	action = 1	current_phase = 0	next_phase = 1	reward = -1.657603	array([[-0.9735098 , -0.16191514]], dtype=float32)
time = 653	action = 0	current_phase = 1	next_phase = 0	reward = -0.342166	array([[1.0510107, 0.5617767]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -0.656341	array([[1.0244594 , 0.58878183]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.783314	array([[1.0225714, 0.5853956]], dtype=float32)
Terminal occured. Episode end.
Train on 1113 samples, validate on 478 samples
Epoch 1/500
 - 1s - loss: 1.0002 - val_loss: 0.3419
Epoch 2/500
 - 1s - loss: 0.2421 - val_loss: 0.1819
Epoch 3/500
 - 1s - loss: 0.1848 - val_loss: 0.1606
Epoch 4/500
 - 1s - loss: 0.1645 - val_loss: 0.1402
Epoch 5/500
 - 1s - loss: 0.1444 - val_loss: 0.1235
Epoch 6/500
 - 1s - loss: 0.1319 - val_loss: 0.1118
Epoch 7/500
 - 1s - loss: 0.1240 - val_loss: 0.1011
Epoch 8/500
 - 1s - loss: 0.1128 - val_loss: 0.0964
Epoch 9/500
 - 1s - loss: 0.1053 - val_loss: 0.0881
Epoch 10/500
 - 1s - loss: 0.1031 - val_loss: 0.0861
Epoch 11/500
 - 1s - loss: 0.0954 - val_loss: 0.0812
Epoch 12/500
 - 1s - loss: 0.0933 - val_loss: 0.0815
Epoch 13/500
 - 1s - loss: 0.0886 - val_loss: 0.0825
Epoch 14/500
 - 1s - loss: 0.0862 - val_loss: 0.0784
Epoch 15/500
 - 1s - loss: 0.0823 - val_loss: 0.0753
Epoch 16/500
 - 1s - loss: 0.0787 - val_loss: 0.0732
Epoch 17/500
 - 1s - loss: 0.0792 - val_loss: 0.0727
Epoch 18/500
 - 1s - loss: 0.0729 - val_loss: 0.0700
Epoch 19/500
 - 1s - loss: 0.0743 - val_loss: 0.0695
Epoch 20/500
 - 1s - loss: 0.0679 - val_loss: 0.0658
Epoch 21/500
 - 1s - loss: 0.0671 - val_loss: 0.0676
Epoch 22/500
 - 1s - loss: 0.0667 - val_loss: 0.0692
Epoch 23/500
 - 1s - loss: 0.0636 - val_loss: 0.0639
Epoch 24/500
 - 1s - loss: 0.0628 - val_loss: 0.0634
Epoch 25/500
 - 1s - loss: 0.0595 - val_loss: 0.0636
Epoch 26/500
 - 1s - loss: 0.0574 - val_loss: 0.0603
Epoch 27/500
 - 1s - loss: 0.0565 - val_loss: 0.0584
Epoch 28/500
 - 1s - loss: 0.0547 - val_loss: 0.0575
Epoch 29/500
 - 1s - loss: 0.0552 - val_loss: 0.0589
Epoch 30/500
 - 1s - loss: 0.0525 - val_loss: 0.0592
Epoch 31/500
 - 1s - loss: 0.0519 - val_loss: 0.0590
Epoch 32/500
 - 1s - loss: 0.0464 - val_loss: 0.0589
Epoch 33/500
 - 1s - loss: 0.0466 - val_loss: 0.0566
Epoch 34/500
 - 1s - loss: 0.0469 - val_loss: 0.0565
Epoch 35/500
 - 1s - loss: 0.0469 - val_loss: 0.0647
Epoch 36/500
 - 1s - loss: 0.0443 - val_loss: 0.0569
Epoch 37/500
 - 1s - loss: 0.0440 - val_loss: 0.0595
Epoch 38/500
 - 1s - loss: 0.0421 - val_loss: 0.0614
Epoch 39/500
 - 1s - loss: 0.0424 - val_loss: 0.0578
Epoch 40/500
 - 1s - loss: 0.0425 - val_loss: 0.0616
Epoch 41/500
 - 1s - loss: 0.0405 - val_loss: 0.0623
Epoch 42/500
 - 1s - loss: 0.0400 - val_loss: 0.0555
Epoch 43/500
 - 1s - loss: 0.0388 - val_loss: 0.0628
Epoch 44/500
 - 1s - loss: 0.0367 - val_loss: 0.0576
Epoch 45/500
 - 1s - loss: 0.0374 - val_loss: 0.0628
Epoch 46/500
 - 1s - loss: 0.0356 - val_loss: 0.0596
Epoch 47/500
 - 1s - loss: 0.0371 - val_loss: 0.0615
Epoch 48/500
 - 1s - loss: 0.0358 - val_loss: 0.0584
Epoch 49/500
 - 1s - loss: 0.0349 - val_loss: 0.0621
Epoch 50/500
 - 1s - loss: 0.0344 - val_loss: 0.0590
Epoch 51/500
 - 1s - loss: 0.0355 - val_loss: 0.0630
Epoch 52/500
 - 1s - loss: 0.0354 - val_loss: 0.0652
Loading configuration... done.
***Starting server on port 50041 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
length of memory (state 0, action 0): 507, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
END
Could not connect to TraCI server at localhost:50041 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[ 0.0876864, -2.0390632]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-0.5560082, -1.9736884]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-0.5349643, -1.9450647]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -0.619296	array([[-0.6633517, -1.585862 ]], dtype=float32)
time = 40	action = 0	current_phase = 0	next_phase = 1	reward = -0.532205	array([[-0.6492688, -1.9869653]], dtype=float32)
time = 45	action = 0	current_phase = 0	next_phase = 1	reward = -0.695894	array([[-0.18281437, -2.0002599 ]], dtype=float32)
time = 50	action = 0	current_phase = 0	next_phase = 1	reward = 0.213885	array([[-0.5921278, -2.0168037]], dtype=float32)
time = 55	action = 0	current_phase = 0	next_phase = 1	reward = -0.195062	array([[-0.5612623, -2.0057747]], dtype=float32)
time = 60	action = 0	current_phase = 0	next_phase = 1	reward = -0.550690	array([[-0.74395245, -1.6430775 ]], dtype=float32)
time = 65	action = 0	current_phase = 0	next_phase = 1	reward = -0.251841	array([[-0.8314883, -1.9753585]], dtype=float32)
time = 70	action = 0	current_phase = 0	next_phase = 1	reward = -0.453386	array([[-0.92839  , -1.9431943]], dtype=float32)
time = 75	action = 0	current_phase = 0	next_phase = 1	reward = 0.001497	array([[-0.9202498, -1.8916006]], dtype=float32)
time = 80	action = 0	current_phase = 0	next_phase = 1	reward = -0.252506	array([[-0.4291334, -1.9225354]], dtype=float32)
time = 85	action = 0	current_phase = 0	next_phase = 1	reward = 0.021115	array([[-0.24001667, -2.053647  ]], dtype=float32)
time = 90	action = 0	current_phase = 0	next_phase = 1	reward = -0.588938	array([[-0.48248327, -1.9488658 ]], dtype=float32)
time = 95	action = 0	current_phase = 0	next_phase = 1	reward = 0.115862	array([[-0.0748774, -1.885418 ]], dtype=float32)
time = 100	action = 0	current_phase = 0	next_phase = 1	reward = -0.258930	array([[-0.3264233, -1.9023395]], dtype=float32)
time = 105	action = 0	current_phase = 0	next_phase = 1	reward = -0.851848	array([[-0.38179645, -1.9837462 ]], dtype=float32)
time = 110	action = 0	current_phase = 0	next_phase = 1	reward = -0.135290	array([[-0.63244134, -2.050941  ]], dtype=float32)
time = 115	action = 0	current_phase = 0	next_phase = 1	reward = -0.525540	array([[-1.51277  , -1.8673725]], dtype=float32)
time = 120	action = 0	current_phase = 0	next_phase = 1	reward = 0.016672	array([[-0.85038877, -1.9830416 ]], dtype=float32)
time = 125	action = 0	current_phase = 0	next_phase = 1	reward = 0.550235	array([[-1.0285889, -1.8644776]], dtype=float32)
time = 130	action = 0	current_phase = 0	next_phase = 1	reward = 0.142914	array([[-0.77199554, -2.0155036 ]], dtype=float32)
time = 135	action = 0	current_phase = 0	next_phase = 1	reward = 0.014882	array([[-0.3052743, -2.0193408]], dtype=float32)
time = 140	action = 0	current_phase = 0	next_phase = 1	reward = -0.029920	array([[-0.21889184, -2.020593  ]], dtype=float32)
time = 145	action = 0	current_phase = 0	next_phase = 1	reward = -0.024686	array([[-0.5067292, -1.9116492]], dtype=float32)
time = 150	action = 0	current_phase = 0	next_phase = 1	reward = -0.536498	array([[-0.00217909, -2.0363803 ]], dtype=float32)
time = 155	action = 0	current_phase = 0	next_phase = 1	reward = -0.202926	array([[ 0.1021668, -2.1316786]], dtype=float32)
time = 160	action = 0	current_phase = 0	next_phase = 1	reward = -0.022032	array([[-0.444789, -1.991385]], dtype=float32)
time = 165	action = 0	current_phase = 0	next_phase = 1	reward = -0.913135	array([[-0.7773172, -1.540497 ]], dtype=float32)
time = 170	action = 0	current_phase = 0	next_phase = 1	reward = 0.284520	array([[-1.1608354, -1.7843887]], dtype=float32)
time = 175	action = 0	current_phase = 0	next_phase = 1	reward = -0.286888	array([[-0.58847266, -1.9902965 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.065664	array([[-0.10810478, -1.8966225 ]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = 0.220199	array([[ 0.04729372, -2.1089973 ]], dtype=float32)
time = 190	action = 0	current_phase = 0	next_phase = 1	reward = -0.317581	array([[-0.4845102, -1.7421933]], dtype=float32)
time = 195	action = 0	current_phase = 0	next_phase = 1	reward = -1.173923	array([[-0.16063042, -1.9668969 ]], dtype=float32)
time = 200	action = 0	current_phase = 0	next_phase = 1	reward = 0.537820	array([[-0.65065324, -1.7978415 ]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -0.260560	array([[-0.24667357, -1.9852716 ]], dtype=float32)
time = 210	action = 0	current_phase = 0	next_phase = 1	reward = 0.675134	array([[-1.1919482, -1.5896949]], dtype=float32)
time = 215	action = 0	current_phase = 0	next_phase = 1	reward = -0.215565	array([[-0.9843844, -1.7570765]], dtype=float32)
time = 220	action = 0	current_phase = 0	next_phase = 1	reward = -0.711658	array([[-0.4810669, -2.1374242]], dtype=float32)
time = 225	action = 0	current_phase = 0	next_phase = 1	reward = -0.673898	array([[-1.1007859, -1.9163262]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = -0.309157	array([[-0.58146596, -1.9651116 ]], dtype=float32)
time = 235	action = 0	current_phase = 0	next_phase = 1	reward = -0.607599	array([[-0.2147149, -1.9943925]], dtype=float32)
time = 240	action = 0	current_phase = 0	next_phase = 1	reward = -0.390665	array([[-0.9117898, -2.007895 ]], dtype=float32)
time = 245	action = 0	current_phase = 0	next_phase = 1	reward = -1.109020	array([[-0.78510594, -1.8164015 ]], dtype=float32)
time = 250	action = 0	current_phase = 0	next_phase = 1	reward = 0.154604	array([[-0.9561258, -1.6796484]], dtype=float32)
time = 255	action = 0	current_phase = 0	next_phase = 1	reward = -0.545170	array([[-0.2563935, -1.9272901]], dtype=float32)
time = 260	action = 0	current_phase = 0	next_phase = 1	reward = -0.599230	array([[-0.34265828, -1.8134332 ]], dtype=float32)
time = 265	action = 0	current_phase = 0	next_phase = 1	reward = -0.137632	array([[-0.4086246, -2.015292 ]], dtype=float32)
time = 270	action = 0	current_phase = 0	next_phase = 1	reward = -0.559849	array([[-0.5929075, -1.9947051]], dtype=float32)
time = 275	action = 0	current_phase = 0	next_phase = 1	reward = -0.167557	array([[-0.12495658, -2.0409837 ]], dtype=float32)
time = 280	action = 0	current_phase = 0	next_phase = 1	reward = 0.131341	array([[-0.07875906, -2.0744827 ]], dtype=float32)
time = 285	action = 0	current_phase = 0	next_phase = 1	reward = -1.034807	array([[-0.3105717, -1.8791583]], dtype=float32)
time = 290	action = 0	current_phase = 0	next_phase = 1	reward = -0.489095	array([[-0.44141856, -2.0804374 ]], dtype=float32)
time = 295	action = 0	current_phase = 0	next_phase = 1	reward = -0.635095	array([[-0.45616174, -2.0262246 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 1s - loss: 0.2011 - val_loss: 0.1523
Epoch 2/50
 - 1s - loss: 0.1595 - val_loss: 0.1468
Epoch 3/50
 - 1s - loss: 0.1483 - val_loss: 0.1309
Epoch 4/50
 - 1s - loss: 0.1320 - val_loss: 0.1237
Epoch 5/50
 - 1s - loss: 0.1256 - val_loss: 0.1330
Epoch 6/50
 - 1s - loss: 0.1184 - val_loss: 0.1260
Epoch 7/50
 - 1s - loss: 0.1194 - val_loss: 0.1222
Epoch 8/50
 - 1s - loss: 0.1054 - val_loss: 0.1294
Epoch 9/50
 - 1s - loss: 0.1033 - val_loss: 0.1196
Epoch 10/50
 - 1s - loss: 0.0962 - val_loss: 0.1207
Epoch 11/50
 - 1s - loss: 0.0946 - val_loss: 0.1114
Epoch 12/50
 - 1s - loss: 0.0935 - val_loss: 0.1170
Epoch 13/50
 - 1s - loss: 0.0878 - val_loss: 0.1275
Epoch 14/50
 - 1s - loss: 0.0920 - val_loss: 0.1207
Epoch 15/50
 - 1s - loss: 0.0889 - val_loss: 0.1214
Epoch 16/50
 - 1s - loss: 0.0814 - val_loss: 0.1125
Epoch 17/50
 - 1s - loss: 0.0785 - val_loss: 0.1206
Epoch 18/50
 - 1s - loss: 0.0746 - val_loss: 0.1221
Epoch 19/50
 - 1s - loss: 0.0807 - val_loss: 0.1223
Epoch 20/50
 - 1s - loss: 0.0745 - val_loss: 0.1232
Epoch 21/50
 - 1s - loss: 0.0787 - val_loss: 0.1211
length of memory (state 0, action 0): 563, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 300	action = 0	current_phase = 0	next_phase = 1	reward = -0.177005	array([[-1.0571841, -2.5421307]], dtype=float32)
time = 305	action = 0	current_phase = 0	next_phase = 1	reward = -0.539174	array([[-0.49014944, -2.2587664 ]], dtype=float32)
time = 310	action = 0	current_phase = 0	next_phase = 1	reward = -0.834349	array([[-0.44785112, -2.2793481 ]], dtype=float32)
time = 315	action = 1	current_phase = 0	next_phase = 1	reward = -3.278392	array([[-2.1403384, -1.8494606]], dtype=float32)
time = 323	action = 0	current_phase = 1	next_phase = 0	reward = -1.487474	array([[-1.8826447, -2.1415722]], dtype=float32)
time = 328	action = 0	current_phase = 1	next_phase = 0	reward = -1.239304	array([[-1.5791632, -1.986788 ]], dtype=float32)
time = 333	action = 0	current_phase = 1	next_phase = 0	reward = -1.431449	array([[-1.7362081, -1.7891072]], dtype=float32)
time = 338	action = 0	current_phase = 1	next_phase = 0	reward = -1.619405	array([[-1.5739833, -1.6779865]], dtype=float32)
time = 343	action = 0	current_phase = 1	next_phase = 0	reward = -1.557822	array([[-1.4393342, -2.0410736]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.999993	array([[-1.24952  , -1.6663033]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.555711	array([[-1.1870251, -1.5571731]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.800015	array([[-1.8414209, -1.5584562]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = 0.400777	array([[-0.50032896, -2.0971835 ]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.009938	array([[-0.53007656, -2.2166739 ]], dtype=float32)
time = 376	action = 0	current_phase = 0	next_phase = 1	reward = -0.657257	array([[-0.6377069, -2.3433986]], dtype=float32)
time = 381	action = 0	current_phase = 0	next_phase = 1	reward = -1.201870	array([[-0.755891, -2.41723 ]], dtype=float32)
time = 386	action = 0	current_phase = 0	next_phase = 1	reward = -1.532349	array([[-0.9008474, -2.1436598]], dtype=float32)
time = 391	action = 0	current_phase = 0	next_phase = 1	reward = -2.226161	array([[-1.1645063, -2.5989518]], dtype=float32)
time = 396	action = 0	current_phase = 0	next_phase = 1	reward = -2.744667	array([[-1.2268642, -2.9820411]], dtype=float32)
time = 401	action = 0	current_phase = 0	next_phase = 1	reward = -3.226931	array([[-1.2510482, -3.0132253]], dtype=float32)
time = 406	action = 0	current_phase = 0	next_phase = 1	reward = -3.754154	array([[-1.2059531, -2.9677715]], dtype=float32)
time = 411	action = 0	current_phase = 0	next_phase = 1	reward = -4.061473	array([[-1.1749731, -3.0069945]], dtype=float32)
time = 416	action = 0	current_phase = 0	next_phase = 1	reward = -4.621318	array([[-1.0951545, -3.0935655]], dtype=float32)
time = 421	action = 0	current_phase = 0	next_phase = 1	reward = -4.856744	array([[-2.2071123, -3.0900674]], dtype=float32)
time = 426	action = 0	current_phase = 0	next_phase = 1	reward = -5.768548	array([[-2.118067, -3.970667]], dtype=float32)
time = 431	action = 0	current_phase = 0	next_phase = 1	reward = -6.304176	array([[-1.936564, -4.198118]], dtype=float32)
time = 436	action = 0	current_phase = 0	next_phase = 1	reward = -6.521229	array([[-2.0592186, -4.123343 ]], dtype=float32)
time = 441	action = 0	current_phase = 0	next_phase = 1	reward = -7.402691	array([[-1.9506936, -4.3431716]], dtype=float32)
time = 446	action = 0	current_phase = 0	next_phase = 1	reward = -7.499160	array([[-1.7185109, -4.547325 ]], dtype=float32)
time = 451	action = 0	current_phase = 0	next_phase = 1	reward = -8.056225	array([[-2.0016336, -4.3272886]], dtype=float32)
time = 456	action = 0	current_phase = 0	next_phase = 1	reward = -8.183875	array([[-1.466267 , -4.4302144]], dtype=float32)
time = 461	action = 0	current_phase = 0	next_phase = 1	reward = -9.080037	array([[-2.2205122, -4.1578193]], dtype=float32)
time = 466	action = 0	current_phase = 0	next_phase = 1	reward = -10.535609	array([[-1.6727586, -4.656032 ]], dtype=float32)
time = 471	action = 0	current_phase = 0	next_phase = 1	reward = -10.723484	array([[-1.54982  , -4.6334405]], dtype=float32)
time = 476	action = 0	current_phase = 0	next_phase = 1	reward = -12.023381	array([[-1.6994566, -4.6537457]], dtype=float32)
time = 481	action = 0	current_phase = 0	next_phase = 1	reward = -12.702901	array([[-2.1693742, -4.3281174]], dtype=float32)
time = 486	action = 0	current_phase = 0	next_phase = 1	reward = -13.145861	array([[-1.8485788, -4.580531 ]], dtype=float32)
time = 491	action = 0	current_phase = 0	next_phase = 1	reward = -13.793675	array([[-1.715553 , -4.6909404]], dtype=float32)
time = 496	action = 0	current_phase = 0	next_phase = 1	reward = -14.235249	array([[-1.8955973, -4.575504 ]], dtype=float32)
time = 501	action = 0	current_phase = 0	next_phase = 1	reward = -15.517702	array([[-1.5391638, -4.7325544]], dtype=float32)
time = 506	action = 0	current_phase = 0	next_phase = 1	reward = -16.103592	array([[-1.832531 , -4.6335063]], dtype=float32)
time = 511	action = 0	current_phase = 0	next_phase = 1	reward = -17.037818	array([[-1.8543954, -4.6330986]], dtype=float32)
time = 516	action = 0	current_phase = 0	next_phase = 1	reward = -18.267994	array([[-1.6993786, -4.720169 ]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -18.576819	array([[-1.8240056, -4.6686234]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -19.285509	array([[-1.732625 , -4.7246075]], dtype=float32)
time = 531	action = 0	current_phase = 0	next_phase = 1	reward = -20.458049	array([[-1.8823531, -4.6227984]], dtype=float32)
time = 536	action = 0	current_phase = 0	next_phase = 1	reward = -21.564184	array([[-1.8886812, -4.6212883]], dtype=float32)
time = 541	action = 0	current_phase = 0	next_phase = 1	reward = -23.084344	array([[-1.8920497, -4.6186266]], dtype=float32)
time = 546	action = 0	current_phase = 0	next_phase = 1	reward = -24.093219	array([[-1.8655729, -4.6457353]], dtype=float32)
time = 551	action = 0	current_phase = 0	next_phase = 1	reward = -24.615810	array([[-1.8171879, -4.685249 ]], dtype=float32)
time = 556	action = 0	current_phase = 0	next_phase = 1	reward = -25.309083	array([[-1.8750641, -4.6324573]], dtype=float32)
time = 561	action = 0	current_phase = 0	next_phase = 1	reward = -26.085125	array([[-1.8968446, -4.615946 ]], dtype=float32)
time = 566	action = 0	current_phase = 0	next_phase = 1	reward = -27.607364	array([[-1.8254513, -4.6862183]], dtype=float32)
time = 571	action = 0	current_phase = 0	next_phase = 1	reward = -28.444224	array([[-1.9177138, -4.599303 ]], dtype=float32)
time = 576	action = 0	current_phase = 0	next_phase = 1	reward = -29.329381	array([[-1.8825243, -4.632331 ]], dtype=float32)
time = 581	action = 0	current_phase = 0	next_phase = 1	reward = -30.808405	array([[-1.8568193, -4.6516714]], dtype=float32)
time = 586	action = 0	current_phase = 0	next_phase = 1	reward = -31.248750	array([[-1.8930359, -4.617085 ]], dtype=float32)
time = 591	action = 0	current_phase = 0	next_phase = 1	reward = -32.404715	array([[-1.8492934, -4.65975  ]], dtype=float32)
time = 596	action = 0	current_phase = 0	next_phase = 1	reward = -32.709869	array([[-1.86336 , -4.641041]], dtype=float32)
Train on 834 samples, validate on 358 samples
Epoch 1/50
 - 1s - loss: 3.4861 - val_loss: 1.3533
Epoch 2/50
 - 1s - loss: 3.2520 - val_loss: 1.2786
Epoch 3/50
 - 1s - loss: 3.0840 - val_loss: 1.2255
Epoch 4/50
 - 1s - loss: 2.9382 - val_loss: 1.1717
Epoch 5/50
 - 1s - loss: 2.7513 - val_loss: 1.1084
Epoch 6/50
 - 1s - loss: 2.6560 - val_loss: 1.0697
Epoch 7/50
 - 1s - loss: 2.5303 - val_loss: 1.0362
Epoch 8/50
 - 1s - loss: 2.4661 - val_loss: 1.0167
Epoch 9/50
 - 1s - loss: 2.3820 - val_loss: 0.9813
Epoch 10/50
 - 1s - loss: 2.2909 - val_loss: 0.9596
Epoch 11/50
 - 1s - loss: 2.2322 - val_loss: 0.9375
Epoch 12/50
 - 1s - loss: 2.1543 - val_loss: 0.9050
Epoch 13/50
 - 1s - loss: 2.0711 - val_loss: 0.8856
Epoch 14/50
 - 1s - loss: 1.9969 - val_loss: 0.8605
Epoch 15/50
 - 1s - loss: 1.9265 - val_loss: 0.8341
Epoch 16/50
 - 1s - loss: 1.8729 - val_loss: 0.8078
Epoch 17/50
 - 1s - loss: 1.8070 - val_loss: 0.7920
Epoch 18/50
 - 1s - loss: 1.7552 - val_loss: 0.7715
Epoch 19/50
 - 1s - loss: 1.7055 - val_loss: 0.7511
Epoch 20/50
 - 1s - loss: 1.6507 - val_loss: 0.7331
Epoch 21/50
 - 1s - loss: 1.5936 - val_loss: 0.7166
Epoch 22/50
 - 1s - loss: 1.5464 - val_loss: 0.6949
Epoch 23/50
 - 1s - loss: 1.4957 - val_loss: 0.6761
Epoch 24/50
 - 1s - loss: 1.4549 - val_loss: 0.6574
Epoch 25/50
 - 1s - loss: 1.4041 - val_loss: 0.6422
Epoch 26/50
 - 1s - loss: 1.3577 - val_loss: 0.6191
Epoch 27/50
 - 1s - loss: 1.3209 - val_loss: 0.6059
Epoch 28/50
 - 1s - loss: 1.2783 - val_loss: 0.5987
Epoch 29/50
 - 1s - loss: 1.2327 - val_loss: 0.5804
Epoch 30/50
 - 1s - loss: 1.1953 - val_loss: 0.5678
Epoch 31/50
 - 1s - loss: 1.1562 - val_loss: 0.5664
Epoch 32/50
 - 1s - loss: 1.1147 - val_loss: 0.5606
Epoch 33/50
 - 1s - loss: 1.0898 - val_loss: 0.5482
Epoch 34/50
 - 1s - loss: 1.0531 - val_loss: 0.5258
Epoch 35/50
 - 1s - loss: 1.0241 - val_loss: 0.5207
Epoch 36/50
 - 1s - loss: 0.9825 - val_loss: 0.4942
Epoch 37/50
 - 1s - loss: 0.9591 - val_loss: 0.4773
Epoch 38/50
 - 1s - loss: 0.9171 - val_loss: 0.4782
Epoch 39/50
 - 1s - loss: 0.8974 - val_loss: 0.4577
Epoch 40/50
 - 1s - loss: 0.8725 - val_loss: 0.4367
Epoch 41/50
 - 1s - loss: 0.8475 - val_loss: 0.4283
Epoch 42/50
 - 1s - loss: 0.8169 - val_loss: 0.4175
Epoch 43/50
 - 1s - loss: 0.7890 - val_loss: 0.4098
Epoch 44/50
 - 1s - loss: 0.7634 - val_loss: 0.4077
Epoch 45/50
 - 1s - loss: 0.7384 - val_loss: 0.4016
Epoch 46/50
 - 1s - loss: 0.7084 - val_loss: 0.3837
Epoch 47/50
 - 1s - loss: 0.6985 - val_loss: 0.3759
Epoch 48/50
 - 1s - loss: 0.6693 - val_loss: 0.3772
Epoch 49/50
 - 1s - loss: 0.6479 - val_loss: 0.3670
Epoch 50/50
 - 1s - loss: 0.6276 - val_loss: 0.3627
length of memory (state 0, action 0): 613, after forget
length of memory (state 0, action 1): 304, after forget
length of memory (state 1, action 0): 497, after forget
length of memory (state 1, action 1): 292, after forget
time = 601	action = 1	current_phase = 0	next_phase = 1	reward = -45.657991	array([[-17.31106 ,  -4.802313]], dtype=float32)
time = 609	action = 0	current_phase = 1	next_phase = 0	reward = -15.132264	array([[-2.0932865, -2.872345 ]], dtype=float32)
time = 614	action = 0	current_phase = 1	next_phase = 0	reward = -8.446698	array([[-1.9610586, -3.1198487]], dtype=float32)
time = 619	action = 0	current_phase = 1	next_phase = 0	reward = -2.260417	array([[-1.3155534, -3.530518 ]], dtype=float32)
time = 624	action = 0	current_phase = 1	next_phase = 0	reward = 0.313631	array([[-0.56810886, -3.4719698 ]], dtype=float32)
time = 629	action = 0	current_phase = 1	next_phase = 0	reward = 0.315833	array([[-0.67022145, -3.357796  ]], dtype=float32)
time = 634	action = 0	current_phase = 1	next_phase = 0	reward = -1.028824	array([[-0.94681406, -3.3296525 ]], dtype=float32)
time = 639	action = 0	current_phase = 1	next_phase = 0	reward = -1.940573	array([[-1.5286644, -3.1483607]], dtype=float32)
time = 644	action = 0	current_phase = 1	next_phase = 0	reward = -3.688698	array([[-1.9220462, -2.934134 ]], dtype=float32)
time = 649	action = 0	current_phase = 1	next_phase = 0	reward = -3.585958	array([[-2.5096881, -2.5261035]], dtype=float32)
time = 654	action = 1	current_phase = 1	next_phase = 0	reward = -3.442125	array([[-2.4854789, -1.9122076]], dtype=float32)
time = 662	action = 0	current_phase = 0	next_phase = 1	reward = 0.913123	array([[-0.43618616, -2.3406353 ]], dtype=float32)
time = 667	action = 0	current_phase = 0	next_phase = 1	reward = 0.626482	array([[-0.7738408, -2.1267042]], dtype=float32)
time = 672	action = 0	current_phase = 0	next_phase = 1	reward = -0.642242	array([[-0.50088805, -1.9170842 ]], dtype=float32)
time = 677	action = 0	current_phase = 0	next_phase = 1	reward = -1.326605	array([[-1.4027085, -1.9308361]], dtype=float32)
time = 682	action = 1	current_phase = 0	next_phase = 1	reward = -3.078408	array([[-2.3781002, -2.0185778]], dtype=float32)
time = 690	action = 0	current_phase = 1	next_phase = 0	reward = -0.301514	array([[-0.59118193, -2.3252647 ]], dtype=float32)
time = 695	action = 0	current_phase = 1	next_phase = 0	reward = 0.214014	array([[-0.40848765, -2.6730387 ]], dtype=float32)
time = 700	action = 0	current_phase = 1	next_phase = 0	reward = -0.163172	array([[-0.70556843, -2.1863053 ]], dtype=float32)
time = 705	action = 0	current_phase = 1	next_phase = 0	reward = -0.794432	array([[-0.7142519, -2.048186 ]], dtype=float32)
time = 710	action = 0	current_phase = 1	next_phase = 0	reward = -1.520444	array([[-0.9910158, -2.040399 ]], dtype=float32)
time = 715	action = 0	current_phase = 1	next_phase = 0	reward = -0.805470	array([[-0.86147904, -2.0207584 ]], dtype=float32)
time = 720	action = 0	current_phase = 1	next_phase = 0	reward = -0.745493	array([[-1.1762952, -1.9011021]], dtype=float32)
time = 725	action = 0	current_phase = 1	next_phase = 0	reward = -0.934004	array([[-1.1736264, -1.5961082]], dtype=float32)
time = 730	action = 1	current_phase = 1	next_phase = 0	reward = -1.185617	array([[-1.8022327, -1.7835159]], dtype=float32)
time = 738	action = 0	current_phase = 0	next_phase = 1	reward = 0.390385	array([[-1.201628 , -1.8279687]], dtype=float32)
time = 743	action = 0	current_phase = 0	next_phase = 1	reward = -0.918560	array([[-1.611613 , -1.8046216]], dtype=float32)
time = 748	action = 0	current_phase = 0	next_phase = 1	reward = -1.481973	array([[-1.9185598, -1.9203944]], dtype=float32)
time = 753	action = 0	current_phase = 0	next_phase = 1	reward = -2.512441	array([[-1.0358548, -2.1803522]], dtype=float32)
time = 758	action = 0	current_phase = 0	next_phase = 1	reward = -3.174043	array([[-1.5383995, -2.4892342]], dtype=float32)
time = 763	action = 0	current_phase = 0	next_phase = 1	reward = -3.665559	array([[-2.280541 , -3.7866921]], dtype=float32)
time = 768	action = 0	current_phase = 0	next_phase = 1	reward = -4.127831	array([[-1.642825 , -3.9144948]], dtype=float32)
time = 773	action = 0	current_phase = 0	next_phase = 1	reward = -4.771237	array([[-2.0681658, -4.134814 ]], dtype=float32)
time = 778	action = 1	current_phase = 0	next_phase = 1	reward = -6.256924	array([[-5.5804935, -3.512653 ]], dtype=float32)
time = 786	action = 0	current_phase = 1	next_phase = 0	reward = -0.473871	array([[-0.70452935, -2.1457453 ]], dtype=float32)
time = 791	action = 0	current_phase = 1	next_phase = 0	reward = 0.290697	array([[-0.66794586, -3.2615833 ]], dtype=float32)
time = 796	action = 0	current_phase = 1	next_phase = 0	reward = -0.348437	array([[-0.54947865, -3.137847  ]], dtype=float32)
time = 801	action = 0	current_phase = 1	next_phase = 0	reward = -0.841737	array([[-0.6867675, -2.7594447]], dtype=float32)
time = 806	action = 0	current_phase = 1	next_phase = 0	reward = -0.664464	array([[-1.0408385, -2.2170267]], dtype=float32)
time = 811	action = 0	current_phase = 1	next_phase = 0	reward = -1.689037	array([[-0.96162796, -1.731128  ]], dtype=float32)
time = 816	action = 1	current_phase = 1	next_phase = 0	reward = -2.054934	array([[-1.7554761, -1.7133672]], dtype=float32)
time = 824	action = 0	current_phase = 0	next_phase = 1	reward = 0.766219	array([[-0.73642635, -2.1741433 ]], dtype=float32)
time = 829	action = 0	current_phase = 0	next_phase = 1	reward = 0.008129	array([[-0.700181 , -2.0539107]], dtype=float32)
time = 834	action = 0	current_phase = 0	next_phase = 1	reward = -0.226502	array([[-0.66432905, -1.8856745 ]], dtype=float32)
time = 839	action = 0	current_phase = 0	next_phase = 1	reward = -1.132540	array([[-0.60682344, -1.9728237 ]], dtype=float32)
time = 844	action = 0	current_phase = 0	next_phase = 1	reward = -1.348982	array([[-0.89139825, -2.2507842 ]], dtype=float32)
time = 849	action = 0	current_phase = 0	next_phase = 1	reward = -2.003007	array([[-0.7770064, -2.5594728]], dtype=float32)
time = 854	action = 0	current_phase = 0	next_phase = 1	reward = -1.808307	array([[-1.0024495, -2.2543986]], dtype=float32)
time = 859	action = 0	current_phase = 0	next_phase = 1	reward = -2.208501	array([[-1.5704817, -1.9217638]], dtype=float32)
time = 864	action = 0	current_phase = 0	next_phase = 1	reward = -3.218949	array([[-1.3427743, -2.1299694]], dtype=float32)
time = 869	action = 0	current_phase = 0	next_phase = 1	reward = -3.919207	array([[-2.4832387, -3.079899 ]], dtype=float32)
time = 874	action = 1	current_phase = 0	next_phase = 1	reward = -5.098678	array([[-4.3463387, -2.9069688]], dtype=float32)
time = 882	action = 0	current_phase = 1	next_phase = 0	reward = -0.274809	array([[-0.977187 , -2.0148664]], dtype=float32)
time = 887	action = 0	current_phase = 1	next_phase = 0	reward = -0.568678	array([[-0.82315767, -1.8224924 ]], dtype=float32)
time = 892	action = 0	current_phase = 1	next_phase = 0	reward = -1.743758	array([[-0.94898695, -1.7531888 ]], dtype=float32)
time = 897	action = 0	current_phase = 1	next_phase = 0	reward = -1.380364	array([[-1.6089494, -1.7797511]], dtype=float32)
Train on 836 samples, validate on 359 samples
Epoch 1/50
 - 1s - loss: 1.4244 - val_loss: 1.0667
Epoch 2/50
 - 1s - loss: 1.3973 - val_loss: 1.0592
Epoch 3/50
 - 1s - loss: 1.3773 - val_loss: 1.0484
Epoch 4/50
 - 1s - loss: 1.3613 - val_loss: 1.0130
Epoch 5/50
 - 1s - loss: 1.3612 - val_loss: 1.0285
Epoch 6/50
 - 1s - loss: 1.3437 - val_loss: 1.0102
Epoch 7/50
 - 1s - loss: 1.3448 - val_loss: 0.9845
Epoch 8/50
 - 1s - loss: 1.3286 - val_loss: 0.9714
Epoch 9/50
 - 1s - loss: 1.3160 - val_loss: 0.9609
Epoch 10/50
 - 1s - loss: 1.3110 - val_loss: 0.9458
Epoch 11/50
 - 1s - loss: 1.3028 - val_loss: 0.9325
Epoch 12/50
 - 1s - loss: 1.2935 - val_loss: 0.9322
Epoch 13/50
 - 1s - loss: 1.2886 - val_loss: 0.9213
Epoch 14/50
 - 1s - loss: 1.2813 - val_loss: 0.8961
Epoch 15/50
 - 1s - loss: 1.2743 - val_loss: 0.9018
Epoch 16/50
 - 1s - loss: 1.2729 - val_loss: 0.8942
Epoch 17/50
 - 1s - loss: 1.2577 - val_loss: 0.8828
Epoch 18/50
 - 1s - loss: 1.2570 - val_loss: 0.8809
Epoch 19/50
 - 1s - loss: 1.2587 - val_loss: 0.8705
Epoch 20/50
 - 1s - loss: 1.2515 - val_loss: 0.8566
Epoch 21/50
 - 1s - loss: 1.2443 - val_loss: 0.8488
Epoch 22/50
 - 1s - loss: 1.2431 - val_loss: 0.8438
Epoch 23/50
 - 1s - loss: 1.2344 - val_loss: 0.8224
Epoch 24/50
 - 1s - loss: 1.2318 - val_loss: 0.8270
Epoch 25/50
 - 1s - loss: 1.2245 - val_loss: 0.8014
Epoch 26/50
 - 1s - loss: 1.2211 - val_loss: 0.7991
Epoch 27/50
 - 1s - loss: 1.2127 - val_loss: 0.8095
Epoch 28/50
 - 1s - loss: 1.2119 - val_loss: 0.7907
Epoch 29/50
 - 1s - loss: 1.2089 - val_loss: 0.7751
Epoch 30/50
 - 1s - loss: 1.2041 - val_loss: 0.7705
Epoch 31/50
 - 1s - loss: 1.1999 - val_loss: 0.7612
Epoch 32/50
 - 1s - loss: 1.1922 - val_loss: 0.7617
Epoch 33/50
 - 1s - loss: 1.1940 - val_loss: 0.7708
Epoch 34/50
 - 1s - loss: 1.1932 - val_loss: 0.7667
Epoch 35/50
 - 1s - loss: 1.1814 - val_loss: 0.7388
Epoch 36/50
 - 1s - loss: 1.1794 - val_loss: 0.7261
Epoch 37/50
 - 1s - loss: 1.1846 - val_loss: 0.7177
Epoch 38/50
 - 1s - loss: 1.1811 - val_loss: 0.7107
Epoch 39/50
 - 1s - loss: 1.1830 - val_loss: 0.7050
Epoch 40/50
 - 1s - loss: 1.1678 - val_loss: 0.7077
Epoch 41/50
 - 1s - loss: 1.1724 - val_loss: 0.7000
Epoch 42/50
 - 1s - loss: 1.1637 - val_loss: 0.6942
Epoch 43/50
 - 1s - loss: 1.1538 - val_loss: 0.6871
Epoch 44/50
 - 1s - loss: 1.1666 - val_loss: 0.6939
Epoch 45/50
 - 1s - loss: 1.1585 - val_loss: 0.7033
Epoch 46/50
 - 1s - loss: 1.1491 - val_loss: 0.6742
Epoch 47/50
 - 1s - loss: 1.1451 - val_loss: 0.6749
Epoch 48/50
 - 1s - loss: 1.1250 - val_loss: 0.6610
Epoch 49/50
 - 1s - loss: 1.1255 - val_loss: 0.6718
Epoch 50/50
 - 1s - loss: 1.1396 - val_loss: 0.6700
length of memory (state 0, action 0): 635, after forget
length of memory (state 0, action 1): 308, after forget
length of memory (state 1, action 0): 524, after forget
length of memory (state 1, action 1): 295, after forget
time = 902	action = 1	current_phase = 1	next_phase = 0	reward = -1.610000	array([[-1.8837898, -1.0769937]], dtype=float32)
time = 910	action = 0	current_phase = 0	next_phase = 1	reward = 0.726801	array([[-0.7969196, -2.1062934]], dtype=float32)
time = 915	action = 0	current_phase = 0	next_phase = 1	reward = 0.406007	array([[-0.73014015, -2.2177017 ]], dtype=float32)
time = 920	action = 0	current_phase = 0	next_phase = 1	reward = -0.116528	array([[-0.7403357, -1.9631631]], dtype=float32)
time = 925	action = 0	current_phase = 0	next_phase = 1	reward = -1.304709	array([[-1.3062406, -2.0813704]], dtype=float32)
time = 930	action = 1	current_phase = 0	next_phase = 1	reward = -1.669907	array([[-2.3018315, -1.8053622]], dtype=float32)
time = 938	action = 0	current_phase = 1	next_phase = 0	reward = 0.670740	array([[-0.5589232, -1.8881973]], dtype=float32)
time = 943	action = 0	current_phase = 1	next_phase = 0	reward = -0.420799	array([[-0.85772324, -1.6620384 ]], dtype=float32)
time = 948	action = 0	current_phase = 1	next_phase = 0	reward = -0.032951	array([[-0.92489874, -1.6700984 ]], dtype=float32)
time = 953	action = 0	current_phase = 1	next_phase = 0	reward = -0.493502	array([[-1.1407737, -1.5784909]], dtype=float32)
time = 958	action = 0	current_phase = 1	next_phase = 0	reward = -0.750162	array([[-1.1295302, -1.4465735]], dtype=float32)
time = 963	action = 0	current_phase = 1	next_phase = 0	reward = -0.247657	array([[-1.2871526, -1.4023452]], dtype=float32)
time = 968	action = 1	current_phase = 1	next_phase = 0	reward = -0.777609	array([[-1.6784115, -1.1483998]], dtype=float32)
time = 976	action = 0	current_phase = 0	next_phase = 1	reward = 0.710341	array([[-0.3009596, -2.440615 ]], dtype=float32)
time = 981	action = 0	current_phase = 0	next_phase = 1	reward = -0.074526	array([[-0.63143057, -1.9842722 ]], dtype=float32)
time = 986	action = 0	current_phase = 0	next_phase = 1	reward = 0.627716	array([[-0.45871913, -2.3380566 ]], dtype=float32)
time = 991	action = 0	current_phase = 0	next_phase = 1	reward = -0.050634	array([[-0.51010704, -1.9677277 ]], dtype=float32)
time = 996	action = 0	current_phase = 0	next_phase = 1	reward = -0.335775	array([[-0.07962269, -2.3286448 ]], dtype=float32)
time = 1001	action = 0	current_phase = 0	next_phase = 1	reward = -0.864191	array([[-0.849623 , -2.2926347]], dtype=float32)
time = 1006	action = 0	current_phase = 0	next_phase = 1	reward = -0.101927	array([[-0.4351681, -2.7033901]], dtype=float32)
time = 1011	action = 0	current_phase = 0	next_phase = 1	reward = -0.346032	array([[-0.79725266, -2.1023965 ]], dtype=float32)
time = 1016	action = 0	current_phase = 0	next_phase = 1	reward = -0.450585	array([[-0.7496439, -2.3625145]], dtype=float32)
time = 1021	action = 0	current_phase = 0	next_phase = 1	reward = -1.097220	array([[-1.1109473, -2.0362475]], dtype=float32)
time = 1026	action = 0	current_phase = 0	next_phase = 1	reward = -1.404747	array([[-1.1986505, -2.3062675]], dtype=float32)
time = 1031	action = 0	current_phase = 0	next_phase = 1	reward = -1.524280	array([[-1.3990455, -2.1103942]], dtype=float32)
time = 1036	action = 1	current_phase = 0	next_phase = 1	reward = -2.308518	array([[-2.3139925, -1.956608 ]], dtype=float32)
time = 1044	action = 0	current_phase = 1	next_phase = 0	reward = -0.645218	array([[-0.8831115, -2.0707984]], dtype=float32)
time = 1049	action = 0	current_phase = 1	next_phase = 0	reward = -0.472841	array([[-1.0449611, -1.9072053]], dtype=float32)
time = 1054	action = 0	current_phase = 1	next_phase = 0	reward = -0.677374	array([[-1.2376654, -2.1064036]], dtype=float32)
time = 1059	action = 0	current_phase = 1	next_phase = 0	reward = -0.729618	array([[-0.90850234, -2.2684832 ]], dtype=float32)
time = 1064	action = 0	current_phase = 1	next_phase = 0	reward = -1.569943	array([[-1.4374647, -2.574933 ]], dtype=float32)
time = 1069	action = 1	current_phase = 1	next_phase = 0	reward = -2.947116	array([[-3.0721543, -2.600154 ]], dtype=float32)
time = 1077	action = 0	current_phase = 0	next_phase = 1	reward = -0.926011	array([[-1.7545722, -2.0447645]], dtype=float32)
time = 1082	action = 0	current_phase = 0	next_phase = 1	reward = -1.741319	array([[-2.2071602, -2.2653692]], dtype=float32)
time = 1087	action = 1	current_phase = 0	next_phase = 1	reward = -2.554949	array([[-2.8728123, -2.162415 ]], dtype=float32)
time = 1095	action = 0	current_phase = 1	next_phase = 0	reward = 0.121346	array([[-0.87165684, -2.012012  ]], dtype=float32)
time = 1100	action = 0	current_phase = 1	next_phase = 0	reward = -0.448093	array([[-1.1439327, -1.9333005]], dtype=float32)
time = 1105	action = 0	current_phase = 1	next_phase = 0	reward = -1.051705	array([[-1.0912334, -2.17807  ]], dtype=float32)
time = 1110	action = 0	current_phase = 1	next_phase = 0	reward = -0.903812	array([[-1.0044724, -1.7199783]], dtype=float32)
time = 1115	action = 0	current_phase = 1	next_phase = 0	reward = -0.804511	array([[-1.0334911, -1.3804371]], dtype=float32)
time = 1120	action = 1	current_phase = 1	next_phase = 0	reward = -2.108515	array([[-2.104105 , -1.8407667]], dtype=float32)
time = 1128	action = 0	current_phase = 0	next_phase = 1	reward = 0.425359	array([[-0.5143287, -1.9734851]], dtype=float32)
time = 1133	action = 0	current_phase = 0	next_phase = 1	reward = -0.258832	array([[-1.5288731, -1.977003 ]], dtype=float32)
time = 1138	action = 0	current_phase = 0	next_phase = 1	reward = -0.780568	array([[-1.1350305, -2.12555  ]], dtype=float32)
time = 1143	action = 0	current_phase = 0	next_phase = 1	reward = -1.472130	array([[-1.4568324, -2.1331117]], dtype=float32)
time = 1148	action = 1	current_phase = 0	next_phase = 1	reward = -2.388683	array([[-2.8301382, -2.2815335]], dtype=float32)
time = 1156	action = 0	current_phase = 1	next_phase = 0	reward = 0.169641	array([[-0.5805218, -1.9181662]], dtype=float32)
time = 1161	action = 0	current_phase = 1	next_phase = 0	reward = -0.040065	array([[-0.89823663, -2.471451  ]], dtype=float32)
time = 1166	action = 0	current_phase = 1	next_phase = 0	reward = -0.052206	array([[-0.84762657, -2.6406212 ]], dtype=float32)
time = 1171	action = 0	current_phase = 1	next_phase = 0	reward = -1.158145	array([[-0.98459804, -1.5745306 ]], dtype=float32)
time = 1176	action = 0	current_phase = 1	next_phase = 0	reward = -1.301900	array([[-1.3831766, -1.7043886]], dtype=float32)
time = 1181	action = 0	current_phase = 1	next_phase = 0	reward = -1.071449	array([[-1.5445958, -1.8225574]], dtype=float32)
time = 1186	action = 0	current_phase = 1	next_phase = 0	reward = -1.375693	array([[-1.1198134, -2.3517592]], dtype=float32)
time = 1191	action = 0	current_phase = 1	next_phase = 0	reward = -1.402403	array([[-1.4290271, -2.0120575]], dtype=float32)
time = 1196	action = 1	current_phase = 1	next_phase = 0	reward = -2.014844	array([[-2.6352794, -1.8426322]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.1251 - val_loss: 0.3035
Epoch 2/50
 - 1s - loss: 1.1154 - val_loss: 0.2989
Epoch 3/50
 - 1s - loss: 1.0831 - val_loss: 0.2876
Epoch 4/50
 - 1s - loss: 1.0882 - val_loss: 0.2910
Epoch 5/50
 - 1s - loss: 1.0773 - val_loss: 0.2876
Epoch 6/50
 - 1s - loss: 1.0742 - val_loss: 0.2856
Epoch 7/50
 - 1s - loss: 1.0583 - val_loss: 0.2702
Epoch 8/50
 - 1s - loss: 1.0465 - val_loss: 0.2723
Epoch 9/50
 - 1s - loss: 1.0637 - val_loss: 0.2897
Epoch 10/50
 - 1s - loss: 1.0516 - val_loss: 0.2652
Epoch 11/50
 - 1s - loss: 1.0398 - val_loss: 0.2562
Epoch 12/50
 - 1s - loss: 1.0540 - val_loss: 0.2674
Epoch 13/50
 - 1s - loss: 1.0133 - val_loss: 0.2499
Epoch 14/50
 - 1s - loss: 1.0087 - val_loss: 0.2502
Epoch 15/50
 - 1s - loss: 1.0104 - val_loss: 0.2470
Epoch 16/50
 - 1s - loss: 1.0493 - val_loss: 0.2633
Epoch 17/50
 - 1s - loss: 0.9959 - val_loss: 0.2306
Epoch 18/50
 - 1s - loss: 1.0133 - val_loss: 0.2353
Epoch 19/50
 - 1s - loss: 0.9846 - val_loss: 0.2394
Epoch 20/50
 - 1s - loss: 0.9966 - val_loss: 0.2375
Epoch 21/50
 - 1s - loss: 0.9873 - val_loss: 0.2278
Epoch 22/50
 - 1s - loss: 0.9770 - val_loss: 0.2424
Epoch 23/50
 - 1s - loss: 1.0049 - val_loss: 0.2480
Epoch 24/50
 - 1s - loss: 0.9739 - val_loss: 0.2305
Epoch 25/50
 - 1s - loss: 0.9702 - val_loss: 0.2545
Epoch 26/50
 - 1s - loss: 0.9632 - val_loss: 0.2416
Epoch 27/50
 - 1s - loss: 0.9865 - val_loss: 0.2282
Epoch 28/50
 - 1s - loss: 0.9567 - val_loss: 0.2364
Epoch 29/50
 - 1s - loss: 0.9691 - val_loss: 0.2406
Epoch 30/50
 - 1s - loss: 0.9463 - val_loss: 0.2386
Epoch 31/50
 - 1s - loss: 0.9578 - val_loss: 0.2220
Epoch 32/50
 - 1s - loss: 0.9411 - val_loss: 0.2128
Epoch 33/50
 - 1s - loss: 0.9519 - val_loss: 0.2054
Epoch 34/50
 - 1s - loss: 0.9484 - val_loss: 0.2123
Epoch 35/50
 - 1s - loss: 0.9227 - val_loss: 0.2017
Epoch 36/50
 - 1s - loss: 0.9378 - val_loss: 0.2099
Epoch 37/50
 - 1s - loss: 0.9273 - val_loss: 0.2015
Epoch 38/50
 - 1s - loss: 0.9350 - val_loss: 0.1907
Epoch 39/50
 - 1s - loss: 0.9452 - val_loss: 0.2359
Epoch 40/50
 - 1s - loss: 0.9192 - val_loss: 0.1970
Epoch 41/50
 - 1s - loss: 0.9381 - val_loss: 0.1784
Epoch 42/50
 - 1s - loss: 0.9245 - val_loss: 0.2168
Epoch 43/50
 - 1s - loss: 0.9086 - val_loss: 0.1889
Epoch 44/50
 - 1s - loss: 0.9139 - val_loss: 0.1794
Epoch 45/50
 - 1s - loss: 0.9268 - val_loss: 0.1853
Epoch 46/50
 - 1s - loss: 0.9053 - val_loss: 0.1826
Epoch 47/50
 - 1s - loss: 0.9050 - val_loss: 0.1897
Epoch 48/50
 - 1s - loss: 0.9024 - val_loss: 0.1964
Epoch 49/50
 - 1s - loss: 0.9051 - val_loss: 0.1883
Epoch 50/50
 - 1s - loss: 0.8921 - val_loss: 0.1891
length of memory (state 0, action 0): 657, after forget
length of memory (state 0, action 1): 312, after forget
length of memory (state 1, action 0): 548, after forget
length of memory (state 1, action 1): 300, after forget
time = 1204	action = 0	current_phase = 0	next_phase = 1	reward = 0.482547	array([[-0.306217, -2.188193]], dtype=float32)
time = 1209	action = 0	current_phase = 0	next_phase = 1	reward = -0.349840	array([[-0.50683916, -2.0131392 ]], dtype=float32)
time = 1214	action = 0	current_phase = 0	next_phase = 1	reward = -0.286854	array([[-0.8920439, -1.8230953]], dtype=float32)
time = 1219	action = 0	current_phase = 0	next_phase = 1	reward = -1.415894	array([[-1.4271388, -1.8750844]], dtype=float32)
time = 1224	action = 1	current_phase = 0	next_phase = 1	reward = -2.384676	array([[-2.056538 , -1.8084319]], dtype=float32)
time = 1232	action = 0	current_phase = 1	next_phase = 0	reward = -0.118337	array([[-0.7769048, -1.9296575]], dtype=float32)
time = 1237	action = 0	current_phase = 1	next_phase = 0	reward = -0.731677	array([[-1.0463052, -1.9884336]], dtype=float32)
time = 1242	action = 0	current_phase = 1	next_phase = 0	reward = -0.697457	array([[-1.0390396, -1.7975205]], dtype=float32)
time = 1247	action = 0	current_phase = 1	next_phase = 0	reward = -0.375017	array([[-1.0177957, -1.3779345]], dtype=float32)
time = 1252	action = 0	current_phase = 1	next_phase = 0	reward = -1.356235	array([[-1.3116329, -1.6180162]], dtype=float32)
time = 1257	action = 1	current_phase = 1	next_phase = 0	reward = -2.351505	array([[-2.1168082, -2.050455 ]], dtype=float32)
time = 1265	action = 0	current_phase = 0	next_phase = 1	reward = -0.107012	array([[-0.32194698, -2.3134754 ]], dtype=float32)
time = 1270	action = 0	current_phase = 0	next_phase = 1	reward = -0.453924	array([[-0.3993492, -2.2925658]], dtype=float32)
time = 1275	action = 0	current_phase = 0	next_phase = 1	reward = -0.732221	array([[-0.898312 , -2.4795096]], dtype=float32)
time = 1280	action = 0	current_phase = 0	next_phase = 1	reward = -1.211743	array([[-1.3431221, -2.398347 ]], dtype=float32)
time = 1285	action = 0	current_phase = 0	next_phase = 1	reward = -1.276990	array([[-1.4830561, -1.8883374]], dtype=float32)
time = 1290	action = 0	current_phase = 0	next_phase = 1	reward = -1.678562	array([[-1.4988194, -1.8749342]], dtype=float32)
time = 1295	action = 0	current_phase = 0	next_phase = 1	reward = -1.905411	array([[-2.116662, -2.378586]], dtype=float32)
time = 1300	action = 0	current_phase = 0	next_phase = 1	reward = -2.817275	array([[-2.1816707, -3.3468533]], dtype=float32)
time = 1305	action = 1	current_phase = 0	next_phase = 1	reward = -3.460211	array([[-3.4729543, -2.8468719]], dtype=float32)
time = 1313	action = 0	current_phase = 1	next_phase = 0	reward = -0.286162	array([[-1.3605001, -1.9187729]], dtype=float32)
time = 1318	action = 0	current_phase = 1	next_phase = 0	reward = -0.845995	array([[-0.75451267, -2.4179792 ]], dtype=float32)
time = 1323	action = 0	current_phase = 1	next_phase = 0	reward = -0.608362	array([[-0.8653778, -2.5521479]], dtype=float32)
time = 1328	action = 0	current_phase = 1	next_phase = 0	reward = -1.329463	array([[-1.0501243, -1.2677621]], dtype=float32)
time = 1333	action = 0	current_phase = 1	next_phase = 0	reward = -1.335043	array([[-1.4573076, -1.6217694]], dtype=float32)
time = 1338	action = 1	current_phase = 1	next_phase = 0	reward = -2.039505	array([[-2.419577 , -1.6169089]], dtype=float32)
time = 1346	action = 0	current_phase = 0	next_phase = 1	reward = 0.371847	array([[-0.7516668, -2.459851 ]], dtype=float32)
time = 1351	action = 0	current_phase = 0	next_phase = 1	reward = -0.056980	array([[-1.0488667, -1.9295766]], dtype=float32)
time = 1356	action = 0	current_phase = 0	next_phase = 1	reward = -0.960081	array([[-1.4886311, -1.7060869]], dtype=float32)
time = 1361	action = 0	current_phase = 0	next_phase = 1	reward = -1.510940	array([[-1.4206876, -1.7759545]], dtype=float32)
time = 1366	action = 0	current_phase = 0	next_phase = 1	reward = -1.930625	array([[-1.5679991, -2.3081546]], dtype=float32)
time = 1371	action = 0	current_phase = 0	next_phase = 1	reward = -2.527483	array([[-2.836926 , -3.0368268]], dtype=float32)
time = 1376	action = 0	current_phase = 0	next_phase = 1	reward = -2.423668	array([[-2.0289125, -3.0139415]], dtype=float32)
time = 1381	action = 1	current_phase = 0	next_phase = 1	reward = -3.548089	array([[-4.317689 , -3.0926862]], dtype=float32)
time = 1389	action = 0	current_phase = 1	next_phase = 0	reward = 0.150043	array([[-0.7193185, -1.949896 ]], dtype=float32)
time = 1394	action = 0	current_phase = 1	next_phase = 0	reward = -0.445432	array([[-0.83128846, -2.3119667 ]], dtype=float32)
time = 1399	action = 0	current_phase = 1	next_phase = 0	reward = -0.236231	array([[-1.0970051, -1.1006966]], dtype=float32)
time = 1404	action = 0	current_phase = 1	next_phase = 0	reward = -0.284204	array([[-1.0146451, -1.4825213]], dtype=float32)
time = 1409	action = 0	current_phase = 1	next_phase = 0	reward = -0.715129	array([[-1.4017806, -1.533447 ]], dtype=float32)
time = 1414	action = 1	current_phase = 1	next_phase = 0	reward = -1.457754	array([[-1.802685, -1.716074]], dtype=float32)
time = 1422	action = 0	current_phase = 0	next_phase = 1	reward = 0.242603	array([[-0.554661 , -2.4781075]], dtype=float32)
time = 1427	action = 0	current_phase = 0	next_phase = 1	reward = -0.888802	array([[-0.5265874, -2.3670256]], dtype=float32)
time = 1432	action = 0	current_phase = 0	next_phase = 1	reward = -1.303519	array([[-1.2799203, -1.937804 ]], dtype=float32)
time = 1437	action = 0	current_phase = 0	next_phase = 1	reward = -0.789220	array([[-1.780374 , -2.0397925]], dtype=float32)
time = 1442	action = 0	current_phase = 0	next_phase = 1	reward = -1.180555	array([[-1.4920046, -1.9381845]], dtype=float32)
time = 1447	action = 1	current_phase = 0	next_phase = 1	reward = -2.276015	array([[-2.4379268, -2.0828779]], dtype=float32)
time = 1455	action = 0	current_phase = 1	next_phase = 0	reward = -0.421944	array([[-1.0894183, -1.9073197]], dtype=float32)
time = 1460	action = 0	current_phase = 1	next_phase = 0	reward = -0.912167	array([[-1.0086349, -2.0539484]], dtype=float32)
time = 1465	action = 0	current_phase = 1	next_phase = 0	reward = -0.824154	array([[-0.98414445, -2.3049157 ]], dtype=float32)
time = 1470	action = 0	current_phase = 1	next_phase = 0	reward = -0.626034	array([[-1.8518097, -1.934834 ]], dtype=float32)
time = 1475	action = 0	current_phase = 1	next_phase = 0	reward = -1.022287	array([[-1.0109501, -1.9052982]], dtype=float32)
time = 1480	action = 1	current_phase = 1	next_phase = 0	reward = -1.999448	array([[-2.4147785, -1.8396195]], dtype=float32)
time = 1488	action = 0	current_phase = 0	next_phase = 1	reward = -0.097457	array([[-1.0804867, -1.8780141]], dtype=float32)
time = 1493	action = 0	current_phase = 0	next_phase = 1	reward = -1.104834	array([[-1.5478014, -2.0224712]], dtype=float32)
time = 1498	action = 1	current_phase = 0	next_phase = 1	reward = -1.162989	array([[-2.0006485, -1.8386316]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.9389 - val_loss: 0.1424
Epoch 2/50
 - 1s - loss: 0.9329 - val_loss: 0.1428
Epoch 3/50
 - 1s - loss: 0.9116 - val_loss: 0.1513
Epoch 4/50
 - 1s - loss: 0.8826 - val_loss: 0.1434
Epoch 5/50
 - 1s - loss: 0.9027 - val_loss: 0.1345
Epoch 6/50
 - 1s - loss: 0.8739 - val_loss: 0.1370
Epoch 7/50
 - 1s - loss: 0.8658 - val_loss: 0.1253
Epoch 8/50
 - 1s - loss: 0.8690 - val_loss: 0.1262
Epoch 9/50
 - 1s - loss: 0.8837 - val_loss: 0.1376
Epoch 10/50
 - 1s - loss: 0.8540 - val_loss: 0.1224
Epoch 11/50
 - 1s - loss: 0.8677 - val_loss: 0.1197
Epoch 12/50
 - 1s - loss: 0.8468 - val_loss: 0.1177
Epoch 13/50
 - 1s - loss: 0.8559 - val_loss: 0.1219
Epoch 14/50
 - 1s - loss: 0.8348 - val_loss: 0.1190
Epoch 15/50
 - 1s - loss: 0.8433 - val_loss: 0.1165
Epoch 16/50
 - 1s - loss: 0.8390 - val_loss: 0.1161
Epoch 17/50
 - 1s - loss: 0.9279 - val_loss: 0.1335
Epoch 18/50
 - 1s - loss: 0.8382 - val_loss: 0.1331
Epoch 19/50
 - 1s - loss: 0.8543 - val_loss: 0.1264
Epoch 20/50
 - 1s - loss: 0.8296 - val_loss: 0.1126
Epoch 21/50
 - 1s - loss: 0.8390 - val_loss: 0.1187
Epoch 22/50
 - 1s - loss: 0.8133 - val_loss: 0.1171
Epoch 23/50
 - 1s - loss: 0.8078 - val_loss: 0.1024
Epoch 24/50
 - 1s - loss: 0.8569 - val_loss: 0.1136
Epoch 25/50
 - 1s - loss: 0.8039 - val_loss: 0.1128
Epoch 26/50
 - 1s - loss: 0.8260 - val_loss: 0.1063
Epoch 27/50
 - 1s - loss: 0.8039 - val_loss: 0.1153
Epoch 28/50
 - 1s - loss: 0.8595 - val_loss: 0.1066
Epoch 29/50
 - 1s - loss: 0.7948 - val_loss: 0.1093
Epoch 30/50
 - 1s - loss: 0.7868 - val_loss: 0.1103
Epoch 31/50
 - 1s - loss: 0.7944 - val_loss: 0.1043
Epoch 32/50
 - 1s - loss: 0.7965 - val_loss: 0.1032
Epoch 33/50
 - 1s - loss: 0.8083 - val_loss: 0.1031
length of memory (state 0, action 0): 683, after forget
length of memory (state 0, action 1): 317, after forget
length of memory (state 1, action 0): 568, after forget
length of memory (state 1, action 1): 304, after forget
time = 1506	action = 0	current_phase = 1	next_phase = 0	reward = 0.383379	array([[-0.69162154, -2.31006   ]], dtype=float32)
time = 1511	action = 0	current_phase = 1	next_phase = 0	reward = -0.509625	array([[-0.80199975, -2.1092324 ]], dtype=float32)
time = 1516	action = 0	current_phase = 1	next_phase = 0	reward = -0.239508	array([[-0.7554104, -2.6102521]], dtype=float32)
time = 1521	action = 0	current_phase = 1	next_phase = 0	reward = -0.290924	array([[-1.200825 , -1.9842036]], dtype=float32)
time = 1526	action = 0	current_phase = 1	next_phase = 0	reward = -0.900697	array([[-1.367418 , -2.3372757]], dtype=float32)
time = 1531	action = 0	current_phase = 1	next_phase = 0	reward = -0.655848	array([[-1.2678487, -2.647976 ]], dtype=float32)
time = 1536	action = 0	current_phase = 1	next_phase = 0	reward = -1.138847	array([[-1.9033558, -2.077075 ]], dtype=float32)
time = 1541	action = 0	current_phase = 1	next_phase = 0	reward = -0.996158	array([[-1.3650664, -1.6218785]], dtype=float32)
time = 1546	action = 1	current_phase = 1	next_phase = 0	reward = -1.846597	array([[-2.5066297, -1.8104062]], dtype=float32)
time = 1554	action = 0	current_phase = 0	next_phase = 1	reward = 0.343772	array([[-0.6509715, -1.8931069]], dtype=float32)
time = 1559	action = 0	current_phase = 0	next_phase = 1	reward = -0.452753	array([[-1.3887073, -1.9691565]], dtype=float32)
time = 1564	action = 1	current_phase = 0	next_phase = 1	reward = -0.985449	array([[-2.2254739, -1.7194259]], dtype=float32)
time = 1572	action = 0	current_phase = 1	next_phase = 0	reward = -0.116186	array([[-0.63934004, -1.7311094 ]], dtype=float32)
time = 1577	action = 0	current_phase = 1	next_phase = 0	reward = 0.055366	array([[-0.8582114, -2.0117428]], dtype=float32)
time = 1582	action = 0	current_phase = 1	next_phase = 0	reward = 0.088350	array([[-0.8028376, -1.4441878]], dtype=float32)
time = 1587	action = 0	current_phase = 1	next_phase = 0	reward = -0.536824	array([[-1.0223976, -1.3254188]], dtype=float32)
time = 1592	action = 0	current_phase = 1	next_phase = 0	reward = -0.636449	array([[-1.2552805, -1.8508495]], dtype=float32)
time = 1597	action = 0	current_phase = 1	next_phase = 0	reward = -0.831777	array([[-1.8369229, -1.8405098]], dtype=float32)
time = 1602	action = 0	current_phase = 1	next_phase = 0	reward = -1.179419	array([[-1.4564068, -1.7772061]], dtype=float32)
time = 1607	action = 1	current_phase = 1	next_phase = 0	reward = -1.929213	array([[-2.3535807, -1.7784572]], dtype=float32)
time = 1615	action = 0	current_phase = 0	next_phase = 1	reward = -0.172300	array([[-1.6439064, -1.9054914]], dtype=float32)
time = 1620	action = 1	current_phase = 0	next_phase = 1	reward = -1.123708	array([[-1.9250623, -1.9059331]], dtype=float32)
time = 1628	action = 0	current_phase = 1	next_phase = 0	reward = 0.271997	array([[-0.514158 , -1.8406751]], dtype=float32)
time = 1633	action = 0	current_phase = 1	next_phase = 0	reward = 0.076611	array([[-0.5903526, -2.8507414]], dtype=float32)
time = 1638	action = 0	current_phase = 1	next_phase = 0	reward = -0.557341	array([[-0.79299045, -2.7372024 ]], dtype=float32)
time = 1643	action = 0	current_phase = 1	next_phase = 0	reward = -0.423347	array([[-1.685904 , -1.8891329]], dtype=float32)
time = 1648	action = 1	current_phase = 1	next_phase = 0	reward = -1.930064	array([[-2.1000183, -1.4754938]], dtype=float32)
time = 1656	action = 0	current_phase = 0	next_phase = 1	reward = -0.244239	array([[-0.7722305, -2.5467842]], dtype=float32)
time = 1661	action = 0	current_phase = 0	next_phase = 1	reward = -0.096254	array([[-1.0143142, -2.5943673]], dtype=float32)
time = 1666	action = 1	current_phase = 0	next_phase = 1	reward = -1.584125	array([[-2.1880226, -1.8076177]], dtype=float32)
time = 1674	action = 0	current_phase = 1	next_phase = 0	reward = -0.571023	array([[-1.2069161, -1.9483802]], dtype=float32)
time = 1679	action = 0	current_phase = 1	next_phase = 0	reward = -0.406925	array([[-1.2748854, -1.9427216]], dtype=float32)
time = 1684	action = 0	current_phase = 1	next_phase = 0	reward = -0.787382	array([[-0.962739 , -1.7368294]], dtype=float32)
time = 1689	action = 0	current_phase = 1	next_phase = 0	reward = -0.762047	array([[-1.388202 , -1.7222126]], dtype=float32)
time = 1694	action = 1	current_phase = 1	next_phase = 0	reward = -1.643518	array([[-2.0376635, -1.6833428]], dtype=float32)
time = 1702	action = 0	current_phase = 0	next_phase = 1	reward = -0.136082	array([[-0.9308107, -1.9114087]], dtype=float32)
time = 1707	action = 0	current_phase = 0	next_phase = 1	reward = -0.541099	array([[-1.6842439, -1.8427091]], dtype=float32)
time = 1712	action = 1	current_phase = 0	next_phase = 1	reward = -1.620845	array([[-1.9448259, -1.7460511]], dtype=float32)
time = 1720	action = 0	current_phase = 1	next_phase = 0	reward = -0.342441	array([[-0.6682996, -2.0834472]], dtype=float32)
time = 1725	action = 0	current_phase = 1	next_phase = 0	reward = -0.315882	array([[-0.72525615, -2.7744832 ]], dtype=float32)
time = 1730	action = 0	current_phase = 1	next_phase = 0	reward = -0.209422	array([[-0.7451577, -2.435943 ]], dtype=float32)
time = 1735	action = 0	current_phase = 1	next_phase = 0	reward = -0.305882	array([[-1.1522406, -1.546002 ]], dtype=float32)
time = 1740	action = 0	current_phase = 1	next_phase = 0	reward = -0.040263	array([[-1.2536626, -1.9819055]], dtype=float32)
time = 1745	action = 0	current_phase = 1	next_phase = 0	reward = -1.086850	array([[-1.5460532, -2.006058 ]], dtype=float32)
time = 1750	action = 1	current_phase = 1	next_phase = 0	reward = -1.922497	array([[-2.2743661, -2.101036 ]], dtype=float32)
time = 1758	action = 0	current_phase = 0	next_phase = 1	reward = -0.548083	array([[-1.291114 , -2.4062026]], dtype=float32)
time = 1763	action = 0	current_phase = 0	next_phase = 1	reward = -1.046314	array([[-1.6829848, -2.344546 ]], dtype=float32)
time = 1768	action = 0	current_phase = 0	next_phase = 1	reward = -1.235525	array([[-1.8424538, -2.2355294]], dtype=float32)
time = 1773	action = 1	current_phase = 0	next_phase = 1	reward = -1.979382	array([[-2.5516522, -2.5142596]], dtype=float32)
time = 1781	action = 0	current_phase = 1	next_phase = 0	reward = 0.194901	array([[-0.84462684, -1.5871582 ]], dtype=float32)
time = 1786	action = 0	current_phase = 1	next_phase = 0	reward = -0.780620	array([[-1.0606973, -1.1460903]], dtype=float32)
time = 1791	action = 0	current_phase = 1	next_phase = 0	reward = -1.147736	array([[-1.1757574, -1.5912004]], dtype=float32)
time = 1796	action = 1	current_phase = 1	next_phase = 0	reward = -2.211442	array([[-2.1664588, -1.7896476]], dtype=float32)
time = 1804	action = 0	current_phase = 0	next_phase = 1	reward = 0.144331	array([[-1.2035469, -1.8220558]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.4551 - val_loss: 2.1136
Epoch 2/50
 - 1s - loss: 0.3932 - val_loss: 2.1565
Epoch 3/50
 - 1s - loss: 0.3728 - val_loss: 2.2438
Epoch 4/50
 - 1s - loss: 0.3818 - val_loss: 2.2561
Epoch 5/50
 - 1s - loss: 0.3591 - val_loss: 2.3732
Epoch 6/50
 - 1s - loss: 0.3432 - val_loss: 2.3797
Epoch 7/50
 - 1s - loss: 0.3456 - val_loss: 2.3857
Epoch 8/50
 - 1s - loss: 0.3366 - val_loss: 2.4161
Epoch 9/50
 - 1s - loss: 0.3196 - val_loss: 2.4259
Epoch 10/50
 - 1s - loss: 0.3219 - val_loss: 2.4331
Epoch 11/50
 - 1s - loss: 0.3097 - val_loss: 2.4406
length of memory (state 0, action 0): 694, after forget
length of memory (state 0, action 1): 322, after forget
length of memory (state 1, action 0): 600, after forget
length of memory (state 1, action 1): 310, after forget
time = 1809	action = 0	current_phase = 0	next_phase = 1	reward = -0.682598	array([[-1.4486626, -1.8470054]], dtype=float32)
time = 1814	action = 0	current_phase = 0	next_phase = 1	reward = -0.572007	array([[-1.4698013, -1.9870567]], dtype=float32)
time = 1819	action = 1	current_phase = 0	next_phase = 1	reward = -3.565504	array([[-2.1180701, -2.0693598]], dtype=float32)
time = 1827	action = 0	current_phase = 1	next_phase = 0	reward = 0.006044	array([[-1.162596 , -1.8259159]], dtype=float32)
time = 1832	action = 0	current_phase = 1	next_phase = 0	reward = -0.177366	array([[-0.79643106, -2.447187  ]], dtype=float32)
time = 1837	action = 0	current_phase = 1	next_phase = 0	reward = -0.939194	array([[-1.2333632, -2.3946095]], dtype=float32)
time = 1842	action = 0	current_phase = 1	next_phase = 0	reward = -1.205680	array([[-1.6015229, -2.8371084]], dtype=float32)
time = 1847	action = 0	current_phase = 1	next_phase = 0	reward = -1.332108	array([[-2.4447122, -2.7225273]], dtype=float32)
time = 1852	action = 0	current_phase = 1	next_phase = 0	reward = -1.219288	array([[-1.9607805, -2.6719444]], dtype=float32)
time = 1857	action = 1	current_phase = 1	next_phase = 0	reward = -1.812472	array([[-2.2906718, -1.8627386]], dtype=float32)
time = 1865	action = 0	current_phase = 0	next_phase = 1	reward = -0.404815	array([[-1.1108618, -2.2506564]], dtype=float32)
time = 1870	action = 0	current_phase = 0	next_phase = 1	reward = -0.405841	array([[-0.84443176, -3.2081199 ]], dtype=float32)
time = 1875	action = 0	current_phase = 0	next_phase = 1	reward = -1.170978	array([[-1.4685013, -2.2376688]], dtype=float32)
time = 1880	action = 0	current_phase = 0	next_phase = 1	reward = -1.538287	array([[-1.8562766, -2.6273823]], dtype=float32)
time = 1885	action = 0	current_phase = 0	next_phase = 1	reward = -1.671310	array([[-2.4674125, -3.2982683]], dtype=float32)
time = 1890	action = 1	current_phase = 0	next_phase = 1	reward = -2.189816	array([[-2.6116514, -2.561415 ]], dtype=float32)
time = 1898	action = 0	current_phase = 1	next_phase = 0	reward = 0.009821	array([[-1.4543717, -2.364498 ]], dtype=float32)
time = 1903	action = 0	current_phase = 1	next_phase = 0	reward = -0.231872	array([[-0.9357765, -2.9914634]], dtype=float32)
time = 1908	action = 0	current_phase = 1	next_phase = 0	reward = -0.066299	array([[-1.0259955, -2.907176 ]], dtype=float32)
time = 1913	action = 0	current_phase = 1	next_phase = 0	reward = -1.193328	array([[-1.9543808, -2.1028101]], dtype=float32)
time = 1918	action = 0	current_phase = 1	next_phase = 0	reward = -1.065024	array([[-1.4623153, -2.3576653]], dtype=float32)
time = 1923	action = 0	current_phase = 1	next_phase = 0	reward = -1.518413	array([[-2.2994623, -3.016698 ]], dtype=float32)
time = 1928	action = 1	current_phase = 1	next_phase = 0	reward = -2.954084	array([[-3.2997801, -2.5992908]], dtype=float32)
time = 1936	action = 0	current_phase = 0	next_phase = 1	reward = -0.858605	array([[-1.3118782, -2.5721228]], dtype=float32)
time = 1941	action = 0	current_phase = 0	next_phase = 1	reward = -0.700959	array([[-1.7562449, -3.5259614]], dtype=float32)
time = 1946	action = 0	current_phase = 0	next_phase = 1	reward = -1.203055	array([[-2.1469178, -2.9235537]], dtype=float32)
time = 1951	action = 0	current_phase = 0	next_phase = 1	reward = -1.731790	array([[-2.2225919, -2.4004974]], dtype=float32)
time = 1956	action = 1	current_phase = 0	next_phase = 1	reward = -1.928284	array([[-3.3678656, -2.5362988]], dtype=float32)
time = 1964	action = 0	current_phase = 1	next_phase = 0	reward = 0.045959	array([[-1.4513172, -1.9478577]], dtype=float32)
time = 1969	action = 0	current_phase = 1	next_phase = 0	reward = -1.005416	array([[-1.2243248, -2.6709683]], dtype=float32)
time = 1974	action = 0	current_phase = 1	next_phase = 0	reward = -0.766028	array([[-1.5930471, -2.7330823]], dtype=float32)
time = 1979	action = 0	current_phase = 1	next_phase = 0	reward = -1.273299	array([[-1.995729 , -2.6025941]], dtype=float32)
time = 1984	action = 0	current_phase = 1	next_phase = 0	reward = -2.469738	array([[-2.3255658, -3.1970894]], dtype=float32)
time = 1989	action = 1	current_phase = 1	next_phase = 0	reward = -3.330449	array([[-4.384077 , -3.0461502]], dtype=float32)
time = 1997	action = 0	current_phase = 0	next_phase = 1	reward = -0.338201	array([[-1.7175657, -2.575876 ]], dtype=float32)
time = 2002	action = 0	current_phase = 0	next_phase = 1	reward = -0.845760	array([[-1.8802905, -2.6362436]], dtype=float32)
time = 2007	action = 1	current_phase = 0	next_phase = 1	reward = -2.187829	array([[-2.8785968, -2.2906313]], dtype=float32)
time = 2015	action = 0	current_phase = 1	next_phase = 0	reward = 0.403520	array([[-1.1657804, -2.0705311]], dtype=float32)
time = 2020	action = 0	current_phase = 1	next_phase = 0	reward = -0.271199	array([[-1.155866, -2.515856]], dtype=float32)
time = 2025	action = 0	current_phase = 1	next_phase = 0	reward = -1.104359	array([[-1.0641036, -2.9395308]], dtype=float32)
time = 2030	action = 0	current_phase = 1	next_phase = 0	reward = -1.464888	array([[-1.7357867, -3.019808 ]], dtype=float32)
time = 2035	action = 1	current_phase = 1	next_phase = 0	reward = -2.365899	array([[-3.3045394, -2.56893  ]], dtype=float32)
time = 2043	action = 0	current_phase = 0	next_phase = 1	reward = 0.075916	array([[-1.0498683, -2.323628 ]], dtype=float32)
time = 2048	action = 0	current_phase = 0	next_phase = 1	reward = -0.197116	array([[-1.5052836, -2.1642783]], dtype=float32)
time = 2053	action = 0	current_phase = 0	next_phase = 1	reward = -0.489671	array([[-1.0225952, -2.919158 ]], dtype=float32)
time = 2058	action = 0	current_phase = 0	next_phase = 1	reward = -1.139726	array([[-2.155665 , -2.5818808]], dtype=float32)
time = 2063	action = 0	current_phase = 0	next_phase = 1	reward = -1.469567	array([[-2.2173245, -2.3081596]], dtype=float32)
time = 2068	action = 1	current_phase = 0	next_phase = 1	reward = -2.678268	array([[-4.5056534, -3.053771 ]], dtype=float32)
time = 2076	action = 0	current_phase = 1	next_phase = 0	reward = -0.452455	array([[-0.24616608, -1.6915077 ]], dtype=float32)
time = 2081	action = 0	current_phase = 1	next_phase = 0	reward = -0.192823	array([[-0.5777753, -2.593894 ]], dtype=float32)
time = 2086	action = 0	current_phase = 1	next_phase = 0	reward = -1.089658	array([[-1.1073824, -2.5972826]], dtype=float32)
time = 2091	action = 0	current_phase = 1	next_phase = 0	reward = -1.112243	array([[-1.0423245, -2.7336578]], dtype=float32)
time = 2096	action = 0	current_phase = 1	next_phase = 0	reward = -0.889595	array([[-1.5980862, -2.434612 ]], dtype=float32)
time = 2101	action = 0	current_phase = 1	next_phase = 0	reward = -1.386119	array([[-1.1433952, -1.9267594]], dtype=float32)
time = 2106	action = 1	current_phase = 1	next_phase = 0	reward = -3.337602	array([[-2.3448322, -1.6398308]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.0394 - val_loss: 0.0740
Epoch 2/50
 - 1s - loss: 1.0302 - val_loss: 0.0886
Epoch 3/50
 - 1s - loss: 0.9840 - val_loss: 0.0793
Epoch 4/50
 - 1s - loss: 0.9929 - val_loss: 0.0879
Epoch 5/50
 - 1s - loss: 0.9673 - val_loss: 0.0828
Epoch 6/50
 - 1s - loss: 0.9597 - val_loss: 0.0882
Epoch 7/50
 - 1s - loss: 0.9476 - val_loss: 0.0935
Epoch 8/50
 - 1s - loss: 0.9426 - val_loss: 0.0807
Epoch 9/50
 - 1s - loss: 0.9623 - val_loss: 0.0904
Epoch 10/50
 - 1s - loss: 0.9662 - val_loss: 0.0912
Epoch 11/50
 - 1s - loss: 0.9255 - val_loss: 0.0813
length of memory (state 0, action 0): 712, after forget
length of memory (state 0, action 1): 327, after forget
length of memory (state 1, action 0): 627, after forget
length of memory (state 1, action 1): 315, after forget
time = 2114	action = 0	current_phase = 0	next_phase = 1	reward = -0.923552	array([[-1.7896595, -2.3768675]], dtype=float32)
time = 2119	action = 1	current_phase = 0	next_phase = 1	reward = -1.984164	array([[-2.669211 , -2.6390982]], dtype=float32)
time = 2127	action = 0	current_phase = 1	next_phase = 0	reward = -1.244670	array([[-1.5988446, -2.2250547]], dtype=float32)
time = 2132	action = 0	current_phase = 1	next_phase = 0	reward = -1.003474	array([[-1.4128348, -2.6742907]], dtype=float32)
time = 2137	action = 0	current_phase = 1	next_phase = 0	reward = -1.188679	array([[-1.3393722, -1.858214 ]], dtype=float32)
time = 2142	action = 1	current_phase = 1	next_phase = 0	reward = -1.843735	array([[-1.7882885, -1.195719 ]], dtype=float32)
time = 2150	action = 0	current_phase = 0	next_phase = 1	reward = 0.230278	array([[-0.4678042, -2.9235506]], dtype=float32)
time = 2155	action = 0	current_phase = 0	next_phase = 1	reward = -0.099521	array([[-0.7255311, -3.0662465]], dtype=float32)
time = 2160	action = 0	current_phase = 0	next_phase = 1	reward = -0.066315	array([[-1.2889208, -2.6053305]], dtype=float32)
time = 2165	action = 0	current_phase = 0	next_phase = 1	reward = -0.494910	array([[-1.0944269, -2.5835307]], dtype=float32)
time = 2170	action = 0	current_phase = 0	next_phase = 1	reward = -1.214469	array([[-1.9830693, -2.4259562]], dtype=float32)
time = 2175	action = 0	current_phase = 0	next_phase = 1	reward = -1.405937	array([[-2.0367265, -2.5062528]], dtype=float32)
time = 2180	action = 0	current_phase = 0	next_phase = 1	reward = -1.484537	array([[-2.0917053, -2.7294574]], dtype=float32)
time = 2185	action = 0	current_phase = 0	next_phase = 1	reward = -1.444601	array([[-3.119989 , -3.2689342]], dtype=float32)
time = 2190	action = 0	current_phase = 0	next_phase = 1	reward = -2.272071	array([[-2.1755633, -3.39608  ]], dtype=float32)
time = 2195	action = 0	current_phase = 0	next_phase = 1	reward = -2.467918	array([[-2.8515072, -3.7598367]], dtype=float32)
time = 2200	action = 1	current_phase = 0	next_phase = 1	reward = -2.316105	array([[-4.0624757, -3.417519 ]], dtype=float32)
time = 2208	action = 0	current_phase = 1	next_phase = 0	reward = 0.028291	array([[-0.45801952, -1.4845822 ]], dtype=float32)
time = 2213	action = 0	current_phase = 1	next_phase = 0	reward = -0.896665	array([[-1.5164701, -2.1142964]], dtype=float32)
time = 2218	action = 0	current_phase = 1	next_phase = 0	reward = -1.463968	array([[-1.2940998, -3.1656473]], dtype=float32)
time = 2223	action = 1	current_phase = 1	next_phase = 0	reward = -1.952026	array([[-3.1667674, -2.4895725]], dtype=float32)
time = 2231	action = 0	current_phase = 0	next_phase = 1	reward = -0.430245	array([[-0.98496807, -2.6567116 ]], dtype=float32)
time = 2236	action = 0	current_phase = 0	next_phase = 1	reward = -0.688094	array([[-1.6340345, -2.4751577]], dtype=float32)
time = 2241	action = 0	current_phase = 0	next_phase = 1	reward = -0.626240	array([[-1.1842296, -2.8432136]], dtype=float32)
time = 2246	action = 0	current_phase = 0	next_phase = 1	reward = -0.649081	array([[-2.253706 , -2.7480621]], dtype=float32)
time = 2251	action = 0	current_phase = 0	next_phase = 1	reward = -1.563455	array([[-2.3201077, -2.4276657]], dtype=float32)
time = 2256	action = 1	current_phase = 0	next_phase = 1	reward = -1.702559	array([[-3.2881665, -2.9376569]], dtype=float32)
time = 2264	action = 0	current_phase = 1	next_phase = 0	reward = 0.546470	array([[-0.5606002, -1.463092 ]], dtype=float32)
time = 2269	action = 0	current_phase = 1	next_phase = 0	reward = -0.221667	array([[-1.2321908, -1.5056235]], dtype=float32)
time = 2274	action = 0	current_phase = 1	next_phase = 0	reward = -0.165140	array([[-1.6245595, -1.8655804]], dtype=float32)
time = 2279	action = 1	current_phase = 1	next_phase = 0	reward = -1.061947	array([[-2.1146302, -1.9467009]], dtype=float32)
time = 2287	action = 0	current_phase = 0	next_phase = 1	reward = -0.293053	array([[-0.49750292, -2.6122985 ]], dtype=float32)
time = 2292	action = 0	current_phase = 0	next_phase = 1	reward = -0.170767	array([[-1.2493081, -2.3596137]], dtype=float32)
time = 2297	action = 0	current_phase = 0	next_phase = 1	reward = -0.345347	array([[-1.6419942, -1.8298732]], dtype=float32)
time = 2302	action = 1	current_phase = 0	next_phase = 1	reward = -1.087359	array([[-2.2429888, -1.9064641]], dtype=float32)
time = 2310	action = 0	current_phase = 1	next_phase = 0	reward = 0.038852	array([[-1.3165978, -1.893097 ]], dtype=float32)
time = 2315	action = 0	current_phase = 1	next_phase = 0	reward = -0.818229	array([[-1.5305935, -1.7950451]], dtype=float32)
time = 2320	action = 0	current_phase = 1	next_phase = 0	reward = -0.714128	array([[-1.5063512, -1.9500751]], dtype=float32)
time = 2325	action = 0	current_phase = 1	next_phase = 0	reward = -1.176040	array([[-2.1264226, -2.5295317]], dtype=float32)
time = 2330	action = 1	current_phase = 1	next_phase = 0	reward = -1.886001	array([[-4.0094185, -2.4563744]], dtype=float32)
time = 2338	action = 0	current_phase = 0	next_phase = 1	reward = 0.281020	array([[-0.7525523, -2.6253972]], dtype=float32)
time = 2343	action = 0	current_phase = 0	next_phase = 1	reward = -0.003677	array([[-1.2535942, -2.5587976]], dtype=float32)
time = 2348	action = 0	current_phase = 0	next_phase = 1	reward = -0.368154	array([[-1.5735408, -2.100647 ]], dtype=float32)
time = 2353	action = 0	current_phase = 0	next_phase = 1	reward = -0.859520	array([[-1.4718497, -2.1609228]], dtype=float32)
time = 2358	action = 1	current_phase = 0	next_phase = 1	reward = -1.661527	array([[-2.9259536, -2.0250912]], dtype=float32)
time = 2366	action = 0	current_phase = 1	next_phase = 0	reward = -0.646694	array([[-1.4844344, -1.5279427]], dtype=float32)
time = 2371	action = 0	current_phase = 1	next_phase = 0	reward = -0.489590	array([[-1.2224956, -1.4055393]], dtype=float32)
time = 2376	action = 0	current_phase = 1	next_phase = 0	reward = -0.607474	array([[-1.0585682, -2.266526 ]], dtype=float32)
time = 2381	action = 0	current_phase = 1	next_phase = 0	reward = -1.089049	array([[-2.1336985, -2.1738012]], dtype=float32)
time = 2386	action = 0	current_phase = 1	next_phase = 0	reward = -1.354931	array([[-2.377643 , -2.6815434]], dtype=float32)
time = 2391	action = 0	current_phase = 1	next_phase = 0	reward = -1.248130	array([[-2.8569918, -3.0519302]], dtype=float32)
time = 2396	action = 0	current_phase = 1	next_phase = 0	reward = -1.750954	array([[-2.8060803, -3.0704012]], dtype=float32)
time = 2401	action = 1	current_phase = 1	next_phase = 0	reward = -2.840306	array([[-3.9286222, -3.4402463]], dtype=float32)
time = 2409	action = 0	current_phase = 0	next_phase = 1	reward = -0.832840	array([[-1.6164095, -2.926344 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.2740 - val_loss: 0.4108
Epoch 2/50
 - 1s - loss: 0.2057 - val_loss: 0.4163
Epoch 3/50
 - 1s - loss: 0.1824 - val_loss: 0.3997
Epoch 4/50
 - 1s - loss: 0.2005 - val_loss: 0.3885
Epoch 5/50
 - 1s - loss: 0.1850 - val_loss: 0.3861
Epoch 6/50
 - 1s - loss: 0.1835 - val_loss: 0.3886
Epoch 7/50
 - 1s - loss: 0.1695 - val_loss: 0.3847
Epoch 8/50
 - 1s - loss: 0.1740 - val_loss: 0.4096
Epoch 9/50
 - 1s - loss: 0.1783 - val_loss: 0.3861
Epoch 10/50
 - 1s - loss: 0.1749 - val_loss: 0.3835
Epoch 11/50
 - 1s - loss: 0.1668 - val_loss: 0.4033
Epoch 12/50
 - 1s - loss: 0.1720 - val_loss: 0.3845
Epoch 13/50
 - 1s - loss: 0.1761 - val_loss: 0.3844
Epoch 14/50
 - 1s - loss: 0.1663 - val_loss: 0.3803
Epoch 15/50
 - 1s - loss: 0.1685 - val_loss: 0.3858
Epoch 16/50
 - 1s - loss: 0.1660 - val_loss: 0.3820
Epoch 17/50
 - 1s - loss: 0.1645 - val_loss: 0.3763
Epoch 18/50
 - 1s - loss: 0.1598 - val_loss: 0.3878
Epoch 19/50
 - 1s - loss: 0.1655 - val_loss: 0.3815
Epoch 20/50
 - 1s - loss: 0.1804 - val_loss: 0.3797
Epoch 21/50
 - 1s - loss: 0.1519 - val_loss: 0.3975
Epoch 22/50
 - 1s - loss: 0.1496 - val_loss: 0.3781
Epoch 23/50
 - 1s - loss: 0.1528 - val_loss: 0.3805
Epoch 24/50
 - 1s - loss: 0.1490 - val_loss: 0.4062
Epoch 25/50
 - 1s - loss: 0.1503 - val_loss: 0.3710
Epoch 26/50
 - 1s - loss: 0.1592 - val_loss: 0.3829
Epoch 27/50
 - 1s - loss: 0.1450 - val_loss: 0.3754
Epoch 28/50
 - 1s - loss: 0.1649 - val_loss: 0.3748
Epoch 29/50
 - 1s - loss: 0.1433 - val_loss: 0.3688
Epoch 30/50
 - 1s - loss: 0.1565 - val_loss: 0.3698
Epoch 31/50
 - 1s - loss: 0.1508 - val_loss: 0.3721
Epoch 32/50
 - 1s - loss: 0.1597 - val_loss: 0.3636
Epoch 33/50
 - 1s - loss: 0.1353 - val_loss: 0.3648
Epoch 34/50
 - 1s - loss: 0.1428 - val_loss: 0.3658
Epoch 35/50
 - 1s - loss: 0.1473 - val_loss: 0.3636
Epoch 36/50
 - 1s - loss: 0.1488 - val_loss: 0.3615
Epoch 37/50
 - 1s - loss: 0.1428 - val_loss: 0.3604
Epoch 38/50
 - 1s - loss: 0.1479 - val_loss: 0.3580
Epoch 39/50
 - 1s - loss: 0.1559 - val_loss: 0.3594
Epoch 40/50
 - 1s - loss: 0.1315 - val_loss: 0.3568
Epoch 41/50
 - 1s - loss: 0.1389 - val_loss: 0.3585
Epoch 42/50
 - 1s - loss: 0.1319 - val_loss: 0.3584
Epoch 43/50
 - 1s - loss: 0.1361 - val_loss: 0.3597
Epoch 44/50
 - 1s - loss: 0.1341 - val_loss: 0.3592
Epoch 45/50
 - 1s - loss: 0.1317 - val_loss: 0.3595
Epoch 46/50
 - 1s - loss: 0.1345 - val_loss: 0.3601
Epoch 47/50
 - 1s - loss: 0.1289 - val_loss: 0.3530
Epoch 48/50
 - 1s - loss: 0.1265 - val_loss: 0.3524
Epoch 49/50
 - 1s - loss: 0.1324 - val_loss: 0.3537
Epoch 50/50
 - 1s - loss: 0.1585 - val_loss: 0.3558
length of memory (state 0, action 0): 736, after forget
length of memory (state 0, action 1): 332, after forget
length of memory (state 1, action 0): 647, after forget
length of memory (state 1, action 1): 320, after forget
time = 2414	action = 0	current_phase = 0	next_phase = 1	reward = -0.730473	array([[-1.815306, -3.272282]], dtype=float32)
time = 2419	action = 0	current_phase = 0	next_phase = 1	reward = -1.230880	array([[-2.273131 , -3.1089988]], dtype=float32)
time = 2424	action = 1	current_phase = 0	next_phase = 1	reward = -2.083989	array([[-3.3257723, -3.278545 ]], dtype=float32)
time = 2432	action = 0	current_phase = 1	next_phase = 0	reward = -0.389088	array([[-1.4231269, -1.6044325]], dtype=float32)
time = 2437	action = 0	current_phase = 1	next_phase = 0	reward = -0.359296	array([[-1.3022999, -2.9314675]], dtype=float32)
time = 2442	action = 0	current_phase = 1	next_phase = 0	reward = -0.867091	array([[-1.7268888, -3.276566 ]], dtype=float32)
time = 2447	action = 0	current_phase = 1	next_phase = 0	reward = -1.262666	array([[-3.05651  , -3.1584268]], dtype=float32)
time = 2452	action = 0	current_phase = 1	next_phase = 0	reward = -1.342083	array([[-2.2178445, -3.716824 ]], dtype=float32)
time = 2457	action = 0	current_phase = 1	next_phase = 0	reward = -1.288192	array([[-2.7580776, -3.254624 ]], dtype=float32)
time = 2462	action = 1	current_phase = 1	next_phase = 0	reward = -2.623194	array([[-3.720264 , -3.6180413]], dtype=float32)
time = 2470	action = 0	current_phase = 0	next_phase = 1	reward = -0.235610	array([[-1.5213058, -2.3092587]], dtype=float32)
time = 2475	action = 0	current_phase = 0	next_phase = 1	reward = -1.363209	array([[-2.5965357, -3.141088 ]], dtype=float32)
time = 2480	action = 1	current_phase = 0	next_phase = 1	reward = -3.039699	array([[-3.8498414, -3.005522 ]], dtype=float32)
time = 2488	action = 0	current_phase = 1	next_phase = 0	reward = -0.162940	array([[-1.3850921, -1.9668127]], dtype=float32)
time = 2493	action = 0	current_phase = 1	next_phase = 0	reward = -0.272247	array([[-1.0752764, -3.0533848]], dtype=float32)
time = 2498	action = 0	current_phase = 1	next_phase = 0	reward = -0.789390	array([[-1.4158828, -3.2775867]], dtype=float32)
time = 2503	action = 0	current_phase = 1	next_phase = 0	reward = -1.422291	array([[-1.4885174, -3.171915 ]], dtype=float32)
time = 2508	action = 0	current_phase = 1	next_phase = 0	reward = -1.227229	array([[-2.466783 , -2.6847997]], dtype=float32)
time = 2513	action = 0	current_phase = 1	next_phase = 0	reward = -0.965287	array([[-2.8090987, -2.8657086]], dtype=float32)
time = 2518	action = 0	current_phase = 1	next_phase = 0	reward = -1.446284	array([[-2.6057267, -3.4204073]], dtype=float32)
time = 2523	action = 1	current_phase = 1	next_phase = 0	reward = -2.595731	array([[-3.121992 , -2.7439382]], dtype=float32)
time = 2531	action = 0	current_phase = 0	next_phase = 1	reward = -0.132386	array([[-2.1563785, -2.8153524]], dtype=float32)
time = 2536	action = 0	current_phase = 0	next_phase = 1	reward = -1.176470	array([[-2.4122887, -2.7767813]], dtype=float32)
time = 2541	action = 0	current_phase = 0	next_phase = 1	reward = -1.551538	array([[-1.9328289, -3.143814 ]], dtype=float32)
time = 2546	action = 1	current_phase = 0	next_phase = 1	reward = -3.030468	array([[-3.3493686, -3.2270463]], dtype=float32)
time = 2554	action = 0	current_phase = 1	next_phase = 0	reward = 0.388383	array([[-0.891267 , -2.0427408]], dtype=float32)
time = 2559	action = 0	current_phase = 1	next_phase = 0	reward = -0.440121	array([[-0.9624502, -2.9834263]], dtype=float32)
time = 2564	action = 0	current_phase = 1	next_phase = 0	reward = -0.725032	array([[-0.780257 , -3.3365695]], dtype=float32)
time = 2569	action = 0	current_phase = 1	next_phase = 0	reward = -0.920487	array([[-1.621189, -3.179625]], dtype=float32)
time = 2574	action = 0	current_phase = 1	next_phase = 0	reward = -1.121603	array([[-1.9094805, -2.9752698]], dtype=float32)
time = 2579	action = 0	current_phase = 1	next_phase = 0	reward = -1.107312	array([[-1.2878835, -3.0563865]], dtype=float32)
time = 2584	action = 0	current_phase = 1	next_phase = 0	reward = -1.061167	array([[-1.5609133, -3.3057775]], dtype=float32)
time = 2589	action = 0	current_phase = 1	next_phase = 0	reward = -1.233497	array([[-2.0431013, -2.908077 ]], dtype=float32)
time = 2594	action = 1	current_phase = 1	next_phase = 0	reward = -1.586853	array([[-2.8839393, -2.669858 ]], dtype=float32)
time = 2602	action = 0	current_phase = 0	next_phase = 1	reward = -0.206406	array([[-1.0490495, -2.4892468]], dtype=float32)
time = 2607	action = 0	current_phase = 0	next_phase = 1	reward = -1.134932	array([[-1.5243795, -2.1058352]], dtype=float32)
time = 2612	action = 0	current_phase = 0	next_phase = 1	reward = -0.975572	array([[-1.3578072, -2.8426726]], dtype=float32)
time = 2617	action = 0	current_phase = 0	next_phase = 1	reward = -1.369002	array([[-2.3160844, -2.755509 ]], dtype=float32)
time = 2622	action = 0	current_phase = 0	next_phase = 1	reward = -1.186915	array([[-2.6891394, -2.8053064]], dtype=float32)
time = 2627	action = 1	current_phase = 0	next_phase = 1	reward = -1.423187	array([[-3.4135897, -3.169186 ]], dtype=float32)
time = 2635	action = 0	current_phase = 1	next_phase = 0	reward = -0.049418	array([[-0.8068258, -2.1620681]], dtype=float32)
time = 2640	action = 0	current_phase = 1	next_phase = 0	reward = -1.137700	array([[-1.0054077, -2.7404964]], dtype=float32)
time = 2645	action = 0	current_phase = 1	next_phase = 0	reward = -1.410041	array([[-1.0034553, -2.8833554]], dtype=float32)
time = 2650	action = 0	current_phase = 1	next_phase = 0	reward = -1.554482	array([[-1.7832514, -2.7317743]], dtype=float32)
time = 2655	action = 1	current_phase = 1	next_phase = 0	reward = -2.305887	array([[-2.4985676, -2.429242 ]], dtype=float32)
time = 2663	action = 0	current_phase = 0	next_phase = 1	reward = 0.327761	array([[-1.0251644, -2.349148 ]], dtype=float32)
time = 2668	action = 0	current_phase = 0	next_phase = 1	reward = -0.132267	array([[-1.6772143, -2.0183792]], dtype=float32)
time = 2673	action = 0	current_phase = 0	next_phase = 1	reward = -0.261834	array([[-1.2766078, -2.45246  ]], dtype=float32)
time = 2678	action = 0	current_phase = 0	next_phase = 1	reward = -1.304345	array([[-1.388324 , -2.8877332]], dtype=float32)
time = 2683	action = 1	current_phase = 0	next_phase = 1	reward = -1.942096	array([[-2.9918127, -2.7422574]], dtype=float32)
time = 2691	action = 0	current_phase = 1	next_phase = 0	reward = -0.650062	array([[-0.82085204, -1.9407816 ]], dtype=float32)
time = 2696	action = 0	current_phase = 1	next_phase = 0	reward = -0.807022	array([[-0.93057775, -2.6618571 ]], dtype=float32)
time = 2701	action = 0	current_phase = 1	next_phase = 0	reward = -0.394244	array([[-1.0326629, -2.4972131]], dtype=float32)
time = 2706	action = 0	current_phase = 1	next_phase = 0	reward = -1.157084	array([[-1.4087201, -2.3340127]], dtype=float32)
time = 2711	action = 0	current_phase = 1	next_phase = 0	reward = -0.751088	array([[-1.8880174, -2.3011355]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.2339 - val_loss: 2.2167
Epoch 2/50
 - 1s - loss: 0.2240 - val_loss: 2.2184
Epoch 3/50
 - 1s - loss: 0.2121 - val_loss: 2.2147
Epoch 4/50
 - 1s - loss: 0.2066 - val_loss: 2.2168
Epoch 5/50
 - 1s - loss: 0.2102 - val_loss: 2.2065
Epoch 6/50
 - 1s - loss: 0.1950 - val_loss: 2.2105
Epoch 7/50
 - 1s - loss: 0.2033 - val_loss: 2.2155
Epoch 8/50
 - 1s - loss: 0.2000 - val_loss: 2.2138
Epoch 9/50
 - 1s - loss: 0.1921 - val_loss: 2.2150
Epoch 10/50
 - 1s - loss: 0.1914 - val_loss: 2.2085
Epoch 11/50
 - 1s - loss: 0.1994 - val_loss: 2.2173
Epoch 12/50
 - 1s - loss: 0.1873 - val_loss: 2.2043
Epoch 13/50
 - 1s - loss: 0.1881 - val_loss: 2.2118
Epoch 14/50
 - 1s - loss: 0.1813 - val_loss: 2.2032
Epoch 15/50
 - 1s - loss: 0.1795 - val_loss: 2.2026
Epoch 16/50
 - 1s - loss: 0.1756 - val_loss: 2.2064
Epoch 17/50
 - 1s - loss: 0.1821 - val_loss: 2.2055
Epoch 18/50
 - 1s - loss: 0.1709 - val_loss: 2.2142
Epoch 19/50
 - 1s - loss: 0.1880 - val_loss: 2.2055
Epoch 20/50
 - 1s - loss: 0.1783 - val_loss: 2.2068
Epoch 21/50
 - 1s - loss: 0.1712 - val_loss: 2.2036
Epoch 22/50
 - 1s - loss: 0.1785 - val_loss: 2.2063
Epoch 23/50
 - 1s - loss: 0.1643 - val_loss: 2.2001
Epoch 24/50
 - 1s - loss: 0.1670 - val_loss: 2.1997
Epoch 25/50
 - 1s - loss: 0.1670 - val_loss: 2.2062
Epoch 26/50
 - 1s - loss: 0.1661 - val_loss: 2.2123
Epoch 27/50
 - 1s - loss: 0.1617 - val_loss: 2.1999
Epoch 28/50
 - 1s - loss: 0.1648 - val_loss: 2.2060
Epoch 29/50
 - 1s - loss: 0.1601 - val_loss: 2.2063
Epoch 30/50
 - 1s - loss: 0.1528 - val_loss: 2.2001
Epoch 31/50
 - 1s - loss: 0.1758 - val_loss: 2.1978
Epoch 32/50
 - 1s - loss: 0.1620 - val_loss: 2.2008
Epoch 33/50
 - 1s - loss: 0.1599 - val_loss: 2.1993
Epoch 34/50
 - 1s - loss: 0.1571 - val_loss: 2.2013
Epoch 35/50
 - 1s - loss: 0.1603 - val_loss: 2.1950
Epoch 36/50
 - 1s - loss: 0.1622 - val_loss: 2.1959
Epoch 37/50
 - 1s - loss: 0.1490 - val_loss: 2.1939
Epoch 38/50
 - 1s - loss: 0.1602 - val_loss: 2.1977
Epoch 39/50
 - 1s - loss: 0.1483 - val_loss: 2.1992
Epoch 40/50
 - 1s - loss: 0.1560 - val_loss: 2.1953
Epoch 41/50
 - 1s - loss: 0.1519 - val_loss: 2.1910
Epoch 42/50
 - 1s - loss: 0.1542 - val_loss: 2.2022
Epoch 43/50
 - 1s - loss: 0.1502 - val_loss: 2.1960
Epoch 44/50
 - 1s - loss: 0.1504 - val_loss: 2.1904
Epoch 45/50
 - 1s - loss: 0.1600 - val_loss: 2.1980
Epoch 46/50
 - 1s - loss: 0.1434 - val_loss: 2.2005
Epoch 47/50
 - 1s - loss: 0.1359 - val_loss: 2.1989
Epoch 48/50
 - 1s - loss: 0.1491 - val_loss: 2.2176
Epoch 49/50
 - 1s - loss: 0.1483 - val_loss: 2.2043
Epoch 50/50
 - 1s - loss: 0.1636 - val_loss: 2.2063
length of memory (state 0, action 0): 752, after forget
length of memory (state 0, action 1): 337, after forget
length of memory (state 1, action 0): 677, after forget
length of memory (state 1, action 1): 324, after forget
time = 2716	action = 0	current_phase = 1	next_phase = 0	reward = -0.236689	array([[-1.5231949, -1.9926176]], dtype=float32)
time = 2721	action = 1	current_phase = 1	next_phase = 0	reward = -1.110471	array([[-2.0325332, -2.0275733]], dtype=float32)
time = 2729	action = 0	current_phase = 0	next_phase = 1	reward = -0.138769	array([[-0.9157313, -2.524111 ]], dtype=float32)
time = 2734	action = 0	current_phase = 0	next_phase = 1	reward = -0.755195	array([[-1.4105798, -2.4415548]], dtype=float32)
time = 2739	action = 0	current_phase = 0	next_phase = 1	reward = -0.981037	array([[-1.9244759, -2.470728 ]], dtype=float32)
time = 2744	action = 0	current_phase = 0	next_phase = 1	reward = -1.133965	array([[-1.8672688, -2.8545766]], dtype=float32)
time = 2749	action = 1	current_phase = 0	next_phase = 1	reward = -1.542863	array([[-2.783043 , -2.7241437]], dtype=float32)
time = 2757	action = 0	current_phase = 1	next_phase = 0	reward = -0.067067	array([[-1.0756516, -1.9409497]], dtype=float32)
time = 2762	action = 0	current_phase = 1	next_phase = 0	reward = 0.081495	array([[-1.2793319, -2.360797 ]], dtype=float32)
time = 2767	action = 0	current_phase = 1	next_phase = 0	reward = -0.717345	array([[-1.3977227, -2.521685 ]], dtype=float32)
time = 2772	action = 1	current_phase = 1	next_phase = 0	reward = -1.313479	array([[-2.7635212, -2.4216993]], dtype=float32)
time = 2780	action = 0	current_phase = 0	next_phase = 1	reward = 0.077767	array([[-0.98295915, -2.223134  ]], dtype=float32)
time = 2785	action = 0	current_phase = 0	next_phase = 1	reward = 0.084315	array([[-1.2597895, -2.3418198]], dtype=float32)
time = 2790	action = 0	current_phase = 0	next_phase = 1	reward = -0.748078	array([[-2.024692 , -2.2451093]], dtype=float32)
time = 2795	action = 0	current_phase = 0	next_phase = 1	reward = -1.000776	array([[-1.9410689, -2.3348706]], dtype=float32)
time = 2800	action = 1	current_phase = 0	next_phase = 1	reward = -1.279355	array([[-2.736761 , -2.1320493]], dtype=float32)
time = 2808	action = 0	current_phase = 1	next_phase = 0	reward = -0.058314	array([[-1.347614 , -2.6195195]], dtype=float32)
time = 2813	action = 0	current_phase = 1	next_phase = 0	reward = 0.070376	array([[-0.76050127, -3.378422  ]], dtype=float32)
time = 2818	action = 0	current_phase = 1	next_phase = 0	reward = -0.173479	array([[-0.9573477, -3.0899856]], dtype=float32)
time = 2823	action = 0	current_phase = 1	next_phase = 0	reward = -0.876075	array([[-1.3625075, -3.0140698]], dtype=float32)
time = 2828	action = 0	current_phase = 1	next_phase = 0	reward = -0.757185	array([[-2.471406 , -2.5864286]], dtype=float32)
time = 2833	action = 1	current_phase = 1	next_phase = 0	reward = -1.442605	array([[-2.8926275, -2.8589513]], dtype=float32)
time = 2841	action = 1	current_phase = 0	next_phase = 1	reward = -1.434957	array([[-2.3359053, -1.9932808]], dtype=float32)
time = 2849	action = 0	current_phase = 1	next_phase = 0	reward = -0.616660	array([[-1.2940212, -1.9098599]], dtype=float32)
time = 2854	action = 0	current_phase = 1	next_phase = 0	reward = -0.602314	array([[-1.2197025, -2.9456685]], dtype=float32)
time = 2859	action = 0	current_phase = 1	next_phase = 0	reward = -0.763423	array([[-1.1322128, -3.286406 ]], dtype=float32)
time = 2864	action = 0	current_phase = 1	next_phase = 0	reward = -0.589811	array([[-1.9393141, -2.2317533]], dtype=float32)
time = 2869	action = 1	current_phase = 1	next_phase = 0	reward = -1.624928	array([[-2.8638685, -2.2120423]], dtype=float32)
time = 2877	action = 0	current_phase = 0	next_phase = 1	reward = -0.252909	array([[-1.0171167, -2.3520432]], dtype=float32)
time = 2882	action = 0	current_phase = 0	next_phase = 1	reward = -0.940820	array([[-1.5051895, -2.21853  ]], dtype=float32)
time = 2887	action = 0	current_phase = 0	next_phase = 1	reward = -1.017940	array([[-1.8279186, -2.4863915]], dtype=float32)
time = 2892	action = 0	current_phase = 0	next_phase = 1	reward = -1.522654	array([[-2.1344259, -2.8973746]], dtype=float32)
time = 2897	action = 0	current_phase = 0	next_phase = 1	reward = -1.656925	array([[-2.4179516, -2.9400656]], dtype=float32)
time = 2902	action = 1	current_phase = 0	next_phase = 1	reward = -1.995717	array([[-2.7739353, -2.5267537]], dtype=float32)
time = 2910	action = 0	current_phase = 1	next_phase = 0	reward = -0.307185	array([[-1.3385926, -2.1334696]], dtype=float32)
time = 2915	action = 0	current_phase = 1	next_phase = 0	reward = -0.496572	array([[-1.3723383, -2.6955678]], dtype=float32)
time = 2920	action = 0	current_phase = 1	next_phase = 0	reward = -0.439010	array([[-1.6145906, -2.0381799]], dtype=float32)
time = 2925	action = 1	current_phase = 1	next_phase = 0	reward = -0.922193	array([[-2.1373343, -1.6220202]], dtype=float32)
time = 2933	action = 0	current_phase = 0	next_phase = 1	reward = 0.345374	array([[-0.29299164, -2.835637  ]], dtype=float32)
time = 2938	action = 0	current_phase = 0	next_phase = 1	reward = 0.283666	array([[-0.23294091, -3.0367253 ]], dtype=float32)
time = 2943	action = 0	current_phase = 0	next_phase = 1	reward = 0.017893	array([[-0.74314255, -3.0715845 ]], dtype=float32)
time = 2948	action = 0	current_phase = 0	next_phase = 1	reward = 0.009776	array([[-1.2359949, -2.0166063]], dtype=float32)
time = 2953	action = 0	current_phase = 0	next_phase = 1	reward = -0.813346	array([[-1.7489339, -2.2502947]], dtype=float32)
time = 2958	action = 0	current_phase = 0	next_phase = 1	reward = -0.868962	array([[-1.2965579, -2.679967 ]], dtype=float32)
time = 2963	action = 0	current_phase = 0	next_phase = 1	reward = -0.931748	array([[-1.1342845, -3.032932 ]], dtype=float32)
time = 2968	action = 1	current_phase = 0	next_phase = 1	reward = -1.457823	array([[-2.5010786, -2.3131924]], dtype=float32)
time = 2976	action = 0	current_phase = 1	next_phase = 0	reward = -1.011327	array([[-0.7890866, -1.7284079]], dtype=float32)
time = 2981	action = 0	current_phase = 1	next_phase = 0	reward = -1.127895	array([[-1.3579528, -2.4733183]], dtype=float32)
time = 2986	action = 1	current_phase = 1	next_phase = 0	reward = -2.525120	array([[-2.2797484, -2.1660492]], dtype=float32)
time = 2994	action = 0	current_phase = 0	next_phase = 1	reward = 0.416049	array([[-0.95879304, -2.3925354 ]], dtype=float32)
time = 2999	action = 0	current_phase = 0	next_phase = 1	reward = 0.037005	array([[-0.69745356, -2.6333196 ]], dtype=float32)
time = 3004	action = 0	current_phase = 0	next_phase = 1	reward = -0.670857	array([[-1.4645144, -2.2801785]], dtype=float32)
time = 3009	action = 0	current_phase = 0	next_phase = 1	reward = -0.596642	array([[-1.7751722, -2.9133027]], dtype=float32)
time = 3014	action = 1	current_phase = 0	next_phase = 1	reward = -1.441226	array([[-2.9443035, -2.357277 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.0098 - val_loss: 0.1092
Epoch 2/50
 - 1s - loss: 1.0003 - val_loss: 0.0976
Epoch 3/50
 - 1s - loss: 0.9932 - val_loss: 0.1036
Epoch 4/50
 - 1s - loss: 0.9830 - val_loss: 0.1081
Epoch 5/50
 - 1s - loss: 0.9760 - val_loss: 0.1074
Epoch 6/50
 - 1s - loss: 0.9793 - val_loss: 0.0959
Epoch 7/50
 - 1s - loss: 0.9667 - val_loss: 0.1136
Epoch 8/50
 - 1s - loss: 0.9663 - val_loss: 0.1122
Epoch 9/50
 - 1s - loss: 0.9598 - val_loss: 0.1068
Epoch 10/50
 - 1s - loss: 0.9386 - val_loss: 0.1076
Epoch 11/50
 - 1s - loss: 0.9174 - val_loss: 0.1200
Epoch 12/50
 - 1s - loss: 0.9129 - val_loss: 0.1137
Epoch 13/50
 - 1s - loss: 0.8966 - val_loss: 0.1175
Epoch 14/50
 - 1s - loss: 0.8711 - val_loss: 0.1175
Epoch 15/50
 - 1s - loss: 0.8613 - val_loss: 0.1170
Epoch 16/50
 - 1s - loss: 0.8643 - val_loss: 0.1227
length of memory (state 0, action 0): 776, after forget
length of memory (state 0, action 1): 343, after forget
length of memory (state 1, action 0): 695, after forget
length of memory (state 1, action 1): 330, after forget
time = 3022	action = 0	current_phase = 1	next_phase = 0	reward = 0.268418	array([[-0.8077824, -2.3993714]], dtype=float32)
time = 3027	action = 0	current_phase = 1	next_phase = 0	reward = 0.086397	array([[-1.0265461, -2.5482907]], dtype=float32)
time = 3032	action = 0	current_phase = 1	next_phase = 0	reward = -0.683501	array([[-1.8705223, -2.4413502]], dtype=float32)
time = 3037	action = 0	current_phase = 1	next_phase = 0	reward = -0.725433	array([[-1.995027, -2.54559 ]], dtype=float32)
time = 3042	action = 0	current_phase = 1	next_phase = 0	reward = -0.808104	array([[-2.0507965, -2.1506605]], dtype=float32)
time = 3047	action = 1	current_phase = 1	next_phase = 0	reward = -1.886583	array([[-2.590224 , -2.2151926]], dtype=float32)
time = 3055	action = 0	current_phase = 0	next_phase = 1	reward = 0.283578	array([[-0.74179906, -2.8105037 ]], dtype=float32)
time = 3060	action = 0	current_phase = 0	next_phase = 1	reward = 0.346873	array([[-1.3690438, -2.432541 ]], dtype=float32)
time = 3065	action = 0	current_phase = 0	next_phase = 1	reward = -0.554588	array([[-1.3888975, -2.0592875]], dtype=float32)
time = 3070	action = 0	current_phase = 0	next_phase = 1	reward = -1.389812	array([[-1.4616461, -2.5643563]], dtype=float32)
time = 3075	action = 0	current_phase = 0	next_phase = 1	reward = -1.344785	array([[-2.9182873, -3.9800131]], dtype=float32)
time = 3080	action = 0	current_phase = 0	next_phase = 1	reward = -1.285274	array([[-1.923745 , -3.8211248]], dtype=float32)
time = 3085	action = 0	current_phase = 0	next_phase = 1	reward = -1.381704	array([[-2.405558 , -3.9226508]], dtype=float32)
time = 3090	action = 1	current_phase = 0	next_phase = 1	reward = -2.351757	array([[-3.7264261, -3.389726 ]], dtype=float32)
time = 3098	action = 0	current_phase = 1	next_phase = 0	reward = -0.255727	array([[-0.7799345, -2.3372045]], dtype=float32)
time = 3103	action = 0	current_phase = 1	next_phase = 0	reward = -0.487679	array([[-1.0890173, -2.6981003]], dtype=float32)
time = 3108	action = 0	current_phase = 1	next_phase = 0	reward = 0.032023	array([[-1.5088979, -2.6756866]], dtype=float32)
time = 3113	action = 0	current_phase = 1	next_phase = 0	reward = -0.230117	array([[-1.0733163, -2.1681373]], dtype=float32)
time = 3118	action = 0	current_phase = 1	next_phase = 0	reward = -0.210518	array([[-1.2068263, -2.0067456]], dtype=float32)
time = 3123	action = 0	current_phase = 1	next_phase = 0	reward = -0.190628	array([[-1.0196103, -2.174401 ]], dtype=float32)
time = 3128	action = 0	current_phase = 1	next_phase = 0	reward = -1.402678	array([[-1.0891997, -1.5400802]], dtype=float32)
time = 3133	action = 1	current_phase = 1	next_phase = 0	reward = -3.258688	array([[-2.8506532, -2.1593468]], dtype=float32)
time = 3141	action = 0	current_phase = 0	next_phase = 1	reward = -0.174156	array([[-0.69322455, -3.183013  ]], dtype=float32)
time = 3146	action = 0	current_phase = 0	next_phase = 1	reward = -0.357095	array([[-1.2619052, -2.7272635]], dtype=float32)
time = 3151	action = 0	current_phase = 0	next_phase = 1	reward = -0.472545	array([[-1.1797564, -3.0426106]], dtype=float32)
time = 3156	action = 0	current_phase = 0	next_phase = 1	reward = -0.995768	array([[-2.010822 , -3.0429144]], dtype=float32)
time = 3161	action = 1	current_phase = 0	next_phase = 1	reward = -2.247521	array([[-3.2444396, -3.0714014]], dtype=float32)
time = 3169	action = 0	current_phase = 1	next_phase = 0	reward = -0.551856	array([[-1.6576959, -2.5062094]], dtype=float32)
time = 3174	action = 0	current_phase = 1	next_phase = 0	reward = -0.361372	array([[-2.0254176, -2.8957016]], dtype=float32)
time = 3179	action = 0	current_phase = 1	next_phase = 0	reward = -1.014981	array([[-2.0270107, -2.4742239]], dtype=float32)
time = 3184	action = 0	current_phase = 1	next_phase = 0	reward = -1.102827	array([[-2.1430123, -2.7565012]], dtype=float32)
time = 3189	action = 0	current_phase = 1	next_phase = 0	reward = -1.661382	array([[-2.716713 , -3.1526268]], dtype=float32)
time = 3194	action = 1	current_phase = 1	next_phase = 0	reward = -2.357895	array([[-4.5243626, -3.74883  ]], dtype=float32)
time = 3202	action = 1	current_phase = 0	next_phase = 1	reward = -1.942453	array([[-2.7151926, -2.2567875]], dtype=float32)
time = 3210	action = 0	current_phase = 1	next_phase = 0	reward = -0.976375	array([[-1.6668144, -2.5961037]], dtype=float32)
time = 3215	action = 0	current_phase = 1	next_phase = 0	reward = -1.032283	array([[-1.6370189, -3.1214511]], dtype=float32)
time = 3220	action = 0	current_phase = 1	next_phase = 0	reward = -0.943579	array([[-1.6817406, -3.2180018]], dtype=float32)
time = 3225	action = 0	current_phase = 1	next_phase = 0	reward = -1.401491	array([[-2.8062375, -3.362938 ]], dtype=float32)
time = 3230	action = 0	current_phase = 1	next_phase = 0	reward = -1.253909	array([[-2.4129481, -3.5267634]], dtype=float32)
time = 3235	action = 0	current_phase = 1	next_phase = 0	reward = -1.467188	array([[-2.8074408, -3.284093 ]], dtype=float32)
time = 3240	action = 1	current_phase = 1	next_phase = 0	reward = -1.680439	array([[-3.3598464, -3.2270513]], dtype=float32)
time = 3248	action = 0	current_phase = 0	next_phase = 1	reward = -0.632381	array([[-1.4098084, -2.2359772]], dtype=float32)
time = 3253	action = 0	current_phase = 0	next_phase = 1	reward = -1.147104	array([[-1.6629161, -2.711215 ]], dtype=float32)
time = 3258	action = 0	current_phase = 0	next_phase = 1	reward = -1.346775	array([[-2.163907 , -3.0195334]], dtype=float32)
time = 3263	action = 0	current_phase = 0	next_phase = 1	reward = -1.324753	array([[-2.1580229, -3.4656203]], dtype=float32)
time = 3268	action = 1	current_phase = 0	next_phase = 1	reward = -1.657011	array([[-3.4965491, -2.641636 ]], dtype=float32)
time = 3276	action = 0	current_phase = 1	next_phase = 0	reward = 0.054412	array([[-1.1768118, -1.7563571]], dtype=float32)
time = 3281	action = 0	current_phase = 1	next_phase = 0	reward = -0.605068	array([[-1.7031149, -2.3029675]], dtype=float32)
time = 3286	action = 0	current_phase = 1	next_phase = 0	reward = -0.772889	array([[-1.8569789, -2.5913887]], dtype=float32)
time = 3291	action = 0	current_phase = 1	next_phase = 0	reward = -1.401293	array([[-2.150713 , -2.9418633]], dtype=float32)
time = 3296	action = 0	current_phase = 1	next_phase = 0	reward = -1.356326	array([[-2.6349013, -2.8193026]], dtype=float32)
time = 3301	action = 1	current_phase = 1	next_phase = 0	reward = -2.574887	array([[-4.1098175, -3.326719 ]], dtype=float32)
time = 3309	action = 0	current_phase = 0	next_phase = 1	reward = -0.331713	array([[-2.0161889, -2.649872 ]], dtype=float32)
time = 3314	action = 0	current_phase = 0	next_phase = 1	reward = -0.455991	array([[-2.2251244, -2.7198818]], dtype=float32)
time = 3319	action = 1	current_phase = 0	next_phase = 1	reward = -1.726270	array([[-2.8951936, -2.2659516]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.0455 - val_loss: 0.0941
Epoch 2/50
 - 1s - loss: 0.9939 - val_loss: 0.0883
Epoch 3/50
 - 1s - loss: 0.9807 - val_loss: 0.0908
Epoch 4/50
 - 1s - loss: 0.9725 - val_loss: 0.1035
Epoch 5/50
 - 1s - loss: 1.0002 - val_loss: 0.0943
Epoch 6/50
 - 1s - loss: 0.9585 - val_loss: 0.0970
Epoch 7/50
 - 1s - loss: 0.9992 - val_loss: 0.1003
Epoch 8/50
 - 1s - loss: 0.9487 - val_loss: 0.0942
Epoch 9/50
 - 1s - loss: 0.9509 - val_loss: 0.0969
Epoch 10/50
 - 1s - loss: 0.9357 - val_loss: 0.0960
Epoch 11/50
 - 1s - loss: 0.9410 - val_loss: 0.1038
Epoch 12/50
 - 1s - loss: 0.9206 - val_loss: 0.0996
length of memory (state 0, action 0): 793, after forget
length of memory (state 0, action 1): 348, after forget
length of memory (state 1, action 0): 723, after forget
length of memory (state 1, action 1): 335, after forget
time = 3327	action = 0	current_phase = 1	next_phase = 0	reward = -0.177843	array([[-1.8078113, -2.5583668]], dtype=float32)
time = 3332	action = 0	current_phase = 1	next_phase = 0	reward = -0.210321	array([[-1.6526742, -3.2623515]], dtype=float32)
time = 3337	action = 0	current_phase = 1	next_phase = 0	reward = -0.462453	array([[-1.8808157, -3.4960177]], dtype=float32)
time = 3342	action = 0	current_phase = 1	next_phase = 0	reward = -0.629767	array([[-2.4958508, -3.1075194]], dtype=float32)
time = 3347	action = 1	current_phase = 1	next_phase = 0	reward = -2.231469	array([[-3.7028105, -3.6411612]], dtype=float32)
time = 3355	action = 1	current_phase = 0	next_phase = 1	reward = -1.634237	array([[-2.4138966, -2.201111 ]], dtype=float32)
time = 3363	action = 0	current_phase = 1	next_phase = 0	reward = -0.294460	array([[-1.748841, -2.380481]], dtype=float32)
time = 3368	action = 0	current_phase = 1	next_phase = 0	reward = -0.830860	array([[-1.6371851, -2.9494905]], dtype=float32)
time = 3373	action = 0	current_phase = 1	next_phase = 0	reward = -1.359139	array([[-2.283602, -3.022635]], dtype=float32)
time = 3378	action = 0	current_phase = 1	next_phase = 0	reward = -0.516613	array([[-2.5187635, -2.993104 ]], dtype=float32)
time = 3383	action = 1	current_phase = 1	next_phase = 0	reward = -1.838371	array([[-3.3496952, -2.797274 ]], dtype=float32)
time = 3391	action = 0	current_phase = 0	next_phase = 1	reward = 0.093533	array([[-1.9091862, -2.1831589]], dtype=float32)
time = 3396	action = 1	current_phase = 0	next_phase = 1	reward = -1.248281	array([[-2.3780866, -2.1629682]], dtype=float32)
time = 3404	action = 0	current_phase = 1	next_phase = 0	reward = -0.007945	array([[-1.2392988, -2.6431465]], dtype=float32)
time = 3409	action = 0	current_phase = 1	next_phase = 0	reward = -0.378938	array([[-0.837767 , -3.2177422]], dtype=float32)
time = 3414	action = 0	current_phase = 1	next_phase = 0	reward = 0.131355	array([[-1.0145454, -3.088199 ]], dtype=float32)
time = 3419	action = 0	current_phase = 1	next_phase = 0	reward = -0.491836	array([[-1.4684427, -2.74586  ]], dtype=float32)
time = 3424	action = 0	current_phase = 1	next_phase = 0	reward = -0.314479	array([[-1.4994075, -2.8837132]], dtype=float32)
time = 3429	action = 0	current_phase = 1	next_phase = 0	reward = -0.582001	array([[-1.1372507, -2.8912072]], dtype=float32)
time = 3434	action = 0	current_phase = 1	next_phase = 0	reward = -0.275514	array([[-1.5297964, -3.0540686]], dtype=float32)
time = 3439	action = 0	current_phase = 1	next_phase = 0	reward = -0.882900	array([[-1.2783765, -2.0657146]], dtype=float32)
time = 3444	action = 0	current_phase = 1	next_phase = 0	reward = -0.367745	array([[-1.2639146, -3.0387733]], dtype=float32)
time = 3449	action = 0	current_phase = 1	next_phase = 0	reward = -0.711486	array([[-1.1952398, -2.2476768]], dtype=float32)
time = 3454	action = 0	current_phase = 1	next_phase = 0	reward = -0.876657	array([[-2.055404 , -2.5886312]], dtype=float32)
time = 3459	action = 0	current_phase = 1	next_phase = 0	reward = -1.210789	array([[-2.0317843, -2.8419745]], dtype=float32)
time = 3464	action = 0	current_phase = 1	next_phase = 0	reward = -1.093994	array([[-2.0247896, -2.7060783]], dtype=float32)
time = 3469	action = 0	current_phase = 1	next_phase = 0	reward = -1.590697	array([[-2.7086508, -2.8673353]], dtype=float32)
time = 3474	action = 1	current_phase = 1	next_phase = 0	reward = -1.552336	array([[-3.177197 , -2.6143699]], dtype=float32)
time = 3482	action = 0	current_phase = 0	next_phase = 1	reward = 0.493235	array([[-1.0513382, -3.0801694]], dtype=float32)
time = 3487	action = 0	current_phase = 0	next_phase = 1	reward = -0.409755	array([[-1.0167308, -2.7141147]], dtype=float32)
time = 3492	action = 0	current_phase = 0	next_phase = 1	reward = -1.071691	array([[-1.69121  , -2.5962715]], dtype=float32)
time = 3497	action = 0	current_phase = 0	next_phase = 1	reward = -1.327591	array([[-2.3765275, -2.602136 ]], dtype=float32)
time = 3502	action = 1	current_phase = 0	next_phase = 1	reward = -2.225352	array([[-3.7101145, -2.6814466]], dtype=float32)
time = 3510	action = 0	current_phase = 1	next_phase = 0	reward = -0.294249	array([[-1.4436901, -1.8199035]], dtype=float32)
time = 3515	action = 0	current_phase = 1	next_phase = 0	reward = -0.074880	array([[-1.4626062, -2.1530206]], dtype=float32)
time = 3520	action = 0	current_phase = 1	next_phase = 0	reward = -0.974186	array([[-1.8291361, -2.8676536]], dtype=float32)
time = 3525	action = 1	current_phase = 1	next_phase = 0	reward = -2.255650	array([[-3.0923553, -2.9058814]], dtype=float32)
time = 3533	action = 0	current_phase = 0	next_phase = 1	reward = -0.258806	array([[-1.4555173, -3.0155709]], dtype=float32)
time = 3538	action = 0	current_phase = 0	next_phase = 1	reward = -0.506348	array([[-2.17567  , -2.3761303]], dtype=float32)
time = 3543	action = 1	current_phase = 0	next_phase = 1	reward = -1.774817	array([[-3.1191735, -2.6087356]], dtype=float32)
time = 3551	action = 0	current_phase = 1	next_phase = 0	reward = -0.063238	array([[-1.4060833, -2.218019 ]], dtype=float32)
time = 3556	action = 0	current_phase = 1	next_phase = 0	reward = -0.688184	array([[-1.8729525, -2.402219 ]], dtype=float32)
time = 3561	action = 0	current_phase = 1	next_phase = 0	reward = -0.900019	array([[-2.3499818, -2.9438102]], dtype=float32)
time = 3566	action = 0	current_phase = 1	next_phase = 0	reward = -1.071239	array([[-2.9368935, -3.197739 ]], dtype=float32)
time = 3571	action = 1	current_phase = 1	next_phase = 0	reward = -2.793882	array([[-3.9995728, -3.1129837]], dtype=float32)
time = 3579	action = 0	current_phase = 0	next_phase = 1	reward = -0.353385	array([[-1.3076184, -2.797483 ]], dtype=float32)
time = 3584	action = 0	current_phase = 0	next_phase = 1	reward = -0.552138	array([[-1.4853655, -3.0908563]], dtype=float32)
time = 3589	action = 0	current_phase = 0	next_phase = 1	reward = -0.680200	array([[-1.6678585, -2.9792793]], dtype=float32)
time = 3594	action = 0	current_phase = 0	next_phase = 1	reward = -1.089418	array([[-1.8799372, -3.1475954]], dtype=float32)
time = 3599	action = 0	current_phase = 0	next_phase = 1	reward = -1.369763	array([[-2.0074315, -3.6495922]], dtype=float32)
time = 3604	action = 0	current_phase = 0	next_phase = 1	reward = -1.816600	array([[-3.024591 , -3.3539672]], dtype=float32)
time = 3609	action = 1	current_phase = 0	next_phase = 1	reward = -2.005746	array([[-3.453052 , -3.0729747]], dtype=float32)
time = 3617	action = 0	current_phase = 1	next_phase = 0	reward = -0.278390	array([[-1.7507739, -1.9332339]], dtype=float32)
time = 3622	action = 0	current_phase = 1	next_phase = 0	reward = -0.619216	array([[-1.4435616, -2.6396825]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.1190 - val_loss: 1.8187
Epoch 2/50
 - 1s - loss: 0.1138 - val_loss: 1.8490
Epoch 3/50
 - 1s - loss: 0.1185 - val_loss: 1.8195
Epoch 4/50
 - 1s - loss: 0.1133 - val_loss: 1.8219
Epoch 5/50
 - 1s - loss: 0.1182 - val_loss: 1.8326
Epoch 6/50
 - 1s - loss: 0.1064 - val_loss: 1.8331
Epoch 7/50
 - 1s - loss: 0.0955 - val_loss: 1.8286
Epoch 8/50
 - 1s - loss: 0.0891 - val_loss: 1.8269
Epoch 9/50
 - 1s - loss: 0.1026 - val_loss: 1.8442
Epoch 10/50
 - 1s - loss: 0.0945 - val_loss: 1.8389
Epoch 11/50
 - 1s - loss: 0.0929 - val_loss: 1.8341
length of memory (state 0, action 0): 806, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 754, after forget
length of memory (state 1, action 1): 340, after forget
time = 3627	action = 0	current_phase = 1	next_phase = 0	reward = -0.606599	array([[-2.4378142, -2.7558882]], dtype=float32)
time = 3632	action = 1	current_phase = 1	next_phase = 0	reward = -1.071380	array([[-2.5898585, -2.4046254]], dtype=float32)
time = 3640	action = 0	current_phase = 0	next_phase = 1	reward = -0.012336	array([[-1.3340396, -2.3124723]], dtype=float32)
time = 3645	action = 0	current_phase = 0	next_phase = 1	reward = -0.011325	array([[-1.1052701, -2.6691835]], dtype=float32)
time = 3650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
time = 3925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4371042, -2.6039178]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.1059 - val_loss: 1.8242
Epoch 2/50
 - 1s - loss: 0.0906 - val_loss: 1.8346
Epoch 3/50
 - 1s - loss: 0.1008 - val_loss: 1.8497
Epoch 4/50
 - 1s - loss: 0.0891 - val_loss: 1.8727
Epoch 5/50
 - 1s - loss: 0.0946 - val_loss: 1.8958
Epoch 6/50
 - 1s - loss: 0.0801 - val_loss: 1.7949
Epoch 7/50
 - 1s - loss: 0.0872 - val_loss: 1.8685
Epoch 8/50
 - 1s - loss: 0.0887 - val_loss: 1.8164
Epoch 9/50
 - 1s - loss: 0.0786 - val_loss: 1.8541
Epoch 10/50
 - 1s - loss: 0.0814 - val_loss: 1.8229
Epoch 11/50
 - 1s - loss: 0.0795 - val_loss: 1.9182
Epoch 12/50
 - 1s - loss: 0.0699 - val_loss: 1.8228
Epoch 13/50
 - 1s - loss: 0.0799 - val_loss: 1.8457
Epoch 14/50
 - 1s - loss: 0.0747 - val_loss: 1.8968
Epoch 15/50
 - 1s - loss: 0.0797 - val_loss: 1.8189
Epoch 16/50
 - 1s - loss: 0.0802 - val_loss: 1.8601
length of memory (state 0, action 0): 864, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 3930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 3995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
time = 4225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9393077, -2.5408297]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.9099 - val_loss: 0.0560
Epoch 2/50
 - 1s - loss: 0.9032 - val_loss: 0.0578
Epoch 3/50
 - 1s - loss: 0.9500 - val_loss: 0.0586
Epoch 4/50
 - 1s - loss: 0.8846 - val_loss: 0.0558
Epoch 5/50
 - 1s - loss: 0.8868 - val_loss: 0.0551
Epoch 6/50
 - 1s - loss: 0.9041 - val_loss: 0.0597
Epoch 7/50
 - 1s - loss: 0.8741 - val_loss: 0.0642
Epoch 8/50
 - 1s - loss: 0.8651 - val_loss: 0.0613
Epoch 9/50
 - 1s - loss: 0.8569 - val_loss: 0.0634
Epoch 10/50
 - 1s - loss: 0.8747 - val_loss: 0.0631
Epoch 11/50
 - 1s - loss: 0.8770 - val_loss: 0.0664
Epoch 12/50
 - 1s - loss: 0.8624 - val_loss: 0.0681
Epoch 13/50
 - 1s - loss: 0.8451 - val_loss: 0.0670
Epoch 14/50
 - 1s - loss: 0.8455 - val_loss: 0.0682
Epoch 15/50
 - 1s - loss: 0.8429 - val_loss: 0.0710
length of memory (state 0, action 0): 924, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 4230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
time = 4525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.9095414, -2.5124907]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.1628 - val_loss: 1.7045
Epoch 2/50
 - 1s - loss: 0.1668 - val_loss: 1.7490
Epoch 3/50
 - 1s - loss: 0.1576 - val_loss: 1.7241
Epoch 4/50
 - 1s - loss: 0.1462 - val_loss: 1.7560
Epoch 5/50
 - 1s - loss: 0.1457 - val_loss: 1.7224
Epoch 6/50
 - 1s - loss: 0.1422 - val_loss: 1.7184
Epoch 7/50
 - 1s - loss: 0.1474 - val_loss: 1.7385
Epoch 8/50
 - 1s - loss: 0.1353 - val_loss: 1.7415
Epoch 9/50
 - 1s - loss: 0.1462 - val_loss: 1.9130
Epoch 10/50
 - 1s - loss: 0.1385 - val_loss: 1.7813
Epoch 11/50
 - 1s - loss: 0.1341 - val_loss: 1.8009
length of memory (state 0, action 0): 984, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 4530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
time = 4825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97507  , -2.4884543]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.9649 - val_loss: 0.0856
Epoch 2/50
 - 1s - loss: 0.8802 - val_loss: 0.0880
Epoch 3/50
 - 1s - loss: 0.8885 - val_loss: 0.0766
Epoch 4/50
 - 1s - loss: 0.8667 - val_loss: 0.0785
Epoch 5/50
 - 1s - loss: 0.8826 - val_loss: 0.0816
Epoch 6/50
 - 1s - loss: 0.8341 - val_loss: 0.0810
Epoch 7/50
 - 1s - loss: 0.8527 - val_loss: 0.0802
Epoch 8/50
 - 1s - loss: 0.8405 - val_loss: 0.0814
Epoch 9/50
 - 1s - loss: 0.8307 - val_loss: 0.0874
Epoch 10/50
 - 1s - loss: 0.8920 - val_loss: 0.0876
Epoch 11/50
 - 1s - loss: 0.8176 - val_loss: 0.0843
Epoch 12/50
 - 1s - loss: 0.8073 - val_loss: 0.0848
Epoch 13/50
 - 1s - loss: 0.8003 - val_loss: 0.0840
length of memory (state 0, action 0): 1044, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 4830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 4995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
time = 5125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8146627, -2.4503756]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.1680 - val_loss: 1.7500
Epoch 2/50
 - 1s - loss: 0.1579 - val_loss: 1.7811
Epoch 3/50
 - 1s - loss: 0.1590 - val_loss: 1.8034
Epoch 4/50
 - 1s - loss: 0.1529 - val_loss: 1.8650
Epoch 5/50
 - 1s - loss: 0.1551 - val_loss: 1.8514
Epoch 6/50
 - 1s - loss: 0.1470 - val_loss: 1.8671
Epoch 7/50
 - 1s - loss: 0.1490 - val_loss: 1.8435
Epoch 8/50
 - 1s - loss: 0.1366 - val_loss: 1.8344
Epoch 9/50
 - 1s - loss: 0.1430 - val_loss: 1.8548
Epoch 10/50
 - 1s - loss: 0.1408 - val_loss: 1.8779
Epoch 11/50
 - 1s - loss: 0.1417 - val_loss: 1.9253
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 5130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
time = 5425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.770283 , -2.4727907]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.1616 - val_loss: 1.8926
Epoch 2/50
 - 1s - loss: 0.1607 - val_loss: 1.8717
Epoch 3/50
 - 1s - loss: 0.1550 - val_loss: 1.8860
Epoch 4/50
 - 1s - loss: 0.1548 - val_loss: 1.8777
Epoch 5/50
 - 1s - loss: 0.1437 - val_loss: 1.8930
Epoch 6/50
 - 1s - loss: 0.1377 - val_loss: 1.8960
Epoch 7/50
 - 1s - loss: 0.1382 - val_loss: 1.8830
Epoch 8/50
 - 1s - loss: 0.1358 - val_loss: 1.8993
Epoch 9/50
 - 1s - loss: 0.1344 - val_loss: 1.9321
Epoch 10/50
 - 1s - loss: 0.1400 - val_loss: 1.9397
Epoch 11/50
 - 1s - loss: 0.1321 - val_loss: 1.9078
Epoch 12/50
 - 1s - loss: 0.1391 - val_loss: 1.9412
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 5430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
time = 5725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69885993, -2.4511786 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.1332 - val_loss: 2.0150
Epoch 2/50
 - 1s - loss: 0.1200 - val_loss: 1.9958
Epoch 3/50
 - 1s - loss: 0.1219 - val_loss: 1.9259
Epoch 4/50
 - 1s - loss: 0.1257 - val_loss: 1.9547
Epoch 5/50
 - 1s - loss: 0.1065 - val_loss: 1.9574
Epoch 6/50
 - 1s - loss: 0.1022 - val_loss: 1.9834
Epoch 7/50
 - 1s - loss: 0.1033 - val_loss: 1.9594
Epoch 8/50
 - 1s - loss: 0.1096 - val_loss: 1.9760
Epoch 9/50
 - 1s - loss: 0.1046 - val_loss: 1.9697
Epoch 10/50
 - 1s - loss: 0.1039 - val_loss: 1.9687
Epoch 11/50
 - 1s - loss: 0.0954 - val_loss: 1.9587
Epoch 12/50
 - 1s - loss: 0.0983 - val_loss: 2.0450
Epoch 13/50
 - 1s - loss: 0.1067 - val_loss: 1.9683
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 5730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 5995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 6000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 6005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 6010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 6015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 6020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
time = 6025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8081055, -2.4354692]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.1366 - val_loss: 1.9396
Epoch 2/50
 - 1s - loss: 0.1213 - val_loss: 1.9338
Epoch 3/50
 - 1s - loss: 0.1177 - val_loss: 1.9356
Epoch 4/50
 - 1s - loss: 0.1086 - val_loss: 1.9330
Epoch 5/50
 - 1s - loss: 0.1090 - val_loss: 1.9489
Epoch 6/50
 - 1s - loss: 0.0966 - val_loss: 1.9395
Epoch 7/50
 - 1s - loss: 0.0974 - val_loss: 1.9448
Epoch 8/50
 - 1s - loss: 0.0933 - val_loss: 1.9437
Epoch 9/50
 - 1s - loss: 0.1057 - val_loss: 1.9483
Epoch 10/50
 - 1s - loss: 0.0910 - val_loss: 1.9390
Epoch 11/50
 - 1s - loss: 0.0894 - val_loss: 1.9471
Epoch 12/50
 - 1s - loss: 0.0915 - val_loss: 1.9556
Epoch 13/50
 - 1s - loss: 0.1217 - val_loss: 1.9517
Epoch 14/50
 - 1s - loss: 0.0798 - val_loss: 1.9588
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 6030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
time = 6325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8616463, -2.4292545]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.1171 - val_loss: 0.1652
Epoch 2/50
 - 1s - loss: 0.1160 - val_loss: 0.1651
Epoch 3/50
 - 1s - loss: 0.1104 - val_loss: 0.1620
Epoch 4/50
 - 1s - loss: 0.1004 - val_loss: 0.1663
Epoch 5/50
 - 1s - loss: 0.1004 - val_loss: 0.1678
Epoch 6/50
 - 1s - loss: 0.1130 - val_loss: 0.1706
Epoch 7/50
 - 1s - loss: 0.0930 - val_loss: 0.1597
Epoch 8/50
 - 1s - loss: 0.0932 - val_loss: 0.1645
Epoch 9/50
 - 1s - loss: 0.0880 - val_loss: 0.1625
Epoch 10/50
 - 1s - loss: 0.0887 - val_loss: 0.1667
Epoch 11/50
 - 1s - loss: 0.0929 - val_loss: 0.1645
Epoch 12/50
 - 1s - loss: 0.0866 - val_loss: 0.1699
Epoch 13/50
 - 1s - loss: 0.0904 - val_loss: 0.1677
Epoch 14/50
 - 1s - loss: 0.0843 - val_loss: 0.1647
Epoch 15/50
 - 1s - loss: 0.0763 - val_loss: 0.1683
Epoch 16/50
 - 1s - loss: 0.0787 - val_loss: 0.1742
Epoch 17/50
 - 1s - loss: 0.0817 - val_loss: 0.1725
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 6330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
time = 6625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70824444, -2.47423   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.1379 - val_loss: 1.9489
Epoch 2/50
 - 1s - loss: 0.1313 - val_loss: 1.9508
Epoch 3/50
 - 1s - loss: 0.1192 - val_loss: 1.9701
Epoch 4/50
 - 1s - loss: 0.1123 - val_loss: 1.9644
Epoch 5/50
 - 1s - loss: 0.1147 - val_loss: 1.9537
Epoch 6/50
 - 1s - loss: 0.1123 - val_loss: 1.9507
Epoch 7/50
 - 1s - loss: 0.1080 - val_loss: 1.9484
Epoch 8/50
 - 1s - loss: 0.1132 - val_loss: 1.9620
Epoch 9/50
 - 1s - loss: 0.0935 - val_loss: 1.9666
Epoch 10/50
 - 1s - loss: 0.0993 - val_loss: 1.9626
Epoch 11/50
 - 1s - loss: 0.1133 - val_loss: 1.9656
Epoch 12/50
 - 1s - loss: 0.0984 - val_loss: 1.9671
Epoch 13/50
 - 1s - loss: 0.0831 - val_loss: 1.9717
Epoch 14/50
 - 1s - loss: 0.0889 - val_loss: 1.9710
Epoch 15/50
 - 1s - loss: 0.0850 - val_loss: 1.9557
Epoch 16/50
 - 1s - loss: 0.0947 - val_loss: 1.9739
Epoch 17/50
 - 1s - loss: 0.0961 - val_loss: 1.9574
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 6630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
time = 6925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6340153, -2.4597037]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.9221 - val_loss: 0.0640
Epoch 2/50
 - 1s - loss: 0.9189 - val_loss: 0.0607
Epoch 3/50
 - 1s - loss: 0.9063 - val_loss: 0.0664
Epoch 4/50
 - 1s - loss: 0.8867 - val_loss: 0.0746
Epoch 5/50
 - 1s - loss: 0.8852 - val_loss: 0.0745
Epoch 6/50
 - 1s - loss: 0.8621 - val_loss: 0.0734
Epoch 7/50
 - 1s - loss: 0.8636 - val_loss: 0.0952
Epoch 8/50
 - 1s - loss: 0.8564 - val_loss: 0.0815
Epoch 9/50
 - 1s - loss: 0.8350 - val_loss: 0.0880
Epoch 10/50
 - 1s - loss: 0.8320 - val_loss: 0.0884
Epoch 11/50
 - 1s - loss: 0.8377 - val_loss: 0.0835
Epoch 12/50
 - 1s - loss: 0.8337 - val_loss: 0.0684
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 6930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 6995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
time = 7225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6922929, -2.4724097]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.1013 - val_loss: 1.6900
Epoch 2/50
 - 1s - loss: 0.0943 - val_loss: 1.7011
Epoch 3/50
 - 1s - loss: 0.0878 - val_loss: 1.7032
Epoch 4/50
 - 1s - loss: 0.0849 - val_loss: 1.6976
Epoch 5/50
 - 1s - loss: 0.0836 - val_loss: 1.7072
Epoch 6/50
 - 1s - loss: 0.0788 - val_loss: 1.6998
Epoch 7/50
 - 1s - loss: 0.0796 - val_loss: 1.7013
Epoch 8/50
 - 1s - loss: 0.0759 - val_loss: 1.7151
Epoch 9/50
 - 1s - loss: 0.0763 - val_loss: 1.7184
Epoch 10/50
 - 1s - loss: 0.0724 - val_loss: 1.7287
Epoch 11/50
 - 1s - loss: 0.0724 - val_loss: 1.7626
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 7230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
time = 7525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.72461987, -2.4609222 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.8126 - val_loss: 0.1713
Epoch 2/50
 - 1s - loss: 0.8334 - val_loss: 0.1478
Epoch 3/50
 - 1s - loss: 0.8058 - val_loss: 0.1576
Epoch 4/50
 - 1s - loss: 0.7876 - val_loss: 0.1605
Epoch 5/50
 - 1s - loss: 0.8279 - val_loss: 0.1741
Epoch 6/50
 - 1s - loss: 0.7803 - val_loss: 0.1914
Epoch 7/50
 - 1s - loss: 0.7580 - val_loss: 0.2156
Epoch 8/50
 - 1s - loss: 0.7843 - val_loss: 0.1824
Epoch 9/50
 - 1s - loss: 0.7504 - val_loss: 0.2133
Epoch 10/50
 - 1s - loss: 0.7459 - val_loss: 0.1958
Epoch 11/50
 - 1s - loss: 0.7569 - val_loss: 0.1635
Epoch 12/50
 - 1s - loss: 0.7452 - val_loss: 0.1853
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 7530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
time = 7825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.63458216, -2.441435  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.7881 - val_loss: 0.0879
Epoch 2/50
 - 1s - loss: 0.7674 - val_loss: 0.0951
Epoch 3/50
 - 1s - loss: 0.8018 - val_loss: 0.0895
Epoch 4/50
 - 1s - loss: 0.7716 - val_loss: 0.0969
Epoch 5/50
 - 1s - loss: 0.7646 - val_loss: 0.1291
Epoch 6/50
 - 1s - loss: 0.7638 - val_loss: 0.0859
Epoch 7/50
 - 1s - loss: 0.7396 - val_loss: 0.1115
Epoch 8/50
 - 1s - loss: 0.7571 - val_loss: 0.0905
Epoch 9/50
 - 1s - loss: 0.7393 - val_loss: 0.0843
Epoch 10/50
 - 1s - loss: 0.7265 - val_loss: 0.1248
Epoch 11/50
 - 1s - loss: 0.7460 - val_loss: 0.0944
Epoch 12/50
 - 1s - loss: 0.7272 - val_loss: 0.1095
Epoch 13/50
 - 1s - loss: 0.7177 - val_loss: 0.1106
Epoch 14/50
 - 1s - loss: 0.7216 - val_loss: 0.0989
Epoch 15/50
 - 1s - loss: 0.7267 - val_loss: 0.1057
Epoch 16/50
 - 1s - loss: 0.7216 - val_loss: 0.1181
Epoch 17/50
 - 1s - loss: 0.7072 - val_loss: 0.1115
Epoch 18/50
 - 1s - loss: 0.7045 - val_loss: 0.1188
Epoch 19/50
 - 1s - loss: 0.6967 - val_loss: 0.1198
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 7830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 7995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
time = 8125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5074984, -2.420902 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.7401 - val_loss: 0.0433
Epoch 2/50
 - 1s - loss: 0.7414 - val_loss: 0.0450
Epoch 3/50
 - 1s - loss: 0.7389 - val_loss: 0.0452
Epoch 4/50
 - 1s - loss: 0.7644 - val_loss: 0.0461
Epoch 5/50
 - 1s - loss: 0.7316 - val_loss: 0.0496
Epoch 6/50
 - 1s - loss: 0.7118 - val_loss: 0.0485
Epoch 7/50
 - 1s - loss: 0.7160 - val_loss: 0.0451
Epoch 8/50
 - 1s - loss: 0.7100 - val_loss: 0.0473
Epoch 9/50
 - 1s - loss: 0.7113 - val_loss: 0.0488
Epoch 10/50
 - 1s - loss: 0.6970 - val_loss: 0.0531
Epoch 11/50
 - 1s - loss: 0.7130 - val_loss: 0.0529
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 8130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
time = 8425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5591221, -2.4190006]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.0994 - val_loss: 1.4273
Epoch 2/50
 - 1s - loss: 0.0885 - val_loss: 1.4361
Epoch 3/50
 - 1s - loss: 0.0857 - val_loss: 1.4372
Epoch 4/50
 - 1s - loss: 0.0875 - val_loss: 1.4386
Epoch 5/50
 - 1s - loss: 0.0842 - val_loss: 1.4375
Epoch 6/50
 - 1s - loss: 0.0819 - val_loss: 1.4317
Epoch 7/50
 - 1s - loss: 0.0757 - val_loss: 1.4425
Epoch 8/50
 - 1s - loss: 0.0745 - val_loss: 1.4398
Epoch 9/50
 - 1s - loss: 0.0695 - val_loss: 1.4470
Epoch 10/50
 - 1s - loss: 0.0757 - val_loss: 1.4503
Epoch 11/50
 - 1s - loss: 0.0759 - val_loss: 1.4548
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 8430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
time = 8725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5331495, -2.4032698]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.0761 - val_loss: 1.4425
Epoch 2/50
 - 1s - loss: 0.0780 - val_loss: 1.4484
Epoch 3/50
 - 1s - loss: 0.0708 - val_loss: 1.4538
Epoch 4/50
 - 1s - loss: 0.0722 - val_loss: 1.4527
Epoch 5/50
 - 1s - loss: 0.0728 - val_loss: 1.4516
Epoch 6/50
 - 1s - loss: 0.0681 - val_loss: 1.4588
Epoch 7/50
 - 1s - loss: 0.0680 - val_loss: 1.4580
Epoch 8/50
 - 1s - loss: 0.0624 - val_loss: 1.4671
Epoch 9/50
 - 1s - loss: 0.0706 - val_loss: 1.4677
Epoch 10/50
 - 1s - loss: 0.0631 - val_loss: 1.4714
Epoch 11/50
 - 1s - loss: 0.0658 - val_loss: 1.4772
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 8730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 8995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 9000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 9005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 9010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 9015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 9020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
time = 9025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.4866346, -2.412861 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.7180 - val_loss: 0.0347
Epoch 2/50
 - 1s - loss: 0.7110 - val_loss: 0.0378
Epoch 3/50
 - 1s - loss: 0.7034 - val_loss: 0.0383
Epoch 4/50
 - 1s - loss: 0.7068 - val_loss: 0.0439
Epoch 5/50
 - 1s - loss: 0.6916 - val_loss: 0.0386
Epoch 6/50
 - 1s - loss: 0.6870 - val_loss: 0.0431
Epoch 7/50
 - 1s - loss: 0.6835 - val_loss: 0.0427
Epoch 8/50
 - 1s - loss: 0.6799 - val_loss: 0.0416
Epoch 9/50
 - 1s - loss: 0.6866 - val_loss: 0.0411
Epoch 10/50
 - 1s - loss: 0.6768 - val_loss: 0.0444
Epoch 11/50
 - 1s - loss: 0.6849 - val_loss: 0.0504
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 9030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
time = 9325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.5199449, -2.3998415]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.6814 - val_loss: 0.0744
Epoch 2/50
 - 1s - loss: 0.6853 - val_loss: 0.0705
Epoch 3/50
 - 1s - loss: 0.6685 - val_loss: 0.0722
Epoch 4/50
 - 1s - loss: 0.6646 - val_loss: 0.0721
Epoch 5/50
 - 1s - loss: 0.6667 - val_loss: 0.0680
Epoch 6/50
 - 1s - loss: 0.6566 - val_loss: 0.0691
Epoch 7/50
 - 1s - loss: 0.6518 - val_loss: 0.0735
Epoch 8/50
 - 1s - loss: 0.6447 - val_loss: 0.0779
Epoch 9/50
 - 1s - loss: 0.6474 - val_loss: 0.0817
Epoch 10/50
 - 1s - loss: 0.6398 - val_loss: 0.0731
Epoch 11/50
 - 1s - loss: 0.6473 - val_loss: 0.0631
Epoch 12/50
 - 1s - loss: 0.6361 - val_loss: 0.0745
Epoch 13/50
 - 1s - loss: 0.6369 - val_loss: 0.0721
Epoch 14/50
 - 1s - loss: 0.6263 - val_loss: 0.0620
Epoch 15/50
 - 1s - loss: 0.6295 - val_loss: 0.0715
Epoch 16/50
 - 1s - loss: 0.6279 - val_loss: 0.0694
Epoch 17/50
 - 1s - loss: 0.6297 - val_loss: 0.0704
Epoch 18/50
 - 1s - loss: 0.6148 - val_loss: 0.0684
Epoch 19/50
 - 1s - loss: 0.6149 - val_loss: 0.0649
Epoch 20/50
 - 1s - loss: 0.6119 - val_loss: 0.0655
Epoch 21/50
 - 1s - loss: 0.6128 - val_loss: 0.0780
Epoch 22/50
 - 1s - loss: 0.6019 - val_loss: 0.0696
Epoch 23/50
 - 1s - loss: 0.6086 - val_loss: 0.0710
Epoch 24/50
 - 1s - loss: 0.6082 - val_loss: 0.0704
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 9330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
time = 9625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.46175468, -2.417521  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.6194 - val_loss: 0.0339
Epoch 2/50
 - 1s - loss: 0.6101 - val_loss: 0.0369
Epoch 3/50
 - 1s - loss: 0.6051 - val_loss: 0.0362
Epoch 4/50
 - 1s - loss: 0.6013 - val_loss: 0.0357
Epoch 5/50
 - 1s - loss: 0.5949 - val_loss: 0.0399
Epoch 6/50
 - 1s - loss: 0.5925 - val_loss: 0.0370
Epoch 7/50
 - 1s - loss: 0.5898 - val_loss: 0.0371
Epoch 8/50
 - 1s - loss: 0.5946 - val_loss: 0.0389
Epoch 9/50
 - 1s - loss: 0.5919 - val_loss: 0.0390
Epoch 10/50
 - 1s - loss: 0.5894 - val_loss: 0.0391
Epoch 11/50
 - 1s - loss: 0.5828 - val_loss: 0.0388
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 9630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
time = 9925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.41358995, -2.3987079 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.5936 - val_loss: 0.0298
Epoch 2/50
 - 1s - loss: 0.5944 - val_loss: 0.0401
Epoch 3/50
 - 1s - loss: 0.5985 - val_loss: 0.0425
Epoch 4/50
 - 1s - loss: 0.5788 - val_loss: 0.0379
Epoch 5/50
 - 1s - loss: 0.5791 - val_loss: 0.0345
Epoch 6/50
 - 1s - loss: 0.5729 - val_loss: 0.0376
Epoch 7/50
 - 1s - loss: 0.5710 - val_loss: 0.0361
Epoch 8/50
 - 1s - loss: 0.5713 - val_loss: 0.0404
Epoch 9/50
 - 1s - loss: 0.5707 - val_loss: 0.0438
Epoch 10/50
 - 1s - loss: 0.5617 - val_loss: 0.0409
Epoch 11/50
 - 1s - loss: 0.5560 - val_loss: 0.0422
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 9930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 9995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
time = 10225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.39117324, -2.3764215 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.5808 - val_loss: 0.0358
Epoch 2/50
 - 1s - loss: 0.5655 - val_loss: 0.0371
Epoch 3/50
 - 1s - loss: 0.5686 - val_loss: 0.0376
Epoch 4/50
 - 1s - loss: 0.5594 - val_loss: 0.0413
Epoch 5/50
 - 1s - loss: 0.5647 - val_loss: 0.0404
Epoch 6/50
 - 1s - loss: 0.5515 - val_loss: 0.0457
Epoch 7/50
 - 1s - loss: 0.5517 - val_loss: 0.0478
Epoch 8/50
 - 1s - loss: 0.5509 - val_loss: 0.0452
Epoch 9/50
 - 1s - loss: 0.5451 - val_loss: 0.0479
Epoch 10/50
 - 1s - loss: 0.5452 - val_loss: 0.0486
Epoch 11/50
 - 1s - loss: 0.5427 - val_loss: 0.0489
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 10230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
time = 10525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.364138 , -2.3583071]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.5522 - val_loss: 0.0489
Epoch 2/50
 - 1s - loss: 0.5502 - val_loss: 0.0553
Epoch 3/50
 - 1s - loss: 0.5381 - val_loss: 0.0533
Epoch 4/50
 - 1s - loss: 0.5407 - val_loss: 0.0495
Epoch 5/50
 - 1s - loss: 0.5370 - val_loss: 0.0501
Epoch 6/50
 - 1s - loss: 0.5283 - val_loss: 0.0496
Epoch 7/50
 - 1s - loss: 0.5351 - val_loss: 0.0640
Epoch 8/50
 - 1s - loss: 0.5309 - val_loss: 0.0669
Epoch 9/50
 - 1s - loss: 0.5250 - val_loss: 0.0587
Epoch 10/50
 - 1s - loss: 0.5133 - val_loss: 0.0724
Epoch 11/50
 - 1s - loss: 0.5202 - val_loss: 0.0702
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 10530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
time = 10825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.40860558, -2.354045  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.6081 - val_loss: 0.0489
Epoch 2/50
 - 1s - loss: 0.5927 - val_loss: 0.0450
Epoch 3/50
 - 1s - loss: 0.5842 - val_loss: 0.0460
Epoch 4/50
 - 1s - loss: 0.5857 - val_loss: 0.0448
Epoch 5/50
 - 1s - loss: 0.5789 - val_loss: 0.0483
Epoch 6/50
 - 1s - loss: 0.5789 - val_loss: 0.0496
Epoch 7/50
 - 1s - loss: 0.5648 - val_loss: 0.0481
Epoch 8/50
 - 1s - loss: 0.5732 - val_loss: 0.0466
Epoch 9/50
 - 1s - loss: 0.5653 - val_loss: 0.0546
Epoch 10/50
 - 1s - loss: 0.5586 - val_loss: 0.0515
Epoch 11/50
 - 1s - loss: 0.5631 - val_loss: 0.0481
Epoch 12/50
 - 1s - loss: 0.5543 - val_loss: 0.0487
Epoch 13/50
 - 1s - loss: 0.5500 - val_loss: 0.0473
Epoch 14/50
 - 1s - loss: 0.5555 - val_loss: 0.0477
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 10830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 10995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
time = 11125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.33208525, -2.3186145 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.5292 - val_loss: 0.0742
Epoch 2/50
 - 1s - loss: 0.5326 - val_loss: 0.0750
Epoch 3/50
 - 1s - loss: 0.5215 - val_loss: 0.0686
Epoch 4/50
 - 1s - loss: 0.5232 - val_loss: 0.0660
Epoch 5/50
 - 1s - loss: 0.5180 - val_loss: 0.0595
Epoch 6/50
 - 1s - loss: 0.5128 - val_loss: 0.0617
Epoch 7/50
 - 1s - loss: 0.5102 - val_loss: 0.0633
Epoch 8/50
 - 1s - loss: 0.5067 - val_loss: 0.0694
Epoch 9/50
 - 1s - loss: 0.5080 - val_loss: 0.0648
Epoch 10/50
 - 1s - loss: 0.5024 - val_loss: 0.0725
Epoch 11/50
 - 1s - loss: 0.5000 - val_loss: 0.0621
Epoch 12/50
 - 1s - loss: 0.4976 - val_loss: 0.0681
Epoch 13/50
 - 1s - loss: 0.5036 - val_loss: 0.0630
Epoch 14/50
 - 1s - loss: 0.4926 - val_loss: 0.0624
Epoch 15/50
 - 1s - loss: 0.4961 - val_loss: 0.0600
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 11130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
time = 11425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30913246, -2.3356576 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.0822 - val_loss: 0.0346
Epoch 2/50
 - 1s - loss: 0.0849 - val_loss: 0.0358
Epoch 3/50
 - 1s - loss: 0.0649 - val_loss: 0.0394
Epoch 4/50
 - 1s - loss: 0.0845 - val_loss: 0.0366
Epoch 5/50
 - 1s - loss: 0.0764 - val_loss: 0.0390
Epoch 6/50
 - 1s - loss: 0.0709 - val_loss: 0.0388
Epoch 7/50
 - 1s - loss: 0.0684 - val_loss: 0.0431
Epoch 8/50
 - 1s - loss: 0.0648 - val_loss: 0.0418
Epoch 9/50
 - 1s - loss: 0.0734 - val_loss: 0.0441
Epoch 10/50
 - 1s - loss: 0.0613 - val_loss: 0.0443
Epoch 11/50
 - 1s - loss: 0.0646 - val_loss: 0.0435
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 11430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
time = 11725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.2907287, -2.3547685]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.0743 - val_loss: 1.1161
Epoch 2/50
 - 1s - loss: 0.0732 - val_loss: 1.1227
Epoch 3/50
 - 1s - loss: 0.0756 - val_loss: 1.1271
Epoch 4/50
 - 1s - loss: 0.0636 - val_loss: 1.1310
Epoch 5/50
 - 1s - loss: 0.0782 - val_loss: 1.1319
Epoch 6/50
 - 1s - loss: 0.0652 - val_loss: 1.1411
Epoch 7/50
 - 1s - loss: 0.0850 - val_loss: 1.1403
Epoch 8/50
 - 1s - loss: 0.0724 - val_loss: 1.1452
Epoch 9/50
 - 1s - loss: 0.0644 - val_loss: 1.1534
Epoch 10/50
 - 1s - loss: 0.0667 - val_loss: 1.1707
Epoch 11/50
 - 1s - loss: 0.0565 - val_loss: 1.1808
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 11730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 11995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 12000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 12005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 12010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 12015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 12020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
time = 12025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.3582151, -2.3475394]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.5804 - val_loss: 0.0411
Epoch 2/50
 - 1s - loss: 0.5523 - val_loss: 0.0413
Epoch 3/50
 - 1s - loss: 0.5416 - val_loss: 0.0450
Epoch 4/50
 - 1s - loss: 0.5281 - val_loss: 0.0420
Epoch 5/50
 - 1s - loss: 0.5360 - val_loss: 0.0425
Epoch 6/50
 - 1s - loss: 0.5214 - val_loss: 0.0468
Epoch 7/50
 - 1s - loss: 0.5236 - val_loss: 0.0445
Epoch 8/50
 - 1s - loss: 0.5105 - val_loss: 0.0475
Epoch 9/50
 - 1s - loss: 0.5107 - val_loss: 0.0482
Epoch 10/50
 - 1s - loss: 0.5270 - val_loss: 0.0452
Epoch 11/50
 - 1s - loss: 0.5034 - val_loss: 0.0484
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 12030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
time = 12325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.31708097, -2.3095393 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.0894 - val_loss: 0.0495
Epoch 2/50
 - 1s - loss: 0.0871 - val_loss: 0.0554
Epoch 3/50
 - 1s - loss: 0.0709 - val_loss: 0.0574
Epoch 4/50
 - 1s - loss: 0.0744 - val_loss: 0.0549
Epoch 5/50
 - 1s - loss: 0.0633 - val_loss: 0.0515
Epoch 6/50
 - 1s - loss: 0.0718 - val_loss: 0.0570
Epoch 7/50
 - 1s - loss: 0.0671 - val_loss: 0.0562
Epoch 8/50
 - 1s - loss: 0.0666 - val_loss: 0.0584
Epoch 9/50
 - 1s - loss: 0.0687 - val_loss: 0.0596
Epoch 10/50
 - 1s - loss: 0.0700 - val_loss: 0.0614
Epoch 11/50
 - 1s - loss: 0.0692 - val_loss: 0.0635
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 12330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
time = 12625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.199942, -2.270784]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.0760 - val_loss: 0.0503
Epoch 2/50
 - 1s - loss: 0.0850 - val_loss: 0.0579
Epoch 3/50
 - 1s - loss: 0.0791 - val_loss: 0.0575
Epoch 4/50
 - 1s - loss: 0.0680 - val_loss: 0.0618
Epoch 5/50
 - 1s - loss: 0.0754 - val_loss: 0.0614
Epoch 6/50
 - 1s - loss: 0.0693 - val_loss: 0.0659
Epoch 7/50
 - 1s - loss: 0.0703 - val_loss: 0.0622
Epoch 8/50
 - 1s - loss: 0.0760 - val_loss: 0.0683
Epoch 9/50
 - 1s - loss: 0.0671 - val_loss: 0.0620
Epoch 10/50
 - 1s - loss: 0.0673 - val_loss: 0.0618
Epoch 11/50
 - 1s - loss: 0.0720 - val_loss: 0.0596
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 12630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
time = 12925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23944294, -2.2574344 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.0970 - val_loss: 1.1119
Epoch 2/50
 - 1s - loss: 0.0821 - val_loss: 1.1146
Epoch 3/50
 - 1s - loss: 0.0784 - val_loss: 1.1243
Epoch 4/50
 - 1s - loss: 0.0754 - val_loss: 1.1293
Epoch 5/50
 - 1s - loss: 0.0747 - val_loss: 1.1333
Epoch 6/50
 - 1s - loss: 0.0703 - val_loss: 1.1350
Epoch 7/50
 - 1s - loss: 0.0740 - val_loss: 1.1414
Epoch 8/50
 - 1s - loss: 0.0669 - val_loss: 1.1430
Epoch 9/50
 - 1s - loss: 0.0699 - val_loss: 1.1420
Epoch 10/50
 - 1s - loss: 0.0782 - val_loss: 1.1426
Epoch 11/50
 - 1s - loss: 0.0700 - val_loss: 1.1392
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 12930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 12995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
time = 13225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.30501926, -2.2732682 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.0906 - val_loss: 0.0412
Epoch 2/50
 - 1s - loss: 0.0884 - val_loss: 0.0447
Epoch 3/50
 - 1s - loss: 0.0780 - val_loss: 0.0452
Epoch 4/50
 - 1s - loss: 0.0854 - val_loss: 0.0411
Epoch 5/50
 - 1s - loss: 0.0797 - val_loss: 0.0463
Epoch 6/50
 - 1s - loss: 0.0860 - val_loss: 0.0433
Epoch 7/50
 - 1s - loss: 0.0817 - val_loss: 0.0405
Epoch 8/50
 - 1s - loss: 0.0747 - val_loss: 0.0399
Epoch 9/50
 - 1s - loss: 0.0710 - val_loss: 0.0457
Epoch 10/50
 - 1s - loss: 0.0737 - val_loss: 0.0447
Epoch 11/50
 - 1s - loss: 0.0708 - val_loss: 0.0469
Epoch 12/50
 - 1s - loss: 0.0633 - val_loss: 0.0471
Epoch 13/50
 - 1s - loss: 0.0704 - val_loss: 0.0466
Epoch 14/50
 - 1s - loss: 0.0705 - val_loss: 0.0466
Epoch 15/50
 - 1s - loss: 0.0646 - val_loss: 0.0509
Epoch 16/50
 - 1s - loss: 0.0689 - val_loss: 0.0501
Epoch 17/50
 - 1s - loss: 0.0693 - val_loss: 0.0498
Epoch 18/50
 - 1s - loss: 0.0607 - val_loss: 0.0511
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 13230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
time = 13525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23598278, -2.2459629 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.5858 - val_loss: 0.1167
Epoch 2/50
 - 1s - loss: 0.5783 - val_loss: 0.1128
Epoch 3/50
 - 1s - loss: 0.5523 - val_loss: 0.1145
Epoch 4/50
 - 1s - loss: 0.5432 - val_loss: 0.1224
Epoch 5/50
 - 1s - loss: 0.5369 - val_loss: 0.1170
Epoch 6/50
 - 1s - loss: 0.5265 - val_loss: 0.1111
Epoch 7/50
 - 1s - loss: 0.5297 - val_loss: 0.1187
Epoch 8/50
 - 1s - loss: 0.5102 - val_loss: 0.1125
Epoch 9/50
 - 1s - loss: 0.5167 - val_loss: 0.1135
Epoch 10/50
 - 1s - loss: 0.5014 - val_loss: 0.1140
Epoch 11/50
 - 1s - loss: 0.4887 - val_loss: 0.1280
Epoch 12/50
 - 1s - loss: 0.4899 - val_loss: 0.1186
Epoch 13/50
 - 1s - loss: 0.4953 - val_loss: 0.1213
Epoch 14/50
 - 1s - loss: 0.4911 - val_loss: 0.1208
Epoch 15/50
 - 1s - loss: 0.4874 - val_loss: 0.1229
Epoch 16/50
 - 1s - loss: 0.4779 - val_loss: 0.1243
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 13530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
time = 13825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.24967074, -2.281743  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.5078 - val_loss: 0.1219
Epoch 2/50
 - 1s - loss: 0.4943 - val_loss: 0.1191
Epoch 3/50
 - 1s - loss: 0.5019 - val_loss: 0.1283
Epoch 4/50
 - 1s - loss: 0.4880 - val_loss: 0.1291
Epoch 5/50
 - 1s - loss: 0.4937 - val_loss: 0.1284
Epoch 6/50
 - 1s - loss: 0.4824 - val_loss: 0.1255
Epoch 7/50
 - 1s - loss: 0.4780 - val_loss: 0.1217
Epoch 8/50
 - 1s - loss: 0.4705 - val_loss: 0.1250
Epoch 9/50
 - 1s - loss: 0.4748 - val_loss: 0.1292
Epoch 10/50
 - 1s - loss: 0.4676 - val_loss: 0.1230
Epoch 11/50
 - 1s - loss: 0.4727 - val_loss: 0.1261
Epoch 12/50
 - 1s - loss: 0.4763 - val_loss: 0.1302
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 13830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 13995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14000	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14005	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14010	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14015	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14020	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14025	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14030	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14035	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14040	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14045	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14050	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14055	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14060	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14065	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14070	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14075	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14080	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14085	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14090	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14095	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14100	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14105	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14110	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14115	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14120	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
time = 14125	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.21604645, -2.2750778 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.5151 - val_loss: 0.0401
Epoch 2/50
 - 1s - loss: 0.5140 - val_loss: 0.0454
Epoch 3/50
 - 1s - loss: 0.4979 - val_loss: 0.0494
Epoch 4/50
 - 1s - loss: 0.5015 - val_loss: 0.0442
Epoch 5/50
 - 1s - loss: 0.4954 - val_loss: 0.0433
Epoch 6/50
 - 1s - loss: 0.4968 - val_loss: 0.0514
Epoch 7/50
 - 1s - loss: 0.4890 - val_loss: 0.0521
Epoch 8/50
 - 1s - loss: 0.4862 - val_loss: 0.0491
Epoch 9/50
 - 1s - loss: 0.4848 - val_loss: 0.0521
Epoch 10/50
 - 1s - loss: 0.4821 - val_loss: 0.0562
Epoch 11/50
 - 1s - loss: 0.4715 - val_loss: 0.0543
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 14130	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14135	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14140	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14145	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14150	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14155	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14160	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14165	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14170	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14175	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14180	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14185	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14190	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14195	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14200	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14205	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14210	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14215	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14220	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14225	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14230	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14235	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14240	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14245	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14250	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14255	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14260	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14265	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14270	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14275	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14280	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14285	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14290	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14295	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14300	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14305	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14310	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14315	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14320	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14325	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14330	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14335	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14340	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14345	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14350	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14355	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14360	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14365	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14370	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14375	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14380	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14385	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14390	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14395	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14400	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14405	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14410	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14415	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14420	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
time = 14425	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.14780593, -2.273042  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.4600 - val_loss: 0.0338
Epoch 2/50
 - 1s - loss: 0.4651 - val_loss: 0.0339
Epoch 3/50
 - 1s - loss: 0.4553 - val_loss: 0.0349
Epoch 4/50
 - 1s - loss: 0.4446 - val_loss: 0.0334
Epoch 5/50
 - 1s - loss: 0.4462 - val_loss: 0.0352
Epoch 6/50
 - 1s - loss: 0.4491 - val_loss: 0.0361
Epoch 7/50
 - 1s - loss: 0.4470 - val_loss: 0.0365
Epoch 8/50
 - 1s - loss: 0.4370 - val_loss: 0.0392
Epoch 9/50
 - 1s - loss: 0.4361 - val_loss: 0.0378
Epoch 10/50
 - 1s - loss: 0.4405 - val_loss: 0.0359
Epoch 11/50
 - 1s - loss: 0.4309 - val_loss: 0.0393
Epoch 12/50
 - 1s - loss: 0.4231 - val_loss: 0.0435
Epoch 13/50
 - 1s - loss: 0.4302 - val_loss: 0.0362
Epoch 14/50
 - 1s - loss: 0.4159 - val_loss: 0.0388
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 14430	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14435	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14440	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14445	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14450	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14455	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14460	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14465	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14470	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14475	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14480	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14485	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14490	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14495	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14500	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14505	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14510	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14515	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14520	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14525	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14530	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14535	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14540	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14545	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14550	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14555	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14560	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14565	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14570	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14575	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14580	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14585	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14590	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14595	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14600	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14605	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14610	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14615	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14620	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14625	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14630	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14635	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14640	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14645	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14650	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14655	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14660	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14665	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14670	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14675	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14680	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14685	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14690	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14695	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14700	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14705	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14710	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14715	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14720	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
time = 14725	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.23095107, -2.2578807 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 0.4483 - val_loss: 0.0970
Epoch 2/50
 - 1s - loss: 0.4362 - val_loss: 0.0966
Epoch 3/50
 - 1s - loss: 0.4342 - val_loss: 0.0979
Epoch 4/50
 - 1s - loss: 0.4347 - val_loss: 0.1018
Epoch 5/50
 - 1s - loss: 0.4305 - val_loss: 0.1052
Epoch 6/50
 - 1s - loss: 0.4250 - val_loss: 0.0973
Epoch 7/50
 - 1s - loss: 0.4237 - val_loss: 0.1003
Epoch 8/50
 - 1s - loss: 0.4115 - val_loss: 0.1119
Epoch 9/50
 - 1s - loss: 0.4253 - val_loss: 0.1070
Epoch 10/50
 - 1s - loss: 0.4212 - val_loss: 0.1107
Epoch 11/50
 - 1s - loss: 0.4032 - val_loss: 0.1100
Epoch 12/50
 - 1s - loss: 0.4135 - val_loss: 0.1099
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 353, after forget
length of memory (state 1, action 0): 755, after forget
length of memory (state 1, action 1): 341, after forget
time = 14730	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14735	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14740	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14745	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14750	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14755	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14760	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14765	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14770	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14775	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14780	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14785	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14790	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14795	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14800	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14805	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14810	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14815	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14820	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14825	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14830	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14835	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14840	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14845	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14850	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14855	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14860	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14865	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14870	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14875	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14880	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14885	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14890	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14895	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14900	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14905	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14910	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14915	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14920	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14925	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14930	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14935	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14940	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14945	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14950	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14955	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14960	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14965	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14970	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14975	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14980	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14985	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14990	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
time = 14995	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.1504662, -2.2293768]], dtype=float32)
END
finished ['osm.passenger.trips.xml']
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_map_feature (InputLayer)  (None, 150, 150, 1)  0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 38, 38, 32)   2048        input_map_feature[0][0]          
__________________________________________________________________________________________________
bn1 (BatchNormalization)        (None, 38, 38, 32)   96          conv1[0][0]                      
__________________________________________________________________________________________________
act1 (Activation)               (None, 38, 38, 32)   0           bn1[0][0]                        
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 19, 19, 32)   0           act1[0][0]                       Loading configuration... done.
***Starting server on port 33151 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00

__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 19, 32)   0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2 (Conv2D)                  (None, 10, 10, 16)   8192        dropout_3[0][0]                  
__________________________________________________________________________________________________
bn2 (BatchNormalization)        (None, 10, 10, 16)   48          conv2[0][0]                      
__________________________________________________________________________________________________
act2 (Activation)               (None, 10, 10, 16)   0           bn2[0][0]                        
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 16)     0           act2[0][0]                       
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 5, 5, 16)     0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
input_cur_phase (InputLayer)    (None, 1)            0                                            
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 400)          0           dropout_4[0][0]                  
__________________________________________________________________________________________________
input_next_phase (InputLayer)   (None, 1)            0                                            
__________________________________________________________________________________________________
input_num_of_vehicles (InputLay (None, 8)            0                                            
__________________________________________________________________________________________________
input_queue_length (InputLayer) (None, 8)            0                                            
__________________________________________________________________________________________________
input_waiting_time (InputLayer) (None, 8)            0                                            
__________________________________________________________________________________________________
all_flatten_feature (Concatenat (None, 426)          0           input_cur_phase[0][0]            
                                                                 flatten_2[0][0]                  
                                                                 input_next_phase[0][0]           
                                                                 input_num_of_vehicles[0][0]      
                                                                 input_queue_length[0][0]         
                                                                 input_waiting_time[0][0]         
__________________________________________________________________________________________________
hidden_shared_1 (Dense)         (None, 20)           8540        all_flatten_feature[0][0]        
__________________________________________________________________________________________________
hidden_separate_branch_0_1 (Den (None, 20)           420         hidden_shared_1[0][0]            
__________________________________________________________________________________________________
hidden_separate_branch_1_1 (Den (None, 20)           420         hidden_shared_1[0][0]            
__________________________________________________________________________________________________
q_values_separate_branch_0 (Den (None, 2)            42          hidden_separate_branch_0_1[0][0] 
__________________________________________________________________________________________________
selector_0 (Selector)           (None, 1)            0           input_cur_phase[0][0]            
__________________________________________________________________________________________________
q_values_separate_branch_1 (Den (None, 2)            42          hidden_separate_branch_1_1[0][0] 
__________________________________________________________________________________________________
selector_1 (Selector)           (None, 1)            0           input_cur_phase[0][0]            
__________________________________________________________________________________________________
multiply_0 (Multiply)           (None, 2)            0           q_values_separate_branch_0[0][0] 
                                                                 selector_0[0][0]                 
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 2)            0           q_values_separate_branch_1[0][0] 
                                                                 selector_1[0][0]                 
__________________________________________________________________________________________________
add_2 (Add)                     (None, 2)            0           multiply_0[0][0]                 
                                                                 multiply_1[0][0]                 
==================================================================================================
Total params: 19,848
Trainable params: 19,752
Non-trainable params: 96
__________________________________________________________________________________________________
Could not connect to TraCI server at localhost:33151 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.336063	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -1.884166	array([[-0.22438538,  0.11550364]], dtype=float32)
time = 43	action = 1	current_phase = 1	next_phase = 0	reward = -2.922076	array([[-0.23697639,  0.13485163]], dtype=float32)
time = 51	action = 0	current_phase = 0	next_phase = 1	reward = -0.126828	array([[-0.06359074, -0.23422998]], dtype=float32)
time = 56	action = 1	current_phase = 0	next_phase = 1	reward = -2.229408	array([[-0.08590339, -0.2503055 ]], dtype=float32)
time = 64	action = 0	current_phase = 1	next_phase = 0	reward = -1.309694	array([[-0.22501409,  0.18691678]], dtype=float32)
time = 69	action = 1	current_phase = 1	next_phase = 0	reward = -2.502815	array([[-0.24977984,  0.19648959]], dtype=float32)
time = 77	action = 0	current_phase = 0	next_phase = 1	reward = -1.480125	array([[-0.07289121, -0.24936232]], dtype=float32)
time = 82	action = 1	current_phase = 0	next_phase = 1	reward = -4.100848	array([[-0.08139531, -0.24422073]], dtype=float32)
time = 90	action = 0	current_phase = 1	next_phase = 0	reward = -2.200634	array([[-0.21799125,  0.21099024]], dtype=float32)
time = 95	action = 1	current_phase = 1	next_phase = 0	reward = -4.327315	array([[-0.23912168,  0.1922943 ]], dtype=float32)
time = 103	action = 0	current_phase = 0	next_phase = 1	reward = -1.331625	array([[-0.08344871, -0.24570736]], dtype=float32)
time = 108	action = 1	current_phase = 0	next_phase = 1	reward = -5.436361	array([[-0.08101435, -0.25146985]], dtype=float32)
time = 116	action = 0	current_phase = 1	next_phase = 0	reward = -3.670757	array([[-0.206054 ,  0.1904374]], dtype=float32)
time = 121	action = 1	current_phase = 1	next_phase = 0	reward = -6.375201	array([[-0.23377633,  0.19252455]], dtype=float32)
time = 129	action = 0	current_phase = 0	next_phase = 1	reward = -1.561670	array([[-0.09203526, -0.2356483 ]], dtype=float32)
time = 134	action = 1	current_phase = 0	next_phase = 1	reward = -5.917200	array([[-0.0948161 , -0.24573568]], dtype=float32)
time = 142	action = 0	current_phase = 1	next_phase = 0	reward = -2.866776	array([[-0.20238124,  0.17215918]], dtype=float32)
time = 147	action = 1	current_phase = 1	next_phase = 0	reward = -7.315578	array([[-0.23690297,  0.20454293]], dtype=float32)
time = 155	action = 0	current_phase = 0	next_phase = 1	reward = -1.906941	array([[-0.1080804 , -0.23167616]], dtype=float32)
time = 160	action = 1	current_phase = 0	next_phase = 1	reward = -4.816964	array([[-0.09370732, -0.25175342]], dtype=float32)
time = 168	action = 0	current_phase = 1	next_phase = 0	reward = -4.068229	array([[-0.21819222,  0.21225631]], dtype=float32)
time = 173	action = 1	current_phase = 1	next_phase = 0	reward = -7.413022	array([[-0.23566765,  0.20584062]], dtype=float32)
time = 181	action = 0	current_phase = 0	next_phase = 1	reward = -2.074386	array([[-0.09652615, -0.23020448]], dtype=float32)
time = 186	action = 1	current_phase = 0	next_phase = 1	reward = -5.039368	array([[-0.08167934, -0.25382707]], dtype=float32)
time = 194	action = 0	current_phase = 1	next_phase = 0	reward = -2.912522	array([[-0.20597821,  0.18196976]], dtype=float32)
time = 199	action = 1	current_phase = 1	next_phase = 0	reward = -8.451896	array([[-0.22970448,  0.1769418 ]], dtype=float32)
time = 207	action = 0	current_phase = 0	next_phase = 1	reward = -3.166228	array([[-0.09555832, -0.22489603]], dtype=float32)
time = 212	action = 1	current_phase = 0	next_phase = 1	reward = -5.884539	array([[-0.0878161, -0.236245 ]], dtype=float32)
time = 220	action = 0	current_phase = 1	next_phase = 0	reward = -2.934648	array([[-0.20395064,  0.17081295]], dtype=float32)
time = 225	action = 1	current_phase = 1	next_phase = 0	reward = -8.113004	array([[-0.23542838,  0.18707545]], dtype=float32)
time = 233	action = 0	current_phase = 0	next_phase = 1	reward = -3.098362	array([[-0.10309756, -0.23503454]], dtype=float32)
time = 238	action = 1	current_phase = 0	next_phase = 1	reward = -6.767111	array([[-0.09076936, -0.24632202]], dtype=float32)
time = 246	action = 0	current_phase = 1	next_phase = 0	reward = -2.620055	array([[-0.211353  ,  0.16029434]], dtype=float32)
time = 251	action = 1	current_phase = 1	next_phase = 0	reward = -7.557754	array([[-0.22221324,  0.14884661]], dtype=float32)
time = 259	action = 0	current_phase = 0	next_phase = 1	reward = -3.220803	array([[-0.09048519, -0.2289522 ]], dtype=float32)
time = 264	action = 1	current_phase = 0	next_phase = 1	reward = -8.280308	array([[-0.08914351, -0.23257731]], dtype=float32)
time = 272	action = 0	current_phase = 1	next_phase = 0	reward = -3.650550	array([[-0.20967245,  0.15552457]], dtype=float32)
time = 277	action = 1	current_phase = 1	next_phase = 0	reward = -7.980720	array([[-0.21487066,  0.171601  ]], dtype=float32)
time = 285	action = 0	current_phase = 0	next_phase = 1	reward = -3.546133	array([[-0.10536343, -0.22666827]], dtype=float32)
time = 290	action = 1	current_phase = 0	next_phase = 1	reward = -7.188612	array([[-0.10709749, -0.23509608]], dtype=float32)
time = 298	action = 0	current_phase = 1	next_phase = 0	reward = -2.937395	array([[-0.20505852,  0.1769342 ]], dtype=float32)
time = 303	action = 1	current_phase = 1	next_phase = 0	reward = -8.256403	array([[-0.22272211,  0.17617041]], dtype=float32)
time = 311	action = 0	current_phase = 0	next_phase = 1	reward = -3.401349	array([[-0.10150443, -0.22302233]], dtype=float32)
time = 316	action = 1	current_phase = 0	next_phase = 1	reward = -7.070257	array([[-0.08741242, -0.2335257 ]], dtype=float32)
time = 324	action = 0	current_phase = 1	next_phase = 0	reward = -3.583652	array([[-0.20439008,  0.17609799]], dtype=float32)
time = 329	action = 1	current_phase = 1	next_phase = 0	reward = -9.231774	array([[-0.21656911,  0.17322755]], dtype=float32)
time = 337	action = 0	current_phase = 0	next_phase = 1	reward = -3.936001	array([[-0.10830794, -0.21645755]], dtype=float32)
time = 342	action = 1	current_phase = 0	next_phase = 1	reward = -7.545930	array([[-0.09849095, -0.22232847]], dtype=float32)
time = 350	action = 0	current_phase = 1	next_phase = 0	reward = -3.442200	array([[-0.21025066,  0.16835089]], dtype=float32)
time = 355	action = 1	current_phase = 1	next_phase = 0	reward = -7.938136	array([[-0.21799985,  0.17174307]], dtype=float32)
time = 363	action = 0	current_phase = 0	next_phase = 1	reward = -2.969501	array([[-0.1072697 , -0.22951028]], dtype=float32)
time = 368	action = 1	current_phase = 0	next_phase = 1	reward = -6.720776	array([[-0.10215135, -0.23391041]], dtype=float32)
time = 376	action = 0	current_phase = 1	next_phase = 0	reward = -2.603156	array([[-0.21548069,  0.16708757]], dtype=float32)
time = 381	action = 1	current_phase = 1	next_phase = 0	reward = -8.216159	array([[-0.2234055 ,  0.16831341]], dtype=float32)
time = 389	action = 0	current_phase = 0	next_phase = 1	reward = -2.921261	array([[-0.08187806, -0.22732386]], dtype=float32)
time = 394	action = 1	current_phase = 0	next_phase = 1	reward = -7.510978	array([[-0.08090106, -0.23933691]], dtype=float32)
time = 402	action = 0	current_phase = 1	next_phase = 0	reward = -2.976246	array([[-0.1976788,  0.1572163]], dtype=float32)
time = 407	action = 1	current_phase = 1	next_phase = 0	reward = -8.306599	array([[-0.21791472,  0.16085613]], dtype=float32)
time = 415	action = 0	current_phase = 0	next_phase = 1	reward = -3.392482	array([[-0.08491232, -0.22322631]], dtype=float32)
time = 420	action = 1	current_phase = 0	next_phase = 1	reward = -8.332797	array([[-0.08116189, -0.23101617]], dtype=float32)
time = 428	action = 0	current_phase = 1	next_phase = 0	reward = -3.569254	array([[-0.20210445,  0.1394582 ]], dtype=float32)
time = 433	action = 1	current_phase = 1	next_phase = 0	reward = -8.629103	array([[-0.20927168,  0.15602964]], dtype=float32)
time = 441	action = 0	current_phase = 0	next_phase = 1	reward = -4.011765	array([[-0.08878359, -0.22556505]], dtype=float32)
time = 446	action = 1	current_phase = 0	next_phase = 1	reward = -8.456607	array([[-0.08647224, -0.23802766]], dtype=float32)
time = 454	action = 0	current_phase = 1	next_phase = 0	reward = -2.595089	array([[-0.19090258,  0.11905295]], dtype=float32)
time = 459	action = 1	current_phase = 1	next_phase = 0	reward = -8.381316	array([[-0.21096702,  0.13126251]], dtype=float32)
time = 467	action = 0	current_phase = 0	next_phase = 1	reward = -4.444887	array([[-0.10796582, -0.21965007]], dtype=float32)
time = 472	action = 1	current_phase = 0	next_phase = 1	reward = -8.909875	array([[-0.10759652, -0.22614418]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -2.445705	array([[-0.19217654,  0.13191617]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -8.761894	array([[-0.21288608,  0.14922355]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -4.340255	array([[-0.09936073, -0.21396272]], dtype=float32)
time = 498	action = 1	current_phase = 0	next_phase = 1	reward = -8.254216	array([[-0.10979386, -0.22696087]], dtype=float32)
time = 506	action = 0	current_phase = 1	next_phase = 0	reward = -2.823738	array([[-0.19208969,  0.12645836]], dtype=float32)
time = 511	action = 1	current_phase = 1	next_phase = 0	reward = -8.147444	array([[-0.20923018,  0.1349434 ]], dtype=float32)
time = 519	action = 0	current_phase = 0	next_phase = 1	reward = -4.106941	array([[-0.11567829, -0.214414  ]], dtype=float32)
time = 524	action = 1	current_phase = 0	next_phase = 1	reward = -9.241726	array([[-0.10941164, -0.21313453]], dtype=float32)
time = 532	action = 0	current_phase = 1	next_phase = 0	reward = -3.463901	array([[-0.18689033,  0.12076704]], dtype=float32)
time = 537	action = 1	current_phase = 1	next_phase = 0	reward = -6.691399	array([[-0.20423469,  0.11881836]], dtype=float32)
time = 545	action = 0	current_phase = 0	next_phase = 1	reward = -3.894258	array([[-0.10937913, -0.21466555]], dtype=float32)
time = 550	action = 1	current_phase = 0	next_phase = 1	reward = -9.177903	array([[-0.10363046, -0.21796048]], dtype=float32)
time = 558	action = 0	current_phase = 1	next_phase = 0	reward = -3.380390	array([[-0.1884269,  0.1126551]], dtype=float32)
time = 563	action = 1	current_phase = 1	next_phase = 0	reward = -7.754123	array([[-0.20184205,  0.12390174]], dtype=float32)
time = 571	action = 0	current_phase = 0	next_phase = 1	reward = -3.958662	array([[-0.12717892, -0.22078496]], dtype=float32)Simulation ended at time: 676.00
Reason: TraCI requested termination.
Performance: 
 Duration: 5317ms
 Real time factor: 127.139
 UPS: 6640.398721
Vehicles: 
 Inserted: 485 (Loaded: 621)
 Running: 66
 Waiting: 36

DijkstraRouter answered 9141 queries and explored 4.55 edges on average.
DijkstraRouter spent 1ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 55875 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00

time = 576	action = 1	current_phase = 0	next_phase = 1	reward = -9.715273	array([[-0.13215122, -0.22746451]], dtype=float32)
time = 584	action = 0	current_phase = 1	next_phase = 0	reward = -3.246092	array([[-0.19683476,  0.12148387]], dtype=float32)
time = 589	action = 1	current_phase = 1	next_phase = 0	reward = -8.095774	array([[-0.20535381,  0.13215828]], dtype=float32)
time = 597	action = 0	current_phase = 0	next_phase = 1	reward = -5.124383	array([[-0.092055  , -0.21726958]], dtype=float32)
time = 602	action = 1	current_phase = 0	next_phase = 1	reward = -10.209069	array([[-0.10022177, -0.22470264]], dtype=float32)
time = 610	action = 0	current_phase = 1	next_phase = 0	reward = -4.012329	array([[-0.19926208,  0.13057321]], dtype=float32)
time = 615	action = 1	current_phase = 1	next_phase = 0	reward = -8.962543	array([[-0.2098168 ,  0.14394322]], dtype=float32)
time = 623	action = 0	current_phase = 0	next_phase = 1	reward = -4.569516	array([[-0.09732489, -0.21283603]], dtype=float32)
time = 628	action = 1	current_phase = 0	next_phase = 1	reward = -9.305959	array([[-0.09506854, -0.22044931]], dtype=float32)
time = 636	action = 0	current_phase = 1	next_phase = 0	reward = -3.476309	array([[-0.18841675,  0.1224661 ]], dtype=float32)
time = 641	action = 1	current_phase = 1	next_phase = 0	reward = -8.056262	array([[-0.20910941,  0.14623223]], dtype=float32)
time = 649	action = 0	current_phase = 0	next_phase = 1	reward = -4.314132	array([[-0.09785143, -0.2123847 ]], dtype=float32)
time = 654	action = 1	current_phase = 0	next_phase = 1	reward = -9.264642	array([[-0.09906191, -0.21980539]], dtype=float32)
time = 662	action = 0	current_phase = 1	next_phase = 0	reward = -3.004232	array([[-0.18198101,  0.11133739]], dtype=float32)
time = 667	action = 1	current_phase = 1	next_phase = 0	reward = -8.138733	array([[-0.20879088,  0.13654076]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:55875 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.648799	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -3.443467	array([[-0.07127401, -0.21530016]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.397133	array([[-0.22899093,  0.12794566]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.485030	array([[-0.23924538,  0.13859034]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.787994	array([[-0.08837196, -0.24981888]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.105068	array([[-0.0935736 , -0.25531462]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -3.662260	array([[-0.09054594, -0.25683618]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.618947	array([[-0.23436472,  0.22569035]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.281534	array([[-0.2486836 ,  0.20813984]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.520022	array([[-0.08276151, -0.24945939]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.412985	array([[-0.0868831 , -0.25298306]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -5.729375	array([[-0.08480977, -0.23827419]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -2.675603	array([[-0.21504396,  0.19851229]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -4.320793	array([[-0.236591  ,  0.20014419]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.507798	array([[-0.08302766, -0.25198126]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -2.988321	array([[-0.09402837, -0.24844863]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -7.314942	array([[-0.09852901, -0.24498138]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -3.116038	array([[-0.21696639,  0.19681697]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -5.330153	array([[-0.22923772,  0.20873377]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.166665	array([[-0.08617443, -0.25777975]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -2.322516	array([[-0.08017835, -0.25523052]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -6.472468	array([[-0.08731028, -0.25095806]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -2.979857	array([[-0.22973028,  0.24593525]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -6.108391	array([[-0.2562908 ,  0.25080466]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.777946	array([[-0.07083935, -0.26520225]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -2.492057	array([[-0.08079219, -0.2679714 ]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -5.907302	array([[-0.08585358, -0.2682971 ]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -2.865343	array([[-0.22625202,  0.25324404]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -6.990331	array([[-0.23466259,  0.24118859]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -3.651109	array([[-0.07278712, -0.25969452]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -3.816021	array([[-0.09035839, -0.27453113]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -7.623868	array([[-0.08738041, -0.27173874]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.357707	array([[-0.22113931,  0.21601425]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -7.846670	array([[-0.23488936,  0.21445192]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -4.734584	array([[-0.06747937, -0.23617719]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -4.862575	array([[-0.0786974 , -0.24715172]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -8.724618	array([[-0.09659696, -0.25904122]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -4.060315	array([[-0.19273086,  0.18776739]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -7.912352	array([[-0.21398777,  0.19107652]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -3.817495	array([[-0.06562194, -0.23733096]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -3.596116	array([[-0.08096392, -0.24976785]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -8.236702	array([[-0.099685 , -0.2714746]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -3.518370	array([[-0.20083973,  0.20590386]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -7.704686	array([[-0.2164186 ,  0.20073378]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -3.646649	array([[-0.06191674, -0.2536767 ]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -4.639683	array([[-0.07754955, -0.2557158 ]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -8.077322	array([[-0.10008305, -0.26351583]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -3.282825	array([[-0.20941594,  0.22801961]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4904ms
 Real time factor: 136.419
 UPS: 7130.913540
Vehicles: 
 Inserted: 484 (Loaded: 621)
 Running: 65
 Waiting: 32

DijkstraRouter answered 6977 queries and explored 3.61 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 47207 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -7.814063	array([[-0.22254962,  0.220749  ]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -4.081079	array([[-0.06070013, -0.2462661 ]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -4.595258	array([[-0.08092307, -0.25642762]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -8.187654	array([[-0.08916368, -0.27186853]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -3.146024	array([[-0.2096425 ,  0.21201439]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -8.221366	array([[-0.22769222,  0.2186382 ]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -5.711027	array([[-0.05349712, -0.24757925]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -5.845092	array([[-0.07353333, -0.24904571]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -10.370924	array([[-0.09395543, -0.26649052]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -4.531204	array([[-0.19419752,  0.16496953]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -9.386912	array([[-0.20872872,  0.17960474]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -5.281579	array([[-0.05795176, -0.23389384]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -6.238206	array([[-0.06746179, -0.2452583 ]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -10.133871	array([[-0.08442284, -0.25061888]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -5.077072	array([[-0.18161154,  0.13657323]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -9.465836	array([[-0.19895537,  0.13047493]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -4.600289	array([[-0.05239135, -0.23075023]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -5.330732	array([[-0.06436603, -0.24310791]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -9.555213	array([[-0.08128381, -0.25229955]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -4.782035	array([[-0.17756483,  0.12900513]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -10.796568	array([[-0.19076246,  0.12387858]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -5.163405	array([[-0.05061728, -0.22730766]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -5.612789	array([[-0.06145476, -0.22583851]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -10.008966	array([[-0.08894631, -0.2444436 ]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -5.793893	array([[-0.17407048,  0.12332177]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -11.949578	array([[-0.1931665 ,  0.11839567]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -5.220946	array([[-0.05746886, -0.21419401]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -5.215650	array([[-0.06414476, -0.22634614]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -10.264929	array([[-0.08558328, -0.24625254]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -5.296734	array([[-0.17672464,  0.1359342 ]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -12.199840	array([[-0.19183694,  0.14530776]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -5.713774	array([[-0.06466492, -0.22271127]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -5.727217	array([[-0.07238765, -0.2253028 ]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -11.683191	array([[-0.08995593, -0.24039754]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -5.692745	array([[-0.16954067,  0.10377425]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -12.243524	array([[-0.18864816,  0.12049145]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -5.190860	array([[-0.06438133, -0.23153545]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -5.416530	array([[-0.06498754, -0.23550515]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -10.459119	array([[-0.08644766, -0.24596354]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -5.564791	array([[-0.18427071,  0.13469617]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -10.445549	array([[-0.20213851,  0.13585593]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -5.225610	array([[-0.05938469, -0.22991343]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -5.518591	array([[-0.06313244, -0.23714529]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -9.631320	array([[-0.08603136, -0.25570333]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -4.233980	array([[-0.18757491,  0.14391232]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -10.235490	array([[-0.20027916,  0.15135613]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -4.783046	array([[-0.05885485, -0.2439354 ]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = -5.819319	array([[-0.06837642, -0.24101292]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -10.320547	array([[-0.07970066, -0.25348756]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -5.072053	array([[-0.17419934,  0.14582251]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -9.700049	array([[-0.20048214,  0.13305548]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.985701	array([[-0.05682002, -0.23467676]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -6.371724	array([[-0.06515321, -0.23741092]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -9.988996	array([[-0.09256446, -0.25200224]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -4.052567	array([[-0.17927483,  0.12922552]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:47207 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.648799	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -3.443467	array([[-0.07127401, -0.21530016]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.397133	array([[-0.22899093,  0.12794566]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.485030	array([[-0.23924538,  0.13859034]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.787994	array([[-0.08837196, -0.24981888]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.105068	array([[-0.0935736 , -0.25531462]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -3.662260	array([[-0.09054594, -0.25683618]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.618947	array([[-0.23436472,  0.22569035]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.281534	array([[-0.2486836 ,  0.20813984]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.520022	array([[-0.08276151, -0.24945939]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.412985	array([[-0.0868831 , -0.25298306]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -5.729375	array([[-0.08480977, -0.23827419]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -2.675603	array([[-0.21504396,  0.19851229]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -4.320793	array([[-0.236591  ,  0.20014419]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.507798	array([[-0.08302766, -0.25198126]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -2.988321	array([[-0.09402837, -0.24844863]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -7.314942	array([[-0.09852901, -0.24498138]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -3.116038	array([[-0.21696639,  0.19681697]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -5.330153	array([[-0.22923772,  0.20873377]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.166665	array([[-0.08617443, -0.25777975]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -2.322516	array([[-0.08017835, -0.25523052]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -6.472468	array([[-0.08731028, -0.25095806]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -2.979857	array([[-0.22973028,  0.24593525]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -6.108391	array([[-0.2562908 ,  0.25080466]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.777946	array([[-0.07083935, -0.26520225]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -2.492057	array([[-0.08079219, -0.2679714 ]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -5.907302	array([[-0.08585358, -0.2682971 ]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -2.865343	array([[-0.22625202,  0.25324404]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -6.990331	array([[-0.23466259,  0.24118859]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -3.651109	array([[-0.07278712, -0.25969452]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -3.816021	array([[-0.09035839, -0.27453113]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -7.623868	array([[-0.08738041, -0.27173874]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.357707	array([[-0.22113931,  0.21601425]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -7.846670	array([[-0.23488936,  0.21445192]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -4.734584	array([[-0.06747937, -0.23617719]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -4.862575	array([[-0.0786974 , -0.24715172]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -8.724618	array([[-0.09659696, -0.25904122]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -4.060315	array([[-0.19273086,  0.18776739]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -7.912352	array([[-0.21398777,  0.19107652]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -3.817495	array([[-0.06562194, -0.23733096]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -3.596116	array([[-0.08096392, -0.24976785]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -8.236702	array([[-0.099685 , -0.2714746]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -3.518370	array([[-0.20083973,  0.20590386]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -7.704686	array([[-0.2164186 ,  0.20073378]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -3.646649	array([[-0.06191674, -0.2536767 ]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -4.639683	array([[-0.07754955, -0.2557158 ]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -8.077322	array([[-0.10008305, -0.26351583]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -3.282825	array([[-0.20941594,  0.22801961]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -7.814063	array([[-0.22254962,  0.220749  ]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -4.081079	array([[-0.06070013, -0.2462661 ]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -4.595258	array([[-0.08092307, -0.25642762]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -8.187654	array([[-0.08916368, -0.27186853]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -3.146024	array([[-0.2096425 ,  0.21201439]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -8.221366	array([[-0.22769222,  0.2186382 ]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -5.711027	array([[-0.05349712, -0.24757925]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -5.845092	array([[-0.07353333, -0.24904571]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -10.370924	array([[-0.09395543, -0.26649052]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -4.531204	array([[-0.19419752,  0.16496953]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -9.386912	array([[-0.20872872,  0.17960474]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -5.281579	array([[-0.05795176, -0.23389384]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -6.238206	array([[-0.06746179, -0.2452583 ]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -10.133871	array([[-0.08442284, -0.25061888]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -5.077072	array([[-0.18161154,  0.13657323]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -9.465836	array([[-0.19895537,  0.13047493]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -4.600289	array([[-0.05239135, -0.23075023]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -5.330732	array([[-0.06436603, -0.24310791]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -9.555213	array([[-0.08128381, -0.25229955]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -4.782035	array([[-0.17756483,  0.12900513]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -10.796568	array([[-0.19076246,  0.12387858]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -5.163405	array([[-0.05061728, -0.22730766]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -5.612789	array([[-0.06145476, -0.22583851]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -10.008966	array([[-0.08894631, -0.2444436 ]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -5.793893	array([[-0.17407048,  0.12332177]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -11.949578	array([[-0.1931665 ,  0.11839567]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4831ms
 Real time factor: 138.481
 UPS: 7238.666943
Vehicles: 
 Inserted: 484 (Loaded: 621)
 Running: 65
 Waiting: 32

DijkstraRouter answered 6977 queries and explored 3.61 edges on average.
DijkstraRouter spent 1ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 44569 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -5.220946	array([[-0.05746886, -0.21419401]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -5.215650	array([[-0.06414476, -0.22634614]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -10.264929	array([[-0.08558328, -0.24625254]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -5.296734	array([[-0.17672464,  0.1359342 ]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -12.199840	array([[-0.19183694,  0.14530776]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -5.713774	array([[-0.06466492, -0.22271127]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -5.727217	array([[-0.07238765, -0.2253028 ]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -11.683191	array([[-0.08995593, -0.24039754]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -5.692745	array([[-0.16954067,  0.10377425]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -12.243524	array([[-0.18864816,  0.12049145]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -5.190860	array([[-0.06438133, -0.23153545]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -5.416530	array([[-0.06498754, -0.23550515]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -10.459119	array([[-0.08644766, -0.24596354]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -5.564791	array([[-0.18427071,  0.13469617]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -10.445549	array([[-0.20213851,  0.13585593]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -5.225610	array([[-0.05938469, -0.22991343]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -5.518591	array([[-0.06313244, -0.23714529]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -9.631320	array([[-0.08603136, -0.25570333]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -4.233980	array([[-0.18757491,  0.14391232]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -10.235490	array([[-0.20027916,  0.15135613]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -4.783046	array([[-0.05885485, -0.2439354 ]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = -5.819319	array([[-0.06837642, -0.24101292]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -10.320547	array([[-0.07970066, -0.25348756]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -5.072053	array([[-0.17419934,  0.14582251]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -9.700049	array([[-0.20048214,  0.13305548]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.985701	array([[-0.05682002, -0.23467676]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -6.371724	array([[-0.06515321, -0.23741092]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -9.988996	array([[-0.09256446, -0.25200224]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -4.052567	array([[-0.17927483,  0.12922552]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:44569 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.648799	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -3.443467	array([[-0.07127401, -0.21530016]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.397133	array([[-0.22899093,  0.12794566]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.485030	array([[-0.23924538,  0.13859034]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.787994	array([[-0.08837196, -0.24981888]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.105068	array([[-0.0935736 , -0.25531462]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -3.662260	array([[-0.09054594, -0.25683618]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.618947	array([[-0.23436472,  0.22569035]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.281534	array([[-0.2486836 ,  0.20813984]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.520022	array([[-0.08276151, -0.24945939]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.412985	array([[-0.0868831 , -0.25298306]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -5.729375	array([[-0.08480977, -0.23827419]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -2.675603	array([[-0.21504396,  0.19851229]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -4.320793	array([[-0.236591  ,  0.20014419]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.507798	array([[-0.08302766, -0.25198126]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -2.988321	array([[-0.09402837, -0.24844863]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -7.314942	array([[-0.09852901, -0.24498138]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -3.116038	array([[-0.21696639,  0.19681697]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -5.330153	array([[-0.22923772,  0.20873377]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.166665	array([[-0.08617443, -0.25777975]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -2.322516	array([[-0.08017835, -0.25523052]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -6.472468	array([[-0.08731028, -0.25095806]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -2.979857	array([[-0.22973028,  0.24593525]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -6.108391	array([[-0.2562908 ,  0.25080466]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.777946	array([[-0.07083935, -0.26520225]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -2.492057	array([[-0.08079219, -0.2679714 ]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -5.907302	array([[-0.08585358, -0.2682971 ]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -2.865343	array([[-0.22625202,  0.25324404]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -6.990331	array([[-0.23466259,  0.24118859]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -3.651109	array([[-0.07278712, -0.25969452]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -3.816021	array([[-0.09035839, -0.27453113]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -7.623868	array([[-0.08738041, -0.27173874]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.357707	array([[-0.22113931,  0.21601425]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -7.846670	array([[-0.23488936,  0.21445192]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -4.734584	array([[-0.06747937, -0.23617719]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -4.862575	array([[-0.0786974 , -0.24715172]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -8.724618	array([[-0.09659696, -0.25904122]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -4.060315	array([[-0.19273086,  0.18776739]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -7.912352	array([[-0.21398777,  0.19107652]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -3.817495	array([[-0.06562194, -0.23733096]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -3.596116	array([[-0.08096392, -0.24976785]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -8.236702	array([[-0.099685 , -0.2714746]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -3.518370	array([[-0.20083973,  0.20590386]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -7.704686	array([[-0.2164186 ,  0.20073378]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -3.646649	array([[-0.06191674, -0.2536767 ]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -4.639683	array([[-0.07754955, -0.2557158 ]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -8.077322	array([[-0.10008305, -0.26351583]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -3.282825	array([[-0.20941594,  0.22801961]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -7.814063	array([[-0.22254962,  0.220749  ]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -4.081079	array([[-0.06070013, -0.2462661 ]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -4.595258	array([[-0.08092307, -0.25642762]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -8.187654	array([[-0.08916368, -0.27186853]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -3.146024	array([[-0.2096425 ,  0.21201439]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -8.221366	array([[-0.22769222,  0.2186382 ]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -5.711027	array([[-0.05349712, -0.24757925]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -5.845092	array([[-0.07353333, -0.24904571]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -10.370924	array([[-0.09395543, -0.26649052]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -4.531204	array([[-0.19419752,  0.16496953]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -9.386912	array([[-0.20872872,  0.17960474]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -5.281579	array([[-0.05795176, -0.23389384]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -6.238206	array([[-0.06746179, -0.2452583 ]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -10.133871	array([[-0.08442284, -0.25061888]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -5.077072	array([[-0.18161154,  0.13657323]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -9.465836	array([[-0.19895537,  0.13047493]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -4.600289	array([[-0.05239135, -0.23075023]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -5.330732	array([[-0.06436603, -0.24310791]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -9.555213	array([[-0.08128381, -0.25229955]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -4.782035	array([[-0.17756483,  0.12900513]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -10.796568	array([[-0.19076246,  0.12387858]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -5.163405	array([[-0.05061728, -0.22730766]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -5.612789	array([[-0.06145476, -0.22583851]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -10.008966	array([[-0.08894631, -0.2444436 ]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -5.793893	array([[-0.17407048,  0.12332177]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -11.949578	array([[-0.1931665 ,  0.11839567]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -5.220946	array([[-0.05746886, -0.21419401]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -5.215650	array([[-0.06414476, -0.22634614]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -10.264929	array([[-0.08558328, -0.24625254]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -5.296734	array([[-0.17672464,  0.1359342 ]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -12.199840	array([[-0.19183694,  0.14530776]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -5.713774	array([[-0.06466492, -0.22271127]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -5.727217	array([[-0.07238765, -0.2253028 ]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -11.683191	array([[-0.08995593, -0.24039754]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -5.692745	array([[-0.16954067,  0.10377425]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -12.243524	array([[-0.18864816,  0.12049145]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -5.190860	array([[-0.06438133, -0.23153545]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -5.416530	array([[-0.06498754, -0.23550515]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -10.459119	array([[-0.08644766, -0.24596354]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -5.564791	array([[-0.18427071,  0.13469617]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -10.445549	array([[-0.20213851,  0.13585593]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -5.225610	array([[-0.05938469, -0.22991343]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -5.518591	array([[-0.06313244, -0.23714529]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -9.631320	array([[-0.08603136, -0.25570333]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -4.233980	array([[-0.18757491,  0.14391232]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -10.235490	array([[-0.20027916,  0.15135613]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -4.783046	array([[-0.05885485, -0.2439354 ]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = -5.819319	array([[-0.06837642, -0.24101292]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -10.320547	array([[-0.07970066, -0.25348756]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -5.072053	array([[-0.17419934,  0.14582251]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -9.700049	array([[-0.20048214,  0.13305548]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.985701	array([[-0.05682002, -0.23467676]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4858ms
 Real time factor: 137.711
 UPS: 7198.435570
Vehicles: 
 Inserted: 484 (Loaded: 621)
 Running: 65
 Waiting: 32

DijkstraRouter answered 6977 queries and explored 3.61 edges on average.
DijkstraRouter spent 2ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 50013 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -6.371724	array([[-0.06515321, -0.23741092]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -9.988996	array([[-0.09256446, -0.25200224]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -4.052567	array([[-0.17927483,  0.12922552]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:50013 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.648799	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -3.443467	array([[-0.07127401, -0.21530016]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.397133	array([[-0.22899093,  0.12794566]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.485030	array([[-0.23924538,  0.13859034]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.787994	array([[-0.08837196, -0.24981888]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.105068	array([[-0.0935736 , -0.25531462]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -3.662260	array([[-0.09054594, -0.25683618]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.618947	array([[-0.23436472,  0.22569035]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.281534	array([[-0.2486836 ,  0.20813984]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.520022	array([[-0.08276151, -0.24945939]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.412985	array([[-0.0868831 , -0.25298306]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -5.729375	array([[-0.08480977, -0.23827419]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -2.675603	array([[-0.21504396,  0.19851229]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -4.320793	array([[-0.236591  ,  0.20014419]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.507798	array([[-0.08302766, -0.25198126]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -2.988321	array([[-0.09402837, -0.24844863]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -7.314942	array([[-0.09852901, -0.24498138]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -3.116038	array([[-0.21696639,  0.19681697]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -5.330153	array([[-0.22923772,  0.20873377]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.166665	array([[-0.08617443, -0.25777975]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -2.322516	array([[-0.08017835, -0.25523052]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -6.472468	array([[-0.08731028, -0.25095806]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -2.979857	array([[-0.22973028,  0.24593525]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -6.108391	array([[-0.2562908 ,  0.25080466]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.777946	array([[-0.07083935, -0.26520225]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -2.492057	array([[-0.08079219, -0.2679714 ]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -5.907302	array([[-0.08585358, -0.2682971 ]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -2.865343	array([[-0.22625202,  0.25324404]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -6.990331	array([[-0.23466259,  0.24118859]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -3.651109	array([[-0.07278712, -0.25969452]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -3.816021	array([[-0.09035839, -0.27453113]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -7.623868	array([[-0.08738041, -0.27173874]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.357707	array([[-0.22113931,  0.21601425]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -7.846670	array([[-0.23488936,  0.21445192]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -4.734584	array([[-0.06747937, -0.23617719]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -4.862575	array([[-0.0786974 , -0.24715172]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -8.724618	array([[-0.09659696, -0.25904122]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -4.060315	array([[-0.19273086,  0.18776739]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -7.912352	array([[-0.21398777,  0.19107652]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -3.817495	array([[-0.06562194, -0.23733096]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -3.596116	array([[-0.08096392, -0.24976785]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -8.236702	array([[-0.099685 , -0.2714746]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -3.518370	array([[-0.20083973,  0.20590386]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -7.704686	array([[-0.2164186 ,  0.20073378]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -3.646649	array([[-0.06191674, -0.2536767 ]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -4.639683	array([[-0.07754955, -0.2557158 ]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -8.077322	array([[-0.10008305, -0.26351583]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -3.282825	array([[-0.20941594,  0.22801961]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -7.814063	array([[-0.22254962,  0.220749  ]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -4.081079	array([[-0.06070013, -0.2462661 ]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -4.595258	array([[-0.08092307, -0.25642762]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -8.187654	array([[-0.08916368, -0.27186853]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -3.146024	array([[-0.2096425 ,  0.21201439]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -8.221366	array([[-0.22769222,  0.2186382 ]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -5.711027	array([[-0.05349712, -0.24757925]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -5.845092	array([[-0.07353333, -0.24904571]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -10.370924	array([[-0.09395543, -0.26649052]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -4.531204	array([[-0.19419752,  0.16496953]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -9.386912	array([[-0.20872872,  0.17960474]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -5.281579	array([[-0.05795176, -0.23389384]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4824ms
 Real time factor: 138.682
 UPS: 7249.170813
Vehicles: 
 Inserted: 484 (Loaded: 621)
 Running: 65
 Waiting: 32

DijkstraRouter answered 6977 queries and explored 3.61 edges on average.
DijkstraRouter spent 1ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 53541 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -6.238206	array([[-0.06746179, -0.2452583 ]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -10.133871	array([[-0.08442284, -0.25061888]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -5.077072	array([[-0.18161154,  0.13657323]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -9.465836	array([[-0.19895537,  0.13047493]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -4.600289	array([[-0.05239135, -0.23075023]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -5.330732	array([[-0.06436603, -0.24310791]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -9.555213	array([[-0.08128381, -0.25229955]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -4.782035	array([[-0.17756483,  0.12900513]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -10.796568	array([[-0.19076246,  0.12387858]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -5.163405	array([[-0.05061728, -0.22730766]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -5.612789	array([[-0.06145476, -0.22583851]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -10.008966	array([[-0.08894631, -0.2444436 ]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -5.793893	array([[-0.17407048,  0.12332177]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -11.949578	array([[-0.1931665 ,  0.11839567]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -5.220946	array([[-0.05746886, -0.21419401]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -5.215650	array([[-0.06414476, -0.22634614]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -10.264929	array([[-0.08558328, -0.24625254]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -5.296734	array([[-0.17672464,  0.1359342 ]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -12.199840	array([[-0.19183694,  0.14530776]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -5.713774	array([[-0.06466492, -0.22271127]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -5.727217	array([[-0.07238765, -0.2253028 ]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -11.683191	array([[-0.08995593, -0.24039754]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -5.692745	array([[-0.16954067,  0.10377425]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -12.243524	array([[-0.18864816,  0.12049145]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -5.190860	array([[-0.06438133, -0.23153545]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -5.416530	array([[-0.06498754, -0.23550515]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -10.459119	array([[-0.08644766, -0.24596354]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -5.564791	array([[-0.18427071,  0.13469617]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -10.445549	array([[-0.20213851,  0.13585593]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -5.225610	array([[-0.05938469, -0.22991343]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -5.518591	array([[-0.06313244, -0.23714529]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -9.631320	array([[-0.08603136, -0.25570333]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -4.233980	array([[-0.18757491,  0.14391232]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -10.235490	array([[-0.20027916,  0.15135613]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -4.783046	array([[-0.05885485, -0.2439354 ]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = -5.819319	array([[-0.06837642, -0.24101292]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -10.320547	array([[-0.07970066, -0.25348756]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -5.072053	array([[-0.17419934,  0.14582251]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -9.700049	array([[-0.20048214,  0.13305548]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.985701	array([[-0.05682002, -0.23467676]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -6.371724	array([[-0.06515321, -0.23741092]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -9.988996	array([[-0.09256446, -0.25200224]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -4.052567	array([[-0.17927483,  0.12922552]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:53541 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.648799	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -3.443467	array([[-0.07127401, -0.21530016]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.397133	array([[-0.22899093,  0.12794566]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.485030	array([[-0.23924538,  0.13859034]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.787994	array([[-0.08837196, -0.24981888]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.105068	array([[-0.0935736 , -0.25531462]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -3.662260	array([[-0.09054594, -0.25683618]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.618947	array([[-0.23436472,  0.22569035]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.281534	array([[-0.2486836 ,  0.20813984]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.520022	array([[-0.08276151, -0.24945939]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.412985	array([[-0.0868831 , -0.25298306]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -5.729375	array([[-0.08480977, -0.23827419]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -2.675603	array([[-0.21504396,  0.19851229]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -4.320793	array([[-0.236591  ,  0.20014419]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.507798	array([[-0.08302766, -0.25198126]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -2.988321	array([[-0.09402837, -0.24844863]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -7.314942	array([[-0.09852901, -0.24498138]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -3.116038	array([[-0.21696639,  0.19681697]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -5.330153	array([[-0.22923772,  0.20873377]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.166665	array([[-0.08617443, -0.25777975]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -2.322516	array([[-0.08017835, -0.25523052]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -6.472468	array([[-0.08731028, -0.25095806]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -2.979857	array([[-0.22973028,  0.24593525]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -6.108391	array([[-0.2562908 ,  0.25080466]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.777946	array([[-0.07083935, -0.26520225]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -2.492057	array([[-0.08079219, -0.2679714 ]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -5.907302	array([[-0.08585358, -0.2682971 ]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -2.865343	array([[-0.22625202,  0.25324404]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -6.990331	array([[-0.23466259,  0.24118859]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -3.651109	array([[-0.07278712, -0.25969452]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -3.816021	array([[-0.09035839, -0.27453113]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -7.623868	array([[-0.08738041, -0.27173874]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.357707	array([[-0.22113931,  0.21601425]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -7.846670	array([[-0.23488936,  0.21445192]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -4.734584	array([[-0.06747937, -0.23617719]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -4.862575	array([[-0.0786974 , -0.24715172]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -8.724618	array([[-0.09659696, -0.25904122]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -4.060315	array([[-0.19273086,  0.18776739]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -7.912352	array([[-0.21398777,  0.19107652]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -3.817495	array([[-0.06562194, -0.23733096]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -3.596116	array([[-0.08096392, -0.24976785]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -8.236702	array([[-0.099685 , -0.2714746]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -3.518370	array([[-0.20083973,  0.20590386]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -7.704686	array([[-0.2164186 ,  0.20073378]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -3.646649	array([[-0.06191674, -0.2536767 ]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -4.639683	array([[-0.07754955, -0.2557158 ]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -8.077322	array([[-0.10008305, -0.26351583]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -3.282825	array([[-0.20941594,  0.22801961]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -7.814063	array([[-0.22254962,  0.220749  ]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -4.081079	array([[-0.06070013, -0.2462661 ]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -4.595258	array([[-0.08092307, -0.25642762]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -8.187654	array([[-0.08916368, -0.27186853]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -3.146024	array([[-0.2096425 ,  0.21201439]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -8.221366	array([[-0.22769222,  0.2186382 ]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -5.711027	array([[-0.05349712, -0.24757925]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -5.845092	array([[-0.07353333, -0.24904571]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -10.370924	array([[-0.09395543, -0.26649052]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -4.531204	array([[-0.19419752,  0.16496953]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -9.386912	array([[-0.20872872,  0.17960474]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -5.281579	array([[-0.05795176, -0.23389384]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -6.238206	array([[-0.06746179, -0.2452583 ]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -10.133871	array([[-0.08442284, -0.25061888]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -5.077072	array([[-0.18161154,  0.13657323]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -9.465836	array([[-0.19895537,  0.13047493]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -4.600289	array([[-0.05239135, -0.23075023]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -5.330732	array([[-0.06436603, -0.24310791]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -9.555213	array([[-0.08128381, -0.25229955]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -4.782035	array([[-0.17756483,  0.12900513]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -10.796568	array([[-0.19076246,  0.12387858]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -5.163405	array([[-0.05061728, -0.22730766]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -5.612789	array([[-0.06145476, -0.22583851]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -10.008966	array([[-0.08894631, -0.2444436 ]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -5.793893	array([[-0.17407048,  0.12332177]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -11.949578	array([[-0.1931665 ,  0.11839567]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -5.220946	array([[-0.05746886, -0.21419401]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -5.215650	array([[-0.06414476, -0.22634614]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -10.264929	array([[-0.08558328, -0.24625254]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -5.296734	array([[-0.17672464,  0.1359342 ]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -12.199840	array([[-0.19183694,  0.14530776]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -5.713774	array([[-0.06466492, -0.22271127]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -5.727217	array([[-0.07238765, -0.2253028 ]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -11.683191	array([[-0.08995593, -0.24039754]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -5.692745	array([[-0.16954067,  0.10377425]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -12.243524	array([[-0.18864816,  0.12049145]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -5.190860	array([[-0.06438133, -0.23153545]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -5.416530	array([[-0.06498754, -0.23550515]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4842ms
 Real time factor: 138.166
 UPS: 7222.222222
Vehicles: 
 Inserted: 484 (Loaded: 621)
 Running: 65
 Waiting: 32

DijkstraRouter answered 6977 queries and explored 3.61 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 46281 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -10.459119	array([[-0.08644766, -0.24596354]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -5.564791	array([[-0.18427071,  0.13469617]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -10.445549	array([[-0.20213851,  0.13585593]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -5.225610	array([[-0.05938469, -0.22991343]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -5.518591	array([[-0.06313244, -0.23714529]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -9.631320	array([[-0.08603136, -0.25570333]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -4.233980	array([[-0.18757491,  0.14391232]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -10.235490	array([[-0.20027916,  0.15135613]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -4.783046	array([[-0.05885485, -0.2439354 ]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = -5.819319	array([[-0.06837642, -0.24101292]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -10.320547	array([[-0.07970066, -0.25348756]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -5.072053	array([[-0.17419934,  0.14582251]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -9.700049	array([[-0.20048214,  0.13305548]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.985701	array([[-0.05682002, -0.23467676]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -6.371724	array([[-0.06515321, -0.23741092]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -9.988996	array([[-0.09256446, -0.25200224]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -4.052567	array([[-0.17927483,  0.12922552]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:46281 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.648799	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -1.838054	array([[-0.07127401, -0.21530016]], dtype=float32)
time = 40	action = 1	current_phase = 0	next_phase = 1	reward = -4.142402	array([[-0.08158684, -0.2136553 ]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -2.051128	array([[-0.23530254,  0.13830352]], dtype=float32)
time = 53	action = 1	current_phase = 1	next_phase = 0	reward = -3.620599	array([[-0.24255438,  0.15282807]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -0.036984	array([[-0.08231783, -0.23413256]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -0.322373	array([[-0.07732166, -0.2419639 ]], dtype=float32)
time = 71	action = 0	current_phase = 0	next_phase = 1	reward = -1.351008	array([[-0.07928267, -0.24652877]], dtype=float32)
time = 76	action = 1	current_phase = 0	next_phase = 1	reward = -4.855147	array([[-0.08846809, -0.25247902]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -1.644338	array([[-0.22134629,  0.22509906]], dtype=float32)
time = 89	action = 1	current_phase = 1	next_phase = 0	reward = -2.296987	array([[-0.22325546,  0.18985641]], dtype=float32)
time = 97	action = 0	current_phase = 0	next_phase = 1	reward = -1.322496	array([[-0.07851315, -0.2542946 ]], dtype=float32)
time = 102	action = 0	current_phase = 0	next_phase = 1	reward = -2.706305	array([[-0.08706099, -0.24957055]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -3.283472	array([[-0.09060133, -0.24772075]], dtype=float32)
time = 112	action = 1	current_phase = 0	next_phase = 1	reward = -7.915172	array([[-0.07715774, -0.23796809]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -3.265329	array([[-0.19927636,  0.19756033]], dtype=float32)
time = 125	action = 1	current_phase = 1	next_phase = 0	reward = -5.118201	array([[-0.22074327,  0.2065471 ]], dtype=float32)
time = 133	action = 0	current_phase = 0	next_phase = 1	reward = -2.188898	array([[-0.08339886, -0.2585104 ]], dtype=float32)
time = 138	action = 0	current_phase = 0	next_phase = 1	reward = -2.749300	array([[-0.09739806, -0.25676984]], dtype=float32)
time = 143	action = 0	current_phase = 0	next_phase = 1	reward = -4.009495	array([[-0.09918573, -0.2555425 ]], dtype=float32)
time = 148	action = 1	current_phase = 0	next_phase = 1	reward = -8.679116	array([[-0.09407596, -0.24414271]], dtype=float32)
time = 156	action = 0	current_phase = 1	next_phase = 0	reward = -3.233722	array([[-0.22749662,  0.2783612 ]], dtype=float32)
time = 161	action = 1	current_phase = 1	next_phase = 0	reward = -6.806086	array([[-0.24673888,  0.28371015]], dtype=float32)
time = 169	action = 0	current_phase = 0	next_phase = 1	reward = -2.868464	array([[-0.05840129, -0.26169217]], dtype=float32)
time = 174	action = 0	current_phase = 0	next_phase = 1	reward = -3.613196	array([[-0.0797676 , -0.26258206]], dtype=float32)
time = 179	action = 0	current_phase = 0	next_phase = 1	reward = -3.887374	array([[-0.07873096, -0.26305038]], dtype=float32)
time = 184	action = 1	current_phase = 0	next_phase = 1	reward = -7.999051	array([[-0.08141011, -0.26077864]], dtype=float32)
time = 192	action = 0	current_phase = 1	next_phase = 0	reward = -3.627149	array([[-0.22249308,  0.27203238]], dtype=float32)
time = 197	action = 1	current_phase = 1	next_phase = 0	reward = -9.111920	array([[-0.23378481,  0.27491498]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -4.375558	array([[-0.0724151 , -0.25253642]], dtype=float32)
time = 210	action = 0	current_phase = 0	next_phase = 1	reward = -5.277493	array([[-0.08638921, -0.2608826 ]], dtype=float32)
time = 215	action = 0	current_phase = 0	next_phase = 1	reward = -5.081472	array([[-0.09884728, -0.2642231 ]], dtype=float32)
time = 220	action = 1	current_phase = 0	next_phase = 1	reward = -10.673515	array([[-0.08659892, -0.25583908]], dtype=float32)
time = 228	action = 0	current_phase = 1	next_phase = 0	reward = -4.360874	array([[-0.21582004,  0.25245267]], dtype=float32)
time = 233	action = 1	current_phase = 1	next_phase = 0	reward = -7.857738	array([[-0.22306633,  0.24662519]], dtype=float32)
time = 241	action = 0	current_phase = 0	next_phase = 1	reward = -4.713202	array([[-0.05473198, -0.25088888]], dtype=float32)
time = 246	action = 0	current_phase = 0	next_phase = 1	reward = -5.272247	array([[-0.07524998, -0.25825843]], dtype=float32)
time = 251	action = 0	current_phase = 0	next_phase = 1	reward = -5.802119	array([[-0.10719221, -0.27062637]], dtype=float32)
time = 256	action = 1	current_phase = 0	next_phase = 1	reward = -11.775236	array([[-0.10747586, -0.27040216]], dtype=float32)
time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -5.112905	array([[-0.17865221,  0.20297666]], dtype=float32)
time = 269	action = 1	current_phase = 1	next_phase = 0	reward = -9.433204	array([[-0.19857332,  0.22080626]], dtype=float32)
time = 277	action = 0	current_phase = 0	next_phase = 1	reward = -4.131167	array([[-0.05696064, -0.2291774 ]], dtype=float32)
time = 282	action = 0	current_phase = 0	next_phase = 1	reward = -4.360843	array([[-0.09277853, -0.2539795 ]], dtype=float32)
time = 287	action = 0	current_phase = 0	next_phase = 1	reward = -5.777884	array([[-0.11097668, -0.2687275 ]], dtype=float32)
time = 292	action = 1	current_phase = 0	next_phase = 1	reward = -11.935581	array([[-0.11961773, -0.26927215]], dtype=float32)
time = 300	action = 0	current_phase = 1	next_phase = 0	reward = -5.062368	array([[-0.18254626,  0.1981512 ]], dtype=float32)Simulation ended at time: 674.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4759ms
 Real time factor: 141.626
 UPS: 6977.096029
Vehicles: 
 Inserted: 473 (Loaded: 621)
 Running: 63
 Waiting: 46

DijkstraRouter answered 11900 queries and explored 3.16 edges on average.
DijkstraRouter spent 2ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 36997 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 305	action = 1	current_phase = 1	next_phase = 0	reward = -8.946403	array([[-0.19512236,  0.19917727]], dtype=float32)
time = 313	action = 0	current_phase = 0	next_phase = 1	reward = -4.533625	array([[-0.06348208, -0.24286193]], dtype=float32)
time = 318	action = 0	current_phase = 0	next_phase = 1	reward = -5.177113	array([[-0.08361959, -0.25895503]], dtype=float32)
time = 323	action = 0	current_phase = 0	next_phase = 1	reward = -6.544505	array([[-0.10552444, -0.2693749 ]], dtype=float32)
time = 328	action = 1	current_phase = 0	next_phase = 1	reward = -12.776811	array([[-0.11191368, -0.26288927]], dtype=float32)
time = 336	action = 0	current_phase = 1	next_phase = 0	reward = -5.704987	array([[-0.17320488,  0.18214098]], dtype=float32)
time = 341	action = 1	current_phase = 1	next_phase = 0	reward = -10.318214	array([[-0.1942493 ,  0.18918326]], dtype=float32)
time = 349	action = 0	current_phase = 0	next_phase = 1	reward = -4.684996	array([[-0.06220047, -0.24417627]], dtype=float32)
time = 354	action = 0	current_phase = 0	next_phase = 1	reward = -5.604494	array([[-0.08404069, -0.26254103]], dtype=float32)
time = 359	action = 0	current_phase = 0	next_phase = 1	reward = -6.639668	array([[-0.10078023, -0.27226445]], dtype=float32)
time = 364	action = 1	current_phase = 0	next_phase = 1	reward = -13.443525	array([[-0.11241089, -0.27593476]], dtype=float32)
time = 372	action = 0	current_phase = 1	next_phase = 0	reward = -6.383355	array([[-0.17255461,  0.15333477]], dtype=float32)
time = 377	action = 1	current_phase = 1	next_phase = 0	reward = -12.091345	array([[-0.19105977,  0.1653254 ]], dtype=float32)
time = 385	action = 0	current_phase = 0	next_phase = 1	reward = -5.307301	array([[-0.07003386, -0.24217361]], dtype=float32)
time = 390	action = 0	current_phase = 0	next_phase = 1	reward = -5.138875	array([[-0.08007817, -0.2571347 ]], dtype=float32)
time = 395	action = 0	current_phase = 0	next_phase = 1	reward = -6.440445	array([[-0.10483383, -0.2719116 ]], dtype=float32)
time = 400	action = 1	current_phase = 0	next_phase = 1	reward = -13.058642	array([[-0.10567001, -0.26906705]], dtype=float32)
time = 408	action = 0	current_phase = 1	next_phase = 0	reward = -6.096417	array([[-0.15958562,  0.1435544 ]], dtype=float32)
time = 413	action = 1	current_phase = 1	next_phase = 0	reward = -10.288256	array([[-0.185063 ,  0.1460138]], dtype=float32)
time = 421	action = 0	current_phase = 0	next_phase = 1	reward = -4.088924	array([[-0.06005462, -0.24280651]], dtype=float32)
time = 426	action = 0	current_phase = 0	next_phase = 1	reward = -4.948435	array([[-0.07291593, -0.25331986]], dtype=float32)
time = 431	action = 0	current_phase = 0	next_phase = 1	reward = -6.296544	array([[-0.09617238, -0.25945196]], dtype=float32)
time = 436	action = 1	current_phase = 0	next_phase = 1	reward = -12.686238	array([[-0.11470993, -0.26555333]], dtype=float32)
time = 444	action = 0	current_phase = 1	next_phase = 0	reward = -5.453494	array([[-0.16271551,  0.1464622 ]], dtype=float32)
time = 449	action = 1	current_phase = 1	next_phase = 0	reward = -10.805126	array([[-0.17712861,  0.1496266 ]], dtype=float32)
time = 457	action = 0	current_phase = 0	next_phase = 1	reward = -4.135159	array([[-0.06703255, -0.23986821]], dtype=float32)
time = 462	action = 0	current_phase = 0	next_phase = 1	reward = -4.588456	array([[-0.07675475, -0.24901474]], dtype=float32)
time = 467	action = 0	current_phase = 0	next_phase = 1	reward = -5.879758	array([[-0.11070567, -0.26379806]], dtype=float32)
time = 472	action = 1	current_phase = 0	next_phase = 1	reward = -11.983945	array([[-0.11228531, -0.2637847 ]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -5.466850	array([[-0.14970107,  0.14268835]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -9.279296	array([[-0.15930153,  0.14548504]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -3.940456	array([[-0.06135507, -0.24055883]], dtype=float32)
time = 498	action = 0	current_phase = 0	next_phase = 1	reward = -4.222191	array([[-0.08267225, -0.24575956]], dtype=float32)
time = 503	action = 0	current_phase = 0	next_phase = 1	reward = -5.802853	array([[-0.10694733, -0.25867015]], dtype=float32)
time = 508	action = 1	current_phase = 0	next_phase = 1	reward = -12.511190	array([[-0.1183072 , -0.26182756]], dtype=float32)
time = 516	action = 0	current_phase = 1	next_phase = 0	reward = -5.724565	array([[-0.1517565 ,  0.13338791]], dtype=float32)
time = 521	action = 1	current_phase = 1	next_phase = 0	reward = -11.355358	array([[-0.17079258,  0.13585718]], dtype=float32)
time = 529	action = 0	current_phase = 0	next_phase = 1	reward = -4.403849	array([[-0.06799062, -0.23889741]], dtype=float32)
time = 534	action = 0	current_phase = 0	next_phase = 1	reward = -4.495231	array([[-0.07359815, -0.24638426]], dtype=float32)
time = 539	action = 0	current_phase = 0	next_phase = 1	reward = -6.102325	array([[-0.10092354, -0.25684118]], dtype=float32)
time = 544	action = 1	current_phase = 0	next_phase = 1	reward = -12.723505	array([[-0.10991342, -0.25493285]], dtype=float32)
time = 552	action = 0	current_phase = 1	next_phase = 0	reward = -5.577621	array([[-0.15803519,  0.14702395]], dtype=float32)
time = 557	action = 1	current_phase = 1	next_phase = 0	reward = -9.709236	array([[-0.1712924,  0.1622515]], dtype=float32)
time = 565	action = 0	current_phase = 0	next_phase = 1	reward = -3.889632	array([[-0.05967344, -0.24571477]], dtype=float32)
time = 570	action = 0	current_phase = 0	next_phase = 1	reward = -4.699315	array([[-0.0784319 , -0.25444162]], dtype=float32)
time = 575	action = 0	current_phase = 0	next_phase = 1	reward = -5.815546	array([[-0.10329727, -0.27263027]], dtype=float32)
time = 580	action = 1	current_phase = 0	next_phase = 1	reward = -11.265131	array([[-0.10952846, -0.27178544]], dtype=float32)
time = 588	action = 0	current_phase = 1	next_phase = 0	reward = -5.113094	array([[-0.16207111,  0.15332009]], dtype=float32)
time = 593	action = 1	current_phase = 1	next_phase = 0	reward = -9.609671	array([[-0.18265818,  0.16812852]], dtype=float32)
time = 601	action = 0	current_phase = 0	next_phase = 1	reward = -4.392865	array([[-0.05823199, -0.25020108]], dtype=float32)
time = 606	action = 0	current_phase = 0	next_phase = 1	reward = -5.016920	array([[-0.06498101, -0.2528826 ]], dtype=float32)
time = 611	action = 0	current_phase = 0	next_phase = 1	reward = -6.000851	array([[-0.08564448, -0.2681473 ]], dtype=float32)
time = 616	action = 1	current_phase = 0	next_phase = 1	reward = -11.984831	array([[-0.09205084, -0.2644298 ]], dtype=float32)
time = 624	action = 0	current_phase = 1	next_phase = 0	reward = -6.026406	array([[-0.1731425 ,  0.15594278]], dtype=float32)
time = 629	action = 1	current_phase = 1	next_phase = 0	reward = -12.908652	array([[-0.18908283,  0.15554431]], dtype=float32)
time = 637	action = 0	current_phase = 0	next_phase = 1	reward = -5.295162	array([[-0.06343667, -0.22932044]], dtype=float32)
time = 642	action = 0	current_phase = 0	next_phase = 1	reward = -6.017874	array([[-0.07551005, -0.25481656]], dtype=float32)
time = 647	action = 0	current_phase = 0	next_phase = 1	reward = -6.139654	array([[-0.09366582, -0.2598778 ]], dtype=float32)
time = 652	action = 1	current_phase = 0	next_phase = 1	reward = -13.917891	array([[-0.10458484, -0.26512897]], dtype=float32)
time = 660	action = 0	current_phase = 1	next_phase = 0	reward = -6.909773	array([[-0.16606745,  0.12445804]], dtype=float32)
time = 665	action = 1	current_phase = 1	next_phase = 0	reward = -11.578491	array([[-0.18351664,  0.14162616]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:36997 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.648799	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -1.838054	array([[-0.07127401, -0.21530016]], dtype=float32)
time = 40	action = 0	current_phase = 0	next_phase = 1	reward = -2.299206	array([[-0.08158684, -0.2136553 ]], dtype=float32)
time = 45	action = 1	current_phase = 0	next_phase = 1	reward = -4.716627	array([[-0.08779754, -0.21171647]], dtype=float32)
time = 53	action = 0	current_phase = 1	next_phase = 0	reward = -2.651710	array([[-0.24005839,  0.15176108]], dtype=float32)
time = 58	action = 1	current_phase = 1	next_phase = 0	reward = -5.392561	array([[-0.24696857,  0.15439878]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = 0.137501	array([[-0.09813347, -0.2320981 ]], dtype=float32)
time = 71	action = 0	current_phase = 0	next_phase = 1	reward = -1.230946	array([[-0.08430517, -0.24850652]], dtype=float32)
time = 76	action = 0	current_phase = 0	next_phase = 1	reward = -1.616364	array([[-0.09315394, -0.24986286]], dtype=float32)
time = 81	action = 0	current_phase = 0	next_phase = 1	reward = -2.635286	array([[-0.0803168 , -0.24586375]], dtype=float32)
time = 86	action = 1	current_phase = 0	next_phase = 1	reward = -6.024286	array([[-0.07497731, -0.24283484]], dtype=float32)
time = 94	action = 0	current_phase = 1	next_phase = 0	reward = -2.296278	array([[-0.22867379,  0.23932955]], dtype=float32)
time = 99	action = 1	current_phase = 1	next_phase = 0	reward = -3.072133	array([[-0.23500073,  0.21529889]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -1.380159	array([[-0.07962437, -0.2581027 ]], dtype=float32)
time = 112	action = 0	current_phase = 0	next_phase = 1	reward = -2.865574	array([[-0.07942092, -0.25760913]], dtype=float32)
time = 117	action = 0	current_phase = 0	next_phase = 1	reward = -3.905783	array([[-0.09027301, -0.24334705]], dtype=float32)
time = 122	action = 0	current_phase = 0	next_phase = 1	reward = -6.037771	array([[-0.08843799, -0.23512684]], dtype=float32)
time = 127	action = 1	current_phase = 0	next_phase = 1	reward = -10.847867	array([[-0.09597783, -0.22209036]], dtype=float32)
time = 135	action = 0	current_phase = 1	next_phase = 0	reward = -2.858204	array([[-0.19910902,  0.21544668]], dtype=float32)
time = 140	action = 1	current_phase = 1	next_phase = 0	reward = -6.119889	array([[-0.21411023,  0.22435166]], dtype=float32)
time = 148	action = 0	current_phase = 0	next_phase = 1	reward = -2.286812	array([[-0.08765869, -0.2608126 ]], dtype=float32)
time = 153	action = 0	current_phase = 0	next_phase = 1	reward = -2.787338	array([[-0.09788317, -0.27126673]], dtype=float32)
time = 158	action = 0	current_phase = 0	next_phase = 1	reward = -4.799770	array([[-0.10041161, -0.26535493]], dtype=float32)
time = 163	action = 0	current_phase = 0	next_phase = 1	reward = -6.259927	array([[-0.0988895 , -0.25724044]], dtype=float32)
time = 168	action = 1	current_phase = 0	next_phase = 1	reward = -11.563459	array([[-0.09077296, -0.24521573]], dtype=float32)
time = 176	action = 0	current_phase = 1	next_phase = 0	reward = -4.532228	array([[-0.21751237,  0.27760476]], dtype=float32)
time = 181	action = 1	current_phase = 1	next_phase = 0	reward = -8.256945	array([[-0.21658534,  0.2597463 ]], dtype=float32)
time = 189	action = 0	current_phase = 0	next_phase = 1	reward = -4.574690	array([[-0.06681199, -0.24206583]], dtype=float32)
time = 194	action = 0	current_phase = 0	next_phase = 1	reward = -5.002033	array([[-0.08479111, -0.2650641 ]], dtype=float32)
time = 199	action = 0	current_phase = 0	next_phase = 1	reward = -5.787202	array([[-0.10133375, -0.2792828 ]], dtype=float32)
time = 204	action = 0	current_phase = 0	next_phase = 1	reward = -7.285054	array([[-0.09134956, -0.2611211 ]], dtype=float32)
time = 209	action = 1	current_phase = 0	next_phase = 1	reward = -13.569095	array([[-0.0978944, -0.2544244]], dtype=float32)
time = 217	action = 0	current_phase = 1	next_phase = 0	reward = -5.821925	array([[-0.18341634,  0.22949141]], dtype=float32)
time = 222	action = 1	current_phase = 1	next_phase = 0	reward = -10.031878	array([[-0.19980526,  0.22417018]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = -4.477784	array([[-0.04963844, -0.23315898]], dtype=float32)
time = 235	action = 0	current_phase = 0	next_phase = 1	reward = -5.252045	array([[-0.07532983, -0.25539318]], dtype=float32)
time = 240	action = 0	current_phase = 0	next_phase = 1	reward = -6.394100	array([[-0.09604329, -0.26745623]], dtype=float32)
time = 245	action = 0	current_phase = 0	next_phase = 1	reward = -7.758070	array([[-0.10642558, -0.26826692]], dtype=float32)
time = 250	action = 1	current_phase = 0	next_phase = 1	reward = -14.731327	array([[-0.10447255, -0.2647453 ]], dtype=float32)
time = 258	action = 0	current_phase = 1	next_phase = 0	reward = -6.940894	array([[-0.18199381,  0.20404373]], dtype=float32)
time = 263	action = 1	current_phase = 1	next_phase = 0	reward = -10.775157	array([[-0.18667741,  0.20457378]], dtype=float32)
time = 271	action = 0	current_phase = 0	next_phase = 1	reward = -4.532708	array([[-0.06369242, -0.23313458]], dtype=float32)
time = 276	action = 0	current_phase = 0	next_phase = 1	reward = -5.400282	array([[-0.08256353, -0.2522315 ]], dtype=float32)
time = 281	action = 0	current_phase = 0	next_phase = 1	reward = -6.591674	array([[-0.1016082 , -0.26044196]], dtype=float32)
time = 286	action = 0	current_phase = 0	next_phase = 1	reward = -8.672153	array([[-0.11519214, -0.2599794 ]], dtype=float32)
time = 291	action = 1	current_phase = 0	next_phase = 1	reward = -16.871932	array([[-0.13105552, -0.2600158 ]], dtype=float32)
time = 299	action = 0	current_phase = 1	next_phase = 0	reward = -7.576937	array([[-0.15433131,  0.1423397 ]], dtype=float32)
time = 304	action = 1	current_phase = 1	next_phase = 0	reward = -13.013071	array([[-0.15687391,  0.14832497]], dtype=float32)
time = 312	action = 0	current_phase = 0	next_phase = 1	reward = -4.971145	array([[-0.07151222, -0.22709006]], dtype=float32)
time = 317	action = 0	current_phase = 0	next_phase = 1	reward = -5.162387	array([[-0.0844402 , -0.24818812]], dtype=float32)
time = 322	action = 0	current_phase = 0	next_phase = 1	reward = -6.631607	array([[-0.10997378, -0.25670943]], dtype=float32)
time = 327	action = 0	current_phase = 0	next_phase = 1	reward = -9.304491	array([[-0.10866183, -0.25552034]], dtype=float32)
time = 332	action = 1	current_phase = 0	next_phase = 1	reward = -16.669878	array([[-0.1228447, -0.2587469]], dtype=float32)
time = 340	action = 0	current_phase = 1	next_phase = 0	reward = -6.603748	array([[-0.16462593,  0.17772983]], dtype=float32)
time = 345	action = 1	current_phase = 1	next_phase = 0	reward = -12.434326	array([[-0.17777455,  0.18341783]], dtype=float32)
time = 353	action = 0	current_phase = 0	next_phase = 1	reward = -5.015402	array([[-0.07114995, -0.24707507]], dtype=float32)
time = 358	action = 0	current_phase = 0	next_phase = 1	reward = -5.510983	array([[-0.07935688, -0.24971795]], dtype=float32)
time = 363	action = 0	current_phase = 0	next_phase = 1	reward = -6.499571	array([[-0.09913053, -0.26861876]], dtype=float32)
time = 368	action = 0	current_phase = 0	next_phase = 1	reward = -9.040271	array([[-0.10479157, -0.26990682]], dtype=float32)
time = 373	action = 1	current_phase = 0	next_phase = 1	reward = -16.111500	array([[-0.12189731, -0.2646501 ]], dtype=float32)
time = 381	action = 0	current_phase = 1	next_phase = 0	reward = -6.308026	array([[-0.15487435,  0.17342371]], dtype=float32)
time = 386	action = 1	current_phase = 1	next_phase = 0	reward = -10.992743	array([[-0.16849314,  0.17571862]], dtype=float32)
time = 394	action = 0	current_phase = 0	next_phase = 1	reward = -4.677661	array([[-0.06738894, -0.24298878]], dtype=float32)
time = 399	action = 0	current_phase = 0	next_phase = 1	reward = -4.852711	array([[-0.07612026, -0.24964757]], dtype=float32)
time = 404	action = 0	current_phase = 0	next_phase = 1	reward = -6.550948	array([[-0.09692168, -0.26829454]], dtype=float32)
time = 409	action = 0	current_phase = 0	next_phase = 1	reward = -9.066769	array([[-0.10892901, -0.275807  ]], dtype=float32)
time = 414	action = 1	current_phase = 0	next_phase = 1	reward = -15.058644	array([[-0.12323412, -0.26778176]], dtype=float32)
time = 422	action = 0	current_phase = 1	next_phase = 0	reward = -6.189195	array([[-0.17080346,  0.1733639 ]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4719ms
 Real time factor: 141.767
 UPS: 6976.901886
Vehicles: 
 Inserted: 453 (Loaded: 621)
 Running: 61
 Waiting: 63

DijkstraRouter answered 16155 queries and explored 3.10 edges on average.
DijkstraRouter spent 2ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 42997 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 427	action = 1	current_phase = 1	next_phase = 0	reward = -11.308062	array([[-0.17441271,  0.17806685]], dtype=float32)
time = 435	action = 0	current_phase = 0	next_phase = 1	reward = -4.678372	array([[-0.06526157, -0.23360671]], dtype=float32)
time = 440	action = 0	current_phase = 0	next_phase = 1	reward = -5.367758	array([[-0.07629508, -0.24239442]], dtype=float32)
time = 445	action = 0	current_phase = 0	next_phase = 1	reward = -6.033863	array([[-0.10615917, -0.25523913]], dtype=float32)
time = 450	action = 0	current_phase = 0	next_phase = 1	reward = -8.462928	array([[-0.11248624, -0.26023963]], dtype=float32)
time = 455	action = 1	current_phase = 0	next_phase = 1	reward = -14.849972	array([[-0.13602468, -0.26433745]], dtype=float32)
time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -6.069604	array([[-0.15022767,  0.1532015 ]], dtype=float32)
time = 468	action = 1	current_phase = 1	next_phase = 0	reward = -10.773886	array([[-0.16073725,  0.15718937]], dtype=float32)
time = 476	action = 0	current_phase = 0	next_phase = 1	reward = -4.795265	array([[-0.08477563, -0.24306306]], dtype=float32)
time = 481	action = 0	current_phase = 0	next_phase = 1	reward = -4.841438	array([[-0.07996252, -0.24468102]], dtype=float32)
time = 486	action = 0	current_phase = 0	next_phase = 1	reward = -6.938428	array([[-0.10351192, -0.25355077]], dtype=float32)
time = 491	action = 0	current_phase = 0	next_phase = 1	reward = -8.886267	array([[-0.122688  , -0.25676337]], dtype=float32)
time = 496	action = 1	current_phase = 0	next_phase = 1	reward = -15.386327	array([[-0.126353  , -0.25582737]], dtype=float32)
time = 504	action = 0	current_phase = 1	next_phase = 0	reward = -6.779450	array([[-0.15487123,  0.14141342]], dtype=float32)
time = 509	action = 1	current_phase = 1	next_phase = 0	reward = -10.625268	array([[-0.1657776 ,  0.15495762]], dtype=float32)
time = 517	action = 0	current_phase = 0	next_phase = 1	reward = -4.041871	array([[-0.05899659, -0.23335399]], dtype=float32)
time = 522	action = 0	current_phase = 0	next_phase = 1	reward = -4.289025	array([[-0.07764427, -0.2429168 ]], dtype=float32)
time = 527	action = 0	current_phase = 0	next_phase = 1	reward = -5.717080	array([[-0.1039149 , -0.26073313]], dtype=float32)
time = 532	action = 0	current_phase = 0	next_phase = 1	reward = -8.355619	array([[-0.11055693, -0.2576945 ]], dtype=float32)
time = 537	action = 1	current_phase = 0	next_phase = 1	reward = -15.847392	array([[-0.12010399, -0.26399168]], dtype=float32)
time = 545	action = 0	current_phase = 1	next_phase = 0	reward = -7.343296	array([[-0.15755855,  0.15896763]], dtype=float32)
time = 550	action = 1	current_phase = 1	next_phase = 0	reward = -12.272863	array([[-0.17394018,  0.17355639]], dtype=float32)
time = 558	action = 0	current_phase = 0	next_phase = 1	reward = -4.474697	array([[-0.0654221 , -0.23732516]], dtype=float32)
time = 563	action = 0	current_phase = 0	next_phase = 1	reward = -5.088478	array([[-0.08031675, -0.25774977]], dtype=float32)
time = 568	action = 0	current_phase = 0	next_phase = 1	reward = -6.630518	array([[-0.09501629, -0.27375767]], dtype=float32)
time = 573	action = 0	current_phase = 0	next_phase = 1	reward = -9.642532	array([[-0.11603269, -0.27844763]], dtype=float32)
time = 578	action = 1	current_phase = 0	next_phase = 1	reward = -15.874741	array([[-0.1294861 , -0.27409714]], dtype=float32)
time = 586	action = 0	current_phase = 1	next_phase = 0	reward = -5.772130	array([[-0.15891889,  0.16681924]], dtype=float32)
time = 591	action = 1	current_phase = 1	next_phase = 0	reward = -11.138178	array([[-0.16759825,  0.17607598]], dtype=float32)
time = 599	action = 0	current_phase = 0	next_phase = 1	reward = -5.452638	array([[-0.07410832, -0.24391612]], dtype=float32)
time = 604	action = 0	current_phase = 0	next_phase = 1	reward = -6.463843	array([[-0.0836481 , -0.25292867]], dtype=float32)
time = 609	action = 0	current_phase = 0	next_phase = 1	reward = -7.403042	array([[-0.1076449 , -0.26940325]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -10.144224	array([[-0.12647124, -0.27733284]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -16.306956	array([[-0.13592611, -0.26556036]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -6.961888	array([[-0.15812825,  0.17506194]], dtype=float32)
time = 632	action = 1	current_phase = 1	next_phase = 0	reward = -10.534201	array([[-0.17110823,  0.16345504]], dtype=float32)
time = 640	action = 0	current_phase = 0	next_phase = 1	reward = -4.393968	array([[-0.05714944, -0.22926116]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.713146	array([[-0.06979325, -0.23882145]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -5.928326	array([[-0.09672064, -0.26253223]], dtype=float32)
time = 655	action = 0	current_phase = 0	next_phase = 1	reward = -8.381895	array([[-0.10789879, -0.26306337]], dtype=float32)
time = 660	action = 1	current_phase = 0	next_phase = 1	reward = -15.372950	array([[-0.13066545, -0.27237716]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:42997 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.336063	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -1.884166	array([[-0.22438538,  0.11550364]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.570094	array([[-0.23697639,  0.13485163]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.500682	array([[-0.23772225,  0.13987413]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.731814	array([[-0.08784555, -0.2460803 ]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -3.006081	array([[-0.09545529, -0.25043568]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -1.285279	array([[-0.22399352,  0.18313056]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -1.636949	array([[-0.24776061,  0.19410805]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -3.629058	array([[-0.24874713,  0.18535225]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -0.593884	array([[-0.09017794, -0.24004859]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -4.967097	array([[-0.08196405, -0.24192269]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -2.428805	array([[-0.21026558,  0.16787602]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -3.593863	array([[-0.22795898,  0.15872934]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -7.999872	array([[-0.24443007,  0.16142854]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -2.269922	array([[-0.1144715 , -0.22320476]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -5.630528	array([[-0.08895107, -0.2214824 ]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -2.311895	array([[-0.20201696,  0.1380099 ]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -3.193679	array([[-0.23232538,  0.14866251]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -8.371061	array([[-0.24988537,  0.17116487]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -2.070927	array([[-0.10837758, -0.2046403 ]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -4.962456	array([[-0.09716156, -0.21427283]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -3.039189	array([[-0.2048586 ,  0.15167817]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -4.119958	array([[-0.22612043,  0.15134738]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -10.417372	array([[-0.24058399,  0.16172343]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -4.655508	array([[-0.15552256, -0.21625017]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -6.189745	array([[-0.12341665, -0.21420258]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -2.186643	array([[-0.20696363,  0.1455134 ]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -3.414193	array([[-0.22576818,  0.14000982]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -9.506176	array([[-0.23766449,  0.14840424]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -4.835354	array([[-0.13951048, -0.21074829]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -7.036567	array([[-0.12545842, -0.21230923]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -1.564568	array([[-0.20351171,  0.11157746]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.850910	array([[-0.2182843 ,  0.11681606]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -8.790204	array([[-0.23854929,  0.13790174]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -3.724804	array([[-0.13180794, -0.20134875]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -6.366038	array([[-0.12086432, -0.20880798]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -2.245308	array([[-0.19880278,  0.09185012]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -4.471679	array([[-0.2137454 ,  0.12144656]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -9.314747	array([[-0.23881269,  0.13409665]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -4.489159	array([[-0.1420849 , -0.20031455]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -7.876242	array([[-0.14585407, -0.20598635]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -2.133053	array([[-0.19420072,  0.10643642]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -4.374075	array([[-0.21645164,  0.12604468]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -10.261416	array([[-0.23439825,  0.13779028]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -4.964948	array([[-0.1503512 , -0.19534172]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -8.687778	array([[-0.15045133, -0.2026521 ]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -3.032666	array([[-0.20578721,  0.12297796]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -3.666066	array([[-0.21397555,  0.12165932]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -9.103656	array([[-0.22048333,  0.14492959]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -4.123292	array([[-0.15971899, -0.20045564]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -7.782263	array([[-0.1461294, -0.2043728]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -3.277962	array([[-0.19556507,  0.09247246]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -4.609700	array([[-0.20722666,  0.10618688]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -8.845439	array([[-0.23270959,  0.11142199]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -3.871080	array([[-0.13339488, -0.19941498]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -7.990285	array([[-0.13873833, -0.20965719]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -2.383989	array([[-0.19938156,  0.08875178]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -3.934024	array([[-0.20608151,  0.09607574]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -10.118653	array([[-0.2347609 ,  0.13419797]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -5.099665	array([[-0.15205869, -0.20472546]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -9.482244	array([[-0.14354113, -0.20777953]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -2.795372	array([[-0.19749291,  0.09905119]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -3.633534	array([[-0.2091013 ,  0.10887362]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -9.853525	array([[-0.22739601,  0.14050998]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -4.727567	array([[-0.14367723, -0.18839276]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -7.885420	array([[-0.15810072, -0.19877777]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -3.065311	array([[-0.19976926,  0.09561506]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -4.029440	array([[-0.20696096,  0.10976815]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -8.293795	array([[-0.23756894,  0.1318083 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -4.493509	array([[-0.1509407, -0.1969443]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -7.895558	array([[-0.14933318, -0.1973134 ]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -2.796723	array([[-0.20563146,  0.11062053]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -4.143128	array([[-0.21960837,  0.12783158]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -8.145110	array([[-0.2386392,  0.1463916]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -3.001651	array([[-0.14491394, -0.19625889]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -8.689430	array([[-0.13803515, -0.20054469]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -3.570505	array([[-0.20241955,  0.12876871]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -4.426502	array([[-0.20497067,  0.12815551]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -9.419198	array([[-0.20863424,  0.14149651]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -4.390797	array([[-0.16433907, -0.20321675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -7.596277	array([[-0.16763891, -0.21021414]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -3.115773	array([[-0.19582084,  0.10545329]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -3.870989	array([[-0.21344832,  0.09825291]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -8.703018	array([[-0.23315643,  0.11673115]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -4.174712	array([[-0.15626937, -0.20010482]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -9.400502	array([[-0.14445165, -0.20092326]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -3.809525	array([[-0.20387134,  0.10111213]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -4.463481	array([[-0.22075322,  0.11206751]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4495ms
 Real time factor: 148.832
 UPS: 6937.263626
Vehicles: 
 Inserted: 457 (Loaded: 621)
 Running: 53
 Waiting: 59

DijkstraRouter answered 14794 queries and explored 4.42 edges on average.
DijkstraRouter spent 6ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 35469 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -10.829165	array([[-0.22852334,  0.13255563]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -5.563715	array([[-0.1552131 , -0.19243026]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -9.893838	array([[-0.15934283, -0.20157273]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -3.019338	array([[-0.20353805,  0.109975  ]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -3.703572	array([[-0.21338527,  0.11996625]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -8.396749	array([[-0.2261818,  0.1380438]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -3.968731	array([[-0.13971344, -0.20172966]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -8.984056	array([[-0.1501528 , -0.20627964]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -2.862676	array([[-0.1958988 ,  0.10011218]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -4.508906	array([[-0.20924169,  0.11455883]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -9.595760	array([[-0.23258027,  0.13961178]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.837704	array([[-0.15392803, -0.19024466]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -8.883356	array([[-0.16636708, -0.20326506]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -3.724846	array([[-0.20003627,  0.10525066]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -4.596333	array([[-0.21744314,  0.10999346]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:35469 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.336063	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -1.884166	array([[-0.22438538,  0.11550364]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.570094	array([[-0.23697639,  0.13485163]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.500682	array([[-0.23772225,  0.13987413]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.731814	array([[-0.08784555, -0.2460803 ]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -3.006081	array([[-0.09545529, -0.25043568]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -1.285279	array([[-0.22399352,  0.18313056]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -1.636949	array([[-0.24776061,  0.19410805]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -3.629058	array([[-0.24874713,  0.18535225]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -0.593884	array([[-0.09017794, -0.24004859]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -4.967097	array([[-0.08196405, -0.24192269]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -2.428805	array([[-0.21026558,  0.16787602]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -3.593863	array([[-0.22795898,  0.15872934]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -7.999872	array([[-0.24443007,  0.16142854]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -2.269922	array([[-0.1144715 , -0.22320476]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -5.630528	array([[-0.08895107, -0.2214824 ]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -2.311895	array([[-0.20201696,  0.1380099 ]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -3.193679	array([[-0.23232538,  0.14866251]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -8.371061	array([[-0.24988537,  0.17116487]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -2.070927	array([[-0.10837758, -0.2046403 ]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -4.962456	array([[-0.09716156, -0.21427283]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -3.039189	array([[-0.2048586 ,  0.15167817]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -4.119958	array([[-0.22612043,  0.15134738]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -10.417372	array([[-0.24058399,  0.16172343]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -4.655508	array([[-0.15552256, -0.21625017]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -6.189745	array([[-0.12341665, -0.21420258]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -2.186643	array([[-0.20696363,  0.1455134 ]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -3.414193	array([[-0.22576818,  0.14000982]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -9.506176	array([[-0.23766449,  0.14840424]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -4.835354	array([[-0.13951048, -0.21074829]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -7.036567	array([[-0.12545842, -0.21230923]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -1.564568	array([[-0.20351171,  0.11157746]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.850910	array([[-0.2182843 ,  0.11681606]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -8.790204	array([[-0.23854929,  0.13790174]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -3.724804	array([[-0.13180794, -0.20134875]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -6.366038	array([[-0.12086432, -0.20880798]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -2.245308	array([[-0.19880278,  0.09185012]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -4.471679	array([[-0.2137454 ,  0.12144656]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -9.314747	array([[-0.23881269,  0.13409665]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -4.489159	array([[-0.1420849 , -0.20031455]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -7.876242	array([[-0.14585407, -0.20598635]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -2.133053	array([[-0.19420072,  0.10643642]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -4.374075	array([[-0.21645164,  0.12604468]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -10.261416	array([[-0.23439825,  0.13779028]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -4.964948	array([[-0.1503512 , -0.19534172]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -8.687778	array([[-0.15045133, -0.2026521 ]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -3.032666	array([[-0.20578721,  0.12297796]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -3.666066	array([[-0.21397555,  0.12165932]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4521ms
 Real time factor: 147.976
 UPS: 6897.367839
Vehicles: 
 Inserted: 457 (Loaded: 621)
 Running: 53
 Waiting: 59

DijkstraRouter answered 14794 queries and explored 4.42 edges on average.
DijkstraRouter spent 3ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 52611 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -9.103656	array([[-0.22048333,  0.14492959]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -4.123292	array([[-0.15971899, -0.20045564]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -7.782263	array([[-0.1461294, -0.2043728]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -3.277962	array([[-0.19556507,  0.09247246]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -4.609700	array([[-0.20722666,  0.10618688]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -8.845439	array([[-0.23270959,  0.11142199]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -3.871080	array([[-0.13339488, -0.19941498]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -7.990285	array([[-0.13873833, -0.20965719]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -2.383989	array([[-0.19938156,  0.08875178]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -3.934024	array([[-0.20608151,  0.09607574]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -10.118653	array([[-0.2347609 ,  0.13419797]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -5.099665	array([[-0.15205869, -0.20472546]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -9.482244	array([[-0.14354113, -0.20777953]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -2.795372	array([[-0.19749291,  0.09905119]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -3.633534	array([[-0.2091013 ,  0.10887362]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -9.853525	array([[-0.22739601,  0.14050998]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -4.727567	array([[-0.14367723, -0.18839276]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -7.885420	array([[-0.15810072, -0.19877777]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -3.065311	array([[-0.19976926,  0.09561506]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -4.029440	array([[-0.20696096,  0.10976815]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -8.293795	array([[-0.23756894,  0.1318083 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -4.493509	array([[-0.1509407, -0.1969443]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -7.895558	array([[-0.14933318, -0.1973134 ]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -2.796723	array([[-0.20563146,  0.11062053]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -4.143128	array([[-0.21960837,  0.12783158]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -8.145110	array([[-0.2386392,  0.1463916]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -3.001651	array([[-0.14491394, -0.19625889]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -8.689430	array([[-0.13803515, -0.20054469]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -3.570505	array([[-0.20241955,  0.12876871]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -4.426502	array([[-0.20497067,  0.12815551]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -9.419198	array([[-0.20863424,  0.14149651]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -4.390797	array([[-0.16433907, -0.20321675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -7.596277	array([[-0.16763891, -0.21021414]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -3.115773	array([[-0.19582084,  0.10545329]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -3.870989	array([[-0.21344832,  0.09825291]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -8.703018	array([[-0.23315643,  0.11673115]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -4.174712	array([[-0.15626937, -0.20010482]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -9.400502	array([[-0.14445165, -0.20092326]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -3.809525	array([[-0.20387134,  0.10111213]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -4.463481	array([[-0.22075322,  0.11206751]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -10.829165	array([[-0.22852334,  0.13255563]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -5.563715	array([[-0.1552131 , -0.19243026]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -9.893838	array([[-0.15934283, -0.20157273]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -3.019338	array([[-0.20353805,  0.109975  ]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -3.703572	array([[-0.21338527,  0.11996625]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -8.396749	array([[-0.2261818,  0.1380438]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -3.968731	array([[-0.13971344, -0.20172966]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -8.984056	array([[-0.1501528 , -0.20627964]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -2.862676	array([[-0.1958988 ,  0.10011218]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -4.508906	array([[-0.20924169,  0.11455883]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -9.595760	array([[-0.23258027,  0.13961178]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.837704	array([[-0.15392803, -0.19024466]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -8.883356	array([[-0.16636708, -0.20326506]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -3.724846	array([[-0.20003627,  0.10525066]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -4.596333	array([[-0.21744314,  0.10999346]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:52611 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.336063	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -1.884166	array([[-0.22438538,  0.11550364]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.570094	array([[-0.23697639,  0.13485163]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.500682	array([[-0.23772225,  0.13987413]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.731814	array([[-0.08784555, -0.2460803 ]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -3.006081	array([[-0.09545529, -0.25043568]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -1.285279	array([[-0.22399352,  0.18313056]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -1.636949	array([[-0.24776061,  0.19410805]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -3.629058	array([[-0.24874713,  0.18535225]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -0.593884	array([[-0.09017794, -0.24004859]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -4.967097	array([[-0.08196405, -0.24192269]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -2.428805	array([[-0.21026558,  0.16787602]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -3.593863	array([[-0.22795898,  0.15872934]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -7.999872	array([[-0.24443007,  0.16142854]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -2.269922	array([[-0.1144715 , -0.22320476]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -5.630528	array([[-0.08895107, -0.2214824 ]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -2.311895	array([[-0.20201696,  0.1380099 ]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -3.193679	array([[-0.23232538,  0.14866251]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -8.371061	array([[-0.24988537,  0.17116487]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -2.070927	array([[-0.10837758, -0.2046403 ]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -4.962456	array([[-0.09716156, -0.21427283]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -3.039189	array([[-0.2048586 ,  0.15167817]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -4.119958	array([[-0.22612043,  0.15134738]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -10.417372	array([[-0.24058399,  0.16172343]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -4.655508	array([[-0.15552256, -0.21625017]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -6.189745	array([[-0.12341665, -0.21420258]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -2.186643	array([[-0.20696363,  0.1455134 ]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -3.414193	array([[-0.22576818,  0.14000982]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -9.506176	array([[-0.23766449,  0.14840424]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -4.835354	array([[-0.13951048, -0.21074829]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -7.036567	array([[-0.12545842, -0.21230923]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -1.564568	array([[-0.20351171,  0.11157746]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.850910	array([[-0.2182843 ,  0.11681606]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -8.790204	array([[-0.23854929,  0.13790174]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -3.724804	array([[-0.13180794, -0.20134875]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -6.366038	array([[-0.12086432, -0.20880798]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -2.245308	array([[-0.19880278,  0.09185012]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -4.471679	array([[-0.2137454 ,  0.12144656]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -9.314747	array([[-0.23881269,  0.13409665]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -4.489159	array([[-0.1420849 , -0.20031455]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -7.876242	array([[-0.14585407, -0.20598635]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -2.133053	array([[-0.19420072,  0.10643642]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -4.374075	array([[-0.21645164,  0.12604468]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -10.261416	array([[-0.23439825,  0.13779028]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -4.964948	array([[-0.1503512 , -0.19534172]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -8.687778	array([[-0.15045133, -0.2026521 ]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -3.032666	array([[-0.20578721,  0.12297796]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -3.666066	array([[-0.21397555,  0.12165932]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -9.103656	array([[-0.22048333,  0.14492959]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -4.123292	array([[-0.15971899, -0.20045564]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -7.782263	array([[-0.1461294, -0.2043728]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -3.277962	array([[-0.19556507,  0.09247246]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -4.609700	array([[-0.20722666,  0.10618688]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -8.845439	array([[-0.23270959,  0.11142199]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -3.871080	array([[-0.13339488, -0.19941498]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -7.990285	array([[-0.13873833, -0.20965719]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -2.383989	array([[-0.19938156,  0.08875178]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -3.934024	array([[-0.20608151,  0.09607574]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -10.118653	array([[-0.2347609 ,  0.13419797]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -5.099665	array([[-0.15205869, -0.20472546]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -9.482244	array([[-0.14354113, -0.20777953]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -2.795372	array([[-0.19749291,  0.09905119]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -3.633534	array([[-0.2091013 ,  0.10887362]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -9.853525	array([[-0.22739601,  0.14050998]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -4.727567	array([[-0.14367723, -0.18839276]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -7.885420	array([[-0.15810072, -0.19877777]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -3.065311	array([[-0.19976926,  0.09561506]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -4.029440	array([[-0.20696096,  0.10976815]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -8.293795	array([[-0.23756894,  0.1318083 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -4.493509	array([[-0.1509407, -0.1969443]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -7.895558	array([[-0.14933318, -0.1973134 ]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -2.796723	array([[-0.20563146,  0.11062053]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -4.143128	array([[-0.21960837,  0.12783158]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -8.145110	array([[-0.2386392,  0.1463916]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4472ms
 Real time factor: 149.597
 UPS: 6972.942755
Vehicles: 
 Inserted: 457 (Loaded: 621)
 Running: 53
 Waiting: 59

DijkstraRouter answered 14794 queries and explored 4.42 edges on average.
DijkstraRouter spent 3ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 51475 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -3.001651	array([[-0.14491394, -0.19625889]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -8.689430	array([[-0.13803515, -0.20054469]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -3.570505	array([[-0.20241955,  0.12876871]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -4.426502	array([[-0.20497067,  0.12815551]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -9.419198	array([[-0.20863424,  0.14149651]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -4.390797	array([[-0.16433907, -0.20321675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -7.596277	array([[-0.16763891, -0.21021414]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -3.115773	array([[-0.19582084,  0.10545329]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -3.870989	array([[-0.21344832,  0.09825291]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -8.703018	array([[-0.23315643,  0.11673115]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -4.174712	array([[-0.15626937, -0.20010482]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -9.400502	array([[-0.14445165, -0.20092326]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -3.809525	array([[-0.20387134,  0.10111213]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -4.463481	array([[-0.22075322,  0.11206751]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -10.829165	array([[-0.22852334,  0.13255563]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -5.563715	array([[-0.1552131 , -0.19243026]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -9.893838	array([[-0.15934283, -0.20157273]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -3.019338	array([[-0.20353805,  0.109975  ]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -3.703572	array([[-0.21338527,  0.11996625]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -8.396749	array([[-0.2261818,  0.1380438]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -3.968731	array([[-0.13971344, -0.20172966]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -8.984056	array([[-0.1501528 , -0.20627964]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -2.862676	array([[-0.1958988 ,  0.10011218]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -4.508906	array([[-0.20924169,  0.11455883]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -9.595760	array([[-0.23258027,  0.13961178]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.837704	array([[-0.15392803, -0.19024466]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -8.883356	array([[-0.16636708, -0.20326506]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -3.724846	array([[-0.20003627,  0.10525066]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -4.596333	array([[-0.21744314,  0.10999346]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:51475 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.336063	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -1.884166	array([[-0.22438538,  0.11550364]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.570094	array([[-0.23697639,  0.13485163]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.500682	array([[-0.23772225,  0.13987413]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.731814	array([[-0.08784555, -0.2460803 ]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -3.006081	array([[-0.09545529, -0.25043568]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -1.285279	array([[-0.22399352,  0.18313056]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -1.636949	array([[-0.24776061,  0.19410805]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -3.629058	array([[-0.24874713,  0.18535225]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -0.593884	array([[-0.09017794, -0.24004859]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -4.967097	array([[-0.08196405, -0.24192269]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -2.428805	array([[-0.21026558,  0.16787602]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -3.593863	array([[-0.22795898,  0.15872934]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -7.999872	array([[-0.24443007,  0.16142854]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -2.269922	array([[-0.1144715 , -0.22320476]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -5.630528	array([[-0.08895107, -0.2214824 ]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -2.311895	array([[-0.20201696,  0.1380099 ]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -3.193679	array([[-0.23232538,  0.14866251]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -8.371061	array([[-0.24988537,  0.17116487]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -2.070927	array([[-0.10837758, -0.2046403 ]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -4.962456	array([[-0.09716156, -0.21427283]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -3.039189	array([[-0.2048586 ,  0.15167817]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -4.119958	array([[-0.22612043,  0.15134738]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -10.417372	array([[-0.24058399,  0.16172343]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -4.655508	array([[-0.15552256, -0.21625017]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -6.189745	array([[-0.12341665, -0.21420258]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -2.186643	array([[-0.20696363,  0.1455134 ]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -3.414193	array([[-0.22576818,  0.14000982]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -9.506176	array([[-0.23766449,  0.14840424]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -4.835354	array([[-0.13951048, -0.21074829]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -7.036567	array([[-0.12545842, -0.21230923]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -1.564568	array([[-0.20351171,  0.11157746]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.850910	array([[-0.2182843 ,  0.11681606]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -8.790204	array([[-0.23854929,  0.13790174]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -3.724804	array([[-0.13180794, -0.20134875]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -6.366038	array([[-0.12086432, -0.20880798]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -2.245308	array([[-0.19880278,  0.09185012]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -4.471679	array([[-0.2137454 ,  0.12144656]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -9.314747	array([[-0.23881269,  0.13409665]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -4.489159	array([[-0.1420849 , -0.20031455]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -7.876242	array([[-0.14585407, -0.20598635]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -2.133053	array([[-0.19420072,  0.10643642]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -4.374075	array([[-0.21645164,  0.12604468]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -10.261416	array([[-0.23439825,  0.13779028]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -4.964948	array([[-0.1503512 , -0.19534172]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -8.687778	array([[-0.15045133, -0.2026521 ]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -3.032666	array([[-0.20578721,  0.12297796]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -3.666066	array([[-0.21397555,  0.12165932]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -9.103656	array([[-0.22048333,  0.14492959]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -4.123292	array([[-0.15971899, -0.20045564]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -7.782263	array([[-0.1461294, -0.2043728]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -3.277962	array([[-0.19556507,  0.09247246]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -4.609700	array([[-0.20722666,  0.10618688]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -8.845439	array([[-0.23270959,  0.11142199]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -3.871080	array([[-0.13339488, -0.19941498]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -7.990285	array([[-0.13873833, -0.20965719]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -2.383989	array([[-0.19938156,  0.08875178]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -3.934024	array([[-0.20608151,  0.09607574]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -10.118653	array([[-0.2347609 ,  0.13419797]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -5.099665	array([[-0.15205869, -0.20472546]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -9.482244	array([[-0.14354113, -0.20777953]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -2.795372	array([[-0.19749291,  0.09905119]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -3.633534	array([[-0.2091013 ,  0.10887362]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -9.853525	array([[-0.22739601,  0.14050998]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -4.727567	array([[-0.14367723, -0.18839276]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -7.885420	array([[-0.15810072, -0.19877777]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -3.065311	array([[-0.19976926,  0.09561506]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -4.029440	array([[-0.20696096,  0.10976815]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -8.293795	array([[-0.23756894,  0.1318083 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -4.493509	array([[-0.1509407, -0.1969443]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -7.895558	array([[-0.14933318, -0.1973134 ]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -2.796723	array([[-0.20563146,  0.11062053]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -4.143128	array([[-0.21960837,  0.12783158]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -8.145110	array([[-0.2386392,  0.1463916]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -3.001651	array([[-0.14491394, -0.19625889]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -8.689430	array([[-0.13803515, -0.20054469]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -3.570505	array([[-0.20241955,  0.12876871]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -4.426502	array([[-0.20497067,  0.12815551]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -9.419198	array([[-0.20863424,  0.14149651]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -4.390797	array([[-0.16433907, -0.20321675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -7.596277	array([[-0.16763891, -0.21021414]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -3.115773	array([[-0.19582084,  0.10545329]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -3.870989	array([[-0.21344832,  0.09825291]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -8.703018	array([[-0.23315643,  0.11673115]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -4.174712	array([[-0.15626937, -0.20010482]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -9.400502	array([[-0.14445165, -0.20092326]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -3.809525	array([[-0.20387134,  0.10111213]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -4.463481	array([[-0.22075322,  0.11206751]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -10.829165	array([[-0.22852334,  0.13255563]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -5.563715	array([[-0.1552131 , -0.19243026]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -9.893838	array([[-0.15934283, -0.20157273]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -3.019338	array([[-0.20353805,  0.109975  ]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -3.703572	array([[-0.21338527,  0.11996625]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -8.396749	array([[-0.2261818,  0.1380438]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -3.968731	array([[-0.13971344, -0.20172966]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -8.984056	array([[-0.1501528 , -0.20627964]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -2.862676	array([[-0.1958988 ,  0.10011218]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -4.508906	array([[-0.20924169,  0.11455883]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -9.595760	array([[-0.23258027,  0.13961178]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.837704	array([[-0.15392803, -0.19024466]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4567ms
 Real time factor: 146.486
 UPS: 6827.895774
Vehicles: 
 Inserted: 457 (Loaded: 621)
 Running: 53
 Waiting: 59

DijkstraRouter answered 14794 queries and explored 4.42 edges on average.
DijkstraRouter spent 4ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 51571 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -8.883356	array([[-0.16636708, -0.20326506]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -3.724846	array([[-0.20003627,  0.10525066]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -4.596333	array([[-0.21744314,  0.10999346]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:51571 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.336063	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -1.884166	array([[-0.22438538,  0.11550364]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.570094	array([[-0.23697639,  0.13485163]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.500682	array([[-0.23772225,  0.13987413]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.731814	array([[-0.08784555, -0.2460803 ]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -3.006081	array([[-0.09545529, -0.25043568]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -1.285279	array([[-0.22399352,  0.18313056]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -1.636949	array([[-0.24776061,  0.19410805]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -3.629058	array([[-0.24874713,  0.18535225]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -0.593884	array([[-0.09017794, -0.24004859]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -4.967097	array([[-0.08196405, -0.24192269]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -2.428805	array([[-0.21026558,  0.16787602]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -3.593863	array([[-0.22795898,  0.15872934]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -7.999872	array([[-0.24443007,  0.16142854]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -2.269922	array([[-0.1144715 , -0.22320476]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -5.630528	array([[-0.08895107, -0.2214824 ]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -2.311895	array([[-0.20201696,  0.1380099 ]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -3.193679	array([[-0.23232538,  0.14866251]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -8.371061	array([[-0.24988537,  0.17116487]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -2.070927	array([[-0.10837758, -0.2046403 ]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -4.962456	array([[-0.09716156, -0.21427283]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -3.039189	array([[-0.2048586 ,  0.15167817]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -4.119958	array([[-0.22612043,  0.15134738]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -10.417372	array([[-0.24058399,  0.16172343]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -4.655508	array([[-0.15552256, -0.21625017]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -6.189745	array([[-0.12341665, -0.21420258]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -2.186643	array([[-0.20696363,  0.1455134 ]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -3.414193	array([[-0.22576818,  0.14000982]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -9.506176	array([[-0.23766449,  0.14840424]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -4.835354	array([[-0.13951048, -0.21074829]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -7.036567	array([[-0.12545842, -0.21230923]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -1.564568	array([[-0.20351171,  0.11157746]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.850910	array([[-0.2182843 ,  0.11681606]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -8.790204	array([[-0.23854929,  0.13790174]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -3.724804	array([[-0.13180794, -0.20134875]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -6.366038	array([[-0.12086432, -0.20880798]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -2.245308	array([[-0.19880278,  0.09185012]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -4.471679	array([[-0.2137454 ,  0.12144656]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -9.314747	array([[-0.23881269,  0.13409665]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -4.489159	array([[-0.1420849 , -0.20031455]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -7.876242	array([[-0.14585407, -0.20598635]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -2.133053	array([[-0.19420072,  0.10643642]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -4.374075	array([[-0.21645164,  0.12604468]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -10.261416	array([[-0.23439825,  0.13779028]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -4.964948	array([[-0.1503512 , -0.19534172]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -8.687778	array([[-0.15045133, -0.2026521 ]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -3.032666	array([[-0.20578721,  0.12297796]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -3.666066	array([[-0.21397555,  0.12165932]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -9.103656	array([[-0.22048333,  0.14492959]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -4.123292	array([[-0.15971899, -0.20045564]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -7.782263	array([[-0.1461294, -0.2043728]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -3.277962	array([[-0.19556507,  0.09247246]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -4.609700	array([[-0.20722666,  0.10618688]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -8.845439	array([[-0.23270959,  0.11142199]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -3.871080	array([[-0.13339488, -0.19941498]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -7.990285	array([[-0.13873833, -0.20965719]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -2.383989	array([[-0.19938156,  0.08875178]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -3.934024	array([[-0.20608151,  0.09607574]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -10.118653	array([[-0.2347609 ,  0.13419797]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -5.099665	array([[-0.15205869, -0.20472546]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4482ms
 Real time factor: 149.264
 UPS: 6957.385096
Vehicles: 
 Inserted: 457 (Loaded: 621)
 Running: 53
 Waiting: 59

DijkstraRouter answered 14794 queries and explored 4.42 edges on average.
DijkstraRouter spent 2ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 52615 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -9.482244	array([[-0.14354113, -0.20777953]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -2.795372	array([[-0.19749291,  0.09905119]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -3.633534	array([[-0.2091013 ,  0.10887362]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -9.853525	array([[-0.22739601,  0.14050998]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -4.727567	array([[-0.14367723, -0.18839276]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -7.885420	array([[-0.15810072, -0.19877777]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -3.065311	array([[-0.19976926,  0.09561506]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -4.029440	array([[-0.20696096,  0.10976815]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -8.293795	array([[-0.23756894,  0.1318083 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -4.493509	array([[-0.1509407, -0.1969443]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -7.895558	array([[-0.14933318, -0.1973134 ]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -2.796723	array([[-0.20563146,  0.11062053]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -4.143128	array([[-0.21960837,  0.12783158]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -8.145110	array([[-0.2386392,  0.1463916]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -3.001651	array([[-0.14491394, -0.19625889]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -8.689430	array([[-0.13803515, -0.20054469]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -3.570505	array([[-0.20241955,  0.12876871]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -4.426502	array([[-0.20497067,  0.12815551]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -9.419198	array([[-0.20863424,  0.14149651]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -4.390797	array([[-0.16433907, -0.20321675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -7.596277	array([[-0.16763891, -0.21021414]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -3.115773	array([[-0.19582084,  0.10545329]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -3.870989	array([[-0.21344832,  0.09825291]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -8.703018	array([[-0.23315643,  0.11673115]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -4.174712	array([[-0.15626937, -0.20010482]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -9.400502	array([[-0.14445165, -0.20092326]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -3.809525	array([[-0.20387134,  0.10111213]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -4.463481	array([[-0.22075322,  0.11206751]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -10.829165	array([[-0.22852334,  0.13255563]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -5.563715	array([[-0.1552131 , -0.19243026]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -9.893838	array([[-0.15934283, -0.20157273]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -3.019338	array([[-0.20353805,  0.109975  ]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -3.703572	array([[-0.21338527,  0.11996625]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -8.396749	array([[-0.2261818,  0.1380438]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -3.968731	array([[-0.13971344, -0.20172966]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -8.984056	array([[-0.1501528 , -0.20627964]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -2.862676	array([[-0.1958988 ,  0.10011218]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -4.508906	array([[-0.20924169,  0.11455883]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -9.595760	array([[-0.23258027,  0.13961178]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -4.837704	array([[-0.15392803, -0.19024466]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -8.883356	array([[-0.16636708, -0.20326506]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -3.724846	array([[-0.20003627,  0.10525066]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -4.596333	array([[-0.21744314,  0.10999346]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:52615 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.336063	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -1.884166	array([[-0.22438538,  0.11550364]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.570094	array([[-0.23697639,  0.13485163]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -2.302475	array([[-0.23772225,  0.13987413]], dtype=float32)
time = 53	action = 1	current_phase = 1	next_phase = 0	reward = -3.896242	array([[-0.23869981,  0.14563867]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = 0.095653	array([[-0.09063455, -0.2324353 ]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -2.785472	array([[-0.07758532, -0.24106596]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -2.228087	array([[-0.22358182,  0.19147822]], dtype=float32)
time = 79	action = 0	current_phase = 1	next_phase = 0	reward = -3.108290	array([[-0.23698609,  0.1842556 ]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -3.485811	array([[-0.24247499,  0.18132186]], dtype=float32)
time = 89	action = 1	current_phase = 1	next_phase = 0	reward = -6.063598	array([[-0.22782794,  0.16657825]], dtype=float32)
time = 97	action = 0	current_phase = 0	next_phase = 1	reward = -1.329590	array([[-0.11963899, -0.21597151]], dtype=float32)
time = 102	action = 1	current_phase = 0	next_phase = 1	reward = -3.759960	array([[-0.09641017, -0.22881846]], dtype=float32)
time = 110	action = 0	current_phase = 1	next_phase = 0	reward = -2.291402	array([[-0.19836904,  0.12479327]], dtype=float32)
time = 115	action = 0	current_phase = 1	next_phase = 0	reward = -3.920200	array([[-0.22140203,  0.13539483]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -5.222189	array([[-0.23029454,  0.12522224]], dtype=float32)
time = 125	action = 1	current_phase = 1	next_phase = 0	reward = -10.715279	array([[-0.23656748,  0.1453416 ]], dtype=float32)
time = 133	action = 0	current_phase = 0	next_phase = 1	reward = -3.499566	array([[-0.13989156, -0.19766852]], dtype=float32)
time = 138	action = 1	current_phase = 0	next_phase = 1	reward = -5.495996	array([[-0.13637292, -0.21118996]], dtype=float32)
time = 146	action = 0	current_phase = 1	next_phase = 0	reward = -2.476608	array([[-0.1926651 ,  0.11113846]], dtype=float32)
time = 151	action = 0	current_phase = 1	next_phase = 0	reward = -5.185650	array([[-0.21512623,  0.13698858]], dtype=float32)
time = 156	action = 0	current_phase = 1	next_phase = 0	reward = -7.159234	array([[-0.2417543 ,  0.15224068]], dtype=float32)
time = 161	action = 1	current_phase = 1	next_phase = 0	reward = -13.633015	array([[-0.24964382,  0.1457283 ]], dtype=float32)
time = 169	action = 0	current_phase = 0	next_phase = 1	reward = -5.099077	array([[-0.16646719, -0.2069377 ]], dtype=float32)
time = 174	action = 1	current_phase = 0	next_phase = 1	reward = -8.051308	array([[-0.14350125, -0.20924552]], dtype=float32)
time = 182	action = 0	current_phase = 1	next_phase = 0	reward = -2.336138	array([[-0.20472427,  0.11240811]], dtype=float32)
time = 187	action = 0	current_phase = 1	next_phase = 0	reward = -3.632890	array([[-0.21186176,  0.12559251]], dtype=float32)
time = 192	action = 0	current_phase = 1	next_phase = 0	reward = -5.834007	array([[-0.2307591 ,  0.13485453]], dtype=float32)
time = 197	action = 1	current_phase = 1	next_phase = 0	reward = -12.876502	array([[-0.24109961,  0.15065143]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -6.138496	array([[-0.17221777, -0.20257376]], dtype=float32)
time = 210	action = 1	current_phase = 0	next_phase = 1	reward = -8.609530	array([[-0.16546024, -0.20856167]], dtype=float32)
time = 218	action = 0	current_phase = 1	next_phase = 0	reward = -2.877850	array([[-0.20543455,  0.10874073]], dtype=float32)
time = 223	action = 0	current_phase = 1	next_phase = 0	reward = -4.272521	array([[-0.20450297,  0.10435969]], dtype=float32)
time = 228	action = 0	current_phase = 1	next_phase = 0	reward = -5.898005	array([[-0.2296896 ,  0.13323437]], dtype=float32)
time = 233	action = 1	current_phase = 1	next_phase = 0	reward = -12.697966	array([[-0.24271923,  0.14861886]], dtype=float32)
time = 241	action = 0	current_phase = 0	next_phase = 1	reward = -5.083413	array([[-0.17177914, -0.20312454]], dtype=float32)
time = 246	action = 1	current_phase = 0	next_phase = 1	reward = -7.360928	array([[-0.1590004 , -0.20968573]], dtype=float32)
time = 254	action = 0	current_phase = 1	next_phase = 0	reward = -3.740676	array([[-0.20084447,  0.10919151]], dtype=float32)
time = 259	action = 0	current_phase = 1	next_phase = 0	reward = -4.026163	array([[-0.21664996,  0.11178114]], dtype=float32)
time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -5.901410	array([[-0.23091026,  0.12378873]], dtype=float32)
time = 269	action = 1	current_phase = 1	next_phase = 0	reward = -12.794754	array([[-0.23882869,  0.1348567 ]], dtype=float32)
time = 277	action = 0	current_phase = 0	next_phase = 1	reward = -6.029974	array([[-0.16674802, -0.19475669]], dtype=float32)
time = 282	action = 1	current_phase = 0	next_phase = 1	reward = -10.401891	array([[-0.15966229, -0.20214733]], dtype=float32)
time = 290	action = 0	current_phase = 1	next_phase = 0	reward = -3.169250	array([[-0.20216615,  0.11663547]], dtype=float32)
time = 295	action = 0	current_phase = 1	next_phase = 0	reward = -3.694678	array([[-0.21359915,  0.12550814]], dtype=float32)
time = 300	action = 0	current_phase = 1	next_phase = 0	reward = -6.459209	array([[-0.23393795,  0.14753781]], dtype=float32)
time = 305	action = 1	current_phase = 1	next_phase = 0	reward = -12.785688	array([[-0.2428467 ,  0.15474668]], dtype=float32)
time = 313	action = 0	current_phase = 0	next_phase = 1	reward = -5.920010	array([[-0.17600411, -0.19518825]], dtype=float32)
time = 318	action = 1	current_phase = 0	next_phase = 1	reward = -9.641846	array([[-0.16496727, -0.20275058]], dtype=float32)
time = 326	action = 0	current_phase = 1	next_phase = 0	reward = -3.948439	array([[-0.1997537,  0.1046663]], dtype=float32)
time = 331	action = 0	current_phase = 1	next_phase = 0	reward = -4.732485	array([[-0.22063136,  0.12810445]], dtype=float32)
time = 336	action = 0	current_phase = 1	next_phase = 0	reward = -7.110633	array([[-0.23019952,  0.13363883]], dtype=float32)
time = 341	action = 1	current_phase = 1	next_phase = 0	reward = -13.174685	array([[-0.24291345,  0.14120014]], dtype=float32)
time = 349	action = 0	current_phase = 0	next_phase = 1	reward = -5.394944	array([[-0.16685182, -0.19448008]], dtype=float32)
time = 354	action = 1	current_phase = 0	next_phase = 1	reward = -10.121369	array([[-0.15696609, -0.2055001 ]], dtype=float32)
time = 362	action = 0	current_phase = 1	next_phase = 0	reward = -3.854563	array([[-0.20337126,  0.10397315]], dtype=float32)
time = 367	action = 0	current_phase = 1	next_phase = 0	reward = -4.498641	array([[-0.22001496,  0.11115801]], dtype=float32)
time = 372	action = 0	current_phase = 1	next_phase = 0	reward = -6.831138	array([[-0.24017142,  0.12188075]], dtype=float32)
time = 377	action = 1	current_phase = 1	next_phase = 0	reward = -12.530608	array([[-0.25244993,  0.1339935 ]], dtype=float32)
time = 385	action = 0	current_phase = 0	next_phase = 1	reward = -5.886057	array([[-0.16271925, -0.19174413]], dtype=float32)
time = 390	action = 1	current_phase = 0	next_phase = 1	reward = -9.827772	array([[-0.1676562 , -0.20208222]], dtype=float32)
time = 398	action = 0	current_phase = 1	next_phase = 0	reward = -3.282344	array([[-0.20431922,  0.10665044]], dtype=float32)
time = 403	action = 0	current_phase = 1	next_phase = 0	reward = -4.060667	array([[-0.21319495,  0.12033178]], dtype=float32)
time = 408	action = 0	current_phase = 1	next_phase = 0	reward = -6.118098	array([[-0.23360808,  0.14089791]], dtype=float32)
time = 413	action = 1	current_phase = 1	next_phase = 0	reward = -12.209968	array([[-0.24344704,  0.15181099]], dtype=float32)
time = 421	action = 0	current_phase = 0	next_phase = 1	reward = -5.230209	array([[-0.16453567, -0.195817  ]], dtype=float32)
time = 426	action = 1	current_phase = 0	next_phase = 1	reward = -8.941972	array([[-0.15196675, -0.19846089]], dtype=float32)
time = 434	action = 0	current_phase = 1	next_phase = 0	reward = -2.656282	array([[-0.20500198,  0.10758777]], dtype=float32)
time = 439	action = 0	current_phase = 1	next_phase = 0	reward = -3.403173	array([[-0.20899555,  0.12222375]], dtype=float32)
time = 444	action = 0	current_phase = 1	next_phase = 0	reward = -5.802663	array([[-0.2242238 ,  0.12454291]], dtype=float32)
time = 449	action = 1	current_phase = 1	next_phase = 0	reward = -11.551930	array([[-0.23770703,  0.13739997]], dtype=float32)
time = 457	action = 0	current_phase = 0	next_phase = 1	reward = -4.999720	array([[-0.16152531, -0.19314301]], dtype=float32)
time = 462	action = 1	current_phase = 0	next_phase = 1	reward = -9.209246	array([[-0.1542497 , -0.20223469]], dtype=float32)
time = 470	action = 0	current_phase = 1	next_phase = 0	reward = -3.728009	array([[-0.20802674,  0.11477428]], dtype=float32)
time = 475	action = 0	current_phase = 1	next_phase = 0	reward = -4.557463	array([[-0.22033264,  0.12616953]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -6.315563	array([[-0.23882224,  0.14516   ]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -12.682132	array([[-0.24781145,  0.15406382]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -5.826005	array([[-0.16885108, -0.19501135]], dtype=float32)
time = 498	action = 1	current_phase = 0	next_phase = 1	reward = -9.209117	array([[-0.15878694, -0.19986424]], dtype=float32)
time = 506	action = 0	current_phase = 1	next_phase = 0	reward = -3.695650	array([[-0.20146321,  0.11881927]], dtype=float32)
time = 511	action = 0	current_phase = 1	next_phase = 0	reward = -3.884010	array([[-0.19947806,  0.11953521]], dtype=float32)
time = 516	action = 0	current_phase = 1	next_phase = 0	reward = -6.128605	array([[-0.21096118,  0.12696917]], dtype=float32)
time = 521	action = 1	current_phase = 1	next_phase = 0	reward = -11.493621	array([[-0.23314802,  0.13319194]], dtype=float32)
time = 529	action = 0	current_phase = 0	next_phase = 1	reward = -4.637371	array([[-0.15832162, -0.1967434 ]], dtype=float32)
time = 534	action = 1	current_phase = 0	next_phase = 1	reward = -8.092384	array([[-0.15729536, -0.20262685]], dtype=float32)
time = 542	action = 0	current_phase = 1	next_phase = 0	reward = -3.092811	array([[-0.2030914 ,  0.10261329]], dtype=float32)Simulation ended at time: 674.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4642ms
 Real time factor: 145.196
 UPS: 6802.886687
Vehicles: 
 Inserted: 438 (Loaded: 621)
 Running: 54
 Waiting: 81

DijkstraRouter answered 20908 queries and explored 4.09 edges on average.
DijkstraRouter spent 4ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 39167 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (1ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 547	action = 0	current_phase = 1	next_phase = 0	reward = -3.787772	array([[-0.21052933,  0.09945289]], dtype=float32)
time = 552	action = 0	current_phase = 1	next_phase = 0	reward = -5.521220	array([[-0.23374018,  0.128275  ]], dtype=float32)
time = 557	action = 1	current_phase = 1	next_phase = 0	reward = -12.302668	array([[-0.24727966,  0.1437645 ]], dtype=float32)
time = 565	action = 0	current_phase = 0	next_phase = 1	reward = -4.950656	array([[-0.1636313 , -0.19123757]], dtype=float32)
time = 570	action = 1	current_phase = 0	next_phase = 1	reward = -7.832476	array([[-0.16372648, -0.2027328 ]], dtype=float32)
time = 578	action = 0	current_phase = 1	next_phase = 0	reward = -3.450212	array([[-0.20286852,  0.11034937]], dtype=float32)
time = 583	action = 0	current_phase = 1	next_phase = 0	reward = -4.318182	array([[-0.21353255,  0.1275604 ]], dtype=float32)
time = 588	action = 0	current_phase = 1	next_phase = 0	reward = -6.079892	array([[-0.23073646,  0.13728109]], dtype=float32)
time = 593	action = 1	current_phase = 1	next_phase = 0	reward = -12.047743	array([[-0.24172911,  0.14379787]], dtype=float32)
time = 601	action = 0	current_phase = 0	next_phase = 1	reward = -5.748381	array([[-0.16324183, -0.19623756]], dtype=float32)
time = 606	action = 1	current_phase = 0	next_phase = 1	reward = -9.803656	array([[-0.15769981, -0.20039584]], dtype=float32)
time = 614	action = 0	current_phase = 1	next_phase = 0	reward = -3.574794	array([[-0.20952749,  0.1175063 ]], dtype=float32)
time = 619	action = 0	current_phase = 1	next_phase = 0	reward = -3.766703	array([[-0.22189084,  0.11726264]], dtype=float32)
time = 624	action = 0	current_phase = 1	next_phase = 0	reward = -5.572907	array([[-0.23055692,  0.14236784]], dtype=float32)
time = 629	action = 1	current_phase = 1	next_phase = 0	reward = -12.190373	array([[-0.23892021,  0.14957395]], dtype=float32)
time = 637	action = 0	current_phase = 0	next_phase = 1	reward = -5.239883	array([[-0.16728976, -0.19119617]], dtype=float32)
time = 642	action = 1	current_phase = 0	next_phase = 1	reward = -8.814443	array([[-0.16887529, -0.2064337 ]], dtype=float32)
time = 650	action = 0	current_phase = 1	next_phase = 0	reward = -3.609242	array([[-0.19731343,  0.10473561]], dtype=float32)
time = 655	action = 0	current_phase = 1	next_phase = 0	reward = -4.359082	array([[-0.2082651 ,  0.10842982]], dtype=float32)
time = 660	action = 0	current_phase = 1	next_phase = 0	reward = -6.090684	array([[-0.22895083,  0.1222259 ]], dtype=float32)
time = 665	action = 1	current_phase = 1	next_phase = 0	reward = -11.840232	array([[-0.24391732,  0.13791871]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:39167 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.05912429, -0.2456197 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.06810096, -0.23193525]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.336063	array([[-0.06943521, -0.22346745]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -1.884166	array([[-0.22438538,  0.11550364]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.570094	array([[-0.23697639,  0.13485163]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -2.302475	array([[-0.23772225,  0.13987413]], dtype=float32)
time = 53	action = 0	current_phase = 1	next_phase = 0	reward = -3.113235	array([[-0.23869981,  0.14563867]], dtype=float32)
time = 58	action = 1	current_phase = 1	next_phase = 0	reward = -5.768793	array([[-0.23909125,  0.15220827]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -0.228136	array([[-0.09463452, -0.22250608]], dtype=float32)
time = 71	action = 1	current_phase = 0	next_phase = 1	reward = -2.801168	array([[-0.08750363, -0.24430972]], dtype=float32)
time = 79	action = 0	current_phase = 1	next_phase = 0	reward = -2.430852	array([[-0.22103529,  0.16949861]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -3.223565	array([[-0.23749907,  0.17085414]], dtype=float32)
time = 89	action = 0	current_phase = 1	next_phase = 0	reward = -3.901144	array([[-0.23814201,  0.17344013]], dtype=float32)
time = 94	action = 0	current_phase = 1	next_phase = 0	reward = -5.171454	array([[-0.23335043,  0.16315407]], dtype=float32)
time = 99	action = 1	current_phase = 1	next_phase = 0	reward = -9.444148	array([[-0.23255022,  0.15640745]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -2.802718	array([[-0.14185643, -0.21703924]], dtype=float32)
time = 112	action = 1	current_phase = 0	next_phase = 1	reward = -3.215252	array([[-0.10376023, -0.22780469]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -1.894316	array([[-0.19271964,  0.09305272]], dtype=float32)
time = 125	action = 0	current_phase = 1	next_phase = 0	reward = -3.998505	array([[-0.21123062,  0.12471582]], dtype=float32)
time = 130	action = 0	current_phase = 1	next_phase = 0	reward = -5.889010	array([[-0.23252305,  0.13730976]], dtype=float32)
time = 135	action = 0	current_phase = 1	next_phase = 0	reward = -7.378131	array([[-0.24360181,  0.14655957]], dtype=float32)
time = 140	action = 1	current_phase = 1	next_phase = 0	reward = -13.205050	array([[-0.25162107,  0.14820626]], dtype=float32)
time = 148	action = 0	current_phase = 0	next_phase = 1	reward = -4.541980	array([[-0.16008264, -0.20122813]], dtype=float32)
time = 153	action = 1	current_phase = 0	next_phase = 1	reward = -7.743669	array([[-0.13955201, -0.21183063]], dtype=float32)
time = 161	action = 0	current_phase = 1	next_phase = 0	reward = -2.771885	array([[-0.21467869,  0.130525  ]], dtype=float32)
time = 166	action = 0	current_phase = 1	next_phase = 0	reward = -3.724030	array([[-0.21775955,  0.14035395]], dtype=float32)
time = 171	action = 0	current_phase = 1	next_phase = 0	reward = -6.099024	array([[-0.22953263,  0.1574454 ]], dtype=float32)
time = 176	action = 0	current_phase = 1	next_phase = 0	reward = -8.422144	array([[-0.23779136,  0.15754697]], dtype=float32)
time = 181	action = 1	current_phase = 1	next_phase = 0	reward = -16.065674	array([[-0.24482961,  0.15247083]], dtype=float32)
time = 189	action = 0	current_phase = 0	next_phase = 1	reward = -6.383103	array([[-0.1819208 , -0.20919031]], dtype=float32)
time = 194	action = 1	current_phase = 0	next_phase = 1	reward = -9.332539	array([[-0.15526481, -0.21403195]], dtype=float32)
time = 202	action = 0	current_phase = 1	next_phase = 0	reward = -2.627271	array([[-0.2021859 ,  0.10881975]], dtype=float32)
time = 207	action = 0	current_phase = 1	next_phase = 0	reward = -4.310036	array([[-0.2070777,  0.1193499]], dtype=float32)
time = 212	action = 0	current_phase = 1	next_phase = 0	reward = -6.659120	array([[-0.22159088,  0.13486205]], dtype=float32)
time = 217	action = 0	current_phase = 1	next_phase = 0	reward = -8.477779	array([[-0.24480322,  0.1472218 ]], dtype=float32)
time = 222	action = 1	current_phase = 1	next_phase = 0	reward = -16.581231	array([[-0.25603405,  0.14670542]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = -5.690493	array([[-0.17442955, -0.2018498 ]], dtype=float32)
time = 235	action = 1	current_phase = 0	next_phase = 1	reward = -8.978754	array([[-0.16447107, -0.20876063]], dtype=float32)
time = 243	action = 0	current_phase = 1	next_phase = 0	reward = -3.498741	array([[-0.19767702,  0.09082587]], dtype=float32)
time = 248	action = 0	current_phase = 1	next_phase = 0	reward = -4.404649	array([[-0.21252126,  0.09980984]], dtype=float32)
time = 253	action = 0	current_phase = 1	next_phase = 0	reward = -6.436460	array([[-0.23032077,  0.11608756]], dtype=float32)
time = 258	action = 0	current_phase = 1	next_phase = 0	reward = -8.251378	array([[-0.250668  ,  0.12829693]], dtype=float32)
time = 263	action = 1	current_phase = 1	next_phase = 0	reward = -15.760711	array([[-0.25471354,  0.14016655]], dtype=float32)
time = 271	action = 0	current_phase = 0	next_phase = 1	reward = -7.089060	array([[-0.17400768, -0.19494632]], dtype=float32)
time = 276	action = 1	current_phase = 0	next_phase = 1	reward = -9.431235	array([[-0.16245778, -0.2009301 ]], dtype=float32)
time = 284	action = 0	current_phase = 1	next_phase = 0	reward = -3.148425	array([[-0.21368387,  0.12270561]], dtype=float32)
time = 289	action = 0	current_phase = 1	next_phase = 0	reward = -3.894246	array([[-0.21262708,  0.12088746]], dtype=float32)
time = 294	action = 0	current_phase = 1	next_phase = 0	reward = -5.910662	array([[-0.22015156,  0.14000218]], dtype=float32)
time = 299	action = 0	current_phase = 1	next_phase = 0	reward = -7.798679	array([[-0.23174226,  0.14642763]], dtype=float32)
time = 304	action = 1	current_phase = 1	next_phase = 0	reward = -14.866650	array([[-0.24387741,  0.1491427 ]], dtype=float32)
time = 312	action = 0	current_phase = 0	next_phase = 1	reward = -6.319523	array([[-0.17234953, -0.19804516]], dtype=float32)
time = 317	action = 1	current_phase = 0	next_phase = 1	reward = -10.183227	array([[-0.158554  , -0.20018613]], dtype=float32)
time = 325	action = 0	current_phase = 1	next_phase = 0	reward = -3.816763	array([[-0.20995763,  0.12448153]], dtype=float32)
time = 330	action = 0	current_phase = 1	next_phase = 0	reward = -4.937660	array([[-0.21264014,  0.13045849]], dtype=float32)
time = 335	action = 0	current_phase = 1	next_phase = 0	reward = -6.472964	array([[-0.23027891,  0.14233994]], dtype=float32)
time = 340	action = 0	current_phase = 1	next_phase = 0	reward = -7.378329	array([[-0.2422351 ,  0.14463367]], dtype=float32)
time = 345	action = 1	current_phase = 1	next_phase = 0	reward = -12.165256	array([[-0.24885103,  0.14797738]], dtype=float32)
time = 353	action = 0	current_phase = 0	next_phase = 1	reward = -3.542872	array([[-0.14445548, -0.18790343]], dtype=float32)
time = 358	action = 1	current_phase = 0	next_phase = 1	reward = -7.645082	array([[-0.14317654, -0.20480564]], dtype=float32)
time = 366	action = 0	current_phase = 1	next_phase = 0	reward = -3.715650	array([[-0.19900669,  0.08561155]], dtype=float32)
time = 371	action = 0	current_phase = 1	next_phase = 0	reward = -4.060230	array([[-0.21222317,  0.09951422]], dtype=float32)
time = 376	action = 0	current_phase = 1	next_phase = 0	reward = -6.178007	array([[-0.23087111,  0.12281323]], dtype=float32)
time = 381	action = 0	current_phase = 1	next_phase = 0	reward = -8.601411	array([[-0.25063038,  0.13579324]], dtype=float32)
time = 386	action = 1	current_phase = 1	next_phase = 0	reward = -15.615115	array([[-0.25662825,  0.14317581]], dtype=float32)
time = 394	action = 0	current_phase = 0	next_phase = 1	reward = -6.905612	array([[-0.16768812, -0.19140317]], dtype=float32)
time = 399	action = 1	current_phase = 0	next_phase = 1	reward = -10.191773	array([[-0.1611948, -0.1985372]], dtype=float32)
time = 407	action = 0	current_phase = 1	next_phase = 0	reward = -3.662010	array([[-0.20431817,  0.11307177]], dtype=float32)
time = 412	action = 0	current_phase = 1	next_phase = 0	reward = -4.363150	array([[-0.21638593,  0.1270489 ]], dtype=float32)
time = 417	action = 0	current_phase = 1	next_phase = 0	reward = -6.348466	array([[-0.23587205,  0.13074045]], dtype=float32)
time = 422	action = 0	current_phase = 1	next_phase = 0	reward = -8.542619	array([[-0.24571846,  0.13577564]], dtype=float32)
time = 427	action = 1	current_phase = 1	next_phase = 0	reward = -15.615264	array([[-0.24496287,  0.14643086]], dtype=float32)
time = 435	action = 0	current_phase = 0	next_phase = 1	reward = -6.098094	array([[-0.17370212, -0.19633275]], dtype=float32)
time = 440	action = 1	current_phase = 0	next_phase = 1	reward = -9.404287	array([[-0.16161248, -0.20063668]], dtype=float32)
time = 448	action = 0	current_phase = 1	next_phase = 0	reward = -3.129881	array([[-0.20685615,  0.11080292]], dtype=float32)
time = 453	action = 0	current_phase = 1	next_phase = 0	reward = -4.129767	array([[-0.2171154,  0.1187567]], dtype=float32)
time = 458	action = 0	current_phase = 1	next_phase = 0	reward = -6.313382	array([[-0.22737345,  0.13585305]], dtype=float32)
time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -8.760640	array([[-0.2373375,  0.1354409]], dtype=float32)
time = 468	action = 1	current_phase = 1	next_phase = 0	reward = -15.124485	array([[-0.24663745,  0.14116701]], dtype=float32)
time = 476	action = 0	current_phase = 0	next_phase = 1	reward = -6.269176	array([[-0.17782596, -0.19925824]], dtype=float32)
time = 481	action = 1	current_phase = 0	next_phase = 1	reward = -10.386480	array([[-0.16169137, -0.20126416]], dtype=float32)
time = 489	action = 0	current_phase = 1	next_phase = 0	reward = -3.815830	array([[-0.21494581,  0.13428256]], dtype=float32)
time = 494	action = 0	current_phase = 1	next_phase = 0	reward = -4.252610	array([[-0.22024514,  0.14074147]], dtype=float32)
time = 499	action = 0	current_phase = 1	next_phase = 0	reward = -5.041767	array([[-0.22526047,  0.15170285]], dtype=float32)
time = 504	action = 0	current_phase = 1	next_phase = 0	reward = -6.467093	array([[-0.22824416,  0.1550877 ]], dtype=float32)
time = 509	action = 1	current_phase = 1	next_phase = 0	reward = -9.725679	array([[-0.21976453,  0.14945573]], dtype=float32)
time = 517	action = 0	current_phase = 0	next_phase = 1	reward = -2.496743	array([[-0.12746231, -0.1852161 ]], dtype=float32)
time = 522	action = 1	current_phase = 0	next_phase = 1	reward = -6.009052	array([[-0.12274484, -0.18981124]], dtype=float32)
time = 530	action = 0	current_phase = 1	next_phase = 0	reward = -3.499656	array([[-0.19875728,  0.09813228]], dtype=float32)
time = 535	action = 0	current_phase = 1	next_phase = 0	reward = -3.703378	array([[-0.21770468,  0.09395452]], dtype=float32)
time = 540	action = 0	current_phase = 1	next_phase = 0	reward = -6.240760	array([[-0.22763322,  0.11110816]], dtype=float32)
time = 545	action = 0	current_phase = 1	next_phase = 0	reward = -8.720324	array([[-0.24362537,  0.13203758]], dtype=float32)
time = 550	action = 1	current_phase = 1	next_phase = 0	reward = -15.820262	array([[-0.24922298,  0.13944751]], dtype=float32)
time = 558	action = 0	current_phase = 0	next_phase = 1	reward = -7.495204	array([[-0.17894174, -0.1970659 ]], dtype=float32)
time = 563	action = 1	current_phase = 0	next_phase = 1	reward = -11.780379	array([[-0.18116243, -0.20373483]], dtype=float32)
time = 571	action = 0	current_phase = 1	next_phase = 0	reward = -3.521216	array([[-0.21082258,  0.11169587]], dtype=float32)
time = 576	action = 0	current_phase = 1	next_phase = 0	reward = -4.212973	array([[-0.21569352,  0.12594604]], dtype=float32)
time = 581	action = 0	current_phase = 1	next_phase = 0	reward = -6.342792	array([[-0.2326197 ,  0.14063525]], dtype=float32)
time = 586	action = 0	current_phase = 1	next_phase = 0	reward = -8.990713	array([[-0.24692088,  0.15308596]], dtype=float32)
time = 591	action = 1	current_phase = 1	next_phase = 0	reward = -15.880650	array([[-0.24961367,  0.15415068]], dtype=float32)
time = 599	action = 0	current_phase = 0	next_phase = 1	reward = -6.807148	array([[-0.17462626, -0.19784456]], dtype=float32)
time = 604	action = 1	current_phase = 0	next_phase = 1	reward = -10.710090	array([[-0.16008843, -0.20188847]], dtype=float32)
time = 612	action = 0	current_phase = 1	next_phase = 0	reward = -3.775964	array([[-0.20961425,  0.11972435]], dtype=float32)
time = 617	action = 0	current_phase = 1	next_phase = 0	reward = -4.271501	array([[-0.21226743,  0.10565443]], dtype=float32)
time = 622	action = 0	current_phase = 1	next_phase = 0	reward = -7.036030	array([[-0.22153918,  0.1350728 ]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -8.846704	array([[-0.2420355 ,  0.13898626]], dtype=float32)
time = 632	action = 1	current_phase = 1	next_phase = 0	reward = -15.649218	array([[-0.25727212,  0.14124328]], dtype=float32)
time = 640	action = 0	current_phase = 0	next_phase = 1	reward = -6.085631	array([[-0.16667268, -0.19160485]], dtype=float32)
time = 645	action = 1	current_phase = 0	next_phase = 1	reward = -9.896282	array([[-0.16032809, -0.20125741]], dtype=float32)
time = 653	action = 0	current_phase = 1	next_phase = 0	reward = -4.086768	array([[-0.20719835,  0.11645853]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -4.177553	array([[-0.21332751,  0.11368385]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 4613ms
 Real time factor: 145.025
 UPS: 6774.333406
Vehicles: 
 Inserted: 420 (Loaded: 621)
 Running: 51
 Waiting: 96

DijkstraRouter answered 22672 queries and explored 3.97 edges on average.
DijkstraRouter spent 5ms answering queries (0.00ms on average).

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -6.137776	array([[-0.23354526,  0.13368118]], dtype=float32)
Terminal occured. Episode end.
Train on 1113 samples, validate on 478 samples
Epoch 1/500
 - 2s - loss: 35.3812 - val_loss: 28.3861
Epoch 2/500
 - 1s - loss: 24.0348 - val_loss: 19.4789
Epoch 3/500
 - 1s - loss: 16.1811 - val_loss: 12.8171
Epoch 4/500
 - 1s - loss: 10.6642 - val_loss: 8.4178
Epoch 5/500
 - 1s - loss: 7.1346 - val_loss: 5.6420
Epoch 6/500
 - 1s - loss: 4.9206 - val_loss: 3.9154
Epoch 7/500
 - 1s - loss: 3.5280 - val_loss: 2.8322
Epoch 8/500
 - 1s - loss: 2.6861 - val_loss: 2.1589
Epoch 9/500
 - 1s - loss: 2.0646 - val_loss: 1.6597
Epoch 10/500
 - 1s - loss: 1.7896 - val_loss: 1.5116
Epoch 11/500
 - 1s - loss: 1.6497 - val_loss: 1.4425
Epoch 12/500
 - 1s - loss: 1.5638 - val_loss: 1.3777
Epoch 13/500
 - 1s - loss: 1.5086 - val_loss: 1.3265
Epoch 14/500
 - 1s - loss: 1.4280 - val_loss: 1.2554
Epoch 15/500
 - 1s - loss: 1.3593 - val_loss: 1.2028
Epoch 16/500
 - 1s - loss: 1.2785 - val_loss: 1.1690
Epoch 17/500
 - 1s - loss: 1.2238 - val_loss: 1.1312
Epoch 18/500
 - 1s - loss: 1.1902 - val_loss: 1.0980
Epoch 19/500
 - 1s - loss: 1.1280 - val_loss: 1.0625
Epoch 20/500
 - 1s - loss: 1.0932 - val_loss: 1.0653
Epoch 21/500
 - 1s - loss: 1.0404 - val_loss: 1.0163
Epoch 22/500
 - 1s - loss: 1.0033 - val_loss: 0.9950
Epoch 23/500
 - 1s - loss: 0.9776 - val_loss: 0.9816
Epoch 24/500
 - 1s - loss: 0.9619 - val_loss: 1.0022
Epoch 25/500
 - 1s - loss: 0.9284 - val_loss: 0.9714
Epoch 26/500
 - 1s - loss: 0.8914 - val_loss: 0.9340
Epoch 27/500
 - 1s - loss: 0.8780 - val_loss: 0.9370
Epoch 28/500
 - 1s - loss: 0.8470 - val_loss: 0.9134
Epoch 29/500
 - 1s - loss: 0.8138 - val_loss: 0.9247
Epoch 30/500
 - 1s - loss: 0.7969 - val_loss: 0.8908
Epoch 31/500
 - 1s - loss: 0.7927 - val_loss: 0.9056
Epoch 32/500
 - 1s - loss: 0.7422 - val_loss: 0.8975
Epoch 33/500
 - 1s - loss: 0.7431 - val_loss: 0.8953
Epoch 34/500
 - 1s - loss: 0.7335 - val_loss: 0.8613
Epoch 35/500
 - 1s - loss: 0.7095 - val_loss: 0.9155
Epoch 36/500
 - 1s - loss: 0.6709 - val_loss: 0.8715
Epoch 37/500
 - 1s - loss: 0.6688 - val_loss: 0.8394
Epoch 38/500
 - 1s - loss: 0.6375 - val_loss: 0.8565
Epoch 39/500
 - 1s - loss: 0.6403 - val_loss: 0.8382
Epoch 40/500
 - 1s - loss: 0.6040 - val_loss: 0.8495
Epoch 41/500
 - 1s - loss: 0.5844 - val_loss: 0.8284
Epoch 42/500
 - 1s - loss: 0.5888 - val_loss: 0.8139
Epoch 43/500
 - 1s - loss: 0.5658 - val_loss: 0.7819
Epoch 44/500
 - 1s - loss: 0.5425 - val_loss: 0.7672
Epoch 45/500
 - 1s - loss: 0.5408 - val_loss: 0.7725
Epoch 46/500
 - 1s - loss: 0.5006 - val_loss: 0.7789
Epoch 47/500
 - 1s - loss: 0.4986 - val_loss: 0.7582
Epoch 48/500
 - 1s - loss: 0.4890 - val_loss: 0.7875
Epoch 49/500
 - 1s - loss: 0.4810 - val_loss: 0.7651
Epoch 50/500
 - 1s - loss: 0.4911 - val_loss: 0.7446
Epoch 51/500
 - 1s - loss: 0.4637 - val_loss: 0.7435
Epoch 52/500
 - 1s - loss: 0.4377 - val_loss: 0.7690
Epoch 53/500
 - 1s - loss: 0.4236 - val_loss: 0.7064
Epoch 54/500
 - 1s - loss: 0.4098 - val_loss: 0.7198
Epoch 55/500
 - 1s - loss: 0.3839 - val_loss: 0.7448
Epoch 56/500
 - 1s - loss: 0.3961 - val_loss: 0.7350
Epoch 57/500
 - 1s - loss: 0.3761 - val_loss: 0.7469
Epoch 58/500
 - 1s - loss: 0.3752 - val_loss: 0.7000
Epoch 59/500
 - 1s - loss: 0.3677 - val_loss: 0.6777
Epoch 60/500
 - 1s - loss: 0.3295 - val_loss: 0.7014
Epoch 61/500
 - 1s - loss: 0.3612 - val_loss: 0.7157
Epoch 62/500
 - 1s - loss: 0.3318 - val_loss: 0.6878
Epoch 63/500
 - 1s - loss: 0.3317 - val_loss: 0.6587
Epoch 64/500
 - 1s - loss: 0.3239 - val_loss: 0.6755
Epoch 65/500
 - 1s - loss: 0.3107 - val_loss: 0.6793
Epoch 66/500
 - 1s - loss: 0.2953 - val_loss: 0.6576
Epoch 67/500
 - 1s - loss: 0.3249 - val_loss: 0.6644
Epoch 68/500
 - 1s - loss: 0.3236 - val_loss: 0.6518
Epoch 69/500
 - 1s - loss: 0.3151 - val_loss: 0.6683
Epoch 70/500
 - 1s - loss: 0.2919 - val_loss: 0.6578
Epoch 71/500
 - 1s - loss: 0.2999 - val_loss: 0.6577
Epoch 72/500
 - 1s - loss: 0.3069 - val_loss: 0.6904
Epoch 73/500
 - 1s - loss: 0.2923 - val_loss: 0.6698
Epoch 74/500
 - 1s - loss: 0.3085 - val_loss: 0.6931
Epoch 75/500
 - 1s - loss: 0.2910 - val_loss: 0.6576
Epoch 76/500
 - 1s - loss: 0.2740 - val_loss: 0.6906
Epoch 77/500
 - 1s - loss: 0.2808 - val_loss: 0.6675
Epoch 78/500
 - 1s - loss: 0.2770 - val_loss: 0.6301
Epoch 79/500
 - 1s - loss: 0.2745 - val_loss: 0.6466
Epoch 80/500
 - 1s - loss: 0.2706 - val_loss: 0.6264
Epoch 81/500
 - 1s - loss: 0.2720 - val_loss: 0.6413
Epoch 82/500
 - 1s - loss: 0.2657 - val_loss: 0.6259
Epoch 83/500
 - 1s - loss: 0.2737 - val_loss: 0.6382
Epoch 84/500
 - 1s - loss: 0.2422 - val_loss: 0.6360
Epoch 85/500
 - 1s - loss: 0.2501 - val_loss: 0.6282
Epoch 86/500
 - 1s - loss: 0.2801 - val_loss: 0.6248
Epoch 87/500
 - 1s - loss: 0.2516 - val_loss: 0.6571
Epoch 88/500
 - 1s - loss: 0.2482 - val_loss: 0.6639
Epoch 89/500
 - 1s - loss: 0.2531 - val_loss: 0.6230
Epoch 90/500
 - 1s - loss: 0.2429 - val_loss: 0.6512
Epoch 91/500
 - 1s - loss: 0.2491 - val_loss: 0.6363
Epoch 92/500
 - 1s - loss: 0.2493 - val_loss: 0.6532
Epoch 93/500
 - 1s - loss: 0.2497 - val_loss: 0.6280
Epoch 94/500
 - 1s - loss: 0.2353 - val_loss: 0.6583
Epoch 95/500
 - 1s - loss: 0.2380 - val_loss: 0.6304
Epoch 96/500
 - 1s - loss: 0.2539 - val_loss: 0.6574
Epoch 97/500
 - 1s - loss: 0.2442 - val_loss: 0.6365
Epoch 98/500
 - 1s - loss: 0.2443 - val_loss: 0.6645
Epoch 99/500
 - 1s - loss: 0.2551 - val_loss: 0.6715
Loading configuration... done.
***Starting server on port 40981 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford (1)/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
length of memory (state 0, action 0): 507, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
END
Could not connect to TraCI server at localhost:40981 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = -0.182184	array([[-0.20970145, -8.461645  ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.505929	array([[-0.334952, -8.402569]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.648799	array([[-2.6161976, -5.237165 ]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -1.838054	array([[-3.634674 , -4.3638444]], dtype=float32)
time = 40	action = 0	current_phase = 0	next_phase = 1	reward = -2.299206	array([[-2.7776704, -7.187255 ]], dtype=float32)
time = 45	action = 0	current_phase = 0	next_phase = 1	reward = -1.751084	array([[-1.8370118, -7.635858 ]], dtype=float32)
time = 50	action = 0	current_phase = 0	next_phase = 1	reward = 0.233842	array([[-1.0093502, -7.674127 ]], dtype=float32)
time = 55	action = 0	current_phase = 0	next_phase = 1	reward = -0.800559	array([[-2.5408664, -6.5845923]], dtype=float32)
time = 60	action = 0	current_phase = 0	next_phase = 1	reward = -2.365444	array([[-3.225553 , -5.6329174]], dtype=float32)
time = 65	action = 0	current_phase = 0	next_phase = 1	reward = -2.420884	array([[-3.539423, -7.210044]], dtype=float32)
time = 70	action = 0	current_phase = 0	next_phase = 1	reward = -1.535422	array([[-4.224592 , -7.2356524]], dtype=float32)
time = 75	action = 0	current_phase = 0	next_phase = 1	reward = -0.540902	array([[-1.0114952, -7.944578 ]], dtype=float32)
time = 80	action = 0	current_phase = 0	next_phase = 1	reward = -0.761735	array([[-1.0368936, -7.5939384]], dtype=float32)
time = 85	action = 0	current_phase = 0	next_phase = 1	reward = -0.753430	array([[-2.273728 , -5.7026224]], dtype=float32)
time = 90	action = 0	current_phase = 0	next_phase = 1	reward = -1.698959	array([[-1.9570973, -7.110452 ]], dtype=float32)
time = 95	action = 0	current_phase = 0	next_phase = 1	reward = -2.974566	array([[-1.9322488, -7.9927177]], dtype=float32)
time = 100	action = 0	current_phase = 0	next_phase = 1	reward = -4.697869	array([[-2.9407625, -7.667075 ]], dtype=float32)
time = 105	action = 0	current_phase = 0	next_phase = 1	reward = -5.281634	array([[-3.8421364, -8.050142 ]], dtype=float32)
time = 110	action = 0	current_phase = 0	next_phase = 1	reward = -2.570614	array([[-3.8875713, -8.330169 ]], dtype=float32)
time = 115	action = 0	current_phase = 0	next_phase = 1	reward = -0.856316	array([[-2.4069867, -7.5693626]], dtype=float32)
time = 120	action = 0	current_phase = 0	next_phase = 1	reward = -0.079825	array([[-2.7935395, -7.172069 ]], dtype=float32)
time = 125	action = 0	current_phase = 0	next_phase = 1	reward = -0.544035	array([[-3.2519875, -6.996444 ]], dtype=float32)
time = 130	action = 0	current_phase = 0	next_phase = 1	reward = -1.961026	array([[-4.336668 , -5.1882963]], dtype=float32)
time = 135	action = 0	current_phase = 0	next_phase = 1	reward = -3.021008	array([[-4.5644712, -6.6326795]], dtype=float32)
time = 140	action = 0	current_phase = 0	next_phase = 1	reward = -4.505197	array([[-4.644102 , -7.9960666]], dtype=float32)
time = 145	action = 0	current_phase = 0	next_phase = 1	reward = -2.976846	array([[-6.449472, -9.378475]], dtype=float32)
time = 150	action = 0	current_phase = 0	next_phase = 1	reward = -0.657546	array([[-3.2318187, -9.10328  ]], dtype=float32)
time = 155	action = 0	current_phase = 0	next_phase = 1	reward = 0.837433	array([[-1.6891135, -6.762201 ]], dtype=float32)
time = 160	action = 0	current_phase = 0	next_phase = 1	reward = 0.550175	array([[-1.3202351, -7.9645543]], dtype=float32)
time = 165	action = 0	current_phase = 0	next_phase = 1	reward = -0.606037	array([[-1.6654814, -6.9788513]], dtype=float32)
time = 170	action = 0	current_phase = 0	next_phase = 1	reward = -2.235313	array([[-1.8854773, -6.84215  ]], dtype=float32)
time = 175	action = 0	current_phase = 0	next_phase = 1	reward = -3.948089	array([[-3.1078606, -6.9642425]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -4.146692	array([[-3.1447854, -8.520326 ]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.303229	array([[-3.3203187, -8.236604 ]], dtype=float32)
time = 190	action = 0	current_phase = 0	next_phase = 1	reward = -0.028810	array([[-3.228766 , -7.1218414]], dtype=float32)
time = 195	action = 0	current_phase = 0	next_phase = 1	reward = 0.514332	array([[-2.0221462, -7.596967 ]], dtype=float32)
time = 200	action = 0	current_phase = 0	next_phase = 1	reward = 0.354684	array([[-2.721561 , -6.9200068]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -1.365603	array([[-3.4611626, -7.3523993]], dtype=float32)
time = 210	action = 0	current_phase = 0	next_phase = 1	reward = -2.466132	array([[-4.469794 , -6.7829313]], dtype=float32)
time = 215	action = 0	current_phase = 0	next_phase = 1	reward = -4.534681	array([[-5.121016 , -6.9527636]], dtype=float32)
time = 220	action = 0	current_phase = 0	next_phase = 1	reward = -4.701878	array([[-5.1304016, -9.714214 ]], dtype=float32)
time = 225	action = 0	current_phase = 0	next_phase = 1	reward = -2.331045	array([[ -3.6737394, -11.982669 ]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = -0.693261	array([[-3.6362658, -8.118082 ]], dtype=float32)
time = 235	action = 0	current_phase = 0	next_phase = 1	reward = 0.234827	array([[-3.2890224, -7.0456486]], dtype=float32)
time = 240	action = 0	current_phase = 0	next_phase = 1	reward = -0.560455	array([[-3.056549 , -7.3816214]], dtype=float32)
time = 245	action = 0	current_phase = 0	next_phase = 1	reward = -2.009452	array([[-3.3350348, -6.691649 ]], dtype=float32)
time = 250	action = 0	current_phase = 0	next_phase = 1	reward = -3.424135	array([[-3.3351583, -6.533433 ]], dtype=float32)
time = 255	action = 0	current_phase = 0	next_phase = 1	reward = -4.937423	array([[-4.0118246, -7.2667575]], dtype=float32)
time = 260	action = 0	current_phase = 0	next_phase = 1	reward = -4.819693	array([[-4.9054565, -7.681726 ]], dtype=float32)
time = 265	action = 0	current_phase = 0	next_phase = 1	reward = -1.891715	array([[-4.145875, -7.853125]], dtype=float32)
time = 270	action = 0	current_phase = 0	next_phase = 1	reward = -0.136670	array([[-3.7042937, -6.5125623]], dtype=float32)
time = 275	action = 0	current_phase = 0	next_phase = 1	reward = 0.201603	array([[-3.8385148, -5.872543 ]], dtype=float32)
time = 280	action = 0	current_phase = 0	next_phase = 1	reward = -0.236399	array([[-3.9876652, -4.8652577]], dtype=float32)
time = 285	action = 0	current_phase = 0	next_phase = 1	reward = -0.573153	array([[-3.948092, -6.723223]], dtype=float32)
time = 290	action = 0	current_phase = 0	next_phase = 1	reward = -1.529105	array([[-4.524982 , -6.4702134]], dtype=float32)
time = 295	action = 0	current_phase = 0	next_phase = 1	reward = -2.433874	array([[-4.2841287, -5.976753 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 1s - loss: 3.0279 - val_loss: 1.8408
Epoch 2/50
 - 1s - loss: 2.0931 - val_loss: 1.4928
Epoch 3/50
 - 1s - loss: 1.7536 - val_loss: 1.3456
Epoch 4/50
 - 1s - loss: 1.5035 - val_loss: 1.3131
Epoch 5/50
 - 1s - loss: 1.3692 - val_loss: 1.1297
Epoch 6/50
 - 1s - loss: 1.2678 - val_loss: 1.1346
Epoch 7/50
 - 1s - loss: 1.0949 - val_loss: 1.1168
Epoch 8/50
 - 1s - loss: 1.0955 - val_loss: 0.9889
Epoch 9/50
 - 1s - loss: 0.8762 - val_loss: 1.0668
Epoch 10/50
 - 1s - loss: 1.0445 - val_loss: 0.9174
Epoch 11/50
 - 1s - loss: 0.9250 - val_loss: 0.9918
Epoch 12/50
 - 1s - loss: 0.8824 - val_loss: 0.8719
Epoch 13/50
 - 1s - loss: 0.7442 - val_loss: 0.9183
Epoch 14/50
 - 1s - loss: 0.7938 - val_loss: 0.8678
Epoch 15/50
 - 1s - loss: 0.7381 - val_loss: 0.8712
Epoch 16/50
 - 1s - loss: 0.7397 - val_loss: 0.8867
Epoch 17/50
 - 1s - loss: 0.7041 - val_loss: 0.8923
Epoch 18/50
 - 1s - loss: 0.6453 - val_loss: 0.8078
Epoch 19/50
 - 1s - loss: 0.6137 - val_loss: 0.8127
Epoch 20/50
 - 1s - loss: 0.6627 - val_loss: 0.9678
Epoch 21/50
 - 1s - loss: 0.5669 - val_loss: 0.8605
Epoch 22/50
 - 1s - loss: 0.6158 - val_loss: 0.8301
Epoch 23/50
 - 1s - loss: 0.5738 - val_loss: 0.8338
Epoch 24/50
 - 1s - loss: 0.5903 - val_loss: 0.8640
Epoch 25/50
 - 1s - loss: 0.5933 - val_loss: 0.8215
Epoch 26/50
 - 1s - loss: 0.4970 - val_loss: 0.8184
Epoch 27/50
 - 1s - loss: 0.5227 - val_loss: 0.8070
Epoch 28/50
 - 1s - loss: 0.5212 - val_loss: 0.8643
Epoch 29/50
 - 1s - loss: 0.5157 - val_loss: 0.8130
Epoch 30/50
 - 1s - loss: 0.4665 - val_loss: 0.8240
Epoch 31/50
 - 1s - loss: 0.4516 - val_loss: 0.8381
Epoch 32/50
 - 1s - loss: 0.5168 - val_loss: 0.8067
Epoch 33/50
 - 1s - loss: 0.4966 - val_loss: 0.8702
Epoch 34/50
 - 1s - loss: 0.5019 - val_loss: 0.8002
Epoch 35/50
 - 1s - loss: 0.4459 - val_loss: 0.7301
Epoch 36/50
 - 1s - loss: 0.4843 - val_loss: 0.7978
Epoch 37/50
 - 1s - loss: 0.4701 - val_loss: 0.7346
Epoch 38/50
 - 1s - loss: 0.4075 - val_loss: 0.7841
Epoch 39/50
 - 1s - loss: 0.3997 - val_loss: 0.7446
Epoch 40/50
 - 1s - loss: 0.4402 - val_loss: 0.7494
Epoch 41/50
 - 1s - loss: 0.3997 - val_loss: 0.7688
Epoch 42/50
 - 1s - loss: 0.3697 - val_loss: 0.8898
Epoch 43/50
 - 1s - loss: 0.3900 - val_loss: 0.7551
Epoch 44/50
 - 1s - loss: 0.4037 - val_loss: 0.7124
Epoch 45/50
 - 1s - loss: 0.3670 - val_loss: 0.7496
Epoch 46/50
 - 1s - loss: 0.3328 - val_loss: 0.7957
Epoch 47/50
 - 1s - loss: 0.3500 - val_loss: 0.8155
Epoch 48/50
 - 1s - loss: 0.3706 - val_loss: 0.7764
Epoch 49/50
 - 1s - loss: 0.3851 - val_loss: 0.8153
Epoch 50/50
 - 1s - loss: 0.3421 - val_loss: 0.7742
length of memory (state 0, action 0): 563, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 300	action = 0	current_phase = 0	next_phase = 1	reward = -0.682299	array([[-5.3852644, -5.642796 ]], dtype=float32)
time = 305	action = 0	current_phase = 0	next_phase = 1	reward = 0.612708	array([[-3.344789, -7.060447]], dtype=float32)
time = 310	action = 0	current_phase = 0	next_phase = 1	reward = 0.444948	array([[-1.8755409, -7.706295 ]], dtype=float32)
time = 315	action = 0	current_phase = 0	next_phase = 1	reward = -0.031806	array([[-1.8010505, -7.8683167]], dtype=float32)
time = 320	action = 0	current_phase = 0	next_phase = 1	reward = -0.397057	array([[-2.779228, -8.097429]], dtype=float32)
time = 325	action = 0	current_phase = 0	next_phase = 1	reward = -1.328100	array([[-2.9582164, -6.003789 ]], dtype=float32)
time = 330	action = 0	current_phase = 0	next_phase = 1	reward = -1.853446	array([[-2.9659197, -6.117321 ]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.674643	array([[-3.4086757, -8.148789 ]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -0.041330	array([[-2.9219997, -8.576937 ]], dtype=float32)
time = 345	action = 0	current_phase = 0	next_phase = 1	reward = -0.186231	array([[-4.0301013, -5.768307 ]], dtype=float32)
time = 350	action = 0	current_phase = 0	next_phase = 1	reward = -0.306047	array([[-4.4558687, -6.838721 ]], dtype=float32)
time = 355	action = 0	current_phase = 0	next_phase = 1	reward = -1.468488	array([[-5.5216866, -5.67344  ]], dtype=float32)
time = 360	action = 0	current_phase = 0	next_phase = 1	reward = -2.720604	array([[-6.4588594, -6.55923  ]], dtype=float32)
time = 365	action = 0	current_phase = 0	next_phase = 1	reward = -2.427131	array([[-6.4116316, -7.8890285]], dtype=float32)
time = 370	action = 0	current_phase = 0	next_phase = 1	reward = -0.692759	array([[-5.5885973, -9.793311 ]], dtype=float32)
time = 375	action = 0	current_phase = 0	next_phase = 1	reward = -0.149766	array([[-4.7155485, -7.808856 ]], dtype=float32)
time = 380	action = 0	current_phase = 0	next_phase = 1	reward = -0.734750	array([[-5.7904453, -7.160466 ]], dtype=float32)
time = 385	action = 0	current_phase = 0	next_phase = 1	reward = -1.574207	array([[-3.9779027, -6.8824024]], dtype=float32)
time = 390	action = 0	current_phase = 0	next_phase = 1	reward = -2.266952	array([[-4.887066 , -7.3187146]], dtype=float32)
time = 395	action = 0	current_phase = 0	next_phase = 1	reward = -4.515008	array([[-6.3693056, -8.197631 ]], dtype=float32)
time = 400	action = 0	current_phase = 0	next_phase = 1	reward = -5.964557	array([[-6.998604, -8.158515]], dtype=float32)
time = 405	action = 0	current_phase = 0	next_phase = 1	reward = -3.544145	array([[-8.554986, -9.746938]], dtype=float32)
time = 410	action = 0	current_phase = 0	next_phase = 1	reward = -2.306518	array([[-5.335622, -8.233148]], dtype=float32)
time = 415	action = 0	current_phase = 0	next_phase = 1	reward = -0.807767	array([[-3.6541612, -9.728399 ]], dtype=float32)
time = 420	action = 0	current_phase = 0	next_phase = 1	reward = -0.504256	array([[-2.7172155, -9.825206 ]], dtype=float32)
time = 425	action = 0	current_phase = 0	next_phase = 1	reward = -1.225963	array([[-5.04562  , -7.4761915]], dtype=float32)
time = 430	action = 0	current_phase = 0	next_phase = 1	reward = -2.350566	array([[-5.30849  , -7.9818473]], dtype=float32)
time = 435	action = 0	current_phase = 0	next_phase = 1	reward = -3.772905	array([[-8.862868, -9.41184 ]], dtype=float32)
time = 440	action = 0	current_phase = 0	next_phase = 1	reward = -5.450960	array([[ -6.5252743, -15.157122 ]], dtype=float32)
time = 445	action = 0	current_phase = 0	next_phase = 1	reward = -3.177026	array([[ -6.029703, -15.912758]], dtype=float32)
time = 450	action = 0	current_phase = 0	next_phase = 1	reward = -0.879862	array([[ -6.4699326, -11.244676 ]], dtype=float32)
time = 455	action = 1	current_phase = 0	next_phase = 1	reward = -1.871829	array([[-7.733696, -6.453219]], dtype=float32)
time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -0.473565	array([[-4.474235, -8.133105]], dtype=float32)
time = 468	action = 0	current_phase = 1	next_phase = 0	reward = -1.369886	array([[-3.9946756, -9.772602 ]], dtype=float32)
time = 473	action = 0	current_phase = 1	next_phase = 0	reward = -2.845536	array([[-4.68981 , -9.796215]], dtype=float32)
time = 478	action = 0	current_phase = 1	next_phase = 0	reward = -3.853655	array([[-6.7589774, -9.271314 ]], dtype=float32)
time = 483	action = 0	current_phase = 1	next_phase = 0	reward = -5.766475	array([[ -9.328173, -11.199554]], dtype=float32)
time = 488	action = 0	current_phase = 1	next_phase = 0	reward = -5.975656	array([[ -5.0523834, -16.94761  ]], dtype=float32)
time = 493	action = 0	current_phase = 1	next_phase = 0	reward = -5.920063	array([[ -9.814556, -10.418656]], dtype=float32)
time = 498	action = 1	current_phase = 1	next_phase = 0	reward = -8.979645	array([[-10.867424,  -9.378336]], dtype=float32)
time = 506	action = 0	current_phase = 0	next_phase = 1	reward = -2.236670	array([[-4.0691643, -8.867807 ]], dtype=float32)
time = 511	action = 0	current_phase = 0	next_phase = 1	reward = -0.836249	array([[-3.5730383, -9.646169 ]], dtype=float32)
time = 516	action = 0	current_phase = 0	next_phase = 1	reward = -0.454311	array([[-3.5081496, -8.704888 ]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.579155	array([[-3.867877, -8.169487]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -0.756981	array([[-4.3047776, -6.9375153]], dtype=float32)
time = 531	action = 0	current_phase = 0	next_phase = 1	reward = -1.711050	array([[-4.5595646, -8.423493 ]], dtype=float32)
time = 536	action = 0	current_phase = 0	next_phase = 1	reward = -2.288904	array([[-4.6224127, -8.598231 ]], dtype=float32)
time = 541	action = 0	current_phase = 0	next_phase = 1	reward = -3.892011	array([[-5.1059637, -9.36796  ]], dtype=float32)
time = 546	action = 0	current_phase = 0	next_phase = 1	reward = -5.932261	array([[ -8.358009, -12.371927]], dtype=float32)
time = 551	action = 0	current_phase = 0	next_phase = 1	reward = -7.185685	array([[ -5.6060543, -17.175488 ]], dtype=float32)
time = 556	action = 0	current_phase = 0	next_phase = 1	reward = -8.196276	array([[ -4.974827, -18.617586]], dtype=float32)
time = 561	action = 0	current_phase = 0	next_phase = 1	reward = -9.250913	array([[ -4.6159353, -19.371279 ]], dtype=float32)
time = 566	action = 0	current_phase = 0	next_phase = 1	reward = -9.532431	array([[ -4.5612164, -19.443789 ]], dtype=float32)
time = 571	action = 0	current_phase = 0	next_phase = 1	reward = -11.673238	array([[ -4.5864143, -19.419046 ]], dtype=float32)
time = 576	action = 0	current_phase = 0	next_phase = 1	reward = -12.954141	array([[ -4.5741415, -19.43241  ]], dtype=float32)
time = 581	action = 0	current_phase = 0	next_phase = 1	reward = -14.110521	array([[ -4.537382, -19.481318]], dtype=float32)
time = 586	action = 0	current_phase = 0	next_phase = 1	reward = -15.520153	array([[ -4.5278816, -19.4915   ]], dtype=float32)
time = 591	action = 0	current_phase = 0	next_phase = 1	reward = -16.427260	array([[ -4.5288963, -19.490625 ]], dtype=float32)
time = 596	action = 0	current_phase = 0	next_phase = 1	reward = -18.368006	array([[ -4.5406895, -19.477789 ]], dtype=float32)
Train on 834 samples, validate on 358 samples
Epoch 1/50
 - 1s - loss: 0.8407 - val_loss: 1.0434
Epoch 2/50
 - 1s - loss: 0.7422 - val_loss: 1.0748
Epoch 3/50
 - 1s - loss: 0.6839 - val_loss: 0.9902
Epoch 4/50
 - 1s - loss: 0.7380 - val_loss: 0.8865
Epoch 5/50
 - 1s - loss: 0.6299 - val_loss: 1.1414
Epoch 6/50
 - 1s - loss: 0.6316 - val_loss: 0.9329
Epoch 7/50
 - 1s - loss: 0.7014 - val_loss: 1.0148
Epoch 8/50
 - 1s - loss: 0.6314 - val_loss: 1.0822
Epoch 9/50
 - 1s - loss: 0.6069 - val_loss: 0.9537
Epoch 10/50
 - 1s - loss: 0.5984 - val_loss: 1.0349
Epoch 11/50
 - 1s - loss: 0.5533 - val_loss: 1.0364
Epoch 12/50
 - 1s - loss: 0.5422 - val_loss: 0.9934
Epoch 13/50
 - 1s - loss: 0.5881 - val_loss: 1.0509
Epoch 14/50
 - 1s - loss: 0.5472 - val_loss: 0.9391
length of memory (state 0, action 0): 613, after forget
length of memory (state 0, action 1): 304, after forget
length of memory (state 1, action 0): 497, after forget
length of memory (state 1, action 1): 292, after forget
time = 601	action = 0	current_phase = 0	next_phase = 1	reward = -19.511632	array([[ -5.2329392, -20.297943 ]], dtype=float32)
time = 606	action = 0	current_phase = 0	next_phase = 1	reward = -20.051322	array([[ -5.2549753, -20.287014 ]], dtype=float32)
time = 611	action = 0	current_phase = 0	next_phase = 1	reward = -21.135540	array([[ -5.2232275, -20.301527 ]], dtype=float32)
time = 616	action = 0	current_phase = 0	next_phase = 1	reward = -22.197209	array([[ -5.263744, -20.28237 ]], dtype=float32)
time = 621	action = 0	current_phase = 0	next_phase = 1	reward = -22.893709	array([[ -5.246799, -20.291616]], dtype=float32)
time = 626	action = 0	current_phase = 0	next_phase = 1	reward = -24.600705	array([[ -5.262336, -20.283165]], dtype=float32)
time = 631	action = 0	current_phase = 0	next_phase = 1	reward = -24.717570	array([[ -5.2487717, -20.290804 ]], dtype=float32)
time = 636	action = 0	current_phase = 0	next_phase = 1	reward = -26.546890	array([[ -5.257382, -20.286142]], dtype=float32)
time = 641	action = 0	current_phase = 0	next_phase = 1	reward = -26.999355	array([[ -5.234606, -20.297445]], dtype=float32)
time = 646	action = 0	current_phase = 0	next_phase = 1	reward = -28.414857	array([[ -5.257223, -20.286219]], dtype=float32)
time = 651	action = 0	current_phase = 0	next_phase = 1	reward = -28.834554	array([[ -5.253723, -20.288303]], dtype=float32)
time = 656	action = 0	current_phase = 0	next_phase = 1	reward = -29.702816	array([[ -5.2408795, -20.294743 ]], dtype=float32)
time = 661	action = 0	current_phase = 0	next_phase = 1	reward = -30.711412	array([[ -5.2579966, -20.285982 ]], dtype=float32)
time = 666	action = 0	current_phase = 0	next_phase = 1	reward = -31.878826	array([[ -5.2383447, -20.295876 ]], dtype=float32)
time = 671	action = 0	current_phase = 0	next_phase = 1	reward = -32.426811	array([[ -5.2534575, -20.288477 ]], dtype=float32)
time = 676	action = 0	current_phase = 0	next_phase = 1	reward = -33.503525	array([[ -5.2601223, -20.2847   ]], dtype=float32)
time = 681	action = 0	current_phase = 0	next_phase = 1	reward = -34.715639	array([[ -5.233978, -20.297758]], dtype=float32)
time = 686	action = 0	current_phase = 0	next_phase = 1	reward = -35.908761	array([[ -5.256171, -20.287008]], dtype=float32)
time = 691	action = 0	current_phase = 0	next_phase = 1	reward = -36.331486	array([[ -5.239639, -20.29533 ]], dtype=float32)
time = 696	action = 0	current_phase = 0	next_phase = 1	reward = -37.482322	array([[ -5.259277, -20.285267]], dtype=float32)
time = 701	action = 0	current_phase = 0	next_phase = 1	reward = -38.220038	array([[ -5.2568493, -20.28663  ]], dtype=float32)
time = 706	action = 0	current_phase = 0	next_phase = 1	reward = -39.317154	array([[ -5.2567387, -20.286692 ]], dtype=float32)
time = 711	action = 0	current_phase = 0	next_phase = 1	reward = -40.031539	array([[ -5.259195, -20.285295]], dtype=float32)
time = 716	action = 0	current_phase = 0	next_phase = 1	reward = -40.984697	array([[ -5.260234, -20.284641]], dtype=float32)
time = 721	action = 0	current_phase = 0	next_phase = 1	reward = -42.391404	array([[ -5.256499, -20.28677 ]], dtype=float32)
time = 726	action = 0	current_phase = 0	next_phase = 1	reward = -42.749012	array([[ -5.254876, -20.28773 ]], dtype=float32)
time = 731	action = 0	current_phase = 0	next_phase = 1	reward = -44.154416	array([[ -5.258583, -20.285446]], dtype=float32)
time = 736	action = 0	current_phase = 0	next_phase = 1	reward = -44.993475	array([[ -5.240345, -20.295013]], dtype=float32)
time = 741	action = 0	current_phase = 0	next_phase = 1	reward = -46.231394	array([[ -5.261974, -20.28221 ]], dtype=float32)
time = 746	action = 0	current_phase = 0	next_phase = 1	reward = -46.530178	array([[ -5.2601137, -20.284367 ]], dtype=float32)
time = 751	action = 0	current_phase = 0	next_phase = 1	reward = -47.679474	array([[ -5.258193, -20.28495 ]], dtype=float32)
time = 756	action = 0	current_phase = 0	next_phase = 1	reward = -48.524010	array([[ -5.2616954, -20.28325  ]], dtype=float32)
time = 761	action = 0	current_phase = 0	next_phase = 1	reward = -49.837112	array([[ -5.2585583, -20.2844   ]], dtype=float32)
time = 766	action = 0	current_phase = 0	next_phase = 1	reward = -50.943678	array([[ -5.2622113, -20.282238 ]], dtype=float32)
time = 771	action = 0	current_phase = 0	next_phase = 1	reward = -51.724295	array([[ -5.260469, -20.282396]], dtype=float32)
time = 776	action = 0	current_phase = 0	next_phase = 1	reward = -52.353584	array([[ -5.2618136, -20.278372 ]], dtype=float32)
time = 781	action = 0	current_phase = 0	next_phase = 1	reward = -53.487564	array([[ -5.2620907, -20.27983  ]], dtype=float32)
time = 786	action = 0	current_phase = 0	next_phase = 1	reward = -54.440683	array([[ -5.2591753, -20.282827 ]], dtype=float32)
time = 791	action = 0	current_phase = 0	next_phase = 1	reward = -55.460679	array([[ -5.263068, -20.274977]], dtype=float32)
time = 796	action = 0	current_phase = 0	next_phase = 1	reward = -56.275250	array([[ -5.2470403, -20.291586 ]], dtype=float32)
time = 801	action = 0	current_phase = 0	next_phase = 1	reward = -56.829094	array([[ -5.2641263, -20.262197 ]], dtype=float32)
time = 806	action = 0	current_phase = 0	next_phase = 1	reward = -58.291240	array([[ -5.2628107, -20.276531 ]], dtype=float32)
time = 811	action = 0	current_phase = 0	next_phase = 1	reward = -58.701046	array([[ -5.2640743, -20.260664 ]], dtype=float32)
time = 816	action = 0	current_phase = 0	next_phase = 1	reward = -60.155581	array([[ -5.2604227, -20.270264 ]], dtype=float32)
time = 821	action = 0	current_phase = 0	next_phase = 1	reward = -61.014848	array([[ -5.2644477, -20.259668 ]], dtype=float32)
time = 826	action = 0	current_phase = 0	next_phase = 1	reward = -62.010670	array([[ -5.263264, -20.260744]], dtype=float32)
time = 831	action = 0	current_phase = 0	next_phase = 1	reward = -62.905354	array([[ -5.2642794, -20.259272 ]], dtype=float32)
time = 836	action = 0	current_phase = 0	next_phase = 1	reward = -64.124965	array([[ -5.2648754, -20.25798  ]], dtype=float32)
time = 841	action = 0	current_phase = 0	next_phase = 1	reward = -64.968583	array([[ -5.264101, -20.25897 ]], dtype=float32)
time = 846	action = 0	current_phase = 0	next_phase = 1	reward = -65.628530	array([[ -5.263551, -20.259584]], dtype=float32)
time = 851	action = 0	current_phase = 0	next_phase = 1	reward = -65.902200	array([[ -5.26458, -20.25764]], dtype=float32)
time = 856	action = 0	current_phase = 0	next_phase = 1	reward = -67.591836	array([[ -5.2645082, -20.257435 ]], dtype=float32)
time = 861	action = 0	current_phase = 0	next_phase = 1	reward = -67.955704	array([[ -5.26494, -20.25661]], dtype=float32)
time = 866	action = 0	current_phase = 0	next_phase = 1	reward = -69.856352	array([[ -5.2650104, -20.25633  ]], dtype=float32)
time = 871	action = 0	current_phase = 0	next_phase = 1	reward = -70.444865	array([[ -5.2651033, -20.256222 ]], dtype=float32)
time = 876	action = 0	current_phase = 0	next_phase = 1	reward = -71.321436	array([[ -5.2646885, -20.256487 ]], dtype=float32)
time = 881	action = 0	current_phase = 0	next_phase = 1	reward = -72.595741	array([[ -5.264922, -20.256353]], dtype=float32)
time = 886	action = 0	current_phase = 0	next_phase = 1	reward = -73.123813	array([[ -5.2645473, -20.256592 ]], dtype=float32)
time = 891	action = 0	current_phase = 0	next_phase = 1	reward = -74.158184	array([[ -5.264963, -20.256193]], dtype=float32)
time = 896	action = 0	current_phase = 0	next_phase = 1	reward = -74.948666	array([[ -5.2651634, -20.255995 ]], dtype=float32)
Train on 834 samples, validate on 358 samples
Epoch 1/50
 - 1s - loss: 17.2473 - val_loss: 38.1494
Epoch 2/50
 - 1s - loss: 16.8592 - val_loss: 37.2006
Epoch 3/50
 - 1s - loss: 16.4404 - val_loss: 36.3054
Epoch 4/50
 - 1s - loss: 16.0558 - val_loss: 35.4281
Epoch 5/50
 - 1s - loss: 15.6856 - val_loss: 34.4511
Epoch 6/50
 - 1s - loss: 15.3190 - val_loss: 33.5638
Epoch 7/50
 - 1s - loss: 14.9137 - val_loss: 32.4968
Epoch 8/50
 - 1s - loss: 14.4892 - val_loss: 31.4842
Epoch 9/50
 - 1s - loss: 14.0850 - val_loss: 30.5026
Epoch 10/50
 - 1s - loss: 13.6608 - val_loss: 29.4708
Epoch 11/50
 - 1s - loss: 13.2156 - val_loss: 28.4409
Epoch 12/50
 - 1s - loss: 12.8460 - val_loss: 27.6316
Epoch 13/50
 - 1s - loss: 12.4667 - val_loss: 26.7804
Epoch 14/50
 - 1s - loss: 12.1679 - val_loss: 26.0216
Epoch 15/50
 - 1s - loss: 11.8286 - val_loss: 25.3530
Epoch 16/50
 - 1s - loss: 11.4975 - val_loss: 24.6799
Epoch 17/50
 - 1s - loss: 11.2038 - val_loss: 24.0930
Epoch 18/50
 - 1s - loss: 10.9783 - val_loss: 23.5367
Epoch 19/50
 - 1s - loss: 10.7468 - val_loss: 23.1496
Epoch 20/50
 - 1s - loss: 10.5495 - val_loss: 22.6080
Epoch 21/50
 - 1s - loss: 10.2966 - val_loss: 22.3203
Epoch 22/50
 - 1s - loss: 10.1481 - val_loss: 21.7788
Epoch 23/50
 - 1s - loss: 9.9229 - val_loss: 21.3094
Epoch 24/50
 - 1s - loss: 9.7842 - val_loss: 20.9319
Epoch 25/50
 - 1s - loss: 9.6244 - val_loss: 20.5965
Epoch 26/50
 - 1s - loss: 9.4065 - val_loss: 20.2215
Epoch 27/50
 - 1s - loss: 9.2986 - val_loss: 19.8974
Epoch 28/50
 - 1s - loss: 9.1417 - val_loss: 19.6307
Epoch 29/50
 - 1s - loss: 8.9861 - val_loss: 19.2587
Epoch 30/50
 - 1s - loss: 8.8782 - val_loss: 18.9112
Epoch 31/50
 - 1s - loss: 8.7356 - val_loss: 18.6704
Epoch 32/50
 - 1s - loss: 8.6127 - val_loss: 18.3019
Epoch 33/50
 - 1s - loss: 8.5134 - val_loss: 18.1156
Epoch 34/50
 - 1s - loss: 8.3682 - val_loss: 17.7493
Epoch 35/50
 - 1s - loss: 8.2098 - val_loss: 17.6104
Epoch 36/50
 - 1s - loss: 8.0415 - val_loss: 17.2212
Epoch 37/50
 - 1s - loss: 7.9850 - val_loss: 16.9815
Epoch 38/50
 - 1s - loss: 7.8686 - val_loss: 16.6652
Epoch 39/50
 - 1s - loss: 7.7197 - val_loss: 16.4378
Epoch 40/50
 - 1s - loss: 7.6307 - val_loss: 16.1252
Epoch 41/50
 - 1s - loss: 7.5409 - val_loss: 15.9290
Epoch 42/50
 - 1s - loss: 7.3841 - val_loss: 15.7078
Epoch 43/50
 - 1s - loss: 7.3124 - val_loss: 15.4007
Epoch 44/50
 - 1s - loss: 7.1578 - val_loss: 15.2074
Epoch 45/50
 - 1s - loss: 7.0700 - val_loss: 14.9288
Epoch 46/50
 - 1s - loss: 6.9474 - val_loss: 14.7034
Epoch 47/50
 - 1s - loss: 6.8449 - val_loss: 14.6229
Epoch 48/50
 - 1s - loss: 6.7441 - val_loss: 14.3603
Epoch 49/50
 - 1s - loss: 6.6313 - val_loss: 14.1035
Epoch 50/50
 - 1s - loss: 6.5558 - val_loss: 13.9045
length of memory (state 0, action 0): 673, after forget
length of memory (state 0, action 1): 304, after forget
length of memory (state 1, action 0): 497, after forget
length of memory (state 1, action 1): 292, after forget
time = 901	action = 1	current_phase = 0	next_phase = 1	reward = -107.004995	array([[-24.99331 , -20.476358]], dtype=float32)
time = 909	action = 0	current_phase = 1	next_phase = 0	reward = -44.887108	array([[ -6.7820344, -17.369097 ]], dtype=float32)
time = 914	action = 0	current_phase = 1	next_phase = 0	reward = -28.468047	array([[ -6.7820344, -17.369097 ]], dtype=float32)
time = 919	action = 0	current_phase = 1	next_phase = 0	reward = -18.761208	array([[ -6.7819643, -17.369244 ]], dtype=float32)
time = 924	action = 0	current_phase = 1	next_phase = 0	reward = -5.674925	array([[ -5.666455, -20.537231]], dtype=float32)
time = 929	action = 0	current_phase = 1	next_phase = 0	reward = 0.193947	array([[ -5.094293, -20.86059 ]], dtype=float32)
time = 934	action = 0	current_phase = 1	next_phase = 0	reward = 2.345683	array([[ -2.4958956, -13.22522  ]], dtype=float32)
time = 939	action = 0	current_phase = 1	next_phase = 0	reward = -2.808996	array([[ -7.0469623, -12.151094 ]], dtype=float32)
time = 944	action = 0	current_phase = 1	next_phase = 0	reward = -3.707048	array([[ -4.9296007, -16.106466 ]], dtype=float32)
time = 949	action = 0	current_phase = 1	next_phase = 0	reward = -5.054799	array([[ -4.72782 , -20.075563]], dtype=float32)
time = 954	action = 0	current_phase = 1	next_phase = 0	reward = -8.904518	array([[ -5.0508347, -20.582336 ]], dtype=float32)
time = 959	action = 0	current_phase = 1	next_phase = 0	reward = -7.369598	array([[ -5.2264647, -20.522835 ]], dtype=float32)
time = 964	action = 0	current_phase = 1	next_phase = 0	reward = -7.245402	array([[ -6.5007596, -18.665092 ]], dtype=float32)
time = 969	action = 0	current_phase = 1	next_phase = 0	reward = -7.976433	array([[ -5.468721, -17.274817]], dtype=float32)
time = 974	action = 0	current_phase = 1	next_phase = 0	reward = -8.457440	array([[ -5.171166, -18.17877 ]], dtype=float32)
time = 979	action = 0	current_phase = 1	next_phase = 0	reward = -10.602990	array([[ -4.889165, -19.69287 ]], dtype=float32)
time = 984	action = 0	current_phase = 1	next_phase = 0	reward = -11.764434	array([[ -5.228535, -20.828716]], dtype=float32)
time = 989	action = 0	current_phase = 1	next_phase = 0	reward = -13.259707	array([[ -5.248391, -20.908783]], dtype=float32)
time = 994	action = 0	current_phase = 1	next_phase = 0	reward = -14.236433	array([[ -4.881935, -20.81363 ]], dtype=float32)
time = 999	action = 0	current_phase = 1	next_phase = 0	reward = -15.113603	array([[ -4.657271, -20.423096]], dtype=float32)
time = 1004	action = 0	current_phase = 1	next_phase = 0	reward = -15.588899	array([[ -5.171597, -21.05157 ]], dtype=float32)
time = 1009	action = 0	current_phase = 1	next_phase = 0	reward = -16.806729	array([[ -5.239085, -21.025452]], dtype=float32)
time = 1014	action = 0	current_phase = 1	next_phase = 0	reward = -16.955635	array([[ -5.071092, -20.921381]], dtype=float32)
time = 1019	action = 0	current_phase = 1	next_phase = 0	reward = -16.393084	array([[ -5.2361946, -21.13725  ]], dtype=float32)
time = 1024	action = 0	current_phase = 1	next_phase = 0	reward = -15.948393	array([[ -5.0282793, -20.915205 ]], dtype=float32)
time = 1029	action = 0	current_phase = 1	next_phase = 0	reward = -16.210539	array([[ -5.237237, -20.883133]], dtype=float32)
time = 1034	action = 0	current_phase = 1	next_phase = 0	reward = -17.180965	array([[ -4.936086, -20.876352]], dtype=float32)
time = 1039	action = 0	current_phase = 1	next_phase = 0	reward = -18.352816	array([[ -5.0967746, -20.87454  ]], dtype=float32)
time = 1044	action = 0	current_phase = 1	next_phase = 0	reward = -20.654023	array([[ -5.091742, -20.866098]], dtype=float32)
time = 1049	action = 0	current_phase = 1	next_phase = 0	reward = -21.601965	array([[ -5.084909, -20.966366]], dtype=float32)
time = 1054	action = 0	current_phase = 1	next_phase = 0	reward = -23.135685	array([[ -5.133267, -21.072556]], dtype=float32)
time = 1059	action = 0	current_phase = 1	next_phase = 0	reward = -23.919067	array([[ -5.210122, -21.076645]], dtype=float32)
time = 1064	action = 0	current_phase = 1	next_phase = 0	reward = -24.818293	array([[ -5.0538616, -21.096174 ]], dtype=float32)
time = 1069	action = 0	current_phase = 1	next_phase = 0	reward = -25.436387	array([[ -5.099852, -21.120415]], dtype=float32)
time = 1074	action = 0	current_phase = 1	next_phase = 0	reward = -26.312870	array([[ -5.0608325, -21.111814 ]], dtype=float32)
time = 1079	action = 0	current_phase = 1	next_phase = 0	reward = -27.120935	array([[ -5.0807834, -21.118961 ]], dtype=float32)
time = 1084	action = 0	current_phase = 1	next_phase = 0	reward = -28.072281	array([[ -5.0760803, -21.127436 ]], dtype=float32)
time = 1089	action = 0	current_phase = 1	next_phase = 0	reward = -27.800462	array([[ -5.103244, -21.129488]], dtype=float32)
time = 1094	action = 0	current_phase = 1	next_phase = 0	reward = -27.478299	array([[ -5.0609527, -21.128157 ]], dtype=float32)
time = 1099	action = 0	current_phase = 1	next_phase = 0	reward = -26.142388	array([[ -5.083311, -21.128023]], dtype=float32)
time = 1104	action = 0	current_phase = 1	next_phase = 0	reward = -25.671518	array([[ -5.1584005, -21.116692 ]], dtype=float32)
time = 1109	action = 0	current_phase = 1	next_phase = 0	reward = -25.048929	array([[ -5.2218266, -21.103401 ]], dtype=float32)
time = 1114	action = 0	current_phase = 1	next_phase = 0	reward = -26.034396	array([[ -5.236098, -21.098543]], dtype=float32)
time = 1119	action = 0	current_phase = 1	next_phase = 0	reward = -27.579355	array([[ -5.259776, -21.055437]], dtype=float32)
time = 1124	action = 0	current_phase = 1	next_phase = 0	reward = -27.442482	array([[ -5.0813775, -21.122948 ]], dtype=float32)
time = 1129	action = 0	current_phase = 1	next_phase = 0	reward = -27.586921	array([[ -5.1740675, -21.104368 ]], dtype=float32)
time = 1134	action = 0	current_phase = 1	next_phase = 0	reward = -27.687431	array([[ -5.0904837, -21.037897 ]], dtype=float32)
time = 1139	action = 0	current_phase = 1	next_phase = 0	reward = -27.923650	array([[ -5.211636, -21.11841 ]], dtype=float32)
time = 1144	action = 0	current_phase = 1	next_phase = 0	reward = -28.179605	array([[ -5.156966, -21.118286]], dtype=float32)
time = 1149	action = 0	current_phase = 1	next_phase = 0	reward = -29.819487	array([[ -5.2900004, -21.088148 ]], dtype=float32)
time = 1154	action = 0	current_phase = 1	next_phase = 0	reward = -29.663727	array([[ -5.2200913, -21.114384 ]], dtype=float32)
time = 1159	action = 0	current_phase = 1	next_phase = 0	reward = -30.269584	array([[ -5.5861382, -20.93506  ]], dtype=float32)
time = 1164	action = 0	current_phase = 1	next_phase = 0	reward = -30.778954	array([[ -5.3787084, -21.05782  ]], dtype=float32)
time = 1169	action = 0	current_phase = 1	next_phase = 0	reward = -30.455774	array([[ -5.3627853, -21.075403 ]], dtype=float32)
time = 1174	action = 0	current_phase = 1	next_phase = 0	reward = -31.361798	array([[ -5.53974 , -20.975048]], dtype=float32)
time = 1179	action = 0	current_phase = 1	next_phase = 0	reward = -32.806314	array([[ -5.631567, -20.912075]], dtype=float32)
time = 1184	action = 0	current_phase = 1	next_phase = 0	reward = -34.437021	array([[ -5.351211, -21.07381 ]], dtype=float32)
time = 1189	action = 0	current_phase = 1	next_phase = 0	reward = -34.118845	array([[ -5.166434, -21.127838]], dtype=float32)
time = 1194	action = 0	current_phase = 1	next_phase = 0	reward = -34.501168	array([[ -5.4502907, -21.030415 ]], dtype=float32)
time = 1199	action = 0	current_phase = 1	next_phase = 0	reward = -34.198910	array([[ -5.55003 , -20.958809]], dtype=float32)
Train on 834 samples, validate on 358 samples
Epoch 1/50
 - 1s - loss: 23.9294 - val_loss: 10.3749
Epoch 2/50
 - 1s - loss: 23.2628 - val_loss: 9.9972
Epoch 3/50
 - 1s - loss: 22.6837 - val_loss: 9.6904
Epoch 4/50
 - 1s - loss: 22.1287 - val_loss: 9.4327
Epoch 5/50
 - 1s - loss: 21.5898 - val_loss: 9.2767
Epoch 6/50
 - 1s - loss: 21.0648 - val_loss: 8.8395
Epoch 7/50
 - 1s - loss: 20.5865 - val_loss: 8.5011
Epoch 8/50
 - 1s - loss: 19.9768 - val_loss: 8.0936
Epoch 9/50
 - 1s - loss: 19.5689 - val_loss: 7.9915
Epoch 10/50
 - 1s - loss: 19.2021 - val_loss: 7.7501
Epoch 11/50
 - 1s - loss: 18.8158 - val_loss: 7.5543
Epoch 12/50
 - 1s - loss: 18.4549 - val_loss: 7.3800
Epoch 13/50
 - 1s - loss: 18.1606 - val_loss: 7.1825
Epoch 14/50
 - 1s - loss: 17.8315 - val_loss: 7.0752
Epoch 15/50
 - 1s - loss: 17.5855 - val_loss: 6.8848
Epoch 16/50
 - 1s - loss: 17.3025 - val_loss: 6.7861
Epoch 17/50
 - 1s - loss: 17.0459 - val_loss: 6.6113
Epoch 18/50
 - 1s - loss: 16.7388 - val_loss: 6.5923
Epoch 19/50
 - 1s - loss: 16.4944 - val_loss: 6.4092
Epoch 20/50
 - 1s - loss: 16.2890 - val_loss: 6.2798
Epoch 21/50
 - 1s - loss: 16.1297 - val_loss: 6.2186
Epoch 22/50
 - 1s - loss: 15.7588 - val_loss: 6.1029
Epoch 23/50
 - 1s - loss: 15.5736 - val_loss: 6.0006
Epoch 24/50
 - 1s - loss: 15.2925 - val_loss: 5.9938
Epoch 25/50
 - 1s - loss: 15.0813 - val_loss: 5.8147
Epoch 26/50
 - 1s - loss: 14.9146 - val_loss: 5.7745
Epoch 27/50
 - 1s - loss: 14.5952 - val_loss: 5.6634
Epoch 28/50
 - 1s - loss: 14.3915 - val_loss: 5.5582
Epoch 29/50
 - 1s - loss: 14.2176 - val_loss: 5.4566
Epoch 30/50
 - 1s - loss: 14.0717 - val_loss: 5.4304
Epoch 31/50
 - 1s - loss: 13.8823 - val_loss: 5.3554
Epoch 32/50
 - 1s - loss: 13.6353 - val_loss: 5.3637
Epoch 33/50
 - 1s - loss: 13.5032 - val_loss: 5.2918
Epoch 34/50
 - 1s - loss: 13.3071 - val_loss: 5.1624
Epoch 35/50
 - 1s - loss: 13.2116 - val_loss: 5.0816
Epoch 36/50
 - 1s - loss: 13.0094 - val_loss: 5.0238
Epoch 37/50
 - 1s - loss: 12.8640 - val_loss: 4.9482
Epoch 38/50
 - 1s - loss: 12.7090 - val_loss: 4.8717
Epoch 39/50
 - 1s - loss: 12.4843 - val_loss: 4.9209
Epoch 40/50
 - 1s - loss: 12.3907 - val_loss: 4.7647
Epoch 41/50
 - 1s - loss: 12.1919 - val_loss: 4.7314
Epoch 42/50
 - 1s - loss: 12.0769 - val_loss: 4.6643
Epoch 43/50
 - 1s - loss: 12.0270 - val_loss: 4.6374
Epoch 44/50
 - 1s - loss: 11.7948 - val_loss: 4.5389
Epoch 45/50
 - 1s - loss: 11.6837 - val_loss: 4.4818
Epoch 46/50
 - 1s - loss: 11.6212 - val_loss: 4.5557
Epoch 47/50
 - 1s - loss: 11.4199 - val_loss: 4.4427
Epoch 48/50
 - 1s - loss: 11.2972 - val_loss: 4.2423
Epoch 49/50
 - 1s - loss: 11.1564 - val_loss: 4.3510
Epoch 50/50
 - 1s - loss: 11.0836 - val_loss: 4.1987
length of memory (state 0, action 0): 673, after forget
length of memory (state 0, action 1): 305, after forget
length of memory (state 1, action 0): 556, after forget
length of memory (state 1, action 1): 292, after forget
time = 1204	action = 1	current_phase = 1	next_phase = 0	reward = -46.739777	array([[-27.493744, -21.04728 ]], dtype=float32)
time = 1212	action = 1	current_phase = 0	next_phase = 1	reward = -33.717841	array([[-37.76196 , -21.920675]], dtype=float32)
time = 1220	action = 1	current_phase = 1	next_phase = 0	reward = -16.997464	array([[-24.32451 , -20.977211]], dtype=float32)
time = 1228	action = 1	current_phase = 0	next_phase = 1	reward = -7.770708	array([[-12.3577175, -12.236657 ]], dtype=float32)
time = 1236	action = 0	current_phase = 1	next_phase = 0	reward = -2.664839	array([[-5.9767923, -9.021135 ]], dtype=float32)
time = 1241	action = 0	current_phase = 1	next_phase = 0	reward = -3.298945	array([[-5.846096, -9.665025]], dtype=float32)
time = 1246	action = 0	current_phase = 1	next_phase = 0	reward = -5.654449	array([[ -5.3564796, -11.375461 ]], dtype=float32)
time = 1251	action = 0	current_phase = 1	next_phase = 0	reward = -7.836793	array([[ -7.864498 , -14.8234005]], dtype=float32)
time = 1256	action = 0	current_phase = 1	next_phase = 0	reward = -10.486999	array([[ -7.314727, -19.148058]], dtype=float32)
time = 1261	action = 0	current_phase = 1	next_phase = 0	reward = -13.249066	array([[ -9.532074, -20.093302]], dtype=float32)
time = 1266	action = 0	current_phase = 1	next_phase = 0	reward = -13.115064	array([[ -8.166996, -21.63614 ]], dtype=float32)
time = 1271	action = 0	current_phase = 1	next_phase = 0	reward = -11.073679	array([[-10.0521555, -21.842031 ]], dtype=float32)
time = 1276	action = 0	current_phase = 1	next_phase = 0	reward = -12.093170	array([[-14.714445, -21.607141]], dtype=float32)
time = 1281	action = 0	current_phase = 1	next_phase = 0	reward = -10.711915	array([[-15.581683, -21.562363]], dtype=float32)
time = 1286	action = 0	current_phase = 1	next_phase = 0	reward = -10.477467	array([[-16.299314, -21.394327]], dtype=float32)
time = 1291	action = 0	current_phase = 1	next_phase = 0	reward = -11.529328	array([[-21.067469, -21.077799]], dtype=float32)
time = 1296	action = 0	current_phase = 1	next_phase = 0	reward = -12.770874	array([[-17.442986, -21.62894 ]], dtype=float32)
time = 1301	action = 0	current_phase = 1	next_phase = 0	reward = -14.480377	array([[-14.806245, -21.883068]], dtype=float32)
time = 1306	action = 0	current_phase = 1	next_phase = 0	reward = -16.014585	array([[ -9.62422 , -21.571245]], dtype=float32)
time = 1311	action = 0	current_phase = 1	next_phase = 0	reward = -17.722021	array([[-18.626822, -22.56611 ]], dtype=float32)
time = 1316	action = 0	current_phase = 1	next_phase = 0	reward = -19.000892	array([[-19.750505, -22.608948]], dtype=float32)
time = 1321	action = 0	current_phase = 1	next_phase = 0	reward = -19.643946	array([[-18.943722, -22.649902]], dtype=float32)
time = 1326	action = 0	current_phase = 1	next_phase = 0	reward = -20.562938	array([[-16.316875, -22.641777]], dtype=float32)
time = 1331	action = 1	current_phase = 1	next_phase = 0	reward = -28.400628	array([[-25.447998, -21.684599]], dtype=float32)
time = 1339	action = 1	current_phase = 0	next_phase = 1	reward = -22.891470	array([[-35.456806, -21.473894]], dtype=float32)
time = 1347	action = 0	current_phase = 1	next_phase = 0	reward = -9.023567	array([[-12.353262, -21.394241]], dtype=float32)
time = 1352	action = 0	current_phase = 1	next_phase = 0	reward = -6.504613	array([[-10.980775, -18.720285]], dtype=float32)
time = 1357	action = 0	current_phase = 1	next_phase = 0	reward = -6.492623	array([[ -7.3645115, -16.43072  ]], dtype=float32)
time = 1362	action = 0	current_phase = 1	next_phase = 0	reward = -8.415155	array([[ -6.6797495, -16.160254 ]], dtype=float32)
time = 1367	action = 0	current_phase = 1	next_phase = 0	reward = -11.152575	array([[ -7.4396257, -19.370602 ]], dtype=float32)
time = 1372	action = 0	current_phase = 1	next_phase = 0	reward = -13.354522	array([[ -7.64787 , -20.465836]], dtype=float32)
time = 1377	action = 0	current_phase = 1	next_phase = 0	reward = -12.546627	array([[ -9.914192, -22.294212]], dtype=float32)
time = 1382	action = 0	current_phase = 1	next_phase = 0	reward = -13.012648	array([[ -8.557598, -21.4461  ]], dtype=float32)
time = 1387	action = 0	current_phase = 1	next_phase = 0	reward = -12.088904	array([[-11.32102 , -21.962362]], dtype=float32)
time = 1392	action = 0	current_phase = 1	next_phase = 0	reward = -11.972571	array([[-13.226067, -21.861788]], dtype=float32)
time = 1397	action = 0	current_phase = 1	next_phase = 0	reward = -12.633177	array([[-12.869745, -21.904047]], dtype=float32)
time = 1402	action = 0	current_phase = 1	next_phase = 0	reward = -14.411231	array([[-11.459356, -21.798883]], dtype=float32)
time = 1407	action = 0	current_phase = 1	next_phase = 0	reward = -15.979732	array([[ -9.093233, -21.52105 ]], dtype=float32)
time = 1412	action = 0	current_phase = 1	next_phase = 0	reward = -17.280014	array([[-14.08431 , -22.638136]], dtype=float32)
time = 1417	action = 0	current_phase = 1	next_phase = 0	reward = -17.817479	array([[-11.202546, -21.499943]], dtype=float32)
time = 1422	action = 0	current_phase = 1	next_phase = 0	reward = -19.312132	array([[-16.607191, -22.786146]], dtype=float32)
time = 1427	action = 0	current_phase = 1	next_phase = 0	reward = -19.535464	array([[-20.620708, -22.671757]], dtype=float32)
time = 1432	action = 1	current_phase = 1	next_phase = 0	reward = -26.038575	array([[-24.745638, -21.970312]], dtype=float32)
time = 1440	action = 1	current_phase = 0	next_phase = 1	reward = -23.410291	array([[-35.47244, -21.25653]], dtype=float32)
time = 1448	action = 0	current_phase = 1	next_phase = 0	reward = -9.115556	array([[-10.819794, -21.569084]], dtype=float32)
time = 1453	action = 0	current_phase = 1	next_phase = 0	reward = -6.572168	array([[ -8.248023, -18.551662]], dtype=float32)
time = 1458	action = 0	current_phase = 1	next_phase = 0	reward = -6.201331	array([[ -9.913074, -16.482372]], dtype=float32)
time = 1463	action = 0	current_phase = 1	next_phase = 0	reward = -8.890905	array([[ -4.7158794, -16.86227  ]], dtype=float32)
time = 1468	action = 0	current_phase = 1	next_phase = 0	reward = -11.071732	array([[ -6.7254047, -19.267517 ]], dtype=float32)
time = 1473	action = 0	current_phase = 1	next_phase = 0	reward = -11.729777	array([[ -7.7755966, -21.358328 ]], dtype=float32)
time = 1478	action = 0	current_phase = 1	next_phase = 0	reward = -13.058798	array([[-10.997607, -22.410965]], dtype=float32)
time = 1483	action = 0	current_phase = 1	next_phase = 0	reward = -12.603526	array([[-11.423276, -22.377892]], dtype=float32)
time = 1488	action = 0	current_phase = 1	next_phase = 0	reward = -12.290423	array([[-11.746198, -21.812498]], dtype=float32)
time = 1493	action = 0	current_phase = 1	next_phase = 0	reward = -12.405603	array([[-12.772822, -22.051981]], dtype=float32)
time = 1498	action = 0	current_phase = 1	next_phase = 0	reward = -13.507941	array([[-12.210915, -21.675495]], dtype=float32)
time = 1503	action = 0	current_phase = 1	next_phase = 0	reward = -15.046145	array([[ -9.673993, -21.573841]], dtype=float32)
Train on 837 samples, validate on 359 samples
Epoch 1/50
 - 1s - loss: 12.6506 - val_loss: 5.9977
Epoch 2/50
 - 1s - loss: 12.2930 - val_loss: 5.8600
Epoch 3/50
 - 1s - loss: 12.2795 - val_loss: 5.7584
Epoch 4/50
 - 1s - loss: 12.0848 - val_loss: 5.7271
Epoch 5/50
 - 1s - loss: 11.8540 - val_loss: 5.5920
Epoch 6/50
 - 1s - loss: 11.8053 - val_loss: 5.5051
Epoch 7/50
 - 1s - loss: 11.5797 - val_loss: 5.3433
Epoch 8/50
 - 1s - loss: 11.4699 - val_loss: 5.2701
Epoch 9/50
 - 1s - loss: 11.4151 - val_loss: 5.1645
Epoch 10/50
 - 1s - loss: 11.2799 - val_loss: 5.1185
Epoch 11/50
 - 1s - loss: 11.1977 - val_loss: 5.0380
Epoch 12/50
 - 1s - loss: 11.0353 - val_loss: 4.9485
Epoch 13/50
 - 1s - loss: 10.9832 - val_loss: 4.8472
Epoch 14/50
 - 1s - loss: 10.8488 - val_loss: 4.8104
Epoch 15/50
 - 1s - loss: 10.7358 - val_loss: 4.7234
Epoch 16/50
 - 1s - loss: 10.6171 - val_loss: 4.6673
Epoch 17/50
 - 1s - loss: 10.6106 - val_loss: 4.5381
Epoch 18/50
 - 1s - loss: 10.4402 - val_loss: 4.5031
Epoch 19/50
 - 1s - loss: 10.4106 - val_loss: 4.4070
Epoch 20/50
 - 1s - loss: 10.2826 - val_loss: 4.3816
Epoch 21/50
 - 1s - loss: 10.2397 - val_loss: 4.2991
Epoch 22/50
 - 1s - loss: 10.1597 - val_loss: 4.2519
Epoch 23/50
 - 1s - loss: 10.0785 - val_loss: 4.2158
Epoch 24/50
 - 1s - loss: 9.9446 - val_loss: 4.0810
Epoch 25/50
 - 1s - loss: 9.9125 - val_loss: 4.0728
Epoch 26/50
 - 1s - loss: 9.8079 - val_loss: 4.0113
Epoch 27/50
 - 1s - loss: 9.7625 - val_loss: 3.9625
Epoch 28/50
 - 1s - loss: 9.6883 - val_loss: 3.8793
Epoch 29/50
 - 1s - loss: 9.5782 - val_loss: 3.8159
Epoch 30/50
 - 1s - loss: 9.5475 - val_loss: 3.7631
Epoch 31/50
 - 1s - loss: 9.4970 - val_loss: 3.7313
Epoch 32/50
 - 1s - loss: 9.3880 - val_loss: 3.6246
Epoch 33/50
 - 1s - loss: 9.3421 - val_loss: 3.5442
Epoch 34/50
 - 1s - loss: 9.3294 - val_loss: 3.5738
Epoch 35/50
 - 1s - loss: 9.2195 - val_loss: 3.4766
Epoch 36/50
 - 1s - loss: 9.2200 - val_loss: 3.4485
Epoch 37/50
 - 1s - loss: 9.0958 - val_loss: 3.4090
Epoch 38/50
 - 1s - loss: 9.0468 - val_loss: 3.3725
Epoch 39/50
 - 1s - loss: 9.0081 - val_loss: 3.4179
Epoch 40/50
 - 1s - loss: 8.9345 - val_loss: 3.3308
Epoch 41/50
 - 1s - loss: 8.9131 - val_loss: 3.2604
Epoch 42/50
 - 1s - loss: 8.9099 - val_loss: 3.2029
Epoch 43/50
 - 1s - loss: 8.7667 - val_loss: 3.2145
Epoch 44/50
 - 1s - loss: 8.7685 - val_loss: 3.1596
Epoch 45/50
 - 1s - loss: 8.6894 - val_loss: 3.1010
Epoch 46/50
 - 1s - loss: 8.6126 - val_loss: 3.1760
Epoch 47/50
 - 1s - loss: 8.5721 - val_loss: 3.0960
Epoch 48/50
 - 1s - loss: 8.5201 - val_loss: 3.0431
Epoch 49/50
 - 1s - loss: 8.5350 - val_loss: 2.9981
Epoch 50/50
 - 1s - loss: 8.4011 - val_loss: 2.9195
length of memory (state 0, action 0): 673, after forget
length of memory (state 0, action 1): 309, after forget
length of memory (state 1, action 0): 604, after forget
length of memory (state 1, action 1): 296, after forget
time = 1508	action = 0	current_phase = 1	next_phase = 0	reward = -16.643332	array([[-16.982143, -22.983477]], dtype=float32)
time = 1513	action = 0	current_phase = 1	next_phase = 0	reward = -17.830010	array([[-22.39518 , -23.745535]], dtype=float32)
time = 1518	action = 0	current_phase = 1	next_phase = 0	reward = -18.105205	array([[-22.42908 , -23.570986]], dtype=float32)
time = 1523	action = 1	current_phase = 1	next_phase = 0	reward = -23.159231	array([[-23.977026, -23.86593 ]], dtype=float32)
time = 1531	action = 1	current_phase = 0	next_phase = 1	reward = -21.430081	array([[-37.969368, -21.539576]], dtype=float32)
time = 1539	action = 0	current_phase = 1	next_phase = 0	reward = -8.261839	array([[-12.438301, -20.10003 ]], dtype=float32)
time = 1544	action = 0	current_phase = 1	next_phase = 0	reward = -5.665665	array([[-10.768766, -18.456343]], dtype=float32)
time = 1549	action = 0	current_phase = 1	next_phase = 0	reward = -6.224920	array([[ -4.743432, -14.15572 ]], dtype=float32)
time = 1554	action = 0	current_phase = 1	next_phase = 0	reward = -8.165360	array([[ -8.987076, -14.781368]], dtype=float32)
time = 1559	action = 0	current_phase = 1	next_phase = 0	reward = -11.040436	array([[-10.3308525, -19.535799 ]], dtype=float32)
time = 1564	action = 0	current_phase = 1	next_phase = 0	reward = -11.971836	array([[-12.899858, -20.911974]], dtype=float32)
time = 1569	action = 0	current_phase = 1	next_phase = 0	reward = -12.170439	array([[-18.992376, -23.770689]], dtype=float32)
time = 1574	action = 0	current_phase = 1	next_phase = 0	reward = -12.508920	array([[-14.911381, -22.225237]], dtype=float32)
time = 1579	action = 0	current_phase = 1	next_phase = 0	reward = -12.459162	array([[-16.62788 , -22.242554]], dtype=float32)
time = 1584	action = 0	current_phase = 1	next_phase = 0	reward = -12.052269	array([[-17.777088, -22.144556]], dtype=float32)
time = 1589	action = 0	current_phase = 1	next_phase = 0	reward = -12.595290	array([[-18.464912, -21.873096]], dtype=float32)
time = 1594	action = 0	current_phase = 1	next_phase = 0	reward = -14.328779	array([[-15.984734, -22.292543]], dtype=float32)
time = 1599	action = 0	current_phase = 1	next_phase = 0	reward = -15.630950	array([[-15.25506 , -21.985933]], dtype=float32)
time = 1604	action = 0	current_phase = 1	next_phase = 0	reward = -17.477599	array([[-20.617752, -23.659891]], dtype=float32)
time = 1609	action = 0	current_phase = 1	next_phase = 0	reward = -17.906515	array([[-21.386147, -23.737684]], dtype=float32)
time = 1614	action = 0	current_phase = 1	next_phase = 0	reward = -18.873782	array([[-23.365437, -23.902529]], dtype=float32)
time = 1619	action = 1	current_phase = 1	next_phase = 0	reward = -23.317104	array([[-24.454338, -23.50395 ]], dtype=float32)
time = 1627	action = 1	current_phase = 0	next_phase = 1	reward = -21.010631	array([[-39.66838 , -21.750582]], dtype=float32)
time = 1635	action = 0	current_phase = 1	next_phase = 0	reward = -8.939198	array([[-13.214852, -21.798023]], dtype=float32)
time = 1640	action = 0	current_phase = 1	next_phase = 0	reward = -6.627422	array([[-10.54173 , -19.200903]], dtype=float32)
time = 1645	action = 0	current_phase = 1	next_phase = 0	reward = -6.342160	array([[ -5.3877373, -16.139132 ]], dtype=float32)
time = 1650	action = 0	current_phase = 1	next_phase = 0	reward = -8.381919	array([[ -6.9073744, -17.151217 ]], dtype=float32)
time = 1655	action = 0	current_phase = 1	next_phase = 0	reward = -11.043692	array([[ -8.673323, -19.781944]], dtype=float32)
time = 1660	action = 0	current_phase = 1	next_phase = 0	reward = -13.183417	array([[-14.623955, -22.297565]], dtype=float32)
time = 1665	action = 0	current_phase = 1	next_phase = 0	reward = -12.903993	array([[-13.542858, -23.350666]], dtype=float32)
time = 1670	action = 0	current_phase = 1	next_phase = 0	reward = -14.315281	array([[-17.046278, -23.487686]], dtype=float32)
time = 1675	action = 0	current_phase = 1	next_phase = 0	reward = -13.358120	array([[-14.595122, -22.441984]], dtype=float32)
time = 1680	action = 0	current_phase = 1	next_phase = 0	reward = -13.067857	array([[-17.023092, -21.976606]], dtype=float32)
time = 1685	action = 0	current_phase = 1	next_phase = 0	reward = -12.236053	array([[-17.317179, -21.933954]], dtype=float32)
time = 1690	action = 0	current_phase = 1	next_phase = 0	reward = -13.118168	array([[-16.341545, -21.912643]], dtype=float32)
time = 1695	action = 0	current_phase = 1	next_phase = 0	reward = -15.328546	array([[-17.031775, -22.719473]], dtype=float32)
time = 1700	action = 0	current_phase = 1	next_phase = 0	reward = -16.607483	array([[-19.23662 , -23.351952]], dtype=float32)
time = 1705	action = 0	current_phase = 1	next_phase = 0	reward = -15.803400	array([[-21.997797, -23.802505]], dtype=float32)
time = 1710	action = 0	current_phase = 1	next_phase = 0	reward = -16.519191	array([[-21.46103 , -23.577805]], dtype=float32)
time = 1715	action = 1	current_phase = 1	next_phase = 0	reward = -17.416631	array([[-23.619497, -22.480652]], dtype=float32)
time = 1723	action = 1	current_phase = 0	next_phase = 1	reward = -15.713499	array([[-38.543747, -21.914146]], dtype=float32)
time = 1731	action = 1	current_phase = 1	next_phase = 0	reward = -3.670265	array([[-10.307625 ,  -9.3290205]], dtype=float32)
time = 1739	action = 0	current_phase = 0	next_phase = 1	reward = 3.805579	array([[-4.9393845, -9.138514 ]], dtype=float32)
time = 1744	action = 0	current_phase = 0	next_phase = 1	reward = 5.943580	array([[ -4.5525837, -10.283279 ]], dtype=float32)
time = 1749	action = 0	current_phase = 0	next_phase = 1	reward = 0.641053	array([[ -4.6698213, -12.003841 ]], dtype=float32)
time = 1754	action = 0	current_phase = 0	next_phase = 1	reward = 0.646841	array([[ -4.969571, -12.200502]], dtype=float32)
time = 1759	action = 0	current_phase = 0	next_phase = 1	reward = -1.865761	array([[ -5.571553, -15.649906]], dtype=float32)
time = 1764	action = 0	current_phase = 0	next_phase = 1	reward = -5.056178	array([[ -9.03364 , -17.545527]], dtype=float32)
time = 1769	action = 0	current_phase = 0	next_phase = 1	reward = -9.136930	array([[ -8.633064, -18.45857 ]], dtype=float32)
time = 1774	action = 0	current_phase = 0	next_phase = 1	reward = -11.626518	array([[-11.771477, -20.702387]], dtype=float32)
time = 1779	action = 0	current_phase = 0	next_phase = 1	reward = -13.992626	array([[-12.916206, -21.351099]], dtype=float32)
time = 1784	action = 0	current_phase = 0	next_phase = 1	reward = -15.938197	array([[-13.7979355, -21.832613 ]], dtype=float32)
time = 1789	action = 0	current_phase = 0	next_phase = 1	reward = -17.335083	array([[-16.421885, -22.914331]], dtype=float32)
time = 1794	action = 1	current_phase = 0	next_phase = 1	reward = -26.992276	array([[-23.081882, -23.031206]], dtype=float32)
time = 1802	action = 0	current_phase = 1	next_phase = 0	reward = -10.612471	array([[-10.515608, -17.963621]], dtype=float32)
time = 1807	action = 0	current_phase = 1	next_phase = 0	reward = -7.499940	array([[ -7.019862, -19.291857]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 9.7436 - val_loss: 28.6744
Epoch 2/50
 - 1s - loss: 8.0301 - val_loss: 28.5200
Epoch 3/50
 - 1s - loss: 7.5032 - val_loss: 28.4173
Epoch 4/50
 - 1s - loss: 7.1889 - val_loss: 28.0539
Epoch 5/50
 - 1s - loss: 7.1188 - val_loss: 27.9025
Epoch 6/50
 - 1s - loss: 6.8614 - val_loss: 27.7894
Epoch 7/50
 - 1s - loss: 6.8328 - val_loss: 27.4105
Epoch 8/50
 - 1s - loss: 6.7145 - val_loss: 27.4342
Epoch 9/50
 - 1s - loss: 6.3721 - val_loss: 27.3995
Epoch 10/50
 - 1s - loss: 6.2376 - val_loss: 27.1909
Epoch 11/50
 - 1s - loss: 6.1623 - val_loss: 27.1723
Epoch 12/50
 - 1s - loss: 6.1122 - val_loss: 26.8983
Epoch 13/50
 - 1s - loss: 5.9500 - val_loss: 26.7216
Epoch 14/50
 - 1s - loss: 5.8958 - val_loss: 26.7397
Epoch 15/50
 - 1s - loss: 5.9494 - val_loss: 26.3788
Epoch 16/50
 - 1s - loss: 5.7253 - val_loss: 26.3456
Epoch 17/50
 - 1s - loss: 5.6996 - val_loss: 26.2150
Epoch 18/50
 - 1s - loss: 5.6136 - val_loss: 26.4182
Epoch 19/50
 - 1s - loss: 5.5542 - val_loss: 26.1684
Epoch 20/50
 - 1s - loss: 5.5111 - val_loss: 25.8632
Epoch 21/50
 - 1s - loss: 5.4819 - val_loss: 25.8647
Epoch 22/50
 - 1s - loss: 5.4581 - val_loss: 25.7935
Epoch 23/50
 - 1s - loss: 5.3212 - val_loss: 25.8996
Epoch 24/50
 - 1s - loss: 5.3376 - val_loss: 25.7649
Epoch 25/50
 - 1s - loss: 5.1990 - val_loss: 25.5165
Epoch 26/50
 - 1s - loss: 5.1850 - val_loss: 25.3507
Epoch 27/50
 - 1s - loss: 5.0674 - val_loss: 25.2989
Epoch 28/50
 - 1s - loss: 5.0106 - val_loss: 25.2105
Epoch 29/50
 - 1s - loss: 5.0433 - val_loss: 25.3533
Epoch 30/50
 - 1s - loss: 4.9753 - val_loss: 25.0721
Epoch 31/50
 - 1s - loss: 4.9574 - val_loss: 25.0442
Epoch 32/50
 - 1s - loss: 4.8904 - val_loss: 25.1355
Epoch 33/50
 - 1s - loss: 4.7966 - val_loss: 25.1314
Epoch 34/50
 - 1s - loss: 4.8032 - val_loss: 24.7534
Epoch 35/50
 - 1s - loss: 4.7223 - val_loss: 25.1611
Epoch 36/50
 - 1s - loss: 4.7839 - val_loss: 24.9081
Epoch 37/50
 - 1s - loss: 4.6583 - val_loss: 24.6017
Epoch 38/50
 - 1s - loss: 4.5490 - val_loss: 24.4656
Epoch 39/50
 - 1s - loss: 4.5207 - val_loss: 24.3495
Epoch 40/50
 - 1s - loss: 4.4729 - val_loss: 24.4725
Epoch 41/50
 - 1s - loss: 4.4562 - val_loss: 24.4607
Epoch 42/50
 - 1s - loss: 4.4291 - val_loss: 24.1806
Epoch 43/50
 - 1s - loss: 4.2916 - val_loss: 24.1684
Epoch 44/50
 - 1s - loss: 4.4358 - val_loss: 24.2388
Epoch 45/50
 - 1s - loss: 4.2327 - val_loss: 24.2710
Epoch 46/50
 - 1s - loss: 4.3784 - val_loss: 23.8987
Epoch 47/50
 - 1s - loss: 4.1658 - val_loss: 24.1667
Epoch 48/50
 - 1s - loss: 4.1158 - val_loss: 23.9045
Epoch 49/50
 - 1s - loss: 4.2755 - val_loss: 23.6836
Epoch 50/50
 - 1s - loss: 4.2652 - val_loss: 23.6289
length of memory (state 0, action 0): 684, after forget
length of memory (state 0, action 1): 313, after forget
length of memory (state 1, action 0): 641, after forget
length of memory (state 1, action 1): 300, after forget
time = 1812	action = 0	current_phase = 1	next_phase = 0	reward = -4.214759	array([[ -4.4391375, -17.8699   ]], dtype=float32)
time = 1817	action = 0	current_phase = 1	next_phase = 0	reward = -3.232586	array([[ -4.3365316, -15.209095 ]], dtype=float32)
time = 1822	action = 0	current_phase = 1	next_phase = 0	reward = -3.222262	array([[ -4.5192075, -11.819859 ]], dtype=float32)
time = 1827	action = 0	current_phase = 1	next_phase = 0	reward = -3.585345	array([[ -7.325115 , -12.9351425]], dtype=float32)
time = 1832	action = 0	current_phase = 1	next_phase = 0	reward = -5.671889	array([[ -8.061865, -14.872074]], dtype=float32)
time = 1837	action = 0	current_phase = 1	next_phase = 0	reward = -7.900172	array([[-11.371262, -16.777287]], dtype=float32)
time = 1842	action = 1	current_phase = 1	next_phase = 0	reward = -15.865651	array([[-20.970106, -19.765007]], dtype=float32)
time = 1850	action = 1	current_phase = 0	next_phase = 1	reward = -12.206526	array([[-9.625795, -7.932169]], dtype=float32)
time = 1858	action = 1	current_phase = 1	next_phase = 0	reward = -8.607884	array([[-10.783058, -10.605234]], dtype=float32)
time = 1866	action = 0	current_phase = 0	next_phase = 1	reward = -0.509616	array([[-4.71239 , -9.565473]], dtype=float32)
time = 1871	action = 0	current_phase = 0	next_phase = 1	reward = -0.081341	array([[-4.397376, -8.731696]], dtype=float32)
time = 1876	action = 0	current_phase = 0	next_phase = 1	reward = -1.470074	array([[-5.122286, -8.695916]], dtype=float32)
time = 1881	action = 0	current_phase = 0	next_phase = 1	reward = -2.220411	array([[ -4.711157, -11.756753]], dtype=float32)
time = 1886	action = 0	current_phase = 0	next_phase = 1	reward = -3.514608	array([[ -5.0128856, -12.600169 ]], dtype=float32)
time = 1891	action = 0	current_phase = 0	next_phase = 1	reward = -5.068840	array([[ -6.225482, -14.02557 ]], dtype=float32)
time = 1896	action = 0	current_phase = 0	next_phase = 1	reward = -6.165952	array([[ -7.413806, -19.456509]], dtype=float32)
time = 1901	action = 0	current_phase = 0	next_phase = 1	reward = -8.606177	array([[ -9.290369, -20.179129]], dtype=float32)
time = 1906	action = 0	current_phase = 0	next_phase = 1	reward = -10.249577	array([[-13.491957, -20.878317]], dtype=float32)
time = 1911	action = 0	current_phase = 0	next_phase = 1	reward = -12.258334	array([[-21.975977, -24.393791]], dtype=float32)
time = 1916	action = 1	current_phase = 0	next_phase = 1	reward = -19.440580	array([[-28.021406, -24.73648 ]], dtype=float32)
time = 1924	action = 0	current_phase = 1	next_phase = 0	reward = -7.152129	array([[-11.013683, -12.901686]], dtype=float32)
time = 1929	action = 0	current_phase = 1	next_phase = 0	reward = -4.569890	array([[ -4.9401484, -18.869762 ]], dtype=float32)
time = 1934	action = 0	current_phase = 1	next_phase = 0	reward = -2.232382	array([[ -3.8054416, -15.080462 ]], dtype=float32)
time = 1939	action = 0	current_phase = 1	next_phase = 0	reward = -2.010987	array([[ -4.678133, -11.626498]], dtype=float32)
time = 1944	action = 0	current_phase = 1	next_phase = 0	reward = -2.023996	array([[ -4.455037, -10.251507]], dtype=float32)
time = 1949	action = 0	current_phase = 1	next_phase = 0	reward = -3.550829	array([[ -7.303612, -14.37089 ]], dtype=float32)
time = 1954	action = 0	current_phase = 1	next_phase = 0	reward = -6.012284	array([[ -7.992951, -14.74362 ]], dtype=float32)
time = 1959	action = 0	current_phase = 1	next_phase = 0	reward = -7.639922	array([[-13.6796665, -14.897136 ]], dtype=float32)
time = 1964	action = 1	current_phase = 1	next_phase = 0	reward = -13.690380	array([[-18.822674, -18.544   ]], dtype=float32)
time = 1972	action = 1	current_phase = 0	next_phase = 1	reward = -11.373017	array([[-8.2102165, -7.737849 ]], dtype=float32)
time = 1980	action = 1	current_phase = 1	next_phase = 0	reward = -8.283086	array([[-10.897331,  -9.365071]], dtype=float32)
time = 1988	action = 0	current_phase = 0	next_phase = 1	reward = -0.943433	array([[ -4.3703055, -10.091283 ]], dtype=float32)
time = 1993	action = 0	current_phase = 0	next_phase = 1	reward = -0.448342	array([[ -4.2825637, -10.426663 ]], dtype=float32)
time = 1998	action = 0	current_phase = 0	next_phase = 1	reward = -1.108597	array([[ -4.3282933, -11.259609 ]], dtype=float32)
time = 2003	action = 0	current_phase = 0	next_phase = 1	reward = -2.169644	array([[ -5.0645003, -10.806176 ]], dtype=float32)
time = 2008	action = 0	current_phase = 0	next_phase = 1	reward = -2.947228	array([[ -4.9573917, -11.442417 ]], dtype=float32)
time = 2013	action = 0	current_phase = 0	next_phase = 1	reward = -4.424927	array([[ -7.3872724, -12.817457 ]], dtype=float32)
time = 2018	action = 0	current_phase = 0	next_phase = 1	reward = -6.380005	array([[ -9.26929 , -16.328714]], dtype=float32)
time = 2023	action = 0	current_phase = 0	next_phase = 1	reward = -7.503942	array([[ -8.855518, -19.94089 ]], dtype=float32)
time = 2028	action = 0	current_phase = 0	next_phase = 1	reward = -10.425207	array([[-12.623906, -21.045599]], dtype=float32)
time = 2033	action = 0	current_phase = 0	next_phase = 1	reward = -11.932872	array([[-22.882065, -23.51071 ]], dtype=float32)
time = 2038	action = 0	current_phase = 0	next_phase = 1	reward = -14.338810	array([[-22.236647, -25.030912]], dtype=float32)
time = 2043	action = 1	current_phase = 0	next_phase = 1	reward = -22.354350	array([[-25.985981, -25.082304]], dtype=float32)
time = 2051	action = 0	current_phase = 1	next_phase = 0	reward = -9.374553	array([[-11.168505, -15.766319]], dtype=float32)
time = 2056	action = 0	current_phase = 1	next_phase = 0	reward = -6.325135	array([[ -6.5064077, -20.512693 ]], dtype=float32)
time = 2061	action = 0	current_phase = 1	next_phase = 0	reward = -4.789864	array([[ -3.6033928, -16.743126 ]], dtype=float32)
time = 2066	action = 0	current_phase = 1	next_phase = 0	reward = -3.935407	array([[ -4.4190774, -14.522198 ]], dtype=float32)
time = 2071	action = 0	current_phase = 1	next_phase = 0	reward = -3.430275	array([[ -5.082775 , -14.9309025]], dtype=float32)
time = 2076	action = 0	current_phase = 1	next_phase = 0	reward = -4.557367	array([[ -4.914684, -14.636607]], dtype=float32)
time = 2081	action = 0	current_phase = 1	next_phase = 0	reward = -6.282543	array([[ -9.980738, -14.88823 ]], dtype=float32)
time = 2086	action = 0	current_phase = 1	next_phase = 0	reward = -8.134252	array([[ -8.077839, -18.184978]], dtype=float32)
time = 2091	action = 0	current_phase = 1	next_phase = 0	reward = -10.205802	array([[-12.548704, -21.179277]], dtype=float32)
time = 2096	action = 1	current_phase = 1	next_phase = 0	reward = -18.560057	array([[-27.079008, -23.528315]], dtype=float32)
time = 2104	action = 1	current_phase = 0	next_phase = 1	reward = -14.490528	array([[-16.465485, -10.622686]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 12.4758 - val_loss: 6.4849
Epoch 2/50
 - 1s - loss: 12.2445 - val_loss: 6.6059
Epoch 3/50
 - 1s - loss: 12.0644 - val_loss: 6.4438
Epoch 4/50
 - 1s - loss: 11.8303 - val_loss: 6.2739
Epoch 5/50
 - 1s - loss: 11.7793 - val_loss: 6.2497
Epoch 6/50
 - 1s - loss: 11.6752 - val_loss: 6.3832
Epoch 7/50
 - 1s - loss: 11.5215 - val_loss: 6.1911
Epoch 8/50
 - 1s - loss: 11.5076 - val_loss: 5.9835
Epoch 9/50
 - 1s - loss: 11.2870 - val_loss: 6.1967
Epoch 10/50
 - 1s - loss: 11.1073 - val_loss: 6.1636
Epoch 11/50
 - 1s - loss: 11.1464 - val_loss: 6.1647
Epoch 12/50
 - 1s - loss: 10.9369 - val_loss: 6.1946
Epoch 13/50
 - 1s - loss: 10.8796 - val_loss: 6.0593
Epoch 14/50
 - 1s - loss: 10.8192 - val_loss: 5.9196
Epoch 15/50
 - 1s - loss: 10.6887 - val_loss: 5.7931
Epoch 16/50
 - 1s - loss: 10.6092 - val_loss: 5.8015
Epoch 17/50
 - 1s - loss: 10.4202 - val_loss: 5.5700
Epoch 18/50
 - 1s - loss: 10.4434 - val_loss: 5.8440
Epoch 19/50
 - 1s - loss: 10.3489 - val_loss: 5.7008
Epoch 20/50
 - 1s - loss: 10.3983 - val_loss: 5.6195
Epoch 21/50
 - 1s - loss: 10.2895 - val_loss: 5.5722
Epoch 22/50
 - 1s - loss: 10.2242 - val_loss: 5.4625
Epoch 23/50
 - 1s - loss: 10.0050 - val_loss: 5.4178
Epoch 24/50
 - 1s - loss: 10.0969 - val_loss: 5.4203
Epoch 25/50
 - 1s - loss: 9.9762 - val_loss: 5.3769
Epoch 26/50
 - 1s - loss: 9.8728 - val_loss: 5.3712
Epoch 27/50
 - 1s - loss: 9.9031 - val_loss: 5.4013
Epoch 28/50
 - 1s - loss: 9.7916 - val_loss: 5.6087
Epoch 29/50
 - 1s - loss: 9.7515 - val_loss: 5.1524
Epoch 30/50
 - 1s - loss: 9.5989 - val_loss: 5.1646
Epoch 31/50
 - 1s - loss: 9.5294 - val_loss: 5.1696
Epoch 32/50
 - 1s - loss: 9.5381 - val_loss: 5.1576
Epoch 33/50
 - 1s - loss: 9.4506 - val_loss: 5.0202
Epoch 34/50
 - 1s - loss: 9.4140 - val_loss: 4.9745
Epoch 35/50
 - 1s - loss: 9.4481 - val_loss: 4.9724
Epoch 36/50
 - 1s - loss: 9.2924 - val_loss: 4.8945
Epoch 37/50
 - 1s - loss: 9.3478 - val_loss: 5.0718
Epoch 38/50
 - 1s - loss: 9.2360 - val_loss: 4.8463
Epoch 39/50
 - 1s - loss: 9.1929 - val_loss: 4.9182
Epoch 40/50
 - 1s - loss: 9.1660 - val_loss: 4.8005
Epoch 41/50
 - 1s - loss: 9.1654 - val_loss: 4.7182
Epoch 42/50
 - 1s - loss: 9.0794 - val_loss: 4.5977
Epoch 43/50
 - 1s - loss: 9.0466 - val_loss: 4.7042
Epoch 44/50
 - 1s - loss: 8.9803 - val_loss: 4.6865
Epoch 45/50
 - 1s - loss: 8.9100 - val_loss: 4.6472
Epoch 46/50
 - 1s - loss: 8.8868 - val_loss: 4.4966
Epoch 47/50
 - 1s - loss: 8.8191 - val_loss: 4.5352
Epoch 48/50
 - 1s - loss: 8.9024 - val_loss: 4.4670
Epoch 49/50
 - 1s - loss: 8.8535 - val_loss: 4.4776
Epoch 50/50
 - 1s - loss: 8.7954 - val_loss: 4.6701
length of memory (state 0, action 0): 705, after forget
length of memory (state 0, action 1): 318, after forget
length of memory (state 1, action 0): 664, after forget
length of memory (state 1, action 1): 305, after forget
time = 2112	action = 1	current_phase = 1	next_phase = 0	reward = -7.608689	array([[-14.133755, -10.82334 ]], dtype=float32)
time = 2120	action = 0	current_phase = 0	next_phase = 1	reward = -0.314682	array([[ -4.435254, -13.582533]], dtype=float32)
time = 2125	action = 0	current_phase = 0	next_phase = 1	reward = -0.157078	array([[-4.7825546, -9.093826 ]], dtype=float32)
time = 2130	action = 0	current_phase = 0	next_phase = 1	reward = -0.817541	array([[ -5.353526 , -10.5194235]], dtype=float32)
time = 2135	action = 0	current_phase = 0	next_phase = 1	reward = -1.950580	array([[ -6.108   , -10.559249]], dtype=float32)
time = 2140	action = 0	current_phase = 0	next_phase = 1	reward = -3.639835	array([[ -7.5711164, -11.278793 ]], dtype=float32)
time = 2145	action = 0	current_phase = 0	next_phase = 1	reward = -4.845540	array([[ -8.273564, -16.03608 ]], dtype=float32)
time = 2150	action = 0	current_phase = 0	next_phase = 1	reward = -6.436213	array([[-12.193121, -19.953165]], dtype=float32)
time = 2155	action = 0	current_phase = 0	next_phase = 1	reward = -8.809821	array([[-16.251797, -21.594414]], dtype=float32)
time = 2160	action = 0	current_phase = 0	next_phase = 1	reward = -10.826695	array([[-16.902523, -22.82889 ]], dtype=float32)
time = 2165	action = 1	current_phase = 0	next_phase = 1	reward = -17.800988	array([[-27.03669 , -26.546396]], dtype=float32)
time = 2173	action = 1	current_phase = 1	next_phase = 0	reward = -12.869863	array([[-12.463137, -11.87052 ]], dtype=float32)
time = 2181	action = 1	current_phase = 0	next_phase = 1	reward = -7.626331	array([[-17.383865, -12.742284]], dtype=float32)
time = 2189	action = 0	current_phase = 1	next_phase = 0	reward = -2.041391	array([[ -4.448957, -10.861728]], dtype=float32)
time = 2194	action = 0	current_phase = 1	next_phase = 0	reward = -1.634121	array([[ -4.307648, -13.042249]], dtype=float32)
time = 2199	action = 0	current_phase = 1	next_phase = 0	reward = -2.204079	array([[ -5.341729, -13.173084]], dtype=float32)
time = 2204	action = 0	current_phase = 1	next_phase = 0	reward = -4.183921	array([[ -9.359483, -14.900677]], dtype=float32)
time = 2209	action = 0	current_phase = 1	next_phase = 0	reward = -4.713536	array([[-10.805819, -15.420507]], dtype=float32)
time = 2214	action = 0	current_phase = 1	next_phase = 0	reward = -6.178876	array([[ -9.526758, -17.292767]], dtype=float32)
time = 2219	action = 0	current_phase = 1	next_phase = 0	reward = -9.058913	array([[-16.024748, -19.612715]], dtype=float32)
time = 2224	action = 1	current_phase = 1	next_phase = 0	reward = -16.648935	array([[-25.756308, -23.000452]], dtype=float32)
time = 2232	action = 1	current_phase = 0	next_phase = 1	reward = -13.979189	array([[-17.133875, -10.378211]], dtype=float32)
time = 2240	action = 1	current_phase = 1	next_phase = 0	reward = -8.280622	array([[-13.031273, -11.715125]], dtype=float32)
time = 2248	action = 0	current_phase = 0	next_phase = 1	reward = -0.655127	array([[ -4.3949895, -10.750174 ]], dtype=float32)
time = 2253	action = 0	current_phase = 0	next_phase = 1	reward = 0.259845	array([[ -4.3421984, -11.412227 ]], dtype=float32)
time = 2258	action = 0	current_phase = 0	next_phase = 1	reward = -0.935928	array([[ -4.5934496, -10.146679 ]], dtype=float32)
time = 2263	action = 0	current_phase = 0	next_phase = 1	reward = -1.537001	array([[ -5.319912, -10.135483]], dtype=float32)
time = 2268	action = 0	current_phase = 0	next_phase = 1	reward = -2.745295	array([[ -6.7906876, -10.5019245]], dtype=float32)
time = 2273	action = 0	current_phase = 0	next_phase = 1	reward = -3.999652	array([[ -8.894839 , -12.8161125]], dtype=float32)
time = 2278	action = 0	current_phase = 0	next_phase = 1	reward = -5.997928	array([[-12.128188, -16.90234 ]], dtype=float32)
time = 2283	action = 0	current_phase = 0	next_phase = 1	reward = -7.313235	array([[-13.454196, -20.696083]], dtype=float32)
time = 2288	action = 0	current_phase = 0	next_phase = 1	reward = -10.128884	array([[-18.402983, -22.237139]], dtype=float32)
time = 2293	action = 0	current_phase = 0	next_phase = 1	reward = -12.148877	array([[-21.172314, -24.720753]], dtype=float32)
time = 2298	action = 1	current_phase = 0	next_phase = 1	reward = -19.844467	array([[-30.361277, -27.212433]], dtype=float32)
time = 2306	action = 0	current_phase = 1	next_phase = 0	reward = -7.380885	array([[-11.551584, -14.55316 ]], dtype=float32)
time = 2311	action = 0	current_phase = 1	next_phase = 0	reward = -4.748247	array([[ -4.7578435, -18.503279 ]], dtype=float32)
time = 2316	action = 0	current_phase = 1	next_phase = 0	reward = -3.427944	array([[ -4.2044945, -15.113109 ]], dtype=float32)
time = 2321	action = 0	current_phase = 1	next_phase = 0	reward = -3.623978	array([[ -5.9005756, -12.941694 ]], dtype=float32)
time = 2326	action = 0	current_phase = 1	next_phase = 0	reward = -2.934483	array([[ -7.7808037, -13.729482 ]], dtype=float32)
time = 2331	action = 0	current_phase = 1	next_phase = 0	reward = -4.175311	array([[-10.358985, -14.516471]], dtype=float32)
time = 2336	action = 0	current_phase = 1	next_phase = 0	reward = -6.557949	array([[-13.515342, -15.207179]], dtype=float32)
time = 2341	action = 1	current_phase = 1	next_phase = 0	reward = -12.928140	array([[-21.20864 , -17.832754]], dtype=float32)
time = 2349	action = 1	current_phase = 0	next_phase = 1	reward = -11.130581	array([[-9.243068 , -7.8173027]], dtype=float32)
time = 2357	action = 1	current_phase = 1	next_phase = 0	reward = -7.815689	array([[-10.924868,  -9.792094]], dtype=float32)
time = 2365	action = 0	current_phase = 0	next_phase = 1	reward = -1.956782	array([[-5.168929, -9.110851]], dtype=float32)
time = 2370	action = 0	current_phase = 0	next_phase = 1	reward = -1.963770	array([[ -4.268237, -10.878815]], dtype=float32)
time = 2375	action = 0	current_phase = 0	next_phase = 1	reward = -2.413462	array([[ -4.916855, -12.217055]], dtype=float32)
time = 2380	action = 0	current_phase = 0	next_phase = 1	reward = -3.271350	array([[ -4.8593826, -13.410934 ]], dtype=float32)
time = 2385	action = 0	current_phase = 0	next_phase = 1	reward = -4.088303	array([[ -6.4394255, -12.943797 ]], dtype=float32)
time = 2390	action = 0	current_phase = 0	next_phase = 1	reward = -5.191024	array([[-10.55641  , -15.7603445]], dtype=float32)
time = 2395	action = 0	current_phase = 0	next_phase = 1	reward = -7.581783	array([[-13.014872, -20.36152 ]], dtype=float32)
time = 2400	action = 0	current_phase = 0	next_phase = 1	reward = -7.778466	array([[-14.351646, -21.350397]], dtype=float32)
time = 2405	action = 0	current_phase = 0	next_phase = 1	reward = -10.164860	array([[-16.68739 , -22.671562]], dtype=float32)
time = 2410	action = 1	current_phase = 0	next_phase = 1	reward = -17.709304	array([[-26.779722, -26.122654]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 10.0879 - val_loss: 2.8051
Epoch 2/50
 - 1s - loss: 9.7614 - val_loss: 2.6134
Epoch 3/50
 - 1s - loss: 9.7732 - val_loss: 2.7487
Epoch 4/50
 - 1s - loss: 9.5352 - val_loss: 2.5409
Epoch 5/50
 - 1s - loss: 9.4776 - val_loss: 2.5578
Epoch 6/50
 - 1s - loss: 9.4270 - val_loss: 2.4756
Epoch 7/50
 - 1s - loss: 9.3488 - val_loss: 2.6432
Epoch 8/50
 - 1s - loss: 9.2067 - val_loss: 2.4775
Epoch 9/50
 - 1s - loss: 9.1594 - val_loss: 2.3893
Epoch 10/50
 - 1s - loss: 8.9938 - val_loss: 2.7162
Epoch 11/50
 - 1s - loss: 9.0475 - val_loss: 2.5053
Epoch 12/50
 - 1s - loss: 8.9136 - val_loss: 2.2868
Epoch 13/50
 - 1s - loss: 8.9467 - val_loss: 2.4135
Epoch 14/50
 - 1s - loss: 8.7972 - val_loss: 2.3495
Epoch 15/50
 - 1s - loss: 8.7817 - val_loss: 2.4786
Epoch 16/50
 - 1s - loss: 8.7522 - val_loss: 2.4679
Epoch 17/50
 - 1s - loss: 8.6991 - val_loss: 2.2948
Epoch 18/50
 - 1s - loss: 8.7236 - val_loss: 2.3252
Epoch 19/50
 - 1s - loss: 8.5571 - val_loss: 2.1930
Epoch 20/50
 - 1s - loss: 8.4934 - val_loss: 2.4950
Epoch 21/50
 - 1s - loss: 8.4227 - val_loss: 2.4002
Epoch 22/50
 - 1s - loss: 8.4424 - val_loss: 2.4152
Epoch 23/50
 - 1s - loss: 8.4146 - val_loss: 2.3073
Epoch 24/50
 - 1s - loss: 8.3359 - val_loss: 2.2320
Epoch 25/50
 - 1s - loss: 8.2758 - val_loss: 2.3868
Epoch 26/50
 - 1s - loss: 8.2997 - val_loss: 2.3575
Epoch 27/50
 - 1s - loss: 8.2173 - val_loss: 2.0911
Epoch 28/50
 - 1s - loss: 8.2907 - val_loss: 2.2168
Epoch 29/50
 - 1s - loss: 8.1080 - val_loss: 2.4310
Epoch 30/50
 - 1s - loss: 8.0587 - val_loss: 2.0943
Epoch 31/50
 - 1s - loss: 8.0719 - val_loss: 2.1332
Epoch 32/50
 - 1s - loss: 8.0564 - val_loss: 2.0685
Epoch 33/50
 - 1s - loss: 7.9712 - val_loss: 2.1620
Epoch 34/50
 - 1s - loss: 7.9365 - val_loss: 2.0747
Epoch 35/50
 - 1s - loss: 7.9186 - val_loss: 2.1110
Epoch 36/50
 - 1s - loss: 7.9162 - val_loss: 2.2080
Epoch 37/50
 - 1s - loss: 7.9077 - val_loss: 2.1590
Epoch 38/50
 - 1s - loss: 7.8885 - val_loss: 2.2524
Epoch 39/50
 - 1s - loss: 7.9298 - val_loss: 1.9532
Epoch 40/50
 - 1s - loss: 7.8126 - val_loss: 1.9216
Epoch 41/50
 - 1s - loss: 7.8676 - val_loss: 2.2230
Epoch 42/50
 - 1s - loss: 7.8362 - val_loss: 2.2534
Epoch 43/50
 - 1s - loss: 7.8652 - val_loss: 2.0020
Epoch 44/50
 - 1s - loss: 7.7863 - val_loss: 2.0141
Epoch 45/50
 - 1s - loss: 7.6594 - val_loss: 2.2247
Epoch 46/50
 - 1s - loss: 7.6910 - val_loss: 2.0728
Epoch 47/50
 - 1s - loss: 7.7529 - val_loss: 2.1224
Epoch 48/50
 - 1s - loss: 7.6991 - val_loss: 2.0704
Epoch 49/50
 - 1s - loss: 7.7000 - val_loss: 2.2205
Epoch 50/50
 - 1s - loss: 7.6575 - val_loss: 1.9322
length of memory (state 0, action 0): 733, after forget
length of memory (state 0, action 1): 324, after forget
length of memory (state 1, action 0): 678, after forget
length of memory (state 1, action 1): 311, after forget
time = 2418	action = 0	current_phase = 1	next_phase = 0	reward = -6.662503	array([[-11.551406, -11.838275]], dtype=float32)
time = 2423	action = 0	current_phase = 1	next_phase = 0	reward = -3.615430	array([[ -3.9053288, -16.353418 ]], dtype=float32)
time = 2428	action = 0	current_phase = 1	next_phase = 0	reward = -2.608506	array([[ -4.0236487, -14.449756 ]], dtype=float32)
time = 2433	action = 0	current_phase = 1	next_phase = 0	reward = -1.970541	array([[ -4.8840733, -12.885461 ]], dtype=float32)
time = 2438	action = 0	current_phase = 1	next_phase = 0	reward = -2.398130	array([[ -8.901414, -13.132451]], dtype=float32)
time = 2443	action = 0	current_phase = 1	next_phase = 0	reward = -3.686665	array([[-10.538778, -14.21361 ]], dtype=float32)
time = 2448	action = 0	current_phase = 1	next_phase = 0	reward = -5.737822	array([[-11.00666 , -15.116758]], dtype=float32)
time = 2453	action = 0	current_phase = 1	next_phase = 0	reward = -7.651186	array([[-18.307096, -18.42716 ]], dtype=float32)
time = 2458	action = 1	current_phase = 1	next_phase = 0	reward = -14.148789	array([[-26.815096, -22.5611  ]], dtype=float32)
time = 2466	action = 0	current_phase = 0	next_phase = 1	reward = -5.710106	array([[ -8.265965, -10.401142]], dtype=float32)
time = 2471	action = 0	current_phase = 0	next_phase = 1	reward = -3.751530	array([[ -4.316851, -15.11719 ]], dtype=float32)
time = 2476	action = 0	current_phase = 0	next_phase = 1	reward = -2.222867	array([[ -4.421969, -12.142555]], dtype=float32)
time = 2481	action = 0	current_phase = 0	next_phase = 1	reward = 0.018524	array([[-5.84663 , -9.863301]], dtype=float32)
time = 2486	action = 1	current_phase = 0	next_phase = 1	reward = -2.045722	array([[-7.0189676, -6.751901 ]], dtype=float32)
time = 2494	action = 0	current_phase = 1	next_phase = 0	reward = -2.270331	array([[-6.021955, -8.948734]], dtype=float32)
time = 2499	action = 0	current_phase = 1	next_phase = 0	reward = -3.415377	array([[-6.1344805, -9.995359 ]], dtype=float32)
time = 2504	action = 0	current_phase = 1	next_phase = 0	reward = -5.644288	array([[ -7.5899844, -12.649854 ]], dtype=float32)
time = 2509	action = 1	current_phase = 1	next_phase = 0	reward = -10.537235	array([[-20.025671, -17.069927]], dtype=float32)
time = 2517	action = 0	current_phase = 0	next_phase = 1	reward = -3.774319	array([[-7.2251186, -8.137001 ]], dtype=float32)
time = 2522	action = 0	current_phase = 0	next_phase = 1	reward = -2.071102	array([[ -3.8139286, -11.654954 ]], dtype=float32)
time = 2527	action = 0	current_phase = 0	next_phase = 1	reward = -1.769129	array([[ -5.050063, -12.108833]], dtype=float32)
time = 2532	action = 0	current_phase = 0	next_phase = 1	reward = -1.227051	array([[-6.1250334, -9.551126 ]], dtype=float32)
time = 2537	action = 0	current_phase = 0	next_phase = 1	reward = -1.898939	array([[ -5.1925325, -11.695103 ]], dtype=float32)
time = 2542	action = 0	current_phase = 0	next_phase = 1	reward = -2.663341	array([[ -6.369591, -11.236241]], dtype=float32)
time = 2547	action = 0	current_phase = 0	next_phase = 1	reward = -4.365820	array([[ -8.900266, -14.293774]], dtype=float32)
time = 2552	action = 0	current_phase = 0	next_phase = 1	reward = -5.490713	array([[-12.745676, -20.068039]], dtype=float32)
time = 2557	action = 0	current_phase = 0	next_phase = 1	reward = -7.845058	array([[-16.487122, -22.744686]], dtype=float32)
time = 2562	action = 0	current_phase = 0	next_phase = 1	reward = -9.045862	array([[-19.915735, -24.313053]], dtype=float32)
time = 2567	action = 0	current_phase = 0	next_phase = 1	reward = -10.954786	array([[-25.706165, -26.857107]], dtype=float32)
time = 2572	action = 1	current_phase = 0	next_phase = 1	reward = -16.715783	array([[-28.46632 , -27.711348]], dtype=float32)
time = 2580	action = 0	current_phase = 1	next_phase = 0	reward = -5.759263	array([[-12.672997, -12.689906]], dtype=float32)
time = 2585	action = 0	current_phase = 1	next_phase = 0	reward = -2.697182	array([[ -4.5142307, -15.637342 ]], dtype=float32)
time = 2590	action = 0	current_phase = 1	next_phase = 0	reward = -1.416023	array([[ -4.535708, -12.600563]], dtype=float32)
time = 2595	action = 0	current_phase = 1	next_phase = 0	reward = -1.289520	array([[ -5.8959546, -11.458127 ]], dtype=float32)
time = 2600	action = 0	current_phase = 1	next_phase = 0	reward = -2.803338	array([[-10.268136, -13.444249]], dtype=float32)
time = 2605	action = 0	current_phase = 1	next_phase = 0	reward = -3.888463	array([[-10.058125, -13.40858 ]], dtype=float32)
time = 2610	action = 0	current_phase = 1	next_phase = 0	reward = -5.892215	array([[-14.808209, -17.132301]], dtype=float32)
time = 2615	action = 1	current_phase = 1	next_phase = 0	reward = -11.881741	array([[-19.935394, -19.48459 ]], dtype=float32)
time = 2623	action = 0	current_phase = 0	next_phase = 1	reward = -4.348341	array([[-7.666833, -8.932886]], dtype=float32)
time = 2628	action = 0	current_phase = 0	next_phase = 1	reward = -2.598432	array([[ -3.7774682, -13.25116  ]], dtype=float32)
time = 2633	action = 0	current_phase = 0	next_phase = 1	reward = -0.808053	array([[ -4.3856134, -12.71168  ]], dtype=float32)
time = 2638	action = 0	current_phase = 0	next_phase = 1	reward = -0.117538	array([[-5.198141, -9.464781]], dtype=float32)
time = 2643	action = 0	current_phase = 0	next_phase = 1	reward = 0.158552	array([[-6.261247, -7.144502]], dtype=float32)
time = 2648	action = 1	current_phase = 0	next_phase = 1	reward = -3.029880	array([[-7.5137625, -6.7902694]], dtype=float32)
time = 2656	action = 0	current_phase = 1	next_phase = 0	reward = -2.432803	array([[-5.9404225, -9.010219 ]], dtype=float32)
time = 2661	action = 0	current_phase = 1	next_phase = 0	reward = -3.127947	array([[ -4.6876483, -13.355297 ]], dtype=float32)
time = 2666	action = 0	current_phase = 1	next_phase = 0	reward = -4.078820	array([[ -7.9122477, -14.106019 ]], dtype=float32)
time = 2671	action = 0	current_phase = 1	next_phase = 0	reward = -4.886280	array([[-10.124744, -14.040089]], dtype=float32)
time = 2676	action = 0	current_phase = 1	next_phase = 0	reward = -5.976369	array([[-10.623578, -15.654062]], dtype=float32)
time = 2681	action = 0	current_phase = 1	next_phase = 0	reward = -7.843295	array([[-12.3718405, -19.649996 ]], dtype=float32)
time = 2686	action = 0	current_phase = 1	next_phase = 0	reward = -7.692003	array([[-19.149208, -22.586237]], dtype=float32)
time = 2691	action = 0	current_phase = 1	next_phase = 0	reward = -8.726284	array([[-17.769264, -18.606133]], dtype=float32)
time = 2696	action = 0	current_phase = 1	next_phase = 0	reward = -8.875408	array([[-14.509839, -16.757011]], dtype=float32)
time = 2701	action = 0	current_phase = 1	next_phase = 0	reward = -10.126562	array([[-17.374271, -17.738297]], dtype=float32)
time = 2706	action = 1	current_phase = 1	next_phase = 0	reward = -16.143225	array([[-21.111282, -20.576883]], dtype=float32)
time = 2714	action = 1	current_phase = 0	next_phase = 1	reward = -13.069126	array([[-15.356848, -12.082559]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 7.0696 - val_loss: 3.7355
Epoch 2/50
 - 1s - loss: 6.8837 - val_loss: 3.8772
Epoch 3/50
 - 1s - loss: 6.7802 - val_loss: 3.8479
Epoch 4/50
 - 1s - loss: 6.6329 - val_loss: 3.7590
Epoch 5/50
 - 1s - loss: 6.5922 - val_loss: 3.8160
Epoch 6/50
 - 1s - loss: 6.5942 - val_loss: 3.8291
Epoch 7/50
 - 1s - loss: 6.6030 - val_loss: 3.8592
Epoch 8/50
 - 1s - loss: 6.5219 - val_loss: 3.8622
Epoch 9/50
 - 1s - loss: 6.5434 - val_loss: 3.8090
Epoch 10/50
 - 1s - loss: 6.5565 - val_loss: 3.9077
Epoch 11/50
 - 1s - loss: 6.4195 - val_loss: 3.8438
length of memory (state 0, action 0): 753, after forget
length of memory (state 0, action 1): 328, after forget
length of memory (state 1, action 0): 706, after forget
length of memory (state 1, action 1): 315, after forget
time = 2722	action = 1	current_phase = 1	next_phase = 0	reward = -9.690977	array([[-14.856534, -10.632668]], dtype=float32)
time = 2730	action = 0	current_phase = 0	next_phase = 1	reward = -3.080089	array([[ -4.686474, -11.458395]], dtype=float32)
time = 2735	action = 0	current_phase = 0	next_phase = 1	reward = -3.624212	array([[ -3.9271479, -13.474962 ]], dtype=float32)
time = 2740	action = 0	current_phase = 0	next_phase = 1	reward = -5.223245	array([[ -4.6088023, -14.563649 ]], dtype=float32)
time = 2745	action = 0	current_phase = 0	next_phase = 1	reward = -6.242215	array([[ -7.4040546, -17.731153 ]], dtype=float32)
time = 2750	action = 0	current_phase = 0	next_phase = 1	reward = -6.995714	array([[-11.204329, -20.75405 ]], dtype=float32)
time = 2755	action = 0	current_phase = 0	next_phase = 1	reward = -8.593138	array([[-13.2058525, -22.438995 ]], dtype=float32)
time = 2760	action = 0	current_phase = 0	next_phase = 1	reward = -9.929316	array([[-14.457052, -23.150713]], dtype=float32)
time = 2765	action = 0	current_phase = 0	next_phase = 1	reward = -11.468620	array([[-22.210909, -26.221073]], dtype=float32)
time = 2770	action = 1	current_phase = 0	next_phase = 1	reward = -19.903095	array([[-28.994804, -27.925516]], dtype=float32)
time = 2778	action = 0	current_phase = 1	next_phase = 0	reward = -8.055862	array([[-14.487413, -16.96837 ]], dtype=float32)
time = 2783	action = 0	current_phase = 1	next_phase = 0	reward = -4.735602	array([[ -5.981985, -20.027565]], dtype=float32)
time = 2788	action = 0	current_phase = 1	next_phase = 0	reward = -2.388942	array([[ -4.0391393, -15.9372015]], dtype=float32)
time = 2793	action = 0	current_phase = 1	next_phase = 0	reward = -2.039547	array([[ -5.6490183, -14.161997 ]], dtype=float32)
time = 2798	action = 0	current_phase = 1	next_phase = 0	reward = -1.576220	array([[ -5.9452853, -12.304398 ]], dtype=float32)
time = 2803	action = 0	current_phase = 1	next_phase = 0	reward = -2.796002	array([[ -8.986778, -14.462016]], dtype=float32)
time = 2808	action = 0	current_phase = 1	next_phase = 0	reward = -4.813419	array([[-10.377162, -15.193412]], dtype=float32)
time = 2813	action = 1	current_phase = 1	next_phase = 0	reward = -10.983551	array([[-17.922468, -16.603075]], dtype=float32)
time = 2821	action = 0	current_phase = 0	next_phase = 1	reward = -4.273659	array([[-6.974059, -8.993056]], dtype=float32)
time = 2826	action = 0	current_phase = 0	next_phase = 1	reward = -2.838395	array([[ -3.6015503, -11.739232 ]], dtype=float32)
time = 2831	action = 0	current_phase = 0	next_phase = 1	reward = -1.407118	array([[ -4.149092, -12.873342]], dtype=float32)
time = 2836	action = 0	current_phase = 0	next_phase = 1	reward = -0.996315	array([[-4.960663, -9.450814]], dtype=float32)
time = 2841	action = 0	current_phase = 0	next_phase = 1	reward = -1.195955	array([[-5.5133967, -9.05637  ]], dtype=float32)
time = 2846	action = 0	current_phase = 0	next_phase = 1	reward = -2.541539	array([[-6.975592, -9.263495]], dtype=float32)
time = 2851	action = 0	current_phase = 0	next_phase = 1	reward = -4.019675	array([[ -8.654581, -10.507954]], dtype=float32)
time = 2856	action = 0	current_phase = 0	next_phase = 1	reward = -5.532907	array([[-13.765804, -16.828457]], dtype=float32)
time = 2861	action = 0	current_phase = 0	next_phase = 1	reward = -7.299277	array([[-14.654078, -21.83764 ]], dtype=float32)
time = 2866	action = 0	current_phase = 0	next_phase = 1	reward = -9.562159	array([[-17.120537, -23.410471]], dtype=float32)
time = 2871	action = 0	current_phase = 0	next_phase = 1	reward = -11.341560	array([[-22.31658 , -26.246683]], dtype=float32)
time = 2876	action = 0	current_phase = 0	next_phase = 1	reward = -13.127532	array([[-26.294052, -27.689686]], dtype=float32)
time = 2881	action = 1	current_phase = 0	next_phase = 1	reward = -20.569916	array([[-32.443867, -28.65659 ]], dtype=float32)
time = 2889	action = 0	current_phase = 1	next_phase = 0	reward = -8.747958	array([[-10.047454, -16.961721]], dtype=float32)
time = 2894	action = 0	current_phase = 1	next_phase = 0	reward = -6.929847	array([[ -5.945106, -19.10128 ]], dtype=float32)
time = 2899	action = 0	current_phase = 1	next_phase = 0	reward = -5.387307	array([[ -5.4876113, -18.008358 ]], dtype=float32)
time = 2904	action = 0	current_phase = 1	next_phase = 0	reward = -4.973153	array([[ -6.679386, -16.543087]], dtype=float32)
time = 2909	action = 0	current_phase = 1	next_phase = 0	reward = -4.374422	array([[ -8.104674, -16.073832]], dtype=float32)
time = 2914	action = 0	current_phase = 1	next_phase = 0	reward = -5.396903	array([[ -8.727465, -16.224655]], dtype=float32)
time = 2919	action = 0	current_phase = 1	next_phase = 0	reward = -7.811781	array([[-12.03525 , -19.259266]], dtype=float32)
time = 2924	action = 0	current_phase = 1	next_phase = 0	reward = -9.607140	array([[-18.514315, -21.781073]], dtype=float32)
time = 2929	action = 0	current_phase = 1	next_phase = 0	reward = -11.619254	array([[-23.204582, -26.30321 ]], dtype=float32)
time = 2934	action = 0	current_phase = 1	next_phase = 0	reward = -12.010473	array([[-22.583254, -28.766594]], dtype=float32)
time = 2939	action = 1	current_phase = 1	next_phase = 0	reward = -17.529684	array([[-30.644924, -26.877031]], dtype=float32)
time = 2947	action = 0	current_phase = 0	next_phase = 1	reward = -6.517714	array([[-11.419544, -17.968878]], dtype=float32)
time = 2952	action = 0	current_phase = 0	next_phase = 1	reward = -3.287501	array([[ -4.7708554, -14.457338 ]], dtype=float32)
time = 2957	action = 0	current_phase = 0	next_phase = 1	reward = -2.442899	array([[ -5.4998784, -11.712837 ]], dtype=float32)
time = 2962	action = 0	current_phase = 0	next_phase = 1	reward = -1.543110	array([[ -5.7371335, -10.282841 ]], dtype=float32)
time = 2967	action = 0	current_phase = 0	next_phase = 1	reward = -1.595451	array([[ -5.5812693, -11.025133 ]], dtype=float32)
time = 2972	action = 0	current_phase = 0	next_phase = 1	reward = -3.403422	array([[ -7.813302, -10.301324]], dtype=float32)
time = 2977	action = 0	current_phase = 0	next_phase = 1	reward = -4.682867	array([[-11.312765, -14.58093 ]], dtype=float32)
time = 2982	action = 0	current_phase = 0	next_phase = 1	reward = -6.100730	array([[-14.818005, -20.440754]], dtype=float32)
time = 2987	action = 0	current_phase = 0	next_phase = 1	reward = -9.012641	array([[-19.000887, -22.243708]], dtype=float32)
time = 2992	action = 0	current_phase = 0	next_phase = 1	reward = -9.733824	array([[-19.490768, -24.321   ]], dtype=float32)
time = 2997	action = 1	current_phase = 0	next_phase = 1	reward = -16.778761	array([[-27.746254, -27.679844]], dtype=float32)
time = 3005	action = 1	current_phase = 1	next_phase = 0	reward = -11.343610	array([[-11.417897, -10.396033]], dtype=float32)
time = 3013	action = 1	current_phase = 0	next_phase = 1	reward = -6.469034	array([[-13.210398,  -9.356728]], dtype=float32)
time = 3021	action = 0	current_phase = 1	next_phase = 0	reward = -1.992333	array([[ -4.5006866, -10.751157 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 7.9596 - val_loss: 1.0872
Epoch 2/50
 - 1s - loss: 7.9914 - val_loss: 1.0379
Epoch 3/50
 - 1s - loss: 7.8558 - val_loss: 1.0253
Epoch 4/50
 - 1s - loss: 7.7765 - val_loss: 1.0305
Epoch 5/50
 - 1s - loss: 7.8301 - val_loss: 1.0434
Epoch 6/50
 - 1s - loss: 7.6293 - val_loss: 1.1634
Epoch 7/50
 - 1s - loss: 7.6162 - val_loss: 1.1121
Epoch 8/50
 - 1s - loss: 7.6040 - val_loss: 0.9871
Epoch 9/50
 - 1s - loss: 7.6488 - val_loss: 1.0133
Epoch 10/50
 - 1s - loss: 7.5428 - val_loss: 1.0093
Epoch 11/50
 - 1s - loss: 7.5712 - val_loss: 0.9288
Epoch 12/50
 - 1s - loss: 7.4782 - val_loss: 1.0170
Epoch 13/50
 - 1s - loss: 7.5028 - val_loss: 0.9722
Epoch 14/50
 - 1s - loss: 7.4668 - val_loss: 1.1496
Epoch 15/50
 - 1s - loss: 7.3710 - val_loss: 1.0124
Epoch 16/50
 - 1s - loss: 7.3755 - val_loss: 1.0681
Epoch 17/50
 - 1s - loss: 7.3397 - val_loss: 1.0841
Epoch 18/50
 - 1s - loss: 7.3224 - val_loss: 1.0725
Epoch 19/50
 - 1s - loss: 7.3588 - val_loss: 1.1182
Epoch 20/50
 - 1s - loss: 7.2569 - val_loss: 1.0416
Epoch 21/50
 - 1s - loss: 7.2411 - val_loss: 1.0346
length of memory (state 0, action 0): 783, after forget
length of memory (state 0, action 1): 332, after forget
length of memory (state 1, action 0): 724, after forget
length of memory (state 1, action 1): 319, after forget
time = 3026	action = 0	current_phase = 1	next_phase = 0	reward = -1.751051	array([[ -5.413051, -12.819551]], dtype=float32)
time = 3031	action = 0	current_phase = 1	next_phase = 0	reward = -3.020486	array([[ -5.4984245, -14.369301 ]], dtype=float32)
time = 3036	action = 0	current_phase = 1	next_phase = 0	reward = -3.949777	array([[ -8.004108, -16.216383]], dtype=float32)
time = 3041	action = 0	current_phase = 1	next_phase = 0	reward = -4.902926	array([[ -9.77517, -17.30411]], dtype=float32)
time = 3046	action = 0	current_phase = 1	next_phase = 0	reward = -7.040152	array([[ -9.180974, -18.62182 ]], dtype=float32)
time = 3051	action = 0	current_phase = 1	next_phase = 0	reward = -9.434501	array([[-16.408335, -21.028847]], dtype=float32)
time = 3056	action = 1	current_phase = 1	next_phase = 0	reward = -17.283534	array([[-25.549604, -25.423527]], dtype=float32)
time = 3064	action = 0	current_phase = 0	next_phase = 1	reward = -6.766282	array([[-12.716788, -17.31735 ]], dtype=float32)
time = 3069	action = 0	current_phase = 0	next_phase = 1	reward = -4.217594	array([[ -4.1321473, -14.767976 ]], dtype=float32)
time = 3074	action = 0	current_phase = 0	next_phase = 1	reward = -2.212553	array([[ -4.616374, -13.552913]], dtype=float32)
time = 3079	action = 0	current_phase = 0	next_phase = 1	reward = -0.208996	array([[-5.998922, -9.965379]], dtype=float32)
time = 3084	action = 0	current_phase = 0	next_phase = 1	reward = -0.633025	array([[-5.9272594, -8.444638 ]], dtype=float32)
time = 3089	action = 0	current_phase = 0	next_phase = 1	reward = -1.192861	array([[-7.1110845, -7.4954667]], dtype=float32)
time = 3094	action = 0	current_phase = 0	next_phase = 1	reward = -2.283813	array([[ -9.449385, -10.22187 ]], dtype=float32)
time = 3099	action = 0	current_phase = 0	next_phase = 1	reward = -4.136495	array([[-13.207328, -13.580612]], dtype=float32)
time = 3104	action = 0	current_phase = 0	next_phase = 1	reward = -5.997340	array([[-15.369201, -19.041418]], dtype=float32)
time = 3109	action = 0	current_phase = 0	next_phase = 1	reward = -7.961032	array([[-18.591042, -23.6955  ]], dtype=float32)
time = 3114	action = 0	current_phase = 0	next_phase = 1	reward = -9.845548	array([[-21.18103 , -25.617027]], dtype=float32)
time = 3119	action = 0	current_phase = 0	next_phase = 1	reward = -11.269991	array([[-25.193848, -27.17405 ]], dtype=float32)
time = 3124	action = 1	current_phase = 0	next_phase = 1	reward = -18.242542	array([[-30.64552 , -28.846909]], dtype=float32)
time = 3132	action = 0	current_phase = 1	next_phase = 0	reward = -7.168994	array([[-10.995294, -17.031843]], dtype=float32)
time = 3137	action = 0	current_phase = 1	next_phase = 0	reward = -4.385452	array([[ -5.3400383, -18.993683 ]], dtype=float32)
time = 3142	action = 0	current_phase = 1	next_phase = 0	reward = -2.926221	array([[ -5.754043, -15.636315]], dtype=float32)
time = 3147	action = 0	current_phase = 1	next_phase = 0	reward = -2.280104	array([[ -8.288187, -14.090126]], dtype=float32)
time = 3152	action = 0	current_phase = 1	next_phase = 0	reward = -3.153092	array([[ -9.650134, -15.177226]], dtype=float32)
time = 3157	action = 0	current_phase = 1	next_phase = 0	reward = -4.924601	array([[ -8.336282, -15.469337]], dtype=float32)
time = 3162	action = 0	current_phase = 1	next_phase = 0	reward = -6.604448	array([[-14.262362, -18.786018]], dtype=float32)
time = 3167	action = 0	current_phase = 1	next_phase = 0	reward = -7.368058	array([[-16.563444, -18.330807]], dtype=float32)
time = 3172	action = 1	current_phase = 1	next_phase = 0	reward = -11.187258	array([[-16.431202, -15.616866]], dtype=float32)
time = 3180	action = 0	current_phase = 0	next_phase = 1	reward = -3.976091	array([[ -6.849824, -12.173975]], dtype=float32)
time = 3185	action = 0	current_phase = 0	next_phase = 1	reward = -2.610307	array([[ -5.0057745, -12.798388 ]], dtype=float32)
time = 3190	action = 0	current_phase = 0	next_phase = 1	reward = -2.082508	array([[ -5.2011194, -12.277303 ]], dtype=float32)
time = 3195	action = 0	current_phase = 0	next_phase = 1	reward = -1.120069	array([[ -5.7568817, -11.158687 ]], dtype=float32)
time = 3200	action = 0	current_phase = 0	next_phase = 1	reward = -1.973021	array([[-6.965193, -9.692148]], dtype=float32)
time = 3205	action = 0	current_phase = 0	next_phase = 1	reward = -3.073394	array([[ -8.54709 , -11.802634]], dtype=float32)
time = 3210	action = 0	current_phase = 0	next_phase = 1	reward = -4.424369	array([[-11.973186, -16.409843]], dtype=float32)
time = 3215	action = 0	current_phase = 0	next_phase = 1	reward = -6.239973	array([[-14.614361, -19.642233]], dtype=float32)
time = 3220	action = 0	current_phase = 0	next_phase = 1	reward = -7.945347	array([[-15.792809, -22.91787 ]], dtype=float32)
time = 3225	action = 0	current_phase = 0	next_phase = 1	reward = -9.920858	array([[-22.235222, -25.67016 ]], dtype=float32)
time = 3230	action = 0	current_phase = 0	next_phase = 1	reward = -11.130048	array([[-24.127861, -26.603022]], dtype=float32)
time = 3235	action = 1	current_phase = 0	next_phase = 1	reward = -17.267439	array([[-29.426022, -28.435564]], dtype=float32)
time = 3243	action = 0	current_phase = 1	next_phase = 0	reward = -6.254685	array([[-12.549556, -13.061108]], dtype=float32)
time = 3248	action = 0	current_phase = 1	next_phase = 0	reward = -3.498231	array([[ -4.0660214, -16.75257  ]], dtype=float32)
time = 3253	action = 0	current_phase = 1	next_phase = 0	reward = -1.810555	array([[ -5.2383094, -12.692705 ]], dtype=float32)
time = 3258	action = 0	current_phase = 1	next_phase = 0	reward = -1.238064	array([[ -7.5520544, -13.218229 ]], dtype=float32)
time = 3263	action = 0	current_phase = 1	next_phase = 0	reward = -2.241684	array([[ -9.121632 , -13.8360405]], dtype=float32)
time = 3268	action = 0	current_phase = 1	next_phase = 0	reward = -4.053180	array([[-10.142926, -13.873105]], dtype=float32)
time = 3273	action = 0	current_phase = 1	next_phase = 0	reward = -5.524647	array([[-14.053964, -16.908096]], dtype=float32)
time = 3278	action = 0	current_phase = 1	next_phase = 0	reward = -6.776517	array([[-16.104614, -17.359951]], dtype=float32)
time = 3283	action = 1	current_phase = 1	next_phase = 0	reward = -10.270300	array([[-15.921918, -14.937514]], dtype=float32)
time = 3291	action = 0	current_phase = 0	next_phase = 1	reward = -3.627842	array([[ -5.9301767, -12.639002 ]], dtype=float32)
time = 3296	action = 0	current_phase = 0	next_phase = 1	reward = -1.562397	array([[ -5.465704, -12.252836]], dtype=float32)
time = 3301	action = 0	current_phase = 0	next_phase = 1	reward = -0.700683	array([[ -5.9281425, -10.989922 ]], dtype=float32)
time = 3306	action = 0	current_phase = 0	next_phase = 1	reward = -0.253232	array([[-6.3448496, -9.492161 ]], dtype=float32)
time = 3311	action = 0	current_phase = 0	next_phase = 1	reward = -1.450613	array([[-6.640379 , -7.3624144]], dtype=float32)
time = 3316	action = 0	current_phase = 0	next_phase = 1	reward = -2.401062	array([[-7.7003107, -8.340554 ]], dtype=float32)
time = 3321	action = 0	current_phase = 0	next_phase = 1	reward = -3.068720	array([[-12.83838 , -14.989647]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 11.5901 - val_loss: 4.0206
Epoch 2/50
 - 1s - loss: 10.8670 - val_loss: 3.7738
Epoch 3/50
 - 1s - loss: 10.6601 - val_loss: 3.5903
Epoch 4/50
 - 1s - loss: 10.3315 - val_loss: 3.5112
Epoch 5/50
 - 1s - loss: 10.2513 - val_loss: 3.3129
Epoch 6/50
 - 1s - loss: 10.2354 - val_loss: 3.4015
Epoch 7/50
 - 1s - loss: 10.0954 - val_loss: 3.4652
Epoch 8/50
 - 1s - loss: 9.9189 - val_loss: 3.6005
Epoch 9/50
 - 1s - loss: 9.9248 - val_loss: 3.3009
Epoch 10/50
 - 1s - loss: 9.7421 - val_loss: 3.3054
Epoch 11/50
 - 1s - loss: 9.7085 - val_loss: 3.1455
Epoch 12/50
 - 1s - loss: 9.6224 - val_loss: 3.1574
Epoch 13/50
 - 1s - loss: 9.5582 - val_loss: 3.1897
Epoch 14/50
 - 1s - loss: 9.5464 - val_loss: 3.2539
Epoch 15/50
 - 1s - loss: 9.4452 - val_loss: 3.3729
Epoch 16/50
 - 1s - loss: 9.3977 - val_loss: 3.2165
Epoch 17/50
 - 1s - loss: 9.3601 - val_loss: 3.1529
Epoch 18/50
 - 1s - loss: 9.4002 - val_loss: 3.1204
Epoch 19/50
 - 1s - loss: 9.2497 - val_loss: 3.3670
Epoch 20/50
 - 1s - loss: 9.2124 - val_loss: 3.2333
Epoch 21/50
 - 1s - loss: 9.1726 - val_loss: 3.1393
Epoch 22/50
 - 1s - loss: 9.0486 - val_loss: 3.1738
Epoch 23/50
 - 1s - loss: 9.0289 - val_loss: 3.1698
Epoch 24/50
 - 1s - loss: 9.0904 - val_loss: 3.2740
Epoch 25/50
 - 1s - loss: 9.1106 - val_loss: 3.3351
Epoch 26/50
 - 1s - loss: 9.0078 - val_loss: 3.1460
Epoch 27/50
 - 1s - loss: 9.0027 - val_loss: 3.2349
Epoch 28/50
 - 1s - loss: 9.0067 - val_loss: 3.2270
length of memory (state 0, action 0): 813, after forget
length of memory (state 0, action 1): 334, after forget
length of memory (state 1, action 0): 746, after forget
length of memory (state 1, action 1): 322, after forget
time = 3326	action = 1	current_phase = 0	next_phase = 1	reward = -7.169059	array([[-26.540333, -22.317926]], dtype=float32)
time = 3334	action = 1	current_phase = 1	next_phase = 0	reward = -6.445049	array([[-7.272304 , -6.7070174]], dtype=float32)
time = 3342	action = 1	current_phase = 0	next_phase = 1	reward = -5.608446	array([[-12.821971,  -8.398158]], dtype=float32)
time = 3350	action = 0	current_phase = 1	next_phase = 0	reward = -0.933980	array([[ -6.495742, -10.011276]], dtype=float32)
time = 3355	action = 0	current_phase = 1	next_phase = 0	reward = -0.640093	array([[-10.525634, -10.679818]], dtype=float32)
time = 3360	action = 0	current_phase = 1	next_phase = 0	reward = -2.376610	array([[-7.2426853, -9.373581 ]], dtype=float32)
time = 3365	action = 1	current_phase = 1	next_phase = 0	reward = -6.738584	array([[-15.72385, -14.37251]], dtype=float32)
time = 3373	action = 1	current_phase = 0	next_phase = 1	reward = -5.675788	array([[-8.149195, -7.455162]], dtype=float32)
time = 3381	action = 0	current_phase = 1	next_phase = 0	reward = -3.458568	array([[ -9.316188, -10.049338]], dtype=float32)
time = 3386	action = 1	current_phase = 1	next_phase = 0	reward = -7.938778	array([[-17.928795, -12.855852]], dtype=float32)
time = 3394	action = 0	current_phase = 0	next_phase = 1	reward = -3.137443	array([[-7.519511 , -8.3205805]], dtype=float32)
time = 3399	action = 0	current_phase = 0	next_phase = 1	reward = -3.303312	array([[ -5.295637, -10.667014]], dtype=float32)
time = 3404	action = 0	current_phase = 0	next_phase = 1	reward = -3.716937	array([[ -7.044818 , -14.4235325]], dtype=float32)
time = 3409	action = 0	current_phase = 0	next_phase = 1	reward = -4.530678	array([[-13.032811, -17.723938]], dtype=float32)
time = 3414	action = 0	current_phase = 0	next_phase = 1	reward = -4.763744	array([[-16.051102, -19.668875]], dtype=float32)
time = 3419	action = 0	current_phase = 0	next_phase = 1	reward = -6.354566	array([[-19.218058, -22.874939]], dtype=float32)
time = 3424	action = 0	current_phase = 0	next_phase = 1	reward = -7.173902	array([[-24.145775, -25.22454 ]], dtype=float32)
time = 3429	action = 1	current_phase = 0	next_phase = 1	reward = -14.330595	array([[-28.45092, -26.05988]], dtype=float32)
time = 3437	action = 1	current_phase = 1	next_phase = 0	reward = -10.987256	array([[-13.657966, -10.015734]], dtype=float32)
time = 3445	action = 1	current_phase = 0	next_phase = 1	reward = -6.711712	array([[-12.14375 , -11.963337]], dtype=float32)
time = 3453	action = 0	current_phase = 1	next_phase = 0	reward = -2.425861	array([[ -6.1544113, -10.287193 ]], dtype=float32)
time = 3458	action = 0	current_phase = 1	next_phase = 0	reward = -2.162478	array([[ -7.931291, -11.234476]], dtype=float32)
time = 3463	action = 0	current_phase = 1	next_phase = 0	reward = -3.380585	array([[-12.468511, -16.991558]], dtype=float32)
time = 3468	action = 0	current_phase = 1	next_phase = 0	reward = -5.143062	array([[-14.6163  , -17.326075]], dtype=float32)
time = 3473	action = 0	current_phase = 1	next_phase = 0	reward = -6.051464	array([[-15.310742, -18.095764]], dtype=float32)
time = 3478	action = 0	current_phase = 1	next_phase = 0	reward = -7.556406	array([[-18.669415, -19.51993 ]], dtype=float32)
time = 3483	action = 1	current_phase = 1	next_phase = 0	reward = -16.112870	array([[-28.789547, -25.894272]], dtype=float32)
time = 3491	action = 0	current_phase = 0	next_phase = 1	reward = -6.924430	array([[-10.163274, -13.316775]], dtype=float32)
time = 3496	action = 0	current_phase = 0	next_phase = 1	reward = -4.622047	array([[ -4.1137  , -14.653928]], dtype=float32)
time = 3501	action = 0	current_phase = 0	next_phase = 1	reward = -2.866157	array([[ -5.320819, -14.357443]], dtype=float32)
time = 3506	action = 0	current_phase = 0	next_phase = 1	reward = -0.422167	array([[ -7.4165926, -10.536672 ]], dtype=float32)
time = 3511	action = 0	current_phase = 0	next_phase = 1	reward = -0.567880	array([[-8.102784, -8.188875]], dtype=float32)
time = 3516	action = 1	current_phase = 0	next_phase = 1	reward = -4.342812	array([[-9.726269, -8.814488]], dtype=float32)
time = 3524	action = 0	current_phase = 1	next_phase = 0	reward = -2.523115	array([[-8.085281, -8.942954]], dtype=float32)
time = 3529	action = 0	current_phase = 1	next_phase = 0	reward = -3.564957	array([[-10.642192, -11.537002]], dtype=float32)
time = 3534	action = 0	current_phase = 1	next_phase = 0	reward = -4.647866	array([[-14.911897, -17.088808]], dtype=float32)
time = 3539	action = 1	current_phase = 1	next_phase = 0	reward = -9.079426	array([[-17.530792, -16.540619]], dtype=float32)
time = 3547	action = 0	current_phase = 0	next_phase = 1	reward = -3.598138	array([[-7.1150093, -8.683906 ]], dtype=float32)
time = 3552	action = 0	current_phase = 0	next_phase = 1	reward = -2.955024	array([[ -5.2945824, -12.4967375]], dtype=float32)
time = 3557	action = 0	current_phase = 0	next_phase = 1	reward = -2.632240	array([[ -7.496564, -12.699557]], dtype=float32)
time = 3562	action = 0	current_phase = 0	next_phase = 1	reward = -3.351558	array([[ -9.937544, -12.222991]], dtype=float32)
time = 3567	action = 0	current_phase = 0	next_phase = 1	reward = -3.668568	array([[-14.041682, -15.282025]], dtype=float32)
time = 3572	action = 0	current_phase = 0	next_phase = 1	reward = -4.719483	array([[-15.0187025, -17.491219 ]], dtype=float32)
time = 3577	action = 0	current_phase = 0	next_phase = 1	reward = -6.329878	array([[-19.263317, -21.379097]], dtype=float32)
time = 3582	action = 1	current_phase = 0	next_phase = 1	reward = -12.194652	array([[-26.181606, -24.662527]], dtype=float32)
time = 3590	action = 1	current_phase = 1	next_phase = 0	reward = -10.633843	array([[-10.050052,  -8.537418]], dtype=float32)
time = 3598	action = 1	current_phase = 0	next_phase = 1	reward = -7.069706	array([[-17.06192 , -12.074439]], dtype=float32)
time = 3606	action = 0	current_phase = 1	next_phase = 0	reward = -1.826512	array([[ -5.4723673, -10.3342285]], dtype=float32)
time = 3611	action = 0	current_phase = 1	next_phase = 0	reward = -1.546486	array([[ -7.3316097, -13.544884 ]], dtype=float32)
time = 3616	action = 0	current_phase = 1	next_phase = 0	reward = -2.361219	array([[ -6.7908945, -15.228794 ]], dtype=float32)
time = 3621	action = 0	current_phase = 1	next_phase = 0	reward = -3.708476	array([[-12.875241, -16.294464]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 3.9511 - val_loss: 16.2438
Epoch 2/50
 - 1s - loss: 3.8308 - val_loss: 16.5171
Epoch 3/50
 - 1s - loss: 3.5637 - val_loss: 16.5161
Epoch 4/50
 - 1s - loss: 3.6392 - val_loss: 16.2473
Epoch 5/50
 - 1s - loss: 3.4914 - val_loss: 16.3453
Epoch 6/50
 - 1s - loss: 3.2854 - val_loss: 16.1812
Epoch 7/50
 - 1s - loss: 3.2948 - val_loss: 16.1663
Epoch 8/50
 - 1s - loss: 3.1643 - val_loss: 16.2795
Epoch 9/50
 - 1s - loss: 3.3077 - val_loss: 16.0704
Epoch 10/50
 - 1s - loss: 3.2248 - val_loss: 16.0445
Epoch 11/50
 - 1s - loss: 3.1265 - val_loss: 16.2322
Epoch 12/50
 - 1s - loss: 3.0157 - val_loss: 16.2422
Epoch 13/50
 - 1s - loss: 3.0657 - val_loss: 16.1060
Epoch 14/50
 - 1s - loss: 3.0145 - val_loss: 16.1465
Epoch 15/50
 - 1s - loss: 2.9362 - val_loss: 16.1479
Epoch 16/50
 - 1s - loss: 2.9160 - val_loss: 16.2054
Epoch 17/50
 - 1s - loss: 2.9959 - val_loss: 16.1100
Epoch 18/50
 - 1s - loss: 2.8286 - val_loss: 16.0823
Epoch 19/50
 - 1s - loss: 2.8715 - val_loss: 15.9954
Epoch 20/50
 - 1s - loss: 2.7544 - val_loss: 16.0326
Epoch 21/50
 - 1s - loss: 2.9104 - val_loss: 16.1642
Epoch 22/50
 - 1s - loss: 2.7433 - val_loss: 16.2614
Epoch 23/50
 - 1s - loss: 2.7757 - val_loss: 16.0201
Epoch 24/50
 - 1s - loss: 2.7498 - val_loss: 16.5311
Epoch 25/50
 - 1s - loss: 2.8335 - val_loss: 16.0600
Epoch 26/50
 - 1s - loss: 2.7904 - val_loss: 16.3489
Epoch 27/50
 - 1s - loss: 2.7379 - val_loss: 16.1081
Epoch 28/50
 - 1s - loss: 2.6571 - val_loss: 16.2355
Epoch 29/50
 - 1s - loss: 2.6994 - val_loss: 15.9486
Epoch 30/50
 - 1s - loss: 2.7009 - val_loss: 16.2493
Epoch 31/50
 - 1s - loss: 2.6648 - val_loss: 16.2788
Epoch 32/50
 - 1s - loss: 2.5680 - val_loss: 16.2891
Epoch 33/50
 - 1s - loss: 2.6585 - val_loss: 16.0994
Epoch 34/50
 - 1s - loss: 2.5341 - val_loss: 16.2159
Epoch 35/50
 - 1s - loss: 2.6366 - val_loss: 16.2028
Epoch 36/50
 - 1s - loss: 2.5328 - val_loss: 16.1982
Epoch 37/50
 - 1s - loss: 2.5591 - val_loss: 16.0072
Epoch 38/50
 - 1s - loss: 2.4951 - val_loss: 16.0111
Epoch 39/50
 - 1s - loss: 2.5089 - val_loss: 16.0239
length of memory (state 0, action 0): 832, after forget
length of memory (state 0, action 1): 342, after forget
length of memory (state 1, action 0): 763, after forget
length of memory (state 1, action 1): 329, after forget
time = 3626	action = 0	current_phase = 1	next_phase = 0	reward = -4.986791	array([[-16.52721 , -16.911081]], dtype=float32)
time = 3631	action = 1	current_phase = 1	next_phase = 0	reward = -10.812587	array([[-20.982538, -18.629755]], dtype=float32)
time = 3639	action = 1	current_phase = 0	next_phase = 1	reward = -9.549820	array([[-11.003574,  -8.685904]], dtype=float32)
time = 3647	action = 1	current_phase = 1	next_phase = 0	reward = -7.418343	array([[-11.397976,  -8.734779]], dtype=float32)
time = 3655	action = 0	current_phase = 0	next_phase = 1	reward = -2.382273	array([[-6.2053967, -9.976751 ]], dtype=float32)
time = 3660	action = 0	current_phase = 0	next_phase = 1	reward = -2.129483	array([[ -5.0902076, -11.358997 ]], dtype=float32)
time = 3665	action = 0	current_phase = 0	next_phase = 1	reward = -2.685626	array([[ -5.196537, -13.524689]], dtype=float32)
time = 3670	action = 0	current_phase = 0	next_phase = 1	reward = -3.327178	array([[ -9.483606, -11.667267]], dtype=float32)
time = 3675	action = 0	current_phase = 0	next_phase = 1	reward = -3.768710	array([[-11.712882, -16.272955]], dtype=float32)
time = 3680	action = 0	current_phase = 0	next_phase = 1	reward = -4.479550	array([[-17.249685, -18.652536]], dtype=float32)
time = 3685	action = 1	current_phase = 0	next_phase = 1	reward = -9.266284	array([[-23.491558, -23.387064]], dtype=float32)
time = 3693	action = 0	current_phase = 1	next_phase = 0	reward = -3.915556	array([[-10.753284, -11.709433]], dtype=float32)
time = 3698	action = 0	current_phase = 1	next_phase = 0	reward = -4.231703	array([[-13.062639, -15.612883]], dtype=float32)
time = 3703	action = 1	current_phase = 1	next_phase = 0	reward = -6.803060	array([[-17.464912, -16.552643]], dtype=float32)
time = 3711	action = 1	current_phase = 0	next_phase = 1	reward = -4.896143	array([[-7.3280597, -6.9312887]], dtype=float32)
time = 3719	action = 1	current_phase = 1	next_phase = 0	reward = -4.678990	array([[-10.863453, -10.464356]], dtype=float32)
time = 3727	action = 0	current_phase = 0	next_phase = 1	reward = -1.875035	array([[-7.39803 , -8.347873]], dtype=float32)
time = 3732	action = 0	current_phase = 0	next_phase = 1	reward = -1.963181	array([[-7.629016, -9.25404 ]], dtype=float32)
time = 3737	action = 0	current_phase = 0	next_phase = 1	reward = -2.938900	array([[-12.066787, -13.276629]], dtype=float32)
time = 3742	action = 1	current_phase = 0	next_phase = 1	reward = -8.168329	array([[-17.897299, -17.611279]], dtype=float32)
time = 3750	action = 0	current_phase = 1	next_phase = 0	reward = -5.159310	array([[-11.200399, -13.411372]], dtype=float32)
time = 3755	action = 0	current_phase = 1	next_phase = 0	reward = -5.512100	array([[-10.050055, -17.609211]], dtype=float32)
time = 3760	action = 0	current_phase = 1	next_phase = 0	reward = -6.291605	array([[-14.986628, -19.29677 ]], dtype=float32)
time = 3765	action = 0	current_phase = 1	next_phase = 0	reward = -7.405989	array([[-17.55202 , -19.810658]], dtype=float32)
time = 3770	action = 0	current_phase = 1	next_phase = 0	reward = -8.572493	array([[-14.479721, -23.287748]], dtype=float32)
time = 3775	action = 0	current_phase = 1	next_phase = 0	reward = -10.493314	array([[-15.1802845, -26.436607 ]], dtype=float32)
time = 3780	action = 0	current_phase = 1	next_phase = 0	reward = -12.733065	array([[-27.832306, -29.538277]], dtype=float32)
time = 3785	action = 1	current_phase = 1	next_phase = 0	reward = -21.365615	array([[-32.01029 , -31.772406]], dtype=float32)
time = 3793	action = 1	current_phase = 0	next_phase = 1	reward = -16.275942	array([[-32.0462  , -26.174871]], dtype=float32)
time = 3801	action = 1	current_phase = 1	next_phase = 0	reward = -9.041077	array([[-18.6225  , -15.170601]], dtype=float32)
time = 3809	action = 0	current_phase = 0	next_phase = 1	reward = -1.450714	array([[-6.823083, -9.636732]], dtype=float32)
time = 3814	action = 0	current_phase = 0	next_phase = 1	reward = -0.765198	array([[ -5.928424, -10.246154]], dtype=float32)
time = 3819	action = 0	current_phase = 0	next_phase = 1	reward = -1.528210	array([[-10.280334, -13.562459]], dtype=float32)
time = 3824	action = 0	current_phase = 0	next_phase = 1	reward = -2.894006	array([[-16.339249, -17.514269]], dtype=float32)
time = 3829	action = 0	current_phase = 0	next_phase = 1	reward = -3.344374	array([[-20.589106, -21.248474]], dtype=float32)
time = 3834	action = 1	current_phase = 0	next_phase = 1	reward = -10.824255	array([[-28.258646, -23.9063  ]], dtype=float32)
time = 3842	action = 0	current_phase = 1	next_phase = 0	reward = -6.085203	array([[-13.250799, -20.27047 ]], dtype=float32)
time = 3847	action = 0	current_phase = 1	next_phase = 0	reward = -5.766201	array([[-13.17366 , -20.677372]], dtype=float32)
time = 3852	action = 0	current_phase = 1	next_phase = 0	reward = -5.437100	array([[-14.460386, -21.143223]], dtype=float32)
time = 3857	action = 0	current_phase = 1	next_phase = 0	reward = -5.935357	array([[-20.036528, -20.159357]], dtype=float32)
time = 3862	action = 0	current_phase = 1	next_phase = 0	reward = -6.978451	array([[-17.873253, -20.601889]], dtype=float32)
time = 3867	action = 0	current_phase = 1	next_phase = 0	reward = -8.620782	array([[-22.336529, -24.891727]], dtype=float32)
time = 3872	action = 0	current_phase = 1	next_phase = 0	reward = -10.643444	array([[-23.633696, -27.97025 ]], dtype=float32)
time = 3877	action = 1	current_phase = 1	next_phase = 0	reward = -17.284433	array([[-31.54933, -30.41474]], dtype=float32)
time = 3885	action = 1	current_phase = 0	next_phase = 1	reward = -13.013607	array([[-15.463377, -14.376509]], dtype=float32)
time = 3893	action = 1	current_phase = 1	next_phase = 0	reward = -6.909591	array([[-14.589764, -12.844395]], dtype=float32)
time = 3901	action = 0	current_phase = 0	next_phase = 1	reward = -0.601020	array([[ -4.4076743, -11.227684 ]], dtype=float32)
time = 3906	action = 0	current_phase = 0	next_phase = 1	reward = -1.027096	array([[ -5.5105653, -10.350518 ]], dtype=float32)
time = 3911	action = 0	current_phase = 0	next_phase = 1	reward = -1.947848	array([[ -8.566329 , -13.1354885]], dtype=float32)
time = 3916	action = 0	current_phase = 0	next_phase = 1	reward = -1.548077	array([[ -8.956875, -17.186054]], dtype=float32)
time = 3921	action = 0	current_phase = 0	next_phase = 1	reward = -1.777502	array([[-12.809872, -18.39183 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 8.9809 - val_loss: 1.7673
Epoch 2/50
 - 1s - loss: 8.8950 - val_loss: 1.9797
Epoch 3/50
 - 1s - loss: 8.6609 - val_loss: 1.8147
Epoch 4/50
 - 1s - loss: 8.4947 - val_loss: 1.8906
Epoch 5/50
 - 1s - loss: 8.5051 - val_loss: 1.8309
Epoch 6/50
 - 1s - loss: 8.4145 - val_loss: 1.8732
Epoch 7/50
 - 1s - loss: 8.4484 - val_loss: 1.7625
Epoch 8/50
 - 1s - loss: 8.4054 - val_loss: 1.8121
Epoch 9/50
 - 1s - loss: 8.3199 - val_loss: 1.8374
Epoch 10/50
 - 1s - loss: 8.2908 - val_loss: 1.8188
Epoch 11/50
 - 1s - loss: 8.3311 - val_loss: 1.8962
Epoch 12/50
 - 1s - loss: 8.1969 - val_loss: 1.8636
Epoch 13/50
 - 1s - loss: 8.1200 - val_loss: 1.8309
Epoch 14/50
 - 1s - loss: 8.1939 - val_loss: 1.8929
Epoch 15/50
 - 1s - loss: 8.1455 - val_loss: 1.9043
Epoch 16/50
 - 1s - loss: 8.1618 - val_loss: 1.8605
Epoch 17/50
 - 1s - loss: 8.1061 - val_loss: 1.9284
length of memory (state 0, action 0): 851, after forget
length of memory (state 0, action 1): 349, after forget
length of memory (state 1, action 0): 780, after forget
length of memory (state 1, action 1): 337, after forget
time = 3926	action = 0	current_phase = 0	next_phase = 1	reward = -2.401532	array([[-15.724255, -19.307705]], dtype=float32)
time = 3931	action = 0	current_phase = 0	next_phase = 1	reward = -3.377453	array([[-19.10463, -19.73449]], dtype=float32)
time = 3936	action = 0	current_phase = 0	next_phase = 1	reward = -3.639327	array([[-22.04684 , -23.662178]], dtype=float32)
time = 3941	action = 0	current_phase = 0	next_phase = 1	reward = -4.185847	array([[-24.503736, -24.890581]], dtype=float32)
time = 3946	action = 0	current_phase = 0	next_phase = 1	reward = -4.862429	array([[-25.174366, -25.73815 ]], dtype=float32)
time = 3951	action = 1	current_phase = 0	next_phase = 1	reward = -6.752031	array([[-26.65457 , -25.970142]], dtype=float32)
time = 3959	action = 1	current_phase = 1	next_phase = 0	reward = -3.075151	array([[-13.492277, -13.392972]], dtype=float32)
time = 3967	action = 0	current_phase = 0	next_phase = 1	reward = -1.114427	array([[-2.999049, -7.855706]], dtype=float32)
time = 3972	action = 0	current_phase = 0	next_phase = 1	reward = -1.870724	array([[-6.0508323, -6.694344 ]], dtype=float32)
time = 3977	action = 0	current_phase = 0	next_phase = 1	reward = -2.328408	array([[ -7.7221346, -12.357065 ]], dtype=float32)
time = 3982	action = 0	current_phase = 0	next_phase = 1	reward = -2.508414	array([[ -8.448799, -13.972751]], dtype=float32)
time = 3987	action = 0	current_phase = 0	next_phase = 1	reward = -2.608519	array([[-10.822466, -15.757003]], dtype=float32)
time = 3992	action = 0	current_phase = 0	next_phase = 1	reward = -2.829650	array([[-15.900839, -19.3452  ]], dtype=float32)
time = 3997	action = 0	current_phase = 0	next_phase = 1	reward = -3.252970	array([[-18.144964, -21.150108]], dtype=float32)
time = 4002	action = 0	current_phase = 0	next_phase = 1	reward = -3.118276	array([[-16.705296, -21.28884 ]], dtype=float32)
time = 4007	action = 0	current_phase = 0	next_phase = 1	reward = -3.332437	array([[-20.779072, -24.32024 ]], dtype=float32)
time = 4012	action = 0	current_phase = 0	next_phase = 1	reward = -3.497674	array([[-20.270836, -22.654543]], dtype=float32)
time = 4017	action = 0	current_phase = 0	next_phase = 1	reward = -3.868691	array([[-22.334055, -24.566793]], dtype=float32)
time = 4022	action = 0	current_phase = 0	next_phase = 1	reward = -3.845694	array([[-24.01032, -25.69254]], dtype=float32)
time = 4027	action = 0	current_phase = 0	next_phase = 1	reward = -3.941375	array([[-26.13454 , -26.149925]], dtype=float32)
time = 4032	action = 0	current_phase = 0	next_phase = 1	reward = -4.414370	array([[-26.289831, -26.383482]], dtype=float32)
time = 4037	action = 1	current_phase = 0	next_phase = 1	reward = -5.865614	array([[-26.36301 , -26.336456]], dtype=float32)
time = 4045	action = 0	current_phase = 1	next_phase = 0	reward = -0.053361	array([[ -9.986725, -10.320284]], dtype=float32)
time = 4050	action = 0	current_phase = 1	next_phase = 0	reward = 0.410813	array([[-4.801336, -8.494065]], dtype=float32)
time = 4055	action = 0	current_phase = 1	next_phase = 0	reward = -1.072406	array([[ -6.9538345, -10.548712 ]], dtype=float32)
time = 4060	action = 0	current_phase = 1	next_phase = 0	reward = -0.678523	array([[ -8.535969, -12.242444]], dtype=float32)
time = 4065	action = 0	current_phase = 1	next_phase = 0	reward = -0.114538	array([[-5.20875, -8.75103]], dtype=float32)
time = 4070	action = 0	current_phase = 1	next_phase = 0	reward = 0.319418	array([[-5.3854356, -6.946885 ]], dtype=float32)
time = 4075	action = 1	current_phase = 1	next_phase = 0	reward = -0.991324	array([[-7.674811 , -4.9196835]], dtype=float32)
time = 4083	action = 0	current_phase = 0	next_phase = 1	reward = 0.319157	array([[-1.2929218, -8.888477 ]], dtype=float32)
time = 4088	action = 0	current_phase = 0	next_phase = 1	reward = 0.062861	array([[-1.4874911, -8.76125  ]], dtype=float32)
time = 4093	action = 0	current_phase = 0	next_phase = 1	reward = 0.326692	array([[-1.4425848, -8.36999  ]], dtype=float32)
time = 4098	action = 0	current_phase = 0	next_phase = 1	reward = 0.335324	array([[-1.5467377, -8.910168 ]], dtype=float32)
time = 4103	action = 0	current_phase = 0	next_phase = 1	reward = 0.385827	array([[-1.7498124, -8.750049 ]], dtype=float32)
time = 4108	action = 0	current_phase = 0	next_phase = 1	reward = 0.339141	array([[-1.7057347, -8.698783 ]], dtype=float32)
time = 4113	action = 0	current_phase = 0	next_phase = 1	reward = 0.325388	array([[-1.819597, -8.555698]], dtype=float32)
time = 4118	action = 0	current_phase = 0	next_phase = 1	reward = 0.372891	array([[-1.5751042, -8.741018 ]], dtype=float32)
time = 4123	action = 0	current_phase = 0	next_phase = 1	reward = 0.312258	array([[-2.6178365, -7.4844894]], dtype=float32)
time = 4128	action = 0	current_phase = 0	next_phase = 1	reward = 0.308683	array([[-2.4575293, -7.846325 ]], dtype=float32)
time = 4133	action = 0	current_phase = 0	next_phase = 1	reward = 0.349866	array([[-1.7720017, -8.458589 ]], dtype=float32)
time = 4138	action = 0	current_phase = 0	next_phase = 1	reward = 0.301094	array([[-2.0815034, -8.23278  ]], dtype=float32)
time = 4143	action = 0	current_phase = 0	next_phase = 1	reward = 0.308362	array([[-2.4272327, -8.056613 ]], dtype=float32)
time = 4148	action = 0	current_phase = 0	next_phase = 1	reward = 0.349655	array([[-2.1553037, -8.25983  ]], dtype=float32)
time = 4153	action = 0	current_phase = 0	next_phase = 1	reward = 0.309116	array([[-2.6760166, -7.695193 ]], dtype=float32)
time = 4158	action = 0	current_phase = 0	next_phase = 1	reward = 0.296603	array([[-2.7061276, -7.5944586]], dtype=float32)
time = 4163	action = 0	current_phase = 0	next_phase = 1	reward = 0.342432	array([[-3.0738244, -7.4155498]], dtype=float32)
time = 4168	action = 0	current_phase = 0	next_phase = 1	reward = 0.361882	array([[-2.8010585, -7.672139 ]], dtype=float32)
time = 4173	action = 0	current_phase = 0	next_phase = 1	reward = 0.440251	array([[-3.3671584, -7.213742 ]], dtype=float32)
time = 4178	action = 0	current_phase = 0	next_phase = 1	reward = 0.369201	array([[-3.506878 , -7.3507886]], dtype=float32)
time = 4183	action = 0	current_phase = 0	next_phase = 1	reward = 0.210496	array([[-5.304796, -7.879224]], dtype=float32)
time = 4188	action = 0	current_phase = 0	next_phase = 1	reward = -0.013283	array([[-4.911924, -7.938416]], dtype=float32)
time = 4193	action = 0	current_phase = 0	next_phase = 1	reward = -0.013603	array([[-4.5903563, -8.1571245]], dtype=float32)
time = 4198	action = 0	current_phase = 0	next_phase = 1	reward = -0.004787	array([[-5.2877913, -8.378993 ]], dtype=float32)
time = 4203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-5.920459, -9.881024]], dtype=float32)
time = 4208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-5.920459, -9.881024]], dtype=float32)
time = 4213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-5.920459, -9.881024]], dtype=float32)
time = 4218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-5.920459, -9.881024]], dtype=float32)
time = 4223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-5.920459, -9.881024]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 9.1238 - val_loss: 1.0958
Epoch 2/50
 - 1s - loss: 8.7468 - val_loss: 1.1269
Epoch 3/50
 - 1s - loss: 8.8127 - val_loss: 1.0974
Epoch 4/50
 - 1s - loss: 8.4707 - val_loss: 1.0893
Epoch 5/50
 - 1s - loss: 8.5144 - val_loss: 1.0627
Epoch 6/50
 - 1s - loss: 8.5091 - val_loss: 1.0694
Epoch 7/50
 - 1s - loss: 8.4082 - val_loss: 1.0471
Epoch 8/50
 - 1s - loss: 8.4133 - val_loss: 1.0925
Epoch 9/50
 - 1s - loss: 8.3565 - val_loss: 1.1245
Epoch 10/50
 - 1s - loss: 8.3127 - val_loss: 1.0539
Epoch 11/50
 - 1s - loss: 8.4285 - val_loss: 1.0976
Epoch 12/50
 - 1s - loss: 8.2891 - val_loss: 1.1933
Epoch 13/50
 - 1s - loss: 8.2177 - val_loss: 1.2255
Epoch 14/50
 - 1s - loss: 8.1789 - val_loss: 1.1278
Epoch 15/50
 - 1s - loss: 8.1324 - val_loss: 1.1740
Epoch 16/50
 - 1s - loss: 8.0422 - val_loss: 1.3251
Epoch 17/50
 - 1s - loss: 8.0562 - val_loss: 1.1968
length of memory (state 0, action 0): 899, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 4228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
time = 4523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-4.4907312, -9.8009205]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 2.7454 - val_loss: 14.3128
Epoch 2/50
 - 1s - loss: 2.7077 - val_loss: 14.4898
Epoch 3/50
 - 1s - loss: 2.6340 - val_loss: 14.4816
Epoch 4/50
 - 1s - loss: 2.5159 - val_loss: 14.3091
Epoch 5/50
 - 1s - loss: 2.4683 - val_loss: 14.2937
Epoch 6/50
 - 1s - loss: 2.5658 - val_loss: 14.5128
Epoch 7/50
 - 1s - loss: 2.5079 - val_loss: 14.5450
Epoch 8/50
 - 1s - loss: 2.4599 - val_loss: 14.5113
Epoch 9/50
 - 1s - loss: 2.2649 - val_loss: 14.4631
Epoch 10/50
 - 1s - loss: 2.3423 - val_loss: 14.5126
Epoch 11/50
 - 1s - loss: 2.3236 - val_loss: 14.4216
Epoch 12/50
 - 1s - loss: 2.3430 - val_loss: 14.5434
Epoch 13/50
 - 1s - loss: 2.1488 - val_loss: 14.4096
Epoch 14/50
 - 1s - loss: 2.3819 - val_loss: 14.4220
Epoch 15/50
 - 1s - loss: 2.1515 - val_loss: 14.4424
length of memory (state 0, action 0): 959, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 4528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
time = 4823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-3.3215513, -9.474404 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 9.8395 - val_loss: 1.5680
Epoch 2/50
 - 1s - loss: 9.6256 - val_loss: 1.5988
Epoch 3/50
 - 1s - loss: 9.5902 - val_loss: 1.5740
Epoch 4/50
 - 1s - loss: 9.5312 - val_loss: 1.6118
Epoch 5/50
 - 1s - loss: 9.4239 - val_loss: 1.5426
Epoch 6/50
 - 1s - loss: 9.3305 - val_loss: 1.7206
Epoch 7/50
 - 1s - loss: 9.2202 - val_loss: 1.4344
Epoch 8/50
 - 1s - loss: 9.1594 - val_loss: 1.6108
Epoch 9/50
 - 1s - loss: 9.0543 - val_loss: 1.5258
Epoch 10/50
 - 1s - loss: 8.9201 - val_loss: 1.4291
Epoch 11/50
 - 1s - loss: 9.1343 - val_loss: 1.5780
Epoch 12/50
 - 1s - loss: 8.9589 - val_loss: 1.6734
Epoch 13/50
 - 1s - loss: 8.8881 - val_loss: 1.7536
Epoch 14/50
 - 1s - loss: 8.7795 - val_loss: 1.5160
Epoch 15/50
 - 1s - loss: 8.7638 - val_loss: 1.5829
Epoch 16/50
 - 1s - loss: 8.7936 - val_loss: 1.5356
Epoch 17/50
 - 1s - loss: 8.6453 - val_loss: 1.6509
Epoch 18/50
 - 1s - loss: 8.7625 - val_loss: 1.5610
Epoch 19/50
 - 1s - loss: 8.6252 - val_loss: 1.4882
Epoch 20/50
 - 1s - loss: 8.6321 - val_loss: 1.5888
length of memory (state 0, action 0): 1019, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 4828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 4998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5003	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5008	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5013	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5018	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5023	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5028	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5033	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5038	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5043	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5048	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5053	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5058	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5063	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5068	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5073	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5078	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5083	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5088	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5093	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5098	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5103	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5108	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5113	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5118	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
time = 5123	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.4286897, -9.283428 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 8.1025 - val_loss: 3.7897
Epoch 2/50
 - 1s - loss: 7.9931 - val_loss: 3.9538
Epoch 3/50
 - 1s - loss: 7.7591 - val_loss: 3.9682
Epoch 4/50
 - 1s - loss: 7.6327 - val_loss: 4.0243
Epoch 5/50
 - 1s - loss: 7.6611 - val_loss: 4.0209
Epoch 6/50
 - 1s - loss: 7.5696 - val_loss: 3.9959
Epoch 7/50
 - 1s - loss: 7.5691 - val_loss: 4.0700
Epoch 8/50
 - 1s - loss: 7.4288 - val_loss: 4.0880
Epoch 9/50
 - 1s - loss: 7.4636 - val_loss: 4.0001
Epoch 10/50
 - 1s - loss: 7.3562 - val_loss: 4.1303
Epoch 11/50
 - 1s - loss: 7.4056 - val_loss: 4.0799
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 5128	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5133	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5138	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5143	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5148	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5153	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5158	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5163	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5168	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5173	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5178	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5188	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5193	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5198	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
time = 5423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5542183, -9.080593 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 9.0612 - val_loss: 1.0517
Epoch 2/50
 - 1s - loss: 8.9399 - val_loss: 1.0579
Epoch 3/50
 - 1s - loss: 8.7708 - val_loss: 1.2564
Epoch 4/50
 - 1s - loss: 8.6239 - val_loss: 1.1947
Epoch 5/50
 - 1s - loss: 8.7032 - val_loss: 1.1239
Epoch 6/50
 - 1s - loss: 8.6104 - val_loss: 1.2288
Epoch 7/50
 - 1s - loss: 8.4834 - val_loss: 1.1995
Epoch 8/50
 - 1s - loss: 8.5230 - val_loss: 1.1497
Epoch 9/50
 - 1s - loss: 8.6112 - val_loss: 1.2953
Epoch 10/50
 - 1s - loss: 8.4774 - val_loss: 1.3009
Epoch 11/50
 - 1s - loss: 8.4408 - val_loss: 1.2250
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 5428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
time = 5723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.603667, -9.014513]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 7.7845 - val_loss: 3.8225
Epoch 2/50
 - 1s - loss: 7.5863 - val_loss: 4.0623
Epoch 3/50
 - 1s - loss: 7.3754 - val_loss: 4.2485
Epoch 4/50
 - 1s - loss: 7.3035 - val_loss: 4.0744
Epoch 5/50
 - 1s - loss: 7.3054 - val_loss: 4.0196
Epoch 6/50
 - 1s - loss: 7.2190 - val_loss: 3.9874
Epoch 7/50
 - 1s - loss: 7.1794 - val_loss: 4.1018
Epoch 8/50
 - 1s - loss: 7.1609 - val_loss: 3.9179
Epoch 9/50
 - 1s - loss: 7.2169 - val_loss: 4.1371
Epoch 10/50
 - 1s - loss: 7.0058 - val_loss: 4.2434
Epoch 11/50
 - 1s - loss: 7.0370 - val_loss: 4.2504
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 5728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 5998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 6003	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 6008	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 6013	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 6018	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
time = 6023	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.7664638, -9.094627 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 2.8501 - val_loss: 1.2197
Epoch 2/50
 - 1s - loss: 2.4673 - val_loss: 1.2180
Epoch 3/50
 - 1s - loss: 2.6093 - val_loss: 1.4301
Epoch 4/50
 - 1s - loss: 2.5140 - val_loss: 1.4408
Epoch 5/50
 - 1s - loss: 2.4983 - val_loss: 1.4216
Epoch 6/50
 - 1s - loss: 2.4092 - val_loss: 1.3822
Epoch 7/50
 - 1s - loss: 2.3937 - val_loss: 1.4512
Epoch 8/50
 - 1s - loss: 2.3757 - val_loss: 1.2867
Epoch 9/50
 - 1s - loss: 2.2881 - val_loss: 1.3296
Epoch 10/50
 - 1s - loss: 2.3070 - val_loss: 1.4762
Epoch 11/50
 - 1s - loss: 2.2325 - val_loss: 1.3379
Epoch 12/50
 - 1s - loss: 2.3998 - val_loss: 1.4918
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 6028	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6033	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6038	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6043	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6048	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6053	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6058	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6063	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6068	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6073	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6078	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6083	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6088	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6093	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6098	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6103	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6108	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6113	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6118	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6123	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6128	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6133	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6138	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6143	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6148	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6153	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6158	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6163	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6168	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6173	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6178	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6188	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6193	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6198	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
time = 6323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.5500503, -8.958315 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 8.2739 - val_loss: 4.3582
Epoch 2/50
 - 1s - loss: 8.2282 - val_loss: 4.2123
Epoch 3/50
 - 1s - loss: 8.0388 - val_loss: 4.2492
Epoch 4/50
 - 1s - loss: 7.8494 - val_loss: 4.1654
Epoch 5/50
 - 1s - loss: 7.9430 - val_loss: 4.1605
Epoch 6/50
 - 1s - loss: 7.8144 - val_loss: 4.1751
Epoch 7/50
 - 1s - loss: 7.7344 - val_loss: 4.1456
Epoch 8/50
 - 1s - loss: 7.7623 - val_loss: 4.1470
Epoch 9/50
 - 1s - loss: 7.7318 - val_loss: 4.2071
Epoch 10/50
 - 1s - loss: 7.8558 - val_loss: 4.1549
Epoch 11/50
 - 1s - loss: 7.6316 - val_loss: 4.1757
Epoch 12/50
 - 1s - loss: 7.5649 - val_loss: 4.2179
Epoch 13/50
 - 1s - loss: 7.5728 - val_loss: 4.2525
Epoch 14/50
 - 1s - loss: 7.4619 - val_loss: 4.1034
Epoch 15/50
 - 1s - loss: 7.5738 - val_loss: 4.1312
Epoch 16/50
 - 1s - loss: 7.5298 - val_loss: 4.1635
Epoch 17/50
 - 1s - loss: 7.3330 - val_loss: 4.2222
Epoch 18/50
 - 1s - loss: 7.4295 - val_loss: 4.1820
Epoch 19/50
 - 1s - loss: 7.3415 - val_loss: 4.1276
Epoch 20/50
 - 1s - loss: 7.3527 - val_loss: 4.1341
Epoch 21/50
 - 1s - loss: 7.4124 - val_loss: 4.2099
Epoch 22/50
 - 1s - loss: 7.2862 - val_loss: 4.2081
Epoch 23/50
 - 1s - loss: 7.3823 - val_loss: 4.1168
Epoch 24/50
 - 1s - loss: 7.3778 - val_loss: 4.1669
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 6328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
time = 6623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9622571, -8.850303 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.4836 - val_loss: 18.1676
Epoch 2/50
 - 1s - loss: 1.4291 - val_loss: 18.0821
Epoch 3/50
 - 1s - loss: 1.4556 - val_loss: 18.0847
Epoch 4/50
 - 1s - loss: 1.4435 - val_loss: 18.0323
Epoch 5/50
 - 1s - loss: 1.2767 - val_loss: 18.0493
Epoch 6/50
 - 1s - loss: 1.3276 - val_loss: 18.0587
Epoch 7/50
 - 1s - loss: 1.1595 - val_loss: 18.1057
Epoch 8/50
 - 1s - loss: 1.2438 - val_loss: 18.0806
Epoch 9/50
 - 1s - loss: 1.2329 - val_loss: 18.1418
Epoch 10/50
 - 1s - loss: 1.2690 - val_loss: 18.3488
Epoch 11/50
 - 1s - loss: 1.1111 - val_loss: 18.0874
Epoch 12/50
 - 1s - loss: 1.1483 - val_loss: 18.0628
Epoch 13/50
 - 1s - loss: 1.1620 - val_loss: 18.1243
Epoch 14/50
 - 1s - loss: 1.0884 - val_loss: 18.2122
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 6628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
time = 6923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9302871, -8.774388 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.5403 - val_loss: 3.4696
Epoch 2/50
 - 1s - loss: 1.4994 - val_loss: 3.6364
Epoch 3/50
 - 1s - loss: 1.4958 - val_loss: 3.6591
Epoch 4/50
 - 1s - loss: 1.2957 - val_loss: 3.4895
Epoch 5/50
 - 1s - loss: 1.3987 - val_loss: 3.5553
Epoch 6/50
 - 1s - loss: 1.4352 - val_loss: 3.6040
Epoch 7/50
 - 1s - loss: 1.2820 - val_loss: 3.4998
Epoch 8/50
 - 1s - loss: 1.1460 - val_loss: 3.5301
Epoch 9/50
 - 1s - loss: 1.4239 - val_loss: 3.5145
Epoch 10/50
 - 1s - loss: 1.1961 - val_loss: 3.5953
Epoch 11/50
 - 1s - loss: 1.3765 - val_loss: 3.5500
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 6928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 6998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7003	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7008	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7013	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7018	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7023	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7028	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7033	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7038	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7043	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7048	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7053	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7058	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7063	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7068	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7073	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7078	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7083	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7088	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7093	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7098	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7103	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7108	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7113	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7118	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7123	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7128	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7133	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7138	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7143	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7148	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7153	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7158	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7163	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7168	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7173	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7178	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7188	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7193	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7198	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
time = 7223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.938705, -8.556341]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 8.5402 - val_loss: 1.3095
Epoch 2/50
 - 1s - loss: 8.4391 - val_loss: 1.4641
Epoch 3/50
 - 1s - loss: 8.3583 - val_loss: 1.3150
Epoch 4/50
 - 1s - loss: 8.2601 - val_loss: 1.3690
Epoch 5/50
 - 1s - loss: 8.1100 - val_loss: 1.4139
Epoch 6/50
 - 1s - loss: 8.2847 - val_loss: 1.3364
Epoch 7/50
 - 1s - loss: 7.9783 - val_loss: 1.5538
Epoch 8/50
 - 1s - loss: 8.0294 - val_loss: 1.3944
Epoch 9/50
 - 1s - loss: 7.9324 - val_loss: 1.4027
Epoch 10/50
 - 1s - loss: 7.9688 - val_loss: 1.3813
Epoch 11/50
 - 1s - loss: 7.8598 - val_loss: 1.4086
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 7228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
time = 7523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-2.0133703, -8.485289 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 7.1704 - val_loss: 3.4969
Epoch 2/50
 - 1s - loss: 7.3123 - val_loss: 3.6399
Epoch 3/50
 - 1s - loss: 6.9627 - val_loss: 3.7990
Epoch 4/50
 - 1s - loss: 7.0945 - val_loss: 3.7770
Epoch 5/50
 - 1s - loss: 6.9393 - val_loss: 3.9378
Epoch 6/50
 - 1s - loss: 6.9422 - val_loss: 3.6512
Epoch 7/50
 - 1s - loss: 6.9223 - val_loss: 3.8158
Epoch 8/50
 - 1s - loss: 6.7539 - val_loss: 3.6491
Epoch 9/50
 - 1s - loss: 6.6911 - val_loss: 3.6688
Epoch 10/50
 - 1s - loss: 7.2190 - val_loss: 3.7469
Epoch 11/50
 - 1s - loss: 6.7672 - val_loss: 3.7205
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 7528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
time = 7823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.9280388, -8.438454 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 3.0957 - val_loss: 1.0813
Epoch 2/50
 - 1s - loss: 2.9748 - val_loss: 1.1868
Epoch 3/50
 - 1s - loss: 2.4685 - val_loss: 1.2117
Epoch 4/50
 - 1s - loss: 2.6588 - val_loss: 1.1967
Epoch 5/50
 - 1s - loss: 2.5736 - val_loss: 1.2665
Epoch 6/50
 - 1s - loss: 2.4832 - val_loss: 1.1365
Epoch 7/50
 - 1s - loss: 2.2800 - val_loss: 1.0954
Epoch 8/50
 - 1s - loss: 2.1996 - val_loss: 1.1355
Epoch 9/50
 - 1s - loss: 2.2225 - val_loss: 1.0867
Epoch 10/50
 - 1s - loss: 2.4754 - val_loss: 1.1359
Epoch 11/50
 - 1s - loss: 2.4700 - val_loss: 1.1844
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 7828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 7998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8003	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8008	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8013	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8018	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8023	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8028	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8033	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8038	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8043	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8048	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8053	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8058	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8063	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8068	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8073	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8078	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8083	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8088	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8093	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8098	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8103	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8108	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8113	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8118	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
time = 8123	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5711918, -8.261924 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.6697 - val_loss: 16.9077
Epoch 2/50
 - 1s - loss: 1.5071 - val_loss: 16.9507
Epoch 3/50
 - 1s - loss: 1.4402 - val_loss: 16.9754
Epoch 4/50
 - 1s - loss: 1.3867 - val_loss: 16.9521
Epoch 5/50
 - 1s - loss: 1.1447 - val_loss: 16.9634
Epoch 6/50
 - 1s - loss: 1.4312 - val_loss: 17.0004
Epoch 7/50
 - 1s - loss: 1.2057 - val_loss: 17.0624
Epoch 8/50
 - 1s - loss: 1.1925 - val_loss: 17.1184
Epoch 9/50
 - 1s - loss: 1.4451 - val_loss: 17.2833
Epoch 10/50
 - 1s - loss: 1.0961 - val_loss: 17.3326
Epoch 11/50
 - 1s - loss: 1.1248 - val_loss: 17.2334
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 8128	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8133	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8138	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8143	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8148	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8153	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8158	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8163	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8168	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8173	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8178	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8188	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8193	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8198	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
time = 8423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4635444, -8.058804 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 8.1048 - val_loss: 1.0483
Epoch 2/50
 - 1s - loss: 8.1394 - val_loss: 1.1918
Epoch 3/50
 - 1s - loss: 8.0827 - val_loss: 1.1183
Epoch 4/50
 - 1s - loss: 7.7557 - val_loss: 1.0866
Epoch 5/50
 - 1s - loss: 7.9258 - val_loss: 1.1164
Epoch 6/50
 - 1s - loss: 7.7012 - val_loss: 1.1204
Epoch 7/50
 - 1s - loss: 7.5527 - val_loss: 1.2203
Epoch 8/50
 - 1s - loss: 7.6163 - val_loss: 1.1460
Epoch 9/50
 - 1s - loss: 7.5704 - val_loss: 1.2673
Epoch 10/50
 - 1s - loss: 7.4433 - val_loss: 1.1327
Epoch 11/50
 - 1s - loss: 7.3663 - val_loss: 1.2271
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 8428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
time = 8723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5180485, -8.00598  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 7.9374 - val_loss: 0.6099
Epoch 2/50
 - 1s - loss: 8.0242 - val_loss: 0.6274
Epoch 3/50
 - 1s - loss: 7.6344 - val_loss: 0.6733
Epoch 4/50
 - 1s - loss: 7.7169 - val_loss: 0.7615
Epoch 5/50
 - 1s - loss: 7.5899 - val_loss: 0.9013
Epoch 6/50
 - 1s - loss: 7.4952 - val_loss: 0.9434
Epoch 7/50
 - 1s - loss: 7.6380 - val_loss: 0.9411
Epoch 8/50
 - 1s - loss: 7.4015 - val_loss: 0.7972
Epoch 9/50
 - 1s - loss: 7.4329 - val_loss: 0.9120
Epoch 10/50
 - 1s - loss: 7.2210 - val_loss: 0.9309
Epoch 11/50
 - 1s - loss: 7.1942 - val_loss: 0.8330
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 8728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 8998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 9003	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 9008	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 9013	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 9018	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
time = 9023	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.5005596, -7.974963 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 2.0435 - val_loss: 13.4152
Epoch 2/50
 - 1s - loss: 1.9755 - val_loss: 13.4780
Epoch 3/50
 - 1s - loss: 1.8130 - val_loss: 13.6897
Epoch 4/50
 - 1s - loss: 1.9174 - val_loss: 13.6288
Epoch 5/50
 - 1s - loss: 1.7900 - val_loss: 13.6330
Epoch 6/50
 - 1s - loss: 1.8951 - val_loss: 13.6129
Epoch 7/50
 - 1s - loss: 1.8324 - val_loss: 13.7338
Epoch 8/50
 - 1s - loss: 1.7120 - val_loss: 13.8136
Epoch 9/50
 - 1s - loss: 1.7502 - val_loss: 13.7921
Epoch 10/50
 - 1s - loss: 1.7322 - val_loss: 13.7152
Epoch 11/50
 - 1s - loss: 1.6980 - val_loss: 13.8652
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 9028	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9033	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9038	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9043	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9048	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9053	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9058	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9063	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9068	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9073	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9078	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9083	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9088	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9093	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9098	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9103	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9108	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9113	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9118	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9123	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9128	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9133	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9138	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9143	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9148	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9153	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9158	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9163	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9168	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9173	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9178	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9188	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9193	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9198	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
time = 9323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.4997978, -7.839074 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 2.4179 - val_loss: 0.7265
Epoch 2/50
 - 1s - loss: 2.1639 - val_loss: 0.8611
Epoch 3/50
 - 1s - loss: 1.9486 - val_loss: 0.7845
Epoch 4/50
 - 1s - loss: 1.9910 - val_loss: 0.9642
Epoch 5/50
 - 1s - loss: 1.9742 - val_loss: 0.9776
Epoch 6/50
 - 1s - loss: 1.8230 - val_loss: 0.8581
Epoch 7/50
 - 1s - loss: 2.0140 - val_loss: 1.1013
Epoch 8/50
 - 1s - loss: 1.8637 - val_loss: 0.9247
Epoch 9/50
 - 1s - loss: 1.8977 - val_loss: 1.1118
Epoch 10/50
 - 1s - loss: 1.7579 - val_loss: 0.9205
Epoch 11/50
 - 1s - loss: 1.8209 - val_loss: 0.9578
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 9328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
time = 9623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.13099 , -7.792489]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 2.5418 - val_loss: 15.5695
Epoch 2/50
 - 1s - loss: 2.1794 - val_loss: 15.6624
Epoch 3/50
 - 1s - loss: 2.1102 - val_loss: 15.5669
Epoch 4/50
 - 1s - loss: 2.3384 - val_loss: 15.5939
Epoch 5/50
 - 1s - loss: 1.9352 - val_loss: 15.5764
Epoch 6/50
 - 1s - loss: 1.8038 - val_loss: 15.4019
Epoch 7/50
 - 1s - loss: 1.6165 - val_loss: 15.6154
Epoch 8/50
 - 1s - loss: 1.7112 - val_loss: 15.7339
Epoch 9/50
 - 1s - loss: 1.8654 - val_loss: 15.5592
Epoch 10/50
 - 1s - loss: 1.6852 - val_loss: 15.3731
Epoch 11/50
 - 1s - loss: 1.6903 - val_loss: 15.2017
Epoch 12/50
 - 1s - loss: 1.4945 - val_loss: 15.3259
Epoch 13/50
 - 1s - loss: 1.4982 - val_loss: 15.5063
Epoch 14/50
 - 1s - loss: 1.5950 - val_loss: 15.2701
Epoch 15/50
 - 1s - loss: 1.5209 - val_loss: 15.6041
Epoch 16/50
 - 1s - loss: 1.4952 - val_loss: 15.2037
Epoch 17/50
 - 1s - loss: 1.5758 - val_loss: 15.5308
Epoch 18/50
 - 1s - loss: 1.5010 - val_loss: 15.4863
Epoch 19/50
 - 1s - loss: 1.5620 - val_loss: 15.5712
Epoch 20/50
 - 1s - loss: 1.6947 - val_loss: 15.3815
Epoch 21/50
 - 1s - loss: 1.5075 - val_loss: 15.6853
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 9628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
time = 9923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1738014, -7.7243805]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 8.2115 - val_loss: 0.5844
Epoch 2/50
 - 1s - loss: 7.7124 - val_loss: 0.5840
Epoch 3/50
 - 1s - loss: 7.8637 - val_loss: 0.5362
Epoch 4/50
 - 1s - loss: 7.6319 - val_loss: 0.6153
Epoch 5/50
 - 1s - loss: 7.8253 - val_loss: 0.7149
Epoch 6/50
 - 1s - loss: 7.7123 - val_loss: 0.5708
Epoch 7/50
 - 1s - loss: 7.4547 - val_loss: 0.5584
Epoch 8/50
 - 1s - loss: 7.5509 - val_loss: 0.7063
Epoch 9/50
 - 1s - loss: 7.5468 - val_loss: 0.5456
Epoch 10/50
 - 1s - loss: 7.3190 - val_loss: 0.5549
Epoch 11/50
 - 1s - loss: 7.4245 - val_loss: 0.6289
Epoch 12/50
 - 1s - loss: 7.4197 - val_loss: 0.6422
Epoch 13/50
 - 1s - loss: 7.2239 - val_loss: 0.7271
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 9928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 9998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10003	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10008	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10013	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10018	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10023	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10028	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10033	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10038	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10043	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10048	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10053	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10058	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10063	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10068	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10073	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10078	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10083	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10088	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10093	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10098	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10103	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10108	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10113	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10118	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10123	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10128	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10133	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10138	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10143	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10148	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10153	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10158	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10163	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10168	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10173	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10178	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10188	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10193	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10198	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
time = 10223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1940126, -7.61843  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.3308 - val_loss: 15.3098
Epoch 2/50
 - 1s - loss: 1.2973 - val_loss: 15.6413
Epoch 3/50
 - 1s - loss: 1.1699 - val_loss: 15.9655
Epoch 4/50
 - 1s - loss: 1.3085 - val_loss: 16.2590
Epoch 5/50
 - 1s - loss: 1.1330 - val_loss: 16.4396
Epoch 6/50
 - 1s - loss: 1.0679 - val_loss: 16.4729
Epoch 7/50
 - 1s - loss: 1.0887 - val_loss: 16.7062
Epoch 8/50
 - 1s - loss: 1.3005 - val_loss: 16.5734
Epoch 9/50
 - 1s - loss: 1.0310 - val_loss: 16.6677
Epoch 10/50
 - 1s - loss: 1.1056 - val_loss: 17.1071
Epoch 11/50
 - 1s - loss: 1.0293 - val_loss: 17.3349
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 10228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
time = 10523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.2461672, -7.635244 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 8.2659 - val_loss: 0.7270
Epoch 2/50
 - 1s - loss: 7.9847 - val_loss: 0.7305
Epoch 3/50
 - 1s - loss: 7.8027 - val_loss: 0.6699
Epoch 4/50
 - 1s - loss: 7.6255 - val_loss: 0.7270
Epoch 5/50
 - 1s - loss: 7.3215 - val_loss: 0.7152
Epoch 6/50
 - 1s - loss: 7.2681 - val_loss: 0.8558
Epoch 7/50
 - 1s - loss: 7.1603 - val_loss: 0.7422
Epoch 8/50
 - 1s - loss: 7.5441 - val_loss: 0.7235
Epoch 9/50
 - 1s - loss: 7.1801 - val_loss: 0.8456
Epoch 10/50
 - 1s - loss: 7.0094 - val_loss: 0.8372
Epoch 11/50
 - 1s - loss: 6.9893 - val_loss: 0.8505
Epoch 12/50
 - 1s - loss: 6.9673 - val_loss: 0.8375
Epoch 13/50
 - 1s - loss: 6.9545 - val_loss: 0.7962
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 10528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
time = 10823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-1.1447744, -7.6034684]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 2.3105 - val_loss: 13.9018
Epoch 2/50
 - 1s - loss: 1.8176 - val_loss: 13.7799
Epoch 3/50
 - 1s - loss: 1.9575 - val_loss: 14.2224
Epoch 4/50
 - 1s - loss: 1.7556 - val_loss: 13.9674
Epoch 5/50
 - 1s - loss: 1.7021 - val_loss: 14.1367
Epoch 6/50
 - 1s - loss: 1.7622 - val_loss: 14.4027
Epoch 7/50
 - 1s - loss: 1.6207 - val_loss: 14.8497
Epoch 8/50
 - 1s - loss: 1.6241 - val_loss: 14.8563
Epoch 9/50
 - 1s - loss: 1.6950 - val_loss: 15.1919
Epoch 10/50
 - 1s - loss: 1.6626 - val_loss: 15.1861
Epoch 11/50
 - 1s - loss: 1.5611 - val_loss: 15.1105
Epoch 12/50
 - 1s - loss: 1.4826 - val_loss: 15.3320
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 10828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 10998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11003	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11008	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11013	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11018	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11023	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11028	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11033	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11038	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11043	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11048	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11053	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11058	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11063	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11068	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11073	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11078	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11083	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11088	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11093	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11098	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11103	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11108	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11113	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11118	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
time = 11123	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.97923803, -7.5827637 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.1518 - val_loss: 15.6080
Epoch 2/50
 - 1s - loss: 1.1369 - val_loss: 15.1920
Epoch 3/50
 - 1s - loss: 1.0001 - val_loss: 15.6185
Epoch 4/50
 - 1s - loss: 1.0001 - val_loss: 15.4165
Epoch 5/50
 - 1s - loss: 1.0234 - val_loss: 15.0894
Epoch 6/50
 - 1s - loss: 0.9414 - val_loss: 15.5530
Epoch 7/50
 - 1s - loss: 0.9090 - val_loss: 15.5151
Epoch 8/50
 - 1s - loss: 0.9381 - val_loss: 15.8453
Epoch 9/50
 - 1s - loss: 1.0452 - val_loss: 15.6895
Epoch 10/50
 - 1s - loss: 0.8689 - val_loss: 15.1018
Epoch 11/50
 - 1s - loss: 0.8964 - val_loss: 15.8808
Epoch 12/50
 - 1s - loss: 0.9307 - val_loss: 15.8085
Epoch 13/50
 - 1s - loss: 0.9025 - val_loss: 15.8636
Epoch 14/50
 - 1s - loss: 0.7663 - val_loss: 15.9175
Epoch 15/50
 - 1s - loss: 0.9047 - val_loss: 15.1172
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 11128	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11133	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11138	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11143	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11148	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11153	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11158	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11163	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11168	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11173	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11178	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11188	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11193	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11198	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
time = 11423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.91820335, -7.6137996 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.7309 - val_loss: 14.9487
Epoch 2/50
 - 1s - loss: 1.6398 - val_loss: 15.1218
Epoch 3/50
 - 1s - loss: 1.5013 - val_loss: 15.1783
Epoch 4/50
 - 1s - loss: 1.7274 - val_loss: 15.1457
Epoch 5/50
 - 1s - loss: 1.6388 - val_loss: 14.8190
Epoch 6/50
 - 1s - loss: 1.4976 - val_loss: 15.1021
Epoch 7/50
 - 1s - loss: 1.5812 - val_loss: 14.9267
Epoch 8/50
 - 1s - loss: 1.6068 - val_loss: 15.1792
Epoch 9/50
 - 1s - loss: 1.4619 - val_loss: 15.2886
Epoch 10/50
 - 1s - loss: 1.5176 - val_loss: 15.1317
Epoch 11/50
 - 1s - loss: 1.3034 - val_loss: 15.2840
Epoch 12/50
 - 1s - loss: 1.3072 - val_loss: 15.2322
Epoch 13/50
 - 1s - loss: 1.4297 - val_loss: 15.4854
Epoch 14/50
 - 1s - loss: 1.3963 - val_loss: 15.4388
Epoch 15/50
 - 1s - loss: 1.3986 - val_loss: 15.4426
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 11428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
time = 11723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.84079313, -7.52717   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.9295 - val_loss: 15.7229
Epoch 2/50
 - 1s - loss: 1.7126 - val_loss: 15.9480
Epoch 3/50
 - 1s - loss: 1.6561 - val_loss: 15.8374
Epoch 4/50
 - 1s - loss: 1.8311 - val_loss: 16.1257
Epoch 5/50
 - 1s - loss: 1.4945 - val_loss: 15.8794
Epoch 6/50
 - 1s - loss: 1.4307 - val_loss: 15.6140
Epoch 7/50
 - 1s - loss: 1.5798 - val_loss: 15.8512
Epoch 8/50
 - 1s - loss: 1.4197 - val_loss: 15.5856
Epoch 9/50
 - 1s - loss: 1.4686 - val_loss: 15.6685
Epoch 10/50
 - 1s - loss: 1.5326 - val_loss: 15.5748
Epoch 11/50
 - 1s - loss: 1.6145 - val_loss: 15.6081
Epoch 12/50
 - 1s - loss: 1.4282 - val_loss: 15.6994
Epoch 13/50
 - 1s - loss: 1.6156 - val_loss: 15.5813
Epoch 14/50
 - 1s - loss: 1.3817 - val_loss: 15.5751
Epoch 15/50
 - 1s - loss: 1.3036 - val_loss: 15.6443
Epoch 16/50
 - 1s - loss: 1.3917 - val_loss: 15.6856
Epoch 17/50
 - 1s - loss: 1.2354 - val_loss: 15.5888
Epoch 18/50
 - 1s - loss: 1.3655 - val_loss: 15.8687
Epoch 19/50
 - 1s - loss: 1.2868 - val_loss: 15.4312
Epoch 20/50
 - 1s - loss: 1.3468 - val_loss: 15.5994
Epoch 21/50
 - 1s - loss: 1.3259 - val_loss: 15.6695
Epoch 22/50
 - 1s - loss: 1.3452 - val_loss: 15.5953
Epoch 23/50
 - 1s - loss: 1.3975 - val_loss: 15.4353
Epoch 24/50
 - 1s - loss: 1.3202 - val_loss: 15.3925
Epoch 25/50
 - 1s - loss: 1.3578 - val_loss: 15.5041
Epoch 26/50
 - 1s - loss: 1.4003 - val_loss: 15.7066
Epoch 27/50
 - 1s - loss: 1.1676 - val_loss: 15.7506
Epoch 28/50
 - 1s - loss: 1.3836 - val_loss: 15.2823
Epoch 29/50
 - 1s - loss: 1.3311 - val_loss: 15.4920
Epoch 30/50
 - 1s - loss: 1.4224 - val_loss: 15.6894
Epoch 31/50
 - 1s - loss: 1.1867 - val_loss: 15.6840
Epoch 32/50
 - 1s - loss: 1.3045 - val_loss: 15.7704
Epoch 33/50
 - 1s - loss: 1.2378 - val_loss: 15.7773
Epoch 34/50
 - 1s - loss: 1.2720 - val_loss: 15.8039
Epoch 35/50
 - 1s - loss: 1.2894 - val_loss: 15.8576
Epoch 36/50
 - 1s - loss: 1.2170 - val_loss: 15.8022
Epoch 37/50
 - 1s - loss: 1.4185 - val_loss: 15.8064
Epoch 38/50
 - 1s - loss: 1.2558 - val_loss: 15.8008
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 11728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 11998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 12003	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 12008	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 12013	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 12018	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
time = 12023	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.8895769, -7.4269686]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 7.6397 - val_loss: 1.1418
Epoch 2/50
 - 1s - loss: 7.4189 - val_loss: 1.1836
Epoch 3/50
 - 1s - loss: 7.4007 - val_loss: 1.3594
Epoch 4/50
 - 1s - loss: 7.3362 - val_loss: 1.2423
Epoch 5/50
 - 1s - loss: 7.1084 - val_loss: 1.1809
Epoch 6/50
 - 1s - loss: 6.8557 - val_loss: 1.0189
Epoch 7/50
 - 1s - loss: 6.7912 - val_loss: 1.2417
Epoch 8/50
 - 1s - loss: 7.0408 - val_loss: 0.9906
Epoch 9/50
 - 1s - loss: 6.8533 - val_loss: 1.1227
Epoch 10/50
 - 1s - loss: 6.8799 - val_loss: 1.2643
Epoch 11/50
 - 1s - loss: 6.9924 - val_loss: 1.1565
Epoch 12/50
 - 1s - loss: 6.8130 - val_loss: 0.9983
Epoch 13/50
 - 1s - loss: 6.8816 - val_loss: 1.1307
Epoch 14/50
 - 1s - loss: 6.7355 - val_loss: 1.3257
Epoch 15/50
 - 1s - loss: 6.6665 - val_loss: 1.1215
Epoch 16/50
 - 1s - loss: 6.7030 - val_loss: 1.2338
Epoch 17/50
 - 1s - loss: 6.5346 - val_loss: 1.6108
Epoch 18/50
 - 1s - loss: 6.6373 - val_loss: 1.2715
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 12028	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12033	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12038	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12043	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12048	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12053	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12058	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12063	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12068	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12073	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12078	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12083	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12088	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12093	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12098	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12103	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12108	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12113	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12118	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12123	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12128	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12133	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12138	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12143	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12148	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12153	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12158	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12163	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12168	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12173	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12178	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12188	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12193	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12198	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
time = 12323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.902802, -7.383836]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.5781 - val_loss: 14.5306
Epoch 2/50
 - 1s - loss: 1.5560 - val_loss: 14.5503
Epoch 3/50
 - 1s - loss: 1.2655 - val_loss: 14.5018
Epoch 4/50
 - 1s - loss: 1.1732 - val_loss: 14.6839
Epoch 5/50
 - 1s - loss: 1.0574 - val_loss: 14.5698
Epoch 6/50
 - 1s - loss: 1.1824 - val_loss: 14.5645
Epoch 7/50
 - 1s - loss: 1.2446 - val_loss: 14.5288
Epoch 8/50
 - 1s - loss: 1.1416 - val_loss: 14.5701
Epoch 9/50
 - 1s - loss: 0.9982 - val_loss: 14.5497
Epoch 10/50
 - 1s - loss: 1.0380 - val_loss: 14.5830
Epoch 11/50
 - 1s - loss: 0.9081 - val_loss: 14.5378
Epoch 12/50
 - 1s - loss: 1.2334 - val_loss: 14.6167
Epoch 13/50
 - 1s - loss: 1.0201 - val_loss: 14.6104
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 12328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
time = 12623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.66179323, -7.3365054 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.4974 - val_loss: 0.7082
Epoch 2/50
 - 1s - loss: 1.8590 - val_loss: 0.7644
Epoch 3/50
 - 1s - loss: 1.5735 - val_loss: 0.7806
Epoch 4/50
 - 1s - loss: 1.2916 - val_loss: 0.8029
Epoch 5/50
 - 1s - loss: 1.1471 - val_loss: 0.7407
Epoch 6/50
 - 1s - loss: 1.2509 - val_loss: 0.8589
Epoch 7/50
 - 1s - loss: 1.2389 - val_loss: 0.8696
Epoch 8/50
 - 1s - loss: 1.3287 - val_loss: 0.8194
Epoch 9/50
 - 1s - loss: 1.1390 - val_loss: 1.0646
Epoch 10/50
 - 1s - loss: 1.2166 - val_loss: 0.8963
Epoch 11/50
 - 1s - loss: 1.1080 - val_loss: 0.9153
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 12628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
time = 12923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.69539785, -7.2587814 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 7.5088 - val_loss: 1.0260
Epoch 2/50
 - 1s - loss: 7.5732 - val_loss: 1.1065
Epoch 3/50
 - 1s - loss: 7.2895 - val_loss: 1.1197
Epoch 4/50
 - 1s - loss: 7.2409 - val_loss: 1.2256
Epoch 5/50
 - 1s - loss: 7.1384 - val_loss: 1.4469
Epoch 6/50
 - 1s - loss: 7.1579 - val_loss: 1.2611
Epoch 7/50
 - 1s - loss: 7.2394 - val_loss: 1.4491
Epoch 8/50
 - 1s - loss: 6.9527 - val_loss: 1.2346
Epoch 9/50
 - 1s - loss: 7.0830 - val_loss: 1.2989
Epoch 10/50
 - 1s - loss: 6.8731 - val_loss: 1.3147
Epoch 11/50
 - 1s - loss: 7.0954 - val_loss: 1.5770
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 12928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 12998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13003	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13008	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13013	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13018	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13023	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13028	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13033	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13038	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13043	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13048	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13053	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13058	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13063	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13068	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13073	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13078	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13083	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13088	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13093	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13098	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13103	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13108	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13113	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13118	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13123	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13128	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13133	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13138	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13143	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13148	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13153	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13158	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13163	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13168	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13173	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13178	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13188	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13193	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13198	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
time = 13223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.6618886, -7.2514815]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 7.2788 - val_loss: 0.7866
Epoch 2/50
 - 1s - loss: 7.2742 - val_loss: 0.7488
Epoch 3/50
 - 1s - loss: 7.5284 - val_loss: 0.8547
Epoch 4/50
 - 1s - loss: 7.4060 - val_loss: 0.8396
Epoch 5/50
 - 1s - loss: 7.1171 - val_loss: 1.0243
Epoch 6/50
 - 1s - loss: 6.9939 - val_loss: 1.0454
Epoch 7/50
 - 1s - loss: 6.9105 - val_loss: 0.9324
Epoch 8/50
 - 1s - loss: 6.9344 - val_loss: 0.9094
Epoch 9/50
 - 1s - loss: 6.9576 - val_loss: 0.9232
Epoch 10/50
 - 1s - loss: 6.8674 - val_loss: 0.8128
Epoch 11/50
 - 1s - loss: 6.6471 - val_loss: 0.9257
Epoch 12/50
 - 1s - loss: 7.5734 - val_loss: 1.0424
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 13228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
time = 13523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.78490067, -7.2636986 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 6.3733 - val_loss: 1.1371
Epoch 2/50
 - 1s - loss: 6.3589 - val_loss: 0.8840
Epoch 3/50
 - 1s - loss: 6.3412 - val_loss: 0.8914
Epoch 4/50
 - 1s - loss: 6.2624 - val_loss: 0.8935
Epoch 5/50
 - 1s - loss: 6.2901 - val_loss: 1.1865
Epoch 6/50
 - 1s - loss: 6.2243 - val_loss: 0.9255
Epoch 7/50
 - 1s - loss: 6.1726 - val_loss: 0.9567
Epoch 8/50
 - 1s - loss: 6.0940 - val_loss: 1.0289
Epoch 9/50
 - 1s - loss: 6.1993 - val_loss: 0.9829
Epoch 10/50
 - 1s - loss: 6.1153 - val_loss: 0.9467
Epoch 11/50
 - 1s - loss: 5.9028 - val_loss: 0.9418
Epoch 12/50
 - 1s - loss: 6.2835 - val_loss: 0.9522
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 13528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
time = 13823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.70874214, -7.2447257 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 2.1817 - val_loss: 12.6922
Epoch 2/50
 - 1s - loss: 2.0521 - val_loss: 12.8201
Epoch 3/50
 - 1s - loss: 2.2737 - val_loss: 12.9507
Epoch 4/50
 - 1s - loss: 1.7266 - val_loss: 12.6943
Epoch 5/50
 - 1s - loss: 1.9856 - val_loss: 12.8413
Epoch 6/50
 - 1s - loss: 1.9844 - val_loss: 12.6881
Epoch 7/50
 - 1s - loss: 1.8816 - val_loss: 12.6739
Epoch 8/50
 - 1s - loss: 1.9321 - val_loss: 12.7806
Epoch 9/50
 - 1s - loss: 1.7215 - val_loss: 12.8781
Epoch 10/50
 - 1s - loss: 1.8135 - val_loss: 12.8625
Epoch 11/50
 - 1s - loss: 1.5993 - val_loss: 12.8681
Epoch 12/50
 - 1s - loss: 1.4954 - val_loss: 12.8108
Epoch 13/50
 - 1s - loss: 1.7670 - val_loss: 12.7305
Epoch 14/50
 - 1s - loss: 1.6377 - val_loss: 12.7532
Epoch 15/50
 - 1s - loss: 1.6420 - val_loss: 13.0027
Epoch 16/50
 - 1s - loss: 1.4666 - val_loss: 12.9078
Epoch 17/50
 - 1s - loss: 1.6528 - val_loss: 12.8219
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 13828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 13998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14003	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14008	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14013	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14018	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14023	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14028	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14033	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14038	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14043	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14048	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14053	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14058	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14063	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14068	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14073	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14078	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14083	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14088	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14093	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14098	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14103	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14108	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14113	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14118	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
time = 14123	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.554409, -7.221583]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 2.1597 - val_loss: 12.9519
Epoch 2/50
 - 1s - loss: 1.8805 - val_loss: 12.9261
Epoch 3/50
 - 1s - loss: 1.7370 - val_loss: 12.9213
Epoch 4/50
 - 1s - loss: 1.8114 - val_loss: 13.0250
Epoch 5/50
 - 1s - loss: 1.8489 - val_loss: 12.9988
Epoch 6/50
 - 1s - loss: 1.7224 - val_loss: 13.0216
Epoch 7/50
 - 1s - loss: 1.6025 - val_loss: 13.0085
Epoch 8/50
 - 1s - loss: 1.7658 - val_loss: 13.0295
Epoch 9/50
 - 1s - loss: 1.5284 - val_loss: 13.1323
Epoch 10/50
 - 1s - loss: 1.4959 - val_loss: 13.2025
Epoch 11/50
 - 1s - loss: 1.5915 - val_loss: 13.2538
Epoch 12/50
 - 1s - loss: 1.5375 - val_loss: 13.1784
Epoch 13/50
 - 1s - loss: 1.5554 - val_loss: 13.2433
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 14128	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14133	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14138	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14143	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14148	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14153	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14158	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14163	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14168	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14173	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14178	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14188	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14193	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14198	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14203	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14208	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14213	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14218	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14223	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14228	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14233	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14238	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14243	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14248	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14253	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14258	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14263	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14268	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14273	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14278	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14283	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14288	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14293	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14298	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14303	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14308	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14313	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14318	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14323	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14328	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14333	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14338	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14343	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14348	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14353	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14358	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14363	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14368	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14373	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14378	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14383	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14388	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14393	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14398	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14403	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14408	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14413	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14418	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
time = 14423	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.57462406, -7.236119  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 1.7270 - val_loss: 12.5159
Epoch 2/50
 - 1s - loss: 1.5948 - val_loss: 12.5960
Epoch 3/50
 - 1s - loss: 1.7871 - val_loss: 12.4851
Epoch 4/50
 - 1s - loss: 1.5523 - val_loss: 12.5034
Epoch 5/50
 - 1s - loss: 1.4606 - val_loss: 12.5298
Epoch 6/50
 - 1s - loss: 1.4058 - val_loss: 12.5529
Epoch 7/50
 - 1s - loss: 1.4666 - val_loss: 12.5850
Epoch 8/50
 - 1s - loss: 1.4630 - val_loss: 12.5879
Epoch 9/50
 - 1s - loss: 1.4325 - val_loss: 12.5799
Epoch 10/50
 - 1s - loss: 1.4906 - val_loss: 12.6787
Epoch 11/50
 - 1s - loss: 1.5129 - val_loss: 12.6305
Epoch 12/50
 - 1s - loss: 1.4233 - val_loss: 12.6698
Epoch 13/50
 - 1s - loss: 1.7792 - val_loss: 12.6546
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 14428	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14433	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14438	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14443	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14448	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14453	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14458	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14463	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14468	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14473	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14478	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14483	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14488	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14493	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14498	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14503	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14508	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14513	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14518	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14523	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14528	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14533	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14538	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14543	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14548	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14553	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14558	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14568	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14573	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14578	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14583	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14588	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14593	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14598	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14603	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14608	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14613	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14618	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14623	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14628	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14633	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14638	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14643	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14648	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14653	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14658	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14663	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14668	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14673	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14678	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14683	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14688	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14693	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14698	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14703	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14708	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14713	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14718	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
time = 14723	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.52719975, -7.1757655 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 1s - loss: 7.3387 - val_loss: 0.7810
Epoch 2/50
 - 1s - loss: 6.8952 - val_loss: 0.8112
Epoch 3/50
 - 1s - loss: 7.1842 - val_loss: 0.9738
Epoch 4/50
 - 1s - loss: 6.8922 - val_loss: 0.9849
Epoch 5/50
 - 1s - loss: 6.8632 - val_loss: 0.9155
Epoch 6/50
 - 1s - loss: 6.6557 - val_loss: 0.7590
Epoch 7/50
 - 1s - loss: 6.6901 - val_loss: 0.9509
Epoch 8/50
 - 1s - loss: 6.6356 - val_loss: 0.7722
Epoch 9/50
 - 1s - loss: 6.4927 - val_loss: 0.8701
Epoch 10/50
 - 1s - loss: 6.6268 - val_loss: 0.7896
Epoch 11/50
 - 1s - loss: 6.4076 - val_loss: 0.8240
Epoch 12/50
 - 1s - loss: 6.4567 - val_loss: 0.8458
Epoch 13/50
 - 1s - loss: 6.5414 - val_loss: 0.9340
Epoch 14/50
 - 1s - loss: 6.2870 - val_loss: 0.8266
Epoch 15/50
 - 1s - loss: 6.5037 - val_loss: 0.9224
Epoch 16/50
 - 1s - loss: 6.2855 - val_loss: 0.8971
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 351, after forget
length of memory (state 1, action 0): 786, after forget
length of memory (state 1, action 1): 339, after forget
time = 14728	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14733	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14738	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14743	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14748	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14753	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14758	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14763	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14768	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14773	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14778	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14783	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14788	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14793	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14798	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14803	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14808	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14813	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14818	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14823	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14828	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14833	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14838	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14843	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14848	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14853	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14858	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14863	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14868	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14873	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14878	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14883	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14888	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14893	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14898	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14903	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14908	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14913	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14918	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14923	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14928	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14933	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14938	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14943	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14948	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14953	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14958	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14963	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14968	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14973	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14978	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14983	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14988	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14993	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
time = 14998	action = 0	current_phase = 0	next_phase = 1	reward = 0.000000	array([[-0.48875284, -7.186273  ]], dtype=float32)
END
finished ['osm.passenger2.trips.xml']
finished Deeplight
