Loading configuration... done.
***Starting server on port 44331 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (1ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
/home/tahiti/桌面/sumo-0.32.0/tools
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_map_feature (InputLayer)  (None, 150, 150, 1)  0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 38, 38, 32)   2048        input_map_feature[0][0]          
__________________________________________________________________________________________________
bn1 (BatchNormalization)        (None, 38, 38, 32)   96          conv1[0][0]                      
__________________________________________________________________________________________________
act1 (Activation)               (None, 38, 38, 32)   0           bn1[0][0]                        
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 19, 19, 32)   0           act1[0][0]                       
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 19, 19, 32)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2 (Conv2D)                  (None, 10, 10, 16)   8192        dropout_1[0][0]                  
__________________________________________________________________________________________________
bn2 (BatchNormalization)        (None, 10, 10, 16)   48          conv2[0][0]                      
__________________________________________________________________________________________________
act2 (Activation)               (None, 10, 10, 16)   0           bn2[0][0]                        
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 16)     0           act2[0][0]                       
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 5, 5, 16)     0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
input_cur_phase (InputLayer)    (None, 1)            0                                            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 400)          0           dropout_2[0][0]                  
__________________________________________________________________________________________________
input_next_phase (InputLayer)   (None, 1)            0                                            
__________________________________________________________________________________________________
input_num_of_vehicles (InputLay (None, 8)            0                                            
__________________________________________________________________________________________________
input_queue_length (InputLayer) (None, 8)            0                                            
__________________________________________________________________________________________________
input_waiting_time (InputLayer) (None, 8)            0                                            
__________________________________________________________________________________________________
all_flatten_feature (Concatenat (None, 426)          0           input_cur_phase[0][0]            
                                                                 flatten_1[0][0]                  
                                                                 input_next_phase[0][0]           
                                                                 input_num_of_vehicles[0][0]      
                                                                 input_queue_length[0][0]         
                                                                 input_waiting_time[0][0]         
__________________________________________________________________________________________________
hidden_shared_1 (Dense)         (None, 20)           8540        all_flatten_feature[0][0]        
__________________________________________________________________________________________________
hidden_separate_branch_0_1 (Den (None, 20)           420         hidden_shared_1[0][0]            
__________________________________________________________________________________________________
hidden_separate_branch_1_1 (Den (None, 20)           420         hidden_shared_1[0][0]            
__________________________________________________________________________________________________
q_values_separate_branch_0 (Den (None, 2)            42          hidden_separate_branch_0_1[0][0] 
__________________________________________________________________________________________________
selector_0 (Selector)           (None, 1)            0           input_cur_phase[0][0]            
__________________________________________________________________________________________________
q_values_separate_branch_1 (Den (None, 2)            42          hidden_separate_branch_1_1[0][0] 
__________________________________________________________________________________________________
selector_1 (Selector)           (None, 1)            0           input_cur_phase[0][0]            
__________________________________________________________________________________________________
multiply_0 (Multiply)           (None, 2)            0           q_values_separate_branch_0[0][0] 
                                                                 selector_0[0][0]                 
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 2)            0           q_values_separate_branch_1[0][0] 
                                                                 selector_1[0][0]                 
__________________________________________________________________________________________________
add_1 (Add)                     (None, 2)            0           multiply_0[0][0]                 
                                                                 multiply_1[0][0]                 
==================================================================================================
Total params: 19,848
Trainable params: 19,752
Non-trainable params: 96
__________________________________________________________________________________________________
Could not connect to TraCI server at localhost:44331 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 1	current_phase = 1	next_phase = 0	reward = -1.623190	array([[1.0410463, 0.5828052]], dtype=float32)
time = 51	action = 0	current_phase = 0	next_phase = 1	reward = -0.701349	array([[-0.9804924 , -0.18058875]], dtype=float32)
time = 56	action = 1	current_phase = 0	next_phase = 1	reward = -2.003345	array([[-0.98511714, -0.1824498 ]], dtype=float32)
time = 64	action = 0	current_phase = 1	next_phase = 0	reward = -0.022476	array([[1.0396333, 0.5592303]], dtype=float32)
time = 69	action = 1	current_phase = 1	next_phase = 0	reward = -1.788284	array([[1.0144538 , 0.57775044]], dtype=float32)
time = 77	action = 0	current_phase = 0	next_phase = 1	reward = -0.844532	array([[-0.9436986 , -0.17055047]], dtype=float32)
time = 82	action = 1	current_phase = 0	next_phase = 1	reward = -1.534409	array([[-0.9368408 , -0.17525299]], dtype=float32)
time = 90	action = 0	current_phase = 1	next_phase = 0	reward = -0.023568	array([[1.01795   , 0.58197147]], dtype=float32)
time = 95	action = 1	current_phase = 1	next_phase = 0	reward = -0.982184	array([[0.97750705, 0.5977851 ]], dtype=float32)
time = 103	action = 0	current_phase = 0	next_phase = 1	reward = -0.052410	array([[-0.9514084 , -0.12663874]], dtype=float32)
time = 108	action = 1	current_phase = 0	next_phase = 1	reward = -2.540724	array([[-0.9217575 , -0.14054981]], dtype=float32)
time = 116	action = 0	current_phase = 1	next_phase = 0	reward = -0.492535	array([[0.9925161, 0.5777867]], dtype=float32)
time = 121	action = 1	current_phase = 1	next_phase = 0	reward = -1.675973	array([[0.9633208, 0.6055496]], dtype=float32)
time = 129	action = 0	current_phase = 0	next_phase = 1	reward = -0.955347	array([[-0.9810122 , -0.09360666]], dtype=float32)
time = 134	action = 1	current_phase = 0	next_phase = 1	reward = -2.275768	array([[-0.94523185, -0.11591058]], dtype=float32)
time = 142	action = 0	current_phase = 1	next_phase = 0	reward = -0.527158	array([[0.9822975 , 0.57925653]], dtype=float32)
time = 147	action = 1	current_phase = 1	next_phase = 0	reward = -1.625722	array([[0.94823986, 0.6070329 ]], dtype=float32)
time = 155	action = 0	current_phase = 0	next_phase = 1	reward = -0.543708	array([[-0.9945503 , -0.12219197]], dtype=float32)
time = 160	action = 1	current_phase = 0	next_phase = 1	reward = -1.926907	array([[-0.93284947, -0.1426435 ]], dtype=float32)
time = 168	action = 0	current_phase = 1	next_phase = 0	reward = -1.075800	array([[1.0171669, 0.5880109]], dtype=float32)
time = 173	action = 1	current_phase = 1	next_phase = 0	reward = -2.027209	array([[0.9838789, 0.6077923]], dtype=float32)
time = 181	action = 0	current_phase = 0	next_phase = 1	reward = -0.875918	array([[-0.9693139 , -0.12175206]], dtype=float32)
time = 186	action = 1	current_phase = 0	next_phase = 1	reward = -2.399272	array([[-0.9795853 , -0.15347192]], dtype=float32)
time = 194	action = 0	current_phase = 1	next_phase = 0	reward = -1.039718	array([[1.0228075 , 0.57285273]], dtype=float32)
time = 199	action = 1	current_phase = 1	next_phase = 0	reward = -1.582636	array([[1.0015705 , 0.59247774]], dtype=float32)
time = 207	action = 0	current_phase = 0	next_phase = 1	reward = -0.296649	array([[-0.91671145, -0.15512225]], dtype=float32)
time = 212	action = 1	current_phase = 0	next_phase = 1	reward = -1.202176	array([[-0.9181545 , -0.17957862]], dtype=float32)
time = 220	action = 0	current_phase = 1	next_phase = 0	reward = 0.201472	array([[1.0527053 , 0.54629964]], dtype=float32)
time = 225	action = 1	current_phase = 1	next_phase = 0	reward = -1.781699	array([[1.0239177 , 0.57903326]], dtype=float32)
time = 233	action = 0	current_phase = 0	next_phase = 1	reward = -0.960858	array([[-0.9966931 , -0.13624588]], dtype=float32)
time = 238	action = 1	current_phase = 0	next_phase = 1	reward = -1.564083	array([[-0.9940438 , -0.14567164]], dtype=float32)
time = 246	action = 0	current_phase = 1	next_phase = 0	reward = -0.997512	array([[1.0544748, 0.582225 ]], dtype=float32)
time = 251	action = 1	current_phase = 1	next_phase = 0	reward = -1.897834	array([[1.0179459 , 0.59723324]], dtype=float32)
time = 259	action = 0	current_phase = 0	next_phase = 1	reward = -0.153093	array([[-0.950594  , -0.13654262]], dtype=float32)
time = 264	action = 1	current_phase = 0	next_phase = 1	reward = -1.269915	array([[-0.95309836, -0.14949754]], dtype=float32)
time = 272	action = 0	current_phase = 1	next_phase = 0	reward = -0.675935	array([[1.0235158, 0.5813189]], dtype=float32)
time = 277	action = 1	current_phase = 1	next_phase = 0	reward = -1.428991	array([[0.9973802, 0.5981575]], dtype=float32)
time = 285	action = 0	current_phase = 0	next_phase = 1	reward = 0.031446	array([[-0.9256771 , -0.14383179]], dtype=float32)
time = 290	action = 1	current_phase = 0	next_phase = 1	reward = -1.162175	array([[-0.9446195 , -0.16079287]], dtype=float32)
time = 298	action = 0	current_phase = 1	next_phase = 0	reward = -0.502285	array([[1.0273038, 0.5689624]], dtype=float32)
time = 303	action = 1	current_phase = 1	next_phase = 0	reward = -1.684013	array([[0.97911507, 0.5943037 ]], dtype=float32)
time = 311	action = 0	current_phase = 0	next_phase = 1	reward = -0.637300	array([[-0.94323725, -0.11773539]], dtype=float32)
time = 316	action = 1	current_phase = 0	next_phase = 1	reward = -1.983840	array([[-0.93962556, -0.14543203]], dtype=float32)
time = 324	action = 0	current_phase = 1	next_phase = 0	reward = -0.012240	array([[1.0063314, 0.5649841]], dtype=float32)
time = 329	action = 1	current_phase = 1	next_phase = 0	reward = -2.539505	array([[0.9834689, 0.5776441]], dtype=float32)
time = 337	action = 0	current_phase = 0	next_phase = 1	reward = -1.931164	array([[-0.9731651, -0.1254741]], dtype=float32)
time = 342	action = 1	current_phase = 0	next_phase = 1	reward = -2.840938	array([[-0.9534234 , -0.12445911]], dtype=float32)
time = 350	action = 0	current_phase = 1	next_phase = 0	reward = -0.847122	array([[0.9856292, 0.5882712]], dtype=float32)
time = 355	action = 1	current_phase = 1	next_phase = 0	reward = -1.653012	array([[0.9735266, 0.5964912]], dtype=float32)
time = 363	action = 0	current_phase = 0	next_phase = 1	reward = -0.079915	array([[-1.0219221 , -0.13338047]], dtype=float32)
time = 368	action = 1	current_phase = 0	next_phase = 1	reward = -2.201865	array([[-0.9815388 , -0.16960233]], dtype=float32)
time = 376	action = 0	current_phase = 1	next_phase = 0	reward = -0.674761	array([[1.0333729 , 0.55937755]], dtype=float32)
time = 381	action = 1	current_phase = 1	next_phase = 0	reward = -1.644882	array([[1.0377911, 0.5643452]], dtype=float32)
time = 389	action = 0	current_phase = 0	next_phase = 1	reward = -0.917451	array([[-0.9545744 , -0.17850834]], dtype=float32)
time = 394	action = 1	current_phase = 0	next_phase = 1	reward = -2.144849	array([[-0.95083046, -0.18761164]], dtype=float32)
time = 402	action = 0	current_phase = 1	next_phase = 0	reward = 0.071557	array([[1.0303023, 0.5712636]], dtype=float32)
time = 407	action = 1	current_phase = 1	next_phase = 0	reward = -1.162089	array([[0.9979429 , 0.59516853]], dtype=float32)
time = 415	action = 0	current_phase = 0	next_phase = 1	reward = -0.789835	array([[-0.97681165, -0.15363432]], dtype=float32)
time = 420	action = 1	current_phase = 0	next_phase = 1	reward = -1.737875	array([[-0.96854585, -0.16999424]], dtype=float32)
time = 428	action = 0	current_phase = 1	next_phase = 0	reward = -1.138110	array([[1.0155721 , 0.57750225]], dtype=float32)
time = 433	action = 1	current_phase = 1	next_phase = 0	reward = -1.639748	array([[0.99741894, 0.5848606 ]], dtype=float32)
time = 441	action = 0	current_phase = 0	next_phase = 1	reward = -0.319622	array([[-0.9924562 , -0.16744319]], dtype=float32)
time = 446	action = 1	current_phase = 0	next_phase = 1	reward = -1.965022	array([[-0.9816582 , -0.16991475]], dtype=float32)
time = 454	action = 0	current_phase = 1	next_phase = 0	reward = -1.135092	array([[1.014082  , 0.56386423]], dtype=float32)
time = 459	action = 1	current_phase = 1	next_phase = 0	reward = -1.615922	array([[1.0251614, 0.5611497]], dtype=float32)
time = 467	action = 0	current_phase = 0	next_phase = 1	reward = -0.471024	array([[-0.9759493 , -0.18422352]], dtype=float32)
time = 472	action = 1	current_phase = 0	next_phase = 1	reward = -1.627636	array([[-0.9721049 , -0.18436164]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -0.465967	array([[1.0683501 , 0.55442536]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -2.518197	array([[1.0353309 , 0.56806713]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -1.001144	array([[-0.94850177, -0.1701968 ]], dtype=float32)
time = 498	action = 1	current_phase = 0	next_phase = 1	reward = -1.449169	array([[-0.9437067 , -0.14083418]], dtype=float32)
time = 506	action = 0	current_phase = 1	next_phase = 0	reward = -0.615835	array([[1.0226704, 0.6010139]], dtype=float32)
time = 511	action = 1	current_phase = 1	next_phase = 0	reward = -2.138832	array([[0.9971541 , 0.61405104]], dtype=float32)
time = 519	action = 0	current_phase = 0	next_phase = 1	reward = 0.141087	array([[-0.9522208 , -0.12147436]], dtype=float32)Simulation ended at time: 676.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2285ms
 Real time factor: 295.842
 UPS: 4287.089716
Vehicles: 
 Inserted: 261 (Loaded: 313)
 Running: 16
 Waiting: 0

DijkstraRouter answered 467 queries and explored 3.25 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 52417 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (6ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00

time = 524	action = 1	current_phase = 0	next_phase = 1	reward = -2.216058	array([[-0.96588635, -0.14261094]], dtype=float32)
time = 532	action = 0	current_phase = 1	next_phase = 0	reward = -1.377885	array([[1.0194851, 0.5550538]], dtype=float32)
time = 537	action = 1	current_phase = 1	next_phase = 0	reward = -1.662845	array([[0.9637526, 0.591439 ]], dtype=float32)
time = 545	action = 0	current_phase = 0	next_phase = 1	reward = -0.718307	array([[-0.9492421 , -0.13210806]], dtype=float32)
time = 550	action = 1	current_phase = 0	next_phase = 1	reward = -1.762079	array([[-0.9099612 , -0.14553633]], dtype=float32)
time = 558	action = 0	current_phase = 1	next_phase = 0	reward = -0.422404	array([[0.9986144, 0.5956917]], dtype=float32)
time = 563	action = 1	current_phase = 1	next_phase = 0	reward = -1.954023	array([[0.9886951 , 0.60226035]], dtype=float32)
time = 571	action = 0	current_phase = 0	next_phase = 1	reward = -0.035374	array([[-0.9802515 , -0.14398725]], dtype=float32)
time = 576	action = 1	current_phase = 0	next_phase = 1	reward = -1.339348	array([[-0.96042645, -0.17424199]], dtype=float32)
time = 584	action = 0	current_phase = 1	next_phase = 0	reward = -0.736799	array([[1.036372 , 0.5628834]], dtype=float32)
time = 589	action = 1	current_phase = 1	next_phase = 0	reward = -1.222594	array([[0.9971162, 0.5876984]], dtype=float32)
time = 597	action = 0	current_phase = 0	next_phase = 1	reward = -0.405593	array([[-0.9492106 , -0.14377236]], dtype=float32)
time = 602	action = 1	current_phase = 0	next_phase = 1	reward = -1.386637	array([[-0.94355464, -0.14651006]], dtype=float32)
time = 610	action = 0	current_phase = 1	next_phase = 0	reward = -0.339512	array([[1.0202068, 0.5813718]], dtype=float32)
time = 615	action = 1	current_phase = 1	next_phase = 0	reward = -1.271780	array([[1.0021361, 0.5893558]], dtype=float32)
time = 623	action = 0	current_phase = 0	next_phase = 1	reward = -0.180813	array([[-0.9662743 , -0.13818423]], dtype=float32)
time = 628	action = 1	current_phase = 0	next_phase = 1	reward = -1.872497	array([[-0.95860296, -0.15374103]], dtype=float32)
time = 636	action = 0	current_phase = 1	next_phase = 0	reward = -1.482339	array([[1.0285597 , 0.56592363]], dtype=float32)
time = 641	action = 1	current_phase = 1	next_phase = 0	reward = -2.181077	array([[0.9904763, 0.5742807]], dtype=float32)
time = 649	action = 0	current_phase = 0	next_phase = 1	reward = -0.775146	array([[-0.9817187, -0.1435084]], dtype=float32)
time = 654	action = 1	current_phase = 0	next_phase = 1	reward = -1.770167	array([[-0.9586174 , -0.16905558]], dtype=float32)
time = 662	action = 0	current_phase = 1	next_phase = 0	reward = -0.761266	array([[1.0014648 , 0.58155984]], dtype=float32)
time = 667	action = 1	current_phase = 1	next_phase = 0	reward = -1.146996	array([[1.0076619, 0.5864609]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:52417 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.062850	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.700355	array([[1.0599525, 0.566923 ]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -1.604073	array([[1.0460906 , 0.56634283]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.887003	array([[-0.9746271 , -0.17608705]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.564281	array([[-0.9782698 , -0.17801575]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.985911	array([[-0.966682  , -0.15401919]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.214064	array([[1.0316117 , 0.56680924]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.079915	array([[1.0056111, 0.5908176]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.379958	array([[-0.9332555 , -0.14782557]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.212051	array([[-0.94407886, -0.1506073 ]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.662442	array([[-0.96389264, -0.12211952]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.721835	array([[0.96641755, 0.5906266 ]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.862137	array([[0.9379138, 0.6063921]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.873256	array([[-0.94894725, -0.1135268 ]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.842350	array([[-0.903769  , -0.12688127]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -3.097361	array([[-0.89113426, -0.10757428]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.231526	array([[0.9704615, 0.5954067]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.655362	array([[0.9386593 , 0.60787565]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.932556	array([[-0.96805984, -0.08979902]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.289053	array([[-0.9216998 , -0.13024095]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.673172	array([[-0.8882945, -0.1350668]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.466230	array([[1.0037777, 0.5870342]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.901679	array([[0.9785979 , 0.60349035]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.651505	array([[-0.9566929 , -0.11070218]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.081846	array([[-0.962103  , -0.13587058]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.805376	array([[-0.94468594, -0.13989788]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.307591	array([[1.0258493 , 0.56545407]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.899653	array([[0.9809464, 0.5940021]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.308382	array([[-0.936112 , -0.1560443]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.957883	array([[-0.95350796, -0.16792062]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -2.468436	array([[-0.94977814, -0.16138934]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = 0.244533	array([[1.0174512 , 0.57927287]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.611840	array([[0.9994411, 0.5983316]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.534783	array([[-0.97690356, -0.14746228]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -1.419881	array([[-0.9526404 , -0.17935213]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.773055	array([[-0.9534976 , -0.14956456]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.895378	array([[1.020482 , 0.5900695]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.939611	array([[0.9881904, 0.5958555]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 0.053216	array([[-0.9413118 , -0.12350785]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.981611	array([[-0.9281404 , -0.13532624]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2282ms
 Real time factor: 293.164
 UPS: 4410.166521
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 460 queries and explored 3.39 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 41525 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.941212	array([[-0.91065896, -0.1364434 ]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -0.891427	array([[1.002965 , 0.5710634]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.572573	array([[0.97044504, 0.5881612 ]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.876981	array([[-0.9314986 , -0.11349407]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -1.169664	array([[-0.9044084 , -0.12397712]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -2.767375	array([[-0.922579  , -0.13121513]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.059995	array([[1.0029125, 0.5559779]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.419203	array([[0.9692894 , 0.57708603]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -1.918668	array([[-0.96898496, -0.12134786]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -2.396534	array([[-0.93570167, -0.12166689]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -3.346320	array([[-0.96451783, -0.11429971]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.393560	array([[0.9960294, 0.5803363]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -2.037986	array([[0.9812039 , 0.59287626]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.323420	array([[-0.9945855 , -0.14310697]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.712778	array([[-0.9475452 , -0.16584231]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.743212	array([[-0.92820376, -0.16971034]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.465246	array([[1.0319703 , 0.55555737]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.141184	array([[1.0130775, 0.5737023]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.258359	array([[-0.9599314 , -0.18704444]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -1.456049	array([[-0.9655982 , -0.16072686]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -2.046047	array([[-0.956505  , -0.15225118]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.516536	array([[1.03933  , 0.5732972]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.146977	array([[1.0228872 , 0.58206815]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.522485	array([[-0.9509927 , -0.17078361]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -1.302962	array([[-0.95490026, -0.17352721]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.932747	array([[-0.9739242 , -0.15997662]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.130556	array([[1.0401497, 0.5604199]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.300942	array([[1.0214461, 0.5732412]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.183517	array([[-0.9785968 , -0.18495518]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.393973	array([[-0.95775914, -0.19937578]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -1.354490	array([[-0.94188815, -0.19330168]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.220252	array([[1.059515  , 0.55765843]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.510614	array([[1.0440385 , 0.58070403]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.939128	array([[-0.9569876 , -0.17713538]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.601425	array([[-0.9692025 , -0.15340483]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -1.634128	array([[-0.9572559 , -0.15144151]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.491899	array([[1.0245906, 0.5894611]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.151624	array([[1.0077106 , 0.59921527]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.558119	array([[-0.9420663 , -0.12443876]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -1.343938	array([[-0.9505171 , -0.14783682]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -2.600415	array([[-0.9188948 , -0.14398137]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -0.874263	array([[0.985568  , 0.58541805]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.930070	array([[0.9679656 , 0.60299873]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -1.596395	array([[-0.9789239, -0.1142027]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -1.617989	array([[-0.9525733 , -0.13170329]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -2.353553	array([[-0.950678  , -0.14069504]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -0.515094	array([[1.009331 , 0.5669268]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.892262	array([[0.98724926, 0.5819426 ]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.968028	array([[-1.0031953 , -0.14832202]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -1.563176	array([[-0.9797875 , -0.16093911]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -2.331855	array([[-0.9655907 , -0.15722029]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.947931	array([[1.0278327, 0.5873589]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -0.919976	array([[0.98714226, 0.60927963]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.420918	array([[-0.9686692 , -0.14178379]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 0.136938	array([[-0.9635395, -0.1559265]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -2.045577	array([[-0.95840514, -0.15554969]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.712433	array([[1.0093904, 0.5816644]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.698678	array([[1.0190605 , 0.56814253]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.022518	array([[-0.9878262, -0.1646603]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.109406	array([[-0.9795076 , -0.15605065]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -2.026198	array([[-0.959044 , -0.1747967]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.737719	array([[1.0361651 , 0.57951576]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:41525 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.062850	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.700355	array([[1.0599525, 0.566923 ]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -1.604073	array([[1.0460906 , 0.56634283]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.887003	array([[-0.9746271 , -0.17608705]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.564281	array([[-0.9782698 , -0.17801575]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.985911	array([[-0.966682  , -0.15401919]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.214064	array([[1.0316117 , 0.56680924]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.079915	array([[1.0056111, 0.5908176]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.379958	array([[-0.9332555 , -0.14782557]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.212051	array([[-0.94407886, -0.1506073 ]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.662442	array([[-0.96389264, -0.12211952]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.721835	array([[0.96641755, 0.5906266 ]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.862137	array([[0.9379138, 0.6063921]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.873256	array([[-0.94894725, -0.1135268 ]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.842350	array([[-0.903769  , -0.12688127]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -3.097361	array([[-0.89113426, -0.10757428]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.231526	array([[0.9704615, 0.5954067]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.655362	array([[0.9386593 , 0.60787565]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.932556	array([[-0.96805984, -0.08979902]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.289053	array([[-0.9216998 , -0.13024095]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.673172	array([[-0.8882945, -0.1350668]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.466230	array([[1.0037777, 0.5870342]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.901679	array([[0.9785979 , 0.60349035]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.651505	array([[-0.9566929 , -0.11070218]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.081846	array([[-0.962103  , -0.13587058]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.805376	array([[-0.94468594, -0.13989788]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.307591	array([[1.0258493 , 0.56545407]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.899653	array([[0.9809464, 0.5940021]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.308382	array([[-0.936112 , -0.1560443]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.957883	array([[-0.95350796, -0.16792062]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -2.468436	array([[-0.94977814, -0.16138934]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = 0.244533	array([[1.0174512 , 0.57927287]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.611840	array([[0.9994411, 0.5983316]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.534783	array([[-0.97690356, -0.14746228]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -1.419881	array([[-0.9526404 , -0.17935213]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.773055	array([[-0.9534976 , -0.14956456]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.895378	array([[1.020482 , 0.5900695]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.939611	array([[0.9881904, 0.5958555]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 0.053216	array([[-0.9413118 , -0.12350785]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.981611	array([[-0.9281404 , -0.13532624]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.941212	array([[-0.91065896, -0.1364434 ]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -0.891427	array([[1.002965 , 0.5710634]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.572573	array([[0.97044504, 0.5881612 ]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.876981	array([[-0.9314986 , -0.11349407]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -1.169664	array([[-0.9044084 , -0.12397712]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -2.767375	array([[-0.922579  , -0.13121513]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.059995	array([[1.0029125, 0.5559779]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.419203	array([[0.9692894 , 0.57708603]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -1.918668	array([[-0.96898496, -0.12134786]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -2.396534	array([[-0.93570167, -0.12166689]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -3.346320	array([[-0.96451783, -0.11429971]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.393560	array([[0.9960294, 0.5803363]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -2.037986	array([[0.9812039 , 0.59287626]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.323420	array([[-0.9945855 , -0.14310697]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.712778	array([[-0.9475452 , -0.16584231]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.743212	array([[-0.92820376, -0.16971034]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.465246	array([[1.0319703 , 0.55555737]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.141184	array([[1.0130775, 0.5737023]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.258359	array([[-0.9599314 , -0.18704444]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -1.456049	array([[-0.9655982 , -0.16072686]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -2.046047	array([[-0.956505  , -0.15225118]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.516536	array([[1.03933  , 0.5732972]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.146977	array([[1.0228872 , 0.58206815]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.522485	array([[-0.9509927 , -0.17078361]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -1.302962	array([[-0.95490026, -0.17352721]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.932747	array([[-0.9739242 , -0.15997662]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.130556	array([[1.0401497, 0.5604199]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.300942	array([[1.0214461, 0.5732412]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2226ms
 Real time factor: 300.539
 UPS: 4521.114106
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 460 queries and explored 3.39 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 44811 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.183517	array([[-0.9785968 , -0.18495518]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.393973	array([[-0.95775914, -0.19937578]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -1.354490	array([[-0.94188815, -0.19330168]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.220252	array([[1.059515  , 0.55765843]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.510614	array([[1.0440385 , 0.58070403]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.939128	array([[-0.9569876 , -0.17713538]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.601425	array([[-0.9692025 , -0.15340483]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -1.634128	array([[-0.9572559 , -0.15144151]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.491899	array([[1.0245906, 0.5894611]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.151624	array([[1.0077106 , 0.59921527]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.558119	array([[-0.9420663 , -0.12443876]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -1.343938	array([[-0.9505171 , -0.14783682]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -2.600415	array([[-0.9188948 , -0.14398137]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -0.874263	array([[0.985568  , 0.58541805]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.930070	array([[0.9679656 , 0.60299873]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -1.596395	array([[-0.9789239, -0.1142027]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -1.617989	array([[-0.9525733 , -0.13170329]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -2.353553	array([[-0.950678  , -0.14069504]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -0.515094	array([[1.009331 , 0.5669268]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.892262	array([[0.98724926, 0.5819426 ]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.968028	array([[-1.0031953 , -0.14832202]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -1.563176	array([[-0.9797875 , -0.16093911]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -2.331855	array([[-0.9655907 , -0.15722029]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.947931	array([[1.0278327, 0.5873589]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -0.919976	array([[0.98714226, 0.60927963]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.420918	array([[-0.9686692 , -0.14178379]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 0.136938	array([[-0.9635395, -0.1559265]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -2.045577	array([[-0.95840514, -0.15554969]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.712433	array([[1.0093904, 0.5816644]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.698678	array([[1.0190605 , 0.56814253]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.022518	array([[-0.9878262, -0.1646603]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.109406	array([[-0.9795076 , -0.15605065]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -2.026198	array([[-0.959044 , -0.1747967]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.737719	array([[1.0361651 , 0.57951576]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:44811 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.062850	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.700355	array([[1.0599525, 0.566923 ]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -1.604073	array([[1.0460906 , 0.56634283]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.887003	array([[-0.9746271 , -0.17608705]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.564281	array([[-0.9782698 , -0.17801575]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.985911	array([[-0.966682  , -0.15401919]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.214064	array([[1.0316117 , 0.56680924]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.079915	array([[1.0056111, 0.5908176]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.379958	array([[-0.9332555 , -0.14782557]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.212051	array([[-0.94407886, -0.1506073 ]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.662442	array([[-0.96389264, -0.12211952]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.721835	array([[0.96641755, 0.5906266 ]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.862137	array([[0.9379138, 0.6063921]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.873256	array([[-0.94894725, -0.1135268 ]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.842350	array([[-0.903769  , -0.12688127]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -3.097361	array([[-0.89113426, -0.10757428]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.231526	array([[0.9704615, 0.5954067]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.655362	array([[0.9386593 , 0.60787565]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.932556	array([[-0.96805984, -0.08979902]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.289053	array([[-0.9216998 , -0.13024095]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.673172	array([[-0.8882945, -0.1350668]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.466230	array([[1.0037777, 0.5870342]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.901679	array([[0.9785979 , 0.60349035]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.651505	array([[-0.9566929 , -0.11070218]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.081846	array([[-0.962103  , -0.13587058]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.805376	array([[-0.94468594, -0.13989788]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.307591	array([[1.0258493 , 0.56545407]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.899653	array([[0.9809464, 0.5940021]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.308382	array([[-0.936112 , -0.1560443]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.957883	array([[-0.95350796, -0.16792062]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -2.468436	array([[-0.94977814, -0.16138934]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = 0.244533	array([[1.0174512 , 0.57927287]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.611840	array([[0.9994411, 0.5983316]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.534783	array([[-0.97690356, -0.14746228]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -1.419881	array([[-0.9526404 , -0.17935213]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.773055	array([[-0.9534976 , -0.14956456]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.895378	array([[1.020482 , 0.5900695]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.939611	array([[0.9881904, 0.5958555]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 0.053216	array([[-0.9413118 , -0.12350785]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.981611	array([[-0.9281404 , -0.13532624]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.941212	array([[-0.91065896, -0.1364434 ]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -0.891427	array([[1.002965 , 0.5710634]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.572573	array([[0.97044504, 0.5881612 ]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.876981	array([[-0.9314986 , -0.11349407]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -1.169664	array([[-0.9044084 , -0.12397712]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -2.767375	array([[-0.922579  , -0.13121513]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.059995	array([[1.0029125, 0.5559779]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.419203	array([[0.9692894 , 0.57708603]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -1.918668	array([[-0.96898496, -0.12134786]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -2.396534	array([[-0.93570167, -0.12166689]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -3.346320	array([[-0.96451783, -0.11429971]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.393560	array([[0.9960294, 0.5803363]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -2.037986	array([[0.9812039 , 0.59287626]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.323420	array([[-0.9945855 , -0.14310697]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.712778	array([[-0.9475452 , -0.16584231]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.743212	array([[-0.92820376, -0.16971034]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.465246	array([[1.0319703 , 0.55555737]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.141184	array([[1.0130775, 0.5737023]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.258359	array([[-0.9599314 , -0.18704444]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -1.456049	array([[-0.9655982 , -0.16072686]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -2.046047	array([[-0.956505  , -0.15225118]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.516536	array([[1.03933  , 0.5732972]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.146977	array([[1.0228872 , 0.58206815]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.522485	array([[-0.9509927 , -0.17078361]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -1.302962	array([[-0.95490026, -0.17352721]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.932747	array([[-0.9739242 , -0.15997662]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.130556	array([[1.0401497, 0.5604199]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.300942	array([[1.0214461, 0.5732412]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.183517	array([[-0.9785968 , -0.18495518]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.393973	array([[-0.95775914, -0.19937578]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -1.354490	array([[-0.94188815, -0.19330168]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.220252	array([[1.059515  , 0.55765843]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.510614	array([[1.0440385 , 0.58070403]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.939128	array([[-0.9569876 , -0.17713538]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.601425	array([[-0.9692025 , -0.15340483]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -1.634128	array([[-0.9572559 , -0.15144151]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.491899	array([[1.0245906, 0.5894611]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.151624	array([[1.0077106 , 0.59921527]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.558119	array([[-0.9420663 , -0.12443876]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -1.343938	array([[-0.9505171 , -0.14783682]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -2.600415	array([[-0.9188948 , -0.14398137]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -0.874263	array([[0.985568  , 0.58541805]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.930070	array([[0.9679656 , 0.60299873]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -1.596395	array([[-0.9789239, -0.1142027]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -1.617989	array([[-0.9525733 , -0.13170329]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -2.353553	array([[-0.950678  , -0.14069504]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -0.515094	array([[1.009331 , 0.5669268]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.892262	array([[0.98724926, 0.5819426 ]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.968028	array([[-1.0031953 , -0.14832202]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -1.563176	array([[-0.9797875 , -0.16093911]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -2.331855	array([[-0.9655907 , -0.15722029]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.947931	array([[1.0278327, 0.5873589]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -0.919976	array([[0.98714226, 0.60927963]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.420918	array([[-0.9686692 , -0.14178379]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 0.136938	array([[-0.9635395, -0.1559265]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -2.045577	array([[-0.95840514, -0.15554969]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2262ms
 Real time factor: 295.756
 UPS: 4449.160035
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 460 queries and explored 3.39 edges on average.
DijkstraRouter spent 1ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 59475 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (6ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.712433	array([[1.0093904, 0.5816644]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.698678	array([[1.0190605 , 0.56814253]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.022518	array([[-0.9878262, -0.1646603]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.109406	array([[-0.9795076 , -0.15605065]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -2.026198	array([[-0.959044 , -0.1747967]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.737719	array([[1.0361651 , 0.57951576]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:59475 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.062850	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.700355	array([[1.0599525, 0.566923 ]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -1.604073	array([[1.0460906 , 0.56634283]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.887003	array([[-0.9746271 , -0.17608705]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.564281	array([[-0.9782698 , -0.17801575]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.985911	array([[-0.966682  , -0.15401919]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.214064	array([[1.0316117 , 0.56680924]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.079915	array([[1.0056111, 0.5908176]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.379958	array([[-0.9332555 , -0.14782557]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.212051	array([[-0.94407886, -0.1506073 ]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.662442	array([[-0.96389264, -0.12211952]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.721835	array([[0.96641755, 0.5906266 ]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.862137	array([[0.9379138, 0.6063921]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.873256	array([[-0.94894725, -0.1135268 ]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.842350	array([[-0.903769  , -0.12688127]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -3.097361	array([[-0.89113426, -0.10757428]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.231526	array([[0.9704615, 0.5954067]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.655362	array([[0.9386593 , 0.60787565]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.932556	array([[-0.96805984, -0.08979902]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.289053	array([[-0.9216998 , -0.13024095]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.673172	array([[-0.8882945, -0.1350668]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.466230	array([[1.0037777, 0.5870342]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.901679	array([[0.9785979 , 0.60349035]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.651505	array([[-0.9566929 , -0.11070218]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.081846	array([[-0.962103  , -0.13587058]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.805376	array([[-0.94468594, -0.13989788]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.307591	array([[1.0258493 , 0.56545407]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.899653	array([[0.9809464, 0.5940021]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.308382	array([[-0.936112 , -0.1560443]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.957883	array([[-0.95350796, -0.16792062]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -2.468436	array([[-0.94977814, -0.16138934]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = 0.244533	array([[1.0174512 , 0.57927287]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.611840	array([[0.9994411, 0.5983316]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.534783	array([[-0.97690356, -0.14746228]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -1.419881	array([[-0.9526404 , -0.17935213]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.773055	array([[-0.9534976 , -0.14956456]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.895378	array([[1.020482 , 0.5900695]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.939611	array([[0.9881904, 0.5958555]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 0.053216	array([[-0.9413118 , -0.12350785]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.981611	array([[-0.9281404 , -0.13532624]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.941212	array([[-0.91065896, -0.1364434 ]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -0.891427	array([[1.002965 , 0.5710634]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.572573	array([[0.97044504, 0.5881612 ]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.876981	array([[-0.9314986 , -0.11349407]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -1.169664	array([[-0.9044084 , -0.12397712]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -2.767375	array([[-0.922579  , -0.13121513]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.059995	array([[1.0029125, 0.5559779]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.419203	array([[0.9692894 , 0.57708603]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -1.918668	array([[-0.96898496, -0.12134786]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -2.396534	array([[-0.93570167, -0.12166689]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -3.346320	array([[-0.96451783, -0.11429971]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.393560	array([[0.9960294, 0.5803363]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -2.037986	array([[0.9812039 , 0.59287626]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.323420	array([[-0.9945855 , -0.14310697]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.712778	array([[-0.9475452 , -0.16584231]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.743212	array([[-0.92820376, -0.16971034]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.465246	array([[1.0319703 , 0.55555737]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2258ms
 Real time factor: 296.28
 UPS: 4457.041630
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 460 queries and explored 3.39 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 47883 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (6ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.141184	array([[1.0130775, 0.5737023]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.258359	array([[-0.9599314 , -0.18704444]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -1.456049	array([[-0.9655982 , -0.16072686]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -2.046047	array([[-0.956505  , -0.15225118]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.516536	array([[1.03933  , 0.5732972]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.146977	array([[1.0228872 , 0.58206815]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.522485	array([[-0.9509927 , -0.17078361]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -1.302962	array([[-0.95490026, -0.17352721]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.932747	array([[-0.9739242 , -0.15997662]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.130556	array([[1.0401497, 0.5604199]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.300942	array([[1.0214461, 0.5732412]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.183517	array([[-0.9785968 , -0.18495518]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.393973	array([[-0.95775914, -0.19937578]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -1.354490	array([[-0.94188815, -0.19330168]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.220252	array([[1.059515  , 0.55765843]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.510614	array([[1.0440385 , 0.58070403]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.939128	array([[-0.9569876 , -0.17713538]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.601425	array([[-0.9692025 , -0.15340483]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -1.634128	array([[-0.9572559 , -0.15144151]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.491899	array([[1.0245906, 0.5894611]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.151624	array([[1.0077106 , 0.59921527]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.558119	array([[-0.9420663 , -0.12443876]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -1.343938	array([[-0.9505171 , -0.14783682]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -2.600415	array([[-0.9188948 , -0.14398137]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -0.874263	array([[0.985568  , 0.58541805]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.930070	array([[0.9679656 , 0.60299873]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -1.596395	array([[-0.9789239, -0.1142027]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -1.617989	array([[-0.9525733 , -0.13170329]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -2.353553	array([[-0.950678  , -0.14069504]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -0.515094	array([[1.009331 , 0.5669268]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.892262	array([[0.98724926, 0.5819426 ]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.968028	array([[-1.0031953 , -0.14832202]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -1.563176	array([[-0.9797875 , -0.16093911]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -2.331855	array([[-0.9655907 , -0.15722029]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.947931	array([[1.0278327, 0.5873589]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -0.919976	array([[0.98714226, 0.60927963]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.420918	array([[-0.9686692 , -0.14178379]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 0.136938	array([[-0.9635395, -0.1559265]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -2.045577	array([[-0.95840514, -0.15554969]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.712433	array([[1.0093904, 0.5816644]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.698678	array([[1.0190605 , 0.56814253]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.022518	array([[-0.9878262, -0.1646603]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.109406	array([[-0.9795076 , -0.15605065]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -2.026198	array([[-0.959044 , -0.1747967]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.737719	array([[1.0361651 , 0.57951576]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:47883 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.062850	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.700355	array([[1.0599525, 0.566923 ]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -1.604073	array([[1.0460906 , 0.56634283]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.887003	array([[-0.9746271 , -0.17608705]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.564281	array([[-0.9782698 , -0.17801575]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.985911	array([[-0.966682  , -0.15401919]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.214064	array([[1.0316117 , 0.56680924]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.079915	array([[1.0056111, 0.5908176]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.379958	array([[-0.9332555 , -0.14782557]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -2.212051	array([[-0.94407886, -0.1506073 ]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.662442	array([[-0.96389264, -0.12211952]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.721835	array([[0.96641755, 0.5906266 ]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.862137	array([[0.9379138, 0.6063921]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.873256	array([[-0.94894725, -0.1135268 ]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.842350	array([[-0.903769  , -0.12688127]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -3.097361	array([[-0.89113426, -0.10757428]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.231526	array([[0.9704615, 0.5954067]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.655362	array([[0.9386593 , 0.60787565]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.932556	array([[-0.96805984, -0.08979902]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.289053	array([[-0.9216998 , -0.13024095]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.673172	array([[-0.8882945, -0.1350668]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.466230	array([[1.0037777, 0.5870342]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.901679	array([[0.9785979 , 0.60349035]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.651505	array([[-0.9566929 , -0.11070218]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.081846	array([[-0.962103  , -0.13587058]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.805376	array([[-0.94468594, -0.13989788]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.307591	array([[1.0258493 , 0.56545407]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.899653	array([[0.9809464, 0.5940021]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.308382	array([[-0.936112 , -0.1560443]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.957883	array([[-0.95350796, -0.16792062]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -2.468436	array([[-0.94977814, -0.16138934]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = 0.244533	array([[1.0174512 , 0.57927287]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.611840	array([[0.9994411, 0.5983316]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.534783	array([[-0.97690356, -0.14746228]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -1.419881	array([[-0.9526404 , -0.17935213]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.773055	array([[-0.9534976 , -0.14956456]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.895378	array([[1.020482 , 0.5900695]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.939611	array([[0.9881904, 0.5958555]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 0.053216	array([[-0.9413118 , -0.12350785]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.981611	array([[-0.9281404 , -0.13532624]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.941212	array([[-0.91065896, -0.1364434 ]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -0.891427	array([[1.002965 , 0.5710634]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.572573	array([[0.97044504, 0.5881612 ]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.876981	array([[-0.9314986 , -0.11349407]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -1.169664	array([[-0.9044084 , -0.12397712]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -2.767375	array([[-0.922579  , -0.13121513]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.059995	array([[1.0029125, 0.5559779]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.419203	array([[0.9692894 , 0.57708603]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -1.918668	array([[-0.96898496, -0.12134786]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -2.396534	array([[-0.93570167, -0.12166689]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -3.346320	array([[-0.96451783, -0.11429971]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.393560	array([[0.9960294, 0.5803363]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -2.037986	array([[0.9812039 , 0.59287626]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.323420	array([[-0.9945855 , -0.14310697]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.712778	array([[-0.9475452 , -0.16584231]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.743212	array([[-0.92820376, -0.16971034]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.465246	array([[1.0319703 , 0.55555737]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.141184	array([[1.0130775, 0.5737023]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.258359	array([[-0.9599314 , -0.18704444]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -1.456049	array([[-0.9655982 , -0.16072686]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -2.046047	array([[-0.956505  , -0.15225118]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.516536	array([[1.03933  , 0.5732972]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.146977	array([[1.0228872 , 0.58206815]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.522485	array([[-0.9509927 , -0.17078361]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -1.302962	array([[-0.95490026, -0.17352721]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.932747	array([[-0.9739242 , -0.15997662]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.130556	array([[1.0401497, 0.5604199]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.300942	array([[1.0214461, 0.5732412]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.183517	array([[-0.9785968 , -0.18495518]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.393973	array([[-0.95775914, -0.19937578]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -1.354490	array([[-0.94188815, -0.19330168]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.220252	array([[1.059515  , 0.55765843]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.510614	array([[1.0440385 , 0.58070403]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.939128	array([[-0.9569876 , -0.17713538]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.601425	array([[-0.9692025 , -0.15340483]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -1.634128	array([[-0.9572559 , -0.15144151]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.491899	array([[1.0245906, 0.5894611]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.151624	array([[1.0077106 , 0.59921527]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.558119	array([[-0.9420663 , -0.12443876]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -1.343938	array([[-0.9505171 , -0.14783682]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -2.600415	array([[-0.9188948 , -0.14398137]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -0.874263	array([[0.985568  , 0.58541805]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.930070	array([[0.9679656 , 0.60299873]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -1.596395	array([[-0.9789239, -0.1142027]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -1.617989	array([[-0.9525733 , -0.13170329]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2275ms
 Real time factor: 294.066
 UPS: 4423.736264
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 460 queries and explored 3.39 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 47935 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -2.353553	array([[-0.950678  , -0.14069504]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -0.515094	array([[1.009331 , 0.5669268]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.892262	array([[0.98724926, 0.5819426 ]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.968028	array([[-1.0031953 , -0.14832202]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -1.563176	array([[-0.9797875 , -0.16093911]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -2.331855	array([[-0.9655907 , -0.15722029]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.947931	array([[1.0278327, 0.5873589]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -0.919976	array([[0.98714226, 0.60927963]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.420918	array([[-0.9686692 , -0.14178379]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 0.136938	array([[-0.9635395, -0.1559265]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -2.045577	array([[-0.95840514, -0.15554969]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.712433	array([[1.0093904, 0.5816644]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.698678	array([[1.0190605 , 0.56814253]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.022518	array([[-0.9878262, -0.1646603]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.109406	array([[-0.9795076 , -0.15605065]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -2.026198	array([[-0.959044 , -0.1747967]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.737719	array([[1.0361651 , 0.57951576]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:47935 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -0.619296	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 40	action = 1	current_phase = 0	next_phase = 1	reward = -1.897609	array([[-0.9542076 , -0.16660476]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -1.065417	array([[1.0505183 , 0.56242007]], dtype=float32)
time = 53	action = 1	current_phase = 1	next_phase = 0	reward = -1.938885	array([[1.014507 , 0.5784839]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.303795	array([[-0.9594916 , -0.17368269]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -1.194378	array([[-0.95840496, -0.16386126]], dtype=float32)
time = 71	action = 0	current_phase = 0	next_phase = 1	reward = -1.908283	array([[-0.94425106, -0.14991367]], dtype=float32)
time = 76	action = 1	current_phase = 0	next_phase = 1	reward = -1.819985	array([[-0.96815723, -0.13421485]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = 0.905740	array([[1.0324385, 0.5600534]], dtype=float32)
time = 89	action = 1	current_phase = 1	next_phase = 0	reward = -1.344118	array([[0.99733293, 0.59752667]], dtype=float32)
time = 97	action = 0	current_phase = 0	next_phase = 1	reward = -0.669165	array([[-0.9654049 , -0.12336343]], dtype=float32)
time = 102	action = 0	current_phase = 0	next_phase = 1	reward = -0.761386	array([[-0.9240983 , -0.14199066]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -1.148912	array([[-0.92567784, -0.13691556]], dtype=float32)
time = 112	action = 1	current_phase = 0	next_phase = 1	reward = -2.226307	array([[-0.914116  , -0.13984871]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = 0.438851	array([[1.0061624, 0.5692864]], dtype=float32)
time = 125	action = 1	current_phase = 1	next_phase = 0	reward = -1.755178	array([[0.96443164, 0.60037327]], dtype=float32)
time = 133	action = 0	current_phase = 0	next_phase = 1	reward = -0.847448	array([[-0.9570796, -0.0772469]], dtype=float32)
time = 138	action = 0	current_phase = 0	next_phase = 1	reward = -1.704191	array([[-0.9255921 , -0.11289863]], dtype=float32)
time = 143	action = 0	current_phase = 0	next_phase = 1	reward = -1.868586	array([[-0.9269494 , -0.11675015]], dtype=float32)
time = 148	action = 1	current_phase = 0	next_phase = 1	reward = -4.314300	array([[-0.9233949 , -0.11828225]], dtype=float32)
time = 156	action = 0	current_phase = 1	next_phase = 0	reward = -0.698763	array([[0.97269106, 0.57683384]], dtype=float32)
time = 161	action = 1	current_phase = 1	next_phase = 0	reward = -2.720003	array([[0.93028957, 0.60364765]], dtype=float32)
time = 169	action = 0	current_phase = 0	next_phase = 1	reward = -1.694838	array([[-0.9597538 , -0.10048388]], dtype=float32)
time = 174	action = 0	current_phase = 0	next_phase = 1	reward = -2.479516	array([[-0.90992767, -0.11949296]], dtype=float32)
time = 179	action = 0	current_phase = 0	next_phase = 1	reward = -2.769651	array([[-0.90936524, -0.13275541]], dtype=float32)
time = 184	action = 1	current_phase = 0	next_phase = 1	reward = -3.179933	array([[-0.9478097 , -0.12955093]], dtype=float32)
time = 192	action = 0	current_phase = 1	next_phase = 0	reward = -0.146003	array([[0.99756676, 0.57542646]], dtype=float32)
time = 197	action = 1	current_phase = 1	next_phase = 0	reward = -2.344087	array([[0.9884511 , 0.58832264]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -0.637521	array([[-0.93922347, -0.14389625]], dtype=float32)
time = 210	action = 0	current_phase = 0	next_phase = 1	reward = -2.048113	array([[-0.9073961 , -0.18398604]], dtype=float32)
time = 215	action = 0	current_phase = 0	next_phase = 1	reward = -2.488735	array([[-0.9268266 , -0.14996576]], dtype=float32)
time = 220	action = 1	current_phase = 0	next_phase = 1	reward = -3.319396	array([[-0.94903064, -0.14295915]], dtype=float32)
time = 228	action = 0	current_phase = 1	next_phase = 0	reward = 0.291201	array([[1.012421  , 0.57310855]], dtype=float32)
time = 233	action = 1	current_phase = 1	next_phase = 0	reward = -1.618413	array([[0.97268087, 0.6059248 ]], dtype=float32)
time = 241	action = 0	current_phase = 0	next_phase = 1	reward = -1.289932	array([[-0.96559626, -0.14608651]], dtype=float32)
time = 246	action = 0	current_phase = 0	next_phase = 1	reward = -1.692851	array([[-0.93763685, -0.16624147]], dtype=float32)
time = 251	action = 0	current_phase = 0	next_phase = 1	reward = -1.985974	array([[-0.93769854, -0.15098026]], dtype=float32)
time = 256	action = 1	current_phase = 0	next_phase = 1	reward = -2.596941	array([[-0.9640266 , -0.12201642]], dtype=float32)
time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -0.370225	array([[1.0078992 , 0.57552254]], dtype=float32)
time = 269	action = 1	current_phase = 1	next_phase = 0	reward = -1.052614	array([[0.97464633, 0.6057832 ]], dtype=float32)
time = 277	action = 0	current_phase = 0	next_phase = 1	reward = 0.436523	array([[-0.9844354 , -0.12030577]], dtype=float32)
time = 282	action = 0	current_phase = 0	next_phase = 1	reward = -0.580155	array([[-0.9391693 , -0.14098157]], dtype=float32)
time = 287	action = 0	current_phase = 0	next_phase = 1	reward = -0.114450	array([[-0.9160868 , -0.15522073]], dtype=float32)
time = 292	action = 1	current_phase = 0	next_phase = 1	reward = -1.481578	array([[-0.9219645 , -0.15096149]], dtype=float32)
time = 300	action = 0	current_phase = 1	next_phase = 0	reward = -0.199086	array([[0.99378467, 0.5864732 ]], dtype=float32)
time = 305	action = 1	current_phase = 1	next_phase = 0	reward = -1.232714	array([[0.9760256, 0.5966535]], dtype=float32)Simulation ended at time: 674.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2300ms
 Real time factor: 293.043
 UPS: 4412.173913
Vehicles: 
 Inserted: 259 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 472 queries and explored 3.22 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 43697 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (1ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 313	action = 0	current_phase = 0	next_phase = 1	reward = -0.665669	array([[-0.9804613 , -0.11910447]], dtype=float32)
time = 318	action = 0	current_phase = 0	next_phase = 1	reward = -1.318437	array([[-0.9347987, -0.1460003]], dtype=float32)
time = 323	action = 0	current_phase = 0	next_phase = 1	reward = -1.248970	array([[-0.92806476, -0.14726833]], dtype=float32)
time = 328	action = 1	current_phase = 0	next_phase = 1	reward = -2.366568	array([[-0.90603244, -0.15516497]], dtype=float32)
time = 336	action = 0	current_phase = 1	next_phase = 0	reward = 0.528270	array([[1.0076077 , 0.57229125]], dtype=float32)
time = 341	action = 1	current_phase = 1	next_phase = 0	reward = -2.036276	array([[0.98691237, 0.5861113 ]], dtype=float32)
time = 349	action = 0	current_phase = 0	next_phase = 1	reward = -1.283380	array([[-0.96531385, -0.12264487]], dtype=float32)
time = 354	action = 0	current_phase = 0	next_phase = 1	reward = -1.260331	array([[-0.93472415, -0.15214717]], dtype=float32)
time = 359	action = 0	current_phase = 0	next_phase = 1	reward = -1.826250	array([[-0.93406445, -0.15416366]], dtype=float32)
time = 364	action = 1	current_phase = 0	next_phase = 1	reward = -2.345477	array([[-0.9416187 , -0.15966812]], dtype=float32)
time = 372	action = 0	current_phase = 1	next_phase = 0	reward = -0.170650	array([[1.0231925, 0.5698714]], dtype=float32)
time = 377	action = 1	current_phase = 1	next_phase = 0	reward = -1.246395	array([[0.9753118, 0.5996175]], dtype=float32)
time = 385	action = 0	current_phase = 0	next_phase = 1	reward = -0.893480	array([[-0.96512264, -0.1528163 ]], dtype=float32)
time = 390	action = 0	current_phase = 0	next_phase = 1	reward = -1.471184	array([[-0.95291346, -0.16640896]], dtype=float32)
time = 395	action = 0	current_phase = 0	next_phase = 1	reward = -1.678937	array([[-0.9519497 , -0.16854925]], dtype=float32)
time = 400	action = 1	current_phase = 0	next_phase = 1	reward = -2.291212	array([[-0.9553368 , -0.16048566]], dtype=float32)
time = 408	action = 0	current_phase = 1	next_phase = 0	reward = 0.293431	array([[1.0161529 , 0.57556766]], dtype=float32)
time = 413	action = 1	current_phase = 1	next_phase = 0	reward = -1.660285	array([[0.99077773, 0.60119635]], dtype=float32)
time = 421	action = 0	current_phase = 0	next_phase = 1	reward = -0.835133	array([[-0.9903211, -0.1689904]], dtype=float32)
time = 426	action = 0	current_phase = 0	next_phase = 1	reward = -1.048008	array([[-0.9595278, -0.1759557]], dtype=float32)
time = 431	action = 0	current_phase = 0	next_phase = 1	reward = -1.699468	array([[-0.9689772 , -0.17617396]], dtype=float32)
time = 436	action = 1	current_phase = 0	next_phase = 1	reward = -2.000130	array([[-0.9763214 , -0.15455905]], dtype=float32)
time = 444	action = 0	current_phase = 1	next_phase = 0	reward = 0.074281	array([[1.0301921, 0.5681766]], dtype=float32)
time = 449	action = 1	current_phase = 1	next_phase = 0	reward = -0.998485	array([[0.9824483 , 0.59028834]], dtype=float32)
time = 457	action = 0	current_phase = 0	next_phase = 1	reward = 0.054689	array([[-0.965782  , -0.18217903]], dtype=float32)
time = 462	action = 0	current_phase = 0	next_phase = 1	reward = -0.258841	array([[-0.9484338, -0.2078276]], dtype=float32)
time = 467	action = 0	current_phase = 0	next_phase = 1	reward = -1.007243	array([[-0.9514095 , -0.18654542]], dtype=float32)
time = 472	action = 1	current_phase = 0	next_phase = 1	reward = -1.726984	array([[-0.97298205, -0.18727991]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -0.095228	array([[1.0542293 , 0.56512535]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -1.239773	array([[1.0271361, 0.5945997]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -0.123639	array([[-0.93227595, -0.15310745]], dtype=float32)
time = 498	action = 0	current_phase = 0	next_phase = 1	reward = -0.430497	array([[-0.933109 , -0.1705433]], dtype=float32)
time = 503	action = 0	current_phase = 0	next_phase = 1	reward = -1.290912	array([[-0.9546903 , -0.15443997]], dtype=float32)
time = 508	action = 1	current_phase = 0	next_phase = 1	reward = -1.928724	array([[-0.96011305, -0.12986498]], dtype=float32)
time = 516	action = 0	current_phase = 1	next_phase = 0	reward = -0.735935	array([[0.9908556, 0.5946367]], dtype=float32)
time = 521	action = 1	current_phase = 1	next_phase = 0	reward = -1.482967	array([[0.9841244 , 0.59279233]], dtype=float32)
time = 529	action = 0	current_phase = 0	next_phase = 1	reward = -0.100159	array([[-0.9506768 , -0.13739058]], dtype=float32)
time = 534	action = 0	current_phase = 0	next_phase = 1	reward = -0.905063	array([[-0.91362816, -0.15590602]], dtype=float32)
time = 539	action = 0	current_phase = 0	next_phase = 1	reward = -1.546540	array([[-0.9049535 , -0.16163737]], dtype=float32)
time = 544	action = 1	current_phase = 0	next_phase = 1	reward = -1.898898	array([[-0.9266848, -0.1412594]], dtype=float32)
time = 552	action = 0	current_phase = 1	next_phase = 0	reward = 0.163909	array([[1.0060008, 0.592757 ]], dtype=float32)
time = 557	action = 1	current_phase = 1	next_phase = 0	reward = -1.624222	array([[0.9830914 , 0.60312384]], dtype=float32)
time = 565	action = 0	current_phase = 0	next_phase = 1	reward = -0.657122	array([[-0.9502561 , -0.12440009]], dtype=float32)
time = 570	action = 0	current_phase = 0	next_phase = 1	reward = -1.160830	array([[-0.9266071 , -0.16545017]], dtype=float32)
time = 575	action = 0	current_phase = 0	next_phase = 1	reward = -2.007170	array([[-0.9344143 , -0.15727645]], dtype=float32)
time = 580	action = 1	current_phase = 0	next_phase = 1	reward = -2.923991	array([[-0.951557  , -0.14587846]], dtype=float32)
time = 588	action = 0	current_phase = 1	next_phase = 0	reward = -0.200296	array([[0.99872077, 0.58221453]], dtype=float32)
time = 593	action = 1	current_phase = 1	next_phase = 0	reward = -1.130983	array([[0.9815273, 0.5933925]], dtype=float32)
time = 601	action = 0	current_phase = 0	next_phase = 1	reward = -0.904061	array([[-0.97644913, -0.12985505]], dtype=float32)
time = 606	action = 0	current_phase = 0	next_phase = 1	reward = -0.890813	array([[-0.94685507, -0.14373821]], dtype=float32)
time = 611	action = 0	current_phase = 0	next_phase = 1	reward = -1.039701	array([[-0.9416824 , -0.14012468]], dtype=float32)
time = 616	action = 1	current_phase = 0	next_phase = 1	reward = -1.891106	array([[-0.980121  , -0.15197656]], dtype=float32)
time = 624	action = 0	current_phase = 1	next_phase = 0	reward = -0.344362	array([[1.0022122, 0.5709685]], dtype=float32)
time = 629	action = 1	current_phase = 1	next_phase = 0	reward = -1.168404	array([[0.99254733, 0.5866661 ]], dtype=float32)
time = 637	action = 0	current_phase = 0	next_phase = 1	reward = 0.382078	array([[-0.9867462 , -0.15735614]], dtype=float32)
time = 642	action = 0	current_phase = 0	next_phase = 1	reward = -0.711861	array([[-0.96391225, -0.18756859]], dtype=float32)
time = 647	action = 0	current_phase = 0	next_phase = 1	reward = -1.009996	array([[-0.97116905, -0.16237271]], dtype=float32)
time = 652	action = 1	current_phase = 0	next_phase = 1	reward = -1.905930	array([[-0.9751793, -0.1716026]], dtype=float32)
time = 660	action = 0	current_phase = 1	next_phase = 0	reward = -0.374460	array([[1.0173631, 0.5741918]], dtype=float32)
time = 665	action = 1	current_phase = 1	next_phase = 0	reward = -1.233168	array([[0.9890403, 0.5915079]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:43697 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -0.223894	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -0.619296	array([[-0.9725909 , -0.15537712]], dtype=float32)
time = 40	action = 0	current_phase = 0	next_phase = 1	reward = -0.532205	array([[-0.9542076 , -0.16660476]], dtype=float32)
time = 45	action = 1	current_phase = 0	next_phase = 1	reward = -2.186602	array([[-0.96046305, -0.17138572]], dtype=float32)
time = 53	action = 0	current_phase = 1	next_phase = 0	reward = -0.980823	array([[1.0101825 , 0.57813996]], dtype=float32)
time = 58	action = 1	current_phase = 1	next_phase = 0	reward = -1.490829	array([[1.0157781, 0.5780937]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -0.482468	array([[-0.9617208 , -0.16286236]], dtype=float32)
time = 71	action = 0	current_phase = 0	next_phase = 1	reward = -1.431129	array([[-0.94427896, -0.16756925]], dtype=float32)
time = 76	action = 0	current_phase = 0	next_phase = 1	reward = -1.365787	array([[-0.948204  , -0.15072191]], dtype=float32)
time = 81	action = 0	current_phase = 0	next_phase = 1	reward = -1.999956	array([[-0.94617945, -0.14853701]], dtype=float32)
time = 86	action = 1	current_phase = 0	next_phase = 1	reward = -2.869992	array([[-0.9565499 , -0.13392346]], dtype=float32)
time = 94	action = 0	current_phase = 1	next_phase = 0	reward = 0.237719	array([[0.99067664, 0.5783307 ]], dtype=float32)
time = 99	action = 1	current_phase = 1	next_phase = 0	reward = -1.443854	array([[0.9705504 , 0.60248846]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -0.854192	array([[-0.91723514, -0.12391463]], dtype=float32)
time = 112	action = 0	current_phase = 0	next_phase = 1	reward = -1.718811	array([[-0.8996801 , -0.15317887]], dtype=float32)
time = 117	action = 0	current_phase = 0	next_phase = 1	reward = -2.229265	array([[-0.8876721 , -0.12606144]], dtype=float32)
time = 122	action = 0	current_phase = 0	next_phase = 1	reward = -2.666207	array([[-0.89215004, -0.1085209 ]], dtype=float32)
time = 127	action = 1	current_phase = 0	next_phase = 1	reward = -3.979487	array([[-0.90595084, -0.09417126]], dtype=float32)
time = 135	action = 0	current_phase = 1	next_phase = 0	reward = -0.859396	array([[0.95529544, 0.5980736 ]], dtype=float32)
time = 140	action = 1	current_phase = 1	next_phase = 0	reward = -2.008768	array([[0.91860396, 0.60550606]], dtype=float32)
time = 148	action = 0	current_phase = 0	next_phase = 1	reward = -1.465069	array([[-0.9345187 , -0.08204646]], dtype=float32)
time = 153	action = 0	current_phase = 0	next_phase = 1	reward = -2.169342	array([[-0.88610685, -0.11685602]], dtype=float32)
time = 158	action = 0	current_phase = 0	next_phase = 1	reward = -2.888981	array([[-0.8642335 , -0.12325042]], dtype=float32)
time = 163	action = 0	current_phase = 0	next_phase = 1	reward = -3.423289	array([[-0.8801642 , -0.10353994]], dtype=float32)
time = 168	action = 1	current_phase = 0	next_phase = 1	reward = -5.518797	array([[-0.90300214, -0.11596999]], dtype=float32)
time = 176	action = 0	current_phase = 1	next_phase = 0	reward = -0.691302	array([[0.9720107 , 0.59436613]], dtype=float32)
time = 181	action = 1	current_phase = 1	next_phase = 0	reward = -1.805512	array([[0.9586817 , 0.61808646]], dtype=float32)
time = 189	action = 0	current_phase = 0	next_phase = 1	reward = -1.573209	array([[-0.92835844, -0.09538998]], dtype=float32)
time = 194	action = 0	current_phase = 0	next_phase = 1	reward = -2.397253	array([[-0.9049271 , -0.12221847]], dtype=float32)
time = 199	action = 0	current_phase = 0	next_phase = 1	reward = -2.721609	array([[-0.89674884, -0.13714188]], dtype=float32)
time = 204	action = 0	current_phase = 0	next_phase = 1	reward = -3.050415	array([[-0.8998193 , -0.13365623]], dtype=float32)
time = 209	action = 1	current_phase = 0	next_phase = 1	reward = -4.642990	array([[-0.905792  , -0.13969302]], dtype=float32)
time = 217	action = 0	current_phase = 1	next_phase = 0	reward = -0.093850	array([[0.9939205, 0.5598273]], dtype=float32)
time = 222	action = 1	current_phase = 1	next_phase = 0	reward = -1.812393	array([[0.9569089, 0.5926905]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = -1.710074	array([[-0.9252536 , -0.10512695]], dtype=float32)
time = 235	action = 0	current_phase = 0	next_phase = 1	reward = -2.675754	array([[-0.9312317 , -0.11973497]], dtype=float32)
time = 240	action = 0	current_phase = 0	next_phase = 1	reward = -2.796450	array([[-0.92586696, -0.12661213]], dtype=float32)
time = 245	action = 0	current_phase = 0	next_phase = 1	reward = -4.000630	array([[-0.9327862 , -0.14095704]], dtype=float32)
time = 250	action = 1	current_phase = 0	next_phase = 1	reward = -4.585669	array([[-0.928723 , -0.1277704]], dtype=float32)
time = 258	action = 0	current_phase = 1	next_phase = 0	reward = 0.153852	array([[0.9768792, 0.5961895]], dtype=float32)
time = 263	action = 1	current_phase = 1	next_phase = 0	reward = -2.185923	array([[0.95562327, 0.6084965 ]], dtype=float32)
time = 271	action = 0	current_phase = 0	next_phase = 1	reward = -0.460633	array([[-0.9191451 , -0.08866761]], dtype=float32)
time = 276	action = 0	current_phase = 0	next_phase = 1	reward = -2.074462	array([[-0.8966198 , -0.13435084]], dtype=float32)
time = 281	action = 0	current_phase = 0	next_phase = 1	reward = -2.364247	array([[-0.87992895, -0.10912093]], dtype=float32)
time = 286	action = 0	current_phase = 0	next_phase = 1	reward = -2.269857	array([[-0.8844454 , -0.11845737]], dtype=float32)
time = 291	action = 1	current_phase = 0	next_phase = 1	reward = -3.982931	array([[-0.8923804 , -0.12046682]], dtype=float32)
time = 299	action = 0	current_phase = 1	next_phase = 0	reward = 0.001150	array([[0.95008427, 0.5915207 ]], dtype=float32)
time = 304	action = 1	current_phase = 1	next_phase = 0	reward = -2.005830	array([[0.9334813, 0.6047112]], dtype=float32)
time = 312	action = 0	current_phase = 0	next_phase = 1	reward = -1.217379	array([[-0.9391651 , -0.08043521]], dtype=float32)
time = 317	action = 0	current_phase = 0	next_phase = 1	reward = -2.667743	array([[-0.9016497 , -0.11576634]], dtype=float32)
time = 322	action = 0	current_phase = 0	next_phase = 1	reward = -2.907082	array([[-0.8919397 , -0.12718946]], dtype=float32)
time = 327	action = 0	current_phase = 0	next_phase = 1	reward = -3.736778	array([[-0.88346845, -0.13223769]], dtype=float32)
time = 332	action = 1	current_phase = 0	next_phase = 1	reward = -5.735027	array([[-0.8896415, -0.1205712]], dtype=float32)
time = 340	action = 0	current_phase = 1	next_phase = 0	reward = -0.702996	array([[0.95437163, 0.58216345]], dtype=float32)
time = 345	action = 1	current_phase = 1	next_phase = 0	reward = -2.059595	array([[0.9474367 , 0.59722954]], dtype=float32)
time = 353	action = 0	current_phase = 0	next_phase = 1	reward = -1.186180	array([[-0.94415617, -0.09760118]], dtype=float32)
time = 358	action = 0	current_phase = 0	next_phase = 1	reward = -2.505630	array([[-0.9032059 , -0.11207261]], dtype=float32)
time = 363	action = 0	current_phase = 0	next_phase = 1	reward = -2.657877	array([[-0.9032569 , -0.12196133]], dtype=float32)
time = 368	action = 0	current_phase = 0	next_phase = 1	reward = -3.110671	array([[-0.8998438 , -0.13528365]], dtype=float32)
time = 373	action = 1	current_phase = 0	next_phase = 1	reward = -4.006766	array([[-0.91068894, -0.13350928]], dtype=float32)
time = 381	action = 0	current_phase = 1	next_phase = 0	reward = 0.025113	array([[0.9912949, 0.5694617]], dtype=float32)
time = 386	action = 1	current_phase = 1	next_phase = 0	reward = -2.231580	array([[0.98061836, 0.57774293]], dtype=float32)
time = 394	action = 0	current_phase = 0	next_phase = 1	reward = -2.011335	array([[-0.9269499, -0.1406146]], dtype=float32)
time = 399	action = 0	current_phase = 0	next_phase = 1	reward = -2.845401	array([[-0.8980179 , -0.14742556]], dtype=float32)
time = 404	action = 0	current_phase = 0	next_phase = 1	reward = -3.571859	array([[-0.9176129 , -0.13212696]], dtype=float32)
time = 409	action = 0	current_phase = 0	next_phase = 1	reward = -3.739816	array([[-0.9233936 , -0.11929714]], dtype=float32)
time = 414	action = 1	current_phase = 0	next_phase = 1	reward = -4.857241	array([[-0.947457  , -0.11517038]], dtype=float32)
time = 422	action = 0	current_phase = 1	next_phase = 0	reward = 0.182427	array([[1.0172591 , 0.54811203]], dtype=float32)
time = 427	action = 1	current_phase = 1	next_phase = 0	reward = -1.727460	array([[0.9716501, 0.5933599]], dtype=float32)
time = 435	action = 0	current_phase = 0	next_phase = 1	reward = -1.640097	array([[-0.9568537 , -0.12173417]], dtype=float32)
time = 440	action = 0	current_phase = 0	next_phase = 1	reward = -2.453869	array([[-0.93556863, -0.14605644]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2481ms
 Real time factor: 269.649
 UPS: 4756.549778
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 406 queries and explored 3.28 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 57997 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 445	action = 0	current_phase = 0	next_phase = 1	reward = -2.803182	array([[-0.944046 , -0.1376768]], dtype=float32)
time = 450	action = 0	current_phase = 0	next_phase = 1	reward = -2.869929	array([[-0.96979725, -0.13403502]], dtype=float32)
time = 455	action = 1	current_phase = 0	next_phase = 1	reward = -3.612430	array([[-0.9730495 , -0.14602172]], dtype=float32)
time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -0.068148	array([[1.0039482, 0.5545615]], dtype=float32)
time = 468	action = 1	current_phase = 1	next_phase = 0	reward = -1.886643	array([[0.98003775, 0.5821807 ]], dtype=float32)
time = 476	action = 0	current_phase = 0	next_phase = 1	reward = -0.943841	array([[-0.9831843 , -0.15508835]], dtype=float32)
time = 481	action = 0	current_phase = 0	next_phase = 1	reward = -1.862117	array([[-0.9364276 , -0.16289777]], dtype=float32)
time = 486	action = 0	current_phase = 0	next_phase = 1	reward = -2.094810	array([[-0.94855845, -0.14305308]], dtype=float32)
time = 491	action = 0	current_phase = 0	next_phase = 1	reward = -2.177476	array([[-0.9517276 , -0.14846253]], dtype=float32)
time = 496	action = 1	current_phase = 0	next_phase = 1	reward = -3.063607	array([[-0.9781977 , -0.14080426]], dtype=float32)
time = 504	action = 0	current_phase = 1	next_phase = 0	reward = 0.077117	array([[1.0270478, 0.5761902]], dtype=float32)
time = 509	action = 1	current_phase = 1	next_phase = 0	reward = -1.986546	array([[0.97332895, 0.6180862 ]], dtype=float32)
time = 517	action = 0	current_phase = 0	next_phase = 1	reward = -0.648995	array([[-0.99088883, -0.11861207]], dtype=float32)
time = 522	action = 0	current_phase = 0	next_phase = 1	reward = -1.016919	array([[-0.97029305, -0.14193127]], dtype=float32)
time = 527	action = 0	current_phase = 0	next_phase = 1	reward = -1.512462	array([[-0.95710796, -0.16653466]], dtype=float32)
time = 532	action = 0	current_phase = 0	next_phase = 1	reward = -1.459612	array([[-0.92807055, -0.1474743 ]], dtype=float32)
time = 537	action = 1	current_phase = 0	next_phase = 1	reward = -1.419126	array([[-0.91537964, -0.14715439]], dtype=float32)
time = 545	action = 0	current_phase = 1	next_phase = 0	reward = 0.363935	array([[1.0315378, 0.5752774]], dtype=float32)
time = 550	action = 1	current_phase = 1	next_phase = 0	reward = -1.831974	array([[1.0100223, 0.5919739]], dtype=float32)
time = 558	action = 0	current_phase = 0	next_phase = 1	reward = -0.721548	array([[-0.9736557 , -0.10899168]], dtype=float32)
time = 563	action = 0	current_phase = 0	next_phase = 1	reward = -1.234479	array([[-0.9596805, -0.1494106]], dtype=float32)
time = 568	action = 0	current_phase = 0	next_phase = 1	reward = -1.746828	array([[-0.9652403, -0.1508864]], dtype=float32)
time = 573	action = 0	current_phase = 0	next_phase = 1	reward = -1.801722	array([[-0.94696075, -0.14144239]], dtype=float32)
time = 578	action = 1	current_phase = 0	next_phase = 1	reward = -3.024748	array([[-0.9705158 , -0.15760507]], dtype=float32)
time = 586	action = 0	current_phase = 1	next_phase = 0	reward = 0.028799	array([[1.0053656, 0.5780989]], dtype=float32)
time = 591	action = 1	current_phase = 1	next_phase = 0	reward = -1.262654	array([[0.97432774, 0.6005615 ]], dtype=float32)
time = 599	action = 0	current_phase = 0	next_phase = 1	reward = -0.574974	array([[-0.97085446, -0.13750702]], dtype=float32)
time = 604	action = 0	current_phase = 0	next_phase = 1	reward = -1.092675	array([[-0.93963754, -0.15008086]], dtype=float32)
time = 609	action = 0	current_phase = 0	next_phase = 1	reward = -0.993680	array([[-0.93760884, -0.13087676]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -1.228252	array([[-0.9708143 , -0.14317322]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.946678	array([[-0.9762876 , -0.14851227]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.540125	array([[1.0163221 , 0.57088035]], dtype=float32)
time = 632	action = 1	current_phase = 1	next_phase = 0	reward = -0.780356	array([[1.0001268 , 0.58550507]], dtype=float32)
time = 640	action = 0	current_phase = 0	next_phase = 1	reward = -0.205290	array([[-0.9889432 , -0.16936013]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.223891	array([[-0.96172535, -0.17554286]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = -1.204564	array([[-0.9729392 , -0.15276554]], dtype=float32)
time = 655	action = 0	current_phase = 0	next_phase = 1	reward = -1.779215	array([[-0.9770183, -0.1615885]], dtype=float32)
time = 660	action = 1	current_phase = 0	next_phase = 1	reward = -2.458546	array([[-1.0105659 , -0.15657863]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:57997 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.154288	array([[1.0186824, 0.5857945]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.671490	array([[-0.9665299 , -0.16870281]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -1.575596	array([[-0.9743375 , -0.18299115]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.055419	array([[1.038988 , 0.5620096]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.237352	array([[1.0247917, 0.5804895]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.016446	array([[1.0266252 , 0.58742684]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.443110	array([[-0.93261683, -0.14644809]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.012227	array([[-0.96724576, -0.12643695]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.215970	array([[0.9896348 , 0.58204395]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.283480	array([[0.9522838 , 0.60149616]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.040891	array([[0.9523947, 0.608362 ]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.977593	array([[-0.9307659, -0.1208716]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.883918	array([[-0.9117373 , -0.13243294]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = 0.286657	array([[0.997843 , 0.5845383]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.582469	array([[0.9639263 , 0.60724354]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.463147	array([[0.93206966, 0.6148259 ]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.670579	array([[-0.9605349, -0.1144904]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -2.175688	array([[-0.9312997 , -0.14776543]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.500865	array([[1.0043056 , 0.57488203]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.869957	array([[0.99170566, 0.596291  ]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.565694	array([[0.97493887, 0.6129831 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.598299	array([[-0.9549776 , -0.13879357]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -2.046704	array([[-0.97632277, -0.1564456 ]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.903490	array([[1.0148947 , 0.57730097]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.206850	array([[1.0178757 , 0.58762157]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -2.385158	array([[1.0291884 , 0.58050954]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.924469	array([[-0.92429096, -0.14293228]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.927054	array([[-0.9781265 , -0.15951791]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = 0.524192	array([[1.0483445 , 0.55052745]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.141082	array([[1.0072646, 0.5962632]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.153674	array([[1.002711  , 0.60035646]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.351354	array([[-0.99024737, -0.14973105]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.521358	array([[-0.97443014, -0.178325  ]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.269246	array([[1.0534906, 0.5724657]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.910557	array([[1.032094 , 0.5896538]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.851775	array([[1.0076883, 0.5870092]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.217784	array([[-0.9448881 , -0.11792953]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -2.115930	array([[-0.928639  , -0.12537992]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -1.184492	array([[1.0177798, 0.5721651]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -1.533233	array([[0.95663756, 0.5994168 ]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.712496	array([[0.9500864 , 0.60278124]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.307295	array([[-0.93763655, -0.11037044]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -2.443216	array([[-0.9032067 , -0.13576388]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.424342	array([[0.991735 , 0.5641668]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -0.754622	array([[0.9675661, 0.5851645]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -2.045729	array([[0.9401987, 0.5985634]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.748921	array([[-0.99016863, -0.14691934]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.629664	array([[-0.9520756, -0.1451788]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.422136	array([[1.0153811, 0.5775811]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.044042	array([[1.0120432 , 0.58710116]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.363074	array([[1.0026907 , 0.58526385]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.030510	array([[-0.96487   , -0.15574525]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.927751	array([[-0.9469114 , -0.17888647]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.907515	array([[1.0352211, 0.5634943]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -1.311643	array([[1.0201592, 0.5715707]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.384423	array([[1.0132005 , 0.57394946]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.151676	array([[-0.98204005, -0.17403717]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.783955	array([[-0.94778   , -0.17380527]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -0.407497	array([[1.0258694, 0.5744817]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -1.042190	array([[1.0056291 , 0.59481853]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.679479	array([[1.0105898, 0.5874685]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.325726	array([[-0.9789344 , -0.16462117]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.194196	array([[-0.95090306, -0.17209628]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -0.631407	array([[1.0489587 , 0.56619173]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.533807	array([[1.0001627, 0.5841137]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.511808	array([[1.0043209, 0.584891 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.211420	array([[-0.9983081 , -0.18220231]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.370356	array([[-0.95675975, -0.19167879]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -0.164275	array([[1.0373532, 0.5620906]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.063042	array([[1.0653077, 0.5606356]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.404625	array([[1.0539479, 0.5774778]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.880935	array([[-0.96996254, -0.1737552 ]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.895481	array([[-0.961079  , -0.15615302]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -0.660003	array([[1.0390666, 0.5782738]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.752343	array([[1.015147 , 0.6019701]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.357758	array([[1.0009956, 0.6023215]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.495662	array([[-0.9922424 , -0.10726675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -2.757643	array([[-0.95147586, -0.14306787]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -1.300101	array([[0.99538374, 0.56759804]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.893400	array([[0.95338076, 0.6020456 ]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.799074	array([[0.965493  , 0.60511327]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.934318	array([[-0.964518  , -0.13962105]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -2.074900	array([[-0.96281403, -0.13520518]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -1.335287	array([[1.0176188, 0.5740967]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.524769	array([[0.9879667, 0.5937983]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -2.468569	array([[0.9814966 , 0.59268284]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.646649	array([[-0.9905778, -0.1435135]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -1.282693	array([[-0.96777093, -0.17546725]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -0.104404	array([[1.0604949 , 0.56527436]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.829113	array([[1.0173751 , 0.59880525]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2169ms
 Real time factor: 308.437
 UPS: 4446.749654
Vehicles: 
 Inserted: 257 (Loaded: 313)
 Running: 15
 Waiting: 2

DijkstraRouter answered 440 queries and explored 3.41 edges on average.
DijkstraRouter spent 1ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 46171 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.668408	array([[1.0063326, 0.6073818]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.063598	array([[-0.9523895 , -0.13429481]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.356038	array([[-0.9572207 , -0.14993215]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.340797	array([[1.0436794 , 0.55491024]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.282400	array([[1.0298508 , 0.57055926]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.546743	array([[1.0177245 , 0.57545775]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.244718	array([[-0.972192  , -0.17120421]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.882899	array([[-0.98493993, -0.15153742]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.051064	array([[1.0154796, 0.5780237]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.688491	array([[0.9954733, 0.5916623]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:46171 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.154288	array([[1.0186824, 0.5857945]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.671490	array([[-0.9665299 , -0.16870281]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -1.575596	array([[-0.9743375 , -0.18299115]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.055419	array([[1.038988 , 0.5620096]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.237352	array([[1.0247917, 0.5804895]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.016446	array([[1.0266252 , 0.58742684]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.443110	array([[-0.93261683, -0.14644809]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.012227	array([[-0.96724576, -0.12643695]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.215970	array([[0.9896348 , 0.58204395]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.283480	array([[0.9522838 , 0.60149616]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.040891	array([[0.9523947, 0.608362 ]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.977593	array([[-0.9307659, -0.1208716]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.883918	array([[-0.9117373 , -0.13243294]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = 0.286657	array([[0.997843 , 0.5845383]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.582469	array([[0.9639263 , 0.60724354]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.463147	array([[0.93206966, 0.6148259 ]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.670579	array([[-0.9605349, -0.1144904]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -2.175688	array([[-0.9312997 , -0.14776543]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.500865	array([[1.0043056 , 0.57488203]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.869957	array([[0.99170566, 0.596291  ]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.565694	array([[0.97493887, 0.6129831 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.598299	array([[-0.9549776 , -0.13879357]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -2.046704	array([[-0.97632277, -0.1564456 ]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.903490	array([[1.0148947 , 0.57730097]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.206850	array([[1.0178757 , 0.58762157]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -2.385158	array([[1.0291884 , 0.58050954]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.924469	array([[-0.92429096, -0.14293228]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.927054	array([[-0.9781265 , -0.15951791]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = 0.524192	array([[1.0483445 , 0.55052745]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.141082	array([[1.0072646, 0.5962632]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.153674	array([[1.002711  , 0.60035646]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.351354	array([[-0.99024737, -0.14973105]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.521358	array([[-0.97443014, -0.178325  ]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.269246	array([[1.0534906, 0.5724657]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.910557	array([[1.032094 , 0.5896538]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.851775	array([[1.0076883, 0.5870092]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.217784	array([[-0.9448881 , -0.11792953]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -2.115930	array([[-0.928639  , -0.12537992]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -1.184492	array([[1.0177798, 0.5721651]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -1.533233	array([[0.95663756, 0.5994168 ]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.712496	array([[0.9500864 , 0.60278124]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.307295	array([[-0.93763655, -0.11037044]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -2.443216	array([[-0.9032067 , -0.13576388]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.424342	array([[0.991735 , 0.5641668]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -0.754622	array([[0.9675661, 0.5851645]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -2.045729	array([[0.9401987, 0.5985634]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.748921	array([[-0.99016863, -0.14691934]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.629664	array([[-0.9520756, -0.1451788]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.422136	array([[1.0153811, 0.5775811]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.044042	array([[1.0120432 , 0.58710116]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.363074	array([[1.0026907 , 0.58526385]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2219ms
 Real time factor: 301.487
 UPS: 4346.552501
Vehicles: 
 Inserted: 257 (Loaded: 313)
 Running: 15
 Waiting: 2

DijkstraRouter answered 440 queries and explored 3.41 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 55217 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.030510	array([[-0.96487   , -0.15574525]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.927751	array([[-0.9469114 , -0.17888647]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.907515	array([[1.0352211, 0.5634943]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -1.311643	array([[1.0201592, 0.5715707]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.384423	array([[1.0132005 , 0.57394946]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.151676	array([[-0.98204005, -0.17403717]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.783955	array([[-0.94778   , -0.17380527]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -0.407497	array([[1.0258694, 0.5744817]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -1.042190	array([[1.0056291 , 0.59481853]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.679479	array([[1.0105898, 0.5874685]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.325726	array([[-0.9789344 , -0.16462117]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.194196	array([[-0.95090306, -0.17209628]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -0.631407	array([[1.0489587 , 0.56619173]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.533807	array([[1.0001627, 0.5841137]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.511808	array([[1.0043209, 0.584891 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.211420	array([[-0.9983081 , -0.18220231]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.370356	array([[-0.95675975, -0.19167879]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -0.164275	array([[1.0373532, 0.5620906]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.063042	array([[1.0653077, 0.5606356]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.404625	array([[1.0539479, 0.5774778]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.880935	array([[-0.96996254, -0.1737552 ]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.895481	array([[-0.961079  , -0.15615302]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -0.660003	array([[1.0390666, 0.5782738]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.752343	array([[1.015147 , 0.6019701]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.357758	array([[1.0009956, 0.6023215]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.495662	array([[-0.9922424 , -0.10726675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -2.757643	array([[-0.95147586, -0.14306787]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -1.300101	array([[0.99538374, 0.56759804]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.893400	array([[0.95338076, 0.6020456 ]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.799074	array([[0.965493  , 0.60511327]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.934318	array([[-0.964518  , -0.13962105]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -2.074900	array([[-0.96281403, -0.13520518]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -1.335287	array([[1.0176188, 0.5740967]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.524769	array([[0.9879667, 0.5937983]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -2.468569	array([[0.9814966 , 0.59268284]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.646649	array([[-0.9905778, -0.1435135]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -1.282693	array([[-0.96777093, -0.17546725]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -0.104404	array([[1.0604949 , 0.56527436]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.829113	array([[1.0173751 , 0.59880525]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.668408	array([[1.0063326, 0.6073818]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.063598	array([[-0.9523895 , -0.13429481]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.356038	array([[-0.9572207 , -0.14993215]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.340797	array([[1.0436794 , 0.55491024]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.282400	array([[1.0298508 , 0.57055926]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.546743	array([[1.0177245 , 0.57545775]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.244718	array([[-0.972192  , -0.17120421]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.882899	array([[-0.98493993, -0.15153742]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.051064	array([[1.0154796, 0.5780237]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.688491	array([[0.9954733, 0.5916623]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:55217 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.154288	array([[1.0186824, 0.5857945]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.671490	array([[-0.9665299 , -0.16870281]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -1.575596	array([[-0.9743375 , -0.18299115]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.055419	array([[1.038988 , 0.5620096]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.237352	array([[1.0247917, 0.5804895]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.016446	array([[1.0266252 , 0.58742684]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.443110	array([[-0.93261683, -0.14644809]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.012227	array([[-0.96724576, -0.12643695]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.215970	array([[0.9896348 , 0.58204395]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.283480	array([[0.9522838 , 0.60149616]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.040891	array([[0.9523947, 0.608362 ]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.977593	array([[-0.9307659, -0.1208716]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.883918	array([[-0.9117373 , -0.13243294]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = 0.286657	array([[0.997843 , 0.5845383]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.582469	array([[0.9639263 , 0.60724354]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.463147	array([[0.93206966, 0.6148259 ]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.670579	array([[-0.9605349, -0.1144904]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -2.175688	array([[-0.9312997 , -0.14776543]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.500865	array([[1.0043056 , 0.57488203]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.869957	array([[0.99170566, 0.596291  ]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.565694	array([[0.97493887, 0.6129831 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.598299	array([[-0.9549776 , -0.13879357]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -2.046704	array([[-0.97632277, -0.1564456 ]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.903490	array([[1.0148947 , 0.57730097]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.206850	array([[1.0178757 , 0.58762157]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -2.385158	array([[1.0291884 , 0.58050954]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.924469	array([[-0.92429096, -0.14293228]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.927054	array([[-0.9781265 , -0.15951791]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = 0.524192	array([[1.0483445 , 0.55052745]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.141082	array([[1.0072646, 0.5962632]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.153674	array([[1.002711  , 0.60035646]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.351354	array([[-0.99024737, -0.14973105]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.521358	array([[-0.97443014, -0.178325  ]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.269246	array([[1.0534906, 0.5724657]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.910557	array([[1.032094 , 0.5896538]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.851775	array([[1.0076883, 0.5870092]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.217784	array([[-0.9448881 , -0.11792953]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -2.115930	array([[-0.928639  , -0.12537992]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -1.184492	array([[1.0177798, 0.5721651]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -1.533233	array([[0.95663756, 0.5994168 ]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.712496	array([[0.9500864 , 0.60278124]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.307295	array([[-0.93763655, -0.11037044]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -2.443216	array([[-0.9032067 , -0.13576388]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.424342	array([[0.991735 , 0.5641668]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -0.754622	array([[0.9675661, 0.5851645]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -2.045729	array([[0.9401987, 0.5985634]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.748921	array([[-0.99016863, -0.14691934]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.629664	array([[-0.9520756, -0.1451788]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.422136	array([[1.0153811, 0.5775811]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.044042	array([[1.0120432 , 0.58710116]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.363074	array([[1.0026907 , 0.58526385]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.030510	array([[-0.96487   , -0.15574525]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.927751	array([[-0.9469114 , -0.17888647]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.907515	array([[1.0352211, 0.5634943]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -1.311643	array([[1.0201592, 0.5715707]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.384423	array([[1.0132005 , 0.57394946]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.151676	array([[-0.98204005, -0.17403717]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.783955	array([[-0.94778   , -0.17380527]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -0.407497	array([[1.0258694, 0.5744817]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -1.042190	array([[1.0056291 , 0.59481853]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.679479	array([[1.0105898, 0.5874685]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.325726	array([[-0.9789344 , -0.16462117]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.194196	array([[-0.95090306, -0.17209628]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -0.631407	array([[1.0489587 , 0.56619173]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.533807	array([[1.0001627, 0.5841137]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.511808	array([[1.0043209, 0.584891 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.211420	array([[-0.9983081 , -0.18220231]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.370356	array([[-0.95675975, -0.19167879]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -0.164275	array([[1.0373532, 0.5620906]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.063042	array([[1.0653077, 0.5606356]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.404625	array([[1.0539479, 0.5774778]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.880935	array([[-0.96996254, -0.1737552 ]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.895481	array([[-0.961079  , -0.15615302]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -0.660003	array([[1.0390666, 0.5782738]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.752343	array([[1.015147 , 0.6019701]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.357758	array([[1.0009956, 0.6023215]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.495662	array([[-0.9922424 , -0.10726675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -2.757643	array([[-0.95147586, -0.14306787]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -1.300101	array([[0.99538374, 0.56759804]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2180ms
 Real time factor: 306.881
 UPS: 4424.311927
Vehicles: 
 Inserted: 257 (Loaded: 313)
 Running: 15
 Waiting: 2

DijkstraRouter answered 440 queries and explored 3.41 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 39191 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.893400	array([[0.95338076, 0.6020456 ]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.799074	array([[0.965493  , 0.60511327]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.934318	array([[-0.964518  , -0.13962105]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -2.074900	array([[-0.96281403, -0.13520518]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -1.335287	array([[1.0176188, 0.5740967]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.524769	array([[0.9879667, 0.5937983]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -2.468569	array([[0.9814966 , 0.59268284]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.646649	array([[-0.9905778, -0.1435135]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -1.282693	array([[-0.96777093, -0.17546725]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -0.104404	array([[1.0604949 , 0.56527436]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.829113	array([[1.0173751 , 0.59880525]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.668408	array([[1.0063326, 0.6073818]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.063598	array([[-0.9523895 , -0.13429481]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.356038	array([[-0.9572207 , -0.14993215]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.340797	array([[1.0436794 , 0.55491024]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.282400	array([[1.0298508 , 0.57055926]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.546743	array([[1.0177245 , 0.57545775]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.244718	array([[-0.972192  , -0.17120421]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.882899	array([[-0.98493993, -0.15153742]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.051064	array([[1.0154796, 0.5780237]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.688491	array([[0.9954733, 0.5916623]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:39191 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.154288	array([[1.0186824, 0.5857945]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.671490	array([[-0.9665299 , -0.16870281]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -1.575596	array([[-0.9743375 , -0.18299115]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.055419	array([[1.038988 , 0.5620096]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.237352	array([[1.0247917, 0.5804895]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.016446	array([[1.0266252 , 0.58742684]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.443110	array([[-0.93261683, -0.14644809]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.012227	array([[-0.96724576, -0.12643695]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.215970	array([[0.9896348 , 0.58204395]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.283480	array([[0.9522838 , 0.60149616]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.040891	array([[0.9523947, 0.608362 ]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.977593	array([[-0.9307659, -0.1208716]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.883918	array([[-0.9117373 , -0.13243294]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = 0.286657	array([[0.997843 , 0.5845383]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.582469	array([[0.9639263 , 0.60724354]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.463147	array([[0.93206966, 0.6148259 ]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.670579	array([[-0.9605349, -0.1144904]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -2.175688	array([[-0.9312997 , -0.14776543]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.500865	array([[1.0043056 , 0.57488203]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.869957	array([[0.99170566, 0.596291  ]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.565694	array([[0.97493887, 0.6129831 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.598299	array([[-0.9549776 , -0.13879357]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -2.046704	array([[-0.97632277, -0.1564456 ]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.903490	array([[1.0148947 , 0.57730097]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.206850	array([[1.0178757 , 0.58762157]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -2.385158	array([[1.0291884 , 0.58050954]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.924469	array([[-0.92429096, -0.14293228]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.927054	array([[-0.9781265 , -0.15951791]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = 0.524192	array([[1.0483445 , 0.55052745]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.141082	array([[1.0072646, 0.5962632]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.153674	array([[1.002711  , 0.60035646]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.351354	array([[-0.99024737, -0.14973105]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.521358	array([[-0.97443014, -0.178325  ]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.269246	array([[1.0534906, 0.5724657]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.910557	array([[1.032094 , 0.5896538]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.851775	array([[1.0076883, 0.5870092]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.217784	array([[-0.9448881 , -0.11792953]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -2.115930	array([[-0.928639  , -0.12537992]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -1.184492	array([[1.0177798, 0.5721651]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -1.533233	array([[0.95663756, 0.5994168 ]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2173ms
 Real time factor: 307.869
 UPS: 4438.564197
Vehicles: 
 Inserted: 257 (Loaded: 313)
 Running: 15
 Waiting: 2

DijkstraRouter answered 440 queries and explored 3.41 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 36235 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (1ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.712496	array([[0.9500864 , 0.60278124]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.307295	array([[-0.93763655, -0.11037044]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -2.443216	array([[-0.9032067 , -0.13576388]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.424342	array([[0.991735 , 0.5641668]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -0.754622	array([[0.9675661, 0.5851645]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -2.045729	array([[0.9401987, 0.5985634]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.748921	array([[-0.99016863, -0.14691934]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.629664	array([[-0.9520756, -0.1451788]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.422136	array([[1.0153811, 0.5775811]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.044042	array([[1.0120432 , 0.58710116]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.363074	array([[1.0026907 , 0.58526385]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.030510	array([[-0.96487   , -0.15574525]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.927751	array([[-0.9469114 , -0.17888647]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.907515	array([[1.0352211, 0.5634943]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -1.311643	array([[1.0201592, 0.5715707]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.384423	array([[1.0132005 , 0.57394946]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.151676	array([[-0.98204005, -0.17403717]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.783955	array([[-0.94778   , -0.17380527]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -0.407497	array([[1.0258694, 0.5744817]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -1.042190	array([[1.0056291 , 0.59481853]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.679479	array([[1.0105898, 0.5874685]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.325726	array([[-0.9789344 , -0.16462117]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.194196	array([[-0.95090306, -0.17209628]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -0.631407	array([[1.0489587 , 0.56619173]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.533807	array([[1.0001627, 0.5841137]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.511808	array([[1.0043209, 0.584891 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.211420	array([[-0.9983081 , -0.18220231]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.370356	array([[-0.95675975, -0.19167879]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -0.164275	array([[1.0373532, 0.5620906]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.063042	array([[1.0653077, 0.5606356]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.404625	array([[1.0539479, 0.5774778]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.880935	array([[-0.96996254, -0.1737552 ]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.895481	array([[-0.961079  , -0.15615302]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -0.660003	array([[1.0390666, 0.5782738]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.752343	array([[1.015147 , 0.6019701]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.357758	array([[1.0009956, 0.6023215]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.495662	array([[-0.9922424 , -0.10726675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -2.757643	array([[-0.95147586, -0.14306787]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -1.300101	array([[0.99538374, 0.56759804]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.893400	array([[0.95338076, 0.6020456 ]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.799074	array([[0.965493  , 0.60511327]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.934318	array([[-0.964518  , -0.13962105]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -2.074900	array([[-0.96281403, -0.13520518]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -1.335287	array([[1.0176188, 0.5740967]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.524769	array([[0.9879667, 0.5937983]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -2.468569	array([[0.9814966 , 0.59268284]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.646649	array([[-0.9905778, -0.1435135]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -1.282693	array([[-0.96777093, -0.17546725]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -0.104404	array([[1.0604949 , 0.56527436]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.829113	array([[1.0173751 , 0.59880525]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.668408	array([[1.0063326, 0.6073818]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.063598	array([[-0.9523895 , -0.13429481]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.356038	array([[-0.9572207 , -0.14993215]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.340797	array([[1.0436794 , 0.55491024]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.282400	array([[1.0298508 , 0.57055926]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.546743	array([[1.0177245 , 0.57545775]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.244718	array([[-0.972192  , -0.17120421]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.882899	array([[-0.98493993, -0.15153742]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.051064	array([[1.0154796, 0.5780237]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.688491	array([[0.9954733, 0.5916623]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:36235 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.154288	array([[1.0186824, 0.5857945]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -0.671490	array([[-0.9665299 , -0.16870281]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -1.575596	array([[-0.9743375 , -0.18299115]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.055419	array([[1.038988 , 0.5620096]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.237352	array([[1.0247917, 0.5804895]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -2.016446	array([[1.0266252 , 0.58742684]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.443110	array([[-0.93261683, -0.14644809]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.012227	array([[-0.96724576, -0.12643695]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.215970	array([[0.9896348 , 0.58204395]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.283480	array([[0.9522838 , 0.60149616]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.040891	array([[0.9523947, 0.608362 ]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -0.977593	array([[-0.9307659, -0.1208716]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.883918	array([[-0.9117373 , -0.13243294]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = 0.286657	array([[0.997843 , 0.5845383]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.582469	array([[0.9639263 , 0.60724354]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.463147	array([[0.93206966, 0.6148259 ]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -0.670579	array([[-0.9605349, -0.1144904]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -2.175688	array([[-0.9312997 , -0.14776543]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.500865	array([[1.0043056 , 0.57488203]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.869957	array([[0.99170566, 0.596291  ]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.565694	array([[0.97493887, 0.6129831 ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -0.598299	array([[-0.9549776 , -0.13879357]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -2.046704	array([[-0.97632277, -0.1564456 ]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.903490	array([[1.0148947 , 0.57730097]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -1.206850	array([[1.0178757 , 0.58762157]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -2.385158	array([[1.0291884 , 0.58050954]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.924469	array([[-0.92429096, -0.14293228]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.927054	array([[-0.9781265 , -0.15951791]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = 0.524192	array([[1.0483445 , 0.55052745]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.141082	array([[1.0072646, 0.5962632]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -1.153674	array([[1.002711  , 0.60035646]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.351354	array([[-0.99024737, -0.14973105]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.521358	array([[-0.97443014, -0.178325  ]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.269246	array([[1.0534906, 0.5724657]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -0.910557	array([[1.032094 , 0.5896538]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.851775	array([[1.0076883, 0.5870092]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.217784	array([[-0.9448881 , -0.11792953]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -2.115930	array([[-0.928639  , -0.12537992]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -1.184492	array([[1.0177798, 0.5721651]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -1.533233	array([[0.95663756, 0.5994168 ]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.712496	array([[0.9500864 , 0.60278124]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.307295	array([[-0.93763655, -0.11037044]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -2.443216	array([[-0.9032067 , -0.13576388]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.424342	array([[0.991735 , 0.5641668]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -0.754622	array([[0.9675661, 0.5851645]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -2.045729	array([[0.9401987, 0.5985634]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.748921	array([[-0.99016863, -0.14691934]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.629664	array([[-0.9520756, -0.1451788]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.422136	array([[1.0153811, 0.5775811]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -1.044042	array([[1.0120432 , 0.58710116]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.363074	array([[1.0026907 , 0.58526385]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.030510	array([[-0.96487   , -0.15574525]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.927751	array([[-0.9469114 , -0.17888647]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.907515	array([[1.0352211, 0.5634943]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -1.311643	array([[1.0201592, 0.5715707]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -1.384423	array([[1.0132005 , 0.57394946]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.151676	array([[-0.98204005, -0.17403717]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.783955	array([[-0.94778   , -0.17380527]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -0.407497	array([[1.0258694, 0.5744817]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -1.042190	array([[1.0056291 , 0.59481853]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -1.679479	array([[1.0105898, 0.5874685]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.325726	array([[-0.9789344 , -0.16462117]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.194196	array([[-0.95090306, -0.17209628]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -0.631407	array([[1.0489587 , 0.56619173]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -0.533807	array([[1.0001627, 0.5841137]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -1.511808	array([[1.0043209, 0.584891 ]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 0.211420	array([[-0.9983081 , -0.18220231]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.370356	array([[-0.95675975, -0.19167879]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2209ms
 Real time factor: 302.852
 UPS: 4366.229063
Vehicles: 
 Inserted: 257 (Loaded: 313)
 Running: 15
 Waiting: 2

DijkstraRouter answered 440 queries and explored 3.41 edges on average.
DijkstraRouter spent 0ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 50277 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (5ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -0.164275	array([[1.0373532, 0.5620906]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -0.063042	array([[1.0653077, 0.5606356]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.404625	array([[1.0539479, 0.5774778]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.880935	array([[-0.96996254, -0.1737552 ]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.895481	array([[-0.961079  , -0.15615302]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -0.660003	array([[1.0390666, 0.5782738]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -0.752343	array([[1.015147 , 0.6019701]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -2.357758	array([[1.0009956, 0.6023215]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.495662	array([[-0.9922424 , -0.10726675]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -2.757643	array([[-0.95147586, -0.14306787]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -1.300101	array([[0.99538374, 0.56759804]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.893400	array([[0.95338076, 0.6020456 ]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.799074	array([[0.965493  , 0.60511327]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.934318	array([[-0.964518  , -0.13962105]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -2.074900	array([[-0.96281403, -0.13520518]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -1.335287	array([[1.0176188, 0.5740967]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.524769	array([[0.9879667, 0.5937983]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -2.468569	array([[0.9814966 , 0.59268284]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.646649	array([[-0.9905778, -0.1435135]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -1.282693	array([[-0.96777093, -0.17546725]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -0.104404	array([[1.0604949 , 0.56527436]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -0.829113	array([[1.0173751 , 0.59880525]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.668408	array([[1.0063326, 0.6073818]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.063598	array([[-0.9523895 , -0.13429481]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.356038	array([[-0.9572207 , -0.14993215]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -0.340797	array([[1.0436794 , 0.55491024]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.282400	array([[1.0298508 , 0.57055926]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.546743	array([[1.0177245 , 0.57545775]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -1.244718	array([[-0.972192  , -0.17120421]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.882899	array([[-0.98493993, -0.15153742]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.051064	array([[1.0154796, 0.5780237]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.688491	array([[0.9954733, 0.5916623]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:50277 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -1.464864	array([[1.0186824, 0.5857945]], dtype=float32)
time = 53	action = 1	current_phase = 1	next_phase = 0	reward = -2.081809	array([[1.030314 , 0.5716908]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -0.822916	array([[-0.9535487 , -0.16692029]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.976022	array([[-0.9479691 , -0.17448172]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.460478	array([[1.0278696 , 0.56884265]], dtype=float32)
time = 79	action = 0	current_phase = 1	next_phase = 0	reward = -0.899778	array([[1.0061188, 0.5907462]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -0.040525	array([[0.9867847, 0.5931876]], dtype=float32)
time = 89	action = 1	current_phase = 1	next_phase = 0	reward = -1.355617	array([[0.9891726 , 0.60422045]], dtype=float32)
time = 97	action = 0	current_phase = 0	next_phase = 1	reward = -0.332306	array([[-0.9643329 , -0.13019153]], dtype=float32)
time = 102	action = 1	current_phase = 0	next_phase = 1	reward = -1.194997	array([[-0.9320884 , -0.13558027]], dtype=float32)
time = 110	action = 0	current_phase = 1	next_phase = 0	reward = -0.603855	array([[1.0020437, 0.5741681]], dtype=float32)
time = 115	action = 0	current_phase = 1	next_phase = 0	reward = -0.882754	array([[0.99329525, 0.58063745]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -0.848062	array([[0.9703238 , 0.59835553]], dtype=float32)
time = 125	action = 1	current_phase = 1	next_phase = 0	reward = -1.243356	array([[0.97670245, 0.5953479 ]], dtype=float32)
time = 133	action = 0	current_phase = 0	next_phase = 1	reward = -0.731979	array([[-0.9359127, -0.1125283]], dtype=float32)
time = 138	action = 1	current_phase = 0	next_phase = 1	reward = -2.104732	array([[-0.91670036, -0.1341905 ]], dtype=float32)
time = 146	action = 0	current_phase = 1	next_phase = 0	reward = -0.099592	array([[0.9938011 , 0.57483506]], dtype=float32)
time = 151	action = 0	current_phase = 1	next_phase = 0	reward = -0.956237	array([[0.9636718 , 0.60042477]], dtype=float32)
time = 156	action = 0	current_phase = 1	next_phase = 0	reward = -0.879210	array([[0.93981487, 0.6103729 ]], dtype=float32)
time = 161	action = 1	current_phase = 1	next_phase = 0	reward = -1.404462	array([[0.9673165, 0.6025795]], dtype=float32)
time = 169	action = 0	current_phase = 0	next_phase = 1	reward = -0.160919	array([[-0.96271807, -0.12936246]], dtype=float32)
time = 174	action = 1	current_phase = 0	next_phase = 1	reward = -1.387627	array([[-0.93974775, -0.15766287]], dtype=float32)
time = 182	action = 0	current_phase = 1	next_phase = 0	reward = -0.669411	array([[1.0524868, 0.5841116]], dtype=float32)
time = 187	action = 0	current_phase = 1	next_phase = 0	reward = -1.200179	array([[1.0088414 , 0.60150135]], dtype=float32)
time = 192	action = 0	current_phase = 1	next_phase = 0	reward = -1.666191	array([[1.0088447, 0.6047199]], dtype=float32)
time = 197	action = 1	current_phase = 1	next_phase = 0	reward = -2.339187	array([[1.018753 , 0.5905136]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -0.108308	array([[-0.9303938 , -0.13674715]], dtype=float32)
time = 210	action = 1	current_phase = 0	next_phase = 1	reward = -1.785185	array([[-0.91941977, -0.15836675]], dtype=float32)
time = 218	action = 0	current_phase = 1	next_phase = 0	reward = -0.370667	array([[1.0437459, 0.555338 ]], dtype=float32)
time = 223	action = 0	current_phase = 1	next_phase = 0	reward = -0.513086	array([[0.99947166, 0.5949062 ]], dtype=float32)
time = 228	action = 0	current_phase = 1	next_phase = 0	reward = -0.634568	array([[1.0107776 , 0.59944355]], dtype=float32)
time = 233	action = 1	current_phase = 1	next_phase = 0	reward = -1.398134	array([[1.0070829, 0.6090052]], dtype=float32)
time = 241	action = 0	current_phase = 0	next_phase = 1	reward = 0.088454	array([[-0.96883655, -0.16343956]], dtype=float32)
time = 246	action = 1	current_phase = 0	next_phase = 1	reward = -2.092104	array([[-0.96551204, -0.16960768]], dtype=float32)
time = 254	action = 0	current_phase = 1	next_phase = 0	reward = -0.456998	array([[1.0568444, 0.5714742]], dtype=float32)
time = 259	action = 0	current_phase = 1	next_phase = 0	reward = -1.042343	array([[1.0259038 , 0.59881467]], dtype=float32)
time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -1.357449	array([[1.0151157 , 0.59398407]], dtype=float32)
time = 269	action = 1	current_phase = 1	next_phase = 0	reward = -1.610479	array([[0.9923633, 0.6048394]], dtype=float32)
time = 277	action = 0	current_phase = 0	next_phase = 1	reward = 0.466744	array([[-0.97846925, -0.09763331]], dtype=float32)
time = 282	action = 1	current_phase = 0	next_phase = 1	reward = -1.776223	array([[-0.93584627, -0.12175222]], dtype=float32)
time = 290	action = 0	current_phase = 1	next_phase = 0	reward = -1.176552	array([[1.0403779 , 0.57387555]], dtype=float32)
time = 295	action = 0	current_phase = 1	next_phase = 0	reward = -1.176320	array([[0.9892364, 0.59568  ]], dtype=float32)
time = 300	action = 0	current_phase = 1	next_phase = 0	reward = -1.442817	array([[0.96699715, 0.61063313]], dtype=float32)
time = 305	action = 1	current_phase = 1	next_phase = 0	reward = -2.158645	array([[0.9542488 , 0.61496925]], dtype=float32)
time = 313	action = 0	current_phase = 0	next_phase = 1	reward = -0.172867	array([[-0.95729566, -0.10078695]], dtype=float32)
time = 318	action = 1	current_phase = 0	next_phase = 1	reward = -1.463892	array([[-0.929786  , -0.14254314]], dtype=float32)
time = 326	action = 0	current_phase = 1	next_phase = 0	reward = -0.124144	array([[1.0524998, 0.5344359]], dtype=float32)
time = 331	action = 0	current_phase = 1	next_phase = 0	reward = -0.330165	array([[0.9756384 , 0.58064294]], dtype=float32)
time = 336	action = 0	current_phase = 1	next_phase = 0	reward = -0.486747	array([[0.964453 , 0.5954306]], dtype=float32)
time = 341	action = 1	current_phase = 1	next_phase = 0	reward = -1.471416	array([[0.969419  , 0.60072213]], dtype=float32)
time = 349	action = 0	current_phase = 0	next_phase = 1	reward = -0.448426	array([[-0.9945353 , -0.14111961]], dtype=float32)
time = 354	action = 1	current_phase = 0	next_phase = 1	reward = -1.961596	array([[-0.96057   , -0.16693547]], dtype=float32)
time = 362	action = 0	current_phase = 1	next_phase = 0	reward = -1.254123	array([[1.0237525, 0.5739975]], dtype=float32)
time = 367	action = 0	current_phase = 1	next_phase = 0	reward = -1.415122	array([[0.9929553, 0.5863067]], dtype=float32)
time = 372	action = 0	current_phase = 1	next_phase = 0	reward = -0.965051	array([[1.0233603, 0.5826424]], dtype=float32)
time = 377	action = 1	current_phase = 1	next_phase = 0	reward = -1.585315	array([[1.0083057 , 0.58625793]], dtype=float32)
time = 385	action = 0	current_phase = 0	next_phase = 1	reward = -0.263630	array([[-0.94469297, -0.14323425]], dtype=float32)
time = 390	action = 1	current_phase = 0	next_phase = 1	reward = -1.275270	array([[-0.94827473, -0.18519364]], dtype=float32)
time = 398	action = 0	current_phase = 1	next_phase = 0	reward = -0.151833	array([[1.0597866, 0.5500082]], dtype=float32)
time = 403	action = 0	current_phase = 1	next_phase = 0	reward = -0.482964	array([[1.012841 , 0.5895686]], dtype=float32)
time = 408	action = 0	current_phase = 1	next_phase = 0	reward = -0.474822	array([[1.0034523 , 0.59508985]], dtype=float32)
time = 413	action = 1	current_phase = 1	next_phase = 0	reward = -1.081777	array([[1.0214086, 0.587407 ]], dtype=float32)
time = 421	action = 0	current_phase = 0	next_phase = 1	reward = -0.335145	array([[-0.96119404, -0.17322013]], dtype=float32)
time = 426	action = 1	current_phase = 0	next_phase = 1	reward = -1.621627	array([[-0.94336265, -0.17209904]], dtype=float32)
time = 434	action = 0	current_phase = 1	next_phase = 0	reward = -0.454727	array([[1.0201101 , 0.57154644]], dtype=float32)
time = 439	action = 0	current_phase = 1	next_phase = 0	reward = -0.280016	array([[1.0066053 , 0.58600384]], dtype=float32)
time = 444	action = 0	current_phase = 1	next_phase = 0	reward = -0.389172	array([[1.0185723, 0.5740898]], dtype=float32)
time = 449	action = 1	current_phase = 1	next_phase = 0	reward = -1.385520	array([[1.0108737 , 0.57725567]], dtype=float32)
time = 457	action = 0	current_phase = 0	next_phase = 1	reward = 0.030448	array([[-0.9861815 , -0.17961034]], dtype=float32)
time = 462	action = 1	current_phase = 0	next_phase = 1	reward = -1.333875	array([[-0.96017605, -0.1878137 ]], dtype=float32)
time = 470	action = 0	current_phase = 1	next_phase = 0	reward = -0.542812	array([[1.0474155 , 0.55458754]], dtype=float32)
time = 475	action = 0	current_phase = 1	next_phase = 0	reward = -0.026837	array([[1.041973 , 0.5639874]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -0.778999	array([[1.0458142, 0.5747511]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -2.075456	array([[1.028568 , 0.5910314]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = 0.054654	array([[-0.948789  , -0.14131075]], dtype=float32)
time = 498	action = 1	current_phase = 0	next_phase = 1	reward = -1.187276	array([[-0.9274431 , -0.15881121]], dtype=float32)
time = 506	action = 0	current_phase = 1	next_phase = 0	reward = -0.484889	array([[1.0244795, 0.5820891]], dtype=float32)
time = 511	action = 0	current_phase = 1	next_phase = 0	reward = -0.896011	array([[1.0006695, 0.6066574]], dtype=float32)
time = 516	action = 0	current_phase = 1	next_phase = 0	reward = -1.083394	array([[1.0013692 , 0.59400576]], dtype=float32)
time = 521	action = 1	current_phase = 1	next_phase = 0	reward = -1.300690	array([[0.98185325, 0.5991367 ]], dtype=float32)
time = 529	action = 0	current_phase = 0	next_phase = 1	reward = 0.717990	array([[-0.99003214, -0.12475694]], dtype=float32)
time = 534	action = 1	current_phase = 0	next_phase = 1	reward = -1.198146	array([[-0.9360502 , -0.15460812]], dtype=float32)
time = 542	action = 0	current_phase = 1	next_phase = 0	reward = -0.306278	array([[1.064664  , 0.55412716]], dtype=float32)
time = 547	action = 0	current_phase = 1	next_phase = 0	reward = -0.119555	array([[1.0319064, 0.5867545]], dtype=float32)
time = 552	action = 0	current_phase = 1	next_phase = 0	reward = -0.648558	array([[1.021909  , 0.59898865]], dtype=float32)
time = 557	action = 1	current_phase = 1	next_phase = 0	reward = -1.281717	array([[0.9971318, 0.6020954]], dtype=float32)
time = 565	action = 0	current_phase = 0	next_phase = 1	reward = 0.253753	array([[-0.94413006, -0.13864961]], dtype=float32)
time = 570	action = 1	current_phase = 0	next_phase = 1	reward = -1.271048	array([[-0.9503745 , -0.17254803]], dtype=float32)
time = 578	action = 0	current_phase = 1	next_phase = 0	reward = -0.355952	array([[1.0585262 , 0.54781365]], dtype=float32)
time = 583	action = 0	current_phase = 1	next_phase = 0	reward = -0.607764	array([[0.9998368, 0.5953316]], dtype=float32)
time = 588	action = 0	current_phase = 1	next_phase = 0	reward = -0.276969	array([[1.0203471, 0.5877792]], dtype=float32)
time = 593	action = 1	current_phase = 1	next_phase = 0	reward = -1.159395	array([[1.0313631 , 0.58486044]], dtype=float32)
time = 601	action = 0	current_phase = 0	next_phase = 1	reward = -0.551673	array([[-0.95387197, -0.1351144 ]], dtype=float32)
time = 606	action = 1	current_phase = 0	next_phase = 1	reward = -1.355076	array([[-0.9632653 , -0.15257332]], dtype=float32)
time = 614	action = 0	current_phase = 1	next_phase = 0	reward = -0.852329	array([[1.0280496, 0.5827707]], dtype=float32)
time = 619	action = 0	current_phase = 1	next_phase = 0	reward = -1.107012	array([[1.0108296, 0.5877906]], dtype=float32)Simulation ended at time: 674.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2181ms
 Real time factor: 309.033
 UPS: 4334.708849
Vehicles: 
 Inserted: 260 (Loaded: 313)
 Running: 13
 Waiting: 0

DijkstraRouter answered 419 queries and explored 3.37 edges on average.
DijkstraRouter spent 1ms answering queries (0.00ms on average).
Loading configuration... done.
***Starting server on port 43069 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/osm.net.xml'... done (1ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00

time = 624	action = 0	current_phase = 1	next_phase = 0	reward = -1.219890	array([[1.0041856, 0.5896324]], dtype=float32)
time = 629	action = 1	current_phase = 1	next_phase = 0	reward = -1.738851	array([[1.000605  , 0.58747005]], dtype=float32)
time = 637	action = 0	current_phase = 0	next_phase = 1	reward = 0.446905	array([[-0.9885179, -0.1376834]], dtype=float32)
time = 642	action = 1	current_phase = 0	next_phase = 1	reward = -0.838345	array([[-0.9672396 , -0.18302092]], dtype=float32)
time = 650	action = 0	current_phase = 1	next_phase = 0	reward = -0.279756	array([[1.063403 , 0.5437303]], dtype=float32)
time = 655	action = 0	current_phase = 1	next_phase = 0	reward = -0.210224	array([[1.0007871 , 0.58733714]], dtype=float32)
time = 660	action = 0	current_phase = 1	next_phase = 0	reward = -0.551729	array([[1.0394225, 0.5746259]], dtype=float32)
time = 665	action = 1	current_phase = 1	next_phase = 0	reward = -1.201016	array([[1.0118414 , 0.58078045]], dtype=float32)
Terminal occured. Episode end.
Could not connect to TraCI server at localhost:43069 [Errno 111] Connection refused
 Retrying in 1 seconds
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.018888	array([[-0.97290695, -0.15577462]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.572361	array([[-1.0058475 , -0.15743715]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.914293	array([[-1.0013988 , -0.12409408]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.588394	array([[1.0310154, 0.5835309]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.997702	array([[1.0410463, 0.5828052]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -1.464864	array([[1.0186824, 0.5857945]], dtype=float32)
time = 53	action = 0	current_phase = 1	next_phase = 0	reward = -1.350947	array([[1.030314 , 0.5716908]], dtype=float32)
time = 58	action = 1	current_phase = 1	next_phase = 0	reward = -1.882620	array([[1.0234663 , 0.57444066]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -0.244194	array([[-0.96543884, -0.14850274]], dtype=float32)
time = 71	action = 1	current_phase = 0	next_phase = 1	reward = -1.454673	array([[-0.94001734, -0.17267393]], dtype=float32)
time = 79	action = 0	current_phase = 1	next_phase = 0	reward = -0.490887	array([[1.0446188, 0.5656597]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -0.228979	array([[1.005272 , 0.5877036]], dtype=float32)
time = 89	action = 0	current_phase = 1	next_phase = 0	reward = -0.471892	array([[0.99710363, 0.5982112 ]], dtype=float32)
time = 94	action = 0	current_phase = 1	next_phase = 0	reward = -0.555205	array([[0.98506624, 0.59762764]], dtype=float32)
time = 99	action = 1	current_phase = 1	next_phase = 0	reward = -1.191559	array([[0.98909754, 0.60159755]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = 0.157487	array([[-0.96823317, -0.11327797]], dtype=float32)
time = 112	action = 1	current_phase = 0	next_phase = 1	reward = -1.266474	array([[-0.9184522 , -0.15165927]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = 0.076227	array([[1.032893  , 0.56311363]], dtype=float32)
time = 125	action = 0	current_phase = 1	next_phase = 0	reward = 0.472959	array([[0.9890868 , 0.59491056]], dtype=float32)
time = 130	action = 0	current_phase = 1	next_phase = 0	reward = -0.034452	array([[0.9675605 , 0.61484635]], dtype=float32)
time = 135	action = 0	current_phase = 1	next_phase = 0	reward = -0.596316	array([[0.97903347, 0.6099147 ]], dtype=float32)
time = 140	action = 1	current_phase = 1	next_phase = 0	reward = -1.379378	array([[0.9799279 , 0.59476477]], dtype=float32)
time = 148	action = 0	current_phase = 0	next_phase = 1	reward = -0.551633	array([[-0.9633648 , -0.12760746]], dtype=float32)
time = 153	action = 1	current_phase = 0	next_phase = 1	reward = -1.942353	array([[-0.93540007, -0.14602613]], dtype=float32)
time = 161	action = 0	current_phase = 1	next_phase = 0	reward = -0.846608	array([[1.0108377, 0.575307 ]], dtype=float32)
time = 166	action = 0	current_phase = 1	next_phase = 0	reward = -0.745976	array([[0.9736936 , 0.60488474]], dtype=float32)
time = 171	action = 0	current_phase = 1	next_phase = 0	reward = -0.760779	array([[0.99161744, 0.60718715]], dtype=float32)
time = 176	action = 0	current_phase = 1	next_phase = 0	reward = -0.943581	array([[0.9993845 , 0.60840845]], dtype=float32)
time = 181	action = 1	current_phase = 1	next_phase = 0	reward = -1.766620	array([[1.0069716, 0.6120336]], dtype=float32)
time = 189	action = 0	current_phase = 0	next_phase = 1	reward = -0.076282	array([[-0.9505502 , -0.13350543]], dtype=float32)
time = 194	action = 1	current_phase = 0	next_phase = 1	reward = -2.985877	array([[-0.94725895, -0.13521828]], dtype=float32)
time = 202	action = 0	current_phase = 1	next_phase = 0	reward = -1.832859	array([[1.0331501 , 0.56533015]], dtype=float32)
time = 207	action = 0	current_phase = 1	next_phase = 0	reward = -2.019205	array([[0.9909307, 0.5914899]], dtype=float32)
time = 212	action = 0	current_phase = 1	next_phase = 0	reward = -2.044269	array([[0.99047124, 0.5901984 ]], dtype=float32)
time = 217	action = 0	current_phase = 1	next_phase = 0	reward = -1.207141	array([[0.9749608, 0.5953853]], dtype=float32)
time = 222	action = 1	current_phase = 1	next_phase = 0	reward = -2.317739	array([[0.9835642 , 0.60132474]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = -0.413167	array([[-0.9490673 , -0.13328809]], dtype=float32)
time = 235	action = 1	current_phase = 0	next_phase = 1	reward = -1.662034	array([[-0.9605173 , -0.17927133]], dtype=float32)
time = 243	action = 0	current_phase = 1	next_phase = 0	reward = -0.966920	array([[1.0708784 , 0.55465287]], dtype=float32)
time = 248	action = 0	current_phase = 1	next_phase = 0	reward = -1.120358	array([[0.9954965 , 0.59996974]], dtype=float32)
time = 253	action = 0	current_phase = 1	next_phase = 0	reward = -0.899967	array([[1.0164156, 0.6025807]], dtype=float32)
time = 258	action = 0	current_phase = 1	next_phase = 0	reward = -1.088224	array([[1.023762 , 0.5965471]], dtype=float32)
time = 263	action = 1	current_phase = 1	next_phase = 0	reward = -2.546787	array([[1.0124869, 0.5969035]], dtype=float32)
time = 271	action = 0	current_phase = 0	next_phase = 1	reward = 0.004413	array([[-0.9486795 , -0.09992527]], dtype=float32)
time = 276	action = 1	current_phase = 0	next_phase = 1	reward = -2.163371	array([[-0.9283985 , -0.12027957]], dtype=float32)
time = 284	action = 0	current_phase = 1	next_phase = 0	reward = -1.097781	array([[1.017253  , 0.58020717]], dtype=float32)
time = 289	action = 0	current_phase = 1	next_phase = 0	reward = -1.407136	array([[0.9709351, 0.608238 ]], dtype=float32)
time = 294	action = 0	current_phase = 1	next_phase = 0	reward = -1.801041	array([[0.9591462, 0.607097 ]], dtype=float32)
time = 299	action = 0	current_phase = 1	next_phase = 0	reward = -1.573317	array([[0.96262085, 0.608699  ]], dtype=float32)
time = 304	action = 1	current_phase = 1	next_phase = 0	reward = -2.691964	array([[0.9630796, 0.6093923]], dtype=float32)
time = 312	action = 0	current_phase = 0	next_phase = 1	reward = -0.248190	array([[-0.93637955, -0.0987798 ]], dtype=float32)
time = 317	action = 1	current_phase = 0	next_phase = 1	reward = -2.414097	array([[-0.92241293, -0.13492098]], dtype=float32)
time = 325	action = 0	current_phase = 1	next_phase = 0	reward = -0.862676	array([[1.0317127, 0.5515288]], dtype=float32)
time = 330	action = 0	current_phase = 1	next_phase = 0	reward = -0.976521	array([[0.9559051 , 0.59532386]], dtype=float32)
time = 335	action = 0	current_phase = 1	next_phase = 0	reward = -1.222754	array([[0.9449673, 0.6098228]], dtype=float32)
time = 340	action = 0	current_phase = 1	next_phase = 0	reward = -0.694170	array([[0.9628986, 0.6067971]], dtype=float32)
time = 345	action = 1	current_phase = 1	next_phase = 0	reward = -1.338640	array([[0.99023676, 0.59770906]], dtype=float32)
time = 353	action = 0	current_phase = 0	next_phase = 1	reward = 0.735659	array([[-1.0019554 , -0.14482453]], dtype=float32)Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 2256ms
 Real time factor: 296.543
 UPS: 4308.953901
Vehicles: 
 Inserted: 258 (Loaded: 313)
 Running: 15
 Waiting: 1

DijkstraRouter answered 411 queries and explored 3.42 edges on average.
DijkstraRouter spent 1ms answering queries (0.00ms on average).

time = 358	action = 1	current_phase = 0	next_phase = 1	reward = -1.488473	array([[-0.9673326, -0.1919243]], dtype=float32)
time = 366	action = 0	current_phase = 1	next_phase = 0	reward = -0.789002	array([[1.0519208, 0.5607999]], dtype=float32)
time = 371	action = 0	current_phase = 1	next_phase = 0	reward = -1.027331	array([[1.0493958, 0.5694804]], dtype=float32)
time = 376	action = 0	current_phase = 1	next_phase = 0	reward = -0.825770	array([[1.0136341, 0.5827043]], dtype=float32)
time = 381	action = 0	current_phase = 1	next_phase = 0	reward = -1.327381	array([[1.0223937 , 0.57630885]], dtype=float32)
time = 386	action = 1	current_phase = 1	next_phase = 0	reward = -1.890273	array([[0.9974451, 0.5834677]], dtype=float32)
time = 394	action = 0	current_phase = 0	next_phase = 1	reward = -0.576038	array([[-0.9748116 , -0.16649836]], dtype=float32)
time = 399	action = 1	current_phase = 0	next_phase = 1	reward = -1.757112	array([[-0.9372603 , -0.17635253]], dtype=float32)
time = 407	action = 0	current_phase = 1	next_phase = 0	reward = -0.224859	array([[1.039324  , 0.56901777]], dtype=float32)
time = 412	action = 0	current_phase = 1	next_phase = 0	reward = -0.363485	array([[1.0000482 , 0.59855354]], dtype=float32)
time = 417	action = 0	current_phase = 1	next_phase = 0	reward = -0.831549	array([[1.0238537 , 0.59118825]], dtype=float32)
time = 422	action = 0	current_phase = 1	next_phase = 0	reward = -1.075437	array([[1.0378903 , 0.57538885]], dtype=float32)
time = 427	action = 1	current_phase = 1	next_phase = 0	reward = -2.100966	array([[1.0061704 , 0.59032524]], dtype=float32)
time = 435	action = 0	current_phase = 0	next_phase = 1	reward = -0.288711	array([[-0.989254  , -0.15607738]], dtype=float32)
time = 440	action = 1	current_phase = 0	next_phase = 1	reward = -1.331768	array([[-0.99247587, -0.17393355]], dtype=float32)
time = 448	action = 0	current_phase = 1	next_phase = 0	reward = -0.417553	array([[1.045374 , 0.5521038]], dtype=float32)
time = 453	action = 0	current_phase = 1	next_phase = 0	reward = -0.452603	array([[1.0301545 , 0.56909823]], dtype=float32)
time = 458	action = 0	current_phase = 1	next_phase = 0	reward = -0.597094	array([[1.0599624, 0.55591  ]], dtype=float32)
time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -0.577293	array([[1.0676689 , 0.54863065]], dtype=float32)
time = 468	action = 1	current_phase = 1	next_phase = 0	reward = -1.887543	array([[1.0368354 , 0.56545955]], dtype=float32)
time = 476	action = 0	current_phase = 0	next_phase = 1	reward = -0.732592	array([[-1.0056233 , -0.18909472]], dtype=float32)
time = 481	action = 1	current_phase = 0	next_phase = 1	reward = -1.847841	array([[-0.9695118 , -0.17753626]], dtype=float32)
time = 489	action = 0	current_phase = 1	next_phase = 0	reward = -0.400895	array([[1.0697149, 0.562748 ]], dtype=float32)
time = 494	action = 0	current_phase = 1	next_phase = 0	reward = -0.243858	array([[1.0371083 , 0.59315836]], dtype=float32)
time = 499	action = 0	current_phase = 1	next_phase = 0	reward = -0.475717	array([[1.050038 , 0.5955685]], dtype=float32)
time = 504	action = 0	current_phase = 1	next_phase = 0	reward = -0.984537	array([[1.0400896 , 0.59366745]], dtype=float32)
time = 509	action = 1	current_phase = 1	next_phase = 0	reward = -2.460871	array([[1.005443  , 0.61000663]], dtype=float32)
time = 517	action = 0	current_phase = 0	next_phase = 1	reward = -0.251245	array([[-0.9727203 , -0.10668743]], dtype=float32)
time = 522	action = 1	current_phase = 0	next_phase = 1	reward = -2.098313	array([[-0.9585789, -0.1183358]], dtype=float32)
time = 530	action = 0	current_phase = 1	next_phase = 0	reward = -1.575586	array([[1.0037661 , 0.55841863]], dtype=float32)
time = 535	action = 0	current_phase = 1	next_phase = 0	reward = -1.277429	array([[0.9491214, 0.5956546]], dtype=float32)
time = 540	action = 0	current_phase = 1	next_phase = 0	reward = -1.197406	array([[0.9490231, 0.6072118]], dtype=float32)
time = 545	action = 0	current_phase = 1	next_phase = 0	reward = -1.397865	array([[1.0104376 , 0.58814216]], dtype=float32)
time = 550	action = 1	current_phase = 1	next_phase = 0	reward = -1.583028	array([[0.97112846, 0.606862  ]], dtype=float32)
time = 558	action = 0	current_phase = 0	next_phase = 1	reward = 0.431608	array([[-0.98186964, -0.1152465 ]], dtype=float32)
time = 563	action = 1	current_phase = 0	next_phase = 1	reward = -1.209380	array([[-0.94642735, -0.1507208 ]], dtype=float32)
time = 571	action = 0	current_phase = 1	next_phase = 0	reward = -0.586343	array([[1.0645038, 0.5421642]], dtype=float32)
time = 576	action = 0	current_phase = 1	next_phase = 0	reward = -0.599887	array([[1.0131842, 0.5722208]], dtype=float32)
time = 581	action = 0	current_phase = 1	next_phase = 0	reward = -0.634449	array([[1.019365  , 0.57916254]], dtype=float32)
time = 586	action = 0	current_phase = 1	next_phase = 0	reward = -0.388601	array([[1.0319432, 0.5795092]], dtype=float32)
time = 591	action = 1	current_phase = 1	next_phase = 0	reward = -1.149695	array([[1.0342541, 0.5804479]], dtype=float32)
time = 599	action = 0	current_phase = 0	next_phase = 1	reward = -0.195765	array([[-0.96946657, -0.14310236]], dtype=float32)
time = 604	action = 1	current_phase = 0	next_phase = 1	reward = -1.193298	array([[-0.9541074 , -0.15359072]], dtype=float32)
time = 612	action = 0	current_phase = 1	next_phase = 0	reward = -0.639180	array([[1.0317338, 0.5788067]], dtype=float32)
time = 617	action = 0	current_phase = 1	next_phase = 0	reward = -1.047909	array([[1.0035722, 0.5886292]], dtype=float32)
time = 622	action = 0	current_phase = 1	next_phase = 0	reward = -1.134265	array([[1.0166618, 0.5899118]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -1.073513	array([[1.0074987, 0.5888192]], dtype=float32)
time = 632	action = 1	current_phase = 1	next_phase = 0	reward = -1.890676	array([[1.0170408 , 0.58962107]], dtype=float32)
time = 640	action = 0	current_phase = 0	next_phase = 1	reward = -0.271323	array([[-0.9613206 , -0.14280921]], dtype=float32)
time = 645	action = 1	current_phase = 0	next_phase = 1	reward = -1.657603	array([[-0.9735098 , -0.16191514]], dtype=float32)
time = 653	action = 0	current_phase = 1	next_phase = 0	reward = -0.342166	array([[1.0510107, 0.5617767]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -0.656341	array([[1.0244594 , 0.58878183]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.783314	array([[1.0225714, 0.5853956]], dtype=float32)
Terminal occured. Episode end.
Train on 1113 samples, validate on 478 samples
Epoch 1/500
 - 1s - loss: 1.0001 - val_loss: 0.3419
Epoch 2/500
 - 1s - loss: 0.2420 - val_loss: 0.1817
Epoch 3/500
 - 1s - loss: 0.1846 - val_loss: 0.1601
Epoch 4/500
 - 1s - loss: 0.1642 - val_loss: 0.1398
Epoch 5/500
 - 1s - loss: 0.1452 - val_loss: 0.1230
Epoch 6/500
 - 1s - loss: 0.1333 - val_loss: 0.1101
Epoch 7/500
 - 1s - loss: 0.1244 - val_loss: 0.1019
Epoch 8/500
 - 1s - loss: 0.1122 - val_loss: 0.0971
Epoch 9/500
 - 1s - loss: 0.1077 - val_loss: 0.0895
Epoch 10/500
 - 1s - loss: 0.1038 - val_loss: 0.0872
Epoch 11/500
 - 1s - loss: 0.0954 - val_loss: 0.0849
Epoch 12/500
 - 1s - loss: 0.0958 - val_loss: 0.0836
Epoch 13/500
 - 1s - loss: 0.0891 - val_loss: 0.0821
Epoch 14/500
 - 1s - loss: 0.0865 - val_loss: 0.0775
Epoch 15/500
 - 1s - loss: 0.0844 - val_loss: 0.0747
Epoch 16/500
 - 1s - loss: 0.0787 - val_loss: 0.0708
Epoch 17/500
 - 1s - loss: 0.0787 - val_loss: 0.0735
Epoch 18/500
 - 1s - loss: 0.0766 - val_loss: 0.0691
Epoch 19/500
 - 1s - loss: 0.0751 - val_loss: 0.0686
Epoch 20/500
 - 1s - loss: 0.0693 - val_loss: 0.0650
Epoch 21/500
 - 1s - loss: 0.0669 - val_loss: 0.0679
Epoch 22/500
 - 1s - loss: 0.0673 - val_loss: 0.0724
Epoch 23/500
 - 1s - loss: 0.0643 - val_loss: 0.0637
Epoch 24/500
 - 1s - loss: 0.0660 - val_loss: 0.0637
Epoch 25/500
 - 1s - loss: 0.0609 - val_loss: 0.0605
Epoch 26/500
 - 1s - loss: 0.0583 - val_loss: 0.0610
Epoch 27/500
 - 1s - loss: 0.0592 - val_loss: 0.0570
Epoch 28/500
 - 1s - loss: 0.0558 - val_loss: 0.0571
Epoch 29/500
 - 1s - loss: 0.0547 - val_loss: 0.0604
Epoch 30/500
 - 1s - loss: 0.0552 - val_loss: 0.0595
Epoch 31/500
 - 1s - loss: 0.0539 - val_loss: 0.0587
Epoch 32/500
 - 1s - loss: 0.0486 - val_loss: 0.0569
Epoch 33/500
 - 1s - loss: 0.0487 - val_loss: 0.0547
Epoch 34/500
 - 1s - loss: 0.0468 - val_loss: 0.0559
Epoch 35/500
 - 1s - loss: 0.0470 - val_loss: 0.0650
Epoch 36/500
 - 1s - loss: 0.0463 - val_loss: 0.0556
Epoch 37/500
 - 1s - loss: 0.0441 - val_loss: 0.0580
Epoch 38/500
 - 1s - loss: 0.0431 - val_loss: 0.0573
Epoch 39/500
 - 1s - loss: 0.0434 - val_loss: 0.0569
Epoch 40/500
 - 1s - loss: 0.0424 - val_loss: 0.0563
Epoch 41/500
 - 1s - loss: 0.0416 - val_loss: 0.0547
Epoch 42/500
 - 1s - loss: 0.0416 - val_loss: 0.0539
Epoch 43/500
 - 1s - loss: 0.0404 - val_loss: 0.0550
Epoch 44/500
 - 1s - loss: 0.0373 - val_loss: 0.0542
Epoch 45/500
 - 1s - loss: 0.0357 - val_loss: 0.0574
Epoch 46/500
 - 1s - loss: 0.0366 - val_loss: 0.0551
Epoch 47/500
 - 1s - loss: 0.0361 - val_loss: 0.0589
Epoch 48/500
 - 1s - loss: 0.0371 - val_loss: 0.0553
Epoch 49/500
 - 1s - loss: 0.0337 - val_loss: 0.0557
Epoch 50/500
 - 1s - loss: 0.0336 - val_loss: 0.0558
Epoch 51/500
 - 1s - loss: 0.0362 - val_loss: 0.0541
Epoch 52/500
 - 1s - loss: 0.0362 - val_loss: 0.0594
Loading configuration... done.
***Starting server on port 37457 ***
Loading net-file from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.net.xml'... done (4ms).
Loading additional-files from '/home/tahiti/下载/one_intersection_kingsford/data/one_run/cross.tls.switch.xml'... 
Loading of additional-files failed.
length of memory (state 0, action 0): 507, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
END
Could not connect to TraCI server at localhost:37457 [Errno 111] Connection refused
 Retrying in 1 seconds
