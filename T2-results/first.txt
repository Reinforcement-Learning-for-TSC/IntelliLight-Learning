/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/soup/sumo-0.32.0/tools
Using TensorFlow backend.
2021-07-06 18:55:40.373501: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_map_feature (InputLayer)  (None, 150, 150, 1)  0                                            
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, 38, 38, 32)   2048        input_map_feature[0][0]          
__________________________________________________________________________________________________
bn1 (BatchNormalization)        (None, 38, 38, 32)   96          conv1[0][0]                      
__________________________________________________________________________________________________
act1 (Activation)               (None, 38, 38, 32)   0           bn1[0][0]                        
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 19, 19, 32)   0           act1[0][0]                       
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 19, 19, 32)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2 (Conv2D)                  (None, 10, 10, 16)   8192        dropout_1[0][0]                  
__________________________________________________________________________________________________
bn2 (BatchNormalization)        (None, 10, 10, 16)   48          conv2[0][0]                      
__________________________________________________________________________________________________
act2 (Activation)               (None, 10, 10, 16)   0           bn2[0][0]                        
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 16)     0           act2[0][0]                       
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 5, 5, 16)     0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
input_cur_phase (InputLayer)    (None, 1)            0                                            
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 400)          0           dropout_2[0][0]                  
__________________________________________________________________________________________________
input_next_phase (InputLayer)   (None, 1)            0                                            
__________________________________________________________________________________________________
input_num_of_vehicles (InputLay (None, 12)           0                                            
__________________________________________________________________________________________________
input_queue_length (InputLayer) (None, 12)           0                                            
__________________________________________________________________________________________________
input_waiting_time (InputLayer) (None, 12)           0                                            
__________________________________________________________________________________________________
all_flatten_feature (Concatenat (None, 438)          0           input_cur_phase[0][0]            
                                                                 flatten_1[0][0]                  
                                                                 input_next_phase[0][0]           
                                                                 input_num_of_vehicles[0][0]      
                                                                 input_queue_length[0][0]         
                                                                 input_waiting_time[0][0]         
__________________________________________________________________________________________________
hidden_shared_1 (Dense)         (None, 20)           8780        all_flatten_feature[0][0]        
__________________________________________________________________________________________________
hidden_separate_branch_0_1 (Den (None, 20)           420         hidden_shared_1[0][0]            
__________________________________________________________________________________________________
hidden_separate_branch_1_1 (Den (None, 20)           420         hidden_shared_1[0][0]            
__________________________________________________________________________________________________
q_values_separate_branch_0 (Den (None, 2)            42          hidden_separate_branch_0_1[0][0] 
__________________________________________________________________________________________________
selector_0 (Selector)           (None, 1)            0           input_cur_phase[0][0]            
__________________________________________________________________________________________________
q_values_separate_branch_1 (Den (None, 2)            42          hidden_separate_branch_1_1[0][0] 
__________________________________________________________________________________________________
selector_1 (Selector)           (None, 1)            0           input_cur_phase[0][0]            
__________________________________________________________________________________________________
multiply_0 (Multiply)           (None, 2)            0           q_values_separate_branch_0[0][0] 
                                                                 selector_0[0][0]                 
__________________________________________________________________________________________________
multiply_1 (Multiply)           (None, 2)            0           q_values_separate_branch_1[0][0] 
                                                                 selector_1[0][0]                 
__________________________________________________________________________________________________
add_1 (Add)                     (None, 2)            0           multiply_0[0][0]                 
                                                                 multiply_1[0][0]                 
==================================================================================================
Total params: 20,088
Trainable params: 19,992
Non-trainable params: 96
__________________________________________________________________________________________________
Could not connect to TraCI server at localhost:37523 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 37523 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.899535	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -2.006765	array([[1.0501    , 0.61237735]], dtype=float32)
time = 43	action = 1	current_phase = 1	next_phase = 0	reward = -1.893735	array([[1.0481704, 0.6200118]], dtype=float32)
time = 51	action = 0	current_phase = 0	next_phase = 1	reward = 1.609935	array([[-0.9977285 , -0.17391782]], dtype=float32)
time = 56	action = 1	current_phase = 0	next_phase = 1	reward = -4.342611	array([[-0.99243903, -0.16510208]], dtype=float32)
time = 64	action = 0	current_phase = 1	next_phase = 0	reward = -4.041409	array([[1.056722 , 0.6225092]], dtype=float32)
time = 69	action = 1	current_phase = 1	next_phase = 0	reward = -3.937807	array([[1.0552511 , 0.63026285]], dtype=float32)
time = 77	action = 0	current_phase = 0	next_phase = 1	reward = 1.656507	array([[-0.98917717, -0.16474491]], dtype=float32)
time = 82	action = 1	current_phase = 0	next_phase = 1	reward = -4.804911	array([[-0.9962327, -0.1731681]], dtype=float32)
time = 90	action = 0	current_phase = 1	next_phase = 0	reward = -5.589705	array([[1.05529  , 0.6270443]], dtype=float32)
time = 95	action = 1	current_phase = 1	next_phase = 0	reward = -7.364739	array([[1.0557051, 0.6366164]], dtype=float32)
time = 103	action = 0	current_phase = 0	next_phase = 1	reward = 1.578590	array([[-0.97563016, -0.15573944]], dtype=float32)
time = 108	action = 1	current_phase = 0	next_phase = 1	reward = -5.062315	array([[-0.99522185, -0.15547094]], dtype=float32)
time = 116	action = 0	current_phase = 1	next_phase = 0	reward = -6.688733	array([[1.0715723 , 0.63040537]], dtype=float32)
time = 121	action = 1	current_phase = 1	next_phase = 0	reward = -10.366121	array([[1.0583348 , 0.64685905]], dtype=float32)
time = 129	action = 0	current_phase = 0	next_phase = 1	reward = 0.296656	array([[-0.98288596, -0.17515057]], dtype=float32)
time = 134	action = 1	current_phase = 0	next_phase = 1	reward = -5.542256	array([[-0.99852806, -0.16050565]], dtype=float32)
time = 142	action = 0	current_phase = 1	next_phase = 0	reward = -7.054973	array([[1.0704721, 0.6323222]], dtype=float32)
time = 147	action = 1	current_phase = 1	next_phase = 0	reward = -12.590468	array([[1.0551798, 0.6516791]], dtype=float32)
time = 155	action = 0	current_phase = 0	next_phase = 1	reward = -1.694248	array([[-0.97306263, -0.19001165]], dtype=float32)
time = 160	action = 1	current_phase = 0	next_phase = 1	reward = -6.526306	array([[-0.9860475 , -0.16901429]], dtype=float32)
time = 168	action = 0	current_phase = 1	next_phase = 0	reward = -7.404295	array([[1.0695907, 0.6398419]], dtype=float32)
time = 173	action = 1	current_phase = 1	next_phase = 0	reward = -14.121295	array([[1.053276  , 0.65915054]], dtype=float32)
time = 181	action = 0	current_phase = 0	next_phase = 1	reward = -4.052792	array([[-0.96500164, -0.19921602]], dtype=float32)
time = 186	action = 1	current_phase = 0	next_phase = 1	reward = -9.233904	array([[-0.9710317 , -0.19827534]], dtype=float32)
time = 194	action = 0	current_phase = 1	next_phase = 0	reward = -7.764855	array([[1.0681533 , 0.64738965]], dtype=float32)
time = 199	action = 1	current_phase = 1	next_phase = 0	reward = -15.386499	array([[1.0596989 , 0.66287804]], dtype=float32)
time = 207	action = 0	current_phase = 0	next_phase = 1	reward = -4.669796	array([[-0.96139  , -0.1991524]], dtype=float32)
time = 212	action = 1	current_phase = 0	next_phase = 1	reward = -12.686222	array([[-0.96381783, -0.19610195]], dtype=float32)
time = 220	action = 0	current_phase = 1	next_phase = 0	reward = -8.324778	array([[1.0633564 , 0.66213703]], dtype=float32)
time = 225	action = 1	current_phase = 1	next_phase = 0	reward = -14.316547	array([[1.058668  , 0.66934496]], dtype=float32)
time = 233	action = 0	current_phase = 0	next_phase = 1	reward = -7.341361	array([[-0.96953887, -0.19863458]], dtype=float32)
time = 238	action = 1	current_phase = 0	next_phase = 1	reward = -16.594321	array([[-0.9757405 , -0.18483967]], dtype=float32)
time = 246	action = 0	current_phase = 1	next_phase = 0	reward = -10.011559	array([[1.0572205, 0.6722911]], dtype=float32)
time = 251	action = 1	current_phase = 1	next_phase = 0	reward = -15.090353	array([[1.0571142, 0.6759217]], dtype=float32)
time = 259	action = 0	current_phase = 0	next_phase = 1	reward = -6.699790	array([[-0.9772577 , -0.19668964]], dtype=float32)
time = 264	action = 1	current_phase = 0	next_phase = 1	reward = -17.104620	array([[-0.984268  , -0.18706796]], dtype=float32)
time = 272	action = 0	current_phase = 1	next_phase = 0	reward = -11.767512	array([[1.0589385 , 0.67490226]], dtype=float32)
time = 277	action = 1	current_phase = 1	next_phase = 0	reward = -15.825715	array([[1.0557003 , 0.68091094]], dtype=float32)
time = 285	action = 0	current_phase = 0	next_phase = 1	reward = -4.752481	array([[-0.97520417, -0.18593091]], dtype=float32)
time = 290	action = 1	current_phase = 0	next_phase = 1	reward = -16.939760	array([[-0.9780218 , -0.18349247]], dtype=float32)
time = 298	action = 0	current_phase = 1	next_phase = 0	reward = -13.162827	array([[1.0515463 , 0.68810564]], dtype=float32)
time = 303	action = 1	current_phase = 1	next_phase = 0	reward = -16.732012	array([[1.04386  , 0.6952491]], dtype=float32)
time = 311	action = 0	current_phase = 0	next_phase = 1	reward = -4.268665	array([[-0.967611  , -0.19466548]], dtype=float32)
time = 316	action = 1	current_phase = 0	next_phase = 1	reward = -16.926987	array([[-0.9677319 , -0.18860972]], dtype=float32)
time = 324	action = 0	current_phase = 1	next_phase = 0	reward = -13.583022	array([[1.055858  , 0.69191426]], dtype=float32)
time = 329	action = 1	current_phase = 1	next_phase = 0	reward = -18.461249	array([[1.0404203, 0.7040614]], dtype=float32)
time = 337	action = 0	current_phase = 0	next_phase = 1	reward = -4.851287	array([[-0.9604447 , -0.18761434]], dtype=float32)
time = 342	action = 1	current_phase = 0	next_phase = 1	reward = -16.946355	array([[-0.96718806, -0.18742076]], dtype=float32)
time = 350	action = 0	current_phase = 1	next_phase = 0	reward = -13.848217	array([[1.0576656 , 0.69626546]], dtype=float32)
time = 355	action = 1	current_phase = 1	next_phase = 0	reward = -21.372474	array([[1.0509136, 0.705996 ]], dtype=float32)
time = 363	action = 0	current_phase = 0	next_phase = 1	reward = -5.970843	array([[-0.9593549 , -0.19003016]], dtype=float32)
time = 368	action = 1	current_phase = 0	next_phase = 1	reward = -17.310359	array([[-0.966412  , -0.17997697]], dtype=float32)
time = 376	action = 0	current_phase = 1	next_phase = 0	reward = -13.627443	array([[1.0643557, 0.6933575]], dtype=float32)
time = 381	action = 1	current_phase = 1	next_phase = 0	reward = -20.335870	array([[1.0564449 , 0.70240116]], dtype=float32)
time = 389	action = 0	current_phase = 0	next_phase = 1	reward = -6.308470	array([[-0.96835184, -0.20370999]], dtype=float32)
time = 394	action = 1	current_phase = 0	next_phase = 1	reward = -17.051770	array([[-0.9716324 , -0.20100029]], dtype=float32)
time = 402	action = 0	current_phase = 1	next_phase = 0	reward = -13.274801	array([[1.0779064, 0.6817552]], dtype=float32)
time = 407	action = 1	current_phase = 1	next_phase = 0	reward = -19.136025	array([[1.0710766 , 0.69461817]], dtype=float32)
time = 415	action = 0	current_phase = 0	next_phase = 1	reward = -7.921341	array([[-0.96474046, -0.20568644]], dtype=float32)
time = 420	action = 1	current_phase = 0	next_phase = 1	reward = -17.588909	array([[-0.97200465, -0.19645704]], dtype=float32)
time = 428	action = 0	current_phase = 1	next_phase = 0	reward = -13.989972	array([[1.0730927, 0.690462 ]], dtype=float32)
time = 433	action = 1	current_phase = 1	next_phase = 0	reward = -21.254247	array([[1.0709239, 0.697165 ]], dtype=float32)
time = 441	action = 0	current_phase = 0	next_phase = 1	reward = -8.380441	array([[-0.96139896, -0.21389762]], dtype=float32)
time = 446	action = 1	current_phase = 0	next_phase = 1	reward = -21.391641	array([[-0.9635059 , -0.20911427]], dtype=float32)
time = 454	action = 0	current_phase = 1	next_phase = 0	reward = -14.053104	array([[1.0730349 , 0.69626135]], dtype=float32)
time = 459	action = 1	current_phase = 1	next_phase = 0	reward = -22.287477	array([[1.0740093, 0.6972506]], dtype=float32)
time = 467	action = 0	current_phase = 0	next_phase = 1	reward = -8.661830	array([[-0.9606294 , -0.21751693]], dtype=float32)
time = 472	action = 1	current_phase = 0	next_phase = 1	reward = -23.274103	array([[-0.9650423 , -0.21256326]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -15.772335	array([[1.0757073, 0.6965107]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -21.528681	array([[1.0750523, 0.6997316]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -8.923520	array([[-0.9606182 , -0.21213229]], dtype=float32)
time = 498	action = 1	current_phase = 0	next_phase = 1	reward = -24.020379	array([[-0.961558  , -0.20968081]], dtype=float32)
time = 506	action = 0	current_phase = 1	next_phase = 0	reward = -15.509632	array([[1.0791721 , 0.69952124]], dtype=float32)
time = 511	action = 1	current_phase = 1	next_phase = 0	reward = -21.375626	array([[1.0807987 , 0.69914687]], dtype=float32)
time = 519	action = 0	current_phase = 0	next_phase = 1	reward = -9.216458	array([[-0.95831287, -0.21942621]], dtype=float32)
time = 524	action = 1	current_phase = 0	next_phase = 1	reward = -24.841807	array([[-0.96168125, -0.21211393]], dtype=float32)
time = 532	action = 0	current_phase = 1	next_phase = 0	reward = -16.201114	array([[1.0814637, 0.6958658]], dtype=float32)
time = 537	action = 1	current_phase = 1	next_phase = 0	reward = -21.349115	array([[1.0809525, 0.7009509]], dtype=float32)
time = 545	action = 0	current_phase = 0	next_phase = 1	reward = -6.512091	array([[-0.9627131 , -0.20723866]], dtype=float32)
time = 550	action = 1	current_phase = 0	next_phase = 1	reward = -22.427281	array([[-0.9622167 , -0.20518771]], dtype=float32)
time = 558	action = 0	current_phase = 1	next_phase = 0	reward = -15.878620	array([[1.0787191, 0.7034047]], dtype=float32)
time = 563	action = 1	current_phase = 1	next_phase = 0	reward = -23.499406	array([[1.0793487, 0.7080784]], dtype=float32)
time = 571	action = 0	current_phase = 0	next_phase = 1	reward = -8.381219	array([[-0.9562941, -0.2269871]], dtype=float32)
time = 576	action = 1	current_phase = 0	next_phase = 1	reward = -26.503761	array([[-0.95986784, -0.21960472]], dtype=float32)
time = 584	action = 0	current_phase = 1	next_phase = 0	reward = -18.137014	array([[1.0808862, 0.7035414]], dtype=float32)
time = 589	action = 1	current_phase = 1	next_phase = 0	reward = -25.607567	array([[1.0826932, 0.704762 ]], dtype=float32)
time = 597	action = 0	current_phase = 0	next_phase = 1	reward = -6.338398	array([[-0.9540477 , -0.22653145]], dtype=float32)
time = 602	action = 1	current_phase = 0	next_phase = 1	reward = -24.978834	array([[-0.9572401 , -0.21919139]], dtype=float32)
time = 610	action = 0	current_phase = 1	next_phase = 0	reward = -17.540460	array([[1.0809362, 0.7078559]], dtype=float32)
time = 615	action = 1	current_phase = 1	next_phase = 0	reward = -23.613637	array([[1.0818149, 0.7114298]], dtype=float32)
time = 623	action = 0	current_phase = 0	next_phase = 1	reward = -8.633242	array([[-0.9519048, -0.2230922]], dtype=float32)
time = 628	action = 1	current_phase = 0	next_phase = 1	reward = -24.303210	array([[-0.9589374 , -0.21162994]], dtype=float32)
time = 636	action = 0	current_phase = 1	next_phase = 0	reward = -17.122332	array([[1.085405 , 0.7040961]], dtype=float32)
time = 641	action = 1	current_phase = 1	next_phase = 0	reward = -22.717267	array([[1.0840276 , 0.71347255]], dtype=float32)
time = 649	action = 0	current_phase = 0	next_phase = 1	reward = -8.789422	array([[-0.9539961 , -0.21229088]], dtype=float32)
time = 654	action = 1	current_phase = 0	next_phase = 1	reward = -23.139641	array([[-0.9532292 , -0.20855376]], dtype=float32)
time = 662	action = 0	current_phase = 1	next_phase = 0	reward = -17.051688	array([[1.0819571, 0.7105781]], dtype=float32)
time = 667	action = 1	current_phase = 1	next_phase = 0	reward = -24.648724	array([[1.0819998, 0.7184846]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 676.00
Reason: TraCI requested termination.
Performance: 
 Duration: 129745ms
 Real time factor: 5.21022
 UPS: 634.675710
Vehicles: 
 Inserted: 542
 Running: 216
 Waiting: 0

DijkstraRouter answered 542 queries and explored 2.00 edges on average.
DijkstraRouter spent 3ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:44919 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 44919 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = 0.332082	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.631275	array([[-1.0093249, -0.1566797]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.009262	array([[1.0397912, 0.6119434]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.103357	array([[1.0410347, 0.6186117]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = 1.951576	array([[-1.0033814 , -0.18086743]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = 1.915048	array([[-1.0018293 , -0.18147594]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.634411	array([[-0.994789  , -0.16619098]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -2.180837	array([[1.0407791 , 0.61343837]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -1.837911	array([[1.0406486, 0.6192913]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = 1.949867	array([[-1.0015337 , -0.17245653]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = 1.904299	array([[-1.0097965 , -0.17793402]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.259905	array([[-1.0010374 , -0.16093549]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -2.319951	array([[1.045012 , 0.6132879]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -2.175895	array([[1.0433769, 0.6207578]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = 1.347188	array([[-1.0082922 , -0.15806115]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = 2.542957	array([[-1.0144387 , -0.14534919]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -2.553160	array([[-1.009169 , -0.1470215]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -2.673213	array([[1.0604286, 0.6071538]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -2.508966	array([[1.0573162, 0.6148357]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = 1.668825	array([[-1.0080382 , -0.15907565]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = 2.528793	array([[-1.0041106 , -0.15159622]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.754316	array([[-1.0120759 , -0.15665734]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -2.935191	array([[1.0566545 , 0.60729456]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -2.733921	array([[1.0532198, 0.6161437]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = 1.998653	array([[-1.0256141 , -0.14685836]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = 2.236359	array([[-1.0246161, -0.1475657]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -3.481899	array([[-1.0123944 , -0.15275568]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -3.164269	array([[1.0404949, 0.6184031]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -3.517448	array([[1.0406492, 0.6252192]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = 2.026763	array([[-1.0006597 , -0.16249637]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = 2.562139	array([[-0.9984434 , -0.16333368]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -3.606913	array([[-1.0066944 , -0.16838792]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.434967	array([[1.0391185 , 0.61883974]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -3.309516	array([[1.0404627, 0.6266601]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = 1.695351	array([[-1.0027924 , -0.17129341]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = 2.596370	array([[-1.0112767 , -0.16773447]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -3.616794	array([[-1.0065253 , -0.16831592]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -3.711846	array([[1.0435834, 0.620731 ]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -3.695056	array([[1.0425024 , 0.62670183]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 1.708846	array([[-1.0095357, -0.1573323]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = 2.628867	array([[-1.019409  , -0.15328299]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -3.850258	array([[-1.014692  , -0.15520476]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -3.847455	array([[1.0555832, 0.6156994]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -4.543229	array([[1.0562617 , 0.62214005]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = 2.073758	array([[-1.0274532 , -0.15652123]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = 2.013483	array([[-1.026699  , -0.15684816]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -4.535720	array([[-1.0265561 , -0.15817198]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -4.870435	array([[1.0506743 , 0.61571765]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -5.584141	array([[1.0477855 , 0.62289727]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = 0.891578	array([[-1.017804  , -0.17059475]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = 3.095611	array([[-1.0235643 , -0.13905706]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -5.107084	array([[-1.014294  , -0.14342351]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -5.348718	array([[1.0315406 , 0.63877857]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -5.932341	array([[1.0307713, 0.644784 ]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = 1.423304	array([[-1.0061542 , -0.16756813]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = 2.422321	array([[-1.0033021 , -0.16133393]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -4.783484	array([[-1.0096219 , -0.15747002]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -5.483628	array([[1.0294176 , 0.63881326]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -7.352197	array([[1.0308024, 0.6449783]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = 1.673164	array([[-1.0136291 , -0.16529153]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = 3.154497	array([[-1.0137968 , -0.16448805]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -3.997271	array([[-1.0083896, -0.1563606]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -5.534033	array([[1.0326662 , 0.63605124]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -7.130626	array([[1.0308568, 0.6467951]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = 0.852675	array([[-1.0074787, -0.1715205]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = 3.532744	array([[-1.0177265 , -0.14380933]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -4.584562	array([[-1.0160986 , -0.14446828]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -5.901758	array([[1.0413638 , 0.63421595]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -7.161551	array([[1.0422684, 0.6426672]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 1.510488	array([[-1.0134411 , -0.16355753]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = 2.504940	array([[-1.0260786, -0.1376602]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -4.980837	array([[-1.0155741 , -0.14614797]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -6.145734	array([[1.0418621 , 0.63270366]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -7.666367	array([[1.0348151 , 0.64465666]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = 1.392243	array([[-1.014826 , -0.1710413]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = 2.874683	array([[-1.0264891, -0.1463026]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -5.039169	array([[-1.0152811 , -0.14303084]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -6.151464	array([[1.0291562, 0.6452917]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -8.204199	array([[1.0280739, 0.6518299]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = 1.102939	array([[-0.99709237, -0.17963377]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = 2.889606	array([[-1.0073352 , -0.17011863]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -4.558609	array([[-1.0099713 , -0.15789023]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -6.225451	array([[1.0320148 , 0.64352655]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -8.333044	array([[1.0280763 , 0.65138924]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = 0.903633	array([[-0.99590045, -0.1802457 ]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = 2.551676	array([[-1.0055206 , -0.16970262]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -4.756932	array([[-1.0038117 , -0.16239963]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -6.668629	array([[1.0357436 , 0.64126015]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -9.198174	array([[1.0283564, 0.6544963]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = 0.964597	array([[-0.9982276 , -0.17859802]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = 2.226323	array([[-1.0118464 , -0.15318064]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -4.746227	array([[-1.0110383, -0.1494056]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -6.669148	array([[1.04919  , 0.6380296]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -9.629496	array([[1.0381883 , 0.65025306]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.866101	array([[-0.9941325, -0.1789906]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 2.158065	array([[-1.0050799 , -0.15845796]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -5.616974	array([[-1.0023994 , -0.15171146]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -7.272044	array([[1.048004 , 0.6396942]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -11.254474	array([[1.0358102 , 0.65307146]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.415472	array([[-0.9880291 , -0.17754906]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 3.204321	array([[-1.0048233 , -0.16632533]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -4.454576	array([[-1.00438   , -0.15345189]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -6.446898	array([[1.0311955 , 0.64680827]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 63487ms
 Real time factor: 10.5376
 UPS: 604.895490
Vehicles: 
 Inserted: 536
 Running: 74
 Waiting: 0

DijkstraRouter answered 536 queries and explored 2.00 edges on average.
DijkstraRouter spent 1ms answering queries (0.00ms on average).
Could not connect to TraCI server at localhost:47111 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 47111 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (3ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = 0.332082	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.631275	array([[-1.0093249, -0.1566797]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.009262	array([[1.0397912, 0.6119434]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.103357	array([[1.0410347, 0.6186117]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = 1.951576	array([[-1.0033814 , -0.18086743]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = 1.915048	array([[-1.0018293 , -0.18147594]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.634411	array([[-0.994789  , -0.16619098]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -2.180837	array([[1.0407791 , 0.61343837]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -1.837911	array([[1.0406486, 0.6192913]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = 1.949867	array([[-1.0015337 , -0.17245653]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = 1.904299	array([[-1.0097965 , -0.17793402]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.259905	array([[-1.0010374 , -0.16093549]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -2.319951	array([[1.045012 , 0.6132879]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -2.175895	array([[1.0433769, 0.6207578]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = 1.347188	array([[-1.0082922 , -0.15806115]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = 2.542957	array([[-1.0144387 , -0.14534919]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -2.553160	array([[-1.009169 , -0.1470215]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -2.673213	array([[1.0604286, 0.6071538]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -2.508966	array([[1.0573162, 0.6148357]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = 1.668825	array([[-1.0080382 , -0.15907565]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = 2.528793	array([[-1.0041106 , -0.15159622]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.754316	array([[-1.0120759 , -0.15665734]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -2.935191	array([[1.0566545 , 0.60729456]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -2.733921	array([[1.0532198, 0.6161437]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = 1.998653	array([[-1.0256141 , -0.14685836]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = 2.236359	array([[-1.0246161, -0.1475657]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -3.481899	array([[-1.0123944 , -0.15275568]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -3.164269	array([[1.0404949, 0.6184031]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -3.517448	array([[1.0406492, 0.6252192]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = 2.026763	array([[-1.0006597 , -0.16249637]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = 2.562139	array([[-0.9984434 , -0.16333368]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -3.606913	array([[-1.0066944 , -0.16838792]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.434967	array([[1.0391185 , 0.61883974]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -3.309516	array([[1.0404627, 0.6266601]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = 1.695351	array([[-1.0027924 , -0.17129341]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = 2.596370	array([[-1.0112767 , -0.16773447]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -3.616794	array([[-1.0065253 , -0.16831592]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -3.711846	array([[1.0435834, 0.620731 ]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -3.695056	array([[1.0425024 , 0.62670183]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 1.708846	array([[-1.0095357, -0.1573323]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = 2.628867	array([[-1.019409  , -0.15328299]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -3.850258	array([[-1.014692  , -0.15520476]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -3.847455	array([[1.0555832, 0.6156994]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -4.543229	array([[1.0562617 , 0.62214005]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = 2.073758	array([[-1.0274532 , -0.15652123]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = 2.013483	array([[-1.026699  , -0.15684816]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -4.535720	array([[-1.0265561 , -0.15817198]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -4.870435	array([[1.0506743 , 0.61571765]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -5.584141	array([[1.0477855 , 0.62289727]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = 0.891578	array([[-1.017804  , -0.17059475]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = 3.095611	array([[-1.0235643 , -0.13905706]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -5.107084	array([[-1.014294  , -0.14342351]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -5.348718	array([[1.0315406 , 0.63877857]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -5.932341	array([[1.0307713, 0.644784 ]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = 1.423304	array([[-1.0061542 , -0.16756813]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = 2.422321	array([[-1.0033021 , -0.16133393]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -4.783484	array([[-1.0096219 , -0.15747002]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -5.483628	array([[1.0294176 , 0.63881326]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -7.352197	array([[1.0308024, 0.6449783]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = 1.673164	array([[-1.0136291 , -0.16529153]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = 3.154497	array([[-1.0137968 , -0.16448805]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -3.997271	array([[-1.0083896, -0.1563606]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -5.534033	array([[1.0326662 , 0.63605124]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -7.130626	array([[1.0308568, 0.6467951]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = 0.852675	array([[-1.0074787, -0.1715205]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = 3.532744	array([[-1.0177265 , -0.14380933]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -4.584562	array([[-1.0160986 , -0.14446828]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -5.901758	array([[1.0413638 , 0.63421595]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -7.161551	array([[1.0422684, 0.6426672]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 1.510488	array([[-1.0134411 , -0.16355753]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = 2.504940	array([[-1.0260786, -0.1376602]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -4.980837	array([[-1.0155741 , -0.14614797]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -6.145734	array([[1.0418621 , 0.63270366]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -7.666367	array([[1.0348151 , 0.64465666]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = 1.392243	array([[-1.014826 , -0.1710413]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = 2.874683	array([[-1.0264891, -0.1463026]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -5.039169	array([[-1.0152811 , -0.14303084]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -6.151464	array([[1.0291562, 0.6452917]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -8.204199	array([[1.0280739, 0.6518299]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = 1.102939	array([[-0.99709237, -0.17963377]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = 2.889606	array([[-1.0073352 , -0.17011863]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -4.558609	array([[-1.0099713 , -0.15789023]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -6.225451	array([[1.0320148 , 0.64352655]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -8.333044	array([[1.0280763 , 0.65138924]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = 0.903633	array([[-0.99590045, -0.1802457 ]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = 2.551676	array([[-1.0055206 , -0.16970262]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -4.756932	array([[-1.0038117 , -0.16239963]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -6.668629	array([[1.0357436 , 0.64126015]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -9.198174	array([[1.0283564, 0.6544963]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = 0.964597	array([[-0.9982276 , -0.17859802]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = 2.226323	array([[-1.0118464 , -0.15318064]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -4.746227	array([[-1.0110383, -0.1494056]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -6.669148	array([[1.04919  , 0.6380296]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -9.629496	array([[1.0381883 , 0.65025306]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.866101	array([[-0.9941325, -0.1789906]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 2.158065	array([[-1.0050799 , -0.15845796]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -5.616974	array([[-1.0023994 , -0.15171146]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -7.272044	array([[1.048004 , 0.6396942]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -11.254474	array([[1.0358102 , 0.65307146]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.415472	array([[-0.9880291 , -0.17754906]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 3.204321	array([[-1.0048233 , -0.16632533]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -4.454576	array([[-1.00438   , -0.15345189]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -6.446898	array([[1.0311955 , 0.64680827]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 65611ms
 Real time factor: 10.1965
 UPS: 585.313438
Vehicles: 
 Inserted: 536
 Running: 74
 Waiting: 0

DijkstraRouter answered 536 queries and explored 2.00 edges on average.
DijkstraRouter spent 6ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:36097 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 36097 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = 0.332082	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.631275	array([[-1.0093249, -0.1566797]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.009262	array([[1.0397912, 0.6119434]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.103357	array([[1.0410347, 0.6186117]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = 1.951576	array([[-1.0033814 , -0.18086743]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = 1.915048	array([[-1.0018293 , -0.18147594]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.634411	array([[-0.994789  , -0.16619098]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -2.180837	array([[1.0407791 , 0.61343837]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -1.837911	array([[1.0406486, 0.6192913]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = 1.949867	array([[-1.0015337 , -0.17245653]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = 1.904299	array([[-1.0097965 , -0.17793402]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.259905	array([[-1.0010374 , -0.16093549]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -2.319951	array([[1.045012 , 0.6132879]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -2.175895	array([[1.0433769, 0.6207578]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = 1.347188	array([[-1.0082922 , -0.15806115]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = 2.542957	array([[-1.0144387 , -0.14534919]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -2.553160	array([[-1.009169 , -0.1470215]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -2.673213	array([[1.0604286, 0.6071538]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -2.508966	array([[1.0573162, 0.6148357]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = 1.668825	array([[-1.0080382 , -0.15907565]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = 2.528793	array([[-1.0041106 , -0.15159622]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.754316	array([[-1.0120759 , -0.15665734]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -2.935191	array([[1.0566545 , 0.60729456]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -2.733921	array([[1.0532198, 0.6161437]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = 1.998653	array([[-1.0256141 , -0.14685836]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = 2.236359	array([[-1.0246161, -0.1475657]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -3.481899	array([[-1.0123944 , -0.15275568]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -3.164269	array([[1.0404949, 0.6184031]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -3.517448	array([[1.0406492, 0.6252192]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = 2.026763	array([[-1.0006597 , -0.16249637]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = 2.562139	array([[-0.9984434 , -0.16333368]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -3.606913	array([[-1.0066944 , -0.16838792]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.434967	array([[1.0391185 , 0.61883974]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -3.309516	array([[1.0404627, 0.6266601]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = 1.695351	array([[-1.0027924 , -0.17129341]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = 2.596370	array([[-1.0112767 , -0.16773447]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -3.616794	array([[-1.0065253 , -0.16831592]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -3.711846	array([[1.0435834, 0.620731 ]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -3.695056	array([[1.0425024 , 0.62670183]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 1.708846	array([[-1.0095357, -0.1573323]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = 2.628867	array([[-1.019409  , -0.15328299]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -3.850258	array([[-1.014692  , -0.15520476]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -3.847455	array([[1.0555832, 0.6156994]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -4.543229	array([[1.0562617 , 0.62214005]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = 2.073758	array([[-1.0274532 , -0.15652123]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = 2.013483	array([[-1.026699  , -0.15684816]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -4.535720	array([[-1.0265561 , -0.15817198]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -4.870435	array([[1.0506743 , 0.61571765]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -5.584141	array([[1.0477855 , 0.62289727]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = 0.891578	array([[-1.017804  , -0.17059475]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = 3.095611	array([[-1.0235643 , -0.13905706]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -5.107084	array([[-1.014294  , -0.14342351]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -5.348718	array([[1.0315406 , 0.63877857]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -5.932341	array([[1.0307713, 0.644784 ]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = 1.423304	array([[-1.0061542 , -0.16756813]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = 2.422321	array([[-1.0033021 , -0.16133393]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -4.783484	array([[-1.0096219 , -0.15747002]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -5.483628	array([[1.0294176 , 0.63881326]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -7.352197	array([[1.0308024, 0.6449783]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = 1.673164	array([[-1.0136291 , -0.16529153]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = 3.154497	array([[-1.0137968 , -0.16448805]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -3.997271	array([[-1.0083896, -0.1563606]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -5.534033	array([[1.0326662 , 0.63605124]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -7.130626	array([[1.0308568, 0.6467951]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = 0.852675	array([[-1.0074787, -0.1715205]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = 3.532744	array([[-1.0177265 , -0.14380933]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -4.584562	array([[-1.0160986 , -0.14446828]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -5.901758	array([[1.0413638 , 0.63421595]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -7.161551	array([[1.0422684, 0.6426672]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 1.510488	array([[-1.0134411 , -0.16355753]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = 2.504940	array([[-1.0260786, -0.1376602]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -4.980837	array([[-1.0155741 , -0.14614797]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -6.145734	array([[1.0418621 , 0.63270366]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -7.666367	array([[1.0348151 , 0.64465666]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = 1.392243	array([[-1.014826 , -0.1710413]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = 2.874683	array([[-1.0264891, -0.1463026]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -5.039169	array([[-1.0152811 , -0.14303084]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -6.151464	array([[1.0291562, 0.6452917]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -8.204199	array([[1.0280739, 0.6518299]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = 1.102939	array([[-0.99709237, -0.17963377]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = 2.889606	array([[-1.0073352 , -0.17011863]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -4.558609	array([[-1.0099713 , -0.15789023]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -6.225451	array([[1.0320148 , 0.64352655]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -8.333044	array([[1.0280763 , 0.65138924]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = 0.903633	array([[-0.99590045, -0.1802457 ]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = 2.551676	array([[-1.0055206 , -0.16970262]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -4.756932	array([[-1.0038117 , -0.16239963]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -6.668629	array([[1.0357436 , 0.64126015]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -9.198174	array([[1.0283564, 0.6544963]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = 0.964597	array([[-0.9982276 , -0.17859802]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = 2.226323	array([[-1.0118464 , -0.15318064]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -4.746227	array([[-1.0110383, -0.1494056]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -6.669148	array([[1.04919  , 0.6380296]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -9.629496	array([[1.0381883 , 0.65025306]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.866101	array([[-0.9941325, -0.1789906]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 2.158065	array([[-1.0050799 , -0.15845796]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -5.616974	array([[-1.0023994 , -0.15171146]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -7.272044	array([[1.048004 , 0.6396942]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -11.254474	array([[1.0358102 , 0.65307146]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.415472	array([[-0.9880291 , -0.17754906]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 3.204321	array([[-1.0048233 , -0.16632533]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -4.454576	array([[-1.00438   , -0.15345189]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -6.446898	array([[1.0311955 , 0.64680827]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 65931ms
 Real time factor: 10.147
 UPS: 582.472585
Vehicles: 
 Inserted: 536
 Running: 74
 Waiting: 0

DijkstraRouter answered 536 queries and explored 2.00 edges on average.
DijkstraRouter spent 3ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:57225 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 57225 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (4ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = 0.332082	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.631275	array([[-1.0093249, -0.1566797]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.009262	array([[1.0397912, 0.6119434]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.103357	array([[1.0410347, 0.6186117]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = 1.951576	array([[-1.0033814 , -0.18086743]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = 1.915048	array([[-1.0018293 , -0.18147594]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.634411	array([[-0.994789  , -0.16619098]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -2.180837	array([[1.0407791 , 0.61343837]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -1.837911	array([[1.0406486, 0.6192913]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = 1.949867	array([[-1.0015337 , -0.17245653]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = 1.904299	array([[-1.0097965 , -0.17793402]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.259905	array([[-1.0010374 , -0.16093549]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -2.319951	array([[1.045012 , 0.6132879]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -2.175895	array([[1.0433769, 0.6207578]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = 1.347188	array([[-1.0082922 , -0.15806115]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = 2.542957	array([[-1.0144387 , -0.14534919]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -2.553160	array([[-1.009169 , -0.1470215]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -2.673213	array([[1.0604286, 0.6071538]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -2.508966	array([[1.0573162, 0.6148357]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = 1.668825	array([[-1.0080382 , -0.15907565]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = 2.528793	array([[-1.0041106 , -0.15159622]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.754316	array([[-1.0120759 , -0.15665734]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -2.935191	array([[1.0566545 , 0.60729456]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -2.733921	array([[1.0532198, 0.6161437]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = 1.998653	array([[-1.0256141 , -0.14685836]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = 2.236359	array([[-1.0246161, -0.1475657]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -3.481899	array([[-1.0123944 , -0.15275568]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -3.164269	array([[1.0404949, 0.6184031]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -3.517448	array([[1.0406492, 0.6252192]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = 2.026763	array([[-1.0006597 , -0.16249637]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = 2.562139	array([[-0.9984434 , -0.16333368]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -3.606913	array([[-1.0066944 , -0.16838792]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.434967	array([[1.0391185 , 0.61883974]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -3.309516	array([[1.0404627, 0.6266601]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = 1.695351	array([[-1.0027924 , -0.17129341]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = 2.596370	array([[-1.0112767 , -0.16773447]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -3.616794	array([[-1.0065253 , -0.16831592]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -3.711846	array([[1.0435834, 0.620731 ]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -3.695056	array([[1.0425024 , 0.62670183]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 1.708846	array([[-1.0095357, -0.1573323]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = 2.628867	array([[-1.019409  , -0.15328299]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -3.850258	array([[-1.014692  , -0.15520476]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -3.847455	array([[1.0555832, 0.6156994]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -4.543229	array([[1.0562617 , 0.62214005]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = 2.073758	array([[-1.0274532 , -0.15652123]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = 2.013483	array([[-1.026699  , -0.15684816]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -4.535720	array([[-1.0265561 , -0.15817198]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -4.870435	array([[1.0506743 , 0.61571765]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -5.584141	array([[1.0477855 , 0.62289727]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = 0.891578	array([[-1.017804  , -0.17059475]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = 3.095611	array([[-1.0235643 , -0.13905706]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -5.107084	array([[-1.014294  , -0.14342351]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -5.348718	array([[1.0315406 , 0.63877857]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -5.932341	array([[1.0307713, 0.644784 ]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = 1.423304	array([[-1.0061542 , -0.16756813]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = 2.422321	array([[-1.0033021 , -0.16133393]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -4.783484	array([[-1.0096219 , -0.15747002]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -5.483628	array([[1.0294176 , 0.63881326]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -7.352197	array([[1.0308024, 0.6449783]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = 1.673164	array([[-1.0136291 , -0.16529153]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = 3.154497	array([[-1.0137968 , -0.16448805]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -3.997271	array([[-1.0083896, -0.1563606]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -5.534033	array([[1.0326662 , 0.63605124]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -7.130626	array([[1.0308568, 0.6467951]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = 0.852675	array([[-1.0074787, -0.1715205]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = 3.532744	array([[-1.0177265 , -0.14380933]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -4.584562	array([[-1.0160986 , -0.14446828]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -5.901758	array([[1.0413638 , 0.63421595]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -7.161551	array([[1.0422684, 0.6426672]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 1.510488	array([[-1.0134411 , -0.16355753]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = 2.504940	array([[-1.0260786, -0.1376602]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -4.980837	array([[-1.0155741 , -0.14614797]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -6.145734	array([[1.0418621 , 0.63270366]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -7.666367	array([[1.0348151 , 0.64465666]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = 1.392243	array([[-1.014826 , -0.1710413]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = 2.874683	array([[-1.0264891, -0.1463026]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -5.039169	array([[-1.0152811 , -0.14303084]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -6.151464	array([[1.0291562, 0.6452917]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -8.204199	array([[1.0280739, 0.6518299]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = 1.102939	array([[-0.99709237, -0.17963377]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = 2.889606	array([[-1.0073352 , -0.17011863]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -4.558609	array([[-1.0099713 , -0.15789023]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -6.225451	array([[1.0320148 , 0.64352655]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -8.333044	array([[1.0280763 , 0.65138924]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = 0.903633	array([[-0.99590045, -0.1802457 ]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = 2.551676	array([[-1.0055206 , -0.16970262]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -4.756932	array([[-1.0038117 , -0.16239963]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -6.668629	array([[1.0357436 , 0.64126015]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -9.198174	array([[1.0283564, 0.6544963]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = 0.964597	array([[-0.9982276 , -0.17859802]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = 2.226323	array([[-1.0118464 , -0.15318064]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -4.746227	array([[-1.0110383, -0.1494056]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -6.669148	array([[1.04919  , 0.6380296]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -9.629496	array([[1.0381883 , 0.65025306]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.866101	array([[-0.9941325, -0.1789906]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 2.158065	array([[-1.0050799 , -0.15845796]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -5.616974	array([[-1.0023994 , -0.15171146]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -7.272044	array([[1.048004 , 0.6396942]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -11.254474	array([[1.0358102 , 0.65307146]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.415472	array([[-0.9880291 , -0.17754906]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 3.204321	array([[-1.0048233 , -0.16632533]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -4.454576	array([[-1.00438   , -0.15345189]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -6.446898	array([[1.0311955 , 0.64680827]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 66992ms
 Real time factor: 9.98627
 UPS: 573.247552
Vehicles: 
 Inserted: 536
 Running: 74
 Waiting: 0

DijkstraRouter answered 536 queries and explored 2.00 edges on average.
DijkstraRouter spent 6ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:54385 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 54385 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = 0.332082	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.631275	array([[-1.0093249, -0.1566797]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -2.009262	array([[1.0397912, 0.6119434]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -2.103357	array([[1.0410347, 0.6186117]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = 1.951576	array([[-1.0033814 , -0.18086743]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = 1.915048	array([[-1.0018293 , -0.18147594]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.634411	array([[-0.994789  , -0.16619098]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -2.180837	array([[1.0407791 , 0.61343837]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -1.837911	array([[1.0406486, 0.6192913]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = 1.949867	array([[-1.0015337 , -0.17245653]], dtype=float32)
time = 92	action = 0	current_phase = 0	next_phase = 1	reward = 1.904299	array([[-1.0097965 , -0.17793402]], dtype=float32)
time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -2.259905	array([[-1.0010374 , -0.16093549]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -2.319951	array([[1.045012 , 0.6132879]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -2.175895	array([[1.0433769, 0.6207578]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = 1.347188	array([[-1.0082922 , -0.15806115]], dtype=float32)
time = 123	action = 0	current_phase = 0	next_phase = 1	reward = 2.542957	array([[-1.0144387 , -0.14534919]], dtype=float32)
time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -2.553160	array([[-1.009169 , -0.1470215]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -2.673213	array([[1.0604286, 0.6071538]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -2.508966	array([[1.0573162, 0.6148357]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = 1.668825	array([[-1.0080382 , -0.15907565]], dtype=float32)
time = 154	action = 0	current_phase = 0	next_phase = 1	reward = 2.528793	array([[-1.0041106 , -0.15159622]], dtype=float32)
time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -2.754316	array([[-1.0120759 , -0.15665734]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -2.935191	array([[1.0566545 , 0.60729456]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -2.733921	array([[1.0532198, 0.6161437]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = 1.998653	array([[-1.0256141 , -0.14685836]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = 2.236359	array([[-1.0246161, -0.1475657]], dtype=float32)
time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -3.481899	array([[-1.0123944 , -0.15275568]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -3.164269	array([[1.0404949, 0.6184031]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -3.517448	array([[1.0406492, 0.6252192]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = 2.026763	array([[-1.0006597 , -0.16249637]], dtype=float32)
time = 216	action = 0	current_phase = 0	next_phase = 1	reward = 2.562139	array([[-0.9984434 , -0.16333368]], dtype=float32)
time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -3.606913	array([[-1.0066944 , -0.16838792]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -3.434967	array([[1.0391185 , 0.61883974]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -3.309516	array([[1.0404627, 0.6266601]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = 1.695351	array([[-1.0027924 , -0.17129341]], dtype=float32)
time = 247	action = 0	current_phase = 0	next_phase = 1	reward = 2.596370	array([[-1.0112767 , -0.16773447]], dtype=float32)
time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -3.616794	array([[-1.0065253 , -0.16831592]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -3.711846	array([[1.0435834, 0.620731 ]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -3.695056	array([[1.0425024 , 0.62670183]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = 1.708846	array([[-1.0095357, -0.1573323]], dtype=float32)
time = 278	action = 0	current_phase = 0	next_phase = 1	reward = 2.628867	array([[-1.019409  , -0.15328299]], dtype=float32)
time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -3.850258	array([[-1.014692  , -0.15520476]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -3.847455	array([[1.0555832, 0.6156994]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -4.543229	array([[1.0562617 , 0.62214005]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = 2.073758	array([[-1.0274532 , -0.15652123]], dtype=float32)
time = 309	action = 0	current_phase = 0	next_phase = 1	reward = 2.013483	array([[-1.026699  , -0.15684816]], dtype=float32)
time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -4.535720	array([[-1.0265561 , -0.15817198]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -4.870435	array([[1.0506743 , 0.61571765]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -5.584141	array([[1.0477855 , 0.62289727]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = 0.891578	array([[-1.017804  , -0.17059475]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = 3.095611	array([[-1.0235643 , -0.13905706]], dtype=float32)
time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -5.107084	array([[-1.014294  , -0.14342351]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -5.348718	array([[1.0315406 , 0.63877857]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -5.932341	array([[1.0307713, 0.644784 ]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = 1.423304	array([[-1.0061542 , -0.16756813]], dtype=float32)
time = 371	action = 0	current_phase = 0	next_phase = 1	reward = 2.422321	array([[-1.0033021 , -0.16133393]], dtype=float32)
time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -4.783484	array([[-1.0096219 , -0.15747002]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -5.483628	array([[1.0294176 , 0.63881326]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -7.352197	array([[1.0308024, 0.6449783]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = 1.673164	array([[-1.0136291 , -0.16529153]], dtype=float32)
time = 402	action = 0	current_phase = 0	next_phase = 1	reward = 3.154497	array([[-1.0137968 , -0.16448805]], dtype=float32)
time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -3.997271	array([[-1.0083896, -0.1563606]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -5.534033	array([[1.0326662 , 0.63605124]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -7.130626	array([[1.0308568, 0.6467951]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = 0.852675	array([[-1.0074787, -0.1715205]], dtype=float32)
time = 433	action = 0	current_phase = 0	next_phase = 1	reward = 3.532744	array([[-1.0177265 , -0.14380933]], dtype=float32)
time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -4.584562	array([[-1.0160986 , -0.14446828]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -5.901758	array([[1.0413638 , 0.63421595]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -7.161551	array([[1.0422684, 0.6426672]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = 1.510488	array([[-1.0134411 , -0.16355753]], dtype=float32)
time = 464	action = 0	current_phase = 0	next_phase = 1	reward = 2.504940	array([[-1.0260786, -0.1376602]], dtype=float32)
time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -4.980837	array([[-1.0155741 , -0.14614797]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -6.145734	array([[1.0418621 , 0.63270366]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -7.666367	array([[1.0348151 , 0.64465666]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = 1.392243	array([[-1.014826 , -0.1710413]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = 2.874683	array([[-1.0264891, -0.1463026]], dtype=float32)
time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -5.039169	array([[-1.0152811 , -0.14303084]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -6.151464	array([[1.0291562, 0.6452917]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -8.204199	array([[1.0280739, 0.6518299]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = 1.102939	array([[-0.99709237, -0.17963377]], dtype=float32)
time = 526	action = 0	current_phase = 0	next_phase = 1	reward = 2.889606	array([[-1.0073352 , -0.17011863]], dtype=float32)
time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -4.558609	array([[-1.0099713 , -0.15789023]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -6.225451	array([[1.0320148 , 0.64352655]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -8.333044	array([[1.0280763 , 0.65138924]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = 0.903633	array([[-0.99590045, -0.1802457 ]], dtype=float32)
time = 557	action = 0	current_phase = 0	next_phase = 1	reward = 2.551676	array([[-1.0055206 , -0.16970262]], dtype=float32)
time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -4.756932	array([[-1.0038117 , -0.16239963]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -6.668629	array([[1.0357436 , 0.64126015]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -9.198174	array([[1.0283564, 0.6544963]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = 0.964597	array([[-0.9982276 , -0.17859802]], dtype=float32)
time = 588	action = 0	current_phase = 0	next_phase = 1	reward = 2.226323	array([[-1.0118464 , -0.15318064]], dtype=float32)
time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -4.746227	array([[-1.0110383, -0.1494056]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -6.669148	array([[1.04919  , 0.6380296]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -9.629496	array([[1.0381883 , 0.65025306]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.866101	array([[-0.9941325, -0.1789906]], dtype=float32)
time = 619	action = 0	current_phase = 0	next_phase = 1	reward = 2.158065	array([[-1.0050799 , -0.15845796]], dtype=float32)
time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -5.616974	array([[-1.0023994 , -0.15171146]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -7.272044	array([[1.048004 , 0.6396942]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -11.254474	array([[1.0358102 , 0.65307146]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.415472	array([[-0.9880291 , -0.17754906]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 3.204321	array([[-1.0048233 , -0.16632533]], dtype=float32)
time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -4.454576	array([[-1.00438   , -0.15345189]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -6.446898	array([[1.0311955 , 0.64680827]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 66689ms
 Real time factor: 10.0316
 UPS: 575.852090
Vehicles: 
 Inserted: 536
 Running: 74
 Waiting: 0

DijkstraRouter answered 536 queries and explored 2.00 edges on average.
DijkstraRouter spent 11ms answering queries (0.02ms on average).
Could not connect to TraCI server at localhost:43523 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 43523 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (4ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = 0.332082	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = 0.896630	array([[-1.0093249, -0.1566797]], dtype=float32)
time = 40	action = 1	current_phase = 0	next_phase = 1	reward = -2.392800	array([[-1.0067422 , -0.14687294]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -2.406936	array([[1.0470232 , 0.61528873]], dtype=float32)
time = 53	action = 1	current_phase = 1	next_phase = 0	reward = -1.918737	array([[1.0411172, 0.6254449]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = 1.953760	array([[-1.0024844 , -0.15015954]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = 2.200617	array([[-1.0006208, -0.1508809]], dtype=float32)
time = 71	action = 0	current_phase = 0	next_phase = 1	reward = 0.718811	array([[-1.0017581 , -0.15999934]], dtype=float32)
time = 76	action = 1	current_phase = 0	next_phase = 1	reward = -1.408772	array([[-1.0017338 , -0.16093832]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -1.769710	array([[1.0497305, 0.6056135]], dtype=float32)
time = 89	action = 1	current_phase = 1	next_phase = 0	reward = -1.236309	array([[1.0500671, 0.6132392]], dtype=float32)
time = 97	action = 0	current_phase = 0	next_phase = 1	reward = 1.605958	array([[-0.9983229 , -0.17489982]], dtype=float32)
time = 102	action = 0	current_phase = 0	next_phase = 1	reward = 1.610321	array([[-0.9885808 , -0.18000609]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = 1.018391	array([[-1.0010955 , -0.16078164]], dtype=float32)
time = 112	action = 1	current_phase = 0	next_phase = 1	reward = -1.975340	array([[-0.9903616 , -0.16751415]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -2.126546	array([[1.053112  , 0.60779065]], dtype=float32)
time = 125	action = 1	current_phase = 1	next_phase = 0	reward = -2.211990	array([[1.0514973, 0.6159764]], dtype=float32)
time = 133	action = 0	current_phase = 0	next_phase = 1	reward = 1.969064	array([[-1.0084783 , -0.15955761]], dtype=float32)
time = 138	action = 0	current_phase = 0	next_phase = 1	reward = 2.488323	array([[-1.0082407 , -0.16031182]], dtype=float32)
time = 143	action = 0	current_phase = 0	next_phase = 1	reward = 0.718388	array([[-1.0015966 , -0.16257857]], dtype=float32)
time = 148	action = 1	current_phase = 0	next_phase = 1	reward = -1.878661	array([[-1.0015144 , -0.16155735]], dtype=float32)
time = 156	action = 0	current_phase = 1	next_phase = 0	reward = -2.120297	array([[1.0683867, 0.5996998]], dtype=float32)
time = 161	action = 1	current_phase = 1	next_phase = 0	reward = -1.614402	array([[1.065646  , 0.60876787]], dtype=float32)
time = 169	action = 0	current_phase = 0	next_phase = 1	reward = 1.646957	array([[-1.0058508 , -0.16097915]], dtype=float32)
time = 174	action = 0	current_phase = 0	next_phase = 1	reward = 2.209482	array([[-1.0142941, -0.1553266]], dtype=float32)
time = 179	action = 0	current_phase = 0	next_phase = 1	reward = 0.735073	array([[-1.0008891 , -0.16214201]], dtype=float32)
time = 184	action = 1	current_phase = 0	next_phase = 1	reward = -1.631117	array([[-1.0020876 , -0.16159585]], dtype=float32)
time = 192	action = 0	current_phase = 1	next_phase = 0	reward = -1.964601	array([[1.0542346 , 0.60752314]], dtype=float32)
time = 197	action = 1	current_phase = 1	next_phase = 0	reward = -1.843058	array([[1.0603971, 0.6154252]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = 1.329989	array([[-1.0210679 , -0.14089456]], dtype=float32)
time = 210	action = 0	current_phase = 0	next_phase = 1	reward = 2.235974	array([[-1.0185105 , -0.14106748]], dtype=float32)
time = 215	action = 0	current_phase = 0	next_phase = 1	reward = 1.287569	array([[-1.0029083 , -0.16213834]], dtype=float32)
time = 220	action = 1	current_phase = 0	next_phase = 1	reward = -1.757333	array([[-1.0063223 , -0.14752215]], dtype=float32)
time = 228	action = 0	current_phase = 1	next_phase = 0	reward = -1.890160	array([[1.0411025 , 0.61111766]], dtype=float32)
time = 233	action = 1	current_phase = 1	next_phase = 0	reward = -1.285518	array([[1.0431366, 0.619573 ]], dtype=float32)
time = 241	action = 0	current_phase = 0	next_phase = 1	reward = 1.921879	array([[-1.0079831 , -0.16743395]], dtype=float32)
time = 246	action = 0	current_phase = 0	next_phase = 1	reward = 1.595752	array([[-1.0071598 , -0.16908589]], dtype=float32)
time = 251	action = 0	current_phase = 0	next_phase = 1	reward = 0.720661	array([[-1.0018411, -0.1611807]], dtype=float32)
time = 256	action = 1	current_phase = 0	next_phase = 1	reward = -1.465075	array([[-1.0015119, -0.1614573]], dtype=float32)
time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -1.833156	array([[1.0509268, 0.6071272]], dtype=float32)
time = 269	action = 1	current_phase = 1	next_phase = 0	reward = -2.197613	array([[1.051126 , 0.6155784]], dtype=float32)
time = 277	action = 0	current_phase = 0	next_phase = 1	reward = 1.973579	array([[-1.0038528 , -0.18170115]], dtype=float32)
time = 282	action = 0	current_phase = 0	next_phase = 1	reward = 2.214427	array([[-1.0020859 , -0.18317851]], dtype=float32)
time = 287	action = 0	current_phase = 0	next_phase = 1	reward = 1.288120	array([[-1.0017701, -0.1615237]], dtype=float32)
time = 292	action = 1	current_phase = 0	next_phase = 1	reward = -2.298214	array([[-0.9939459 , -0.17695464]], dtype=float32)
time = 300	action = 0	current_phase = 1	next_phase = 0	reward = -1.972410	array([[1.0541265 , 0.60894775]], dtype=float32)
time = 305	action = 1	current_phase = 1	next_phase = 0	reward = -2.164147	array([[1.0489875, 0.6175997]], dtype=float32)
time = 313	action = 0	current_phase = 0	next_phase = 1	reward = 1.657014	array([[-1.0170454 , -0.16283605]], dtype=float32)
time = 318	action = 0	current_phase = 0	next_phase = 1	reward = 2.503368	array([[-1.0125213 , -0.15546983]], dtype=float32)
time = 323	action = 0	current_phase = 0	next_phase = 1	reward = 1.006297	array([[-0.9989593 , -0.15303092]], dtype=float32)
time = 328	action = 1	current_phase = 0	next_phase = 1	reward = -2.485683	array([[-1.0008107, -0.1605735]], dtype=float32)
time = 336	action = 0	current_phase = 1	next_phase = 0	reward = -2.259200	array([[1.0528036 , 0.60699934]], dtype=float32)
time = 341	action = 1	current_phase = 1	next_phase = 0	reward = -2.063812	array([[1.0579594, 0.6132884]], dtype=float32)
time = 349	action = 0	current_phase = 0	next_phase = 1	reward = 1.338006	array([[-1.0243857 , -0.15884314]], dtype=float32)
time = 354	action = 0	current_phase = 0	next_phase = 1	reward = 2.552771	array([[-1.0307677, -0.1449085]], dtype=float32)
time = 359	action = 0	current_phase = 0	next_phase = 1	reward = 1.011021	array([[-1.0127537 , -0.15508881]], dtype=float32)
time = 364	action = 1	current_phase = 0	next_phase = 1	reward = -1.574862	array([[-1.001998  , -0.16305028]], dtype=float32)
time = 372	action = 0	current_phase = 1	next_phase = 0	reward = -2.116349	array([[1.0600194, 0.6052523]], dtype=float32)
time = 377	action = 1	current_phase = 1	next_phase = 0	reward = -1.414724	array([[1.0537713 , 0.61393017]], dtype=float32)
time = 385	action = 0	current_phase = 0	next_phase = 1	reward = 1.315488	array([[-1.0103141 , -0.14601286]], dtype=float32)
time = 390	action = 0	current_phase = 0	next_phase = 1	reward = 1.926542	array([[-0.99809897, -0.14264499]], dtype=float32)
time = 395	action = 0	current_phase = 0	next_phase = 1	reward = 1.290006	array([[-1.0022593 , -0.16251937]], dtype=float32)
time = 400	action = 1	current_phase = 0	next_phase = 1	reward = -2.371340	array([[-1.0074286 , -0.14645267]], dtype=float32)
time = 408	action = 0	current_phase = 1	next_phase = 0	reward = -2.243546	array([[1.042393 , 0.6180813]], dtype=float32)
time = 413	action = 1	current_phase = 1	next_phase = 0	reward = -2.008941	array([[1.041076  , 0.62581104]], dtype=float32)
time = 421	action = 0	current_phase = 0	next_phase = 1	reward = 1.639085	array([[-1.0012268 , -0.15072945]], dtype=float32)
time = 426	action = 0	current_phase = 0	next_phase = 1	reward = 2.508983	array([[-1.0111867 , -0.14483136]], dtype=float32)
time = 431	action = 0	current_phase = 0	next_phase = 1	reward = 0.719974	array([[-1.0012276, -0.1604152]], dtype=float32)
time = 436	action = 1	current_phase = 0	next_phase = 1	reward = -1.347860	array([[-1.0016464 , -0.16042113]], dtype=float32)
time = 444	action = 0	current_phase = 1	next_phase = 0	reward = -1.775658	array([[1.0505372, 0.6040212]], dtype=float32)
time = 449	action = 1	current_phase = 1	next_phase = 0	reward = -2.137841	array([[1.0505948, 0.6165182]], dtype=float32)
time = 457	action = 0	current_phase = 0	next_phase = 1	reward = 2.574854	array([[-0.9901868 , -0.18015075]], dtype=float32)
time = 462	action = 0	current_phase = 0	next_phase = 1	reward = 1.619891	array([[-0.98828155, -0.17960444]], dtype=float32)
time = 467	action = 0	current_phase = 0	next_phase = 1	reward = 1.009448	array([[-1.0012374, -0.1612986]], dtype=float32)
time = 472	action = 1	current_phase = 0	next_phase = 1	reward = -1.970725	array([[-0.99035496, -0.16796567]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -2.185615	array([[1.0535054, 0.6082851]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -2.056718	array([[1.0530841 , 0.61691576]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = 1.642032	array([[-1.0153135 , -0.15466273]], dtype=float32)
time = 498	action = 0	current_phase = 0	next_phase = 1	reward = 2.492109	array([[-0.9930266 , -0.15699655]], dtype=float32)
time = 503	action = 0	current_phase = 0	next_phase = 1	reward = 0.730583	array([[-1.0015292 , -0.16176862]], dtype=float32)
time = 508	action = 1	current_phase = 0	next_phase = 1	reward = -2.376234	array([[-1.0011067 , -0.16178557]], dtype=float32)
time = 516	action = 0	current_phase = 1	next_phase = 0	reward = -2.360509	array([[1.0669355 , 0.60165733]], dtype=float32)
time = 521	action = 1	current_phase = 1	next_phase = 0	reward = -2.132682	array([[1.0664638, 0.6114438]], dtype=float32)
time = 529	action = 0	current_phase = 0	next_phase = 1	reward = 1.657304	array([[-0.9983001 , -0.16531253]], dtype=float32)
time = 534	action = 0	current_phase = 0	next_phase = 1	reward = 2.216732	array([[-1.006982  , -0.15969521]], dtype=float32)
time = 539	action = 0	current_phase = 0	next_phase = 1	reward = 1.028869	array([[-0.9942719 , -0.16692269]], dtype=float32)
time = 544	action = 1	current_phase = 0	next_phase = 1	reward = -1.482278	array([[-1.0017593, -0.1601662]], dtype=float32)
time = 552	action = 0	current_phase = 1	next_phase = 0	reward = -2.051810	array([[1.0596764 , 0.60562915]], dtype=float32)
time = 557	action = 1	current_phase = 1	next_phase = 0	reward = -1.719983	array([[1.0605855 , 0.61467654]], dtype=float32)
time = 565	action = 0	current_phase = 0	next_phase = 1	reward = 1.651102	array([[-1.0126846 , -0.15594065]], dtype=float32)
time = 570	action = 0	current_phase = 0	next_phase = 1	reward = 1.913884	array([[-1.0032489 , -0.15959628]], dtype=float32)
time = 575	action = 0	current_phase = 0	next_phase = 1	reward = 1.285464	array([[-1.0015771 , -0.16102779]], dtype=float32)
time = 580	action = 1	current_phase = 0	next_phase = 1	reward = -2.377508	array([[-1.0072168 , -0.14705339]], dtype=float32)
time = 588	action = 0	current_phase = 1	next_phase = 0	reward = -2.303897	array([[1.0416595, 0.6188391]], dtype=float32)
time = 593	action = 1	current_phase = 1	next_phase = 0	reward = -2.378199	array([[1.041161 , 0.6264248]], dtype=float32)
time = 601	action = 0	current_phase = 0	next_phase = 1	reward = 1.970142	array([[-0.99549246, -0.15551013]], dtype=float32)
time = 606	action = 0	current_phase = 0	next_phase = 1	reward = 2.218692	array([[-0.99276155, -0.15583032]], dtype=float32)
time = 611	action = 0	current_phase = 0	next_phase = 1	reward = 1.015770	array([[-0.9945414, -0.1658056]], dtype=float32)
time = 616	action = 1	current_phase = 0	next_phase = 1	reward = -1.471308	array([[-1.0018808 , -0.16011554]], dtype=float32)
time = 624	action = 0	current_phase = 1	next_phase = 0	reward = -1.880705	array([[1.0538708, 0.6053605]], dtype=float32)
time = 629	action = 1	current_phase = 1	next_phase = 0	reward = -1.567227	array([[1.0535629, 0.6152129]], dtype=float32)
time = 637	action = 0	current_phase = 0	next_phase = 1	reward = 2.241830	array([[-0.9911775 , -0.17851064]], dtype=float32)
time = 642	action = 0	current_phase = 0	next_phase = 1	reward = 1.300356	array([[-0.99536586, -0.17559555]], dtype=float32)
time = 647	action = 0	current_phase = 0	next_phase = 1	reward = 1.008252	array([[-1.0021217 , -0.16078052]], dtype=float32)
time = 652	action = 1	current_phase = 0	next_phase = 1	reward = -1.849996	array([[-1.0042217, -0.1679098]], dtype=float32)
time = 660	action = 0	current_phase = 1	next_phase = 0	reward = -2.011684	array([[1.0524309, 0.6052366]], dtype=float32)
time = 665	action = 1	current_phase = 1	next_phase = 0	reward = -1.513184	array([[1.0517737 , 0.61445177]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 674.00
Reason: TraCI requested termination.
Performance: 
 Duration: 57845ms
 Real time factor: 11.6518
 UPS: 566.064483
Vehicles: 
 Inserted: 540
 Running: 52
 Waiting: 0

DijkstraRouter answered 540 queries and explored 2.00 edges on average.
DijkstraRouter spent 7ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:56095 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 56095 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = 0.332082	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = 0.896630	array([[-1.0093249, -0.1566797]], dtype=float32)
time = 40	action = 0	current_phase = 0	next_phase = 1	reward = 0.701879	array([[-1.0067422 , -0.14687294]], dtype=float32)
time = 45	action = 1	current_phase = 0	next_phase = 1	reward = -2.486688	array([[-1.0063182 , -0.14813814]], dtype=float32)
time = 53	action = 0	current_phase = 1	next_phase = 0	reward = -2.248216	array([[1.0419987, 0.618873 ]], dtype=float32)
time = 58	action = 1	current_phase = 1	next_phase = 0	reward = -2.213441	array([[1.0403894 , 0.62522626]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = 1.656097	array([[-1.0008129 , -0.17278737]], dtype=float32)
time = 71	action = 0	current_phase = 0	next_phase = 1	reward = 2.520957	array([[-0.9952432 , -0.16455993]], dtype=float32)
time = 76	action = 0	current_phase = 0	next_phase = 1	reward = 1.008578	array([[-0.99413294, -0.16647145]], dtype=float32)
time = 81	action = 0	current_phase = 0	next_phase = 1	reward = 0.718487	array([[-1.001761  , -0.16016306]], dtype=float32)
time = 86	action = 1	current_phase = 0	next_phase = 1	reward = -1.414024	array([[-1.0016252 , -0.16265684]], dtype=float32)
time = 94	action = 0	current_phase = 1	next_phase = 0	reward = -1.874167	array([[1.0506738 , 0.60569763]], dtype=float32)
time = 99	action = 1	current_phase = 1	next_phase = 0	reward = -2.294390	array([[1.0538828 , 0.61647916]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = 2.267493	array([[-0.989759  , -0.17975254]], dtype=float32)
time = 112	action = 0	current_phase = 0	next_phase = 1	reward = 2.182004	array([[-0.99098504, -0.18986493]], dtype=float32)
time = 117	action = 0	current_phase = 0	next_phase = 1	reward = 0.998797	array([[-0.9964991 , -0.18519196]], dtype=float32)
time = 122	action = 0	current_phase = 0	next_phase = 1	reward = 0.723065	array([[-0.993759 , -0.1763963]], dtype=float32)
time = 127	action = 1	current_phase = 0	next_phase = 1	reward = -2.082115	array([[-0.99293584, -0.17610145]], dtype=float32)
time = 135	action = 0	current_phase = 1	next_phase = 0	reward = -1.947257	array([[1.0550032, 0.6079371]], dtype=float32)
time = 140	action = 1	current_phase = 1	next_phase = 0	reward = -2.153833	array([[1.0500413, 0.6134267]], dtype=float32)
time = 148	action = 0	current_phase = 0	next_phase = 1	reward = 1.650403	array([[-1.0088176 , -0.15875715]], dtype=float32)
time = 153	action = 0	current_phase = 0	next_phase = 1	reward = 2.795936	array([[-1.0088091 , -0.16579504]], dtype=float32)
time = 158	action = 0	current_phase = 0	next_phase = 1	reward = 0.715607	array([[-1.0024879 , -0.16232932]], dtype=float32)
time = 163	action = 0	current_phase = 0	next_phase = 1	reward = 0.716777	array([[-1.0010816 , -0.16106516]], dtype=float32)
time = 168	action = 1	current_phase = 0	next_phase = 1	reward = -2.210401	array([[-1.0014967 , -0.16214675]], dtype=float32)
time = 176	action = 0	current_phase = 1	next_phase = 0	reward = -2.287109	array([[1.0681946, 0.6027932]], dtype=float32)
time = 181	action = 1	current_phase = 1	next_phase = 0	reward = -2.105657	array([[1.0657471, 0.61052  ]], dtype=float32)
time = 189	action = 0	current_phase = 0	next_phase = 1	reward = 1.960441	array([[-1.0077022, -0.1684945]], dtype=float32)
time = 194	action = 0	current_phase = 0	next_phase = 1	reward = 2.197468	array([[-1.0069308 , -0.17048305]], dtype=float32)
time = 199	action = 0	current_phase = 0	next_phase = 1	reward = 0.717897	array([[-1.0020906 , -0.16119382]], dtype=float32)
time = 204	action = 0	current_phase = 0	next_phase = 1	reward = 0.726420	array([[-0.9968986 , -0.14524192]], dtype=float32)
time = 209	action = 1	current_phase = 0	next_phase = 1	reward = -1.565390	array([[-1.0013045 , -0.16116658]], dtype=float32)
time = 217	action = 0	current_phase = 1	next_phase = 0	reward = -1.740880	array([[1.0570647, 0.608496 ]], dtype=float32)
time = 222	action = 1	current_phase = 1	next_phase = 0	reward = -1.668737	array([[1.0608323, 0.6138319]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = 1.648708	array([[-1.0034988 , -0.15176842]], dtype=float32)
time = 235	action = 0	current_phase = 0	next_phase = 1	reward = 1.917950	array([[-1.0046432 , -0.16036488]], dtype=float32)
time = 240	action = 0	current_phase = 0	next_phase = 1	reward = 1.291999	array([[-1.0018327 , -0.16272813]], dtype=float32)
time = 245	action = 0	current_phase = 0	next_phase = 1	reward = 0.444495	array([[-1.0072912 , -0.14620371]], dtype=float32)
time = 250	action = 1	current_phase = 0	next_phase = 1	reward = -1.586992	array([[-1.0101233 , -0.15710694]], dtype=float32)
time = 258	action = 0	current_phase = 1	next_phase = 0	reward = -1.901609	array([[1.0416113 , 0.61170596]], dtype=float32)
time = 263	action = 1	current_phase = 1	next_phase = 0	reward = -1.830821	array([[1.0404413, 0.6189997]], dtype=float32)
time = 271	action = 0	current_phase = 0	next_phase = 1	reward = 1.959811	array([[-1.0065758 , -0.16751851]], dtype=float32)
time = 276	action = 0	current_phase = 0	next_phase = 1	reward = 1.900217	array([[-1.005762  , -0.16792175]], dtype=float32)
time = 281	action = 0	current_phase = 0	next_phase = 1	reward = 1.015053	array([[-1.0040747 , -0.16973652]], dtype=float32)
time = 286	action = 0	current_phase = 0	next_phase = 1	reward = 0.728393	array([[-1.0020446 , -0.16163965]], dtype=float32)
time = 291	action = 1	current_phase = 0	next_phase = 1	reward = -1.462219	array([[-1.0011653, -0.1610336]], dtype=float32)
time = 299	action = 0	current_phase = 1	next_phase = 0	reward = -1.774578	array([[1.0539829 , 0.60601056]], dtype=float32)
time = 304	action = 1	current_phase = 1	next_phase = 0	reward = -1.500075	array([[1.0495185 , 0.61313504]], dtype=float32)
time = 312	action = 0	current_phase = 0	next_phase = 1	reward = 1.622655	array([[-0.9943188 , -0.16523218]], dtype=float32)
time = 317	action = 0	current_phase = 0	next_phase = 1	reward = 1.913598	array([[-0.99560356, -0.17541626]], dtype=float32)
time = 322	action = 0	current_phase = 0	next_phase = 1	reward = 1.290148	array([[-1.002074  , -0.16126098]], dtype=float32)
time = 327	action = 0	current_phase = 0	next_phase = 1	reward = 0.442673	array([[-0.99408925, -0.17542535]], dtype=float32)
time = 332	action = 1	current_phase = 0	next_phase = 1	reward = -1.966472	array([[-1.0046818 , -0.16954386]], dtype=float32)
time = 340	action = 0	current_phase = 1	next_phase = 0	reward = -2.128584	array([[1.0544275 , 0.60742223]], dtype=float32)
time = 345	action = 1	current_phase = 1	next_phase = 0	reward = -2.008853	array([[1.0524942, 0.6165686]], dtype=float32)
time = 353	action = 0	current_phase = 0	next_phase = 1	reward = 2.269561	array([[-1.0176274 , -0.16348168]], dtype=float32)
time = 358	action = 0	current_phase = 0	next_phase = 1	reward = 2.192380	array([[-1.0053458 , -0.16883999]], dtype=float32)
time = 363	action = 0	current_phase = 0	next_phase = 1	reward = 0.725725	array([[-1.0016041, -0.1622631]], dtype=float32)
time = 368	action = 0	current_phase = 0	next_phase = 1	reward = 0.725234	array([[-1.0017717 , -0.16338024]], dtype=float32)
time = 373	action = 1	current_phase = 0	next_phase = 1	reward = -2.446170	array([[-1.0017382 , -0.16200121]], dtype=float32)
time = 381	action = 0	current_phase = 1	next_phase = 0	reward = -2.364275	array([[1.0670439 , 0.60383016]], dtype=float32)
time = 386	action = 1	current_phase = 1	next_phase = 0	reward = -2.059322	array([[1.0671083 , 0.60937846]], dtype=float32)
time = 394	action = 0	current_phase = 0	next_phase = 1	reward = 1.650894	array([[-1.0082206 , -0.16859877]], dtype=float32)
time = 399	action = 0	current_phase = 0	next_phase = 1	reward = 2.516668	array([[-0.99934363, -0.17381555]], dtype=float32)
time = 404	action = 0	current_phase = 0	next_phase = 1	reward = 0.719304	array([[-1.0019904 , -0.16358069]], dtype=float32)
time = 409	action = 0	current_phase = 0	next_phase = 1	reward = 0.724760	array([[-1.0029389 , -0.16117844]], dtype=float32)
time = 414	action = 1	current_phase = 0	next_phase = 1	reward = -1.573772	array([[-0.9961425 , -0.14366344]], dtype=float32)
time = 422	action = 0	current_phase = 1	next_phase = 0	reward = -1.946846	array([[1.0545393 , 0.60719836]], dtype=float32)
time = 427	action = 1	current_phase = 1	next_phase = 0	reward = -1.299172	array([[1.0597695, 0.6146005]], dtype=float32)
time = 435	action = 0	current_phase = 0	next_phase = 1	reward = 1.614437	array([[-1.0112572 , -0.14690965]], dtype=float32)
time = 440	action = 0	current_phase = 0	next_phase = 1	reward = 1.615636	array([[-1.0191984 , -0.13885313]], dtype=float32)
time = 445	action = 0	current_phase = 0	next_phase = 1	reward = 1.285788	array([[-1.0020396, -0.1618416]], dtype=float32)
time = 450	action = 0	current_phase = 0	next_phase = 1	reward = 0.439488	array([[-1.0068755 , -0.14825985]], dtype=float32)
time = 455	action = 1	current_phase = 0	next_phase = 1	reward = -1.409990	array([[-1.0089434 , -0.15613467]], dtype=float32)
time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -1.830219	array([[1.0418117 , 0.61298704]], dtype=float32)
time = 468	action = 1	current_phase = 1	next_phase = 0	reward = -1.717560	array([[1.0453848, 0.6170946]], dtype=float32)
time = 476	action = 0	current_phase = 0	next_phase = 1	reward = 1.938272	array([[-1.0016232 , -0.17309345]], dtype=float32)
time = 481	action = 0	current_phase = 0	next_phase = 1	reward = 1.614965	array([[-1.0001751 , -0.17492664]], dtype=float32)
time = 486	action = 0	current_phase = 0	next_phase = 1	reward = 1.005642	array([[-0.9936059 , -0.16627648]], dtype=float32)
time = 491	action = 0	current_phase = 0	next_phase = 1	reward = 0.728702	array([[-1.0014755 , -0.16193934]], dtype=float32)
time = 496	action = 1	current_phase = 0	next_phase = 1	reward = -1.409786	array([[-1.0012472 , -0.16089651]], dtype=float32)
time = 504	action = 0	current_phase = 1	next_phase = 0	reward = -1.933558	array([[1.0496402, 0.6075516]], dtype=float32)
time = 509	action = 1	current_phase = 1	next_phase = 0	reward = -1.447691	array([[1.0478075 , 0.61528915]], dtype=float32)
time = 517	action = 0	current_phase = 0	next_phase = 1	reward = 1.936401	array([[-1.0080154 , -0.16714391]], dtype=float32)
time = 522	action = 0	current_phase = 0	next_phase = 1	reward = 1.878621	array([[-1.0067761 , -0.16858259]], dtype=float32)
time = 527	action = 0	current_phase = 0	next_phase = 1	reward = 1.005210	array([[-1.0051907 , -0.17041923]], dtype=float32)
time = 532	action = 0	current_phase = 0	next_phase = 1	reward = 0.440915	array([[-0.99306405, -0.17431603]], dtype=float32)
time = 537	action = 1	current_phase = 0	next_phase = 1	reward = -1.748192	array([[-0.99103403, -0.1672128 ]], dtype=float32)
time = 545	action = 0	current_phase = 1	next_phase = 0	reward = -2.003512	array([[1.0525211 , 0.60653317]], dtype=float32)
time = 550	action = 1	current_phase = 1	next_phase = 0	reward = -2.198375	array([[1.05222  , 0.6164559]], dtype=float32)
time = 558	action = 0	current_phase = 0	next_phase = 1	reward = 1.648488	array([[-1.0047482 , -0.16044295]], dtype=float32)
time = 563	action = 0	current_phase = 0	next_phase = 1	reward = 2.794724	array([[-1.008323  , -0.16745606]], dtype=float32)
time = 568	action = 0	current_phase = 0	next_phase = 1	reward = 0.725588	array([[-1.0017421, -0.161076 ]], dtype=float32)
time = 573	action = 0	current_phase = 0	next_phase = 1	reward = 0.732109	array([[-1.0013051 , -0.16134554]], dtype=float32)
time = 578	action = 1	current_phase = 0	next_phase = 1	reward = -2.396016	array([[-1.0018497 , -0.16141494]], dtype=float32)
time = 586	action = 0	current_phase = 1	next_phase = 0	reward = -2.414388	array([[1.0688233, 0.6006253]], dtype=float32)
time = 591	action = 1	current_phase = 1	next_phase = 0	reward = -2.386885	array([[1.0649315 , 0.61037767]], dtype=float32)
time = 599	action = 0	current_phase = 0	next_phase = 1	reward = 2.288909	array([[-1.0092032 , -0.15848836]], dtype=float32)
time = 604	action = 0	current_phase = 0	next_phase = 1	reward = 2.204506	array([[-1.0146759 , -0.15316363]], dtype=float32)
time = 609	action = 0	current_phase = 0	next_phase = 1	reward = 0.726386	array([[-1.0019493, -0.1627093]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = 0.729057	array([[-1.0015512 , -0.16108242]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.358582	array([[-1.0022268 , -0.16105169]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -1.884383	array([[1.0610362 , 0.60731304]], dtype=float32)
time = 632	action = 1	current_phase = 1	next_phase = 0	reward = -1.708508	array([[1.0543438, 0.6161114]], dtype=float32)
time = 640	action = 0	current_phase = 0	next_phase = 1	reward = 1.943254	array([[-1.0038904 , -0.15043777]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = 1.607358	array([[-1.0011057, -0.1497581]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 1.003408	array([[-1.0013765 , -0.16091046]], dtype=float32)
time = 655	action = 0	current_phase = 0	next_phase = 1	reward = 0.730483	array([[-1.0089495 , -0.15651062]], dtype=float32)
time = 660	action = 1	current_phase = 0	next_phase = 1	reward = -1.537826	array([[-1.0091598 , -0.15619801]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 59903ms
 Real time factor: 11.1681
 UPS: 530.173781
Vehicles: 
 Inserted: 536
 Running: 58
 Waiting: 0

DijkstraRouter answered 536 queries and explored 2.00 edges on average.
DijkstraRouter spent 3ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:39311 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 39311 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.899535	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -2.006765	array([[1.0501    , 0.61237735]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -3.284783	array([[1.0481704, 0.6200118]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.321901	array([[1.0481998 , 0.62680054]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = 1.361863	array([[-0.99001944, -0.16805756]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -5.557800	array([[-1.0004162 , -0.17056751]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -5.600162	array([[1.0446236 , 0.62983906]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -7.104438	array([[1.0452243 , 0.63860416]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -9.297937	array([[1.0436493, 0.6452585]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = 0.949055	array([[-0.97498536, -0.18036649]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -6.435112	array([[-0.99593055, -0.17488964]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -8.196788	array([[1.0483383, 0.6435051]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -10.730524	array([[1.0390803 , 0.65758175]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -14.561456	array([[1.0290447, 0.6689398]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -3.181728	array([[-0.9669156 , -0.18190551]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -6.420227	array([[-0.97659147, -0.1718344 ]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -7.660801	array([[1.0701779 , 0.64320225]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -11.311903	array([[1.0481454, 0.6623689]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -19.063168	array([[1.0279989, 0.6795651]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -5.574035	array([[-0.966948  , -0.18868518]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -10.591926	array([[-0.97640204, -0.17827913]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -7.083657	array([[1.0703481, 0.651363 ]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -11.190684	array([[1.0607029 , 0.66462517]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -21.420717	array([[1.0405382, 0.6836742]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -7.710980	array([[-0.95753485, -0.1845376 ]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -15.899959	array([[-0.9662204 , -0.18764165]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -8.835054	array([[1.0641718, 0.6660187]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -11.864963	array([[1.0641742 , 0.66833115]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -22.097972	array([[1.0449867, 0.6873117]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -9.451366	array([[-0.95691025, -0.20113492]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -21.589752	array([[-0.95547247, -0.20011066]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -13.017129	array([[1.0450629 , 0.69310105]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -13.142988	array([[1.0453249, 0.6943815]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -20.224594	array([[1.0545098 , 0.69196355]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -9.666034	array([[-0.95980257, -0.201165  ]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -23.852852	array([[-0.9597714 , -0.20911498]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -15.226970	array([[1.0441022 , 0.69428504]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -16.175681	array([[1.0481364 , 0.69628894]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -22.734052	array([[1.0468214 , 0.69942474]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -8.575933	array([[-0.961006  , -0.20265032]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -24.195228	array([[-0.96223515, -0.20299084]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -18.230960	array([[1.051248 , 0.6956687]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -19.662769	array([[1.0377387 , 0.70084614]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -25.813827	array([[1.0414066 , 0.70175725]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -10.040014	array([[-0.9603494 , -0.21013723]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -25.952611	array([[-0.9644463 , -0.20884311]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -18.553626	array([[1.055429  , 0.69037807]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -21.689881	array([[1.0417339, 0.6978835]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -30.413207	array([[1.0286195, 0.7009897]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -11.971503	array([[-0.96361154, -0.20766708]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -24.504995	array([[-0.9753374 , -0.20650335]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -18.727003	array([[1.0668395 , 0.68989694]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -22.183132	array([[1.0534413 , 0.69590974]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -33.968522	array([[1.0316839 , 0.70376813]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -14.604643	array([[-0.9581944 , -0.21074808]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -27.690119	array([[-0.96390927, -0.21871996]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -19.335263	array([[1.072923  , 0.69524616]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -22.397613	array([[1.0620304, 0.7034848]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -35.854473	array([[1.0517732, 0.7081244]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -15.908957	array([[-0.9504105 , -0.21391505]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -30.924593	array([[-0.9439518 , -0.21519457]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -18.396783	array([[1.0717087, 0.7043546]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -21.160432	array([[1.0683111 , 0.70758027]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -32.084814	array([[1.0561194, 0.7152568]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -14.728050	array([[-0.9502879 , -0.22196855]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -32.228539	array([[-0.9508838 , -0.21934666]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -19.565160	array([[1.0775281, 0.7058623]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -20.909817	array([[1.0782244, 0.7066581]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -31.267701	array([[1.0776441 , 0.70627606]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -14.151298	array([[-0.95055753, -0.22642267]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -33.908970	array([[-0.9476207 , -0.21734467]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -22.061961	array([[1.0759327 , 0.71374655]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -22.685295	array([[1.0692697, 0.7181628]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -30.773235	array([[1.0767378, 0.7173992]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -15.083374	array([[-0.9508351 , -0.22467846]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -35.243917	array([[-0.95133966, -0.22340778]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -25.337279	array([[1.0693696, 0.7191846]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -26.682036	array([[1.0670156 , 0.71701527]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -34.580649	array([[1.0687774, 0.7171026]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -15.383108	array([[-0.94913405, -0.23279858]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -34.906468	array([[-0.95306945, -0.23049073]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -23.123609	array([[1.0903262, 0.683615 ]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -26.078236	array([[1.0849054, 0.6973748]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -37.023836	array([[1.0799735 , 0.70828843]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -16.220092	array([[-0.9488491 , -0.22756825]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -39.050102	array([[-0.9474293 , -0.22763401]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -24.488428	array([[1.078446  , 0.72610986]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -26.991891	array([[1.0806386 , 0.72357595]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -36.366527	array([[1.0763962, 0.7262132]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -17.834327	array([[-0.9444597 , -0.23325847]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -38.730682	array([[-0.94963855, -0.2292473 ]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -26.002164	array([[1.0844526 , 0.72122955]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -28.889741	array([[1.0848682, 0.7209074]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -44.600994	array([[1.0788101, 0.7274562]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -19.068271	array([[-0.944889  , -0.23098932]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -37.921330	array([[-0.941071  , -0.22913694]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -24.634555	array([[1.105842, 0.672422]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -25.943925	array([[1.0894568, 0.6972807]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -39.935318	array([[1.0935571 , 0.69737077]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -18.255677	array([[-0.9499713 , -0.23104075]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -40.713333	array([[-0.94596577, -0.2156015 ]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -26.794917	array([[1.0805241, 0.7206877]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -27.023915	array([[1.0793664 , 0.72988605]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 154565ms
 Real time factor: 4.32828
 UPS: 631.261929
Vehicles: 
 Inserted: 533 (Loaded: 536)
 Running: 264
 Waiting: 3

DijkstraRouter answered 562 queries and explored 2.00 edges on average.
DijkstraRouter spent 10ms answering queries (0.02ms on average).
Could not connect to TraCI server at localhost:49861 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 49861 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (2ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.899535	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -2.006765	array([[1.0501    , 0.61237735]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -3.284783	array([[1.0481704, 0.6200118]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.321901	array([[1.0481998 , 0.62680054]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = 1.361863	array([[-0.99001944, -0.16805756]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -5.557800	array([[-1.0004162 , -0.17056751]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -5.600162	array([[1.0446236 , 0.62983906]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -7.104438	array([[1.0452243 , 0.63860416]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -9.297937	array([[1.0436493, 0.6452585]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = 0.949055	array([[-0.97498536, -0.18036649]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -6.435112	array([[-0.99593055, -0.17488964]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -8.196788	array([[1.0483383, 0.6435051]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -10.730524	array([[1.0390803 , 0.65758175]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -14.561456	array([[1.0290447, 0.6689398]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -3.181728	array([[-0.9669156 , -0.18190551]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -6.420227	array([[-0.97659147, -0.1718344 ]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -7.660801	array([[1.0701779 , 0.64320225]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -11.311903	array([[1.0481454, 0.6623689]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -19.063168	array([[1.0279989, 0.6795651]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -5.574035	array([[-0.966948  , -0.18868518]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -10.591926	array([[-0.97640204, -0.17827913]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -7.083657	array([[1.0703481, 0.651363 ]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -11.190684	array([[1.0607029 , 0.66462517]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -21.420717	array([[1.0405382, 0.6836742]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -7.710980	array([[-0.95753485, -0.1845376 ]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -15.899959	array([[-0.9662204 , -0.18764165]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -8.835054	array([[1.0641718, 0.6660187]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -11.864963	array([[1.0641742 , 0.66833115]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -22.097972	array([[1.0449867, 0.6873117]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -9.451366	array([[-0.95691025, -0.20113492]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -21.589752	array([[-0.95547247, -0.20011066]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -13.017129	array([[1.0450629 , 0.69310105]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -13.142988	array([[1.0453249, 0.6943815]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -20.224594	array([[1.0545098 , 0.69196355]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -9.666034	array([[-0.95980257, -0.201165  ]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -23.852852	array([[-0.9597714 , -0.20911498]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -15.226970	array([[1.0441022 , 0.69428504]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -16.175681	array([[1.0481364 , 0.69628894]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -22.734052	array([[1.0468214 , 0.69942474]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -8.575933	array([[-0.961006  , -0.20265032]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -24.195228	array([[-0.96223515, -0.20299084]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -18.230960	array([[1.051248 , 0.6956687]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -19.662769	array([[1.0377387 , 0.70084614]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -25.813827	array([[1.0414066 , 0.70175725]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -10.040014	array([[-0.9603494 , -0.21013723]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -25.952611	array([[-0.9644463 , -0.20884311]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -18.553626	array([[1.055429  , 0.69037807]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -21.689881	array([[1.0417339, 0.6978835]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -30.413207	array([[1.0286195, 0.7009897]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -11.971503	array([[-0.96361154, -0.20766708]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -24.504995	array([[-0.9753374 , -0.20650335]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -18.727003	array([[1.0668395 , 0.68989694]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -22.183132	array([[1.0534413 , 0.69590974]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -33.968522	array([[1.0316839 , 0.70376813]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -14.604643	array([[-0.9581944 , -0.21074808]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -27.690119	array([[-0.96390927, -0.21871996]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -19.335263	array([[1.072923  , 0.69524616]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -22.397613	array([[1.0620304, 0.7034848]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -35.854473	array([[1.0517732, 0.7081244]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -15.908957	array([[-0.9504105 , -0.21391505]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -30.924593	array([[-0.9439518 , -0.21519457]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -18.396783	array([[1.0717087, 0.7043546]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -21.160432	array([[1.0683111 , 0.70758027]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -32.084814	array([[1.0561194, 0.7152568]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -14.728050	array([[-0.9502879 , -0.22196855]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -32.228539	array([[-0.9508838 , -0.21934666]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -19.565160	array([[1.0775281, 0.7058623]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -20.909817	array([[1.0782244, 0.7066581]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -31.267701	array([[1.0776441 , 0.70627606]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -14.151298	array([[-0.95055753, -0.22642267]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -33.908970	array([[-0.9476207 , -0.21734467]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -22.061961	array([[1.0759327 , 0.71374655]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -22.685295	array([[1.0692697, 0.7181628]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -30.773235	array([[1.0767378, 0.7173992]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -15.083374	array([[-0.9508351 , -0.22467846]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -35.243917	array([[-0.95133966, -0.22340778]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -25.337279	array([[1.0693696, 0.7191846]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -26.682036	array([[1.0670156 , 0.71701527]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -34.580649	array([[1.0687774, 0.7171026]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -15.383108	array([[-0.94913405, -0.23279858]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -34.906468	array([[-0.95306945, -0.23049073]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -23.123609	array([[1.0903262, 0.683615 ]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -26.078236	array([[1.0849054, 0.6973748]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -37.023836	array([[1.0799735 , 0.70828843]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -16.220092	array([[-0.9488491 , -0.22756825]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -39.050102	array([[-0.9474293 , -0.22763401]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -24.488428	array([[1.078446  , 0.72610986]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -26.991891	array([[1.0806386 , 0.72357595]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -36.366527	array([[1.0763962, 0.7262132]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -17.834327	array([[-0.9444597 , -0.23325847]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -38.730682	array([[-0.94963855, -0.2292473 ]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -26.002164	array([[1.0844526 , 0.72122955]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -28.889741	array([[1.0848682, 0.7209074]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -44.600994	array([[1.0788101, 0.7274562]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -19.068271	array([[-0.944889  , -0.23098932]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -37.921330	array([[-0.941071  , -0.22913694]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -24.634555	array([[1.105842, 0.672422]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -25.943925	array([[1.0894568, 0.6972807]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -39.935318	array([[1.0935571 , 0.69737077]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -18.255677	array([[-0.9499713 , -0.23104075]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -40.713333	array([[-0.94596577, -0.2156015 ]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -26.794917	array([[1.0805241, 0.7206877]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -27.023915	array([[1.0793664 , 0.72988605]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 150293ms
 Real time factor: 4.45131
 UPS: 649.205219
Vehicles: 
 Inserted: 533 (Loaded: 536)
 Running: 264
 Waiting: 3

DijkstraRouter answered 562 queries and explored 2.00 edges on average.
DijkstraRouter spent 3ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:54777 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 54777 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.899535	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -2.006765	array([[1.0501    , 0.61237735]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -3.284783	array([[1.0481704, 0.6200118]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.321901	array([[1.0481998 , 0.62680054]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = 1.361863	array([[-0.99001944, -0.16805756]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -5.557800	array([[-1.0004162 , -0.17056751]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -5.600162	array([[1.0446236 , 0.62983906]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -7.104438	array([[1.0452243 , 0.63860416]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -9.297937	array([[1.0436493, 0.6452585]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = 0.949055	array([[-0.97498536, -0.18036649]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -6.435112	array([[-0.99593055, -0.17488964]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -8.196788	array([[1.0483383, 0.6435051]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -10.730524	array([[1.0390803 , 0.65758175]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -14.561456	array([[1.0290447, 0.6689398]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -3.181728	array([[-0.9669156 , -0.18190551]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -6.420227	array([[-0.97659147, -0.1718344 ]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -7.660801	array([[1.0701779 , 0.64320225]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -11.311903	array([[1.0481454, 0.6623689]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -19.063168	array([[1.0279989, 0.6795651]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -5.574035	array([[-0.966948  , -0.18868518]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -10.591926	array([[-0.97640204, -0.17827913]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -7.083657	array([[1.0703481, 0.651363 ]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -11.190684	array([[1.0607029 , 0.66462517]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -21.420717	array([[1.0405382, 0.6836742]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -7.710980	array([[-0.95753485, -0.1845376 ]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -15.899959	array([[-0.9662204 , -0.18764165]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -8.835054	array([[1.0641718, 0.6660187]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -11.864963	array([[1.0641742 , 0.66833115]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -22.097972	array([[1.0449867, 0.6873117]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -9.451366	array([[-0.95691025, -0.20113492]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -21.589752	array([[-0.95547247, -0.20011066]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -13.017129	array([[1.0450629 , 0.69310105]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -13.142988	array([[1.0453249, 0.6943815]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -20.224594	array([[1.0545098 , 0.69196355]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -9.666034	array([[-0.95980257, -0.201165  ]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -23.852852	array([[-0.9597714 , -0.20911498]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -15.226970	array([[1.0441022 , 0.69428504]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -16.175681	array([[1.0481364 , 0.69628894]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -22.734052	array([[1.0468214 , 0.69942474]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -8.575933	array([[-0.961006  , -0.20265032]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -24.195228	array([[-0.96223515, -0.20299084]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -18.230960	array([[1.051248 , 0.6956687]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -19.662769	array([[1.0377387 , 0.70084614]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -25.813827	array([[1.0414066 , 0.70175725]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -10.040014	array([[-0.9603494 , -0.21013723]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -25.952611	array([[-0.9644463 , -0.20884311]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -18.553626	array([[1.055429  , 0.69037807]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -21.689881	array([[1.0417339, 0.6978835]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -30.413207	array([[1.0286195, 0.7009897]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -11.971503	array([[-0.96361154, -0.20766708]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -24.504995	array([[-0.9753374 , -0.20650335]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -18.727003	array([[1.0668395 , 0.68989694]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -22.183132	array([[1.0534413 , 0.69590974]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -33.968522	array([[1.0316839 , 0.70376813]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -14.604643	array([[-0.9581944 , -0.21074808]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -27.690119	array([[-0.96390927, -0.21871996]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -19.335263	array([[1.072923  , 0.69524616]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -22.397613	array([[1.0620304, 0.7034848]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -35.854473	array([[1.0517732, 0.7081244]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -15.908957	array([[-0.9504105 , -0.21391505]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -30.924593	array([[-0.9439518 , -0.21519457]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -18.396783	array([[1.0717087, 0.7043546]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -21.160432	array([[1.0683111 , 0.70758027]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -32.084814	array([[1.0561194, 0.7152568]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -14.728050	array([[-0.9502879 , -0.22196855]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -32.228539	array([[-0.9508838 , -0.21934666]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -19.565160	array([[1.0775281, 0.7058623]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -20.909817	array([[1.0782244, 0.7066581]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -31.267701	array([[1.0776441 , 0.70627606]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -14.151298	array([[-0.95055753, -0.22642267]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -33.908970	array([[-0.9476207 , -0.21734467]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -22.061961	array([[1.0759327 , 0.71374655]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -22.685295	array([[1.0692697, 0.7181628]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -30.773235	array([[1.0767378, 0.7173992]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -15.083374	array([[-0.9508351 , -0.22467846]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -35.243917	array([[-0.95133966, -0.22340778]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -25.337279	array([[1.0693696, 0.7191846]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -26.682036	array([[1.0670156 , 0.71701527]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -34.580649	array([[1.0687774, 0.7171026]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -15.383108	array([[-0.94913405, -0.23279858]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -34.906468	array([[-0.95306945, -0.23049073]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -23.123609	array([[1.0903262, 0.683615 ]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -26.078236	array([[1.0849054, 0.6973748]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -37.023836	array([[1.0799735 , 0.70828843]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -16.220092	array([[-0.9488491 , -0.22756825]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -39.050102	array([[-0.9474293 , -0.22763401]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -24.488428	array([[1.078446  , 0.72610986]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -26.991891	array([[1.0806386 , 0.72357595]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -36.366527	array([[1.0763962, 0.7262132]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -17.834327	array([[-0.9444597 , -0.23325847]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -38.730682	array([[-0.94963855, -0.2292473 ]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -26.002164	array([[1.0844526 , 0.72122955]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -28.889741	array([[1.0848682, 0.7209074]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -44.600994	array([[1.0788101, 0.7274562]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -19.068271	array([[-0.944889  , -0.23098932]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -37.921330	array([[-0.941071  , -0.22913694]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -24.634555	array([[1.105842, 0.672422]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -25.943925	array([[1.0894568, 0.6972807]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -39.935318	array([[1.0935571 , 0.69737077]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -18.255677	array([[-0.9499713 , -0.23104075]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -40.713333	array([[-0.94596577, -0.2156015 ]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -26.794917	array([[1.0805241, 0.7206877]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -27.023915	array([[1.0793664 , 0.72988605]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 156759ms
 Real time factor: 4.2677
 UPS: 622.426783
Vehicles: 
 Inserted: 533 (Loaded: 536)
 Running: 264
 Waiting: 3

DijkstraRouter answered 562 queries and explored 2.00 edges on average.
DijkstraRouter spent 3ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:39887 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 39887 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.899535	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -2.006765	array([[1.0501    , 0.61237735]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -3.284783	array([[1.0481704, 0.6200118]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.321901	array([[1.0481998 , 0.62680054]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = 1.361863	array([[-0.99001944, -0.16805756]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -5.557800	array([[-1.0004162 , -0.17056751]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -5.600162	array([[1.0446236 , 0.62983906]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -7.104438	array([[1.0452243 , 0.63860416]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -9.297937	array([[1.0436493, 0.6452585]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = 0.949055	array([[-0.97498536, -0.18036649]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -6.435112	array([[-0.99593055, -0.17488964]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -8.196788	array([[1.0483383, 0.6435051]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -10.730524	array([[1.0390803 , 0.65758175]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -14.561456	array([[1.0290447, 0.6689398]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -3.181728	array([[-0.9669156 , -0.18190551]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -6.420227	array([[-0.97659147, -0.1718344 ]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -7.660801	array([[1.0701779 , 0.64320225]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -11.311903	array([[1.0481454, 0.6623689]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -19.063168	array([[1.0279989, 0.6795651]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -5.574035	array([[-0.966948  , -0.18868518]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -10.591926	array([[-0.97640204, -0.17827913]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -7.083657	array([[1.0703481, 0.651363 ]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -11.190684	array([[1.0607029 , 0.66462517]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -21.420717	array([[1.0405382, 0.6836742]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -7.710980	array([[-0.95753485, -0.1845376 ]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -15.899959	array([[-0.9662204 , -0.18764165]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -8.835054	array([[1.0641718, 0.6660187]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -11.864963	array([[1.0641742 , 0.66833115]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -22.097972	array([[1.0449867, 0.6873117]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -9.451366	array([[-0.95691025, -0.20113492]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -21.589752	array([[-0.95547247, -0.20011066]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -13.017129	array([[1.0450629 , 0.69310105]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -13.142988	array([[1.0453249, 0.6943815]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -20.224594	array([[1.0545098 , 0.69196355]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -9.666034	array([[-0.95980257, -0.201165  ]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -23.852852	array([[-0.9597714 , -0.20911498]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -15.226970	array([[1.0441022 , 0.69428504]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -16.175681	array([[1.0481364 , 0.69628894]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -22.734052	array([[1.0468214 , 0.69942474]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -8.575933	array([[-0.961006  , -0.20265032]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -24.195228	array([[-0.96223515, -0.20299084]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -18.230960	array([[1.051248 , 0.6956687]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -19.662769	array([[1.0377387 , 0.70084614]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -25.813827	array([[1.0414066 , 0.70175725]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -10.040014	array([[-0.9603494 , -0.21013723]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -25.952611	array([[-0.9644463 , -0.20884311]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -18.553626	array([[1.055429  , 0.69037807]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -21.689881	array([[1.0417339, 0.6978835]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -30.413207	array([[1.0286195, 0.7009897]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -11.971503	array([[-0.96361154, -0.20766708]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -24.504995	array([[-0.9753374 , -0.20650335]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -18.727003	array([[1.0668395 , 0.68989694]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -22.183132	array([[1.0534413 , 0.69590974]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -33.968522	array([[1.0316839 , 0.70376813]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -14.604643	array([[-0.9581944 , -0.21074808]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -27.690119	array([[-0.96390927, -0.21871996]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -19.335263	array([[1.072923  , 0.69524616]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -22.397613	array([[1.0620304, 0.7034848]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -35.854473	array([[1.0517732, 0.7081244]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -15.908957	array([[-0.9504105 , -0.21391505]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -30.924593	array([[-0.9439518 , -0.21519457]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -18.396783	array([[1.0717087, 0.7043546]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -21.160432	array([[1.0683111 , 0.70758027]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -32.084814	array([[1.0561194, 0.7152568]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -14.728050	array([[-0.9502879 , -0.22196855]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -32.228539	array([[-0.9508838 , -0.21934666]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -19.565160	array([[1.0775281, 0.7058623]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -20.909817	array([[1.0782244, 0.7066581]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -31.267701	array([[1.0776441 , 0.70627606]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -14.151298	array([[-0.95055753, -0.22642267]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -33.908970	array([[-0.9476207 , -0.21734467]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -22.061961	array([[1.0759327 , 0.71374655]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -22.685295	array([[1.0692697, 0.7181628]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -30.773235	array([[1.0767378, 0.7173992]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -15.083374	array([[-0.9508351 , -0.22467846]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -35.243917	array([[-0.95133966, -0.22340778]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -25.337279	array([[1.0693696, 0.7191846]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -26.682036	array([[1.0670156 , 0.71701527]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -34.580649	array([[1.0687774, 0.7171026]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -15.383108	array([[-0.94913405, -0.23279858]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -34.906468	array([[-0.95306945, -0.23049073]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -23.123609	array([[1.0903262, 0.683615 ]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -26.078236	array([[1.0849054, 0.6973748]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -37.023836	array([[1.0799735 , 0.70828843]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -16.220092	array([[-0.9488491 , -0.22756825]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -39.050102	array([[-0.9474293 , -0.22763401]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -24.488428	array([[1.078446  , 0.72610986]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -26.991891	array([[1.0806386 , 0.72357595]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -36.366527	array([[1.0763962, 0.7262132]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -17.834327	array([[-0.9444597 , -0.23325847]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -38.730682	array([[-0.94963855, -0.2292473 ]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -26.002164	array([[1.0844526 , 0.72122955]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -28.889741	array([[1.0848682, 0.7209074]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -44.600994	array([[1.0788101, 0.7274562]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -19.068271	array([[-0.944889  , -0.23098932]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -37.921330	array([[-0.941071  , -0.22913694]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -24.634555	array([[1.105842, 0.672422]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -25.943925	array([[1.0894568, 0.6972807]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -39.935318	array([[1.0935571 , 0.69737077]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -18.255677	array([[-0.9499713 , -0.23104075]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -40.713333	array([[-0.94596577, -0.2156015 ]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -26.794917	array([[1.0805241, 0.7206877]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -27.023915	array([[1.0793664 , 0.72988605]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 150724ms
 Real time factor: 4.43858
 UPS: 647.348796
Vehicles: 
 Inserted: 533 (Loaded: 536)
 Running: 264
 Waiting: 3

DijkstraRouter answered 562 queries and explored 2.00 edges on average.
DijkstraRouter spent 8ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:51043 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 51043 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (2ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.899535	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -2.006765	array([[1.0501    , 0.61237735]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -3.284783	array([[1.0481704, 0.6200118]], dtype=float32)
time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -3.321901	array([[1.0481998 , 0.62680054]], dtype=float32)
time = 56	action = 0	current_phase = 0	next_phase = 1	reward = 1.361863	array([[-0.99001944, -0.16805756]], dtype=float32)
time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -5.557800	array([[-1.0004162 , -0.17056751]], dtype=float32)
time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -5.600162	array([[1.0446236 , 0.62983906]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -7.104438	array([[1.0452243 , 0.63860416]], dtype=float32)
time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -9.297937	array([[1.0436493, 0.6452585]], dtype=float32)
time = 87	action = 0	current_phase = 0	next_phase = 1	reward = 0.949055	array([[-0.97498536, -0.18036649]], dtype=float32)
time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -6.435112	array([[-0.99593055, -0.17488964]], dtype=float32)
time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -8.196788	array([[1.0483383, 0.6435051]], dtype=float32)
time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -10.730524	array([[1.0390803 , 0.65758175]], dtype=float32)
time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -14.561456	array([[1.0290447, 0.6689398]], dtype=float32)
time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -3.181728	array([[-0.9669156 , -0.18190551]], dtype=float32)
time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -6.420227	array([[-0.97659147, -0.1718344 ]], dtype=float32)
time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -7.660801	array([[1.0701779 , 0.64320225]], dtype=float32)
time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -11.311903	array([[1.0481454, 0.6623689]], dtype=float32)
time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -19.063168	array([[1.0279989, 0.6795651]], dtype=float32)
time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -5.574035	array([[-0.966948  , -0.18868518]], dtype=float32)
time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -10.591926	array([[-0.97640204, -0.17827913]], dtype=float32)
time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -7.083657	array([[1.0703481, 0.651363 ]], dtype=float32)
time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -11.190684	array([[1.0607029 , 0.66462517]], dtype=float32)
time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -21.420717	array([[1.0405382, 0.6836742]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -7.710980	array([[-0.95753485, -0.1845376 ]], dtype=float32)
time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -15.899959	array([[-0.9662204 , -0.18764165]], dtype=float32)
time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -8.835054	array([[1.0641718, 0.6660187]], dtype=float32)
time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -11.864963	array([[1.0641742 , 0.66833115]], dtype=float32)
time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -22.097972	array([[1.0449867, 0.6873117]], dtype=float32)
time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -9.451366	array([[-0.95691025, -0.20113492]], dtype=float32)
time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -21.589752	array([[-0.95547247, -0.20011066]], dtype=float32)
time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -13.017129	array([[1.0450629 , 0.69310105]], dtype=float32)
time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -13.142988	array([[1.0453249, 0.6943815]], dtype=float32)
time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -20.224594	array([[1.0545098 , 0.69196355]], dtype=float32)
time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -9.666034	array([[-0.95980257, -0.201165  ]], dtype=float32)
time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -23.852852	array([[-0.9597714 , -0.20911498]], dtype=float32)
time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -15.226970	array([[1.0441022 , 0.69428504]], dtype=float32)
time = 260	action = 0	current_phase = 1	next_phase = 0	reward = -16.175681	array([[1.0481364 , 0.69628894]], dtype=float32)
time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -22.734052	array([[1.0468214 , 0.69942474]], dtype=float32)
time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -8.575933	array([[-0.961006  , -0.20265032]], dtype=float32)
time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -24.195228	array([[-0.96223515, -0.20299084]], dtype=float32)
time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -18.230960	array([[1.051248 , 0.6956687]], dtype=float32)
time = 291	action = 0	current_phase = 1	next_phase = 0	reward = -19.662769	array([[1.0377387 , 0.70084614]], dtype=float32)
time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -25.813827	array([[1.0414066 , 0.70175725]], dtype=float32)
time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -10.040014	array([[-0.9603494 , -0.21013723]], dtype=float32)
time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -25.952611	array([[-0.9644463 , -0.20884311]], dtype=float32)
time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -18.553626	array([[1.055429  , 0.69037807]], dtype=float32)
time = 322	action = 0	current_phase = 1	next_phase = 0	reward = -21.689881	array([[1.0417339, 0.6978835]], dtype=float32)
time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -30.413207	array([[1.0286195, 0.7009897]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -11.971503	array([[-0.96361154, -0.20766708]], dtype=float32)
time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -24.504995	array([[-0.9753374 , -0.20650335]], dtype=float32)
time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -18.727003	array([[1.0668395 , 0.68989694]], dtype=float32)
time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -22.183132	array([[1.0534413 , 0.69590974]], dtype=float32)
time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -33.968522	array([[1.0316839 , 0.70376813]], dtype=float32)
time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -14.604643	array([[-0.9581944 , -0.21074808]], dtype=float32)
time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -27.690119	array([[-0.96390927, -0.21871996]], dtype=float32)
time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -19.335263	array([[1.072923  , 0.69524616]], dtype=float32)
time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -22.397613	array([[1.0620304, 0.7034848]], dtype=float32)
time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -35.854473	array([[1.0517732, 0.7081244]], dtype=float32)
time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -15.908957	array([[-0.9504105 , -0.21391505]], dtype=float32)
time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -30.924593	array([[-0.9439518 , -0.21519457]], dtype=float32)
time = 410	action = 0	current_phase = 1	next_phase = 0	reward = -18.396783	array([[1.0717087, 0.7043546]], dtype=float32)
time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -21.160432	array([[1.0683111 , 0.70758027]], dtype=float32)
time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -32.084814	array([[1.0561194, 0.7152568]], dtype=float32)
time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -14.728050	array([[-0.9502879 , -0.22196855]], dtype=float32)
time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -32.228539	array([[-0.9508838 , -0.21934666]], dtype=float32)
time = 441	action = 0	current_phase = 1	next_phase = 0	reward = -19.565160	array([[1.0775281, 0.7058623]], dtype=float32)
time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -20.909817	array([[1.0782244, 0.7066581]], dtype=float32)
time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -31.267701	array([[1.0776441 , 0.70627606]], dtype=float32)
time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -14.151298	array([[-0.95055753, -0.22642267]], dtype=float32)
time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -33.908970	array([[-0.9476207 , -0.21734467]], dtype=float32)
time = 472	action = 0	current_phase = 1	next_phase = 0	reward = -22.061961	array([[1.0759327 , 0.71374655]], dtype=float32)
time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -22.685295	array([[1.0692697, 0.7181628]], dtype=float32)
time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -30.773235	array([[1.0767378, 0.7173992]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -15.083374	array([[-0.9508351 , -0.22467846]], dtype=float32)
time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -35.243917	array([[-0.95133966, -0.22340778]], dtype=float32)
time = 503	action = 0	current_phase = 1	next_phase = 0	reward = -25.337279	array([[1.0693696, 0.7191846]], dtype=float32)
time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -26.682036	array([[1.0670156 , 0.71701527]], dtype=float32)
time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -34.580649	array([[1.0687774, 0.7171026]], dtype=float32)
time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -15.383108	array([[-0.94913405, -0.23279858]], dtype=float32)
time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -34.906468	array([[-0.95306945, -0.23049073]], dtype=float32)
time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -23.123609	array([[1.0903262, 0.683615 ]], dtype=float32)
time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -26.078236	array([[1.0849054, 0.6973748]], dtype=float32)
time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -37.023836	array([[1.0799735 , 0.70828843]], dtype=float32)
time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -16.220092	array([[-0.9488491 , -0.22756825]], dtype=float32)
time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -39.050102	array([[-0.9474293 , -0.22763401]], dtype=float32)
time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -24.488428	array([[1.078446  , 0.72610986]], dtype=float32)
time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -26.991891	array([[1.0806386 , 0.72357595]], dtype=float32)
time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -36.366527	array([[1.0763962, 0.7262132]], dtype=float32)
time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -17.834327	array([[-0.9444597 , -0.23325847]], dtype=float32)
time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -38.730682	array([[-0.94963855, -0.2292473 ]], dtype=float32)
time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -26.002164	array([[1.0844526 , 0.72122955]], dtype=float32)
time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -28.889741	array([[1.0848682, 0.7209074]], dtype=float32)
time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -44.600994	array([[1.0788101, 0.7274562]], dtype=float32)
time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -19.068271	array([[-0.944889  , -0.23098932]], dtype=float32)
time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -37.921330	array([[-0.941071  , -0.22913694]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -24.634555	array([[1.105842, 0.672422]], dtype=float32)
time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -25.943925	array([[1.0894568, 0.6972807]], dtype=float32)
time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -39.935318	array([[1.0935571 , 0.69737077]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -18.255677	array([[-0.9499713 , -0.23104075]], dtype=float32)
time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -40.713333	array([[-0.94596577, -0.2156015 ]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -26.794917	array([[1.0805241, 0.7206877]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -27.023915	array([[1.0793664 , 0.72988605]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 151354ms
 Real time factor: 4.4201
 UPS: 644.654254
Vehicles: 
 Inserted: 533 (Loaded: 536)
 Running: 264
 Waiting: 3

DijkstraRouter answered 562 queries and explored 2.00 edges on average.
DijkstraRouter spent 7ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:51329 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 51329 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.899535	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -2.006765	array([[1.0501    , 0.61237735]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -3.284783	array([[1.0481704, 0.6200118]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -4.580413	array([[1.0481998 , 0.62680054]], dtype=float32)
time = 53	action = 1	current_phase = 1	next_phase = 0	reward = -5.142794	array([[1.0465941, 0.6342878]], dtype=float32)
time = 61	action = 0	current_phase = 0	next_phase = 1	reward = 2.072926	array([[-0.983836 , -0.1672456]], dtype=float32)
time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -4.767076	array([[-0.9912259 , -0.16881643]], dtype=float32)
time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -5.917443	array([[1.0485313 , 0.63614476]], dtype=float32)
time = 79	action = 0	current_phase = 1	next_phase = 0	reward = -7.605910	array([[1.0424932, 0.6477127]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -9.283130	array([[1.0427344, 0.6526262]], dtype=float32)
time = 89	action = 1	current_phase = 1	next_phase = 0	reward = -12.599454	array([[1.0413151 , 0.65969944]], dtype=float32)
time = 97	action = 0	current_phase = 0	next_phase = 1	reward = -0.416168	array([[-0.9635305 , -0.18447825]], dtype=float32)
time = 102	action = 1	current_phase = 0	next_phase = 1	reward = -5.254764	array([[-0.97726053, -0.16482216]], dtype=float32)
time = 110	action = 0	current_phase = 1	next_phase = 0	reward = -7.099274	array([[1.0518109, 0.6523296]], dtype=float32)
time = 115	action = 0	current_phase = 1	next_phase = 0	reward = -10.862821	array([[1.0303661, 0.669204 ]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -13.630395	array([[1.018771  , 0.68059015]], dtype=float32)
time = 125	action = 1	current_phase = 1	next_phase = 0	reward = -19.217255	array([[1.0189539, 0.6853378]], dtype=float32)
time = 133	action = 0	current_phase = 0	next_phase = 1	reward = -5.167562	array([[-0.97338325, -0.18092366]], dtype=float32)
time = 138	action = 1	current_phase = 0	next_phase = 1	reward = -8.796781	array([[-0.9852558 , -0.17550212]], dtype=float32)
time = 146	action = 0	current_phase = 1	next_phase = 0	reward = -6.330981	array([[1.059179, 0.654068]], dtype=float32)
time = 151	action = 0	current_phase = 1	next_phase = 0	reward = -10.178876	array([[1.0515507 , 0.66681874]], dtype=float32)
time = 156	action = 0	current_phase = 1	next_phase = 0	reward = -14.677827	array([[1.035429 , 0.6815629]], dtype=float32)
time = 161	action = 1	current_phase = 1	next_phase = 0	reward = -24.232848	array([[1.0122336 , 0.69650626]], dtype=float32)
time = 169	action = 0	current_phase = 0	next_phase = 1	reward = -9.673581	array([[-0.9605353 , -0.18015006]], dtype=float32)
time = 174	action = 1	current_phase = 0	next_phase = 1	reward = -15.935977	array([[-0.9694152 , -0.18430999]], dtype=float32)
time = 182	action = 0	current_phase = 1	next_phase = 0	reward = -9.206761	array([[1.0601472 , 0.67139345]], dtype=float32)
time = 187	action = 0	current_phase = 1	next_phase = 0	reward = -11.666649	array([[1.0568544, 0.6772359]], dtype=float32)
time = 192	action = 0	current_phase = 1	next_phase = 0	reward = -16.091390	array([[1.0410206, 0.6930376]], dtype=float32)
time = 197	action = 1	current_phase = 1	next_phase = 0	reward = -28.880225	array([[1.0210309, 0.7038667]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -12.940312	array([[-0.9485978 , -0.18615046]], dtype=float32)
time = 210	action = 1	current_phase = 0	next_phase = 1	reward = -24.660351	array([[-0.95327914, -0.1935166 ]], dtype=float32)
time = 218	action = 0	current_phase = 1	next_phase = 0	reward = -14.393661	array([[1.0451905, 0.6967745]], dtype=float32)
time = 223	action = 0	current_phase = 1	next_phase = 0	reward = -14.272833	array([[1.052682  , 0.69386244]], dtype=float32)
time = 228	action = 0	current_phase = 1	next_phase = 0	reward = -16.521445	array([[1.0582604, 0.693718 ]], dtype=float32)
time = 233	action = 1	current_phase = 1	next_phase = 0	reward = -28.556068	array([[1.0431914 , 0.70445913]], dtype=float32)
time = 241	action = 0	current_phase = 0	next_phase = 1	reward = -13.525706	array([[-0.94719744, -0.20708305]], dtype=float32)
time = 246	action = 1	current_phase = 0	next_phase = 1	reward = -30.146453	array([[-0.945825  , -0.20452103]], dtype=float32)
time = 254	action = 0	current_phase = 1	next_phase = 0	reward = -18.188618	array([[1.0389407 , 0.70589703]], dtype=float32)
time = 259	action = 0	current_phase = 1	next_phase = 0	reward = -18.491009	array([[1.049005 , 0.7035415]], dtype=float32)
time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -19.387664	array([[1.0466621, 0.7058399]], dtype=float32)
time = 269	action = 1	current_phase = 1	next_phase = 0	reward = -28.070907	array([[1.0501703, 0.7082722]], dtype=float32)
time = 277	action = 0	current_phase = 0	next_phase = 1	reward = -13.935330	array([[-0.95882404, -0.21525574]], dtype=float32)
time = 282	action = 1	current_phase = 0	next_phase = 1	reward = -33.606330	array([[-0.9526138 , -0.21488827]], dtype=float32)
time = 290	action = 0	current_phase = 1	next_phase = 0	reward = -22.464904	array([[1.0325073, 0.7097   ]], dtype=float32)
time = 295	action = 0	current_phase = 1	next_phase = 0	reward = -24.235595	array([[1.0322539, 0.7098141]], dtype=float32)
time = 300	action = 0	current_phase = 1	next_phase = 0	reward = -25.679832	array([[1.0284495 , 0.71469015]], dtype=float32)
time = 305	action = 1	current_phase = 1	next_phase = 0	reward = -35.864734	array([[1.0328188, 0.7157506]], dtype=float32)
time = 313	action = 0	current_phase = 0	next_phase = 1	reward = -14.249221	array([[-0.9503246 , -0.22232015]], dtype=float32)
time = 318	action = 1	current_phase = 0	next_phase = 1	reward = -33.816007	array([[-0.95687336, -0.21628882]], dtype=float32)
time = 326	action = 0	current_phase = 1	next_phase = 0	reward = -23.853805	array([[1.0555313, 0.7084433]], dtype=float32)
time = 331	action = 0	current_phase = 1	next_phase = 0	reward = -27.629228	array([[1.0362921 , 0.71300125]], dtype=float32)
time = 336	action = 0	current_phase = 1	next_phase = 0	reward = -29.803602	array([[1.0189779 , 0.71681845]], dtype=float32)
time = 341	action = 1	current_phase = 1	next_phase = 0	reward = -42.934794	array([[1.0169748 , 0.71717435]], dtype=float32)
time = 349	action = 0	current_phase = 0	next_phase = 1	reward = -16.536547	array([[-0.9454633 , -0.21719885]], dtype=float32)
time = 354	action = 1	current_phase = 0	next_phase = 1	reward = -33.677397	array([[-0.9483741 , -0.21985063]], dtype=float32)
time = 362	action = 0	current_phase = 1	next_phase = 0	reward = -23.693666	array([[1.0705054, 0.708218 ]], dtype=float32)
time = 367	action = 0	current_phase = 1	next_phase = 0	reward = -27.319162	array([[1.0605065, 0.7134493]], dtype=float32)
time = 372	action = 0	current_phase = 1	next_phase = 0	reward = -31.375994	array([[1.0344201 , 0.71707034]], dtype=float32)
time = 377	action = 1	current_phase = 1	next_phase = 0	reward = -46.126249	array([[1.0169685, 0.7206528]], dtype=float32)
time = 385	action = 0	current_phase = 0	next_phase = 1	reward = -20.906764	array([[-0.9427491 , -0.21532354]], dtype=float32)
time = 390	action = 1	current_phase = 0	next_phase = 1	reward = -37.294694	array([[-0.94070584, -0.22165015]], dtype=float32)
time = 398	action = 0	current_phase = 1	next_phase = 0	reward = -23.458908	array([[1.081248  , 0.70617145]], dtype=float32)
time = 403	action = 0	current_phase = 1	next_phase = 0	reward = -26.105633	array([[1.0715892 , 0.71641076]], dtype=float32)
time = 408	action = 0	current_phase = 1	next_phase = 0	reward = -29.657580	array([[1.0525521, 0.7213685]], dtype=float32)
time = 413	action = 1	current_phase = 1	next_phase = 0	reward = -44.403489	array([[1.0374753 , 0.72486585]], dtype=float32)
time = 421	action = 0	current_phase = 0	next_phase = 1	reward = -20.799342	array([[-0.94363445, -0.21930626]], dtype=float32)
time = 426	action = 1	current_phase = 0	next_phase = 1	reward = -39.261801	array([[-0.9450174, -0.2230076]], dtype=float32)
time = 434	action = 0	current_phase = 1	next_phase = 0	reward = -23.695577	array([[1.0694079 , 0.72410434]], dtype=float32)
time = 439	action = 0	current_phase = 1	next_phase = 0	reward = -26.286136	array([[1.0630065, 0.7220577]], dtype=float32)
time = 444	action = 0	current_phase = 1	next_phase = 0	reward = -29.663641	array([[1.0549835 , 0.72418433]], dtype=float32)
time = 449	action = 1	current_phase = 1	next_phase = 0	reward = -46.827663	array([[1.0334584 , 0.73037875]], dtype=float32)
time = 457	action = 0	current_phase = 0	next_phase = 1	reward = -20.979695	array([[-0.9316681, -0.1820991]], dtype=float32)
time = 462	action = 1	current_phase = 0	next_phase = 1	reward = -43.321279	array([[-0.9358463 , -0.21192558]], dtype=float32)
time = 470	action = 0	current_phase = 1	next_phase = 0	reward = -27.683660	array([[1.0561546 , 0.73303324]], dtype=float32)
time = 475	action = 0	current_phase = 1	next_phase = 0	reward = -28.364206	array([[1.05634  , 0.7259314]], dtype=float32)
time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -31.525405	array([[1.0562985, 0.7263452]], dtype=float32)
time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -47.866229	array([[1.0406165, 0.731837 ]], dtype=float32)
time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -21.441193	array([[-0.9431696 , -0.20700583]], dtype=float32)
time = 498	action = 1	current_phase = 0	next_phase = 1	reward = -42.709372	array([[-0.9468906 , -0.21580067]], dtype=float32)
time = 506	action = 0	current_phase = 1	next_phase = 0	reward = -27.121652	array([[1.079937  , 0.70312166]], dtype=float32)
time = 511	action = 0	current_phase = 1	next_phase = 0	reward = -28.608454	array([[1.0744219, 0.7162893]], dtype=float32)
time = 516	action = 0	current_phase = 1	next_phase = 0	reward = -32.448123	array([[1.0663943, 0.7169615]], dtype=float32)
time = 521	action = 1	current_phase = 1	next_phase = 0	reward = -47.467751	array([[1.0541177, 0.7202327]], dtype=float32)
time = 529	action = 0	current_phase = 0	next_phase = 1	reward = -23.209620	array([[-0.9451863 , -0.21639845]], dtype=float32)
time = 534	action = 1	current_phase = 0	next_phase = 1	reward = -43.574682	array([[-0.9437694 , -0.21588328]], dtype=float32)
time = 542	action = 0	current_phase = 1	next_phase = 0	reward = -27.591225	array([[1.0760045, 0.7200533]], dtype=float32)
time = 547	action = 0	current_phase = 1	next_phase = 0	reward = -30.749754	array([[1.0766126 , 0.72359824]], dtype=float32)
time = 552	action = 0	current_phase = 1	next_phase = 0	reward = -34.003359	array([[1.0632895 , 0.73205286]], dtype=float32)
time = 557	action = 1	current_phase = 1	next_phase = 0	reward = -49.460738	array([[1.0553743 , 0.73274016]], dtype=float32)
time = 565	action = 0	current_phase = 0	next_phase = 1	reward = -25.051767	array([[-0.94041437, -0.22269773]], dtype=float32)
time = 570	action = 1	current_phase = 0	next_phase = 1	reward = -53.419779	array([[-0.94245684, -0.21403143]], dtype=float32)
time = 578	action = 0	current_phase = 1	next_phase = 0	reward = -34.602049	array([[1.070489 , 0.7274366]], dtype=float32)
time = 583	action = 0	current_phase = 1	next_phase = 0	reward = -36.262886	array([[1.0698122, 0.7240346]], dtype=float32)
time = 588	action = 0	current_phase = 1	next_phase = 0	reward = -38.730692	array([[1.0591578 , 0.72731364]], dtype=float32)
time = 593	action = 1	current_phase = 1	next_phase = 0	reward = -59.344019	array([[1.0451943, 0.7251204]], dtype=float32)
time = 601	action = 0	current_phase = 0	next_phase = 1	reward = -25.713026	array([[-0.94574517, -0.23191051]], dtype=float32)
time = 606	action = 1	current_phase = 0	next_phase = 1	reward = -52.956408	array([[-0.9469931 , -0.23658389]], dtype=float32)
time = 614	action = 0	current_phase = 1	next_phase = 0	reward = -34.401459	array([[1.0757673 , 0.71873266]], dtype=float32)
time = 619	action = 0	current_phase = 1	next_phase = 0	reward = -37.816149	array([[1.0694635 , 0.71750546]], dtype=float32)
time = 624	action = 0	current_phase = 1	next_phase = 0	reward = -40.346129	array([[1.0587358, 0.7161413]], dtype=float32)
time = 629	action = 1	current_phase = 1	next_phase = 0	reward = -61.157627	array([[1.0552723 , 0.72161865]], dtype=float32)
time = 637	action = 0	current_phase = 0	next_phase = 1	reward = -22.687526	array([[-0.9437625 , -0.23087882]], dtype=float32)
time = 642	action = 1	current_phase = 0	next_phase = 1	reward = -40.935408	array([[-0.93685794, -0.24366754]], dtype=float32)
time = 650	action = 0	current_phase = 1	next_phase = 0	reward = -28.063841	array([[1.0710968, 0.723178 ]], dtype=float32)
time = 655	action = 0	current_phase = 1	next_phase = 0	reward = -32.734772	array([[1.0442406, 0.7327974]], dtype=float32)
time = 660	action = 0	current_phase = 1	next_phase = 0	reward = -38.583855	array([[1.05241   , 0.72006893]], dtype=float32)
time = 665	action = 1	current_phase = 1	next_phase = 0	reward = -55.031673	array([[1.0114148 , 0.72678614]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 674.00
Reason: TraCI requested termination.
Performance: 
 Duration: 170081ms
 Real time factor: 3.96282
 UPS: 627.265832
Vehicles: 
 Inserted: 513 (Loaded: 540)
 Running: 265
 Waiting: 27

DijkstraRouter answered 1544 queries and explored 2.00 edges on average.
DijkstraRouter spent 16ms answering queries (0.01ms on average).
Could not connect to TraCI server at localhost:43141 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 43141 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (2ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (1ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (1ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[-0.99821293, -0.16335824]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[-1.0066959, -0.147993 ]], dtype=float32)
time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -1.899535	array([[-1.006308  , -0.14736545]], dtype=float32)
time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -2.006765	array([[1.0501    , 0.61237735]], dtype=float32)
time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -3.284783	array([[1.0481704, 0.6200118]], dtype=float32)
time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -4.580413	array([[1.0481998 , 0.62680054]], dtype=float32)
time = 53	action = 0	current_phase = 1	next_phase = 0	reward = -5.947603	array([[1.0465941, 0.6342878]], dtype=float32)
time = 58	action = 1	current_phase = 1	next_phase = 0	reward = -6.852087	array([[1.0475013, 0.6425427]], dtype=float32)
time = 66	action = 0	current_phase = 0	next_phase = 1	reward = 1.444265	array([[-0.99250245, -0.1694389 ]], dtype=float32)
time = 71	action = 1	current_phase = 0	next_phase = 1	reward = -4.874957	array([[-0.9934163 , -0.16678658]], dtype=float32)
time = 79	action = 0	current_phase = 1	next_phase = 0	reward = -6.520827	array([[1.0479727, 0.6389175]], dtype=float32)
time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -8.834923	array([[1.0393881 , 0.65140784]], dtype=float32)
time = 89	action = 0	current_phase = 1	next_phase = 0	reward = -10.498403	array([[1.0384208 , 0.66026354]], dtype=float32)
time = 94	action = 0	current_phase = 1	next_phase = 0	reward = -12.386440	array([[1.0375987 , 0.66711307]], dtype=float32)
time = 99	action = 1	current_phase = 1	next_phase = 0	reward = -16.576424	array([[1.0363051, 0.6735885]], dtype=float32)
time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -3.230303	array([[-0.96501267, -0.19319296]], dtype=float32)
time = 112	action = 1	current_phase = 0	next_phase = 1	reward = -6.548398	array([[-0.9801726 , -0.19254199]], dtype=float32)
time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -7.268764	array([[1.056296  , 0.64672184]], dtype=float32)
time = 125	action = 0	current_phase = 1	next_phase = 0	reward = -11.366701	array([[1.0407537 , 0.66430587]], dtype=float32)
time = 130	action = 0	current_phase = 1	next_phase = 0	reward = -15.153665	array([[1.0190316 , 0.68137187]], dtype=float32)
time = 135	action = 0	current_phase = 1	next_phase = 0	reward = -17.817931	array([[1.0106239, 0.6906971]], dtype=float32)
time = 140	action = 1	current_phase = 1	next_phase = 0	reward = -26.088828	array([[1.0079715, 0.6983814]], dtype=float32)
time = 148	action = 0	current_phase = 0	next_phase = 1	reward = -8.932382	array([[-0.9632415, -0.1805683]], dtype=float32)
time = 153	action = 1	current_phase = 0	next_phase = 1	reward = -14.821260	array([[-0.97626096, -0.18247636]], dtype=float32)
time = 161	action = 0	current_phase = 1	next_phase = 0	reward = -8.250196	array([[1.0620384, 0.6647478]], dtype=float32)
time = 166	action = 0	current_phase = 1	next_phase = 0	reward = -10.676217	array([[1.0629947 , 0.66800547]], dtype=float32)
time = 171	action = 0	current_phase = 1	next_phase = 0	reward = -15.306030	array([[1.0488025 , 0.68123573]], dtype=float32)
time = 176	action = 0	current_phase = 1	next_phase = 0	reward = -19.670181	array([[1.0249048, 0.6973647]], dtype=float32)
time = 181	action = 1	current_phase = 1	next_phase = 0	reward = -32.353334	array([[1.0078465, 0.708086 ]], dtype=float32)
time = 189	action = 0	current_phase = 0	next_phase = 1	reward = -14.383633	array([[-0.95361626, -0.18208954]], dtype=float32)
time = 194	action = 1	current_phase = 0	next_phase = 1	reward = -24.842407	array([[-0.95776844, -0.19099845]], dtype=float32)
time = 202	action = 0	current_phase = 1	next_phase = 0	reward = -14.227989	array([[1.0513014 , 0.68995345]], dtype=float32)
time = 207	action = 0	current_phase = 1	next_phase = 0	reward = -14.637853	array([[1.0468397 , 0.69319886]], dtype=float32)
time = 212	action = 0	current_phase = 1	next_phase = 0	reward = -16.051953	array([[1.0506063, 0.6936368]], dtype=float32)
time = 217	action = 0	current_phase = 1	next_phase = 0	reward = -20.435279	array([[1.0457542, 0.698902 ]], dtype=float32)
time = 222	action = 1	current_phase = 1	next_phase = 0	reward = -34.337740	array([[1.0302496 , 0.70883495]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = -19.453112	array([[-0.9509785 , -0.18860042]], dtype=float32)
time = 235	action = 1	current_phase = 0	next_phase = 1	reward = -34.667512	array([[-0.9527424 , -0.19650556]], dtype=float32)
time = 243	action = 0	current_phase = 1	next_phase = 0	reward = -20.654861	array([[1.0366808, 0.703086 ]], dtype=float32)
time = 248	action = 0	current_phase = 1	next_phase = 0	reward = -20.745884	array([[1.0387955, 0.7038443]], dtype=float32)
time = 253	action = 0	current_phase = 1	next_phase = 0	reward = -21.115146	array([[1.0395085 , 0.70514965]], dtype=float32)
time = 258	action = 0	current_phase = 1	next_phase = 0	reward = -22.081493	array([[1.0427732 , 0.70924425]], dtype=float32)
time = 263	action = 1	current_phase = 1	next_phase = 0	reward = -34.733567	array([[1.0416049, 0.7127406]], dtype=float32)
time = 271	action = 0	current_phase = 0	next_phase = 1	reward = -20.026849	array([[-0.94927317, -0.2026229 ]], dtype=float32)
time = 276	action = 1	current_phase = 0	next_phase = 1	reward = -41.088845	array([[-0.95137566, -0.20584546]], dtype=float32)
time = 284	action = 0	current_phase = 1	next_phase = 0	reward = -26.405605	array([[1.0147699, 0.7142587]], dtype=float32)
time = 289	action = 0	current_phase = 1	next_phase = 0	reward = -26.989902	array([[1.0218251, 0.7153856]], dtype=float32)
time = 294	action = 0	current_phase = 1	next_phase = 0	reward = -27.654169	array([[1.0212872 , 0.71792114]], dtype=float32)
time = 299	action = 0	current_phase = 1	next_phase = 0	reward = -28.911910	array([[1.0253463 , 0.71976745]], dtype=float32)
time = 304	action = 1	current_phase = 1	next_phase = 0	reward = -38.236320	array([[1.0280508, 0.7197399]], dtype=float32)
time = 312	action = 0	current_phase = 0	next_phase = 1	reward = -17.378069	array([[-0.9480189 , -0.22019005]], dtype=float32)
time = 317	action = 1	current_phase = 0	next_phase = 1	reward = -39.264653	array([[-0.95013595, -0.21915855]], dtype=float32)
time = 325	action = 0	current_phase = 1	next_phase = 0	reward = -26.915664	array([[1.0483215, 0.7164997]], dtype=float32)
time = 330	action = 0	current_phase = 1	next_phase = 0	reward = -29.825368	array([[1.0346928, 0.7178159]], dtype=float32)
time = 335	action = 0	current_phase = 1	next_phase = 0	reward = -32.879081	array([[1.0119164 , 0.71899974]], dtype=float32)
time = 340	action = 0	current_phase = 1	next_phase = 0	reward = -34.414216	array([[1.0063931 , 0.72461283]], dtype=float32)
time = 345	action = 1	current_phase = 1	next_phase = 0	reward = -47.456014	array([[1.0133036, 0.7284169]], dtype=float32)
time = 353	action = 0	current_phase = 0	next_phase = 1	reward = -21.042335	array([[-0.94259703, -0.21821131]], dtype=float32)
time = 358	action = 1	current_phase = 0	next_phase = 1	reward = -39.909812	array([[-0.94487333, -0.22294798]], dtype=float32)
time = 366	action = 0	current_phase = 1	next_phase = 0	reward = -27.269826	array([[1.0711561, 0.7113261]], dtype=float32)
time = 371	action = 0	current_phase = 1	next_phase = 0	reward = -31.967116	array([[1.055237 , 0.7192833]], dtype=float32)
time = 376	action = 0	current_phase = 1	next_phase = 0	reward = -35.033476	array([[1.0305282, 0.7190976]], dtype=float32)
time = 381	action = 0	current_phase = 1	next_phase = 0	reward = -38.763126	array([[1.0149186 , 0.72597015]], dtype=float32)
time = 386	action = 1	current_phase = 1	next_phase = 0	reward = -56.698546	array([[0.9980284, 0.7258762]], dtype=float32)
time = 394	action = 0	current_phase = 0	next_phase = 1	reward = -22.563231	array([[-0.9359597 , -0.21540785]], dtype=float32)
time = 399	action = 1	current_phase = 0	next_phase = 1	reward = -44.561393	array([[-0.94643366, -0.21975845]], dtype=float32)
time = 407	action = 0	current_phase = 1	next_phase = 0	reward = -28.025291	array([[1.0704405, 0.7099508]], dtype=float32)
time = 412	action = 0	current_phase = 1	next_phase = 0	reward = -31.474448	array([[1.0641134, 0.7184332]], dtype=float32)
time = 417	action = 0	current_phase = 1	next_phase = 0	reward = -34.966740	array([[1.0487561, 0.7233211]], dtype=float32)
time = 422	action = 0	current_phase = 1	next_phase = 0	reward = -39.776643	array([[1.0242617 , 0.73270416]], dtype=float32)
time = 427	action = 1	current_phase = 1	next_phase = 0	reward = -61.036222	array([[1.0071068, 0.7364859]], dtype=float32)
time = 435	action = 0	current_phase = 0	next_phase = 1	reward = -27.854693	array([[-0.9344319, -0.193066 ]], dtype=float32)
time = 440	action = 1	current_phase = 0	next_phase = 1	reward = -52.656850	array([[-0.9347505 , -0.20929982]], dtype=float32)
time = 448	action = 0	current_phase = 1	next_phase = 0	reward = -31.924972	array([[1.0663441, 0.7281266]], dtype=float32)
time = 453	action = 0	current_phase = 1	next_phase = 0	reward = -33.408477	array([[1.064599 , 0.7267975]], dtype=float32)
time = 458	action = 0	current_phase = 1	next_phase = 0	reward = -36.017633	array([[1.0495697, 0.7318492]], dtype=float32)
time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -40.288921	array([[1.0370699, 0.7308035]], dtype=float32)
time = 468	action = 1	current_phase = 1	next_phase = 0	reward = -62.407194	array([[1.0130441, 0.7363321]], dtype=float32)
time = 476	action = 0	current_phase = 0	next_phase = 1	reward = -30.917745	array([[-0.93905675, -0.20331855]], dtype=float32)
time = 481	action = 1	current_phase = 0	next_phase = 1	reward = -55.079738	array([[-0.934505  , -0.21481232]], dtype=float32)
time = 489	action = 0	current_phase = 1	next_phase = 0	reward = -32.966821	array([[1.0517397, 0.7433758]], dtype=float32)
time = 494	action = 0	current_phase = 1	next_phase = 0	reward = -32.640849	array([[1.0638711, 0.7338954]], dtype=float32)
time = 499	action = 0	current_phase = 1	next_phase = 0	reward = -33.740243	array([[1.0663434, 0.7344146]], dtype=float32)
time = 504	action = 0	current_phase = 1	next_phase = 0	reward = -37.585945	array([[1.0588394, 0.7345653]], dtype=float32)
time = 509	action = 1	current_phase = 1	next_phase = 0	reward = -60.502394	array([[1.0426621, 0.7395737]], dtype=float32)
time = 517	action = 0	current_phase = 0	next_phase = 1	reward = -26.264013	array([[-0.94128996, -0.20137885]], dtype=float32)
time = 522	action = 1	current_phase = 0	next_phase = 1	reward = -52.060045	array([[-0.9352136 , -0.22095945]], dtype=float32)
time = 530	action = 0	current_phase = 1	next_phase = 0	reward = -33.031484	array([[1.069084  , 0.73825073]], dtype=float32)
time = 535	action = 0	current_phase = 1	next_phase = 0	reward = -35.629226	array([[1.0626479, 0.7361933]], dtype=float32)
time = 540	action = 0	current_phase = 1	next_phase = 0	reward = -39.461006	array([[1.0528405, 0.7401181]], dtype=float32)
time = 545	action = 0	current_phase = 1	next_phase = 0	reward = -43.706788	array([[1.0239358 , 0.74302614]], dtype=float32)
time = 550	action = 1	current_phase = 1	next_phase = 0	reward = -65.361261	array([[1.0065573 , 0.75013065]], dtype=float32)
time = 558	action = 0	current_phase = 0	next_phase = 1	reward = -34.574615	array([[-0.9371246 , -0.18624398]], dtype=float32)
time = 563	action = 1	current_phase = 0	next_phase = 1	reward = -68.253013	array([[-0.94128954, -0.18418096]], dtype=float32)
time = 571	action = 0	current_phase = 1	next_phase = 0	reward = -47.926592	array([[1.0283867, 0.7273176]], dtype=float32)
time = 576	action = 0	current_phase = 1	next_phase = 0	reward = -52.051597	array([[1.0128297, 0.7325014]], dtype=float32)
time = 581	action = 0	current_phase = 1	next_phase = 0	reward = -56.919669	array([[1.0081481, 0.7282956]], dtype=float32)
time = 586	action = 0	current_phase = 1	next_phase = 0	reward = -59.453962	array([[0.98297846, 0.72161174]], dtype=float32)
time = 591	action = 1	current_phase = 1	next_phase = 0	reward = -90.042052	array([[0.9893178 , 0.73570526]], dtype=float32)
time = 599	action = 0	current_phase = 0	next_phase = 1	reward = -47.333874	array([[-0.9433092 , -0.19445576]], dtype=float32)
time = 604	action = 1	current_phase = 0	next_phase = 1	reward = -96.434572	array([[-0.9392604 , -0.18624339]], dtype=float32)
time = 612	action = 0	current_phase = 1	next_phase = 0	reward = -65.120196	array([[1.0037042, 0.7353449]], dtype=float32)
time = 617	action = 0	current_phase = 1	next_phase = 0	reward = -68.013837	array([[0.9754093, 0.739653 ]], dtype=float32)
time = 622	action = 0	current_phase = 1	next_phase = 0	reward = -69.067025	array([[0.9688434 , 0.74308944]], dtype=float32)
time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -67.979484	array([[0.95547473, 0.7461921 ]], dtype=float32)
time = 632	action = 1	current_phase = 1	next_phase = 0	reward = -94.396870	array([[0.9716941 , 0.74730384]], dtype=float32)
time = 640	action = 0	current_phase = 0	next_phase = 1	reward = -34.002631	array([[-0.92602056, -0.17458665]], dtype=float32)
time = 645	action = 1	current_phase = 0	next_phase = 1	reward = -58.783912	array([[-0.9344788, -0.2429364]], dtype=float32)
time = 653	action = 0	current_phase = 1	next_phase = 0	reward = -39.342806	array([[1.0653825, 0.7201457]], dtype=float32)
time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -41.760367	array([[1.0574285, 0.7367982]], dtype=float32)
time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -45.937717	array([[1.0367218, 0.736538 ]], dtype=float32)
Terminal occured. Episode end.
Simulation ended at time: 669.00
Reason: TraCI requested termination.
Performance: 
 Duration: 176100ms
 Real time factor: 3.79898
 UPS: 638.427030
Vehicles: 
 Inserted: 488 (Loaded: 536)
 Running: 280
 Waiting: 48

DijkstraRouter answered 2627 queries and explored 2.00 edges on average.
DijkstraRouter spent 17ms answering queries (0.01ms on average).
Train on 1113 samples, validate on 478 samples
Epoch 1/500
 - 6s - loss: 255.4483 - val_loss: 266.7304
Epoch 2/500
 - 5s - loss: 228.5646 - val_loss: 244.4793
Epoch 3/500
 - 5s - loss: 210.1050 - val_loss: 226.9875
Epoch 4/500
 - 5s - loss: 194.0430 - val_loss: 210.8205
Epoch 5/500
 - 5s - loss: 179.7715 - val_loss: 196.3578
Epoch 6/500
 - 6s - loss: 166.2847 - val_loss: 182.0004
Epoch 7/500
 - 5s - loss: 152.9517 - val_loss: 168.0835
Epoch 8/500
 - 5s - loss: 140.6264 - val_loss: 155.4527
Epoch 9/500
 - 6s - loss: 129.4052 - val_loss: 143.7810
Epoch 10/500
 - 6s - loss: 118.9515 - val_loss: 132.6091
Epoch 11/500
 - 5s - loss: 109.1641 - val_loss: 122.4730
Epoch 12/500
 - 5s - loss: 100.6142 - val_loss: 113.5714
Epoch 13/500
 - 5s - loss: 93.2680 - val_loss: 105.7214
Epoch 14/500
 - 6s - loss: 86.9585 - val_loss: 98.8320
Epoch 15/500
 - 6s - loss: 81.6865 - val_loss: 93.0049
Epoch 16/500
 - 5s - loss: 77.3312 - val_loss: 88.2524
Epoch 17/500
 - 5s - loss: 73.8815 - val_loss: 84.5334
Epoch 18/500
 - 6s - loss: 71.0706 - val_loss: 81.3841
Epoch 19/500
 - 5s - loss: 68.3403 - val_loss: 78.1815
Epoch 20/500
 - 6s - loss: 65.3712 - val_loss: 75.0006
Epoch 21/500
 - 6s - loss: 62.4064 - val_loss: 72.1638
Epoch 22/500
 - 6s - loss: 59.8046 - val_loss: 69.5437
Epoch 23/500
 - 5s - loss: 57.2677 - val_loss: 66.7661
Epoch 24/500
 - 5s - loss: 54.6612 - val_loss: 64.4343
Epoch 25/500
 - 5s - loss: 52.6627 - val_loss: 62.3855
Epoch 26/500
 - 6s - loss: 50.9574 - val_loss: 60.7424
Epoch 27/500
 - 5s - loss: 49.4565 - val_loss: 59.2642
Epoch 28/500
 - 5s - loss: 48.1799 - val_loss: 57.9058
Epoch 29/500
 - 5s - loss: 47.0354 - val_loss: 56.4544
Epoch 30/500
 - 6s - loss: 45.9860 - val_loss: 55.4647
Epoch 31/500
 - 5s - loss: 45.1177 - val_loss: 54.6428
Epoch 32/500
 - 5s - loss: 44.3117 - val_loss: 53.9628
Epoch 33/500
 - 5s - loss: 43.5545 - val_loss: 53.1618
Epoch 34/500
 - 5s - loss: 42.9699 - val_loss: 52.4952
Epoch 35/500
 - 5s - loss: 42.3772 - val_loss: 51.8416
Epoch 36/500
 - 5s - loss: 41.8355 - val_loss: 51.5928
Epoch 37/500
 - 5s - loss: 41.3541 - val_loss: 50.9623
Epoch 38/500
 - 5s - loss: 40.8930 - val_loss: 50.5877
Epoch 39/500
 - 5s - loss: 40.4822 - val_loss: 50.1002
Epoch 40/500
 - 5s - loss: 39.8697 - val_loss: 49.6863
Epoch 41/500
 - 5s - loss: 39.2132 - val_loss: 49.2645
Epoch 42/500
 - 5s - loss: 38.8253 - val_loss: 48.4916
Epoch 43/500
 - 5s - loss: 38.2652 - val_loss: 48.5204
Epoch 44/500
 - 5s - loss: 37.7793 - val_loss: 47.6776
Epoch 45/500
 - 5s - loss: 37.4884 - val_loss: 47.1590
Epoch 46/500
 - 5s - loss: 36.8815 - val_loss: 46.9656
Epoch 47/500
 - 5s - loss: 36.3912 - val_loss: 46.4404
Epoch 48/500
 - 5s - loss: 35.8491 - val_loss: 45.7216
Epoch 49/500
 - 5s - loss: 35.4407 - val_loss: 45.6056
Epoch 50/500
 - 5s - loss: 34.7292 - val_loss: 44.9558
Epoch 51/500
 - 5s - loss: 34.4073 - val_loss: 44.5526
Epoch 52/500
 - 5s - loss: 33.9180 - val_loss: 43.9315
Epoch 53/500
 - 5s - loss: 33.4536 - val_loss: 43.4713
Epoch 54/500
 - 5s - loss: 33.0887 - val_loss: 43.6203
Epoch 55/500
 - 5s - loss: 32.7136 - val_loss: 43.5622
Epoch 56/500
 - 5s - loss: 32.2420 - val_loss: 42.6144
Epoch 57/500
 - 5s - loss: 31.6700 - val_loss: 42.9978
Epoch 58/500
 - 5s - loss: 31.3760 - val_loss: 41.9338
Epoch 59/500
 - 5s - loss: 30.9496 - val_loss: 40.9258
Epoch 60/500
 - 5s - loss: 30.1667 - val_loss: 41.0566
Epoch 61/500
 - 5s - loss: 30.1456 - val_loss: 40.0498
Epoch 62/500
 - 5s - loss: 29.6731 - val_loss: 39.8111
Epoch 63/500
 - 5s - loss: 29.2915 - val_loss: 38.9096
Epoch 64/500
 - 5s - loss: 28.6554 - val_loss: 38.4136
Epoch 65/500
 - 5s - loss: 28.4874 - val_loss: 37.5530
Epoch 66/500
 - 5s - loss: 28.0045 - val_loss: 37.1868
Epoch 67/500
 - 5s - loss: 27.2985 - val_loss: 36.7976
Epoch 68/500
 - 5s - loss: 26.8433 - val_loss: 37.4922
Epoch 69/500
 - 5s - loss: 26.5923 - val_loss: 36.7079
Epoch 70/500
 - 5s - loss: 25.9130 - val_loss: 36.3061
Epoch 71/500
 - 5s - loss: 25.5652 - val_loss: 36.2609
Epoch 72/500
 - 5s - loss: 25.6899 - val_loss: 34.6534
Epoch 73/500
 - 5s - loss: 25.0162 - val_loss: 35.2612
Epoch 74/500
 - 5s - loss: 24.5316 - val_loss: 34.1461
Epoch 75/500
 - 5s - loss: 24.1258 - val_loss: 33.4774
Epoch 76/500
 - 5s - loss: 23.9681 - val_loss: 33.2662
Epoch 77/500
 - 5s - loss: 23.7643 - val_loss: 33.4298
Epoch 78/500
 - 6s - loss: 23.8794 - val_loss: 33.9962
Epoch 79/500
 - 6s - loss: 22.7575 - val_loss: 33.6230
Epoch 80/500
 - 5s - loss: 22.6798 - val_loss: 32.8664
Epoch 81/500
 - 5s - loss: 22.7726 - val_loss: 32.2971
Epoch 82/500
 - 5s - loss: 22.3882 - val_loss: 32.0253
Epoch 83/500
 - 5s - loss: 22.0896 - val_loss: 33.1257
Epoch 84/500
 - 5s - loss: 22.1241 - val_loss: 31.9455
Epoch 85/500
 - 5s - loss: 21.7776 - val_loss: 31.8444
Epoch 86/500
 - 5s - loss: 20.9638 - val_loss: 31.2742
Epoch 87/500
 - 5s - loss: 21.0915 - val_loss: 30.7749
Epoch 88/500
 - 5s - loss: 21.2982 - val_loss: 30.9797
Epoch 89/500
 - 5s - loss: 21.0558 - val_loss: 29.9407
Epoch 90/500
 - 5s - loss: 20.7944 - val_loss: 31.3007
Epoch 91/500
 - 5s - loss: 20.4394 - val_loss: 29.9475
Epoch 92/500
 - 6s - loss: 20.1665 - val_loss: 30.2441
Epoch 93/500
 - 6s - loss: 20.0665 - val_loss: 30.0736
Epoch 94/500
 - 5s - loss: 19.5002 - val_loss: 28.7564
Epoch 95/500
 - 6s - loss: 19.6358 - val_loss: 29.3720
Epoch 96/500
 - 5s - loss: 19.5079 - val_loss: 28.2767
Epoch 97/500
 - 5s - loss: 19.1374 - val_loss: 28.4258
Epoch 98/500
 - 5s - loss: 18.8501 - val_loss: 29.2589
Epoch 99/500
 - 5s - loss: 18.9684 - val_loss: 29.4201
Epoch 100/500
 - 5s - loss: 18.4995 - val_loss: 28.7432
Epoch 101/500
 - 5s - loss: 18.1683 - val_loss: 27.5900
Epoch 102/500
 - 6s - loss: 18.1258 - val_loss: 26.9812
Epoch 103/500
 - 6s - loss: 17.5740 - val_loss: 26.8448
Epoch 104/500
 - 5s - loss: 17.5930 - val_loss: 26.7220
Epoch 105/500
 - 6s - loss: 17.2110 - val_loss: 26.6018
Epoch 106/500
 - 6s - loss: 17.5088 - val_loss: 26.2523
Epoch 107/500
 - 5s - loss: 16.9499 - val_loss: 25.3506
Epoch 108/500
 - 5s - loss: 16.2954 - val_loss: 25.6631
Epoch 109/500
 - 5s - loss: 15.8986 - val_loss: 25.1983
Epoch 110/500
 - 5s - loss: 16.0893 - val_loss: 25.8440
Epoch 111/500
 - 6s - loss: 15.7422 - val_loss: 24.1717
Epoch 112/500
 - 6s - loss: 15.5524 - val_loss: 24.9973
Epoch 113/500
 - 5s - loss: 15.2848 - val_loss: 23.9344
Epoch 114/500
 - 5s - loss: 15.5760 - val_loss: 23.6610
Epoch 115/500
 - 5s - loss: 14.5922 - val_loss: 24.2704
Epoch 116/500
 - 5s - loss: 14.5360 - val_loss: 23.9991
Epoch 117/500
 - 5s - loss: 14.1577 - val_loss: 24.1253
Epoch 118/500
 - 6s - loss: 14.2774 - val_loss: 23.4154
Epoch 119/500
 - 5s - loss: 13.2898 - val_loss: 23.4422
Epoch 120/500
 - 5s - loss: 13.2593 - val_loss: 23.2596
Epoch 121/500
 - 5s - loss: 13.3250 - val_loss: 23.0379
Epoch 122/500
 - 5s - loss: 12.9798 - val_loss: 22.6653
Epoch 123/500
 - 5s - loss: 12.6824 - val_loss: 24.1394
Epoch 124/500
 - 6s - loss: 13.2356 - val_loss: 22.4130
Epoch 125/500
 - 5s - loss: 12.7870 - val_loss: 23.1312
Epoch 126/500
 - 5s - loss: 11.9044 - val_loss: 22.7917
Epoch 127/500
 - 5s - loss: 12.4803 - val_loss: 22.7974
Epoch 128/500
 - 5s - loss: 12.1844 - val_loss: 23.1409
Epoch 129/500
 - 5s - loss: 12.1679 - val_loss: 22.2370
Epoch 130/500
 - 5s - loss: 11.8948 - val_loss: 22.8719
Epoch 131/500
 - 5s - loss: 11.4052 - val_loss: 23.3783
Epoch 132/500
 - 5s - loss: 11.6226 - val_loss: 23.4702
Epoch 133/500
 - 5s - loss: 11.4317 - val_loss: 22.0418
Epoch 134/500
 - 5s - loss: 11.5947 - val_loss: 22.9060
Epoch 135/500
 - 5s - loss: 10.7832 - val_loss: 23.2911
Epoch 136/500
 - 5s - loss: 10.7835 - val_loss: 21.9111
Epoch 137/500
 - 5s - loss: 10.5830 - val_loss: 22.7687
Epoch 138/500
 - 5s - loss: 10.4459 - val_loss: 22.2444
Epoch 139/500
 - 5s - loss: 10.3381 - val_loss: 21.7899
Epoch 140/500
 - 5s - loss: 10.7535 - val_loss: 22.3379
Epoch 141/500
 - 6s - loss: 9.9307 - val_loss: 22.4021
Epoch 142/500
 - 6s - loss: 10.4690 - val_loss: 22.0792
Epoch 143/500
 - 6s - loss: 10.7661 - val_loss: 21.1013
Epoch 144/500
 - 6s - loss: 9.7060 - val_loss: 22.3932
Epoch 145/500
 - 7s - loss: 9.7529 - val_loss: 22.5058
Epoch 146/500
 - 6s - loss: 10.3156 - val_loss: 22.6837
Epoch 147/500
 - 7s - loss: 9.7353 - val_loss: 21.5209
Epoch 148/500
 - 7s - loss: 9.0884 - val_loss: 22.0299
Epoch 149/500
 - 7s - loss: 9.5910 - val_loss: 22.7906
Epoch 150/500
 - 7s - loss: 8.9156 - val_loss: 22.0729
Epoch 151/500
 - 6s - loss: 8.6980 - val_loss: 21.6658
Epoch 152/500
 - 6s - loss: 9.1606 - val_loss: 21.7209
Epoch 153/500
 - 6s - loss: 8.6643 - val_loss: 23.1223
length of memory (state 0, action 0): 507, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
END
Could not connect to TraCI server at localhost:46029 [Errno 111] Connection refused
 Retrying in 1 seconds
Loading configuration... done.
***Starting server on port 46029 ***
Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (2ms).
Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).
Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).
Loading done.
Simulation started with time: 0.00
time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.032048	array([[  1.0320262, -15.133003 ]], dtype=float32)
time = 25	action = 0	current_phase = 0	next_phase = 1	reward = 0.514166	array([[  0.97409976, -14.974548  ]], dtype=float32)
time = 30	action = 0	current_phase = 0	next_phase = 1	reward = 0.332082	array([[-1.9978755, -6.5751724]], dtype=float32)
time = 35	action = 0	current_phase = 0	next_phase = 1	reward = 0.896630	array([[-2.2165399, -6.635582 ]], dtype=float32)
time = 40	action = 0	current_phase = 0	next_phase = 1	reward = 0.701879	array([[  1.1589578, -15.132341 ]], dtype=float32)
time = 45	action = 0	current_phase = 0	next_phase = 1	reward = 0.717130	array([[-1.5699867, -4.35272  ]], dtype=float32)
time = 50	action = 0	current_phase = 0	next_phase = 1	reward = 0.162829	array([[  0.60366666, -12.794794  ]], dtype=float32)
time = 55	action = 0	current_phase = 0	next_phase = 1	reward = 1.010138	array([[ 0.12923491, -9.960851  ]], dtype=float32)
time = 60	action = 0	current_phase = 0	next_phase = 1	reward = 1.002929	array([[-1.5731963, -4.1140327]], dtype=float32)
time = 65	action = 0	current_phase = 0	next_phase = 1	reward = 0.722055	array([[  0.7413677, -13.092514 ]], dtype=float32)
time = 70	action = 0	current_phase = 0	next_phase = 1	reward = 0.451459	array([[-0.3369063, -9.752217 ]], dtype=float32)
time = 75	action = 0	current_phase = 0	next_phase = 1	reward = 1.005869	array([[-1.2556436, -4.451183 ]], dtype=float32)
time = 80	action = 0	current_phase = 0	next_phase = 1	reward = 0.721652	array([[  1.9216686, -15.322148 ]], dtype=float32)
time = 85	action = 0	current_phase = 0	next_phase = 1	reward = 0.439066	array([[-1.1429431, -4.820856 ]], dtype=float32)
time = 90	action = 0	current_phase = 0	next_phase = 1	reward = 0.724351	array([[-0.20465791, -9.065152  ]], dtype=float32)
time = 95	action = 0	current_phase = 0	next_phase = 1	reward = 0.732076	array([[-0.61377764, -9.805025  ]], dtype=float32)
time = 100	action = 0	current_phase = 0	next_phase = 1	reward = 1.006941	array([[ -0.02155137, -11.754349  ]], dtype=float32)
time = 105	action = 0	current_phase = 0	next_phase = 1	reward = 0.721295	array([[  0.6321231, -12.802087 ]], dtype=float32)
time = 110	action = 0	current_phase = 0	next_phase = 1	reward = 0.716554	array([[-0.9591506, -6.1306047]], dtype=float32)
time = 115	action = 0	current_phase = 0	next_phase = 1	reward = 0.715531	array([[-1.2105459, -6.0141926]], dtype=float32)
time = 120	action = 0	current_phase = 0	next_phase = 1	reward = 0.442034	array([[  0.5907458, -11.651414 ]], dtype=float32)
time = 125	action = 0	current_phase = 0	next_phase = 1	reward = 0.731054	array([[-1.0483257, -5.0434113]], dtype=float32)
time = 130	action = 0	current_phase = 0	next_phase = 1	reward = 1.004985	array([[-0.2715727, -8.7459755]], dtype=float32)
time = 135	action = 0	current_phase = 0	next_phase = 1	reward = 0.720360	array([[  0.7681247, -13.101657 ]], dtype=float32)
time = 140	action = 0	current_phase = 0	next_phase = 1	reward = 0.447026	array([[  0.6652001, -13.254015 ]], dtype=float32)
time = 145	action = 0	current_phase = 0	next_phase = 1	reward = 1.002778	array([[ -0.44477665, -10.1700535 ]], dtype=float32)
time = 150	action = 0	current_phase = 0	next_phase = 1	reward = 0.448687	array([[-1.2587259, -6.7296424]], dtype=float32)
time = 155	action = 0	current_phase = 0	next_phase = 1	reward = 1.011331	array([[  0.5004488, -12.325292 ]], dtype=float32)
time = 160	action = 0	current_phase = 0	next_phase = 1	reward = 0.720394	array([[-0.9224705, -6.81832  ]], dtype=float32)
time = 165	action = 0	current_phase = 0	next_phase = 1	reward = 0.722349	array([[ -0.03146029, -12.430441  ]], dtype=float32)
time = 170	action = 0	current_phase = 0	next_phase = 1	reward = 0.722065	array([[-0.87796384, -5.6749067 ]], dtype=float32)
time = 175	action = 0	current_phase = 0	next_phase = 1	reward = 0.722338	array([[  0.6187848, -12.87028  ]], dtype=float32)
time = 180	action = 0	current_phase = 0	next_phase = 1	reward = 0.728840	array([[  0.43671238, -11.174572  ]], dtype=float32)
time = 185	action = 0	current_phase = 0	next_phase = 1	reward = 0.720612	array([[  0.36714876, -11.313077  ]], dtype=float32)
time = 190	action = 0	current_phase = 0	next_phase = 1	reward = 0.718813	array([[ -0.36873543, -10.052771  ]], dtype=float32)
time = 195	action = 0	current_phase = 0	next_phase = 1	reward = 0.723150	array([[-1.0570774, -7.3862677]], dtype=float32)
time = 200	action = 0	current_phase = 0	next_phase = 1	reward = 0.718705	array([[-0.5550126, -7.825867 ]], dtype=float32)
time = 205	action = 0	current_phase = 0	next_phase = 1	reward = 0.441243	array([[  0.18672013, -11.164062  ]], dtype=float32)
time = 210	action = 0	current_phase = 0	next_phase = 1	reward = 1.002215	array([[  1.2540683, -14.491728 ]], dtype=float32)
time = 215	action = 0	current_phase = 0	next_phase = 1	reward = 0.450685	array([[-0.16545713, -8.585218  ]], dtype=float32)
time = 220	action = 0	current_phase = 0	next_phase = 1	reward = 1.004804	array([[-1.1745601, -8.127265 ]], dtype=float32)
time = 225	action = 0	current_phase = 0	next_phase = 1	reward = 0.722131	array([[-1.0616794, -6.58945  ]], dtype=float32)
time = 230	action = 0	current_phase = 0	next_phase = 1	reward = 0.717689	array([[-0.8907612, -7.7351413]], dtype=float32)
time = 235	action = 0	current_phase = 0	next_phase = 1	reward = 0.713378	array([[  1.4489969, -11.831722 ]], dtype=float32)
time = 240	action = 0	current_phase = 0	next_phase = 1	reward = 0.436131	array([[-0.74499583, -6.34279   ]], dtype=float32)
time = 245	action = 0	current_phase = 0	next_phase = 1	reward = 0.442828	array([[  0.1368748, -10.045662 ]], dtype=float32)
time = 250	action = 0	current_phase = 0	next_phase = 1	reward = 1.014572	array([[ -0.0331775, -11.100772 ]], dtype=float32)
time = 255	action = 0	current_phase = 0	next_phase = 1	reward = 1.001805	array([[  0.52238953, -11.012267  ]], dtype=float32)
time = 260	action = 0	current_phase = 0	next_phase = 1	reward = 0.718439	array([[-0.6920618, -8.117308 ]], dtype=float32)
time = 265	action = 0	current_phase = 0	next_phase = 1	reward = 0.729084	array([[ -0.1631316, -10.2992   ]], dtype=float32)
time = 270	action = 0	current_phase = 0	next_phase = 1	reward = 0.727656	array([[ -0.03226376, -11.948643  ]], dtype=float32)
time = 275	action = 0	current_phase = 0	next_phase = 1	reward = 0.446848	array([[-0.59926665, -9.511362  ]], dtype=float32)
time = 280	action = 0	current_phase = 0	next_phase = 1	reward = 1.004545	array([[-1.0316137, -5.1948233]], dtype=float32)
time = 285	action = 0	current_phase = 0	next_phase = 1	reward = 0.726909	array([[  0.73775494, -13.783854  ]], dtype=float32)
time = 290	action = 0	current_phase = 0	next_phase = 1	reward = 0.716498	array([[  0.2505449, -10.224631 ]], dtype=float32)
time = 295	action = 0	current_phase = 0	next_phase = 1	reward = 0.720700	array([[-0.06475914, -9.2958555 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 41.5776 - val_loss: 32.7770
Epoch 2/50
 - 5s - loss: 35.3865 - val_loss: 31.1101
Epoch 3/50
 - 4s - loss: 32.5741 - val_loss: 30.1843
Epoch 4/50
 - 4s - loss: 32.5063 - val_loss: 31.7044
Epoch 5/50
 - 4s - loss: 30.6331 - val_loss: 31.0876
Epoch 6/50
 - 4s - loss: 29.7824 - val_loss: 29.6442
Epoch 7/50
 - 4s - loss: 28.8010 - val_loss: 29.0183
Epoch 8/50
 - 4s - loss: 28.2828 - val_loss: 27.1681
Epoch 9/50
 - 4s - loss: 26.9487 - val_loss: 27.8048
Epoch 10/50
 - 4s - loss: 26.0440 - val_loss: 28.1581
Epoch 11/50
 - 4s - loss: 26.4855 - val_loss: 27.6520
Epoch 12/50
 - 4s - loss: 25.9377 - val_loss: 26.2295
Epoch 13/50
 - 4s - loss: 24.6818 - val_loss: 25.5857
Epoch 14/50
 - 5s - loss: 24.6112 - val_loss: 25.5153
Epoch 15/50
 - 5s - loss: 24.1442 - val_loss: 24.8242
Epoch 16/50
 - 5s - loss: 23.0897 - val_loss: 24.7290
Epoch 17/50
 - 4s - loss: 22.8198 - val_loss: 24.8146
Epoch 18/50
 - 4s - loss: 21.9517 - val_loss: 24.2521
Epoch 19/50
 - 4s - loss: 22.6426 - val_loss: 24.6347
Epoch 20/50
 - 4s - loss: 22.5566 - val_loss: 24.8172
Epoch 21/50
 - 4s - loss: 21.7138 - val_loss: 24.3621
Epoch 22/50
 - 4s - loss: 20.3904 - val_loss: 23.1177
Epoch 23/50
 - 4s - loss: 20.4576 - val_loss: 24.6844
Epoch 24/50
 - 4s - loss: 20.5030 - val_loss: 24.5645
Epoch 25/50
 - 4s - loss: 21.1173 - val_loss: 22.6423
Epoch 26/50
 - 4s - loss: 20.2570 - val_loss: 24.0795
Epoch 27/50
 - 4s - loss: 19.8560 - val_loss: 23.5726
Epoch 28/50
 - 4s - loss: 19.0084 - val_loss: 22.6957
Epoch 29/50
 - 4s - loss: 18.4905 - val_loss: 22.4266
Epoch 30/50
 - 4s - loss: 18.2965 - val_loss: 22.7067
Epoch 31/50
 - 4s - loss: 17.9438 - val_loss: 22.7399
Epoch 32/50
 - 5s - loss: 18.4338 - val_loss: 22.4218
Epoch 33/50
 - 6s - loss: 17.4570 - val_loss: 23.9497
Epoch 34/50
 - 6s - loss: 17.9126 - val_loss: 23.6292
Epoch 35/50
 - 4s - loss: 17.3015 - val_loss: 22.3942
Epoch 36/50
 - 4s - loss: 16.8342 - val_loss: 22.2579
Epoch 37/50
 - 4s - loss: 17.1099 - val_loss: 22.2490
Epoch 38/50
 - 4s - loss: 17.2732 - val_loss: 20.7430
Epoch 39/50
 - 4s - loss: 16.6718 - val_loss: 20.4894
Epoch 40/50
 - 4s - loss: 16.1595 - val_loss: 21.5912
Epoch 41/50
 - 4s - loss: 17.4286 - val_loss: 19.7448
Epoch 42/50
 - 4s - loss: 15.9996 - val_loss: 21.5501
Epoch 43/50
 - 4s - loss: 16.1023 - val_loss: 21.1527
Epoch 44/50
 - 4s - loss: 15.3808 - val_loss: 23.9948
Epoch 45/50
 - 4s - loss: 15.8608 - val_loss: 21.4053
Epoch 46/50
 - 4s - loss: 15.6459 - val_loss: 21.1920
Epoch 47/50
 - 4s - loss: 15.9975 - val_loss: 21.5200
Epoch 48/50
 - 4s - loss: 14.9777 - val_loss: 23.8244
Epoch 49/50
 - 4s - loss: 14.6172 - val_loss: 23.4809
Epoch 50/50
 - 4s - loss: 14.8797 - val_loss: 22.1557
length of memory (state 0, action 0): 563, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 300	action = 0	current_phase = 0	next_phase = 1	reward = 0.720358	array([[ 0.32287967, -8.917193  ]], dtype=float32)
time = 305	action = 0	current_phase = 0	next_phase = 1	reward = 0.714645	array([[  0.21533 , -10.562274]], dtype=float32)
time = 310	action = 0	current_phase = 0	next_phase = 1	reward = 0.168349	array([[ 0.4407283, -7.1661916]], dtype=float32)
time = 315	action = 0	current_phase = 0	next_phase = 1	reward = 1.289009	array([[  0.384956, -11.323839]], dtype=float32)
time = 320	action = 0	current_phase = 0	next_phase = 1	reward = 0.727921	array([[  0.10895813, -11.341299  ]], dtype=float32)
time = 325	action = 0	current_phase = 0	next_phase = 1	reward = 0.723553	array([[ 0.18778265, -7.7476482 ]], dtype=float32)
time = 330	action = 0	current_phase = 0	next_phase = 1	reward = 0.723489	array([[-0.63088655, -5.196347  ]], dtype=float32)
time = 335	action = 0	current_phase = 0	next_phase = 1	reward = 0.728902	array([[ 0.13351977, -7.1423554 ]], dtype=float32)
time = 340	action = 0	current_phase = 0	next_phase = 1	reward = 0.722516	array([[ 0.9057125, -5.93425  ]], dtype=float32)
time = 345	action = 0	current_phase = 0	next_phase = 1	reward = 0.729297	array([[-0.1121465, -8.767758 ]], dtype=float32)
time = 350	action = 0	current_phase = 0	next_phase = 1	reward = 0.446787	array([[  0.21841156, -10.97421   ]], dtype=float32)
time = 355	action = 0	current_phase = 0	next_phase = 1	reward = 1.005095	array([[-0.22858548, -7.5205164 ]], dtype=float32)
time = 360	action = 0	current_phase = 0	next_phase = 1	reward = 0.443518	array([[ 0.15515077, -7.455465  ]], dtype=float32)
time = 365	action = 0	current_phase = 0	next_phase = 1	reward = 0.996900	array([[ 0.20375836, -9.655071  ]], dtype=float32)
time = 370	action = 0	current_phase = 0	next_phase = 1	reward = 0.723982	array([[ 0.07647026, -7.14735   ]], dtype=float32)
time = 375	action = 0	current_phase = 0	next_phase = 1	reward = 0.717994	array([[ -0.09147167, -10.808847  ]], dtype=float32)
time = 380	action = 0	current_phase = 0	next_phase = 1	reward = 0.727872	array([[-0.3113016, -5.7677135]], dtype=float32)
time = 385	action = 0	current_phase = 0	next_phase = 1	reward = 0.456118	array([[ -0.02367222, -10.447902  ]], dtype=float32)
time = 390	action = 0	current_phase = 0	next_phase = 1	reward = 1.009567	array([[  0.5383333, -10.504366 ]], dtype=float32)
time = 395	action = 0	current_phase = 0	next_phase = 1	reward = 0.726583	array([[ 0.44452655, -9.794706  ]], dtype=float32)
time = 400	action = 0	current_phase = 0	next_phase = 1	reward = 0.729344	array([[ 0.1571337, -5.956233 ]], dtype=float32)
time = 405	action = 0	current_phase = 0	next_phase = 1	reward = 0.718528	array([[-0.0803467, -7.8610888]], dtype=float32)
time = 410	action = 0	current_phase = 0	next_phase = 1	reward = 0.718364	array([[-0.15148449, -9.044374  ]], dtype=float32)
time = 415	action = 0	current_phase = 0	next_phase = 1	reward = 0.442089	array([[ -0.3366102, -10.671963 ]], dtype=float32)
time = 420	action = 0	current_phase = 0	next_phase = 1	reward = 1.004040	array([[ 0.15233314, -9.521617  ]], dtype=float32)
time = 425	action = 0	current_phase = 0	next_phase = 1	reward = 0.720221	array([[  1.1858138, -14.149396 ]], dtype=float32)
time = 430	action = 0	current_phase = 0	next_phase = 1	reward = 0.439865	array([[  0.5528532, -10.763788 ]], dtype=float32)
time = 435	action = 0	current_phase = 0	next_phase = 1	reward = 1.003585	array([[-1.1638522, -5.25122  ]], dtype=float32)
time = 440	action = 0	current_phase = 0	next_phase = 1	reward = 0.720388	array([[ 0.3816043, -9.172794 ]], dtype=float32)
time = 445	action = 0	current_phase = 0	next_phase = 1	reward = 0.445006	array([[-0.21608698, -5.179961  ]], dtype=float32)
time = 450	action = 0	current_phase = 0	next_phase = 1	reward = 1.012759	array([[-0.6525605, -6.9445577]], dtype=float32)
time = 455	action = 0	current_phase = 0	next_phase = 1	reward = 0.725849	array([[-0.26001883, -7.64259   ]], dtype=float32)
time = 460	action = 0	current_phase = 0	next_phase = 1	reward = 0.718635	array([[  0.7245015, -10.479815 ]], dtype=float32)
time = 465	action = 0	current_phase = 0	next_phase = 1	reward = 0.167530	array([[-0.42013407, -8.619326  ]], dtype=float32)
time = 470	action = 0	current_phase = 0	next_phase = 1	reward = 1.285349	array([[-1.2572095, -7.3998027]], dtype=float32)
time = 475	action = 0	current_phase = 0	next_phase = 1	reward = 0.444755	array([[-0.23863721, -7.2077403 ]], dtype=float32)
time = 480	action = 0	current_phase = 0	next_phase = 1	reward = 1.010345	array([[-0.21576273, -5.77766   ]], dtype=float32)
time = 485	action = 0	current_phase = 0	next_phase = 1	reward = 0.721570	array([[ 0.02643502, -7.5622115 ]], dtype=float32)
time = 490	action = 0	current_phase = 0	next_phase = 1	reward = 0.724333	array([[  0.71492445, -11.257701  ]], dtype=float32)
time = 495	action = 0	current_phase = 0	next_phase = 1	reward = 0.723618	array([[ 0.1225394, -5.713049 ]], dtype=float32)
time = 500	action = 0	current_phase = 0	next_phase = 1	reward = 0.723979	array([[ 0.849429, -8.105466]], dtype=float32)
time = 505	action = 0	current_phase = 0	next_phase = 1	reward = 0.723410	array([[-0.35992527, -6.6074047 ]], dtype=float32)
time = 510	action = 0	current_phase = 0	next_phase = 1	reward = 0.444756	array([[-0.11764574, -8.645891  ]], dtype=float32)
time = 515	action = 0	current_phase = 0	next_phase = 1	reward = 0.728673	array([[  0.33944142, -10.779155  ]], dtype=float32)
time = 520	action = 0	current_phase = 0	next_phase = 1	reward = 1.002993	array([[ 0.0148083, -8.100459 ]], dtype=float32)
time = 525	action = 0	current_phase = 0	next_phase = 1	reward = 0.718508	array([[ -0.24996102, -10.024977  ]], dtype=float32)
time = 530	action = 0	current_phase = 0	next_phase = 1	reward = 0.440033	array([[-0.63965464, -8.89262   ]], dtype=float32)
time = 535	action = 0	current_phase = 0	next_phase = 1	reward = 0.729397	array([[-0.15604281, -9.988672  ]], dtype=float32)
time = 540	action = 0	current_phase = 0	next_phase = 1	reward = 1.014737	array([[-0.3314668, -9.489037 ]], dtype=float32)
time = 545	action = 0	current_phase = 0	next_phase = 1	reward = 0.721114	array([[ 0.42552626, -9.574963  ]], dtype=float32)
time = 550	action = 0	current_phase = 0	next_phase = 1	reward = 0.728213	array([[-0.9254385, -5.5292253]], dtype=float32)
time = 555	action = 0	current_phase = 0	next_phase = 1	reward = 0.718347	array([[ 0.27857816, -9.686304  ]], dtype=float32)
time = 560	action = 0	current_phase = 0	next_phase = 1	reward = 0.714853	array([[-0.53167844, -6.841855  ]], dtype=float32)
time = 565	action = 0	current_phase = 0	next_phase = 1	reward = 0.441604	array([[  0.4166361, -10.48689  ]], dtype=float32)
time = 570	action = 0	current_phase = 0	next_phase = 1	reward = 1.008984	array([[-0.7551856, -6.46568  ]], dtype=float32)
time = 575	action = 0	current_phase = 0	next_phase = 1	reward = 0.727207	array([[ 0.42174208, -9.854451  ]], dtype=float32)
time = 580	action = 0	current_phase = 0	next_phase = 1	reward = 0.725953	array([[ -0.04367292, -12.445349  ]], dtype=float32)
time = 585	action = 0	current_phase = 0	next_phase = 1	reward = 0.722098	array([[-0.11776829, -5.9597635 ]], dtype=float32)
time = 590	action = 0	current_phase = 0	next_phase = 1	reward = 0.722938	array([[ 0.36947477, -9.038486  ]], dtype=float32)
time = 595	action = 0	current_phase = 0	next_phase = 1	reward = 0.723753	array([[-0.23241961, -8.2025795 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 20.2856 - val_loss: 9.9427
Epoch 2/50
 - 4s - loss: 20.8137 - val_loss: 10.3243
Epoch 3/50
 - 4s - loss: 18.7147 - val_loss: 8.9959
Epoch 4/50
 - 4s - loss: 17.9417 - val_loss: 10.2178
Epoch 5/50
 - 4s - loss: 18.0896 - val_loss: 8.2071
Epoch 6/50
 - 4s - loss: 17.9061 - val_loss: 8.9833
Epoch 7/50
 - 4s - loss: 17.2250 - val_loss: 8.6493
Epoch 8/50
 - 4s - loss: 17.3140 - val_loss: 9.0277
Epoch 9/50
 - 4s - loss: 16.8725 - val_loss: 9.3046
Epoch 10/50
 - 4s - loss: 16.4989 - val_loss: 9.5646
Epoch 11/50
 - 4s - loss: 16.2646 - val_loss: 9.4149
Epoch 12/50
 - 4s - loss: 18.2466 - val_loss: 8.2166
Epoch 13/50
 - 4s - loss: 16.1414 - val_loss: 7.9696
Epoch 14/50
 - 4s - loss: 15.8413 - val_loss: 7.8082
Epoch 15/50
 - 4s - loss: 15.9410 - val_loss: 8.7250
Epoch 16/50
 - 4s - loss: 15.1592 - val_loss: 8.6698
Epoch 17/50
 - 4s - loss: 16.5319 - val_loss: 8.6740
Epoch 18/50
 - 4s - loss: 15.4412 - val_loss: 8.6197
Epoch 19/50
 - 4s - loss: 15.0214 - val_loss: 9.4403
Epoch 20/50
 - 4s - loss: 15.2241 - val_loss: 8.0090
Epoch 21/50
 - 5s - loss: 14.2140 - val_loss: 7.8758
Epoch 22/50
 - 5s - loss: 14.5660 - val_loss: 7.9483
Epoch 23/50
 - 4s - loss: 14.1197 - val_loss: 8.3678
Epoch 24/50
 - 4s - loss: 14.9115 - val_loss: 8.6746
length of memory (state 0, action 0): 623, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 600	action = 0	current_phase = 0	next_phase = 1	reward = 0.724523	array([[ 0.79766345, -9.575123  ]], dtype=float32)
time = 605	action = 0	current_phase = 0	next_phase = 1	reward = 0.713776	array([[ 0.5845022, -6.9020424]], dtype=float32)
time = 610	action = 0	current_phase = 0	next_phase = 1	reward = 0.445189	array([[ 0.35115552, -7.328132  ]], dtype=float32)
time = 615	action = 0	current_phase = 0	next_phase = 1	reward = 1.003066	array([[ 0.02487421, -6.06022   ]], dtype=float32)
time = 620	action = 0	current_phase = 0	next_phase = 1	reward = 0.441516	array([[ 0.868541, -6.759843]], dtype=float32)
time = 625	action = 0	current_phase = 0	next_phase = 1	reward = 0.727557	array([[ 0.83440924, -9.814613  ]], dtype=float32)
time = 630	action = 0	current_phase = 0	next_phase = 1	reward = 1.000858	array([[ 0.12319088, -8.0733185 ]], dtype=float32)
time = 635	action = 0	current_phase = 0	next_phase = 1	reward = 0.716910	array([[ 1.0072112, -9.904635 ]], dtype=float32)
time = 640	action = 0	current_phase = 0	next_phase = 1	reward = 0.445547	array([[ 0.6086829, -6.13668  ]], dtype=float32)
time = 645	action = 0	current_phase = 0	next_phase = 1	reward = 0.723025	array([[-0.44216514, -6.7906475 ]], dtype=float32)
time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 0.445398	array([[ 0.6752584, -7.69992  ]], dtype=float32)
time = 655	action = 0	current_phase = 0	next_phase = 1	reward = 1.284924	array([[-0.20693016, -5.929158  ]], dtype=float32)
time = 660	action = 0	current_phase = 0	next_phase = 1	reward = 0.725375	array([[ 0.6187303, -8.688799 ]], dtype=float32)
time = 665	action = 0	current_phase = 0	next_phase = 1	reward = 0.446431	array([[ 0.30841208, -5.3303905 ]], dtype=float32)
time = 670	action = 0	current_phase = 0	next_phase = 1	reward = 1.000868	array([[ 0.24088883, -6.8234963 ]], dtype=float32)
time = 675	action = 0	current_phase = 0	next_phase = 1	reward = 0.443131	array([[ 0.68483377, -9.198486  ]], dtype=float32)
time = 680	action = 0	current_phase = 0	next_phase = 1	reward = 1.011132	array([[ 0.19124222, -7.0873547 ]], dtype=float32)
time = 685	action = 0	current_phase = 0	next_phase = 1	reward = 0.721064	array([[ 0.5369971, -6.5041885]], dtype=float32)
time = 690	action = 0	current_phase = 0	next_phase = 1	reward = 0.444550	array([[ 0.1322751, -6.73517  ]], dtype=float32)
time = 695	action = 0	current_phase = 0	next_phase = 1	reward = 1.005863	array([[ 0.19950151, -7.4489098 ]], dtype=float32)
time = 700	action = 0	current_phase = 0	next_phase = 1	reward = 0.723661	array([[ 0.57653785, -6.0384607 ]], dtype=float32)
time = 705	action = 0	current_phase = 0	next_phase = 1	reward = 0.719028	array([[ 0.8875375, -7.6816244]], dtype=float32)
time = 710	action = 0	current_phase = 0	next_phase = 1	reward = 0.445776	array([[ 0.70186067, -6.6278687 ]], dtype=float32)
time = 715	action = 0	current_phase = 0	next_phase = 1	reward = 0.724154	array([[-0.44760108, -7.129746  ]], dtype=float32)
time = 720	action = 0	current_phase = 0	next_phase = 1	reward = 0.736148	array([[-0.1139102, -5.7046566]], dtype=float32)
time = 725	action = 0	current_phase = 0	next_phase = 1	reward = 1.002736	array([[  1.0811403, -10.89918  ]], dtype=float32)
time = 730	action = 0	current_phase = 0	next_phase = 1	reward = 0.717231	array([[ 0.5017524, -9.792969 ]], dtype=float32)
time = 735	action = 0	current_phase = 0	next_phase = 1	reward = 0.724016	array([[ 0.94794273, -8.69185   ]], dtype=float32)
time = 740	action = 0	current_phase = 0	next_phase = 1	reward = 0.728538	array([[ 0.2306416, -7.676734 ]], dtype=float32)
time = 745	action = 0	current_phase = 0	next_phase = 1	reward = 0.731093	array([[ 0.41200423, -9.013517  ]], dtype=float32)
time = 750	action = 0	current_phase = 0	next_phase = 1	reward = 0.450213	array([[ 0.4475236, -7.985446 ]], dtype=float32)
time = 755	action = 0	current_phase = 0	next_phase = 1	reward = 1.006389	array([[-0.35365057, -7.6361356 ]], dtype=float32)
time = 760	action = 0	current_phase = 0	next_phase = 1	reward = 0.728922	array([[ 0.41913676, -6.226985  ]], dtype=float32)
time = 765	action = 0	current_phase = 0	next_phase = 1	reward = 0.721501	array([[ 1.1144996, -8.752018 ]], dtype=float32)
time = 770	action = 0	current_phase = 0	next_phase = 1	reward = 0.720940	array([[ 0.49697304, -7.121055  ]], dtype=float32)
time = 775	action = 0	current_phase = 0	next_phase = 1	reward = 0.725218	array([[ 0.52563286, -6.3611364 ]], dtype=float32)
time = 780	action = 0	current_phase = 0	next_phase = 1	reward = 0.725045	array([[ 0.27995706, -8.01389   ]], dtype=float32)
time = 785	action = 0	current_phase = 0	next_phase = 1	reward = 0.441984	array([[ 0.37391114, -8.668134  ]], dtype=float32)
time = 790	action = 0	current_phase = 0	next_phase = 1	reward = 1.000444	array([[-0.2203883, -7.2579913]], dtype=float32)
time = 795	action = 0	current_phase = 0	next_phase = 1	reward = 0.724768	array([[-0.07160747, -8.779141  ]], dtype=float32)
time = 800	action = 0	current_phase = 0	next_phase = 1	reward = 0.717237	array([[ 0.71743536, -6.889304  ]], dtype=float32)
time = 805	action = 0	current_phase = 0	next_phase = 1	reward = 0.723472	array([[ 0.81572485, -6.413252  ]], dtype=float32)
time = 810	action = 0	current_phase = 0	next_phase = 1	reward = 0.452262	array([[-0.26092625, -4.842085  ]], dtype=float32)
time = 815	action = 0	current_phase = 0	next_phase = 1	reward = 0.733656	array([[ 0.29334688, -6.399942  ]], dtype=float32)
time = 820	action = 0	current_phase = 0	next_phase = 1	reward = 1.005531	array([[ 0.6706598, -9.765417 ]], dtype=float32)
time = 825	action = 0	current_phase = 0	next_phase = 1	reward = 0.721941	array([[ 0.9116368, -6.9003696]], dtype=float32)
time = 830	action = 0	current_phase = 0	next_phase = 1	reward = 0.721091	array([[  0.5443876, -11.440334 ]], dtype=float32)
time = 835	action = 0	current_phase = 0	next_phase = 1	reward = 0.441815	array([[ 0.55594707, -9.6982565 ]], dtype=float32)
time = 840	action = 0	current_phase = 0	next_phase = 1	reward = 0.726605	array([[ 0.2752719, -6.9431105]], dtype=float32)
time = 845	action = 0	current_phase = 0	next_phase = 1	reward = 1.009348	array([[ 0.16424203, -9.567347  ]], dtype=float32)
time = 850	action = 0	current_phase = 0	next_phase = 1	reward = 0.723858	array([[ 0.5228138, -6.695771 ]], dtype=float32)
time = 855	action = 0	current_phase = 0	next_phase = 1	reward = 0.728594	array([[ 1.4097235, -8.301025 ]], dtype=float32)
time = 860	action = 0	current_phase = 0	next_phase = 1	reward = 0.723911	array([[ 0.28824234, -7.311391  ]], dtype=float32)
time = 865	action = 0	current_phase = 0	next_phase = 1	reward = 0.720021	array([[ 0.57772183, -7.4158325 ]], dtype=float32)
time = 870	action = 0	current_phase = 0	next_phase = 1	reward = 0.716227	array([[ 0.5218642, -6.761031 ]], dtype=float32)
time = 875	action = 0	current_phase = 0	next_phase = 1	reward = 0.720884	array([[ 0.5808511, -5.601179 ]], dtype=float32)
time = 880	action = 0	current_phase = 0	next_phase = 1	reward = 0.441416	array([[ 0.5846412, -7.3339148]], dtype=float32)
time = 885	action = 0	current_phase = 0	next_phase = 1	reward = 1.011572	array([[ 0.4409132, -7.1676497]], dtype=float32)
time = 890	action = 0	current_phase = 0	next_phase = 1	reward = 0.446273	array([[  0.47154498, -10.648721  ]], dtype=float32)
time = 895	action = 0	current_phase = 0	next_phase = 1	reward = 1.001922	array([[ 0.34404898, -6.6941476 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 5s - loss: 13.9604 - val_loss: 10.7778
Epoch 2/50
 - 4s - loss: 12.5652 - val_loss: 10.8583
Epoch 3/50
 - 4s - loss: 13.8473 - val_loss: 9.6487
Epoch 4/50
 - 4s - loss: 12.0292 - val_loss: 10.0137
Epoch 5/50
 - 4s - loss: 12.5511 - val_loss: 9.5459
Epoch 6/50
 - 4s - loss: 12.5237 - val_loss: 9.9629
Epoch 7/50
 - 4s - loss: 12.7543 - val_loss: 10.3213
Epoch 8/50
 - 4s - loss: 12.2734 - val_loss: 10.0818
Epoch 9/50
 - 4s - loss: 11.6375 - val_loss: 9.9811
Epoch 10/50
 - 5s - loss: 11.7151 - val_loss: 12.9566
Epoch 11/50
 - 4s - loss: 12.0030 - val_loss: 9.8816
Epoch 12/50
 - 4s - loss: 11.4261 - val_loss: 9.5846
Epoch 13/50
 - 4s - loss: 11.8015 - val_loss: 10.1241
Epoch 14/50
 - 4s - loss: 12.5201 - val_loss: 9.9580
Epoch 15/50
 - 4s - loss: 11.1852 - val_loss: 9.2874
Epoch 16/50
 - 4s - loss: 11.0302 - val_loss: 9.4756
Epoch 17/50
 - 4s - loss: 11.0551 - val_loss: 9.5692
Epoch 18/50
 - 4s - loss: 11.4060 - val_loss: 10.9487
Epoch 19/50
 - 4s - loss: 10.6545 - val_loss: 8.9413
Epoch 20/50
 - 4s - loss: 11.4384 - val_loss: 9.2578
Epoch 21/50
 - 4s - loss: 11.6942 - val_loss: 10.4122
Epoch 22/50
 - 4s - loss: 10.9913 - val_loss: 9.1831
Epoch 23/50
 - 5s - loss: 10.3432 - val_loss: 9.0801
Epoch 24/50
 - 4s - loss: 10.4899 - val_loss: 9.0229
Epoch 25/50
 - 5s - loss: 9.9418 - val_loss: 10.7082
Epoch 26/50
 - 4s - loss: 10.5017 - val_loss: 8.5037
Epoch 27/50
 - 4s - loss: 10.6421 - val_loss: 8.7788
Epoch 28/50
 - 4s - loss: 9.5947 - val_loss: 8.8603
Epoch 29/50
 - 4s - loss: 10.4203 - val_loss: 8.6413
Epoch 30/50
 - 4s - loss: 10.0268 - val_loss: 8.6502
Epoch 31/50
 - 4s - loss: 9.9544 - val_loss: 9.2431
Epoch 32/50
 - 4s - loss: 9.9030 - val_loss: 9.1536
Epoch 33/50
 - 4s - loss: 9.3722 - val_loss: 9.0711
Epoch 34/50
 - 4s - loss: 9.5080 - val_loss: 8.5946
Epoch 35/50
 - 4s - loss: 9.6128 - val_loss: 10.1411
Epoch 36/50
 - 4s - loss: 9.7640 - val_loss: 9.8386
length of memory (state 0, action 0): 683, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 900	action = 0	current_phase = 0	next_phase = 1	reward = 0.721780	array([[-0.15337491, -7.0222616 ]], dtype=float32)
time = 905	action = 0	current_phase = 0	next_phase = 1	reward = 0.442392	array([[ 0.21245861, -8.620695  ]], dtype=float32)
time = 910	action = 0	current_phase = 0	next_phase = 1	reward = 0.724148	array([[ 0.8814416, -8.239151 ]], dtype=float32)
time = 915	action = 0	current_phase = 0	next_phase = 1	reward = 0.999938	array([[ 0.27561784, -6.5697317 ]], dtype=float32)
time = 920	action = 0	current_phase = 0	next_phase = 1	reward = 0.441785	array([[ 0.11647701, -7.6440706 ]], dtype=float32)
time = 925	action = 0	current_phase = 0	next_phase = 1	reward = 1.002810	array([[ 0.33445287, -7.9974775 ]], dtype=float32)
time = 930	action = 0	current_phase = 0	next_phase = 1	reward = 0.449354	array([[-0.48137665, -6.4919558 ]], dtype=float32)
time = 935	action = 0	current_phase = 0	next_phase = 1	reward = 0.727388	array([[ 0.45327115, -7.534028  ]], dtype=float32)
time = 940	action = 0	current_phase = 0	next_phase = 1	reward = 1.012556	array([[ 0.60077643, -8.723447  ]], dtype=float32)
time = 945	action = 0	current_phase = 0	next_phase = 1	reward = 0.727425	array([[ 1.2757802, -9.913489 ]], dtype=float32)
time = 950	action = 0	current_phase = 0	next_phase = 1	reward = 0.720829	array([[ 0.585248 , -7.7917356]], dtype=float32)
time = 955	action = 0	current_phase = 0	next_phase = 1	reward = 0.721009	array([[ 0.3049705, -7.193247 ]], dtype=float32)
time = 960	action = 0	current_phase = 0	next_phase = 1	reward = 0.721766	array([[ 0.6927304, -6.8375273]], dtype=float32)
time = 965	action = 0	current_phase = 0	next_phase = 1	reward = 0.728667	array([[ 0.36973166, -7.1538553 ]], dtype=float32)
time = 970	action = 0	current_phase = 0	next_phase = 1	reward = 0.723904	array([[ 0.455971, -9.533312]], dtype=float32)
time = 975	action = 0	current_phase = 0	next_phase = 1	reward = 0.721825	array([[ 0.02842617, -6.2337337 ]], dtype=float32)
time = 980	action = 0	current_phase = 0	next_phase = 1	reward = 0.440294	array([[ 0.7455735, -8.307433 ]], dtype=float32)
time = 985	action = 0	current_phase = 0	next_phase = 1	reward = 1.005780	array([[ 0.3877287, -9.7231   ]], dtype=float32)
time = 990	action = 0	current_phase = 0	next_phase = 1	reward = 0.453502	array([[ 0.8033571, -7.653862 ]], dtype=float32)
time = 995	action = 0	current_phase = 0	next_phase = 1	reward = 1.006872	array([[ 0.45466685, -7.5980062 ]], dtype=float32)
time = 1000	action = 0	current_phase = 0	next_phase = 1	reward = 0.724212	array([[ 0.33745575, -6.5215635 ]], dtype=float32)
time = 1005	action = 0	current_phase = 0	next_phase = 1	reward = 0.714508	array([[ 0.5251627, -8.344212 ]], dtype=float32)
time = 1010	action = 0	current_phase = 0	next_phase = 1	reward = 0.713511	array([[ 0.30259204, -7.2213    ]], dtype=float32)
time = 1015	action = 0	current_phase = 0	next_phase = 1	reward = 0.715694	array([[ 0.16994524, -6.4459763 ]], dtype=float32)
time = 1020	action = 0	current_phase = 0	next_phase = 1	reward = 0.445650	array([[-1.2601141, -5.0825644]], dtype=float32)
time = 1025	action = 0	current_phase = 0	next_phase = 1	reward = 1.016254	array([[ 0.4032786, -9.607436 ]], dtype=float32)
time = 1030	action = 0	current_phase = 0	next_phase = 1	reward = 0.735709	array([[ 0.6432879, -8.519707 ]], dtype=float32)
time = 1035	action = 0	current_phase = 0	next_phase = 1	reward = 0.444886	array([[ 0.7413621, -7.0336246]], dtype=float32)
time = 1040	action = 0	current_phase = 0	next_phase = 1	reward = 0.993686	array([[-0.73464954, -5.420741  ]], dtype=float32)
time = 1045	action = 0	current_phase = 0	next_phase = 1	reward = 0.719592	array([[ 0.37097287, -7.9515038 ]], dtype=float32)
time = 1050	action = 0	current_phase = 0	next_phase = 1	reward = 0.173193	array([[ 0.6486118, -8.324681 ]], dtype=float32)
time = 1055	action = 0	current_phase = 0	next_phase = 1	reward = 1.289379	array([[ 0.17425203, -8.356209  ]], dtype=float32)
time = 1060	action = 0	current_phase = 0	next_phase = 1	reward = 0.722324	array([[ 0.07391572, -8.692608  ]], dtype=float32)
time = 1065	action = 0	current_phase = 0	next_phase = 1	reward = 0.445451	array([[ 0.4235952, -6.3502398]], dtype=float32)
time = 1070	action = 0	current_phase = 0	next_phase = 1	reward = 1.002885	array([[ 0.57110095, -6.8659344 ]], dtype=float32)
time = 1075	action = 0	current_phase = 0	next_phase = 1	reward = 0.710338	array([[-0.22896338, -6.6912365 ]], dtype=float32)
time = 1080	action = 0	current_phase = 0	next_phase = 1	reward = 0.715195	array([[ 0.66054773, -7.450903  ]], dtype=float32)
time = 1085	action = 0	current_phase = 0	next_phase = 1	reward = 0.159910	array([[ 0.32746363, -7.756015  ]], dtype=float32)
time = 1090	action = 0	current_phase = 0	next_phase = 1	reward = 1.005434	array([[ 0.01045346, -6.825527  ]], dtype=float32)
time = 1095	action = 0	current_phase = 0	next_phase = 1	reward = 1.008042	array([[ 0.09808874, -7.002901  ]], dtype=float32)
time = 1100	action = 0	current_phase = 0	next_phase = 1	reward = 0.720645	array([[ 0.6116655, -6.9846277]], dtype=float32)
time = 1105	action = 0	current_phase = 0	next_phase = 1	reward = 0.441506	array([[ 0.3182907, -8.876639 ]], dtype=float32)
time = 1110	action = 0	current_phase = 0	next_phase = 1	reward = 0.725296	array([[ 0.33425164, -7.9587975 ]], dtype=float32)
time = 1115	action = 0	current_phase = 0	next_phase = 1	reward = 0.723953	array([[ 0.18799019, -8.096439  ]], dtype=float32)
time = 1120	action = 0	current_phase = 0	next_phase = 1	reward = 1.009278	array([[ 0.08115315, -8.333508  ]], dtype=float32)
time = 1125	action = 0	current_phase = 0	next_phase = 1	reward = 0.723874	array([[ 0.6504369, -8.811075 ]], dtype=float32)
time = 1130	action = 0	current_phase = 0	next_phase = 1	reward = 0.721616	array([[ 0.35941958, -6.289345  ]], dtype=float32)
time = 1135	action = 0	current_phase = 0	next_phase = 1	reward = 0.449723	array([[ 0.66177464, -6.619893  ]], dtype=float32)
time = 1140	action = 0	current_phase = 0	next_phase = 1	reward = 1.004395	array([[ 0.57511735, -8.419286  ]], dtype=float32)
time = 1145	action = 0	current_phase = 0	next_phase = 1	reward = 0.720987	array([[ 0.848052, -6.746747]], dtype=float32)
time = 1150	action = 0	current_phase = 0	next_phase = 1	reward = 0.716361	array([[ 0.94266295, -9.1153145 ]], dtype=float32)
time = 1155	action = 0	current_phase = 0	next_phase = 1	reward = 0.716893	array([[ 0.06942272, -7.8841095 ]], dtype=float32)
time = 1160	action = 0	current_phase = 0	next_phase = 1	reward = 0.167832	array([[ 0.39726686, -6.712838  ]], dtype=float32)
time = 1165	action = 0	current_phase = 0	next_phase = 1	reward = 1.294025	array([[-0.92350125, -5.5842533 ]], dtype=float32)
time = 1170	action = 0	current_phase = 0	next_phase = 1	reward = 0.717424	array([[ 0.38558674, -8.418722  ]], dtype=float32)
time = 1175	action = 0	current_phase = 0	next_phase = 1	reward = 0.446734	array([[ 0.32112217, -6.429878  ]], dtype=float32)
time = 1180	action = 0	current_phase = 0	next_phase = 1	reward = 1.000396	array([[-0.1402247, -7.3818026]], dtype=float32)
time = 1185	action = 0	current_phase = 0	next_phase = 1	reward = 0.170794	array([[-0.06210065, -7.9508257 ]], dtype=float32)
time = 1190	action = 0	current_phase = 0	next_phase = 1	reward = 1.285414	array([[ 0.18010068, -6.697749  ]], dtype=float32)
time = 1195	action = 0	current_phase = 0	next_phase = 1	reward = 0.444512	array([[ 1.2779217, -8.623109 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 11.0418 - val_loss: 8.7298
Epoch 2/50
 - 4s - loss: 11.6440 - val_loss: 8.5840
Epoch 3/50
 - 4s - loss: 11.2287 - val_loss: 8.2446
Epoch 4/50
 - 4s - loss: 9.9540 - val_loss: 8.2251
Epoch 5/50
 - 4s - loss: 10.3198 - val_loss: 8.7090
Epoch 6/50
 - 4s - loss: 9.6872 - val_loss: 8.3635
Epoch 7/50
 - 4s - loss: 10.0977 - val_loss: 7.7332
Epoch 8/50
 - 4s - loss: 9.0661 - val_loss: 7.6607
Epoch 9/50
 - 5s - loss: 9.6187 - val_loss: 7.9802
Epoch 10/50
 - 4s - loss: 9.9664 - val_loss: 8.1567
Epoch 11/50
 - 4s - loss: 9.4891 - val_loss: 8.9553
Epoch 12/50
 - 4s - loss: 9.6857 - val_loss: 8.4833
Epoch 13/50
 - 4s - loss: 9.5281 - val_loss: 7.7299
Epoch 14/50
 - 4s - loss: 9.3581 - val_loss: 8.0007
Epoch 15/50
 - 4s - loss: 8.9320 - val_loss: 8.7791
Epoch 16/50
 - 4s - loss: 9.1973 - val_loss: 8.1846
Epoch 17/50
 - 4s - loss: 8.8278 - val_loss: 8.1057
Epoch 18/50
 - 4s - loss: 9.1645 - val_loss: 8.0982
length of memory (state 0, action 0): 743, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 1200	action = 0	current_phase = 0	next_phase = 1	reward = 1.012076	array([[ 0.50828934, -7.4627147 ]], dtype=float32)
time = 1205	action = 0	current_phase = 0	next_phase = 1	reward = 0.729938	array([[ 0.6928425, -7.2193556]], dtype=float32)
time = 1210	action = 0	current_phase = 0	next_phase = 1	reward = 0.442734	array([[ 0.43998647, -6.554008  ]], dtype=float32)
time = 1215	action = 0	current_phase = 0	next_phase = 1	reward = 1.006990	array([[ 0.12127566, -6.3237143 ]], dtype=float32)
time = 1220	action = 0	current_phase = 0	next_phase = 1	reward = 0.436444	array([[ 0.19618559, -7.5638356 ]], dtype=float32)
time = 1225	action = 0	current_phase = 0	next_phase = 1	reward = 1.002838	array([[ 0.52770257, -7.0833216 ]], dtype=float32)
time = 1230	action = 0	current_phase = 0	next_phase = 1	reward = 0.444410	array([[ 0.28905964, -6.7654834 ]], dtype=float32)
time = 1235	action = 0	current_phase = 0	next_phase = 1	reward = 1.002100	array([[ 0.55449796, -7.7084446 ]], dtype=float32)
time = 1240	action = 0	current_phase = 0	next_phase = 1	reward = 0.706804	array([[ 0.9748328, -7.808313 ]], dtype=float32)
time = 1245	action = 0	current_phase = 0	next_phase = 1	reward = 0.440876	array([[ 0.36139655, -7.0720515 ]], dtype=float32)
time = 1250	action = 0	current_phase = 0	next_phase = 1	reward = 0.734436	array([[ 0.32478023, -6.660717  ]], dtype=float32)
time = 1255	action = 0	current_phase = 0	next_phase = 1	reward = 1.002729	array([[-0.08096385, -6.6463065 ]], dtype=float32)
time = 1260	action = 0	current_phase = 0	next_phase = 1	reward = 0.733183	array([[ 0.65849876, -6.8235106 ]], dtype=float32)
time = 1265	action = 0	current_phase = 0	next_phase = 1	reward = 0.721974	array([[ 0.00587726, -5.795968  ]], dtype=float32)
time = 1270	action = 0	current_phase = 0	next_phase = 1	reward = 0.444178	array([[ 0.95690227, -8.6849    ]], dtype=float32)
time = 1275	action = 0	current_phase = 0	next_phase = 1	reward = 1.006686	array([[ 0.13547611, -6.8409986 ]], dtype=float32)
time = 1280	action = 0	current_phase = 0	next_phase = 1	reward = 0.730175	array([[ 0.546288, -6.920084]], dtype=float32)
time = 1285	action = 0	current_phase = 0	next_phase = 1	reward = 0.716375	array([[ 0.1822443, -6.595999 ]], dtype=float32)
time = 1290	action = 0	current_phase = 0	next_phase = 1	reward = 0.448153	array([[ 0.8857591, -8.520243 ]], dtype=float32)
time = 1295	action = 0	current_phase = 0	next_phase = 1	reward = 1.008930	array([[-0.07327676, -6.194703  ]], dtype=float32)
time = 1300	action = 0	current_phase = 0	next_phase = 1	reward = 0.723606	array([[ 0.35423613, -7.1170197 ]], dtype=float32)
time = 1305	action = 0	current_phase = 0	next_phase = 1	reward = 0.722172	array([[ 0.4757123, -8.209394 ]], dtype=float32)
time = 1310	action = 0	current_phase = 0	next_phase = 1	reward = 0.720692	array([[ 0.41706157, -6.305853  ]], dtype=float32)
time = 1315	action = 0	current_phase = 0	next_phase = 1	reward = 0.722297	array([[ 0.3544793, -6.3696747]], dtype=float32)
time = 1320	action = 0	current_phase = 0	next_phase = 1	reward = 0.722807	array([[ 1.4863882, -8.496603 ]], dtype=float32)
time = 1325	action = 0	current_phase = 0	next_phase = 1	reward = 0.720861	array([[ 1.2612085, -7.227371 ]], dtype=float32)
time = 1330	action = 0	current_phase = 0	next_phase = 1	reward = 0.717194	array([[ 0.9874704, -7.50624  ]], dtype=float32)
time = 1335	action = 0	current_phase = 0	next_phase = 1	reward = 0.723761	array([[ 0.58435655, -7.0447702 ]], dtype=float32)
time = 1340	action = 0	current_phase = 0	next_phase = 1	reward = 0.442748	array([[ 0.50247407, -8.773233  ]], dtype=float32)
time = 1345	action = 0	current_phase = 0	next_phase = 1	reward = 0.733817	array([[ 0.00833654, -6.5006866 ]], dtype=float32)
time = 1350	action = 0	current_phase = 0	next_phase = 1	reward = 1.001455	array([[ 0.63025355, -7.038436  ]], dtype=float32)
time = 1355	action = 0	current_phase = 0	next_phase = 1	reward = 0.717637	array([[ 0.28764606, -6.7783046 ]], dtype=float32)
time = 1360	action = 0	current_phase = 0	next_phase = 1	reward = 0.721085	array([[ 1.0155911, -8.263645 ]], dtype=float32)
time = 1365	action = 0	current_phase = 0	next_phase = 1	reward = 0.440022	array([[ 0.5282366, -6.5187836]], dtype=float32)
time = 1370	action = 0	current_phase = 0	next_phase = 1	reward = 1.002488	array([[ 0.47457886, -7.7008014 ]], dtype=float32)
time = 1375	action = 0	current_phase = 0	next_phase = 1	reward = 0.722250	array([[ 0.48343349, -6.6737847 ]], dtype=float32)
time = 1380	action = 0	current_phase = 0	next_phase = 1	reward = 0.716622	array([[ 0.34917617, -6.3308845 ]], dtype=float32)
time = 1385	action = 0	current_phase = 0	next_phase = 1	reward = 0.444241	array([[ 0.46488833, -6.2854753 ]], dtype=float32)
time = 1390	action = 0	current_phase = 0	next_phase = 1	reward = 1.016246	array([[ 0.782531, -9.783328]], dtype=float32)
time = 1395	action = 0	current_phase = 0	next_phase = 1	reward = 0.449749	array([[ 0.12148333, -5.8722925 ]], dtype=float32)
time = 1400	action = 0	current_phase = 0	next_phase = 1	reward = 1.004891	array([[ 0.26587296, -7.211295  ]], dtype=float32)
time = 1405	action = 0	current_phase = 0	next_phase = 1	reward = 0.717671	array([[ 0.41870284, -6.671197  ]], dtype=float32)
time = 1410	action = 0	current_phase = 0	next_phase = 1	reward = 0.441400	array([[ 0.8529458, -8.642721 ]], dtype=float32)
time = 1415	action = 0	current_phase = 0	next_phase = 1	reward = 0.720973	array([[ 0.07123089, -6.2276363 ]], dtype=float32)
time = 1420	action = 0	current_phase = 0	next_phase = 1	reward = 0.721831	array([[ 0.1111443, -7.176423 ]], dtype=float32)
time = 1425	action = 0	current_phase = 0	next_phase = 1	reward = 0.722168	array([[-0.00965309, -6.509302  ]], dtype=float32)
time = 1430	action = 0	current_phase = 0	next_phase = 1	reward = 0.723066	array([[ 0.36720228, -9.906202  ]], dtype=float32)
time = 1435	action = 0	current_phase = 0	next_phase = 1	reward = 0.446779	array([[ 0.5360832, -6.8470144]], dtype=float32)
time = 1440	action = 0	current_phase = 0	next_phase = 1	reward = 1.295522	array([[-0.10740376, -6.0974054 ]], dtype=float32)
time = 1445	action = 0	current_phase = 0	next_phase = 1	reward = 0.725520	array([[ 0.07667303, -6.2442083 ]], dtype=float32)
time = 1450	action = 0	current_phase = 0	next_phase = 1	reward = 0.720479	array([[ 0.44915366, -6.6283183 ]], dtype=float32)
time = 1455	action = 0	current_phase = 0	next_phase = 1	reward = 0.719992	array([[ 0.28616548, -6.0705338 ]], dtype=float32)
time = 1460	action = 0	current_phase = 0	next_phase = 1	reward = 0.443934	array([[ 0.06206942, -6.678065  ]], dtype=float32)
time = 1465	action = 0	current_phase = 0	next_phase = 1	reward = 0.725825	array([[ 0.67778516, -6.117799  ]], dtype=float32)
time = 1470	action = 0	current_phase = 0	next_phase = 1	reward = 0.998935	array([[ 0.4008205, -6.862722 ]], dtype=float32)
time = 1475	action = 0	current_phase = 0	next_phase = 1	reward = 0.729087	array([[ 0.49236608, -7.559096  ]], dtype=float32)
time = 1480	action = 0	current_phase = 0	next_phase = 1	reward = 0.445499	array([[ 0.62263536, -6.3948236 ]], dtype=float32)
time = 1485	action = 0	current_phase = 0	next_phase = 1	reward = 1.007100	array([[-0.04151893, -6.4676666 ]], dtype=float32)
time = 1490	action = 0	current_phase = 0	next_phase = 1	reward = 0.718211	array([[ 0.7411332, -7.837833 ]], dtype=float32)
time = 1495	action = 0	current_phase = 0	next_phase = 1	reward = 0.442665	array([[ 0.22829723, -6.289876  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 8.3148 - val_loss: 11.8605
Epoch 2/50
 - 4s - loss: 8.1999 - val_loss: 9.9672
Epoch 3/50
 - 4s - loss: 8.2248 - val_loss: 11.3291
Epoch 4/50
 - 4s - loss: 8.4913 - val_loss: 10.4934
Epoch 5/50
 - 4s - loss: 8.0429 - val_loss: 10.0526
Epoch 6/50
 - 4s - loss: 8.8901 - val_loss: 10.0427
Epoch 7/50
 - 4s - loss: 7.8119 - val_loss: 10.7456
Epoch 8/50
 - 4s - loss: 8.4236 - val_loss: 9.7465
Epoch 9/50
 - 4s - loss: 7.3173 - val_loss: 9.7230
Epoch 10/50
 - 4s - loss: 7.4732 - val_loss: 10.8682
Epoch 11/50
 - 4s - loss: 7.3962 - val_loss: 11.2212
Epoch 12/50
 - 4s - loss: 7.3259 - val_loss: 10.1120
Epoch 13/50
 - 4s - loss: 7.1665 - val_loss: 9.0082
Epoch 14/50
 - 4s - loss: 7.5590 - val_loss: 9.3349
Epoch 15/50
 - 4s - loss: 7.5134 - val_loss: 11.0422
Epoch 16/50
 - 4s - loss: 7.0643 - val_loss: 9.1181
Epoch 17/50
 - 4s - loss: 7.2242 - val_loss: 9.2126
Epoch 18/50
 - 4s - loss: 6.7472 - val_loss: 9.8092
Epoch 19/50
 - 4s - loss: 6.9030 - val_loss: 10.6823
Epoch 20/50
 - 4s - loss: 6.6683 - val_loss: 9.4772
Epoch 21/50
 - 4s - loss: 7.5011 - val_loss: 10.7513
Epoch 22/50
 - 4s - loss: 7.2345 - val_loss: 10.5529
Epoch 23/50
 - 4s - loss: 6.7077 - val_loss: 12.0612
length of memory (state 0, action 0): 803, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 1500	action = 0	current_phase = 0	next_phase = 1	reward = 1.004043	array([[ 0.51824784, -6.562308  ]], dtype=float32)
time = 1505	action = 0	current_phase = 0	next_phase = 1	reward = 0.724954	array([[ 0.8907652, -8.121935 ]], dtype=float32)
time = 1510	action = 0	current_phase = 0	next_phase = 1	reward = 0.717755	array([[ 0.4642706, -6.3458567]], dtype=float32)
time = 1515	action = 0	current_phase = 0	next_phase = 1	reward = 0.721227	array([[ 0.45582342, -5.9262853 ]], dtype=float32)
time = 1520	action = 0	current_phase = 0	next_phase = 1	reward = 0.719797	array([[ 0.5050962, -7.509358 ]], dtype=float32)
time = 1525	action = 0	current_phase = 0	next_phase = 1	reward = 0.724818	array([[ 0.5823686, -6.352557 ]], dtype=float32)
time = 1530	action = 0	current_phase = 0	next_phase = 1	reward = 0.722568	array([[-0.01868439, -6.503987  ]], dtype=float32)
time = 1535	action = 0	current_phase = 0	next_phase = 1	reward = 0.732047	array([[ 0.6335869, -6.6445355]], dtype=float32)
time = 1540	action = 0	current_phase = 0	next_phase = 1	reward = 0.731583	array([[ 0.5594473, -8.1018305]], dtype=float32)
time = 1545	action = 0	current_phase = 0	next_phase = 1	reward = 0.724371	array([[ 0.6047952, -6.891361 ]], dtype=float32)
time = 1550	action = 0	current_phase = 0	next_phase = 1	reward = 0.719137	array([[ 0.9017229, -7.630697 ]], dtype=float32)
time = 1555	action = 0	current_phase = 0	next_phase = 1	reward = 0.442573	array([[ 1.0357049, -8.154064 ]], dtype=float32)
time = 1560	action = 0	current_phase = 0	next_phase = 1	reward = 1.008444	array([[ 0.67445064, -7.181119  ]], dtype=float32)
time = 1565	action = 0	current_phase = 0	next_phase = 1	reward = 0.726314	array([[ 0.5215452, -6.454949 ]], dtype=float32)
time = 1570	action = 0	current_phase = 0	next_phase = 1	reward = 0.718584	array([[ 1.3343623, -8.834021 ]], dtype=float32)
time = 1575	action = 0	current_phase = 0	next_phase = 1	reward = 0.440845	array([[ 0.5013261, -5.9252687]], dtype=float32)
time = 1580	action = 0	current_phase = 0	next_phase = 1	reward = 1.003305	array([[ 0.72425175, -7.4844637 ]], dtype=float32)
time = 1585	action = 0	current_phase = 0	next_phase = 1	reward = 0.721370	array([[ 0.809129 , -7.1732407]], dtype=float32)
time = 1590	action = 0	current_phase = 0	next_phase = 1	reward = 0.729453	array([[ 0.6567967, -6.9968615]], dtype=float32)
time = 1595	action = 0	current_phase = 0	next_phase = 1	reward = 0.726499	array([[ 0.54829645, -7.639902  ]], dtype=float32)
time = 1600	action = 0	current_phase = 0	next_phase = 1	reward = 0.726252	array([[ 0.5148773, -7.2663636]], dtype=float32)
time = 1605	action = 0	current_phase = 0	next_phase = 1	reward = 0.720154	array([[ 0.7230022, -7.2412753]], dtype=float32)
time = 1610	action = 0	current_phase = 0	next_phase = 1	reward = 0.720947	array([[ 0.49422836, -7.2264256 ]], dtype=float32)
time = 1615	action = 0	current_phase = 0	next_phase = 1	reward = 0.731310	array([[ 0.5557983, -7.6792903]], dtype=float32)
time = 1620	action = 0	current_phase = 0	next_phase = 1	reward = 0.448030	array([[ 0.39067602, -7.2513914 ]], dtype=float32)
time = 1625	action = 0	current_phase = 0	next_phase = 1	reward = 1.005567	array([[ 0.5438621, -6.71246  ]], dtype=float32)
time = 1630	action = 0	current_phase = 0	next_phase = 1	reward = 0.719828	array([[ 0.4896021, -9.039356 ]], dtype=float32)
time = 1635	action = 0	current_phase = 0	next_phase = 1	reward = 0.721561	array([[ 0.7685368, -7.7950616]], dtype=float32)
time = 1640	action = 0	current_phase = 0	next_phase = 1	reward = 0.728128	array([[ 0.55348444, -6.9095316 ]], dtype=float32)
time = 1645	action = 0	current_phase = 0	next_phase = 1	reward = 0.725095	array([[ 0.94190526, -8.356752  ]], dtype=float32)
time = 1650	action = 0	current_phase = 0	next_phase = 1	reward = 0.716950	array([[ 0.9539597, -6.4307203]], dtype=float32)
time = 1655	action = 0	current_phase = 0	next_phase = 1	reward = 0.443342	array([[ 0.24129224, -5.946928  ]], dtype=float32)
time = 1660	action = 0	current_phase = 0	next_phase = 1	reward = 1.003490	array([[ 0.35187316, -7.1982703 ]], dtype=float32)
time = 1665	action = 0	current_phase = 0	next_phase = 1	reward = 0.721740	array([[ 0.55224156, -6.8022614 ]], dtype=float32)
time = 1670	action = 0	current_phase = 0	next_phase = 1	reward = 0.723923	array([[-0.30531287, -5.3693953 ]], dtype=float32)
time = 1675	action = 0	current_phase = 0	next_phase = 1	reward = 0.718257	array([[ 0.28630805, -6.3769155 ]], dtype=float32)
time = 1680	action = 0	current_phase = 0	next_phase = 1	reward = 0.706792	array([[ 0.6393187, -5.9824934]], dtype=float32)
time = 1685	action = 0	current_phase = 0	next_phase = 1	reward = 0.714380	array([[ 0.63857865, -7.26059   ]], dtype=float32)
time = 1690	action = 0	current_phase = 0	next_phase = 1	reward = 0.166808	array([[ 0.44022655, -6.6220846 ]], dtype=float32)
time = 1695	action = 0	current_phase = 0	next_phase = 1	reward = 1.290732	array([[ 0.7119658, -7.984219 ]], dtype=float32)
time = 1700	action = 0	current_phase = 0	next_phase = 1	reward = 0.440462	array([[ 0.19725823, -6.7701907 ]], dtype=float32)
time = 1705	action = 0	current_phase = 0	next_phase = 1	reward = 0.728060	array([[ 0.5781493, -7.4539466]], dtype=float32)
time = 1710	action = 0	current_phase = 0	next_phase = 1	reward = 0.732870	array([[ 0.72012186, -7.6855435 ]], dtype=float32)
time = 1715	action = 0	current_phase = 0	next_phase = 1	reward = 1.001550	array([[ 0.9585221, -8.300648 ]], dtype=float32)
time = 1720	action = 0	current_phase = 0	next_phase = 1	reward = 0.717934	array([[ 0.39960194, -6.364424  ]], dtype=float32)
time = 1725	action = 0	current_phase = 0	next_phase = 1	reward = 0.720877	array([[ 0.7248697, -7.260903 ]], dtype=float32)
time = 1730	action = 0	current_phase = 0	next_phase = 1	reward = 0.716524	array([[ 0.1464386, -5.635191 ]], dtype=float32)
time = 1735	action = 0	current_phase = 0	next_phase = 1	reward = 0.715406	array([[ 0.45590234, -6.332726  ]], dtype=float32)
time = 1740	action = 0	current_phase = 0	next_phase = 1	reward = 0.437577	array([[ 0.367671, -7.243135]], dtype=float32)
time = 1745	action = 0	current_phase = 0	next_phase = 1	reward = 0.722945	array([[ 0.8437145, -8.182331 ]], dtype=float32)
time = 1750	action = 0	current_phase = 0	next_phase = 1	reward = 1.008625	array([[ 0.59710455, -6.8921986 ]], dtype=float32)
time = 1755	action = 0	current_phase = 0	next_phase = 1	reward = 0.444238	array([[ 1.3605194, -8.516102 ]], dtype=float32)
time = 1760	action = 0	current_phase = 0	next_phase = 1	reward = 1.009187	array([[ 0.7266424, -7.4928346]], dtype=float32)
time = 1765	action = 0	current_phase = 0	next_phase = 1	reward = 0.442087	array([[ 0.5395253, -6.5824246]], dtype=float32)
time = 1770	action = 0	current_phase = 0	next_phase = 1	reward = 1.001840	array([[  1.3388319, -10.236385 ]], dtype=float32)
time = 1775	action = 0	current_phase = 0	next_phase = 1	reward = 0.441098	array([[ 0.66549873, -7.418558  ]], dtype=float32)
time = 1780	action = 0	current_phase = 0	next_phase = 1	reward = 1.008637	array([[ 0.2788453, -6.2273464]], dtype=float32)
time = 1785	action = 0	current_phase = 0	next_phase = 1	reward = 0.717851	array([[ 0.6770401, -6.846467 ]], dtype=float32)
time = 1790	action = 0	current_phase = 0	next_phase = 1	reward = 0.445334	array([[ 0.40001726, -6.834059  ]], dtype=float32)
time = 1795	action = 0	current_phase = 0	next_phase = 1	reward = 1.008005	array([[-0.03981352, -6.4963455 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 17.5816 - val_loss: 22.0616
Epoch 2/50
 - 4s - loss: 14.7397 - val_loss: 21.9552
Epoch 3/50
 - 4s - loss: 14.6871 - val_loss: 21.7985
Epoch 4/50
 - 4s - loss: 13.5014 - val_loss: 21.8062
Epoch 5/50
 - 4s - loss: 12.7467 - val_loss: 20.3688
Epoch 6/50
 - 4s - loss: 12.4457 - val_loss: 20.8951
Epoch 7/50
 - 4s - loss: 13.2699 - val_loss: 20.2361
Epoch 8/50
 - 4s - loss: 12.2375 - val_loss: 21.1312
Epoch 9/50
 - 4s - loss: 12.2200 - val_loss: 20.7585
Epoch 10/50
 - 4s - loss: 11.8204 - val_loss: 20.3021
Epoch 11/50
 - 4s - loss: 12.6111 - val_loss: 20.8866
Epoch 12/50
 - 4s - loss: 11.3818 - val_loss: 20.5843
Epoch 13/50
 - 4s - loss: 11.2468 - val_loss: 18.7811
Epoch 14/50
 - 4s - loss: 11.3349 - val_loss: 18.5764
Epoch 15/50
 - 4s - loss: 11.8672 - val_loss: 19.1551
Epoch 16/50
 - 4s - loss: 10.8642 - val_loss: 18.9697
Epoch 17/50
 - 4s - loss: 10.6210 - val_loss: 18.9274
Epoch 18/50
 - 4s - loss: 10.9918 - val_loss: 18.2151
Epoch 19/50
 - 4s - loss: 12.0094 - val_loss: 17.9021
Epoch 20/50
 - 4s - loss: 10.2670 - val_loss: 18.9408
Epoch 21/50
 - 4s - loss: 10.2513 - val_loss: 18.3015
Epoch 22/50
 - 4s - loss: 11.3856 - val_loss: 18.0795
Epoch 23/50
 - 4s - loss: 9.9776 - val_loss: 18.1495
Epoch 24/50
 - 4s - loss: 9.6100 - val_loss: 18.0917
Epoch 25/50
 - 4s - loss: 9.9076 - val_loss: 18.0290
Epoch 26/50
 - 4s - loss: 10.0902 - val_loss: 17.3581
Epoch 27/50
 - 4s - loss: 9.7331 - val_loss: 17.0205
Epoch 28/50
 - 4s - loss: 10.6142 - val_loss: 17.2102
Epoch 29/50
 - 4s - loss: 9.4025 - val_loss: 17.9308
Epoch 30/50
 - 4s - loss: 9.2486 - val_loss: 19.5910
Epoch 31/50
 - 4s - loss: 8.9187 - val_loss: 17.7491
Epoch 32/50
 - 4s - loss: 9.3994 - val_loss: 18.1790
Epoch 33/50
 - 4s - loss: 8.5240 - val_loss: 17.7344
Epoch 34/50
 - 4s - loss: 8.6241 - val_loss: 17.9143
Epoch 35/50
 - 4s - loss: 8.7590 - val_loss: 17.7170
Epoch 36/50
 - 4s - loss: 8.8129 - val_loss: 16.4457
Epoch 37/50
 - 4s - loss: 8.7964 - val_loss: 16.7280
Epoch 38/50
 - 4s - loss: 8.4827 - val_loss: 16.8248
Epoch 39/50
 - 4s - loss: 8.8017 - val_loss: 16.9740
Epoch 40/50
 - 4s - loss: 8.3067 - val_loss: 16.2057
Epoch 41/50
 - 4s - loss: 8.6903 - val_loss: 17.0485
Epoch 42/50
 - 4s - loss: 8.7169 - val_loss: 16.0210
Epoch 43/50
 - 4s - loss: 8.3170 - val_loss: 16.7666
Epoch 44/50
 - 4s - loss: 8.4530 - val_loss: 16.1253
Epoch 45/50
 - 4s - loss: 8.5621 - val_loss: 16.0466
Epoch 46/50
 - 4s - loss: 8.9475 - val_loss: 16.2783
Epoch 47/50
 - 4s - loss: 8.0287 - val_loss: 19.0003
Epoch 48/50
 - 4s - loss: 7.9514 - val_loss: 18.2619
Epoch 49/50
 - 4s - loss: 8.7361 - val_loss: 18.8159
Epoch 50/50
 - 4s - loss: 7.9125 - val_loss: 17.7866
length of memory (state 0, action 0): 863, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 1800	action = 0	current_phase = 0	next_phase = 1	reward = 0.726211	array([[ 1.0966475, -7.0078106]], dtype=float32)
time = 1805	action = 0	current_phase = 0	next_phase = 1	reward = 0.739422	array([[ 1.3917129, -7.8088284]], dtype=float32)
time = 1810	action = 0	current_phase = 0	next_phase = 1	reward = 0.717967	array([[ 1.324796, -7.149769]], dtype=float32)
time = 1815	action = 0	current_phase = 0	next_phase = 1	reward = 0.721471	array([[ 1.2158444, -6.7837114]], dtype=float32)
time = 1820	action = 0	current_phase = 0	next_phase = 1	reward = 0.721514	array([[ 1.2259777, -7.037655 ]], dtype=float32)
time = 1825	action = 0	current_phase = 0	next_phase = 1	reward = 0.722423	array([[ 1.2574439, -7.708335 ]], dtype=float32)
time = 1830	action = 0	current_phase = 0	next_phase = 1	reward = 0.448286	array([[ 1.1687984, -6.9126062]], dtype=float32)
time = 1835	action = 0	current_phase = 0	next_phase = 1	reward = 1.006275	array([[ 1.29674 , -9.666461]], dtype=float32)
time = 1840	action = 0	current_phase = 0	next_phase = 1	reward = 0.718169	array([[ 1.3089437, -6.910512 ]], dtype=float32)
time = 1845	action = 0	current_phase = 0	next_phase = 1	reward = 0.711760	array([[ 1.1706791, -6.801892 ]], dtype=float32)
time = 1850	action = 0	current_phase = 0	next_phase = 1	reward = 0.711241	array([[ 1.3755417, -7.9535055]], dtype=float32)
time = 1855	action = 0	current_phase = 0	next_phase = 1	reward = 0.161945	array([[ 1.1341078, -6.7552423]], dtype=float32)
time = 1860	action = 0	current_phase = 0	next_phase = 1	reward = 1.014907	array([[ 1.3502901, -8.352488 ]], dtype=float32)
time = 1865	action = 0	current_phase = 0	next_phase = 1	reward = 1.000185	array([[ 1.3797121, -8.53185  ]], dtype=float32)
time = 1870	action = 0	current_phase = 0	next_phase = 1	reward = 0.443095	array([[ 1.3298125, -6.9319506]], dtype=float32)
time = 1875	action = 0	current_phase = 0	next_phase = 1	reward = 0.726122	array([[ 1.0703316, -6.6610823]], dtype=float32)
time = 1880	action = 0	current_phase = 0	next_phase = 1	reward = 1.013213	array([[ 1.2565119, -7.661747 ]], dtype=float32)
time = 1885	action = 0	current_phase = 0	next_phase = 1	reward = 0.729694	array([[ 1.7195847, -8.227752 ]], dtype=float32)
time = 1890	action = 0	current_phase = 0	next_phase = 1	reward = 0.724311	array([[ 1.3470917, -7.127116 ]], dtype=float32)
time = 1895	action = 0	current_phase = 0	next_phase = 1	reward = 0.718970	array([[ 1.3593581, -7.2677813]], dtype=float32)
time = 1900	action = 0	current_phase = 0	next_phase = 1	reward = 0.715204	array([[ 1.2772658, -6.8573904]], dtype=float32)
time = 1905	action = 0	current_phase = 0	next_phase = 1	reward = 0.711298	array([[ 1.2837498, -7.0782614]], dtype=float32)
time = 1910	action = 0	current_phase = 0	next_phase = 1	reward = 0.442195	array([[ 1.2206776, -6.934289 ]], dtype=float32)
time = 1915	action = 0	current_phase = 0	next_phase = 1	reward = 1.012569	array([[ 0.8325765, -7.2333775]], dtype=float32)
time = 1920	action = 0	current_phase = 0	next_phase = 1	reward = 0.458269	array([[ 1.1994874, -6.7642097]], dtype=float32)
time = 1925	action = 0	current_phase = 0	next_phase = 1	reward = 1.005479	array([[ 1.1629999, -6.967532 ]], dtype=float32)
time = 1930	action = 0	current_phase = 0	next_phase = 1	reward = 0.722058	array([[ 1.3654687, -7.2135124]], dtype=float32)
time = 1935	action = 0	current_phase = 0	next_phase = 1	reward = 0.726680	array([[ 1.3742337, -7.3302145]], dtype=float32)
time = 1940	action = 0	current_phase = 0	next_phase = 1	reward = 0.717698	array([[ 1.1911922, -6.8547363]], dtype=float32)
time = 1945	action = 0	current_phase = 0	next_phase = 1	reward = 0.717688	array([[ 1.2774875, -7.605359 ]], dtype=float32)
time = 1950	action = 0	current_phase = 0	next_phase = 1	reward = 0.445512	array([[ 0.9713881, -6.605221 ]], dtype=float32)
time = 1955	action = 0	current_phase = 0	next_phase = 1	reward = 1.002936	array([[ 1.086555, -6.860078]], dtype=float32)
time = 1960	action = 0	current_phase = 0	next_phase = 1	reward = 0.720114	array([[ 1.2245195, -7.4579306]], dtype=float32)
time = 1965	action = 0	current_phase = 0	next_phase = 1	reward = 0.439048	array([[ 1.3211305, -6.92249  ]], dtype=float32)
time = 1970	action = 0	current_phase = 0	next_phase = 1	reward = 1.001127	array([[ 1.0355654, -7.041917 ]], dtype=float32)
time = 1975	action = 0	current_phase = 0	next_phase = 1	reward = 0.442419	array([[ 1.1990116, -6.9255457]], dtype=float32)
time = 1980	action = 0	current_phase = 0	next_phase = 1	reward = 0.445108	array([[ 1.1131797, -6.7868047]], dtype=float32)
time = 1985	action = 0	current_phase = 0	next_phase = 1	reward = 1.288848	array([[ 0.95892954, -7.1969557 ]], dtype=float32)
time = 1990	action = 0	current_phase = 0	next_phase = 1	reward = 0.716452	array([[ 1.176786 , -6.8477793]], dtype=float32)
time = 1995	action = 0	current_phase = 0	next_phase = 1	reward = 0.439606	array([[ 1.37287 , -7.240657]], dtype=float32)
time = 2000	action = 0	current_phase = 0	next_phase = 1	reward = 0.720725	array([[ 1.0881608, -7.177578 ]], dtype=float32)
time = 2005	action = 0	current_phase = 0	next_phase = 1	reward = 0.449477	array([[ 1.1934836, -8.309948 ]], dtype=float32)
time = 2010	action = 0	current_phase = 0	next_phase = 1	reward = 1.021174	array([[ 0.9854562, -6.686633 ]], dtype=float32)
time = 2015	action = 0	current_phase = 0	next_phase = 1	reward = 0.724611	array([[ 1.1986277, -7.3960447]], dtype=float32)
time = 2020	action = 0	current_phase = 0	next_phase = 1	reward = 0.999218	array([[ 1.1627636, -6.9813976]], dtype=float32)
time = 2025	action = 0	current_phase = 0	next_phase = 1	reward = 0.714098	array([[ 1.288454, -7.474992]], dtype=float32)
time = 2030	action = 0	current_phase = 0	next_phase = 1	reward = 0.448188	array([[ 1.1853158, -6.7730846]], dtype=float32)
time = 2035	action = 0	current_phase = 0	next_phase = 1	reward = 0.726564	array([[ 1.1091859, -7.591037 ]], dtype=float32)
time = 2040	action = 0	current_phase = 0	next_phase = 1	reward = 0.731508	array([[ 1.2164936, -7.228425 ]], dtype=float32)
time = 2045	action = 0	current_phase = 0	next_phase = 1	reward = 1.011482	array([[ 0.91107893, -7.617941  ]], dtype=float32)
time = 2050	action = 0	current_phase = 0	next_phase = 1	reward = 0.721449	array([[ 1.4343519, -7.678344 ]], dtype=float32)
time = 2055	action = 0	current_phase = 0	next_phase = 1	reward = 0.441703	array([[ 0.9799273, -7.3086367]], dtype=float32)
time = 2060	action = 0	current_phase = 0	next_phase = 1	reward = 0.992889	array([[ 1.2942352, -6.8482723]], dtype=float32)
time = 2065	action = 0	current_phase = 0	next_phase = 1	reward = 0.724139	array([[ 1.2136257, -6.956567 ]], dtype=float32)
time = 2070	action = 0	current_phase = 0	next_phase = 1	reward = 0.717030	array([[ 1.0990045, -6.9824705]], dtype=float32)
time = 2075	action = 0	current_phase = 0	next_phase = 1	reward = 0.727146	array([[ 1.297471 , -6.9260597]], dtype=float32)
time = 2080	action = 0	current_phase = 0	next_phase = 1	reward = 0.169144	array([[ 1.3365772, -7.2761793]], dtype=float32)
time = 2085	action = 0	current_phase = 0	next_phase = 1	reward = 1.002984	array([[ 1.000468, -6.969756]], dtype=float32)
time = 2090	action = 0	current_phase = 0	next_phase = 1	reward = 1.007874	array([[ 0.9569392, -7.1696005]], dtype=float32)
time = 2095	action = 0	current_phase = 0	next_phase = 1	reward = 0.721203	array([[ 1.2235587, -6.76795  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 13.5634 - val_loss: 5.4962
Epoch 2/50
 - 4s - loss: 13.6560 - val_loss: 9.4811
Epoch 3/50
 - 4s - loss: 13.1029 - val_loss: 6.0507
Epoch 4/50
 - 4s - loss: 13.0839 - val_loss: 7.0680
Epoch 5/50
 - 4s - loss: 12.5959 - val_loss: 6.8174
Epoch 6/50
 - 4s - loss: 11.8733 - val_loss: 5.5089
Epoch 7/50
 - 4s - loss: 12.4757 - val_loss: 5.3019
Epoch 8/50
 - 4s - loss: 11.6469 - val_loss: 5.8920
Epoch 9/50
 - 4s - loss: 12.3268 - val_loss: 5.8761
Epoch 10/50
 - 4s - loss: 11.7317 - val_loss: 5.5246
Epoch 11/50
 - 4s - loss: 11.9421 - val_loss: 6.8318
Epoch 12/50
 - 4s - loss: 11.0257 - val_loss: 6.1909
Epoch 13/50
 - 4s - loss: 11.8867 - val_loss: 5.5444
Epoch 14/50
 - 4s - loss: 11.5431 - val_loss: 5.8896
Epoch 15/50
 - 4s - loss: 11.5189 - val_loss: 6.8845
Epoch 16/50
 - 4s - loss: 11.5978 - val_loss: 6.5419
Epoch 17/50
 - 4s - loss: 11.2862 - val_loss: 5.6634
length of memory (state 0, action 0): 923, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 2100	action = 0	current_phase = 0	next_phase = 1	reward = 0.728251	array([[ 1.1402819, -7.353941 ]], dtype=float32)
time = 2105	action = 0	current_phase = 0	next_phase = 1	reward = 0.720686	array([[ 1.8215182, -8.722868 ]], dtype=float32)
time = 2110	action = 0	current_phase = 0	next_phase = 1	reward = 0.437114	array([[ 0.908849, -7.058879]], dtype=float32)
time = 2115	action = 0	current_phase = 0	next_phase = 1	reward = 0.997898	array([[ 0.8948245, -7.582494 ]], dtype=float32)
time = 2120	action = 0	current_phase = 0	next_phase = 1	reward = 0.435405	array([[ 1.0442319, -7.221529 ]], dtype=float32)
time = 2125	action = 0	current_phase = 0	next_phase = 1	reward = 0.719579	array([[ 0.8256924, -7.0443697]], dtype=float32)
time = 2130	action = 0	current_phase = 0	next_phase = 1	reward = 0.727974	array([[ 0.8500142, -7.0963736]], dtype=float32)
time = 2135	action = 0	current_phase = 0	next_phase = 1	reward = 0.997438	array([[ 0.9148624, -8.003216 ]], dtype=float32)
time = 2140	action = 0	current_phase = 0	next_phase = 1	reward = 0.162187	array([[ 0.99569154, -7.583992  ]], dtype=float32)
time = 2145	action = 0	current_phase = 0	next_phase = 1	reward = 1.289825	array([[ 0.7392354, -7.8843775]], dtype=float32)
time = 2150	action = 0	current_phase = 0	next_phase = 1	reward = 0.715102	array([[ 1.1674109, -7.309725 ]], dtype=float32)
time = 2155	action = 0	current_phase = 0	next_phase = 1	reward = 0.441382	array([[ 1.0006766, -7.2388515]], dtype=float32)
time = 2160	action = 0	current_phase = 0	next_phase = 1	reward = 0.734889	array([[ 1.0268397, -8.111086 ]], dtype=float32)
time = 2165	action = 0	current_phase = 0	next_phase = 1	reward = 1.008946	array([[ 0.88904166, -7.1903715 ]], dtype=float32)
time = 2170	action = 0	current_phase = 0	next_phase = 1	reward = 0.729294	array([[ 0.9591124, -7.061305 ]], dtype=float32)
time = 2175	action = 0	current_phase = 0	next_phase = 1	reward = 0.720593	array([[ 1.180717, -7.352357]], dtype=float32)
time = 2180	action = 0	current_phase = 0	next_phase = 1	reward = 0.443224	array([[ 1.3134274, -7.8685503]], dtype=float32)
time = 2185	action = 0	current_phase = 0	next_phase = 1	reward = 0.727811	array([[ 1.4147913, -8.584507 ]], dtype=float32)
time = 2190	action = 0	current_phase = 0	next_phase = 1	reward = 0.733554	array([[ 0.9959953, -7.2243567]], dtype=float32)
time = 2195	action = 0	current_phase = 0	next_phase = 1	reward = 1.004124	array([[ 0.881722, -7.182749]], dtype=float32)
time = 2200	action = 0	current_phase = 0	next_phase = 1	reward = 0.714852	array([[ 0.78764653, -7.52897   ]], dtype=float32)
time = 2205	action = 0	current_phase = 0	next_phase = 1	reward = 0.159327	array([[ 0.79341435, -7.059205  ]], dtype=float32)
time = 2210	action = 0	current_phase = 0	next_phase = 1	reward = 1.006375	array([[-0.27481198, -7.0572233 ]], dtype=float32)
time = 2215	action = 0	current_phase = 0	next_phase = 1	reward = 1.004954	array([[ 0.96424794, -7.3991966 ]], dtype=float32)
time = 2220	action = 0	current_phase = 0	next_phase = 1	reward = 0.729665	array([[ 1.0882154, -7.241667 ]], dtype=float32)
time = 2225	action = 0	current_phase = 0	next_phase = 1	reward = 0.725117	array([[ 0.9358821, -6.905963 ]], dtype=float32)
time = 2230	action = 0	current_phase = 0	next_phase = 1	reward = 0.444710	array([[ 0.88048005, -7.0712996 ]], dtype=float32)
time = 2235	action = 0	current_phase = 0	next_phase = 1	reward = 1.001956	array([[ 0.9299176, -7.257015 ]], dtype=float32)
time = 2240	action = 0	current_phase = 0	next_phase = 1	reward = 0.717052	array([[ 1.0418711, -8.385025 ]], dtype=float32)
time = 2245	action = 0	current_phase = 0	next_phase = 1	reward = 0.440561	array([[ 0.9699116, -6.9578514]], dtype=float32)
time = 2250	action = 0	current_phase = 0	next_phase = 1	reward = 1.005010	array([[ 1.2569375, -7.603657 ]], dtype=float32)
time = 2255	action = 0	current_phase = 0	next_phase = 1	reward = 0.439727	array([[ 0.24678063, -6.6147385 ]], dtype=float32)
time = 2260	action = 0	current_phase = 0	next_phase = 1	reward = 0.997443	array([[ 0.99652314, -7.208663  ]], dtype=float32)
time = 2265	action = 0	current_phase = 0	next_phase = 1	reward = 0.726646	array([[ 1.2174954, -7.3282785]], dtype=float32)
time = 2270	action = 0	current_phase = 0	next_phase = 1	reward = 0.712443	array([[ 0.8113394, -7.138465 ]], dtype=float32)
time = 2275	action = 0	current_phase = 0	next_phase = 1	reward = 0.445724	array([[ 0.851804, -7.140498]], dtype=float32)
time = 2280	action = 0	current_phase = 0	next_phase = 1	reward = 0.998944	array([[ 0.70703745, -6.6465693 ]], dtype=float32)
time = 2285	action = 0	current_phase = 0	next_phase = 1	reward = 0.717576	array([[ 1.06459  , -7.1403694]], dtype=float32)
time = 2290	action = 0	current_phase = 0	next_phase = 1	reward = 0.711537	array([[ 0.8704784, -7.4239607]], dtype=float32)
time = 2295	action = 0	current_phase = 0	next_phase = 1	reward = 0.717592	array([[ 0.9863553, -7.007777 ]], dtype=float32)
time = 2300	action = 0	current_phase = 0	next_phase = 1	reward = 0.447292	array([[ 1.0487783, -7.412653 ]], dtype=float32)
time = 2305	action = 0	current_phase = 0	next_phase = 1	reward = 0.729769	array([[-0.2923491, -6.609275 ]], dtype=float32)
time = 2310	action = 0	current_phase = 0	next_phase = 1	reward = 1.005567	array([[ 0.6119976, -7.20374  ]], dtype=float32)
time = 2315	action = 0	current_phase = 0	next_phase = 1	reward = 0.436052	array([[ 1.3069181, -8.42613  ]], dtype=float32)
time = 2320	action = 0	current_phase = 0	next_phase = 1	reward = 0.996689	array([[ 0.9682672, -7.2514954]], dtype=float32)
time = 2325	action = 0	current_phase = 0	next_phase = 1	reward = 0.727736	array([[ 0.93429303, -7.223587  ]], dtype=float32)
time = 2330	action = 0	current_phase = 0	next_phase = 1	reward = 0.439533	array([[ 0.9840987, -6.9967146]], dtype=float32)
time = 2335	action = 0	current_phase = 0	next_phase = 1	reward = 0.732548	array([[ 0.84007263, -6.8244076 ]], dtype=float32)
time = 2340	action = 0	current_phase = 0	next_phase = 1	reward = 1.009519	array([[ 0.9939313, -7.3792   ]], dtype=float32)
time = 2345	action = 0	current_phase = 0	next_phase = 1	reward = 0.438789	array([[ 0.57780004, -6.640134  ]], dtype=float32)
time = 2350	action = 0	current_phase = 0	next_phase = 1	reward = 1.006159	array([[ 1.5540822, -7.729376 ]], dtype=float32)
time = 2355	action = 0	current_phase = 0	next_phase = 1	reward = 0.444849	array([[ 1.0957344, -7.4734974]], dtype=float32)
time = 2360	action = 0	current_phase = 0	next_phase = 1	reward = 0.997625	array([[ 0.859498, -7.31921 ]], dtype=float32)
time = 2365	action = 0	current_phase = 0	next_phase = 1	reward = 0.436205	array([[ 0.6329453, -6.8166323]], dtype=float32)
time = 2370	action = 0	current_phase = 0	next_phase = 1	reward = 0.722835	array([[ 0.6826649, -7.936777 ]], dtype=float32)
time = 2375	action = 0	current_phase = 0	next_phase = 1	reward = 0.733625	array([[ 0.90118384, -7.5551176 ]], dtype=float32)
time = 2380	action = 0	current_phase = 0	next_phase = 1	reward = 0.731628	array([[ 0.51866484, -7.9989567 ]], dtype=float32)
time = 2385	action = 0	current_phase = 0	next_phase = 1	reward = 1.007858	array([[-0.15582895, -6.7322884 ]], dtype=float32)
time = 2390	action = 0	current_phase = 0	next_phase = 1	reward = 0.721160	array([[ 1.0293047, -7.080431 ]], dtype=float32)
time = 2395	action = 0	current_phase = 0	next_phase = 1	reward = 0.720611	array([[ 0.30236483, -6.9358463 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 11.2286 - val_loss: 7.7261
Epoch 2/50
 - 4s - loss: 11.1291 - val_loss: 6.9755
Epoch 3/50
 - 4s - loss: 9.4844 - val_loss: 8.9312
Epoch 4/50
 - 4s - loss: 10.1959 - val_loss: 5.6885
Epoch 5/50
 - 4s - loss: 9.8417 - val_loss: 5.8051
Epoch 6/50
 - 4s - loss: 9.7076 - val_loss: 5.8138
Epoch 7/50
 - 4s - loss: 10.1188 - val_loss: 6.1549
Epoch 8/50
 - 4s - loss: 9.6829 - val_loss: 6.3405
Epoch 9/50
 - 4s - loss: 9.0607 - val_loss: 7.8270
Epoch 10/50
 - 4s - loss: 9.4248 - val_loss: 7.5105
Epoch 11/50
 - 4s - loss: 9.3579 - val_loss: 6.9817
Epoch 12/50
 - 4s - loss: 8.8403 - val_loss: 7.5659
Epoch 13/50
 - 4s - loss: 8.9971 - val_loss: 8.6888
Epoch 14/50
 - 4s - loss: 8.6558 - val_loss: 7.3892
length of memory (state 0, action 0): 983, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 2400	action = 0	current_phase = 0	next_phase = 1	reward = 0.723967	array([[ 1.0370858, -7.11441  ]], dtype=float32)
time = 2405	action = 0	current_phase = 0	next_phase = 1	reward = 0.438504	array([[ 1.0672939, -7.015917 ]], dtype=float32)
time = 2410	action = 0	current_phase = 0	next_phase = 1	reward = 1.006258	array([[ 1.0646203, -7.472457 ]], dtype=float32)
time = 2415	action = 0	current_phase = 0	next_phase = 1	reward = 0.724682	array([[ 0.98298335, -7.2220683 ]], dtype=float32)
time = 2420	action = 0	current_phase = 0	next_phase = 1	reward = 0.726979	array([[ 0.9775634, -7.2198877]], dtype=float32)
time = 2425	action = 0	current_phase = 0	next_phase = 1	reward = 0.445401	array([[ 0.99091315, -7.0794997 ]], dtype=float32)
time = 2430	action = 0	current_phase = 0	next_phase = 1	reward = 1.007211	array([[ 1.0447018, -7.074643 ]], dtype=float32)
time = 2435	action = 0	current_phase = 0	next_phase = 1	reward = 0.719912	array([[ 1.0616708, -7.1153955]], dtype=float32)
time = 2440	action = 0	current_phase = 0	next_phase = 1	reward = 0.720386	array([[ 1.0795527, -7.123705 ]], dtype=float32)
time = 2445	action = 0	current_phase = 0	next_phase = 1	reward = 0.438908	array([[ 1.0487764, -7.018867 ]], dtype=float32)
time = 2450	action = 0	current_phase = 0	next_phase = 1	reward = 0.998897	array([[ 1.0117769, -7.279616 ]], dtype=float32)
time = 2455	action = 0	current_phase = 0	next_phase = 1	reward = 0.449389	array([[ 0.9686613, -7.0404186]], dtype=float32)
time = 2460	action = 0	current_phase = 0	next_phase = 1	reward = 1.011201	array([[ 0.8785157, -7.2266645]], dtype=float32)
time = 2465	action = 0	current_phase = 0	next_phase = 1	reward = 0.729287	array([[ 1.0173371, -7.081193 ]], dtype=float32)
time = 2470	action = 0	current_phase = 0	next_phase = 1	reward = 0.716726	array([[ 1.051292, -7.019338]], dtype=float32)
time = 2475	action = 0	current_phase = 0	next_phase = 1	reward = 0.446812	array([[ 1.0677378, -7.068953 ]], dtype=float32)
time = 2480	action = 0	current_phase = 0	next_phase = 1	reward = 1.007150	array([[ 0.977911, -7.142471]], dtype=float32)
time = 2485	action = 0	current_phase = 0	next_phase = 1	reward = 0.717139	array([[ 1.0755022, -7.038273 ]], dtype=float32)
time = 2490	action = 0	current_phase = 0	next_phase = 1	reward = 0.726859	array([[ 1.0205419, -7.060334 ]], dtype=float32)
time = 2495	action = 0	current_phase = 0	next_phase = 1	reward = 0.719682	array([[ 1.0367064, -7.257346 ]], dtype=float32)
time = 2500	action = 0	current_phase = 0	next_phase = 1	reward = 0.444845	array([[ 1.2677996, -7.345902 ]], dtype=float32)
time = 2505	action = 0	current_phase = 0	next_phase = 1	reward = 0.997092	array([[ 0.98268366, -7.098461  ]], dtype=float32)
time = 2510	action = 0	current_phase = 0	next_phase = 1	reward = 0.437499	array([[ 0.9753156, -7.3968124]], dtype=float32)
time = 2515	action = 0	current_phase = 0	next_phase = 1	reward = 0.724893	array([[ 1.0349622, -7.186003 ]], dtype=float32)
time = 2520	action = 0	current_phase = 0	next_phase = 1	reward = 1.018990	array([[ 0.9991021, -7.121318 ]], dtype=float32)
time = 2525	action = 0	current_phase = 0	next_phase = 1	reward = 0.725351	array([[ 0.64512634, -7.0814414 ]], dtype=float32)
time = 2530	action = 0	current_phase = 0	next_phase = 1	reward = 0.444807	array([[ 0.9711902, -7.0853395]], dtype=float32)
time = 2535	action = 0	current_phase = 0	next_phase = 1	reward = 0.720124	array([[ 0.75736547, -6.9111233 ]], dtype=float32)
time = 2540	action = 0	current_phase = 0	next_phase = 1	reward = 0.720471	array([[ 0.95154  , -7.1354237]], dtype=float32)
time = 2545	action = 0	current_phase = 0	next_phase = 1	reward = 1.001309	array([[ 1.0668628, -7.1124415]], dtype=float32)
time = 2550	action = 0	current_phase = 0	next_phase = 1	reward = 0.729205	array([[ 0.9933932, -7.1929874]], dtype=float32)
time = 2555	action = 0	current_phase = 0	next_phase = 1	reward = 0.448084	array([[ 0.9849913, -7.297566 ]], dtype=float32)
time = 2560	action = 0	current_phase = 0	next_phase = 1	reward = 1.007188	array([[ 0.9066963, -7.1877084]], dtype=float32)
time = 2565	action = 0	current_phase = 0	next_phase = 1	reward = 0.714683	array([[ 1.0850487, -7.0200896]], dtype=float32)
time = 2570	action = 0	current_phase = 0	next_phase = 1	reward = 0.435610	array([[ 0.8794751, -7.0438843]], dtype=float32)
time = 2575	action = 0	current_phase = 0	next_phase = 1	reward = 0.721417	array([[ 1.1646378, -7.1805296]], dtype=float32)
time = 2580	action = 0	current_phase = 0	next_phase = 1	reward = 1.010571	array([[ 1.0441124, -7.209504 ]], dtype=float32)
time = 2585	action = 0	current_phase = 0	next_phase = 1	reward = 0.731690	array([[ 1.0566673, -7.30475  ]], dtype=float32)
time = 2590	action = 0	current_phase = 0	next_phase = 1	reward = 0.443071	array([[ 1.0265183, -7.0878096]], dtype=float32)
time = 2595	action = 0	current_phase = 0	next_phase = 1	reward = 0.731011	array([[ 0.8870399, -7.3059616]], dtype=float32)
time = 2600	action = 0	current_phase = 0	next_phase = 1	reward = 1.003125	array([[ 1.0991037, -7.040518 ]], dtype=float32)
time = 2605	action = 0	current_phase = 0	next_phase = 1	reward = 0.172193	array([[ 1.1210284, -7.223458 ]], dtype=float32)
time = 2610	action = 0	current_phase = 0	next_phase = 1	reward = 1.289396	array([[ 0.9429383, -7.1273203]], dtype=float32)
time = 2615	action = 0	current_phase = 0	next_phase = 1	reward = 0.720355	array([[ 0.828527 , -7.0813446]], dtype=float32)
time = 2620	action = 0	current_phase = 0	next_phase = 1	reward = 0.446448	array([[ 1.0299895, -7.0616913]], dtype=float32)
time = 2625	action = 0	current_phase = 0	next_phase = 1	reward = 1.007789	array([[ 0.8906448, -7.113608 ]], dtype=float32)
time = 2630	action = 0	current_phase = 0	next_phase = 1	reward = 0.442069	array([[ 1.1077604, -7.3870835]], dtype=float32)
time = 2635	action = 0	current_phase = 0	next_phase = 1	reward = 0.727940	array([[ 1.0416224, -7.03142  ]], dtype=float32)
time = 2640	action = 0	current_phase = 0	next_phase = 1	reward = 1.006854	array([[ 1.0733783, -7.0587463]], dtype=float32)
time = 2645	action = 0	current_phase = 0	next_phase = 1	reward = 0.726209	array([[ 1.0561998, -7.0653715]], dtype=float32)
time = 2650	action = 0	current_phase = 0	next_phase = 1	reward = 0.732273	array([[ 0.89105487, -6.9901047 ]], dtype=float32)
time = 2655	action = 0	current_phase = 0	next_phase = 1	reward = 0.711585	array([[ 1.0190053, -7.5053635]], dtype=float32)
time = 2660	action = 0	current_phase = 0	next_phase = 1	reward = 0.448150	array([[ 1.074502 , -7.0272837]], dtype=float32)
time = 2665	action = 0	current_phase = 0	next_phase = 1	reward = 1.006930	array([[ 1.1649296, -7.3496428]], dtype=float32)
time = 2670	action = 0	current_phase = 0	next_phase = 1	reward = 0.724220	array([[ 0.9423325, -7.0499973]], dtype=float32)
time = 2675	action = 0	current_phase = 0	next_phase = 1	reward = 0.725586	array([[ 1.0408278, -7.1294765]], dtype=float32)
time = 2680	action = 0	current_phase = 0	next_phase = 1	reward = 0.438886	array([[ 0.76298857, -6.874708  ]], dtype=float32)
time = 2685	action = 0	current_phase = 0	next_phase = 1	reward = 0.996254	array([[ 1.1813982, -7.3484035]], dtype=float32)
time = 2690	action = 0	current_phase = 0	next_phase = 1	reward = 0.160041	array([[ 0.98645663, -7.1636934 ]], dtype=float32)
time = 2695	action = 0	current_phase = 0	next_phase = 1	reward = 1.006356	array([[ 0.78407073, -6.903468  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 10.1043 - val_loss: 9.2884
Epoch 2/50
 - 4s - loss: 9.9214 - val_loss: 8.7558
Epoch 3/50
 - 4s - loss: 9.7559 - val_loss: 8.1745
Epoch 4/50
 - 4s - loss: 10.5169 - val_loss: 9.8147
Epoch 5/50
 - 5s - loss: 9.6823 - val_loss: 7.8741
Epoch 6/50
 - 4s - loss: 8.8387 - val_loss: 8.4380
Epoch 7/50
 - 4s - loss: 9.5602 - val_loss: 8.7833
Epoch 8/50
 - 4s - loss: 9.4460 - val_loss: 9.1408
Epoch 9/50
 - 4s - loss: 9.9734 - val_loss: 9.8230
Epoch 10/50
 - 3s - loss: 8.8959 - val_loss: 7.7462
Epoch 11/50
 - 4s - loss: 9.0118 - val_loss: 8.7843
Epoch 12/50
 - 4s - loss: 8.7129 - val_loss: 7.7701
Epoch 13/50
 - 6s - loss: 8.6599 - val_loss: 8.5697
Epoch 14/50
 - 6s - loss: 8.8257 - val_loss: 8.3034
Epoch 15/50
 - 4s - loss: 10.4657 - val_loss: 8.0472
Epoch 16/50
 - 5s - loss: 9.7242 - val_loss: 8.4840
Epoch 17/50
 - 4s - loss: 8.9498 - val_loss: 8.0909
Epoch 18/50
 - 4s - loss: 8.7397 - val_loss: 7.5957
Epoch 19/50
 - 4s - loss: 8.3421 - val_loss: 7.9476
Epoch 20/50
 - 4s - loss: 8.6210 - val_loss: 7.8188
Epoch 21/50
 - 4s - loss: 8.3616 - val_loss: 8.3142
Epoch 22/50
 - 4s - loss: 8.6336 - val_loss: 8.0909
Epoch 23/50
 - 5s - loss: 8.5829 - val_loss: 7.6906
Epoch 24/50
 - 5s - loss: 8.9621 - val_loss: 8.3896
Epoch 25/50
 - 4s - loss: 8.0134 - val_loss: 7.6248
Epoch 26/50
 - 4s - loss: 8.0434 - val_loss: 7.5314
Epoch 27/50
 - 4s - loss: 8.4459 - val_loss: 7.4947
Epoch 28/50
 - 4s - loss: 8.3145 - val_loss: 7.9668
Epoch 29/50
 - 5s - loss: 8.2086 - val_loss: 8.1010
Epoch 30/50
 - 6s - loss: 8.4105 - val_loss: 7.6865
Epoch 31/50
 - 5s - loss: 7.5793 - val_loss: 7.6567
Epoch 32/50
 - 4s - loss: 8.0790 - val_loss: 7.8424
Epoch 33/50
 - 4s - loss: 8.5712 - val_loss: 6.8978
Epoch 34/50
 - 5s - loss: 7.7252 - val_loss: 8.4327
Epoch 35/50
 - 4s - loss: 8.0910 - val_loss: 7.4849
Epoch 36/50
 - 4s - loss: 9.1693 - val_loss: 7.8112
Epoch 37/50
 - 4s - loss: 8.3019 - val_loss: 8.8221
Epoch 38/50
 - 4s - loss: 7.5834 - val_loss: 8.5612
Epoch 39/50
 - 4s - loss: 7.5139 - val_loss: 8.6233
Epoch 40/50
 - 4s - loss: 8.0208 - val_loss: 8.9873
Epoch 41/50
 - 4s - loss: 8.9692 - val_loss: 7.9839
Epoch 42/50
 - 4s - loss: 7.7633 - val_loss: 8.2605
Epoch 43/50
 - 4s - loss: 7.0679 - val_loss: 9.0886
length of memory (state 0, action 0): 1043, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 2700	action = 0	current_phase = 0	next_phase = 1	reward = 0.723003	array([[ 1.0803888, -7.416013 ]], dtype=float32)
time = 2705	action = 0	current_phase = 0	next_phase = 1	reward = 0.716506	array([[ 0.857497, -7.766266]], dtype=float32)
time = 2710	action = 0	current_phase = 0	next_phase = 1	reward = 0.454466	array([[ 0.9982953, -7.188698 ]], dtype=float32)
time = 2715	action = 0	current_phase = 0	next_phase = 1	reward = 1.016120	array([[ 0.90507865, -7.3552094 ]], dtype=float32)
time = 2720	action = 0	current_phase = 0	next_phase = 1	reward = 1.005606	array([[ 1.1101475, -7.2102203]], dtype=float32)
time = 2725	action = 0	current_phase = 0	next_phase = 1	reward = 0.717613	array([[ 1.1758497, -7.2194805]], dtype=float32)
time = 2730	action = 0	current_phase = 0	next_phase = 1	reward = 0.712102	array([[ 1.1614432, -7.158083 ]], dtype=float32)
time = 2735	action = 0	current_phase = 0	next_phase = 1	reward = 0.718333	array([[ 1.1549549, -7.1947546]], dtype=float32)
time = 2740	action = 0	current_phase = 0	next_phase = 1	reward = 0.710771	array([[ 1.1322517, -7.296386 ]], dtype=float32)
time = 2745	action = 0	current_phase = 0	next_phase = 1	reward = 0.167520	array([[ 0.6948006, -6.931381 ]], dtype=float32)
time = 2750	action = 0	current_phase = 0	next_phase = 1	reward = 1.014588	array([[ 0.996639 , -7.1517105]], dtype=float32)
time = 2755	action = 0	current_phase = 0	next_phase = 1	reward = 1.009639	array([[ 1.1575708, -7.4048967]], dtype=float32)
time = 2760	action = 0	current_phase = 0	next_phase = 1	reward = 0.716164	array([[ 1.2456822, -7.280247 ]], dtype=float32)
time = 2765	action = 0	current_phase = 0	next_phase = 1	reward = 0.714407	array([[ 1.1539083, -7.1129093]], dtype=float32)
time = 2770	action = 0	current_phase = 0	next_phase = 1	reward = 0.717763	array([[ 1.1171939, -7.208791 ]], dtype=float32)
time = 2775	action = 0	current_phase = 0	next_phase = 1	reward = 0.436546	array([[ 1.0428913, -7.406493 ]], dtype=float32)
time = 2780	action = 0	current_phase = 0	next_phase = 1	reward = 0.450465	array([[ 1.1332493, -7.246533 ]], dtype=float32)
time = 2785	action = 0	current_phase = 0	next_phase = 1	reward = 1.016562	array([[ 1.1474421, -7.1447144]], dtype=float32)
time = 2790	action = 0	current_phase = 0	next_phase = 1	reward = 1.008696	array([[ 0.9646864, -8.19711  ]], dtype=float32)
time = 2795	action = 0	current_phase = 0	next_phase = 1	reward = 0.730402	array([[ 1.355192, -7.460355]], dtype=float32)
time = 2800	action = 0	current_phase = 0	next_phase = 1	reward = 0.719574	array([[ 1.0811977, -7.191842 ]], dtype=float32)
time = 2805	action = 0	current_phase = 0	next_phase = 1	reward = 0.707821	array([[ 1.1676147, -7.1976976]], dtype=float32)
time = 2810	action = 0	current_phase = 0	next_phase = 1	reward = 0.155041	array([[ 1.1456907, -7.1221538]], dtype=float32)
time = 2815	action = 0	current_phase = 0	next_phase = 1	reward = 1.290054	array([[ 1.1071858, -7.4448442]], dtype=float32)
time = 2820	action = 0	current_phase = 0	next_phase = 1	reward = 0.446094	array([[ 1.1637933, -7.193024 ]], dtype=float32)
time = 2825	action = 0	current_phase = 0	next_phase = 1	reward = 1.007088	array([[ 1.157799, -7.459984]], dtype=float32)
time = 2830	action = 0	current_phase = 0	next_phase = 1	reward = 0.728535	array([[ 1.1511457, -7.201618 ]], dtype=float32)
time = 2835	action = 0	current_phase = 0	next_phase = 1	reward = 0.727176	array([[ 1.0665197, -7.2007074]], dtype=float32)
time = 2840	action = 0	current_phase = 0	next_phase = 1	reward = 0.724849	array([[ 1.1333926, -7.2122116]], dtype=float32)
time = 2845	action = 0	current_phase = 0	next_phase = 1	reward = 0.716902	array([[ 1.1700027, -7.2409134]], dtype=float32)
time = 2850	action = 0	current_phase = 0	next_phase = 1	reward = 0.717968	array([[ 1.1493475, -7.138756 ]], dtype=float32)
time = 2855	action = 0	current_phase = 0	next_phase = 1	reward = 0.724083	array([[ 1.1266675, -7.274824 ]], dtype=float32)
time = 2860	action = 0	current_phase = 0	next_phase = 1	reward = 0.450729	array([[ 1.21786  , -7.3115673]], dtype=float32)
time = 2865	action = 0	current_phase = 0	next_phase = 1	reward = 1.003382	array([[ 1.062912 , -7.3371773]], dtype=float32)
time = 2870	action = 0	current_phase = 0	next_phase = 1	reward = 0.718173	array([[ 1.1674027, -7.153106 ]], dtype=float32)
time = 2875	action = 0	current_phase = 0	next_phase = 1	reward = 0.723482	array([[ 1.4311569, -7.8074284]], dtype=float32)
time = 2880	action = 0	current_phase = 0	next_phase = 1	reward = 0.716447	array([[ 1.1515486, -7.170857 ]], dtype=float32)
time = 2885	action = 0	current_phase = 0	next_phase = 1	reward = 0.445286	array([[ 1.1371639, -7.1384525]], dtype=float32)
time = 2890	action = 0	current_phase = 0	next_phase = 1	reward = 1.003212	array([[ 1.1649497, -7.2771115]], dtype=float32)
time = 2895	action = 0	current_phase = 0	next_phase = 1	reward = 0.446856	array([[ 1.0995541, -7.32576  ]], dtype=float32)
time = 2900	action = 0	current_phase = 0	next_phase = 1	reward = 1.010468	array([[ 1.1265838, -7.1694593]], dtype=float32)
time = 2905	action = 0	current_phase = 0	next_phase = 1	reward = 0.448661	array([[ 1.1258116, -7.247265 ]], dtype=float32)
time = 2910	action = 0	current_phase = 0	next_phase = 1	reward = 0.732490	array([[ 1.1254284, -7.215511 ]], dtype=float32)
time = 2915	action = 0	current_phase = 0	next_phase = 1	reward = 1.005890	array([[ 1.267   , -7.411005]], dtype=float32)
time = 2920	action = 0	current_phase = 0	next_phase = 1	reward = 0.707737	array([[ 1.1672089, -7.165059 ]], dtype=float32)
time = 2925	action = 0	current_phase = 0	next_phase = 1	reward = 0.715917	array([[ 1.0577953, -7.386239 ]], dtype=float32)
time = 2930	action = 0	current_phase = 0	next_phase = 1	reward = 0.725335	array([[ 1.1400542, -7.4782057]], dtype=float32)
time = 2935	action = 0	current_phase = 0	next_phase = 1	reward = 0.448956	array([[ 1.3077803, -7.293806 ]], dtype=float32)
time = 2940	action = 0	current_phase = 0	next_phase = 1	reward = 0.717018	array([[ 1.0805938, -7.140047 ]], dtype=float32)
time = 2945	action = 0	current_phase = 0	next_phase = 1	reward = 1.001432	array([[ 1.0655978, -7.3589125]], dtype=float32)
time = 2950	action = 0	current_phase = 0	next_phase = 1	reward = 0.725192	array([[ 1.2804554, -7.2848616]], dtype=float32)
time = 2955	action = 0	current_phase = 0	next_phase = 1	reward = 0.723636	array([[ 1.1499507, -7.1728115]], dtype=float32)
time = 2960	action = 0	current_phase = 0	next_phase = 1	reward = 0.717552	array([[ 1.1225383, -7.305397 ]], dtype=float32)
time = 2965	action = 0	current_phase = 0	next_phase = 1	reward = 0.441128	array([[ 1.0577321, -7.100833 ]], dtype=float32)
time = 2970	action = 0	current_phase = 0	next_phase = 1	reward = 0.730409	array([[ 2.3667777, -8.58528  ]], dtype=float32)
time = 2975	action = 0	current_phase = 0	next_phase = 1	reward = 1.001108	array([[  2.970309, -10.659836]], dtype=float32)
time = 2980	action = 0	current_phase = 0	next_phase = 1	reward = 0.719488	array([[ 1.1155424, -7.1826777]], dtype=float32)
time = 2985	action = 0	current_phase = 0	next_phase = 1	reward = 0.717473	array([[ 1.1232364, -7.210038 ]], dtype=float32)
time = 2990	action = 0	current_phase = 0	next_phase = 1	reward = 0.712602	array([[ 1.1244576, -7.1633472]], dtype=float32)
time = 2995	action = 0	current_phase = 0	next_phase = 1	reward = 0.717561	array([[ 0.90776205, -7.4544964 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 3s - loss: 9.3141 - val_loss: 6.5861
Epoch 2/50
 - 4s - loss: 9.2695 - val_loss: 7.9976
Epoch 3/50
 - 4s - loss: 9.1501 - val_loss: 7.3698
Epoch 4/50
 - 4s - loss: 8.6149 - val_loss: 7.4466
Epoch 5/50
 - 4s - loss: 9.2424 - val_loss: 7.1290
Epoch 6/50
 - 4s - loss: 8.8809 - val_loss: 6.7148
Epoch 7/50
 - 4s - loss: 8.3834 - val_loss: 6.3713
Epoch 8/50
 - 4s - loss: 9.3033 - val_loss: 6.6090
Epoch 9/50
 - 4s - loss: 8.3079 - val_loss: 6.8943
Epoch 10/50
 - 4s - loss: 8.1956 - val_loss: 6.8226
Epoch 11/50
 - 4s - loss: 9.1516 - val_loss: 6.4343
Epoch 12/50
 - 4s - loss: 7.6145 - val_loss: 6.3991
Epoch 13/50
 - 4s - loss: 8.5178 - val_loss: 5.8226
Epoch 14/50
 - 4s - loss: 8.8482 - val_loss: 5.5701
Epoch 15/50
 - 4s - loss: 8.1672 - val_loss: 6.2995
Epoch 16/50
 - 4s - loss: 7.5849 - val_loss: 6.6591
Epoch 17/50
 - 4s - loss: 7.3435 - val_loss: 6.7656
Epoch 18/50
 - 4s - loss: 7.6882 - val_loss: 6.8896
Epoch 19/50
 - 4s - loss: 7.6561 - val_loss: 6.2272
Epoch 20/50
 - 4s - loss: 7.8868 - val_loss: 5.2367
Epoch 21/50
 - 4s - loss: 8.0553 - val_loss: 5.8049
Epoch 22/50
 - 4s - loss: 8.1016 - val_loss: 5.5827
Epoch 23/50
 - 4s - loss: 7.6939 - val_loss: 6.4236
Epoch 24/50
 - 4s - loss: 7.4593 - val_loss: 5.6261
Epoch 25/50
 - 4s - loss: 8.5379 - val_loss: 6.2169
Epoch 26/50
 - 4s - loss: 7.8813 - val_loss: 6.6404
Epoch 27/50
 - 4s - loss: 7.1545 - val_loss: 6.3436
Epoch 28/50
 - 4s - loss: 7.4777 - val_loss: 6.4007
Epoch 29/50
 - 4s - loss: 8.0969 - val_loss: 6.1356
Epoch 30/50
 - 4s - loss: 7.7193 - val_loss: 7.4356
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 3000	action = 0	current_phase = 0	next_phase = 1	reward = 0.445798	array([[ 1.1344492, -7.2377057]], dtype=float32)
time = 3005	action = 0	current_phase = 0	next_phase = 1	reward = 0.738284	array([[ 1.0574303, -7.2456455]], dtype=float32)
time = 3010	action = 0	current_phase = 0	next_phase = 1	reward = 1.021664	array([[ 1.1615744, -7.2829447]], dtype=float32)
time = 3015	action = 0	current_phase = 0	next_phase = 1	reward = 0.731452	array([[ 1.1320131, -7.3049345]], dtype=float32)
time = 3020	action = 0	current_phase = 0	next_phase = 1	reward = 0.723149	array([[ 1.1407344, -7.2359686]], dtype=float32)
time = 3025	action = 0	current_phase = 0	next_phase = 1	reward = 0.721549	array([[ 1.1856484, -7.281508 ]], dtype=float32)
time = 3030	action = 0	current_phase = 0	next_phase = 1	reward = 0.450394	array([[ 1.3404922, -7.4714875]], dtype=float32)
time = 3035	action = 0	current_phase = 0	next_phase = 1	reward = 1.002899	array([[ 1.1334782, -7.213497 ]], dtype=float32)
time = 3040	action = 0	current_phase = 0	next_phase = 1	reward = 0.720291	array([[ 1.2366853, -7.565434 ]], dtype=float32)
time = 3045	action = 0	current_phase = 0	next_phase = 1	reward = 0.441734	array([[ 1.0964148, -7.300292 ]], dtype=float32)
time = 3050	action = 0	current_phase = 0	next_phase = 1	reward = 0.720866	array([[ 1.1135418, -7.2515507]], dtype=float32)
time = 3055	action = 0	current_phase = 0	next_phase = 1	reward = 0.721401	array([[ 1.3370752, -7.552899 ]], dtype=float32)
time = 3060	action = 0	current_phase = 0	next_phase = 1	reward = 0.725589	array([[ 1.1071718, -7.4195614]], dtype=float32)
time = 3065	action = 0	current_phase = 0	next_phase = 1	reward = 0.723136	array([[ 1.1346307, -7.2354517]], dtype=float32)
time = 3070	action = 0	current_phase = 0	next_phase = 1	reward = 0.997683	array([[ 1.1772707, -7.4222136]], dtype=float32)
time = 3075	action = 0	current_phase = 0	next_phase = 1	reward = 0.439196	array([[ 1.106632 , -7.3283405]], dtype=float32)
time = 3080	action = 0	current_phase = 0	next_phase = 1	reward = 0.729345	array([[ 1.0788083, -7.3007593]], dtype=float32)
time = 3085	action = 0	current_phase = 0	next_phase = 1	reward = 0.725953	array([[ 1.0756314, -7.298066 ]], dtype=float32)
time = 3090	action = 0	current_phase = 0	next_phase = 1	reward = 1.006182	array([[ 1.0996816, -7.464684 ]], dtype=float32)
time = 3095	action = 0	current_phase = 0	next_phase = 1	reward = 0.720283	array([[ 1.3655572, -7.612712 ]], dtype=float32)
time = 3100	action = 0	current_phase = 0	next_phase = 1	reward = 0.723834	array([[ 1.2416494, -7.459501 ]], dtype=float32)
time = 3105	action = 0	current_phase = 0	next_phase = 1	reward = 0.722443	array([[ 1.1235156, -7.332773 ]], dtype=float32)
time = 3110	action = 0	current_phase = 0	next_phase = 1	reward = 0.714056	array([[ 1.1856213, -7.311729 ]], dtype=float32)
time = 3115	action = 0	current_phase = 0	next_phase = 1	reward = 0.715923	array([[ 1.134372 , -7.2858067]], dtype=float32)
time = 3120	action = 0	current_phase = 0	next_phase = 1	reward = 0.721141	array([[ 0.72890306, -7.1234226 ]], dtype=float32)
time = 3125	action = 0	current_phase = 0	next_phase = 1	reward = 0.721640	array([[ 1.0830879, -7.286977 ]], dtype=float32)
time = 3130	action = 0	current_phase = 0	next_phase = 1	reward = 0.719332	array([[ 1.1445084, -7.2300453]], dtype=float32)
time = 3135	action = 0	current_phase = 0	next_phase = 1	reward = 0.444403	array([[ 1.1475017, -7.256279 ]], dtype=float32)
time = 3140	action = 0	current_phase = 0	next_phase = 1	reward = 0.447438	array([[ 1.2087173, -7.510965 ]], dtype=float32)
time = 3145	action = 0	current_phase = 0	next_phase = 1	reward = 1.283478	array([[ 1.1006505, -7.3274527]], dtype=float32)
time = 3150	action = 0	current_phase = 0	next_phase = 1	reward = 0.719153	array([[ 1.1562581, -7.409671 ]], dtype=float32)
time = 3155	action = 0	current_phase = 0	next_phase = 1	reward = 0.447253	array([[ 1.1135538, -7.299615 ]], dtype=float32)
time = 3160	action = 0	current_phase = 0	next_phase = 1	reward = 0.723902	array([[ 1.1681442, -7.3747606]], dtype=float32)
time = 3165	action = 0	current_phase = 0	next_phase = 1	reward = 0.722374	array([[ 1.1255751, -7.3991075]], dtype=float32)
time = 3170	action = 0	current_phase = 0	next_phase = 1	reward = 0.714793	array([[ 1.1816916, -7.4939785]], dtype=float32)
time = 3175	action = 0	current_phase = 0	next_phase = 1	reward = 0.725605	array([[ 1.0999761, -7.2737045]], dtype=float32)
time = 3180	action = 0	current_phase = 0	next_phase = 1	reward = 1.008883	array([[ 1.2055538, -7.425548 ]], dtype=float32)
time = 3185	action = 0	current_phase = 0	next_phase = 1	reward = 0.726955	array([[ 0.7423353, -6.9707527]], dtype=float32)
time = 3190	action = 0	current_phase = 0	next_phase = 1	reward = 0.720382	array([[ 0.7980323, -7.062034 ]], dtype=float32)
time = 3195	action = 0	current_phase = 0	next_phase = 1	reward = 0.723779	array([[ 1.12426 , -7.250886]], dtype=float32)
time = 3200	action = 0	current_phase = 0	next_phase = 1	reward = 0.710395	array([[ 1.1902537, -7.3636875]], dtype=float32)
time = 3205	action = 0	current_phase = 0	next_phase = 1	reward = 0.726390	array([[ 1.141309, -7.296475]], dtype=float32)
time = 3210	action = 0	current_phase = 0	next_phase = 1	reward = 0.443375	array([[ 1.1405795, -7.2243767]], dtype=float32)
time = 3215	action = 0	current_phase = 0	next_phase = 1	reward = 1.006430	array([[ 1.1114063, -7.300085 ]], dtype=float32)
time = 3220	action = 0	current_phase = 0	next_phase = 1	reward = 0.725577	array([[ 1.2579641, -7.4182754]], dtype=float32)
time = 3225	action = 0	current_phase = 0	next_phase = 1	reward = 0.719555	array([[ 1.2206504, -7.382992 ]], dtype=float32)
time = 3230	action = 0	current_phase = 0	next_phase = 1	reward = 0.446544	array([[ 1.1769607, -7.296706 ]], dtype=float32)
time = 3235	action = 0	current_phase = 0	next_phase = 1	reward = 0.735404	array([[ 1.2930589, -7.432027 ]], dtype=float32)
time = 3240	action = 0	current_phase = 0	next_phase = 1	reward = 1.005093	array([[ 1.1157808, -7.256923 ]], dtype=float32)
time = 3245	action = 0	current_phase = 0	next_phase = 1	reward = 0.713618	array([[ 1.1264844, -7.287233 ]], dtype=float32)
time = 3250	action = 0	current_phase = 0	next_phase = 1	reward = 0.443305	array([[ 0.8465977, -7.0646577]], dtype=float32)
time = 3255	action = 0	current_phase = 0	next_phase = 1	reward = 0.722648	array([[ 1.1328564, -7.25673  ]], dtype=float32)
time = 3260	action = 0	current_phase = 0	next_phase = 1	reward = 0.998300	array([[ 1.1157496, -7.2948494]], dtype=float32)
time = 3265	action = 0	current_phase = 0	next_phase = 1	reward = 0.436471	array([[ 1.0544734, -7.485032 ]], dtype=float32)
time = 3270	action = 0	current_phase = 0	next_phase = 1	reward = 1.003466	array([[ 1.1092672, -7.2469845]], dtype=float32)
time = 3275	action = 0	current_phase = 0	next_phase = 1	reward = 0.720529	array([[ 1.1652026, -7.3304987]], dtype=float32)
time = 3280	action = 0	current_phase = 0	next_phase = 1	reward = 0.722394	array([[ 1.1348143, -7.3056226]], dtype=float32)
time = 3285	action = 0	current_phase = 0	next_phase = 1	reward = 0.450152	array([[ 1.1618729, -7.255979 ]], dtype=float32)
time = 3290	action = 0	current_phase = 0	next_phase = 1	reward = 0.732941	array([[ 1.1275041, -7.2873554]], dtype=float32)
time = 3295	action = 0	current_phase = 0	next_phase = 1	reward = 0.718509	array([[ 1.1600833, -7.353157 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 14.1922 - val_loss: 10.5888
Epoch 2/50
 - 4s - loss: 12.9464 - val_loss: 13.2618
Epoch 3/50
 - 4s - loss: 11.9410 - val_loss: 8.2843
Epoch 4/50
 - 4s - loss: 11.9091 - val_loss: 8.8422
Epoch 5/50
 - 4s - loss: 12.3965 - val_loss: 10.3727
Epoch 6/50
 - 4s - loss: 11.5275 - val_loss: 12.3252
Epoch 7/50
 - 4s - loss: 12.7601 - val_loss: 8.2127
Epoch 8/50
 - 4s - loss: 11.9155 - val_loss: 9.5403
Epoch 9/50
 - 4s - loss: 11.2281 - val_loss: 10.4969
Epoch 10/50
 - 4s - loss: 11.0111 - val_loss: 9.9412
Epoch 11/50
 - 4s - loss: 10.8120 - val_loss: 8.0260
Epoch 12/50
 - 4s - loss: 10.7702 - val_loss: 9.5745
Epoch 13/50
 - 4s - loss: 10.9508 - val_loss: 12.1411
Epoch 14/50
 - 4s - loss: 10.7045 - val_loss: 8.8005
Epoch 15/50
 - 4s - loss: 11.1173 - val_loss: 9.4281
Epoch 16/50
 - 4s - loss: 10.8623 - val_loss: 8.6446
Epoch 17/50
 - 4s - loss: 10.5935 - val_loss: 7.4620
Epoch 18/50
 - 4s - loss: 10.7293 - val_loss: 9.3439
Epoch 19/50
 - 4s - loss: 10.5996 - val_loss: 8.0434
Epoch 20/50
 - 4s - loss: 10.8134 - val_loss: 7.9262
Epoch 21/50
 - 4s - loss: 10.4605 - val_loss: 7.9287
Epoch 22/50
 - 4s - loss: 10.4787 - val_loss: 7.8326
Epoch 23/50
 - 4s - loss: 9.7600 - val_loss: 11.4196
Epoch 24/50
 - 4s - loss: 9.9625 - val_loss: 7.6527
Epoch 25/50
 - 4s - loss: 10.6542 - val_loss: 11.0097
Epoch 26/50
 - 4s - loss: 11.3787 - val_loss: 8.2283
Epoch 27/50
 - 4s - loss: 9.5304 - val_loss: 8.8764
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 3300	action = 0	current_phase = 0	next_phase = 1	reward = 1.004059	array([[ 1.443815, -7.682976]], dtype=float32)
time = 3305	action = 0	current_phase = 0	next_phase = 1	reward = 0.449104	array([[ 1.4738715, -7.3000774]], dtype=float32)
time = 3310	action = 0	current_phase = 0	next_phase = 1	reward = 1.005124	array([[ 1.4870989, -7.3931565]], dtype=float32)
time = 3315	action = 0	current_phase = 0	next_phase = 1	reward = 0.721501	array([[ 1.4852273, -7.342428 ]], dtype=float32)
time = 3320	action = 0	current_phase = 0	next_phase = 1	reward = 0.724117	array([[ 1.480963 , -7.3083143]], dtype=float32)
time = 3325	action = 0	current_phase = 0	next_phase = 1	reward = 0.443751	array([[ 1.5028837, -7.3130693]], dtype=float32)
time = 3330	action = 0	current_phase = 0	next_phase = 1	reward = 1.000504	array([[ 1.5265634, -7.546317 ]], dtype=float32)
time = 3335	action = 0	current_phase = 0	next_phase = 1	reward = 0.717900	array([[ 1.437587, -7.267125]], dtype=float32)
time = 3340	action = 0	current_phase = 0	next_phase = 1	reward = 0.722889	array([[ 1.5355346, -7.443711 ]], dtype=float32)
time = 3345	action = 0	current_phase = 0	next_phase = 1	reward = 0.447681	array([[ 1.5061581, -7.309509 ]], dtype=float32)
time = 3350	action = 0	current_phase = 0	next_phase = 1	reward = 0.727137	array([[ 1.4891708, -7.2739916]], dtype=float32)
time = 3355	action = 0	current_phase = 0	next_phase = 1	reward = 1.002852	array([[ 1.5134017, -7.4749947]], dtype=float32)
time = 3360	action = 0	current_phase = 0	next_phase = 1	reward = 0.720103	array([[ 1.5080817, -7.4197154]], dtype=float32)
time = 3365	action = 0	current_phase = 0	next_phase = 1	reward = 0.719953	array([[ 1.808233, -7.747472]], dtype=float32)
time = 3370	action = 0	current_phase = 0	next_phase = 1	reward = 0.728375	array([[ 1.4873774, -7.319317 ]], dtype=float32)
time = 3375	action = 0	current_phase = 0	next_phase = 1	reward = 0.724662	array([[ 1.5518811, -7.3483124]], dtype=float32)
time = 3380	action = 0	current_phase = 0	next_phase = 1	reward = 0.440937	array([[ 1.4358366, -7.25842  ]], dtype=float32)
time = 3385	action = 0	current_phase = 0	next_phase = 1	reward = 1.000876	array([[ 1.4778273, -7.3821106]], dtype=float32)
time = 3390	action = 0	current_phase = 0	next_phase = 1	reward = 0.443642	array([[ 1.503804, -7.391755]], dtype=float32)
time = 3395	action = 0	current_phase = 0	next_phase = 1	reward = 0.730766	array([[ 1.5274765, -7.3027763]], dtype=float32)
time = 3400	action = 0	current_phase = 0	next_phase = 1	reward = 1.019250	array([[ 1.4453518, -7.262425 ]], dtype=float32)
time = 3405	action = 0	current_phase = 0	next_phase = 1	reward = 0.728541	array([[ 1.5725582, -7.4154263]], dtype=float32)
time = 3410	action = 0	current_phase = 0	next_phase = 1	reward = 0.717355	array([[ 1.5091188, -7.2966275]], dtype=float32)
time = 3415	action = 0	current_phase = 0	next_phase = 1	reward = 0.438961	array([[ 1.5226557, -7.404808 ]], dtype=float32)
time = 3420	action = 0	current_phase = 0	next_phase = 1	reward = 0.724039	array([[ 1.5506523, -7.3882046]], dtype=float32)
time = 3425	action = 0	current_phase = 0	next_phase = 1	reward = 0.732073	array([[ 1.5287368, -7.3070536]], dtype=float32)
time = 3430	action = 0	current_phase = 0	next_phase = 1	reward = 1.009167	array([[ 1.4206636, -7.6017513]], dtype=float32)
time = 3435	action = 0	current_phase = 0	next_phase = 1	reward = 0.714526	array([[ 1.4548261, -7.281893 ]], dtype=float32)
time = 3440	action = 0	current_phase = 0	next_phase = 1	reward = 0.433192	array([[ 1.498224, -7.292427]], dtype=float32)
time = 3445	action = 0	current_phase = 0	next_phase = 1	reward = 0.996502	array([[ 1.3672912, -7.359494 ]], dtype=float32)
time = 3450	action = 0	current_phase = 0	next_phase = 1	reward = 0.441540	array([[ 1.4998052, -7.403549 ]], dtype=float32)
time = 3455	action = 0	current_phase = 0	next_phase = 1	reward = 0.452221	array([[ 1.6089785, -7.4952393]], dtype=float32)
time = 3460	action = 0	current_phase = 0	next_phase = 1	reward = 1.291927	array([[ 1.46188  , -7.4944654]], dtype=float32)
time = 3465	action = 0	current_phase = 0	next_phase = 1	reward = 0.718808	array([[ 1.535505, -7.352475]], dtype=float32)
time = 3470	action = 0	current_phase = 0	next_phase = 1	reward = 0.727124	array([[ 1.5336168, -7.3575726]], dtype=float32)
time = 3475	action = 0	current_phase = 0	next_phase = 1	reward = 0.728285	array([[ 1.5407345, -7.6666307]], dtype=float32)
time = 3480	action = 0	current_phase = 0	next_phase = 1	reward = 0.720036	array([[ 1.5551889, -7.4639034]], dtype=float32)
time = 3485	action = 0	current_phase = 0	next_phase = 1	reward = 0.444941	array([[ 1.549309 , -7.3053093]], dtype=float32)
time = 3490	action = 0	current_phase = 0	next_phase = 1	reward = 1.004678	array([[ 1.4161646, -7.423214 ]], dtype=float32)
time = 3495	action = 0	current_phase = 0	next_phase = 1	reward = 0.445585	array([[ 1.6933029, -7.5931625]], dtype=float32)
time = 3500	action = 0	current_phase = 0	next_phase = 1	reward = 0.744881	array([[ 1.5628793, -7.4825125]], dtype=float32)
time = 3505	action = 0	current_phase = 0	next_phase = 1	reward = 1.010764	array([[ 1.6662595, -7.594035 ]], dtype=float32)
time = 3510	action = 0	current_phase = 0	next_phase = 1	reward = 0.726869	array([[ 1.5410779, -7.2993326]], dtype=float32)
time = 3515	action = 0	current_phase = 0	next_phase = 1	reward = 0.723593	array([[ 1.5288794, -7.307393 ]], dtype=float32)
time = 3520	action = 0	current_phase = 0	next_phase = 1	reward = 0.724457	array([[ 1.4981554, -7.3270187]], dtype=float32)
time = 3525	action = 0	current_phase = 0	next_phase = 1	reward = 0.721092	array([[ 1.5430315, -7.358326 ]], dtype=float32)
time = 3530	action = 0	current_phase = 0	next_phase = 1	reward = 0.443316	array([[ 1.6675174, -7.5360146]], dtype=float32)
time = 3535	action = 0	current_phase = 0	next_phase = 1	reward = 1.008413	array([[ 1.5020745, -7.360297 ]], dtype=float32)
time = 3540	action = 0	current_phase = 0	next_phase = 1	reward = 0.719443	array([[ 1.5343826, -7.3167357]], dtype=float32)
time = 3545	action = 0	current_phase = 0	next_phase = 1	reward = 0.720898	array([[ 1.5503709, -7.4708786]], dtype=float32)
time = 3550	action = 0	current_phase = 0	next_phase = 1	reward = 0.724944	array([[ 1.5500853, -7.322838 ]], dtype=float32)
time = 3555	action = 0	current_phase = 0	next_phase = 1	reward = 0.446498	array([[ 1.3126304, -7.27363  ]], dtype=float32)
time = 3560	action = 0	current_phase = 0	next_phase = 1	reward = 0.729352	array([[ 1.6005313, -7.5513926]], dtype=float32)
time = 3565	action = 0	current_phase = 0	next_phase = 1	reward = 0.733473	array([[ 1.5215757, -7.3387423]], dtype=float32)
time = 3570	action = 0	current_phase = 0	next_phase = 1	reward = 0.723326	array([[ 1.5468695, -7.3470154]], dtype=float32)
time = 3575	action = 0	current_phase = 0	next_phase = 1	reward = 0.998234	array([[ 1.5267355, -7.332035 ]], dtype=float32)
time = 3580	action = 0	current_phase = 0	next_phase = 1	reward = 0.442551	array([[ 1.491812 , -7.3466415]], dtype=float32)
time = 3585	action = 0	current_phase = 0	next_phase = 1	reward = 1.007441	array([[ 1.5225537, -7.354829 ]], dtype=float32)
time = 3590	action = 0	current_phase = 0	next_phase = 1	reward = 0.444065	array([[ 1.7625916, -7.5811386]], dtype=float32)
time = 3595	action = 0	current_phase = 0	next_phase = 1	reward = 0.727945	array([[ 1.4680784, -7.3107905]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 10.2400 - val_loss: 9.1050
Epoch 2/50
 - 4s - loss: 8.2432 - val_loss: 7.7680
Epoch 3/50
 - 4s - loss: 8.3365 - val_loss: 6.5897
Epoch 4/50
 - 4s - loss: 8.1144 - val_loss: 6.4775
Epoch 5/50
 - 4s - loss: 7.5354 - val_loss: 7.7889
Epoch 6/50
 - 4s - loss: 7.6115 - val_loss: 6.6092
Epoch 7/50
 - 4s - loss: 7.2876 - val_loss: 6.7926
Epoch 8/50
 - 4s - loss: 7.4717 - val_loss: 7.2390
Epoch 9/50
 - 4s - loss: 6.9434 - val_loss: 6.3843
Epoch 10/50
 - 4s - loss: 8.1317 - val_loss: 7.5079
Epoch 11/50
 - 4s - loss: 6.9472 - val_loss: 6.9066
Epoch 12/50
 - 4s - loss: 6.8548 - val_loss: 7.6130
Epoch 13/50
 - 4s - loss: 7.4880 - val_loss: 6.5676
Epoch 14/50
 - 3s - loss: 6.9603 - val_loss: 7.4839
Epoch 15/50
 - 4s - loss: 7.2549 - val_loss: 6.9973
Epoch 16/50
 - 4s - loss: 7.5429 - val_loss: 7.0759
Epoch 17/50
 - 4s - loss: 6.8801 - val_loss: 7.1812
Epoch 18/50
 - 3s - loss: 7.2830 - val_loss: 6.5357
Epoch 19/50
 - 4s - loss: 6.5850 - val_loss: 7.4068
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 3600	action = 0	current_phase = 0	next_phase = 1	reward = 1.009384	array([[ 1.0564175, -7.233382 ]], dtype=float32)
time = 3605	action = 0	current_phase = 0	next_phase = 1	reward = 0.451038	array([[ 1.506104 , -7.4487677]], dtype=float32)
time = 3610	action = 0	current_phase = 0	next_phase = 1	reward = 1.005432	array([[ 1.5276432, -7.4241877]], dtype=float32)
time = 3615	action = 0	current_phase = 0	next_phase = 1	reward = 0.728596	array([[ 1.5799217, -7.405573 ]], dtype=float32)
time = 3620	action = 0	current_phase = 0	next_phase = 1	reward = 0.724532	array([[ 1.503294, -7.401354]], dtype=float32)
time = 3625	action = 0	current_phase = 0	next_phase = 1	reward = 0.722059	array([[ 1.5601678, -7.4016533]], dtype=float32)
time = 3630	action = 0	current_phase = 0	next_phase = 1	reward = 0.720153	array([[ 1.4841204, -7.3943653]], dtype=float32)
time = 3635	action = 0	current_phase = 0	next_phase = 1	reward = 0.718847	array([[ 1.543417, -7.374489]], dtype=float32)
time = 3640	action = 0	current_phase = 0	next_phase = 1	reward = 0.719823	array([[ 1.5131097, -7.337864 ]], dtype=float32)
time = 3645	action = 0	current_phase = 0	next_phase = 1	reward = 0.443231	array([[ 1.560597 , -7.4159365]], dtype=float32)
time = 3650	action = 0	current_phase = 0	next_phase = 1	reward = 0.998825	array([[ 1.7103438, -7.6393957]], dtype=float32)
time = 3655	action = 0	current_phase = 0	next_phase = 1	reward = 0.440623	array([[ 1.5402007, -7.4758196]], dtype=float32)
time = 3660	action = 0	current_phase = 0	next_phase = 1	reward = 1.007806	array([[ 1.5627403, -7.37639  ]], dtype=float32)
time = 3665	action = 0	current_phase = 0	next_phase = 1	reward = 0.720429	array([[ 1.6063724, -7.456902 ]], dtype=float32)
time = 3670	action = 0	current_phase = 0	next_phase = 1	reward = 0.437242	array([[ 1.2482188, -7.2653465]], dtype=float32)
time = 3675	action = 0	current_phase = 0	next_phase = 1	reward = 0.450039	array([[ 1.4921117, -7.378894 ]], dtype=float32)
time = 3680	action = 0	current_phase = 0	next_phase = 1	reward = 1.014470	array([[ 1.4482541, -7.488575 ]], dtype=float32)
time = 3685	action = 0	current_phase = 0	next_phase = 1	reward = 1.004963	array([[ 1.3780437, -7.3413696]], dtype=float32)
time = 3690	action = 0	current_phase = 0	next_phase = 1	reward = 0.443467	array([[ 1.4832559, -7.33851  ]], dtype=float32)
time = 3695	action = 0	current_phase = 0	next_phase = 1	reward = 1.002638	array([[ 1.5172386, -7.4102573]], dtype=float32)
time = 3700	action = 0	current_phase = 0	next_phase = 1	reward = 0.445916	array([[ 1.5750337, -7.415102 ]], dtype=float32)
time = 3705	action = 0	current_phase = 0	next_phase = 1	reward = 1.010843	array([[ 1.5622864, -7.5146847]], dtype=float32)
time = 3710	action = 0	current_phase = 0	next_phase = 1	reward = 0.728581	array([[ 1.6200933, -7.4805694]], dtype=float32)
time = 3715	action = 0	current_phase = 0	next_phase = 1	reward = 0.719130	array([[ 1.5383596, -7.375414 ]], dtype=float32)
time = 3720	action = 0	current_phase = 0	next_phase = 1	reward = 0.445434	array([[ 1.3901248, -7.4152517]], dtype=float32)
time = 3725	action = 0	current_phase = 0	next_phase = 1	reward = 1.005371	array([[ 1.5510435, -7.398112 ]], dtype=float32)
time = 3730	action = 0	current_phase = 0	next_phase = 1	reward = 0.729283	array([[ 1.599771 , -7.4488344]], dtype=float32)
time = 3735	action = 0	current_phase = 0	next_phase = 1	reward = 0.720567	array([[ 1.6413875, -7.511345 ]], dtype=float32)
time = 3740	action = 0	current_phase = 0	next_phase = 1	reward = 0.442181	array([[ 1.4867477, -7.410227 ]], dtype=float32)
time = 3745	action = 0	current_phase = 0	next_phase = 1	reward = 0.730144	array([[ 1.5415545, -7.3957386]], dtype=float32)
time = 3750	action = 0	current_phase = 0	next_phase = 1	reward = 0.726351	array([[ 1.5376577, -7.4148254]], dtype=float32)
time = 3755	action = 0	current_phase = 0	next_phase = 1	reward = 0.993702	array([[ 1.5426593, -7.3904815]], dtype=float32)
time = 3760	action = 0	current_phase = 0	next_phase = 1	reward = 0.719209	array([[ 1.9061127, -7.8801813]], dtype=float32)
time = 3765	action = 0	current_phase = 0	next_phase = 1	reward = 0.441155	array([[ 1.5651321, -7.3958325]], dtype=float32)
time = 3770	action = 0	current_phase = 0	next_phase = 1	reward = 0.723313	array([[ 1.5456305, -7.4484415]], dtype=float32)
time = 3775	action = 0	current_phase = 0	next_phase = 1	reward = 1.005806	array([[ 1.5502243, -7.7573795]], dtype=float32)
time = 3780	action = 0	current_phase = 0	next_phase = 1	reward = 0.449019	array([[ 1.4740143, -7.321875 ]], dtype=float32)
time = 3785	action = 0	current_phase = 0	next_phase = 1	reward = 1.000026	array([[ 1.0077348, -7.204627 ]], dtype=float32)
time = 3790	action = 0	current_phase = 0	next_phase = 1	reward = 0.166366	array([[ 1.5060205, -7.3416758]], dtype=float32)
time = 3795	action = 0	current_phase = 0	next_phase = 1	reward = 1.284924	array([[ 1.5606737, -7.44396  ]], dtype=float32)
time = 3800	action = 0	current_phase = 0	next_phase = 1	reward = 0.722949	array([[ 1.5829353, -7.450449 ]], dtype=float32)
time = 3805	action = 0	current_phase = 0	next_phase = 1	reward = 0.726422	array([[ 1.5554018, -7.3758   ]], dtype=float32)
time = 3810	action = 0	current_phase = 0	next_phase = 1	reward = 0.450914	array([[ 1.5726418, -7.4282103]], dtype=float32)
time = 3815	action = 0	current_phase = 0	next_phase = 1	reward = 0.728191	array([[ 1.551167, -7.40421 ]], dtype=float32)
time = 3820	action = 0	current_phase = 0	next_phase = 1	reward = 1.005467	array([[ 1.5176272, -7.5505505]], dtype=float32)
time = 3825	action = 0	current_phase = 0	next_phase = 1	reward = 0.721209	array([[ 1.543261 , -7.4026494]], dtype=float32)
time = 3830	action = 0	current_phase = 0	next_phase = 1	reward = 0.715909	array([[ 1.589366 , -7.4291496]], dtype=float32)
time = 3835	action = 0	current_phase = 0	next_phase = 1	reward = 0.438205	array([[ 1.4788084, -7.414225 ]], dtype=float32)
time = 3840	action = 0	current_phase = 0	next_phase = 1	reward = 1.005040	array([[ 1.5374432, -7.5201006]], dtype=float32)
time = 3845	action = 0	current_phase = 0	next_phase = 1	reward = 0.437918	array([[ 1.607162, -7.47913 ]], dtype=float32)
time = 3850	action = 0	current_phase = 0	next_phase = 1	reward = 0.729933	array([[ 1.5675278, -7.485511 ]], dtype=float32)
time = 3855	action = 0	current_phase = 0	next_phase = 1	reward = 0.736349	array([[ 1.7171168, -7.9309225]], dtype=float32)
time = 3860	action = 0	current_phase = 0	next_phase = 1	reward = 1.005072	array([[ 1.574594, -7.383568]], dtype=float32)
time = 3865	action = 0	current_phase = 0	next_phase = 1	reward = 0.721384	array([[ 1.552496, -7.360924]], dtype=float32)
time = 3870	action = 0	current_phase = 0	next_phase = 1	reward = 0.720845	array([[ 1.5598917, -7.422856 ]], dtype=float32)
time = 3875	action = 0	current_phase = 0	next_phase = 1	reward = 0.445975	array([[ 1.5464358, -7.4138813]], dtype=float32)
time = 3880	action = 0	current_phase = 0	next_phase = 1	reward = 0.736956	array([[ 1.5013404, -7.4549866]], dtype=float32)
time = 3885	action = 0	current_phase = 0	next_phase = 1	reward = 1.005590	array([[ 1.5699196, -7.3877144]], dtype=float32)
time = 3890	action = 0	current_phase = 0	next_phase = 1	reward = 0.717124	array([[ 1.4387665, -7.339229 ]], dtype=float32)
time = 3895	action = 0	current_phase = 0	next_phase = 1	reward = 0.717923	array([[ 1.6547952, -7.4997644]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 10.7012 - val_loss: 5.4979
Epoch 2/50
 - 4s - loss: 10.0511 - val_loss: 5.0022
Epoch 3/50
 - 4s - loss: 10.8747 - val_loss: 5.6391
Epoch 4/50
 - 4s - loss: 9.6919 - val_loss: 6.8949
Epoch 5/50
 - 4s - loss: 9.5020 - val_loss: 6.1067
Epoch 6/50
 - 4s - loss: 10.2816 - val_loss: 5.4198
Epoch 7/50
 - 4s - loss: 9.6572 - val_loss: 5.2268
Epoch 8/50
 - 4s - loss: 9.3376 - val_loss: 5.8424
Epoch 9/50
 - 4s - loss: 9.3569 - val_loss: 5.9015
Epoch 10/50
 - 4s - loss: 9.8331 - val_loss: 5.1875
Epoch 11/50
 - 4s - loss: 9.2173 - val_loss: 6.0837
Epoch 12/50
 - 3s - loss: 8.7429 - val_loss: 5.1208
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 3900	action = 0	current_phase = 0	next_phase = 1	reward = 0.722875	array([[ 1.6059155, -7.4341087]], dtype=float32)
time = 3905	action = 0	current_phase = 0	next_phase = 1	reward = 0.721586	array([[ 1.6255398, -7.379258 ]], dtype=float32)
time = 3910	action = 0	current_phase = 0	next_phase = 1	reward = 0.718714	array([[ 1.553431, -7.411908]], dtype=float32)
time = 3915	action = 0	current_phase = 0	next_phase = 1	reward = 0.725330	array([[ 1.6284285, -7.5006247]], dtype=float32)
time = 3920	action = 0	current_phase = 0	next_phase = 1	reward = 0.721843	array([[ 1.6491437, -7.5044713]], dtype=float32)
time = 3925	action = 0	current_phase = 0	next_phase = 1	reward = 0.726373	array([[ 1.6414385, -7.4678893]], dtype=float32)
time = 3930	action = 0	current_phase = 0	next_phase = 1	reward = 0.444121	array([[ 1.6215081, -7.3860803]], dtype=float32)
time = 3935	action = 0	current_phase = 0	next_phase = 1	reward = 1.007776	array([[ 1.6610203, -7.445822 ]], dtype=float32)
time = 3940	action = 0	current_phase = 0	next_phase = 1	reward = 0.720483	array([[ 1.5928984, -7.5256577]], dtype=float32)
time = 3945	action = 0	current_phase = 0	next_phase = 1	reward = 0.448861	array([[ 1.6063757, -7.385417 ]], dtype=float32)
time = 3950	action = 0	current_phase = 0	next_phase = 1	reward = 1.003053	array([[ 1.6506271, -7.4727497]], dtype=float32)
time = 3955	action = 0	current_phase = 0	next_phase = 1	reward = 0.453957	array([[ 1.5691605, -7.36961  ]], dtype=float32)
time = 3960	action = 0	current_phase = 0	next_phase = 1	reward = 0.727589	array([[ 1.6222539, -7.4651737]], dtype=float32)
time = 3965	action = 0	current_phase = 0	next_phase = 1	reward = 1.007324	array([[ 1.657167, -7.519047]], dtype=float32)
time = 3970	action = 0	current_phase = 0	next_phase = 1	reward = 0.167668	array([[ 1.6380968, -7.4723077]], dtype=float32)
time = 3975	action = 0	current_phase = 0	next_phase = 1	reward = 1.281693	array([[ 1.5703397, -7.4348545]], dtype=float32)
time = 3980	action = 0	current_phase = 0	next_phase = 1	reward = 0.715053	array([[ 1.5950222, -7.4221535]], dtype=float32)
time = 3985	action = 0	current_phase = 0	next_phase = 1	reward = 0.441522	array([[ 1.5727854, -7.529944 ]], dtype=float32)
time = 3990	action = 0	current_phase = 0	next_phase = 1	reward = 0.723885	array([[ 1.5614376, -7.440022 ]], dtype=float32)
time = 3995	action = 0	current_phase = 0	next_phase = 1	reward = 1.000865	array([[ 1.596498 , -7.4761324]], dtype=float32)
time = 4000	action = 0	current_phase = 0	next_phase = 1	reward = 0.451149	array([[ 1.4795356, -7.4271226]], dtype=float32)
time = 4005	action = 0	current_phase = 0	next_phase = 1	reward = 0.731088	array([[ 1.6180525, -7.6451902]], dtype=float32)
time = 4010	action = 0	current_phase = 0	next_phase = 1	reward = 0.995422	array([[ 1.7102399, -7.7958193]], dtype=float32)
time = 4015	action = 0	current_phase = 0	next_phase = 1	reward = 0.448789	array([[ 1.517755 , -7.3803387]], dtype=float32)
time = 4020	action = 0	current_phase = 0	next_phase = 1	reward = 0.728496	array([[ 1.4935827, -7.394784 ]], dtype=float32)
time = 4025	action = 0	current_phase = 0	next_phase = 1	reward = 1.001224	array([[ 1.5313864, -7.496543 ]], dtype=float32)
time = 4030	action = 0	current_phase = 0	next_phase = 1	reward = 0.714503	array([[ 1.6138291, -7.5099936]], dtype=float32)
time = 4035	action = 0	current_phase = 0	next_phase = 1	reward = 0.439862	array([[ 1.6675344, -7.511961 ]], dtype=float32)
time = 4040	action = 0	current_phase = 0	next_phase = 1	reward = 0.721548	array([[ 1.6709652, -7.5769987]], dtype=float32)
time = 4045	action = 0	current_phase = 0	next_phase = 1	reward = 0.722367	array([[ 1.6319952, -7.418084 ]], dtype=float32)
time = 4050	action = 0	current_phase = 0	next_phase = 1	reward = 0.736172	array([[ 1.083499 , -7.1594467]], dtype=float32)
time = 4055	action = 0	current_phase = 0	next_phase = 1	reward = 0.735647	array([[ 1.5519028, -7.4162664]], dtype=float32)
time = 4060	action = 0	current_phase = 0	next_phase = 1	reward = 1.010595	array([[ 1.6395202, -7.4369483]], dtype=float32)
time = 4065	action = 0	current_phase = 0	next_phase = 1	reward = 0.736085	array([[ 1.5951562, -7.406845 ]], dtype=float32)
time = 4070	action = 0	current_phase = 0	next_phase = 1	reward = 0.729716	array([[ 1.5388522, -7.522784 ]], dtype=float32)
time = 4075	action = 0	current_phase = 0	next_phase = 1	reward = 0.719762	array([[ 1.5981855, -7.3952894]], dtype=float32)
time = 4080	action = 0	current_phase = 0	next_phase = 1	reward = 0.722564	array([[ 1.7577596, -7.552969 ]], dtype=float32)
time = 4085	action = 0	current_phase = 0	next_phase = 1	reward = 0.717886	array([[ 1.5694108, -7.4120135]], dtype=float32)
time = 4090	action = 0	current_phase = 0	next_phase = 1	reward = 0.441164	array([[ 1.6299529, -7.406129 ]], dtype=float32)
time = 4095	action = 0	current_phase = 0	next_phase = 1	reward = 0.736345	array([[ 1.5915103, -7.3788385]], dtype=float32)
time = 4100	action = 0	current_phase = 0	next_phase = 1	reward = 0.999136	array([[ 1.7367406, -7.670267 ]], dtype=float32)
time = 4105	action = 0	current_phase = 0	next_phase = 1	reward = 0.437465	array([[ 1.4752445, -7.5014997]], dtype=float32)
time = 4110	action = 0	current_phase = 0	next_phase = 1	reward = 0.450511	array([[ 1.5994167, -7.508879 ]], dtype=float32)
time = 4115	action = 0	current_phase = 0	next_phase = 1	reward = 1.293878	array([[ 1.7232709, -8.03479  ]], dtype=float32)
time = 4120	action = 0	current_phase = 0	next_phase = 1	reward = 0.440993	array([[ 1.5825601, -7.4240947]], dtype=float32)
time = 4125	action = 0	current_phase = 0	next_phase = 1	reward = 0.999668	array([[ 1.4417744, -7.3738785]], dtype=float32)
time = 4130	action = 0	current_phase = 0	next_phase = 1	reward = 0.721038	array([[ 1.6937504, -7.761058 ]], dtype=float32)
time = 4135	action = 0	current_phase = 0	next_phase = 1	reward = 0.443475	array([[ 1.5994544, -7.403943 ]], dtype=float32)
time = 4140	action = 0	current_phase = 0	next_phase = 1	reward = 1.007564	array([[ 1.4774594, -7.4635224]], dtype=float32)
time = 4145	action = 0	current_phase = 0	next_phase = 1	reward = 0.713836	array([[ 1.4667325, -7.357744 ]], dtype=float32)
time = 4150	action = 0	current_phase = 0	next_phase = 1	reward = 0.163242	array([[ 1.4721961, -7.442284 ]], dtype=float32)
time = 4155	action = 0	current_phase = 0	next_phase = 1	reward = 1.024092	array([[ 1.5353179, -7.4093294]], dtype=float32)
time = 4160	action = 0	current_phase = 0	next_phase = 1	reward = 1.003466	array([[ 1.5744166, -7.5268016]], dtype=float32)
time = 4165	action = 0	current_phase = 0	next_phase = 1	reward = 0.718838	array([[ 1.6151934, -7.383355 ]], dtype=float32)
time = 4170	action = 0	current_phase = 0	next_phase = 1	reward = 0.721823	array([[ 1.5896277, -7.4502354]], dtype=float32)
time = 4175	action = 0	current_phase = 0	next_phase = 1	reward = 0.717142	array([[ 1.6065722, -7.4059105]], dtype=float32)
time = 4180	action = 0	current_phase = 0	next_phase = 1	reward = 0.725540	array([[ 1.641325, -7.449914]], dtype=float32)
time = 4185	action = 0	current_phase = 0	next_phase = 1	reward = 0.168186	array([[ 1.5900898, -7.395426 ]], dtype=float32)
time = 4190	action = 0	current_phase = 0	next_phase = 1	reward = 1.014933	array([[ 1.5865588, -7.4998293]], dtype=float32)
time = 4195	action = 0	current_phase = 0	next_phase = 1	reward = 0.997795	array([[ 1.6158218, -7.429968 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 3s - loss: 10.8619 - val_loss: 5.1266
Epoch 2/50
 - 4s - loss: 8.0478 - val_loss: 4.9624
Epoch 3/50
 - 4s - loss: 7.8377 - val_loss: 5.8729
Epoch 4/50
 - 3s - loss: 8.0136 - val_loss: 5.2462
Epoch 5/50
 - 4s - loss: 8.7158 - val_loss: 8.5816
Epoch 6/50
 - 4s - loss: 7.9026 - val_loss: 7.3980
Epoch 7/50
 - 4s - loss: 8.2473 - val_loss: 6.6356
Epoch 8/50
 - 3s - loss: 6.9177 - val_loss: 4.7585
Epoch 9/50
 - 4s - loss: 7.6348 - val_loss: 5.2357
Epoch 10/50
 - 4s - loss: 7.2240 - val_loss: 5.1624
Epoch 11/50
 - 4s - loss: 8.9541 - val_loss: 5.5793
Epoch 12/50
 - 3s - loss: 7.0477 - val_loss: 5.1759
Epoch 13/50
 - 4s - loss: 7.3092 - val_loss: 4.9914
Epoch 14/50
 - 4s - loss: 7.1835 - val_loss: 5.2481
Epoch 15/50
 - 4s - loss: 7.4167 - val_loss: 5.0889
Epoch 16/50
 - 4s - loss: 9.2671 - val_loss: 6.3324
Epoch 17/50
 - 4s - loss: 7.7429 - val_loss: 5.0151
Epoch 18/50
 - 4s - loss: 6.6163 - val_loss: 5.7759
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 4200	action = 0	current_phase = 0	next_phase = 1	reward = 0.716557	array([[ 1.5952549, -7.347844 ]], dtype=float32)
time = 4205	action = 0	current_phase = 0	next_phase = 1	reward = 0.716796	array([[ 1.5336347, -7.3063087]], dtype=float32)
time = 4210	action = 0	current_phase = 0	next_phase = 1	reward = 0.717094	array([[ 1.6000948, -7.48455  ]], dtype=float32)
time = 4215	action = 0	current_phase = 0	next_phase = 1	reward = 0.164164	array([[ 1.6495109, -7.4131093]], dtype=float32)
time = 4220	action = 0	current_phase = 0	next_phase = 1	reward = 1.013821	array([[ 1.5000873, -7.404168 ]], dtype=float32)
time = 4225	action = 0	current_phase = 0	next_phase = 1	reward = 1.004344	array([[ 1.5896659, -7.4588804]], dtype=float32)
time = 4230	action = 0	current_phase = 0	next_phase = 1	reward = 0.444302	array([[ 1.6186986, -7.378235 ]], dtype=float32)
time = 4235	action = 0	current_phase = 0	next_phase = 1	reward = 1.005958	array([[ 1.5762658, -7.315883 ]], dtype=float32)
time = 4240	action = 0	current_phase = 0	next_phase = 1	reward = 0.722841	array([[ 1.5557222, -7.3360143]], dtype=float32)
time = 4245	action = 0	current_phase = 0	next_phase = 1	reward = 0.440393	array([[ 1.6744642, -7.458598 ]], dtype=float32)
time = 4250	action = 0	current_phase = 0	next_phase = 1	reward = 1.002553	array([[ 1.516232, -7.514593]], dtype=float32)
time = 4255	action = 0	current_phase = 0	next_phase = 1	reward = 0.445227	array([[ 1.5522919, -7.3303127]], dtype=float32)
time = 4260	action = 0	current_phase = 0	next_phase = 1	reward = 0.998876	array([[ 1.6717925, -7.702111 ]], dtype=float32)
time = 4265	action = 0	current_phase = 0	next_phase = 1	reward = 0.441260	array([[ 1.6154356, -7.366113 ]], dtype=float32)
time = 4270	action = 0	current_phase = 0	next_phase = 1	reward = 0.734036	array([[ 1.5100803, -7.3256435]], dtype=float32)
time = 4275	action = 0	current_phase = 0	next_phase = 1	reward = 1.009486	array([[ 1.501903, -7.268319]], dtype=float32)
time = 4280	action = 0	current_phase = 0	next_phase = 1	reward = 0.723396	array([[ 1.5437837, -7.343538 ]], dtype=float32)
time = 4285	action = 0	current_phase = 0	next_phase = 1	reward = 0.725528	array([[ 1.8037901, -7.688918 ]], dtype=float32)
time = 4290	action = 0	current_phase = 0	next_phase = 1	reward = 0.439362	array([[ 1.558383 , -7.2854924]], dtype=float32)
time = 4295	action = 0	current_phase = 0	next_phase = 1	reward = 1.004598	array([[ 1.5927386, -7.396684 ]], dtype=float32)
time = 4300	action = 0	current_phase = 0	next_phase = 1	reward = 0.441977	array([[ 1.610734 , -7.3744116]], dtype=float32)
time = 4305	action = 0	current_phase = 0	next_phase = 1	reward = 0.997663	array([[ 1.5279012, -7.3740463]], dtype=float32)
time = 4310	action = 0	current_phase = 0	next_phase = 1	reward = 0.440802	array([[ 1.5678105, -7.3228607]], dtype=float32)
time = 4315	action = 0	current_phase = 0	next_phase = 1	reward = 1.003575	array([[ 1.5996151, -7.40469  ]], dtype=float32)
time = 4320	action = 0	current_phase = 0	next_phase = 1	reward = 0.723396	array([[ 1.5861478, -7.3530636]], dtype=float32)
time = 4325	action = 0	current_phase = 0	next_phase = 1	reward = 0.441747	array([[ 1.58361 , -7.367831]], dtype=float32)
time = 4330	action = 0	current_phase = 0	next_phase = 1	reward = 0.726395	array([[ 1.5687189, -7.3327665]], dtype=float32)
time = 4335	action = 0	current_phase = 0	next_phase = 1	reward = 0.729994	array([[ 1.6347532, -7.4251003]], dtype=float32)
time = 4340	action = 0	current_phase = 0	next_phase = 1	reward = 1.015861	array([[ 1.5722694, -7.3186626]], dtype=float32)
time = 4345	action = 0	current_phase = 0	next_phase = 1	reward = 0.718099	array([[ 1.5581465, -7.5413923]], dtype=float32)
time = 4350	action = 0	current_phase = 0	next_phase = 1	reward = 0.716597	array([[ 1.5691156, -7.3097725]], dtype=float32)
time = 4355	action = 0	current_phase = 0	next_phase = 1	reward = 0.449111	array([[ 1.576405 , -7.3303843]], dtype=float32)
time = 4360	action = 0	current_phase = 0	next_phase = 1	reward = 1.011878	array([[ 1.5959249, -7.409734 ]], dtype=float32)
time = 4365	action = 0	current_phase = 0	next_phase = 1	reward = 0.725155	array([[ 1.6011977, -7.3959084]], dtype=float32)
time = 4370	action = 0	current_phase = 0	next_phase = 1	reward = 0.445207	array([[ 1.5615187, -7.308399 ]], dtype=float32)
time = 4375	action = 0	current_phase = 0	next_phase = 1	reward = 1.004190	array([[ 1.5477448, -7.2714643]], dtype=float32)
time = 4380	action = 0	current_phase = 0	next_phase = 1	reward = 0.722262	array([[ 1.5814977, -7.3552976]], dtype=float32)
time = 4385	action = 0	current_phase = 0	next_phase = 1	reward = 0.723004	array([[ 1.6005907, -7.331628 ]], dtype=float32)
time = 4390	action = 0	current_phase = 0	next_phase = 1	reward = 0.725519	array([[ 1.5732117, -7.3550935]], dtype=float32)
time = 4395	action = 0	current_phase = 0	next_phase = 1	reward = 0.716528	array([[ 1.5347342, -7.4080105]], dtype=float32)
time = 4400	action = 0	current_phase = 0	next_phase = 1	reward = 0.163701	array([[ 1.7364535, -7.5381107]], dtype=float32)
time = 4405	action = 0	current_phase = 0	next_phase = 1	reward = 1.285711	array([[ 1.2682102, -7.2749815]], dtype=float32)
time = 4410	action = 0	current_phase = 0	next_phase = 1	reward = 0.720832	array([[ 1.671649, -7.506749]], dtype=float32)
time = 4415	action = 0	current_phase = 0	next_phase = 1	reward = 0.726146	array([[ 1.5465522, -7.327277 ]], dtype=float32)
time = 4420	action = 0	current_phase = 0	next_phase = 1	reward = 0.717407	array([[ 1.5759349, -7.4158444]], dtype=float32)
time = 4425	action = 0	current_phase = 0	next_phase = 1	reward = 0.721946	array([[ 1.5766726, -7.3228407]], dtype=float32)
time = 4430	action = 0	current_phase = 0	next_phase = 1	reward = 0.722379	array([[ 1.7185926, -7.5348268]], dtype=float32)
time = 4435	action = 0	current_phase = 0	next_phase = 1	reward = 0.717283	array([[ 1.6074276, -7.3492556]], dtype=float32)
time = 4440	action = 0	current_phase = 0	next_phase = 1	reward = 0.448680	array([[ 1.6269803, -7.3654795]], dtype=float32)
time = 4445	action = 0	current_phase = 0	next_phase = 1	reward = 1.015754	array([[ 1.4934969, -7.2368107]], dtype=float32)
time = 4450	action = 0	current_phase = 0	next_phase = 1	reward = 0.723720	array([[ 1.5454483, -7.3613925]], dtype=float32)
time = 4455	action = 0	current_phase = 0	next_phase = 1	reward = 0.726186	array([[ 1.5424132, -7.3439627]], dtype=float32)
time = 4460	action = 0	current_phase = 0	next_phase = 1	reward = 0.721065	array([[ 1.6357646, -7.8678613]], dtype=float32)
time = 4465	action = 0	current_phase = 0	next_phase = 1	reward = 0.450984	array([[ 1.5725293, -7.314213 ]], dtype=float32)
time = 4470	action = 0	current_phase = 0	next_phase = 1	reward = 1.004749	array([[ 1.5086126, -7.362503 ]], dtype=float32)
time = 4475	action = 0	current_phase = 0	next_phase = 1	reward = 0.713976	array([[ 1.5466156, -7.3689165]], dtype=float32)
time = 4480	action = 0	current_phase = 0	next_phase = 1	reward = 0.454515	array([[ 1.5679541, -7.3658695]], dtype=float32)
time = 4485	action = 0	current_phase = 0	next_phase = 1	reward = 1.006561	array([[ 1.6187596, -7.443637 ]], dtype=float32)
time = 4490	action = 0	current_phase = 0	next_phase = 1	reward = 0.445533	array([[ 1.5267377, -7.268219 ]], dtype=float32)
time = 4495	action = 0	current_phase = 0	next_phase = 1	reward = 1.004840	array([[ 1.1007919, -7.1780176]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 3s - loss: 8.1774 - val_loss: 8.3709
Epoch 2/50
 - 4s - loss: 8.4536 - val_loss: 7.2129
Epoch 3/50
 - 4s - loss: 8.1418 - val_loss: 8.1392
Epoch 4/50
 - 3s - loss: 7.1591 - val_loss: 6.9333
Epoch 5/50
 - 4s - loss: 7.1322 - val_loss: 6.9557
Epoch 6/50
 - 4s - loss: 7.9470 - val_loss: 7.1468
Epoch 7/50
 - 4s - loss: 6.9983 - val_loss: 7.3834
Epoch 8/50
 - 4s - loss: 6.4466 - val_loss: 7.6341
Epoch 9/50
 - 4s - loss: 7.2371 - val_loss: 8.2339
Epoch 10/50
 - 3s - loss: 6.3276 - val_loss: 6.6480
Epoch 11/50
 - 4s - loss: 7.3405 - val_loss: 7.5272
Epoch 12/50
 - 4s - loss: 7.1686 - val_loss: 6.9059
Epoch 13/50
 - 4s - loss: 6.3933 - val_loss: 7.4655
Epoch 14/50
 - 4s - loss: 7.0677 - val_loss: 7.2199
Epoch 15/50
 - 4s - loss: 6.2293 - val_loss: 6.7360
Epoch 16/50
 - 4s - loss: 6.9728 - val_loss: 6.7690
Epoch 17/50
 - 4s - loss: 6.2885 - val_loss: 8.5093
Epoch 18/50
 - 4s - loss: 5.9158 - val_loss: 6.9539
Epoch 19/50
 - 4s - loss: 6.9223 - val_loss: 7.4555
Epoch 20/50
 - 4s - loss: 6.2126 - val_loss: 6.8153
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 4500	action = 0	current_phase = 0	next_phase = 1	reward = 0.714786	array([[ 1.4852021, -7.334457 ]], dtype=float32)
time = 4505	action = 0	current_phase = 0	next_phase = 1	reward = 0.439318	array([[ 1.5432789, -7.389743 ]], dtype=float32)
time = 4510	action = 0	current_phase = 0	next_phase = 1	reward = 0.731510	array([[ 1.4958875, -7.3602343]], dtype=float32)
time = 4515	action = 0	current_phase = 0	next_phase = 1	reward = 1.008503	array([[ 1.5166008, -7.394124 ]], dtype=float32)
time = 4520	action = 0	current_phase = 0	next_phase = 1	reward = 0.726853	array([[ 1.513644, -7.330549]], dtype=float32)
time = 4525	action = 0	current_phase = 0	next_phase = 1	reward = 0.723091	array([[ 1.6025493, -7.4739084]], dtype=float32)
time = 4530	action = 0	current_phase = 0	next_phase = 1	reward = 0.438933	array([[ 1.4767935, -7.3749046]], dtype=float32)
time = 4535	action = 0	current_phase = 0	next_phase = 1	reward = 1.004998	array([[ 1.5507777, -7.391171 ]], dtype=float32)
time = 4540	action = 0	current_phase = 0	next_phase = 1	reward = 0.712880	array([[ 1.517482, -7.387438]], dtype=float32)
time = 4545	action = 0	current_phase = 0	next_phase = 1	reward = 0.448190	array([[ 1.4761746, -7.3966827]], dtype=float32)
time = 4550	action = 0	current_phase = 0	next_phase = 1	reward = 1.004516	array([[ 1.4438145, -7.3134384]], dtype=float32)
time = 4555	action = 0	current_phase = 0	next_phase = 1	reward = 0.450140	array([[ 2.0547464, -7.86435  ]], dtype=float32)
time = 4560	action = 0	current_phase = 0	next_phase = 1	reward = 1.004708	array([[ 1.5047748, -7.3818536]], dtype=float32)
time = 4565	action = 0	current_phase = 0	next_phase = 1	reward = 0.722949	array([[ 1.2966225, -7.5690722]], dtype=float32)
time = 4570	action = 0	current_phase = 0	next_phase = 1	reward = 0.445118	array([[ 1.5169837, -7.422892 ]], dtype=float32)
time = 4575	action = 0	current_phase = 0	next_phase = 1	reward = 0.729080	array([[ 1.5332735, -7.3724604]], dtype=float32)
time = 4580	action = 0	current_phase = 0	next_phase = 1	reward = 1.003418	array([[ 1.490041 , -7.3475285]], dtype=float32)
time = 4585	action = 0	current_phase = 0	next_phase = 1	reward = 0.440836	array([[ 1.5225275, -7.336014 ]], dtype=float32)
time = 4590	action = 0	current_phase = 0	next_phase = 1	reward = 0.730969	array([[ 1.4392335, -7.3515224]], dtype=float32)
time = 4595	action = 0	current_phase = 0	next_phase = 1	reward = 1.003586	array([[ 1.4024136, -7.4343157]], dtype=float32)
time = 4600	action = 0	current_phase = 0	next_phase = 1	reward = 0.445225	array([[ 1.5102136, -7.3509026]], dtype=float32)
time = 4605	action = 0	current_phase = 0	next_phase = 1	reward = 1.001714	array([[ 1.5287578, -7.4262877]], dtype=float32)
time = 4610	action = 0	current_phase = 0	next_phase = 1	reward = 0.441099	array([[ 1.8241432, -7.894868 ]], dtype=float32)
time = 4615	action = 0	current_phase = 0	next_phase = 1	reward = 0.725544	array([[ 1.4728153, -7.3899803]], dtype=float32)
time = 4620	action = 0	current_phase = 0	next_phase = 1	reward = 1.004512	array([[ 1.1919732, -7.126499 ]], dtype=float32)
time = 4625	action = 0	current_phase = 0	next_phase = 1	reward = 0.727571	array([[ 1.5308993, -7.4760904]], dtype=float32)
time = 4630	action = 0	current_phase = 0	next_phase = 1	reward = 0.444917	array([[ 1.5264094, -7.3353004]], dtype=float32)
time = 4635	action = 0	current_phase = 0	next_phase = 1	reward = 1.009159	array([[ 1.4513996, -7.456865 ]], dtype=float32)
time = 4640	action = 0	current_phase = 0	next_phase = 1	reward = 0.719061	array([[ 1.4976418, -7.3638535]], dtype=float32)
time = 4645	action = 0	current_phase = 0	next_phase = 1	reward = 0.718540	array([[ 1.6705301, -7.543912 ]], dtype=float32)
time = 4650	action = 0	current_phase = 0	next_phase = 1	reward = 0.438869	array([[ 1.4563944, -7.296379 ]], dtype=float32)
time = 4655	action = 0	current_phase = 0	next_phase = 1	reward = 1.000248	array([[ 1.4951594, -7.4352026]], dtype=float32)
time = 4660	action = 0	current_phase = 0	next_phase = 1	reward = 0.164345	array([[ 1.5355146, -7.337885 ]], dtype=float32)
time = 4665	action = 0	current_phase = 0	next_phase = 1	reward = 1.296674	array([[ 1.4809897, -7.424249 ]], dtype=float32)
time = 4670	action = 0	current_phase = 0	next_phase = 1	reward = 0.724839	array([[ 1.5061901, -7.377822 ]], dtype=float32)
time = 4675	action = 0	current_phase = 0	next_phase = 1	reward = 0.708802	array([[ 1.440882 , -7.4156895]], dtype=float32)
time = 4680	action = 0	current_phase = 0	next_phase = 1	reward = 0.715256	array([[ 1.4351952, -7.3426237]], dtype=float32)
time = 4685	action = 0	current_phase = 0	next_phase = 1	reward = 0.438914	array([[ 1.4828126, -7.4232903]], dtype=float32)
time = 4690	action = 0	current_phase = 0	next_phase = 1	reward = 0.450676	array([[ 1.5411541, -7.355197 ]], dtype=float32)
time = 4695	action = 0	current_phase = 0	next_phase = 1	reward = 1.292131	array([[ 1.4508088, -7.360093 ]], dtype=float32)
time = 4700	action = 0	current_phase = 0	next_phase = 1	reward = 0.722495	array([[ 1.5403082, -7.523148 ]], dtype=float32)
time = 4705	action = 0	current_phase = 0	next_phase = 1	reward = 0.720654	array([[ 1.5220816, -7.499215 ]], dtype=float32)
time = 4710	action = 0	current_phase = 0	next_phase = 1	reward = 0.442583	array([[ 1.5144727, -7.3556285]], dtype=float32)
time = 4715	action = 0	current_phase = 0	next_phase = 1	reward = 1.009743	array([[ 1.514066 , -7.3812485]], dtype=float32)
time = 4720	action = 0	current_phase = 0	next_phase = 1	reward = 0.720448	array([[ 1.5099614, -7.396435 ]], dtype=float32)
time = 4725	action = 0	current_phase = 0	next_phase = 1	reward = 0.720123	array([[ 1.5382159, -7.423601 ]], dtype=float32)
time = 4730	action = 0	current_phase = 0	next_phase = 1	reward = 0.722180	array([[ 1.5350907, -7.3822374]], dtype=float32)
time = 4735	action = 0	current_phase = 0	next_phase = 1	reward = 0.723904	array([[ 1.5007861, -7.3204527]], dtype=float32)
time = 4740	action = 0	current_phase = 0	next_phase = 1	reward = 0.725784	array([[ 1.5086896, -7.346349 ]], dtype=float32)
time = 4745	action = 0	current_phase = 0	next_phase = 1	reward = 0.444718	array([[ 1.4739125, -7.394836 ]], dtype=float32)
time = 4750	action = 0	current_phase = 0	next_phase = 1	reward = 1.004411	array([[ 1.5555322, -7.4948826]], dtype=float32)
time = 4755	action = 0	current_phase = 0	next_phase = 1	reward = 0.723549	array([[ 1.468015 , -7.3267155]], dtype=float32)
time = 4760	action = 0	current_phase = 0	next_phase = 1	reward = 0.720833	array([[ 1.4779398, -7.3458166]], dtype=float32)
time = 4765	action = 0	current_phase = 0	next_phase = 1	reward = 0.723463	array([[ 1.5381987, -7.356427 ]], dtype=float32)
time = 4770	action = 0	current_phase = 0	next_phase = 1	reward = 0.712381	array([[ 1.5072968, -7.3362246]], dtype=float32)
time = 4775	action = 0	current_phase = 0	next_phase = 1	reward = 0.432909	array([[ 1.5303447, -7.360633 ]], dtype=float32)
time = 4780	action = 0	current_phase = 0	next_phase = 1	reward = 1.004959	array([[ 1.6330073, -7.5403605]], dtype=float32)
time = 4785	action = 0	current_phase = 0	next_phase = 1	reward = 0.447096	array([[ 1.5136373, -7.3557835]], dtype=float32)
time = 4790	action = 0	current_phase = 0	next_phase = 1	reward = 0.729827	array([[ 1.4810674, -7.36547  ]], dtype=float32)
time = 4795	action = 0	current_phase = 0	next_phase = 1	reward = 1.008933	array([[ 1.4772599, -7.3375683]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 10.9021 - val_loss: 7.2260
Epoch 2/50
 - 4s - loss: 11.1566 - val_loss: 6.8974
Epoch 3/50
 - 3s - loss: 11.1124 - val_loss: 6.6615
Epoch 4/50
 - 4s - loss: 10.6311 - val_loss: 6.0764
Epoch 5/50
 - 4s - loss: 10.6037 - val_loss: 6.6160
Epoch 6/50
 - 4s - loss: 9.9457 - val_loss: 6.6401
Epoch 7/50
 - 4s - loss: 10.0779 - val_loss: 5.9573
Epoch 8/50
 - 4s - loss: 10.4014 - val_loss: 7.6900
Epoch 9/50
 - 4s - loss: 9.3592 - val_loss: 6.1331
Epoch 10/50
 - 4s - loss: 9.4288 - val_loss: 5.6548
Epoch 11/50
 - 4s - loss: 9.0940 - val_loss: 6.0466
Epoch 12/50
 - 4s - loss: 9.2333 - val_loss: 7.5233
Epoch 13/50
 - 4s - loss: 9.1664 - val_loss: 6.1172
Epoch 14/50
 - 4s - loss: 8.5726 - val_loss: 4.9172
Epoch 15/50
 - 4s - loss: 9.1378 - val_loss: 5.9940
Epoch 16/50
 - 4s - loss: 9.8737 - val_loss: 6.3427
Epoch 17/50
 - 4s - loss: 8.1965 - val_loss: 6.5691
Epoch 18/50
 - 3s - loss: 9.3131 - val_loss: 6.6303
Epoch 19/50
 - 3s - loss: 8.8307 - val_loss: 6.6004
Epoch 20/50
 - 4s - loss: 8.9036 - val_loss: 7.8495
Epoch 21/50
 - 3s - loss: 8.5535 - val_loss: 8.8738
Epoch 22/50
 - 4s - loss: 8.4775 - val_loss: 7.9285
Epoch 23/50
 - 4s - loss: 8.5542 - val_loss: 7.6746
Epoch 24/50
 - 3s - loss: 8.2598 - val_loss: 5.6325
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 4800	action = 0	current_phase = 0	next_phase = 1	reward = 0.723340	array([[ 1.819988, -7.332652]], dtype=float32)
time = 4805	action = 0	current_phase = 0	next_phase = 1	reward = 0.721895	array([[ 1.9593084, -7.5108404]], dtype=float32)
time = 4810	action = 0	current_phase = 0	next_phase = 1	reward = 0.722123	array([[ 1.8498919, -7.336382 ]], dtype=float32)
time = 4815	action = 0	current_phase = 0	next_phase = 1	reward = 0.723856	array([[ 1.820411 , -7.3546734]], dtype=float32)
time = 4820	action = 0	current_phase = 0	next_phase = 1	reward = 0.718216	array([[ 1.8543303, -7.4056196]], dtype=float32)
time = 4825	action = 0	current_phase = 0	next_phase = 1	reward = 0.717327	array([[ 1.7748625, -7.325318 ]], dtype=float32)
time = 4830	action = 0	current_phase = 0	next_phase = 1	reward = 0.716782	array([[ 1.8351481, -7.394259 ]], dtype=float32)
time = 4835	action = 0	current_phase = 0	next_phase = 1	reward = 0.437716	array([[ 1.8409884, -7.367651 ]], dtype=float32)
time = 4840	action = 0	current_phase = 0	next_phase = 1	reward = 1.007993	array([[ 1.8596423, -7.3422203]], dtype=float32)
time = 4845	action = 0	current_phase = 0	next_phase = 1	reward = 0.722582	array([[ 1.8189061, -7.3755302]], dtype=float32)
time = 4850	action = 0	current_phase = 0	next_phase = 1	reward = 0.713489	array([[ 1.9916074, -7.539481 ]], dtype=float32)
time = 4855	action = 0	current_phase = 0	next_phase = 1	reward = 0.720293	array([[ 1.8291824, -7.3335752]], dtype=float32)
time = 4860	action = 0	current_phase = 0	next_phase = 1	reward = 0.439368	array([[ 1.796849, -7.345042]], dtype=float32)
time = 4865	action = 0	current_phase = 0	next_phase = 1	reward = 0.731306	array([[ 2.0683115, -7.779396 ]], dtype=float32)
time = 4870	action = 0	current_phase = 0	next_phase = 1	reward = 0.727363	array([[ 2.1884425, -7.7919703]], dtype=float32)
time = 4875	action = 0	current_phase = 0	next_phase = 1	reward = 1.005109	array([[ 1.818373, -7.366601]], dtype=float32)
time = 4880	action = 0	current_phase = 0	next_phase = 1	reward = 0.720788	array([[ 1.8467844, -7.3277254]], dtype=float32)
time = 4885	action = 0	current_phase = 0	next_phase = 1	reward = 0.726451	array([[ 1.8312128, -7.360282 ]], dtype=float32)
time = 4890	action = 0	current_phase = 0	next_phase = 1	reward = 0.444379	array([[ 1.8236558, -7.338832 ]], dtype=float32)
time = 4895	action = 0	current_phase = 0	next_phase = 1	reward = 0.719826	array([[ 1.8347905, -7.3772573]], dtype=float32)
time = 4900	action = 0	current_phase = 0	next_phase = 1	reward = 0.996885	array([[ 2.2011502, -8.044563 ]], dtype=float32)
time = 4905	action = 0	current_phase = 0	next_phase = 1	reward = 0.441455	array([[ 1.8710511, -7.4327593]], dtype=float32)
time = 4910	action = 0	current_phase = 0	next_phase = 1	reward = 1.006415	array([[ 1.8539898, -7.4944167]], dtype=float32)
time = 4915	action = 0	current_phase = 0	next_phase = 1	reward = 0.449327	array([[ 1.8179843, -7.311973 ]], dtype=float32)
time = 4920	action = 0	current_phase = 0	next_phase = 1	reward = 1.005124	array([[ 1.8494751, -7.3334007]], dtype=float32)
time = 4925	action = 0	current_phase = 0	next_phase = 1	reward = 0.718338	array([[ 1.8153174, -7.373315 ]], dtype=float32)
time = 4930	action = 0	current_phase = 0	next_phase = 1	reward = 0.160377	array([[ 1.8514235, -7.3214483]], dtype=float32)
time = 4935	action = 0	current_phase = 0	next_phase = 1	reward = 1.281185	array([[ 1.8137944, -7.3435106]], dtype=float32)
time = 4940	action = 0	current_phase = 0	next_phase = 1	reward = 0.713151	array([[ 1.8403523, -7.4767046]], dtype=float32)
time = 4945	action = 0	current_phase = 0	next_phase = 1	reward = 0.166760	array([[ 1.8395689, -7.358931 ]], dtype=float32)
time = 4950	action = 0	current_phase = 0	next_phase = 1	reward = 1.298312	array([[ 1.5156548, -7.4328327]], dtype=float32)
time = 4955	action = 0	current_phase = 0	next_phase = 1	reward = 0.724716	array([[ 1.8464696, -7.3282285]], dtype=float32)
time = 4960	action = 0	current_phase = 0	next_phase = 1	reward = 0.719951	array([[ 1.7396219, -7.3149   ]], dtype=float32)
time = 4965	action = 0	current_phase = 0	next_phase = 1	reward = 0.723322	array([[ 1.7461607, -7.407458 ]], dtype=float32)
time = 4970	action = 0	current_phase = 0	next_phase = 1	reward = 0.453232	array([[ 1.8474848, -7.3328676]], dtype=float32)
time = 4975	action = 0	current_phase = 0	next_phase = 1	reward = 1.008271	array([[ 1.8848283, -7.3801866]], dtype=float32)
time = 4980	action = 0	current_phase = 0	next_phase = 1	reward = 0.724473	array([[ 1.8909137, -7.426444 ]], dtype=float32)
time = 4985	action = 0	current_phase = 0	next_phase = 1	reward = 0.723644	array([[ 1.7819917, -7.313976 ]], dtype=float32)
time = 4990	action = 0	current_phase = 0	next_phase = 1	reward = 0.720332	array([[ 1.6723087, -7.345339 ]], dtype=float32)
time = 4995	action = 0	current_phase = 0	next_phase = 1	reward = 0.714907	array([[ 1.8310244, -7.324752 ]], dtype=float32)
time = 5000	action = 0	current_phase = 0	next_phase = 1	reward = 0.450088	array([[ 1.889539, -7.510059]], dtype=float32)
time = 5005	action = 0	current_phase = 0	next_phase = 1	reward = 0.730151	array([[ 1.8585675, -7.403649 ]], dtype=float32)
time = 5010	action = 0	current_phase = 0	next_phase = 1	reward = 1.004924	array([[ 1.8770182, -7.376543 ]], dtype=float32)
time = 5015	action = 0	current_phase = 0	next_phase = 1	reward = 0.719220	array([[ 1.7640879, -7.4896574]], dtype=float32)
time = 5020	action = 0	current_phase = 0	next_phase = 1	reward = 0.715568	array([[ 1.8124263, -7.336706 ]], dtype=float32)
time = 5025	action = 0	current_phase = 0	next_phase = 1	reward = 0.720878	array([[ 1.8576796, -7.358961 ]], dtype=float32)
time = 5030	action = 0	current_phase = 0	next_phase = 1	reward = 0.440006	array([[ 1.8968556, -7.421814 ]], dtype=float32)
time = 5035	action = 0	current_phase = 0	next_phase = 1	reward = 0.730695	array([[ 1.7118514, -7.260949 ]], dtype=float32)
time = 5040	action = 0	current_phase = 0	next_phase = 1	reward = 0.728934	array([[ 1.6478097, -7.2968707]], dtype=float32)
time = 5045	action = 0	current_phase = 0	next_phase = 1	reward = 1.009617	array([[ 1.7641141, -7.3931084]], dtype=float32)
time = 5050	action = 0	current_phase = 0	next_phase = 1	reward = 0.734367	array([[ 2.004525, -7.569976]], dtype=float32)
time = 5055	action = 0	current_phase = 0	next_phase = 1	reward = 0.724744	array([[ 1.8334448, -7.34387  ]], dtype=float32)
time = 5060	action = 0	current_phase = 0	next_phase = 1	reward = 0.718851	array([[ 1.8529141, -7.3721275]], dtype=float32)
time = 5065	action = 0	current_phase = 0	next_phase = 1	reward = 0.724909	array([[ 1.8468277, -7.339193 ]], dtype=float32)
time = 5070	action = 0	current_phase = 0	next_phase = 1	reward = 0.717590	array([[ 1.8470914, -7.3936357]], dtype=float32)
time = 5075	action = 0	current_phase = 0	next_phase = 1	reward = 0.714756	array([[ 1.9005353, -7.4336505]], dtype=float32)
time = 5080	action = 0	current_phase = 0	next_phase = 1	reward = 0.722858	array([[ 1.8530705, -7.4081388]], dtype=float32)
time = 5085	action = 0	current_phase = 0	next_phase = 1	reward = 0.732402	array([[ 1.7953165, -7.35261  ]], dtype=float32)
time = 5090	action = 0	current_phase = 0	next_phase = 1	reward = 0.452311	array([[ 1.8377397, -7.34818  ]], dtype=float32)
time = 5095	action = 0	current_phase = 0	next_phase = 1	reward = 1.010183	array([[ 1.7502997, -7.3243036]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 3s - loss: 8.6615 - val_loss: 4.6038
Epoch 2/50
 - 4s - loss: 8.6386 - val_loss: 6.0302
Epoch 3/50
 - 4s - loss: 8.2571 - val_loss: 5.4960
Epoch 4/50
 - 3s - loss: 8.3245 - val_loss: 5.9485
Epoch 5/50
 - 4s - loss: 8.5187 - val_loss: 5.9738
Epoch 6/50
 - 4s - loss: 9.2929 - val_loss: 5.6726
Epoch 7/50
 - 4s - loss: 9.2093 - val_loss: 6.0997
Epoch 8/50
 - 4s - loss: 8.5361 - val_loss: 4.4930
Epoch 9/50
 - 4s - loss: 8.2366 - val_loss: 4.9555
Epoch 10/50
 - 4s - loss: 8.4494 - val_loss: 4.7143
Epoch 11/50
 - 4s - loss: 8.0540 - val_loss: 5.2112
Epoch 12/50
 - 3s - loss: 7.9211 - val_loss: 4.7609
Epoch 13/50
 - 4s - loss: 8.6654 - val_loss: 6.7167
Epoch 14/50
 - 4s - loss: 8.1247 - val_loss: 5.4210
Epoch 15/50
 - 4s - loss: 7.4307 - val_loss: 5.1925
Epoch 16/50
 - 4s - loss: 8.0650 - val_loss: 5.4782
Epoch 17/50
 - 4s - loss: 8.7403 - val_loss: 4.9140
Epoch 18/50
 - 4s - loss: 7.9838 - val_loss: 6.0903
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 5100	action = 0	current_phase = 0	next_phase = 1	reward = 0.723134	array([[ 1.8866811, -7.3036366]], dtype=float32)
time = 5105	action = 0	current_phase = 0	next_phase = 1	reward = 0.722485	array([[ 1.8922772, -7.268631 ]], dtype=float32)
time = 5110	action = 0	current_phase = 0	next_phase = 1	reward = 0.720907	array([[ 1.9008489, -7.2816896]], dtype=float32)
time = 5115	action = 0	current_phase = 0	next_phase = 1	reward = 0.723152	array([[ 1.8787637, -7.2831645]], dtype=float32)
time = 5120	action = 0	current_phase = 0	next_phase = 1	reward = 0.718371	array([[ 2.037025, -7.498561]], dtype=float32)
time = 5125	action = 0	current_phase = 0	next_phase = 1	reward = 0.444496	array([[ 1.879364, -7.328923]], dtype=float32)
time = 5130	action = 0	current_phase = 0	next_phase = 1	reward = 1.005074	array([[ 1.8686104, -7.330766 ]], dtype=float32)
time = 5135	action = 0	current_phase = 0	next_phase = 1	reward = 0.450459	array([[ 1.9814343, -7.412466 ]], dtype=float32)
time = 5140	action = 0	current_phase = 0	next_phase = 1	reward = 1.002482	array([[ 1.9106236, -7.2889175]], dtype=float32)
time = 5145	action = 0	current_phase = 0	next_phase = 1	reward = 0.723487	array([[ 1.8648148, -7.300573 ]], dtype=float32)
time = 5150	action = 0	current_phase = 0	next_phase = 1	reward = 0.440194	array([[ 2.2573905, -7.7512646]], dtype=float32)
time = 5155	action = 0	current_phase = 0	next_phase = 1	reward = 1.006816	array([[ 1.8821316, -7.2991114]], dtype=float32)
time = 5160	action = 0	current_phase = 0	next_phase = 1	reward = 0.717596	array([[ 1.9020267, -7.287032 ]], dtype=float32)
time = 5165	action = 0	current_phase = 0	next_phase = 1	reward = 0.725912	array([[ 1.8868461, -7.277029 ]], dtype=float32)
time = 5170	action = 0	current_phase = 0	next_phase = 1	reward = 0.721380	array([[ 1.8557658, -7.273086 ]], dtype=float32)
time = 5175	action = 0	current_phase = 0	next_phase = 1	reward = 0.723355	array([[ 1.8746033, -7.2706194]], dtype=float32)
time = 5180	action = 0	current_phase = 0	next_phase = 1	reward = 0.722881	array([[ 1.9017091, -7.2980986]], dtype=float32)
time = 5185	action = 0	current_phase = 0	next_phase = 1	reward = 0.721742	array([[ 1.8878803, -7.3167973]], dtype=float32)
time = 5190	action = 0	current_phase = 0	next_phase = 1	reward = 0.725377	array([[ 1.8262858, -7.3316483]], dtype=float32)
time = 5195	action = 0	current_phase = 0	next_phase = 1	reward = 0.720536	array([[ 1.8989668, -7.3157   ]], dtype=float32)
time = 5200	action = 0	current_phase = 0	next_phase = 1	reward = 0.718713	array([[ 1.8995309, -7.264534 ]], dtype=float32)
time = 5205	action = 0	current_phase = 0	next_phase = 1	reward = 0.717253	array([[ 1.9152341, -7.3608923]], dtype=float32)
time = 5210	action = 0	current_phase = 0	next_phase = 1	reward = 0.446777	array([[ 2.1191115, -7.5552917]], dtype=float32)
time = 5215	action = 0	current_phase = 0	next_phase = 1	reward = 0.732184	array([[ 1.8715649, -7.2858114]], dtype=float32)
time = 5220	action = 0	current_phase = 0	next_phase = 1	reward = 1.007153	array([[ 1.7378716, -7.302136 ]], dtype=float32)
time = 5225	action = 0	current_phase = 0	next_phase = 1	reward = 0.723039	array([[ 1.8495469, -7.323799 ]], dtype=float32)
time = 5230	action = 0	current_phase = 0	next_phase = 1	reward = 0.722791	array([[ 1.888082 , -7.2887535]], dtype=float32)
time = 5235	action = 0	current_phase = 0	next_phase = 1	reward = 0.720066	array([[ 1.8394904, -7.2634177]], dtype=float32)
time = 5240	action = 0	current_phase = 0	next_phase = 1	reward = 0.450220	array([[ 1.8953276, -7.3004875]], dtype=float32)
time = 5245	action = 0	current_phase = 0	next_phase = 1	reward = 1.005162	array([[ 1.9155474, -7.3191795]], dtype=float32)
time = 5250	action = 0	current_phase = 0	next_phase = 1	reward = 0.723033	array([[ 1.8485589, -7.3387413]], dtype=float32)
time = 5255	action = 0	current_phase = 0	next_phase = 1	reward = 0.447933	array([[ 1.9038229, -7.276766 ]], dtype=float32)
time = 5260	action = 0	current_phase = 0	next_phase = 1	reward = 1.000876	array([[ 1.8169293, -7.318859 ]], dtype=float32)
time = 5265	action = 0	current_phase = 0	next_phase = 1	reward = 0.718151	array([[ 1.8894916, -7.346812 ]], dtype=float32)
time = 5270	action = 0	current_phase = 0	next_phase = 1	reward = 0.450843	array([[ 1.8747349, -7.2965956]], dtype=float32)
time = 5275	action = 0	current_phase = 0	next_phase = 1	reward = 1.012448	array([[ 1.9476628, -7.379261 ]], dtype=float32)
time = 5280	action = 0	current_phase = 0	next_phase = 1	reward = 0.728589	array([[ 1.8690004, -7.2715178]], dtype=float32)
time = 5285	action = 0	current_phase = 0	next_phase = 1	reward = 0.719270	array([[ 1.8439002, -7.293111 ]], dtype=float32)
time = 5290	action = 0	current_phase = 0	next_phase = 1	reward = 0.718585	array([[ 1.8939161, -7.2726126]], dtype=float32)
time = 5295	action = 0	current_phase = 0	next_phase = 1	reward = 0.719870	array([[ 1.9440293, -7.3434763]], dtype=float32)
time = 5300	action = 0	current_phase = 0	next_phase = 1	reward = 0.727511	array([[ 1.8199811, -7.2495227]], dtype=float32)
time = 5305	action = 0	current_phase = 0	next_phase = 1	reward = 0.721352	array([[ 1.8804531, -7.2818317]], dtype=float32)
time = 5310	action = 0	current_phase = 0	next_phase = 1	reward = 0.717837	array([[ 1.8504844, -7.308111 ]], dtype=float32)
time = 5315	action = 0	current_phase = 0	next_phase = 1	reward = 0.440151	array([[ 1.9184136, -7.289838 ]], dtype=float32)
time = 5320	action = 0	current_phase = 0	next_phase = 1	reward = 1.004987	array([[ 1.8838959, -7.287303 ]], dtype=float32)
time = 5325	action = 0	current_phase = 0	next_phase = 1	reward = 0.725320	array([[ 1.9484382, -7.3326845]], dtype=float32)
time = 5330	action = 0	current_phase = 0	next_phase = 1	reward = 0.442571	array([[ 1.9781728, -7.3938875]], dtype=float32)
time = 5335	action = 0	current_phase = 0	next_phase = 1	reward = 1.000498	array([[ 1.7668071, -7.38958  ]], dtype=float32)
time = 5340	action = 0	current_phase = 0	next_phase = 1	reward = 0.718028	array([[ 1.9763155, -7.3766975]], dtype=float32)
time = 5345	action = 0	current_phase = 0	next_phase = 1	reward = 0.444670	array([[ 1.8870769, -7.3489656]], dtype=float32)
time = 5350	action = 0	current_phase = 0	next_phase = 1	reward = 0.723752	array([[ 1.8643165, -7.294128 ]], dtype=float32)
time = 5355	action = 0	current_phase = 0	next_phase = 1	reward = 0.728801	array([[ 1.8249583, -7.3246655]], dtype=float32)
time = 5360	action = 0	current_phase = 0	next_phase = 1	reward = 1.002455	array([[ 2.1387439, -7.7991285]], dtype=float32)
time = 5365	action = 0	current_phase = 0	next_phase = 1	reward = 0.713179	array([[ 1.9702516, -7.424203 ]], dtype=float32)
time = 5370	action = 0	current_phase = 0	next_phase = 1	reward = 0.448146	array([[ 1.8476257, -7.2924137]], dtype=float32)
time = 5375	action = 0	current_phase = 0	next_phase = 1	reward = 0.734170	array([[ 1.884706 , -7.4407935]], dtype=float32)
time = 5380	action = 0	current_phase = 0	next_phase = 1	reward = 0.730048	array([[ 1.8750339, -7.254165 ]], dtype=float32)
time = 5385	action = 0	current_phase = 0	next_phase = 1	reward = 0.998166	array([[ 1.9027147, -7.345434 ]], dtype=float32)
time = 5390	action = 0	current_phase = 0	next_phase = 1	reward = 0.436536	array([[ 1.9066  , -7.301857]], dtype=float32)
time = 5395	action = 0	current_phase = 0	next_phase = 1	reward = 1.004693	array([[ 1.9298902, -7.3398237]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 3s - loss: 6.3810 - val_loss: 11.7813
Epoch 2/50
 - 4s - loss: 5.5353 - val_loss: 10.1057
Epoch 3/50
 - 4s - loss: 5.7552 - val_loss: 9.2772
Epoch 4/50
 - 4s - loss: 5.4998 - val_loss: 11.0756
Epoch 5/50
 - 4s - loss: 5.2628 - val_loss: 9.4233
Epoch 6/50
 - 3s - loss: 5.1048 - val_loss: 10.1804
Epoch 7/50
 - 3s - loss: 4.6433 - val_loss: 10.4769
Epoch 8/50
 - 4s - loss: 5.7650 - val_loss: 10.9659
Epoch 9/50
 - 4s - loss: 5.1663 - val_loss: 8.5581
Epoch 10/50
 - 4s - loss: 4.3796 - val_loss: 9.0300
Epoch 11/50
 - 4s - loss: 5.0631 - val_loss: 9.0247
Epoch 12/50
 - 4s - loss: 5.8518 - val_loss: 9.2057
Epoch 13/50
 - 4s - loss: 5.2040 - val_loss: 9.1021
Epoch 14/50
 - 4s - loss: 4.7736 - val_loss: 8.7095
Epoch 15/50
 - 4s - loss: 4.6803 - val_loss: 8.5952
Epoch 16/50
 - 4s - loss: 4.8139 - val_loss: 8.7604
Epoch 17/50
 - 4s - loss: 5.1505 - val_loss: 9.2048
Epoch 18/50
 - 4s - loss: 4.3223 - val_loss: 9.3518
Epoch 19/50
 - 4s - loss: 4.3111 - val_loss: 8.5960
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 5400	action = 0	current_phase = 0	next_phase = 1	reward = 0.721268	array([[ 1.9755676, -7.366729 ]], dtype=float32)
time = 5405	action = 0	current_phase = 0	next_phase = 1	reward = 0.445563	array([[ 1.9392145, -7.3767815]], dtype=float32)
time = 5410	action = 0	current_phase = 0	next_phase = 1	reward = 1.007084	array([[ 2.0407183, -7.4943557]], dtype=float32)
time = 5415	action = 0	current_phase = 0	next_phase = 1	reward = 0.720350	array([[ 1.9510343, -7.418509 ]], dtype=float32)
time = 5420	action = 0	current_phase = 0	next_phase = 1	reward = 0.450030	array([[ 1.9138825, -7.359462 ]], dtype=float32)
time = 5425	action = 0	current_phase = 0	next_phase = 1	reward = 0.457941	array([[ 1.9039681, -7.359251 ]], dtype=float32)
time = 5430	action = 0	current_phase = 0	next_phase = 1	reward = 1.284354	array([[ 1.9359591, -7.5102844]], dtype=float32)
time = 5435	action = 0	current_phase = 0	next_phase = 1	reward = 0.451519	array([[ 1.9054401, -7.276703 ]], dtype=float32)
time = 5440	action = 0	current_phase = 0	next_phase = 1	reward = 1.008793	array([[ 1.9265554, -7.3103   ]], dtype=float32)
time = 5445	action = 0	current_phase = 0	next_phase = 1	reward = 0.722344	array([[ 1.918555, -7.269341]], dtype=float32)
time = 5450	action = 0	current_phase = 0	next_phase = 1	reward = 0.719781	array([[ 1.802727 , -7.2512655]], dtype=float32)
time = 5455	action = 0	current_phase = 0	next_phase = 1	reward = 0.721701	array([[ 1.9461558, -7.3235054]], dtype=float32)
time = 5460	action = 0	current_phase = 0	next_phase = 1	reward = 0.727941	array([[ 1.9542162, -7.3549323]], dtype=float32)
time = 5465	action = 0	current_phase = 0	next_phase = 1	reward = 0.721896	array([[ 1.9030225, -7.327366 ]], dtype=float32)
time = 5470	action = 0	current_phase = 0	next_phase = 1	reward = 0.718177	array([[ 1.8803465, -7.299899 ]], dtype=float32)
time = 5475	action = 0	current_phase = 0	next_phase = 1	reward = 0.726651	array([[ 1.8350818, -7.3123465]], dtype=float32)
time = 5480	action = 0	current_phase = 0	next_phase = 1	reward = 0.722006	array([[ 1.8743565, -7.2879066]], dtype=float32)
time = 5485	action = 0	current_phase = 0	next_phase = 1	reward = 0.451806	array([[ 1.9039295, -7.3019066]], dtype=float32)
time = 5490	action = 0	current_phase = 0	next_phase = 1	reward = 1.004704	array([[ 1.8616207, -7.306221 ]], dtype=float32)
time = 5495	action = 0	current_phase = 0	next_phase = 1	reward = 0.729494	array([[ 1.9129107, -7.330725 ]], dtype=float32)
time = 5500	action = 0	current_phase = 0	next_phase = 1	reward = 0.719979	array([[ 1.9139307, -7.30045  ]], dtype=float32)
time = 5505	action = 0	current_phase = 0	next_phase = 1	reward = 0.721567	array([[ 1.928982, -7.289304]], dtype=float32)
time = 5510	action = 0	current_phase = 0	next_phase = 1	reward = 0.721016	array([[ 1.9370782, -7.2935486]], dtype=float32)
time = 5515	action = 0	current_phase = 0	next_phase = 1	reward = 0.442296	array([[ 1.9453743, -7.3395166]], dtype=float32)
time = 5520	action = 0	current_phase = 0	next_phase = 1	reward = 0.721891	array([[ 1.9076259, -7.2935486]], dtype=float32)
time = 5525	action = 0	current_phase = 0	next_phase = 1	reward = 1.000229	array([[ 1.9544427, -7.3509765]], dtype=float32)
time = 5530	action = 0	current_phase = 0	next_phase = 1	reward = 0.720800	array([[ 1.8879716, -7.420682 ]], dtype=float32)
time = 5535	action = 0	current_phase = 0	next_phase = 1	reward = 0.445657	array([[ 1.9176743, -7.2775164]], dtype=float32)
time = 5540	action = 0	current_phase = 0	next_phase = 1	reward = 1.003437	array([[ 1.8586471, -7.346209 ]], dtype=float32)
time = 5545	action = 0	current_phase = 0	next_phase = 1	reward = 0.710921	array([[ 1.9132783, -7.30957  ]], dtype=float32)
time = 5550	action = 0	current_phase = 0	next_phase = 1	reward = 0.715350	array([[ 2.0033777, -7.3895774]], dtype=float32)
time = 5555	action = 0	current_phase = 0	next_phase = 1	reward = 0.444520	array([[ 2.0850837, -7.609012 ]], dtype=float32)
time = 5560	action = 0	current_phase = 0	next_phase = 1	reward = 0.727477	array([[ 1.9524357, -7.32528  ]], dtype=float32)
time = 5565	action = 0	current_phase = 0	next_phase = 1	reward = 0.725767	array([[ 1.8577192, -7.3792105]], dtype=float32)
time = 5570	action = 0	current_phase = 0	next_phase = 1	reward = 0.728968	array([[ 2.2050383, -7.683298 ]], dtype=float32)
time = 5575	action = 0	current_phase = 0	next_phase = 1	reward = 0.730400	array([[ 2.58063 , -8.151245]], dtype=float32)
time = 5580	action = 0	current_phase = 0	next_phase = 1	reward = 1.003214	array([[ 1.8051379, -7.4558234]], dtype=float32)
time = 5585	action = 0	current_phase = 0	next_phase = 1	reward = 0.451305	array([[ 1.9145601, -7.295434 ]], dtype=float32)
time = 5590	action = 0	current_phase = 0	next_phase = 1	reward = 1.006975	array([[ 1.8746574, -7.300393 ]], dtype=float32)
time = 5595	action = 0	current_phase = 0	next_phase = 1	reward = 0.726083	array([[ 1.8321378, -7.319351 ]], dtype=float32)
time = 5600	action = 0	current_phase = 0	next_phase = 1	reward = 0.720736	array([[ 1.9448559, -7.342136 ]], dtype=float32)
time = 5605	action = 0	current_phase = 0	next_phase = 1	reward = 0.722381	array([[ 1.7937157, -7.3615427]], dtype=float32)
time = 5610	action = 0	current_phase = 0	next_phase = 1	reward = 0.724841	array([[ 1.9209802, -7.2861605]], dtype=float32)
time = 5615	action = 0	current_phase = 0	next_phase = 1	reward = 0.718665	array([[ 1.9227164, -7.2740455]], dtype=float32)
time = 5620	action = 0	current_phase = 0	next_phase = 1	reward = 0.717850	array([[ 1.8510115, -7.37426  ]], dtype=float32)
time = 5625	action = 0	current_phase = 0	next_phase = 1	reward = 0.716229	array([[ 1.8732994, -7.35929  ]], dtype=float32)
time = 5630	action = 0	current_phase = 0	next_phase = 1	reward = 0.172267	array([[ 1.9251482, -7.3162794]], dtype=float32)
time = 5635	action = 0	current_phase = 0	next_phase = 1	reward = 1.294610	array([[ 1.9153116, -7.3011017]], dtype=float32)
time = 5640	action = 0	current_phase = 0	next_phase = 1	reward = 0.729491	array([[ 1.8579996, -7.2982864]], dtype=float32)
time = 5645	action = 0	current_phase = 0	next_phase = 1	reward = 0.446858	array([[ 1.8911893, -7.282746 ]], dtype=float32)
time = 5650	action = 0	current_phase = 0	next_phase = 1	reward = 0.999024	array([[ 1.9183843, -7.28701  ]], dtype=float32)
time = 5655	action = 0	current_phase = 0	next_phase = 1	reward = 0.714868	array([[ 1.8940022, -7.293537 ]], dtype=float32)
time = 5660	action = 0	current_phase = 0	next_phase = 1	reward = 0.438377	array([[ 1.9495237, -7.300393 ]], dtype=float32)
time = 5665	action = 0	current_phase = 0	next_phase = 1	reward = 0.997220	array([[ 1.9739196, -7.3370085]], dtype=float32)
time = 5670	action = 0	current_phase = 0	next_phase = 1	reward = 0.441452	array([[ 1.8913805, -7.3125277]], dtype=float32)
time = 5675	action = 0	current_phase = 0	next_phase = 1	reward = 0.731308	array([[ 1.7506278, -7.256114 ]], dtype=float32)
time = 5680	action = 0	current_phase = 0	next_phase = 1	reward = 1.013836	array([[ 1.9167225, -7.336372 ]], dtype=float32)
time = 5685	action = 0	current_phase = 0	next_phase = 1	reward = 0.721859	array([[ 1.9265397, -7.2855997]], dtype=float32)
time = 5690	action = 0	current_phase = 0	next_phase = 1	reward = 0.722219	array([[ 1.9375746, -7.2914867]], dtype=float32)
time = 5695	action = 0	current_phase = 0	next_phase = 1	reward = 0.728123	array([[ 1.883075, -7.338455]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 6.8058 - val_loss: 3.3386
Epoch 2/50
 - 4s - loss: 7.2755 - val_loss: 4.2010
Epoch 3/50
 - 4s - loss: 7.0947 - val_loss: 4.2071
Epoch 4/50
 - 4s - loss: 6.4926 - val_loss: 4.4090
Epoch 5/50
 - 4s - loss: 6.9555 - val_loss: 4.4849
Epoch 6/50
 - 4s - loss: 7.0870 - val_loss: 3.7167
Epoch 7/50
 - 4s - loss: 6.7809 - val_loss: 4.1987
Epoch 8/50
 - 4s - loss: 6.4017 - val_loss: 4.5940
Epoch 9/50
 - 4s - loss: 6.6361 - val_loss: 4.2620
Epoch 10/50
 - 4s - loss: 6.4529 - val_loss: 4.0443
Epoch 11/50
 - 4s - loss: 6.6153 - val_loss: 4.1577
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 5700	action = 0	current_phase = 0	next_phase = 1	reward = 0.719211	array([[ 1.9121206, -7.3647337]], dtype=float32)
time = 5705	action = 0	current_phase = 0	next_phase = 1	reward = 0.439247	array([[ 1.9141285, -7.3696713]], dtype=float32)
time = 5710	action = 0	current_phase = 0	next_phase = 1	reward = 0.723925	array([[ 1.9268167, -7.3873396]], dtype=float32)
time = 5715	action = 0	current_phase = 0	next_phase = 1	reward = 1.003004	array([[ 1.913101, -7.35437 ]], dtype=float32)
time = 5720	action = 0	current_phase = 0	next_phase = 1	reward = 0.728339	array([[ 1.9279034, -7.3718357]], dtype=float32)
time = 5725	action = 0	current_phase = 0	next_phase = 1	reward = 0.718035	array([[ 1.8887298, -7.458847 ]], dtype=float32)
time = 5730	action = 0	current_phase = 0	next_phase = 1	reward = 0.449189	array([[ 1.879462 , -7.3913956]], dtype=float32)
time = 5735	action = 0	current_phase = 0	next_phase = 1	reward = 0.729405	array([[ 1.8403823, -7.3877277]], dtype=float32)
time = 5740	action = 0	current_phase = 0	next_phase = 1	reward = 1.011124	array([[ 1.8920634, -7.3597565]], dtype=float32)
time = 5745	action = 0	current_phase = 0	next_phase = 1	reward = 0.719859	array([[ 1.926492 , -7.3679423]], dtype=float32)
time = 5750	action = 0	current_phase = 0	next_phase = 1	reward = 0.719909	array([[ 1.9302657, -7.357257 ]], dtype=float32)
time = 5755	action = 0	current_phase = 0	next_phase = 1	reward = 0.717856	array([[ 1.8899148, -7.397566 ]], dtype=float32)
time = 5760	action = 0	current_phase = 0	next_phase = 1	reward = 0.731907	array([[ 1.9103568, -7.393981 ]], dtype=float32)
time = 5765	action = 0	current_phase = 0	next_phase = 1	reward = 0.732045	array([[ 1.9314325, -7.3628197]], dtype=float32)
time = 5770	action = 0	current_phase = 0	next_phase = 1	reward = 0.441036	array([[ 1.9251821, -7.3917484]], dtype=float32)
time = 5775	action = 0	current_phase = 0	next_phase = 1	reward = 1.000375	array([[ 1.9604547, -7.3938093]], dtype=float32)
time = 5780	action = 0	current_phase = 0	next_phase = 1	reward = 0.716051	array([[ 1.9719799, -7.4188833]], dtype=float32)
time = 5785	action = 0	current_phase = 0	next_phase = 1	reward = 0.716555	array([[ 1.8480675, -7.386399 ]], dtype=float32)
time = 5790	action = 0	current_phase = 0	next_phase = 1	reward = 0.163865	array([[ 1.8975699, -7.363944 ]], dtype=float32)
time = 5795	action = 0	current_phase = 0	next_phase = 1	reward = 1.274664	array([[ 1.8445785, -7.3947086]], dtype=float32)
time = 5800	action = 0	current_phase = 0	next_phase = 1	reward = 0.714241	array([[ 1.887727 , -7.3331184]], dtype=float32)
time = 5805	action = 0	current_phase = 0	next_phase = 1	reward = 0.441332	array([[ 1.9313514, -7.3411365]], dtype=float32)
time = 5810	action = 0	current_phase = 0	next_phase = 1	reward = 0.729629	array([[ 1.9141195, -7.3957405]], dtype=float32)
time = 5815	action = 0	current_phase = 0	next_phase = 1	reward = 1.008931	array([[ 1.9123805, -7.368485 ]], dtype=float32)
time = 5820	action = 0	current_phase = 0	next_phase = 1	reward = 0.726707	array([[ 1.9336121, -7.355604 ]], dtype=float32)
time = 5825	action = 0	current_phase = 0	next_phase = 1	reward = 0.715371	array([[ 1.944504 , -7.3439274]], dtype=float32)
time = 5830	action = 0	current_phase = 0	next_phase = 1	reward = 0.451911	array([[ 1.9164984, -7.4149456]], dtype=float32)
time = 5835	action = 0	current_phase = 0	next_phase = 1	reward = 0.720476	array([[ 1.896076 , -7.3669834]], dtype=float32)
time = 5840	action = 0	current_phase = 0	next_phase = 1	reward = 0.999756	array([[ 1.8731663, -7.4225893]], dtype=float32)
time = 5845	action = 0	current_phase = 0	next_phase = 1	reward = 0.713930	array([[ 1.9975083, -7.4428267]], dtype=float32)
time = 5850	action = 0	current_phase = 0	next_phase = 1	reward = 0.724246	array([[ 1.9568255, -7.4625244]], dtype=float32)
time = 5855	action = 0	current_phase = 0	next_phase = 1	reward = 0.178368	array([[ 1.6572931, -7.239014 ]], dtype=float32)
time = 5860	action = 0	current_phase = 0	next_phase = 1	reward = 1.285078	array([[ 1.8850815, -7.4044366]], dtype=float32)
time = 5865	action = 0	current_phase = 0	next_phase = 1	reward = 0.724039	array([[ 1.9432642, -7.3489075]], dtype=float32)
time = 5870	action = 0	current_phase = 0	next_phase = 1	reward = 0.442447	array([[ 1.9478652, -7.344563 ]], dtype=float32)
time = 5875	action = 0	current_phase = 0	next_phase = 1	reward = 0.722284	array([[ 1.9810479, -7.4829173]], dtype=float32)
time = 5880	action = 0	current_phase = 0	next_phase = 1	reward = 0.728735	array([[ 1.9108484, -7.3923345]], dtype=float32)
time = 5885	action = 0	current_phase = 0	next_phase = 1	reward = 1.004513	array([[ 1.9660776, -7.6182213]], dtype=float32)
time = 5890	action = 0	current_phase = 0	next_phase = 1	reward = 0.722829	array([[ 1.9316776, -7.375309 ]], dtype=float32)
time = 5895	action = 0	current_phase = 0	next_phase = 1	reward = 0.440370	array([[ 1.8907025, -7.407502 ]], dtype=float32)
time = 5900	action = 0	current_phase = 0	next_phase = 1	reward = 1.011841	array([[ 1.9124315, -7.4051075]], dtype=float32)
time = 5905	action = 0	current_phase = 0	next_phase = 1	reward = 0.446754	array([[ 1.9643042, -7.419105 ]], dtype=float32)
time = 5910	action = 0	current_phase = 0	next_phase = 1	reward = 0.727358	array([[ 1.9309165, -7.372281 ]], dtype=float32)
time = 5915	action = 0	current_phase = 0	next_phase = 1	reward = 1.001852	array([[ 1.8758452, -7.3926163]], dtype=float32)
time = 5920	action = 0	current_phase = 0	next_phase = 1	reward = 0.717088	array([[ 1.7870057, -7.4337206]], dtype=float32)
time = 5925	action = 0	current_phase = 0	next_phase = 1	reward = 0.447643	array([[ 1.8509805, -7.427228 ]], dtype=float32)
time = 5930	action = 0	current_phase = 0	next_phase = 1	reward = 1.005053	array([[ 2.0617812, -7.587791 ]], dtype=float32)
time = 5935	action = 0	current_phase = 0	next_phase = 1	reward = 0.442203	array([[ 1.9162786, -7.374976 ]], dtype=float32)
time = 5940	action = 0	current_phase = 0	next_phase = 1	reward = 0.731554	array([[ 1.9028122, -7.3916636]], dtype=float32)
time = 5945	action = 0	current_phase = 0	next_phase = 1	reward = 1.004791	array([[ 1.9296229, -7.429072 ]], dtype=float32)
time = 5950	action = 0	current_phase = 0	next_phase = 1	reward = 0.720351	array([[ 1.8922875, -7.3800526]], dtype=float32)
time = 5955	action = 0	current_phase = 0	next_phase = 1	reward = 0.726400	array([[ 2.2239563, -7.9644976]], dtype=float32)
time = 5960	action = 0	current_phase = 0	next_phase = 1	reward = 0.165941	array([[ 1.8681943, -7.409335 ]], dtype=float32)
time = 5965	action = 0	current_phase = 0	next_phase = 1	reward = 1.283142	array([[ 1.7108915, -7.642726 ]], dtype=float32)
time = 5970	action = 0	current_phase = 0	next_phase = 1	reward = 0.718093	array([[ 1.8692343, -7.371889 ]], dtype=float32)
time = 5975	action = 0	current_phase = 0	next_phase = 1	reward = 0.449925	array([[ 1.9968379, -7.4604893]], dtype=float32)
time = 5980	action = 0	current_phase = 0	next_phase = 1	reward = 0.735646	array([[ 1.59038 , -7.231624]], dtype=float32)
time = 5985	action = 0	current_phase = 0	next_phase = 1	reward = 1.003780	array([[ 1.8732474, -7.5023394]], dtype=float32)
time = 5990	action = 0	current_phase = 0	next_phase = 1	reward = 0.721974	array([[ 1.8694298, -7.4258566]], dtype=float32)
time = 5995	action = 0	current_phase = 0	next_phase = 1	reward = 0.721793	array([[ 1.8659556, -7.340133 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 9.3263 - val_loss: 3.2006
Epoch 2/50
 - 4s - loss: 8.0581 - val_loss: 3.4541
Epoch 3/50
 - 4s - loss: 7.7059 - val_loss: 3.4282
Epoch 4/50
 - 4s - loss: 7.3658 - val_loss: 3.1703
Epoch 5/50
 - 4s - loss: 8.9632 - val_loss: 3.7840
Epoch 6/50
 - 4s - loss: 7.9512 - val_loss: 3.5702
Epoch 7/50
 - 4s - loss: 8.9838 - val_loss: 4.5908
Epoch 8/50
 - 4s - loss: 7.7826 - val_loss: 3.6323
Epoch 9/50
 - 4s - loss: 7.8027 - val_loss: 5.9277
Epoch 10/50
 - 4s - loss: 7.6100 - val_loss: 4.2337
Epoch 11/50
 - 4s - loss: 7.9265 - val_loss: 3.8425
Epoch 12/50
 - 4s - loss: 7.5249 - val_loss: 3.4783
Epoch 13/50
 - 4s - loss: 7.7252 - val_loss: 3.1075
Epoch 14/50
 - 4s - loss: 6.5849 - val_loss: 4.0649
Epoch 15/50
 - 4s - loss: 7.0574 - val_loss: 3.5869
Epoch 16/50
 - 4s - loss: 7.3047 - val_loss: 3.5121
Epoch 17/50
 - 4s - loss: 6.6743 - val_loss: 3.4446
Epoch 18/50
 - 4s - loss: 7.5699 - val_loss: 4.0198
Epoch 19/50
 - 4s - loss: 8.3255 - val_loss: 3.6804
Epoch 20/50
 - 5s - loss: 7.2390 - val_loss: 3.8238
Epoch 21/50
 - 4s - loss: 7.4364 - val_loss: 5.2935
Epoch 22/50
 - 4s - loss: 6.8708 - val_loss: 4.4867
Epoch 23/50
 - 4s - loss: 7.2653 - val_loss: 3.2377
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 6000	action = 0	current_phase = 0	next_phase = 1	reward = 0.725232	array([[ 1.9972923, -7.458314 ]], dtype=float32)
time = 6005	action = 0	current_phase = 0	next_phase = 1	reward = 0.440171	array([[ 1.955416, -7.425478]], dtype=float32)
time = 6010	action = 0	current_phase = 0	next_phase = 1	reward = 0.994299	array([[ 1.9412401, -7.4592104]], dtype=float32)
time = 6015	action = 0	current_phase = 0	next_phase = 1	reward = 0.715682	array([[ 1.9895971, -7.4953423]], dtype=float32)
time = 6020	action = 0	current_phase = 0	next_phase = 1	reward = 0.728706	array([[ 1.9501803, -7.4287987]], dtype=float32)
time = 6025	action = 0	current_phase = 0	next_phase = 1	reward = 0.719599	array([[ 1.8750994, -7.4824038]], dtype=float32)
time = 6030	action = 0	current_phase = 0	next_phase = 1	reward = 0.450223	array([[ 1.9065611, -7.4254193]], dtype=float32)
time = 6035	action = 0	current_phase = 0	next_phase = 1	reward = 1.004103	array([[ 1.9431608, -7.4437456]], dtype=float32)
time = 6040	action = 0	current_phase = 0	next_phase = 1	reward = 0.724230	array([[ 1.904136 , -7.4184294]], dtype=float32)
time = 6045	action = 0	current_phase = 0	next_phase = 1	reward = 0.725675	array([[ 1.9287589, -7.4145107]], dtype=float32)
time = 6050	action = 0	current_phase = 0	next_phase = 1	reward = 0.443446	array([[ 1.9001458, -7.4272413]], dtype=float32)
time = 6055	action = 0	current_phase = 0	next_phase = 1	reward = 0.993858	array([[ 1.8866694, -7.4430237]], dtype=float32)
time = 6060	action = 0	current_phase = 0	next_phase = 1	reward = 0.446948	array([[ 1.9136136, -7.417342 ]], dtype=float32)
time = 6065	action = 0	current_phase = 0	next_phase = 1	reward = 1.000879	array([[ 1.951761 , -7.4359827]], dtype=float32)
time = 6070	action = 0	current_phase = 0	next_phase = 1	reward = 0.711314	array([[ 2.0275457, -7.6095204]], dtype=float32)
time = 6075	action = 0	current_phase = 0	next_phase = 1	reward = 0.435097	array([[ 1.9500682, -7.4248357]], dtype=float32)
time = 6080	action = 0	current_phase = 0	next_phase = 1	reward = 1.008630	array([[ 1.8980353, -7.6113167]], dtype=float32)
time = 6085	action = 0	current_phase = 0	next_phase = 1	reward = 0.440901	array([[ 1.9587686, -7.439021 ]], dtype=float32)
time = 6090	action = 0	current_phase = 0	next_phase = 1	reward = 1.003308	array([[ 1.954601, -7.430068]], dtype=float32)
time = 6095	action = 0	current_phase = 0	next_phase = 1	reward = 0.725924	array([[ 1.8897893, -7.4549694]], dtype=float32)
time = 6100	action = 0	current_phase = 0	next_phase = 1	reward = 0.456919	array([[ 1.945946 , -7.3783255]], dtype=float32)
time = 6105	action = 0	current_phase = 0	next_phase = 1	reward = 1.004995	array([[ 1.9927957, -7.4196415]], dtype=float32)
time = 6110	action = 0	current_phase = 0	next_phase = 1	reward = 0.724603	array([[ 1.9401815, -7.4105005]], dtype=float32)
time = 6115	action = 0	current_phase = 0	next_phase = 1	reward = 0.717514	array([[ 1.96225 , -7.422488]], dtype=float32)
time = 6120	action = 0	current_phase = 0	next_phase = 1	reward = 0.716503	array([[ 1.9398401, -7.4563427]], dtype=float32)
time = 6125	action = 0	current_phase = 0	next_phase = 1	reward = 0.718287	array([[ 1.9502361, -7.4066477]], dtype=float32)
time = 6130	action = 0	current_phase = 0	next_phase = 1	reward = 0.444230	array([[ 1.9426572, -7.4512177]], dtype=float32)
time = 6135	action = 0	current_phase = 0	next_phase = 1	reward = 1.004527	array([[ 1.9232595, -7.428508 ]], dtype=float32)
time = 6140	action = 0	current_phase = 0	next_phase = 1	reward = 0.722458	array([[ 1.9994586, -7.47567  ]], dtype=float32)
time = 6145	action = 0	current_phase = 0	next_phase = 1	reward = 0.719248	array([[ 1.9411519, -7.418503 ]], dtype=float32)
time = 6150	action = 0	current_phase = 0	next_phase = 1	reward = 0.720181	array([[ 1.9348857, -7.4132357]], dtype=float32)
time = 6155	action = 0	current_phase = 0	next_phase = 1	reward = 0.716968	array([[ 1.9693463, -7.457735 ]], dtype=float32)
time = 6160	action = 0	current_phase = 0	next_phase = 1	reward = 0.443657	array([[ 1.9067624, -7.4371853]], dtype=float32)
time = 6165	action = 0	current_phase = 0	next_phase = 1	reward = 1.005975	array([[ 2.0670278, -7.695389 ]], dtype=float32)
time = 6170	action = 0	current_phase = 0	next_phase = 1	reward = 0.439867	array([[ 1.9153888, -7.448306 ]], dtype=float32)
time = 6175	action = 0	current_phase = 0	next_phase = 1	reward = 1.015614	array([[ 1.9075606, -7.4803257]], dtype=float32)
time = 6180	action = 0	current_phase = 0	next_phase = 1	reward = 0.716999	array([[ 2.0336998, -7.5751386]], dtype=float32)
time = 6185	action = 0	current_phase = 0	next_phase = 1	reward = 0.439871	array([[ 1.9552963, -7.409075 ]], dtype=float32)
time = 6190	action = 0	current_phase = 0	next_phase = 1	reward = 1.003799	array([[ 1.9529469, -7.4813337]], dtype=float32)
time = 6195	action = 0	current_phase = 0	next_phase = 1	reward = 0.725253	array([[ 1.9308169, -7.4541492]], dtype=float32)
time = 6200	action = 0	current_phase = 0	next_phase = 1	reward = 0.719844	array([[ 1.9626548, -7.4558544]], dtype=float32)
time = 6205	action = 0	current_phase = 0	next_phase = 1	reward = 0.448379	array([[ 1.9037006, -7.4641733]], dtype=float32)
time = 6210	action = 0	current_phase = 0	next_phase = 1	reward = 0.724008	array([[ 1.8691156, -7.4539075]], dtype=float32)
time = 6215	action = 0	current_phase = 0	next_phase = 1	reward = 1.004661	array([[ 1.8936484, -7.539008 ]], dtype=float32)
time = 6220	action = 0	current_phase = 0	next_phase = 1	reward = 0.716522	array([[ 1.9957869, -7.4498167]], dtype=float32)
time = 6225	action = 0	current_phase = 0	next_phase = 1	reward = 0.727959	array([[ 1.9336178, -7.4085298]], dtype=float32)
time = 6230	action = 0	current_phase = 0	next_phase = 1	reward = 0.715368	array([[ 1.937022, -7.413504]], dtype=float32)
time = 6235	action = 0	current_phase = 0	next_phase = 1	reward = 0.439619	array([[ 1.9386613, -7.441376 ]], dtype=float32)
time = 6240	action = 0	current_phase = 0	next_phase = 1	reward = 1.011841	array([[ 1.9893  , -7.509514]], dtype=float32)
time = 6245	action = 0	current_phase = 0	next_phase = 1	reward = 0.725305	array([[ 1.9843872, -7.437774 ]], dtype=float32)
time = 6250	action = 0	current_phase = 0	next_phase = 1	reward = 0.723176	array([[ 1.9414804, -7.4314456]], dtype=float32)
time = 6255	action = 0	current_phase = 0	next_phase = 1	reward = 0.726198	array([[ 1.9322321, -7.4454193]], dtype=float32)
time = 6260	action = 0	current_phase = 0	next_phase = 1	reward = 0.717702	array([[ 1.9684803, -7.4647913]], dtype=float32)
time = 6265	action = 0	current_phase = 0	next_phase = 1	reward = 0.715000	array([[ 1.9782355, -7.4581614]], dtype=float32)
time = 6270	action = 0	current_phase = 0	next_phase = 1	reward = 0.713182	array([[ 1.9986289, -7.519538 ]], dtype=float32)
time = 6275	action = 0	current_phase = 0	next_phase = 1	reward = 0.722812	array([[ 1.951597, -7.428641]], dtype=float32)
time = 6280	action = 0	current_phase = 0	next_phase = 1	reward = 0.724547	array([[ 1.92397  , -7.4249086]], dtype=float32)
time = 6285	action = 0	current_phase = 0	next_phase = 1	reward = 0.448644	array([[ 1.8764446, -7.405595 ]], dtype=float32)
time = 6290	action = 0	current_phase = 0	next_phase = 1	reward = 1.003702	array([[ 1.9465091, -7.4144053]], dtype=float32)
time = 6295	action = 0	current_phase = 0	next_phase = 1	reward = 0.728381	array([[ 1.8517711, -7.485588 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 8.6179 - val_loss: 5.7973
Epoch 2/50
 - 4s - loss: 7.1122 - val_loss: 7.2340
Epoch 3/50
 - 4s - loss: 7.6360 - val_loss: 5.6217
Epoch 4/50
 - 4s - loss: 7.3488 - val_loss: 5.9273
Epoch 5/50
 - 4s - loss: 6.8106 - val_loss: 5.5474
Epoch 6/50
 - 4s - loss: 7.4383 - val_loss: 6.0290
Epoch 7/50
 - 4s - loss: 7.4672 - val_loss: 5.1034
Epoch 8/50
 - 4s - loss: 6.9115 - val_loss: 5.3017
Epoch 9/50
 - 4s - loss: 6.0184 - val_loss: 5.6035
Epoch 10/50
 - 4s - loss: 5.8235 - val_loss: 4.8849
Epoch 11/50
 - 4s - loss: 6.5605 - val_loss: 5.5615
Epoch 12/50
 - 4s - loss: 6.5046 - val_loss: 6.2705
Epoch 13/50
 - 4s - loss: 5.9683 - val_loss: 4.9948
Epoch 14/50
 - 4s - loss: 6.2077 - val_loss: 5.8630
Epoch 15/50
 - 4s - loss: 5.9430 - val_loss: 5.2820
Epoch 16/50
 - 4s - loss: 5.7345 - val_loss: 5.8657
Epoch 17/50
 - 4s - loss: 6.2122 - val_loss: 5.4753
Epoch 18/50
 - 4s - loss: 5.7594 - val_loss: 5.2342
Epoch 19/50
 - 4s - loss: 6.2531 - val_loss: 7.3295
Epoch 20/50
 - 4s - loss: 5.7473 - val_loss: 5.9341
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 6300	action = 0	current_phase = 0	next_phase = 1	reward = 0.717956	array([[ 2.2577963, -7.4300528]], dtype=float32)
time = 6305	action = 0	current_phase = 0	next_phase = 1	reward = 0.443781	array([[ 2.3001328, -7.4538064]], dtype=float32)
time = 6310	action = 0	current_phase = 0	next_phase = 1	reward = 1.018933	array([[ 2.2305727, -7.3883767]], dtype=float32)
time = 6315	action = 0	current_phase = 0	next_phase = 1	reward = 0.725648	array([[ 2.3610053, -7.6021013]], dtype=float32)
time = 6320	action = 0	current_phase = 0	next_phase = 1	reward = 0.437381	array([[ 2.2698731, -7.4010572]], dtype=float32)
time = 6325	action = 0	current_phase = 0	next_phase = 1	reward = 1.001353	array([[ 2.1603851, -7.485668 ]], dtype=float32)
time = 6330	action = 0	current_phase = 0	next_phase = 1	reward = 0.442077	array([[ 2.194018 , -7.4204464]], dtype=float32)
time = 6335	action = 0	current_phase = 0	next_phase = 1	reward = 1.003852	array([[ 2.3181167, -7.4509025]], dtype=float32)
time = 6340	action = 0	current_phase = 0	next_phase = 1	reward = 0.444852	array([[ 2.2504687, -7.409746 ]], dtype=float32)
time = 6345	action = 0	current_phase = 0	next_phase = 1	reward = 1.004609	array([[ 2.3316813, -7.6685905]], dtype=float32)
time = 6350	action = 0	current_phase = 0	next_phase = 1	reward = 0.721499	array([[ 2.1861043, -7.412709 ]], dtype=float32)
time = 6355	action = 0	current_phase = 0	next_phase = 1	reward = 0.718841	array([[ 2.2153997, -7.48417  ]], dtype=float32)
time = 6360	action = 0	current_phase = 0	next_phase = 1	reward = 0.165221	array([[ 2.2800465, -7.4338307]], dtype=float32)
time = 6365	action = 0	current_phase = 0	next_phase = 1	reward = 1.013642	array([[ 2.3050418, -7.522378 ]], dtype=float32)
time = 6370	action = 0	current_phase = 0	next_phase = 1	reward = 1.014244	array([[ 2.3072286, -7.620819 ]], dtype=float32)
time = 6375	action = 0	current_phase = 0	next_phase = 1	reward = 0.727660	array([[ 2.2450376, -7.418814 ]], dtype=float32)
time = 6380	action = 0	current_phase = 0	next_phase = 1	reward = 0.724455	array([[ 1.5690942, -7.2158103]], dtype=float32)
time = 6385	action = 0	current_phase = 0	next_phase = 1	reward = 0.723253	array([[ 2.1225963, -7.4275584]], dtype=float32)
time = 6390	action = 0	current_phase = 0	next_phase = 1	reward = 0.723096	array([[ 2.1222339, -7.322504 ]], dtype=float32)
time = 6395	action = 0	current_phase = 0	next_phase = 1	reward = 0.719962	array([[ 2.2890754, -7.424655 ]], dtype=float32)
time = 6400	action = 0	current_phase = 0	next_phase = 1	reward = 0.448752	array([[ 2.2650938, -7.400923 ]], dtype=float32)
time = 6405	action = 0	current_phase = 0	next_phase = 1	reward = 0.999426	array([[ 2.2001047, -7.387678 ]], dtype=float32)
time = 6410	action = 0	current_phase = 0	next_phase = 1	reward = 0.436190	array([[ 2.1751752, -7.3764057]], dtype=float32)
time = 6415	action = 0	current_phase = 0	next_phase = 1	reward = 1.001449	array([[ 2.3088117, -7.4766364]], dtype=float32)
time = 6420	action = 0	current_phase = 0	next_phase = 1	reward = 0.734313	array([[ 2.2479415, -7.4100637]], dtype=float32)
time = 6425	action = 0	current_phase = 0	next_phase = 1	reward = 0.725603	array([[ 2.2854886, -7.4653673]], dtype=float32)
time = 6430	action = 0	current_phase = 0	next_phase = 1	reward = 0.446889	array([[ 2.3231692, -7.5293427]], dtype=float32)
time = 6435	action = 0	current_phase = 0	next_phase = 1	reward = 1.004776	array([[ 2.1993413, -7.5008316]], dtype=float32)
time = 6440	action = 0	current_phase = 0	next_phase = 1	reward = 0.720593	array([[ 2.2817998, -7.43027  ]], dtype=float32)
time = 6445	action = 0	current_phase = 0	next_phase = 1	reward = 0.724334	array([[ 2.3193035, -7.500861 ]], dtype=float32)
time = 6450	action = 0	current_phase = 0	next_phase = 1	reward = 0.720365	array([[ 2.267066, -7.482269]], dtype=float32)
time = 6455	action = 0	current_phase = 0	next_phase = 1	reward = 0.730280	array([[ 2.271461, -7.416361]], dtype=float32)
time = 6460	action = 0	current_phase = 0	next_phase = 1	reward = 0.727920	array([[ 2.2262535, -7.4638395]], dtype=float32)
time = 6465	action = 0	current_phase = 0	next_phase = 1	reward = 0.442775	array([[ 2.150063 , -7.4138985]], dtype=float32)
time = 6470	action = 0	current_phase = 0	next_phase = 1	reward = 1.002993	array([[ 2.2485929, -7.4169273]], dtype=float32)
time = 6475	action = 0	current_phase = 0	next_phase = 1	reward = 0.719609	array([[ 2.1961389, -7.4378786]], dtype=float32)
time = 6480	action = 0	current_phase = 0	next_phase = 1	reward = 0.445406	array([[ 2.2783942, -7.4399633]], dtype=float32)
time = 6485	action = 0	current_phase = 0	next_phase = 1	reward = 0.999477	array([[ 2.270691, -7.522391]], dtype=float32)
time = 6490	action = 0	current_phase = 0	next_phase = 1	reward = 0.435976	array([[ 2.2311244, -7.429931 ]], dtype=float32)
time = 6495	action = 0	current_phase = 0	next_phase = 1	reward = 0.724728	array([[ 2.1941981, -7.5116434]], dtype=float32)
time = 6500	action = 0	current_phase = 0	next_phase = 1	reward = 1.000248	array([[ 2.2810245, -7.433414 ]], dtype=float32)
time = 6505	action = 0	current_phase = 0	next_phase = 1	reward = 0.438686	array([[ 2.3166595, -7.4952917]], dtype=float32)
time = 6510	action = 0	current_phase = 0	next_phase = 1	reward = 0.730037	array([[ 2.0794096, -7.6244125]], dtype=float32)
time = 6515	action = 0	current_phase = 0	next_phase = 1	reward = 1.006784	array([[ 2.2267318, -7.429348 ]], dtype=float32)
time = 6520	action = 0	current_phase = 0	next_phase = 1	reward = 0.722473	array([[ 2.3584213, -7.500678 ]], dtype=float32)
time = 6525	action = 0	current_phase = 0	next_phase = 1	reward = 0.162103	array([[ 2.2803702, -7.410327 ]], dtype=float32)
time = 6530	action = 0	current_phase = 0	next_phase = 1	reward = 1.283929	array([[ 2.260838, -7.537217]], dtype=float32)
time = 6535	action = 0	current_phase = 0	next_phase = 1	reward = 0.723493	array([[ 2.3227186, -7.545656 ]], dtype=float32)
time = 6540	action = 0	current_phase = 0	next_phase = 1	reward = 0.716199	array([[ 2.0748963, -7.3493104]], dtype=float32)
time = 6545	action = 0	current_phase = 0	next_phase = 1	reward = 0.444219	array([[ 2.1171546, -7.392569 ]], dtype=float32)
time = 6550	action = 0	current_phase = 0	next_phase = 1	reward = 0.728101	array([[ 2.2724018, -7.466329 ]], dtype=float32)
time = 6555	action = 0	current_phase = 0	next_phase = 1	reward = 1.000402	array([[ 2.2758613, -7.5343904]], dtype=float32)
time = 6560	action = 0	current_phase = 0	next_phase = 1	reward = 0.721853	array([[ 2.291391, -7.461569]], dtype=float32)
time = 6565	action = 0	current_phase = 0	next_phase = 1	reward = 0.443554	array([[ 2.2163405, -7.414898 ]], dtype=float32)
time = 6570	action = 0	current_phase = 0	next_phase = 1	reward = 0.727247	array([[ 2.2128892, -7.4032526]], dtype=float32)
time = 6575	action = 0	current_phase = 0	next_phase = 1	reward = 0.730845	array([[ 2.2452846, -7.4127417]], dtype=float32)
time = 6580	action = 0	current_phase = 0	next_phase = 1	reward = 1.010435	array([[ 2.2690606, -7.5758414]], dtype=float32)
time = 6585	action = 0	current_phase = 0	next_phase = 1	reward = 0.455215	array([[ 2.2336435, -7.4871783]], dtype=float32)
time = 6590	action = 0	current_phase = 0	next_phase = 1	reward = 1.007081	array([[ 2.2484765, -7.459653 ]], dtype=float32)
time = 6595	action = 0	current_phase = 0	next_phase = 1	reward = 0.721262	array([[ 2.2344995, -7.4397306]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 5s - loss: 7.2932 - val_loss: 5.5102
Epoch 2/50
 - 4s - loss: 6.9364 - val_loss: 4.5700
Epoch 3/50
 - 4s - loss: 6.7815 - val_loss: 5.2141
Epoch 4/50
 - 4s - loss: 7.2267 - val_loss: 6.8128
Epoch 5/50
 - 4s - loss: 7.0074 - val_loss: 6.1173
Epoch 6/50
 - 4s - loss: 7.2123 - val_loss: 5.5164
Epoch 7/50
 - 4s - loss: 6.7842 - val_loss: 5.0329
Epoch 8/50
 - 4s - loss: 6.7470 - val_loss: 5.1191
Epoch 9/50
 - 4s - loss: 6.7868 - val_loss: 4.3135
Epoch 10/50
 - 4s - loss: 6.2512 - val_loss: 4.5191
Epoch 11/50
 - 4s - loss: 6.3767 - val_loss: 8.6171
Epoch 12/50
 - 4s - loss: 6.5566 - val_loss: 4.3704
Epoch 13/50
 - 4s - loss: 6.3999 - val_loss: 5.2220
Epoch 14/50
 - 4s - loss: 5.6434 - val_loss: 6.4794
Epoch 15/50
 - 4s - loss: 7.0679 - val_loss: 5.4564
Epoch 16/50
 - 4s - loss: 6.3016 - val_loss: 5.6296
Epoch 17/50
 - 4s - loss: 7.0950 - val_loss: 6.1382
Epoch 18/50
 - 4s - loss: 6.3066 - val_loss: 5.1803
Epoch 19/50
 - 4s - loss: 6.3768 - val_loss: 4.1863
Epoch 20/50
 - 4s - loss: 5.6578 - val_loss: 4.3309
Epoch 21/50
 - 4s - loss: 5.7648 - val_loss: 6.1679
Epoch 22/50
 - 4s - loss: 6.2078 - val_loss: 6.1620
Epoch 23/50
 - 4s - loss: 5.9458 - val_loss: 4.6562
Epoch 24/50
 - 4s - loss: 6.0016 - val_loss: 4.0197
Epoch 25/50
 - 4s - loss: 5.8219 - val_loss: 4.5428
Epoch 26/50
 - 4s - loss: 5.8192 - val_loss: 7.9513
Epoch 27/50
 - 5s - loss: 6.1616 - val_loss: 4.7769
Epoch 28/50
 - 4s - loss: 6.3607 - val_loss: 4.3798
Epoch 29/50
 - 4s - loss: 7.9797 - val_loss: 4.5819
Epoch 30/50
 - 4s - loss: 5.5894 - val_loss: 7.0298
Epoch 31/50
 - 4s - loss: 6.2478 - val_loss: 4.5687
Epoch 32/50
 - 4s - loss: 5.3426 - val_loss: 5.0587
Epoch 33/50
 - 4s - loss: 5.4159 - val_loss: 4.2183
Epoch 34/50
 - 4s - loss: 5.7885 - val_loss: 6.0380
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 6600	action = 0	current_phase = 0	next_phase = 1	reward = 0.719326	array([[ 2.2720344, -7.4771385]], dtype=float32)
time = 6605	action = 0	current_phase = 0	next_phase = 1	reward = 0.722917	array([[ 2.1482399, -7.446272 ]], dtype=float32)
time = 6610	action = 0	current_phase = 0	next_phase = 1	reward = 0.724201	array([[ 2.3136733, -7.508914 ]], dtype=float32)
time = 6615	action = 0	current_phase = 0	next_phase = 1	reward = 0.716797	array([[ 2.3250754, -7.5602636]], dtype=float32)
time = 6620	action = 0	current_phase = 0	next_phase = 1	reward = 0.437450	array([[ 2.2633278, -7.54323  ]], dtype=float32)
time = 6625	action = 0	current_phase = 0	next_phase = 1	reward = 1.003042	array([[ 2.3069203, -7.5327005]], dtype=float32)
time = 6630	action = 0	current_phase = 0	next_phase = 1	reward = 0.716961	array([[ 2.3264444, -7.5994363]], dtype=float32)
time = 6635	action = 0	current_phase = 0	next_phase = 1	reward = 0.716920	array([[ 2.2957103, -7.480219 ]], dtype=float32)
time = 6640	action = 0	current_phase = 0	next_phase = 1	reward = 0.718577	array([[ 2.2566545, -7.4603033]], dtype=float32)
time = 6645	action = 0	current_phase = 0	next_phase = 1	reward = 0.173320	array([[ 2.3094184, -7.5372057]], dtype=float32)
time = 6650	action = 0	current_phase = 0	next_phase = 1	reward = 1.009303	array([[ 2.1085951, -7.459043 ]], dtype=float32)
time = 6655	action = 0	current_phase = 0	next_phase = 1	reward = 0.999893	array([[ 2.1805665, -7.5446315]], dtype=float32)
time = 6660	action = 0	current_phase = 0	next_phase = 1	reward = 0.716338	array([[ 2.2359893, -7.458905 ]], dtype=float32)
time = 6665	action = 0	current_phase = 0	next_phase = 1	reward = 0.710725	array([[ 2.2042415, -7.4425383]], dtype=float32)
time = 6670	action = 0	current_phase = 0	next_phase = 1	reward = 0.451188	array([[ 2.2576025, -7.4723268]], dtype=float32)
time = 6675	action = 0	current_phase = 0	next_phase = 1	reward = 0.738526	array([[ 2.30814 , -7.545309]], dtype=float32)
time = 6680	action = 0	current_phase = 0	next_phase = 1	reward = 1.001332	array([[ 2.2488968, -7.448779 ]], dtype=float32)
time = 6685	action = 0	current_phase = 0	next_phase = 1	reward = 0.717203	array([[ 2.3188574, -7.554757 ]], dtype=float32)
time = 6690	action = 0	current_phase = 0	next_phase = 1	reward = 0.719884	array([[ 2.2617152, -7.493883 ]], dtype=float32)
time = 6695	action = 0	current_phase = 0	next_phase = 1	reward = 0.719749	array([[ 2.3198192, -7.501135 ]], dtype=float32)
time = 6700	action = 0	current_phase = 0	next_phase = 1	reward = 0.437092	array([[ 2.3087919, -7.491431 ]], dtype=float32)
time = 6705	action = 0	current_phase = 0	next_phase = 1	reward = 1.001031	array([[ 2.3151414, -7.5579777]], dtype=float32)
time = 6710	action = 0	current_phase = 0	next_phase = 1	reward = 0.165249	array([[ 2.3360636, -7.521888 ]], dtype=float32)
time = 6715	action = 0	current_phase = 0	next_phase = 1	reward = 1.009886	array([[ 2.2307632, -7.4698906]], dtype=float32)
time = 6720	action = 0	current_phase = 0	next_phase = 1	reward = 0.999477	array([[ 2.2614572, -7.4760113]], dtype=float32)
time = 6725	action = 0	current_phase = 0	next_phase = 1	reward = 0.725542	array([[ 2.2139447, -7.4858947]], dtype=float32)
time = 6730	action = 0	current_phase = 0	next_phase = 1	reward = 0.447409	array([[ 2.2540905, -7.469902 ]], dtype=float32)
time = 6735	action = 0	current_phase = 0	next_phase = 1	reward = 1.010696	array([[ 2.2820985, -7.507413 ]], dtype=float32)
time = 6740	action = 0	current_phase = 0	next_phase = 1	reward = 0.714952	array([[ 2.3211248, -7.500921 ]], dtype=float32)
time = 6745	action = 0	current_phase = 0	next_phase = 1	reward = 0.153201	array([[ 2.2707198, -7.4771156]], dtype=float32)
time = 6750	action = 0	current_phase = 0	next_phase = 1	reward = 1.278755	array([[ 2.201896, -7.601327]], dtype=float32)
time = 6755	action = 0	current_phase = 0	next_phase = 1	reward = 0.446695	array([[ 2.3373506, -7.599376 ]], dtype=float32)
time = 6760	action = 0	current_phase = 0	next_phase = 1	reward = 1.008006	array([[ 2.2763007, -7.481388 ]], dtype=float32)
time = 6765	action = 0	current_phase = 0	next_phase = 1	reward = 0.720627	array([[ 2.1391232, -7.4235997]], dtype=float32)
time = 6770	action = 0	current_phase = 0	next_phase = 1	reward = 0.452592	array([[ 2.2356284, -7.458681 ]], dtype=float32)
time = 6775	action = 0	current_phase = 0	next_phase = 1	reward = 1.007494	array([[ 2.2441494, -7.4902287]], dtype=float32)
time = 6780	action = 0	current_phase = 0	next_phase = 1	reward = 0.444020	array([[ 2.3102534, -7.5130863]], dtype=float32)
time = 6785	action = 0	current_phase = 0	next_phase = 1	reward = 1.002899	array([[ 2.2609122, -7.5037346]], dtype=float32)
time = 6790	action = 0	current_phase = 0	next_phase = 1	reward = 0.721985	array([[ 2.2045844, -7.4934015]], dtype=float32)
time = 6795	action = 0	current_phase = 0	next_phase = 1	reward = 0.723134	array([[ 2.2500436, -7.4639583]], dtype=float32)
time = 6800	action = 0	current_phase = 0	next_phase = 1	reward = 0.446110	array([[ 2.2457354, -7.474715 ]], dtype=float32)
time = 6805	action = 0	current_phase = 0	next_phase = 1	reward = 1.006346	array([[ 2.3270524, -7.520922 ]], dtype=float32)
time = 6810	action = 0	current_phase = 0	next_phase = 1	reward = 0.720560	array([[ 2.2109392, -7.4723973]], dtype=float32)
time = 6815	action = 0	current_phase = 0	next_phase = 1	reward = 0.438243	array([[ 2.3011053, -7.5075736]], dtype=float32)
time = 6820	action = 0	current_phase = 0	next_phase = 1	reward = 0.996196	array([[ 2.3026998, -7.6081924]], dtype=float32)
time = 6825	action = 0	current_phase = 0	next_phase = 1	reward = 0.718749	array([[ 2.2906458, -7.4881964]], dtype=float32)
time = 6830	action = 0	current_phase = 0	next_phase = 1	reward = 0.438655	array([[ 2.2025077, -7.4883246]], dtype=float32)
time = 6835	action = 0	current_phase = 0	next_phase = 1	reward = 0.725493	array([[ 1.7736852, -7.271929 ]], dtype=float32)
time = 6840	action = 0	current_phase = 0	next_phase = 1	reward = 1.008610	array([[ 2.3212821, -7.522772 ]], dtype=float32)
time = 6845	action = 0	current_phase = 0	next_phase = 1	reward = 0.449841	array([[ 2.2994444, -7.509981 ]], dtype=float32)
time = 6850	action = 0	current_phase = 0	next_phase = 1	reward = 0.723984	array([[ 2.2550461, -7.474383 ]], dtype=float32)
time = 6855	action = 0	current_phase = 0	next_phase = 1	reward = 1.000063	array([[ 2.2415888, -7.4750385]], dtype=float32)
time = 6860	action = 0	current_phase = 0	next_phase = 1	reward = 0.724535	array([[ 2.3118198, -7.498536 ]], dtype=float32)
time = 6865	action = 0	current_phase = 0	next_phase = 1	reward = 0.728042	array([[ 2.2359474, -7.4493456]], dtype=float32)
time = 6870	action = 0	current_phase = 0	next_phase = 1	reward = 0.171297	array([[ 2.2425487, -7.479143 ]], dtype=float32)
time = 6875	action = 0	current_phase = 0	next_phase = 1	reward = 1.286529	array([[ 2.0746305, -7.5797377]], dtype=float32)
time = 6880	action = 0	current_phase = 0	next_phase = 1	reward = 0.725752	array([[ 2.3663251, -7.616909 ]], dtype=float32)
time = 6885	action = 0	current_phase = 0	next_phase = 1	reward = 0.717544	array([[ 2.3107312, -7.489748 ]], dtype=float32)
time = 6890	action = 0	current_phase = 0	next_phase = 1	reward = 0.719544	array([[ 2.1288145, -7.4690213]], dtype=float32)
time = 6895	action = 0	current_phase = 0	next_phase = 1	reward = 0.723938	array([[ 2.2779987, -7.4990544]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.0095 - val_loss: 8.2662
Epoch 2/50
 - 4s - loss: 5.3295 - val_loss: 8.6849
Epoch 3/50
 - 4s - loss: 4.1701 - val_loss: 8.5712
Epoch 4/50
 - 4s - loss: 4.7287 - val_loss: 8.8887
Epoch 5/50
 - 4s - loss: 4.6196 - val_loss: 9.3683
Epoch 6/50
 - 4s - loss: 4.7054 - val_loss: 9.0401
Epoch 7/50
 - 4s - loss: 4.2650 - val_loss: 9.1632
Epoch 8/50
 - 4s - loss: 4.1608 - val_loss: 8.6651
Epoch 9/50
 - 4s - loss: 4.8514 - val_loss: 9.1469
Epoch 10/50
 - 4s - loss: 3.6612 - val_loss: 8.9198
Epoch 11/50
 - 4s - loss: 4.5276 - val_loss: 8.2229
Epoch 12/50
 - 4s - loss: 3.9040 - val_loss: 8.6676
Epoch 13/50
 - 4s - loss: 3.6220 - val_loss: 8.5298
Epoch 14/50
 - 4s - loss: 4.7036 - val_loss: 10.0788
Epoch 15/50
 - 4s - loss: 4.1235 - val_loss: 8.5515
Epoch 16/50
 - 4s - loss: 4.2081 - val_loss: 8.5225
Epoch 17/50
 - 4s - loss: 3.7529 - val_loss: 9.1338
Epoch 18/50
 - 4s - loss: 3.8634 - val_loss: 8.9038
Epoch 19/50
 - 4s - loss: 3.4943 - val_loss: 9.4704
Epoch 20/50
 - 4s - loss: 4.0103 - val_loss: 9.6863
Epoch 21/50
 - 4s - loss: 3.8036 - val_loss: 8.7722
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 6900	action = 0	current_phase = 0	next_phase = 1	reward = 0.714166	array([[ 2.2482264, -7.423275 ]], dtype=float32)
time = 6905	action = 0	current_phase = 0	next_phase = 1	reward = 0.712047	array([[ 2.23618  , -7.4479017]], dtype=float32)
time = 6910	action = 0	current_phase = 0	next_phase = 1	reward = 0.446230	array([[ 2.2317312, -7.482873 ]], dtype=float32)
time = 6915	action = 0	current_phase = 0	next_phase = 1	reward = 1.002505	array([[ 2.3217986, -7.497222 ]], dtype=float32)
time = 6920	action = 0	current_phase = 0	next_phase = 1	reward = 0.718937	array([[ 2.3131268, -7.5433016]], dtype=float32)
time = 6925	action = 0	current_phase = 0	next_phase = 1	reward = 0.720820	array([[ 2.2622974, -7.4585886]], dtype=float32)
time = 6930	action = 0	current_phase = 0	next_phase = 1	reward = 0.720992	array([[ 2.4773748, -7.73516  ]], dtype=float32)
time = 6935	action = 0	current_phase = 0	next_phase = 1	reward = 0.448847	array([[ 2.2848008, -7.479    ]], dtype=float32)
time = 6940	action = 0	current_phase = 0	next_phase = 1	reward = 1.006323	array([[ 2.3202026, -7.463319 ]], dtype=float32)
time = 6945	action = 0	current_phase = 0	next_phase = 1	reward = 0.444516	array([[ 2.2534125, -7.5399384]], dtype=float32)
time = 6950	action = 0	current_phase = 0	next_phase = 1	reward = 0.728293	array([[ 2.3193772, -7.4818115]], dtype=float32)
time = 6955	action = 0	current_phase = 0	next_phase = 1	reward = 1.005162	array([[ 2.2305043, -7.395842 ]], dtype=float32)
time = 6960	action = 0	current_phase = 0	next_phase = 1	reward = 0.446187	array([[ 2.24101  , -7.3772917]], dtype=float32)
time = 6965	action = 0	current_phase = 0	next_phase = 1	reward = 1.009857	array([[ 2.1016157, -7.4206295]], dtype=float32)
time = 6970	action = 0	current_phase = 0	next_phase = 1	reward = 0.726675	array([[ 2.3132308, -7.551857 ]], dtype=float32)
time = 6975	action = 0	current_phase = 0	next_phase = 1	reward = 0.723949	array([[ 1.5591376, -7.0290036]], dtype=float32)
time = 6980	action = 0	current_phase = 0	next_phase = 1	reward = 0.721309	array([[ 2.030052, -7.323623]], dtype=float32)
time = 6985	action = 0	current_phase = 0	next_phase = 1	reward = 0.718353	array([[ 2.2158382, -7.393609 ]], dtype=float32)
time = 6990	action = 0	current_phase = 0	next_phase = 1	reward = 0.726157	array([[ 2.2368972, -7.4075756]], dtype=float32)
time = 6995	action = 0	current_phase = 0	next_phase = 1	reward = 0.718982	array([[ 2.3001897, -7.4545507]], dtype=float32)
time = 7000	action = 0	current_phase = 0	next_phase = 1	reward = 0.441553	array([[ 2.2111466, -7.4010544]], dtype=float32)
time = 7005	action = 0	current_phase = 0	next_phase = 1	reward = 1.000614	array([[ 2.0324748, -7.420643 ]], dtype=float32)
time = 7010	action = 0	current_phase = 0	next_phase = 1	reward = 0.714531	array([[ 2.2821958, -7.4467635]], dtype=float32)
time = 7015	action = 0	current_phase = 0	next_phase = 1	reward = 0.441216	array([[ 2.3022144, -7.441408 ]], dtype=float32)
time = 7020	action = 0	current_phase = 0	next_phase = 1	reward = 0.726542	array([[ 2.2146137, -7.432571 ]], dtype=float32)
time = 7025	action = 0	current_phase = 0	next_phase = 1	reward = 0.723955	array([[ 2.2606204, -7.522851 ]], dtype=float32)
time = 7030	action = 0	current_phase = 0	next_phase = 1	reward = 1.002633	array([[ 2.2673604, -7.559721 ]], dtype=float32)
time = 7035	action = 0	current_phase = 0	next_phase = 1	reward = 0.723537	array([[ 2.289429, -7.425615]], dtype=float32)
time = 7040	action = 0	current_phase = 0	next_phase = 1	reward = 0.715436	array([[ 2.231068 , -7.3926945]], dtype=float32)
time = 7045	action = 0	current_phase = 0	next_phase = 1	reward = 0.726287	array([[ 2.3070724, -7.4322567]], dtype=float32)
time = 7050	action = 0	current_phase = 0	next_phase = 1	reward = 0.457061	array([[ 2.2691624, -7.435095 ]], dtype=float32)
time = 7055	action = 0	current_phase = 0	next_phase = 1	reward = 1.011463	array([[ 2.331299, -7.459423]], dtype=float32)
time = 7060	action = 0	current_phase = 0	next_phase = 1	reward = 0.711054	array([[ 2.292126 , -7.4381437]], dtype=float32)
time = 7065	action = 0	current_phase = 0	next_phase = 1	reward = 0.438744	array([[ 2.2981102, -7.427457 ]], dtype=float32)
time = 7070	action = 0	current_phase = 0	next_phase = 1	reward = 0.448511	array([[ 2.3216207, -7.5242033]], dtype=float32)
time = 7075	action = 0	current_phase = 0	next_phase = 1	reward = 1.016524	array([[ 2.3085067, -7.5156426]], dtype=float32)
time = 7080	action = 0	current_phase = 0	next_phase = 1	reward = 1.003611	array([[ 2.302068, -7.472686]], dtype=float32)
time = 7085	action = 0	current_phase = 0	next_phase = 1	reward = 0.438111	array([[ 2.1281378, -7.3401494]], dtype=float32)
time = 7090	action = 0	current_phase = 0	next_phase = 1	reward = 1.004831	array([[ 2.2624862, -7.429841 ]], dtype=float32)
time = 7095	action = 0	current_phase = 0	next_phase = 1	reward = 0.716339	array([[ 2.234629 , -7.5050764]], dtype=float32)
time = 7100	action = 0	current_phase = 0	next_phase = 1	reward = 0.723107	array([[ 2.3033774, -7.4709206]], dtype=float32)
time = 7105	action = 0	current_phase = 0	next_phase = 1	reward = 0.719674	array([[ 2.2626598, -7.428832 ]], dtype=float32)
time = 7110	action = 0	current_phase = 0	next_phase = 1	reward = 0.728097	array([[ 2.2251208, -7.41588  ]], dtype=float32)
time = 7115	action = 0	current_phase = 0	next_phase = 1	reward = 0.731461	array([[ 2.3394358, -7.4598355]], dtype=float32)
time = 7120	action = 0	current_phase = 0	next_phase = 1	reward = 0.445453	array([[ 2.2308424, -7.4116254]], dtype=float32)
time = 7125	action = 0	current_phase = 0	next_phase = 1	reward = 1.003053	array([[ 2.2511919, -7.475782 ]], dtype=float32)
time = 7130	action = 0	current_phase = 0	next_phase = 1	reward = 0.445119	array([[ 2.3270276, -7.4695253]], dtype=float32)
time = 7135	action = 0	current_phase = 0	next_phase = 1	reward = 1.003355	array([[ 2.205572 , -7.4405193]], dtype=float32)
time = 7140	action = 0	current_phase = 0	next_phase = 1	reward = 0.165451	array([[ 2.317366, -7.459594]], dtype=float32)
time = 7145	action = 0	current_phase = 0	next_phase = 1	reward = 1.280204	array([[ 2.1901634, -7.4867167]], dtype=float32)
time = 7150	action = 0	current_phase = 0	next_phase = 1	reward = 0.450889	array([[ 1.9951737, -7.269234 ]], dtype=float32)
time = 7155	action = 0	current_phase = 0	next_phase = 1	reward = 0.731734	array([[ 2.2543304, -7.424072 ]], dtype=float32)
time = 7160	action = 0	current_phase = 0	next_phase = 1	reward = 1.008212	array([[ 1.9173248, -7.471349 ]], dtype=float32)
time = 7165	action = 0	current_phase = 0	next_phase = 1	reward = 0.719923	array([[ 2.251084 , -7.3770504]], dtype=float32)
time = 7170	action = 0	current_phase = 0	next_phase = 1	reward = 0.716570	array([[ 2.242853 , -7.4052973]], dtype=float32)
time = 7175	action = 0	current_phase = 0	next_phase = 1	reward = 0.438912	array([[ 2.2369716, -7.48774  ]], dtype=float32)
time = 7180	action = 0	current_phase = 0	next_phase = 1	reward = 0.996079	array([[ 2.1596882, -7.455988 ]], dtype=float32)
time = 7185	action = 0	current_phase = 0	next_phase = 1	reward = 0.718354	array([[ 2.324497 , -7.4669333]], dtype=float32)
time = 7190	action = 0	current_phase = 0	next_phase = 1	reward = 0.167657	array([[ 2.260527, -7.436683]], dtype=float32)
time = 7195	action = 0	current_phase = 0	next_phase = 1	reward = 1.291203	array([[ 2.3188913, -7.7398634]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 7.3192 - val_loss: 5.5395
Epoch 2/50
 - 4s - loss: 7.0602 - val_loss: 5.3593
Epoch 3/50
 - 4s - loss: 7.3625 - val_loss: 7.3699
Epoch 4/50
 - 4s - loss: 6.8244 - val_loss: 6.6355
Epoch 5/50
 - 4s - loss: 6.3125 - val_loss: 7.7064
Epoch 6/50
 - 4s - loss: 6.2835 - val_loss: 5.7469
Epoch 7/50
 - 4s - loss: 6.3874 - val_loss: 5.5750
Epoch 8/50
 - 4s - loss: 5.2631 - val_loss: 5.5891
Epoch 9/50
 - 5s - loss: 6.1336 - val_loss: 5.4991
Epoch 10/50
 - 4s - loss: 6.1850 - val_loss: 5.6111
Epoch 11/50
 - 4s - loss: 5.5987 - val_loss: 6.6638
Epoch 12/50
 - 4s - loss: 5.5017 - val_loss: 6.6545
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 7200	action = 0	current_phase = 0	next_phase = 1	reward = 0.440844	array([[ 2.2267184, -7.4455833]], dtype=float32)
time = 7205	action = 0	current_phase = 0	next_phase = 1	reward = 1.006409	array([[ 2.236559, -7.601993]], dtype=float32)
time = 7210	action = 0	current_phase = 0	next_phase = 1	reward = 0.718274	array([[ 2.4964147, -7.8530664]], dtype=float32)
time = 7215	action = 0	current_phase = 0	next_phase = 1	reward = 0.723576	array([[ 2.2328901, -7.5107594]], dtype=float32)
time = 7220	action = 0	current_phase = 0	next_phase = 1	reward = 0.441988	array([[ 2.2080522, -7.6803675]], dtype=float32)
time = 7225	action = 0	current_phase = 0	next_phase = 1	reward = 1.012153	array([[ 2.178751, -7.606622]], dtype=float32)
time = 7230	action = 0	current_phase = 0	next_phase = 1	reward = 0.720245	array([[ 2.2978835, -7.5702467]], dtype=float32)
time = 7235	action = 0	current_phase = 0	next_phase = 1	reward = 0.439870	array([[ 2.1923919, -7.4853   ]], dtype=float32)
time = 7240	action = 0	current_phase = 0	next_phase = 1	reward = 0.723790	array([[ 2.3243947, -7.649278 ]], dtype=float32)
time = 7245	action = 0	current_phase = 0	next_phase = 1	reward = 1.000677	array([[ 2.0773296, -7.509322 ]], dtype=float32)
time = 7250	action = 0	current_phase = 0	next_phase = 1	reward = 0.440163	array([[ 2.3547869, -7.8334885]], dtype=float32)
time = 7255	action = 0	current_phase = 0	next_phase = 1	reward = 0.452510	array([[ 2.1903987, -7.512587 ]], dtype=float32)
time = 7260	action = 0	current_phase = 0	next_phase = 1	reward = 1.286923	array([[ 2.0191355, -7.5881305]], dtype=float32)
time = 7265	action = 0	current_phase = 0	next_phase = 1	reward = 0.720119	array([[ 2.1266413, -7.874505 ]], dtype=float32)
time = 7270	action = 0	current_phase = 0	next_phase = 1	reward = 0.720655	array([[ 2.3136501, -7.583254 ]], dtype=float32)
time = 7275	action = 0	current_phase = 0	next_phase = 1	reward = 0.720284	array([[ 2.5963316, -8.0319395]], dtype=float32)
time = 7280	action = 0	current_phase = 0	next_phase = 1	reward = 0.448961	array([[ 2.0371852, -7.4675655]], dtype=float32)
time = 7285	action = 0	current_phase = 0	next_phase = 1	reward = 0.726178	array([[ 1.9156451, -7.378813 ]], dtype=float32)
time = 7290	action = 0	current_phase = 0	next_phase = 1	reward = 1.010916	array([[ 2.1082392, -7.611842 ]], dtype=float32)
time = 7295	action = 0	current_phase = 0	next_phase = 1	reward = 0.724348	array([[ 2.2400985, -7.507554 ]], dtype=float32)
time = 7300	action = 0	current_phase = 0	next_phase = 1	reward = 0.721228	array([[ 2.2063375, -7.5998735]], dtype=float32)
time = 7305	action = 0	current_phase = 0	next_phase = 1	reward = 0.718718	array([[ 2.190165, -7.505171]], dtype=float32)
time = 7310	action = 0	current_phase = 0	next_phase = 1	reward = 0.440652	array([[ 2.2807794, -7.607918 ]], dtype=float32)
time = 7315	action = 0	current_phase = 0	next_phase = 1	reward = 1.000132	array([[ 2.1742406, -7.624862 ]], dtype=float32)
time = 7320	action = 0	current_phase = 0	next_phase = 1	reward = 0.439062	array([[ 2.1754913, -7.4931116]], dtype=float32)
time = 7325	action = 0	current_phase = 0	next_phase = 1	reward = 0.723972	array([[ 1.982863, -7.481204]], dtype=float32)
time = 7330	action = 0	current_phase = 0	next_phase = 1	reward = 0.455306	array([[ 2.192831, -7.52837 ]], dtype=float32)
time = 7335	action = 0	current_phase = 0	next_phase = 1	reward = 1.019453	array([[ 2.007393, -7.457469]], dtype=float32)
time = 7340	action = 0	current_phase = 0	next_phase = 1	reward = 1.002715	array([[ 2.1488638, -7.607109 ]], dtype=float32)
time = 7345	action = 0	current_phase = 0	next_phase = 1	reward = 0.439804	array([[ 2.3177972, -7.493043 ]], dtype=float32)
time = 7350	action = 0	current_phase = 0	next_phase = 1	reward = 0.998661	array([[ 2.0460434, -7.5239353]], dtype=float32)
time = 7355	action = 0	current_phase = 0	next_phase = 1	reward = 0.716480	array([[ 2.2491908, -7.457355 ]], dtype=float32)
time = 7360	action = 0	current_phase = 0	next_phase = 1	reward = 0.448694	array([[ 2.2176657, -7.451679 ]], dtype=float32)
time = 7365	action = 0	current_phase = 0	next_phase = 1	reward = 1.006999	array([[ 2.1453462, -7.547943 ]], dtype=float32)
time = 7370	action = 0	current_phase = 0	next_phase = 1	reward = 0.717658	array([[ 2.1350183, -7.393257 ]], dtype=float32)
time = 7375	action = 0	current_phase = 0	next_phase = 1	reward = 0.718108	array([[ 2.3021898, -7.5007157]], dtype=float32)
time = 7380	action = 0	current_phase = 0	next_phase = 1	reward = 0.723636	array([[ 2.288262, -7.524454]], dtype=float32)
time = 7385	action = 0	current_phase = 0	next_phase = 1	reward = 0.722149	array([[ 2.2746315, -7.4955454]], dtype=float32)
time = 7390	action = 0	current_phase = 0	next_phase = 1	reward = 0.724522	array([[ 2.1954656, -7.425671 ]], dtype=float32)
time = 7395	action = 0	current_phase = 0	next_phase = 1	reward = 0.715464	array([[ 2.1075225, -7.4296303]], dtype=float32)
time = 7400	action = 0	current_phase = 0	next_phase = 1	reward = 0.440600	array([[ 2.2339983, -7.4950438]], dtype=float32)
time = 7405	action = 0	current_phase = 0	next_phase = 1	reward = 0.999629	array([[ 2.2915134, -7.5613346]], dtype=float32)
time = 7410	action = 0	current_phase = 0	next_phase = 1	reward = 0.443636	array([[ 2.2833214, -7.6200733]], dtype=float32)
time = 7415	action = 0	current_phase = 0	next_phase = 1	reward = 0.726189	array([[ 2.2749743, -7.5368543]], dtype=float32)
time = 7420	action = 0	current_phase = 0	next_phase = 1	reward = 0.727335	array([[ 2.161302 , -7.4889045]], dtype=float32)
time = 7425	action = 0	current_phase = 0	next_phase = 1	reward = 1.003112	array([[ 1.9117727, -7.636961 ]], dtype=float32)
time = 7430	action = 0	current_phase = 0	next_phase = 1	reward = 0.727819	array([[ 2.2690797, -7.572267 ]], dtype=float32)
time = 7435	action = 0	current_phase = 0	next_phase = 1	reward = 0.730495	array([[ 2.2361379, -7.4852047]], dtype=float32)
time = 7440	action = 0	current_phase = 0	next_phase = 1	reward = 0.724283	array([[ 2.1934762, -7.468476 ]], dtype=float32)
time = 7445	action = 0	current_phase = 0	next_phase = 1	reward = 0.728387	array([[ 2.1802053, -7.4463863]], dtype=float32)
time = 7450	action = 0	current_phase = 0	next_phase = 1	reward = 0.718598	array([[ 2.0938683, -7.509819 ]], dtype=float32)
time = 7455	action = 0	current_phase = 0	next_phase = 1	reward = 0.439114	array([[ 2.2631168, -7.5417438]], dtype=float32)
time = 7460	action = 0	current_phase = 0	next_phase = 1	reward = 0.724259	array([[ 2.2616758, -7.6171646]], dtype=float32)
time = 7465	action = 0	current_phase = 0	next_phase = 1	reward = 0.724354	array([[ 2.3130627, -7.599185 ]], dtype=float32)
time = 7470	action = 0	current_phase = 0	next_phase = 1	reward = 1.006674	array([[ 2.4263983, -7.7267795]], dtype=float32)
time = 7475	action = 0	current_phase = 0	next_phase = 1	reward = 0.720106	array([[ 2.0865693, -7.500936 ]], dtype=float32)
time = 7480	action = 0	current_phase = 0	next_phase = 1	reward = 0.720197	array([[ 1.9664745, -7.3985333]], dtype=float32)
time = 7485	action = 0	current_phase = 0	next_phase = 1	reward = 0.167125	array([[ 2.3364105, -7.616304 ]], dtype=float32)
time = 7490	action = 0	current_phase = 0	next_phase = 1	reward = 1.013052	array([[ 2.1498985, -7.4921627]], dtype=float32)
time = 7495	action = 0	current_phase = 0	next_phase = 1	reward = 1.005441	array([[ 2.1047   , -7.6489105]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 7.8853 - val_loss: 3.4144
Epoch 2/50
 - 4s - loss: 7.6147 - val_loss: 4.2940
Epoch 3/50
 - 4s - loss: 7.6551 - val_loss: 3.6056
Epoch 4/50
 - 4s - loss: 6.1481 - val_loss: 3.8634
Epoch 5/50
 - 4s - loss: 5.5587 - val_loss: 3.5839
Epoch 6/50
 - 4s - loss: 7.4945 - val_loss: 4.4247
Epoch 7/50
 - 4s - loss: 6.4791 - val_loss: 3.3295
Epoch 8/50
 - 4s - loss: 6.9862 - val_loss: 3.9542
Epoch 9/50
 - 4s - loss: 6.0704 - val_loss: 4.2888
Epoch 10/50
 - 4s - loss: 6.4761 - val_loss: 4.8801
Epoch 11/50
 - 4s - loss: 6.9049 - val_loss: 3.2390
Epoch 12/50
 - 4s - loss: 5.6049 - val_loss: 3.5690
Epoch 13/50
 - 4s - loss: 6.1224 - val_loss: 4.2242
Epoch 14/50
 - 4s - loss: 6.2978 - val_loss: 4.8341
Epoch 15/50
 - 4s - loss: 5.9163 - val_loss: 3.6874
Epoch 16/50
 - 4s - loss: 7.3665 - val_loss: 4.3765
Epoch 17/50
 - 4s - loss: 5.9848 - val_loss: 3.3429
Epoch 18/50
 - 4s - loss: 6.1992 - val_loss: 3.1461
Epoch 19/50
 - 4s - loss: 6.1181 - val_loss: 3.7243
Epoch 20/50
 - 4s - loss: 6.1534 - val_loss: 3.8917
Epoch 21/50
 - 4s - loss: 6.0565 - val_loss: 3.9133
Epoch 22/50
 - 4s - loss: 5.9647 - val_loss: 3.2884
Epoch 23/50
 - 4s - loss: 5.4299 - val_loss: 3.5056
Epoch 24/50
 - 4s - loss: 6.0852 - val_loss: 3.1816
Epoch 25/50
 - 4s - loss: 5.6814 - val_loss: 3.3888
Epoch 26/50
 - 4s - loss: 6.5221 - val_loss: 3.2119
Epoch 27/50
 - 4s - loss: 5.8640 - val_loss: 4.1202
Epoch 28/50
 - 4s - loss: 6.4366 - val_loss: 3.5474
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 7500	action = 0	current_phase = 0	next_phase = 1	reward = 0.443324	array([[ 2.3183057, -7.5164924]], dtype=float32)
time = 7505	action = 0	current_phase = 0	next_phase = 1	reward = 1.006424	array([[ 2.2310245, -7.5377855]], dtype=float32)
time = 7510	action = 0	current_phase = 0	next_phase = 1	reward = 0.720694	array([[ 2.3585174, -7.592683 ]], dtype=float32)
time = 7515	action = 0	current_phase = 0	next_phase = 1	reward = 0.728161	array([[ 2.155753 , -7.5523357]], dtype=float32)
time = 7520	action = 0	current_phase = 0	next_phase = 1	reward = 0.724274	array([[ 2.247331 , -7.4838543]], dtype=float32)
time = 7525	action = 0	current_phase = 0	next_phase = 1	reward = 0.729855	array([[ 2.1899283, -7.495079 ]], dtype=float32)
time = 7530	action = 0	current_phase = 0	next_phase = 1	reward = 0.726141	array([[ 2.3017209, -7.5817986]], dtype=float32)
time = 7535	action = 0	current_phase = 0	next_phase = 1	reward = 0.723230	array([[ 2.1832173, -7.51462  ]], dtype=float32)
time = 7540	action = 0	current_phase = 0	next_phase = 1	reward = 0.728819	array([[ 2.2873933, -7.5556498]], dtype=float32)
time = 7545	action = 0	current_phase = 0	next_phase = 1	reward = 0.725815	array([[ 2.231817, -7.490678]], dtype=float32)
time = 7550	action = 0	current_phase = 0	next_phase = 1	reward = 0.729838	array([[ 2.2763412, -7.5350986]], dtype=float32)
time = 7555	action = 0	current_phase = 0	next_phase = 1	reward = 0.733848	array([[ 2.2084749, -7.571242 ]], dtype=float32)
time = 7560	action = 0	current_phase = 0	next_phase = 1	reward = 0.722723	array([[ 2.289325 , -7.5310893]], dtype=float32)
time = 7565	action = 0	current_phase = 0	next_phase = 1	reward = 0.718397	array([[ 2.2908204, -7.527526 ]], dtype=float32)
time = 7570	action = 0	current_phase = 0	next_phase = 1	reward = 0.727888	array([[ 2.2902706, -7.4997306]], dtype=float32)
time = 7575	action = 0	current_phase = 0	next_phase = 1	reward = 0.720020	array([[ 2.2508109, -7.5959473]], dtype=float32)
time = 7580	action = 0	current_phase = 0	next_phase = 1	reward = 0.726238	array([[ 2.2272294, -7.495536 ]], dtype=float32)
time = 7585	action = 0	current_phase = 0	next_phase = 1	reward = 0.718663	array([[ 2.3077366, -7.590147 ]], dtype=float32)
time = 7590	action = 0	current_phase = 0	next_phase = 1	reward = 0.440081	array([[ 2.1600778, -7.4801188]], dtype=float32)
time = 7595	action = 0	current_phase = 0	next_phase = 1	reward = 0.997522	array([[ 2.1916816, -7.550106 ]], dtype=float32)
time = 7600	action = 0	current_phase = 0	next_phase = 1	reward = 0.161032	array([[ 2.1303694, -7.463475 ]], dtype=float32)
time = 7605	action = 0	current_phase = 0	next_phase = 1	reward = 1.288048	array([[ 2.0305784, -7.560663 ]], dtype=float32)
time = 7610	action = 0	current_phase = 0	next_phase = 1	reward = 0.447394	array([[ 2.345321 , -7.7083697]], dtype=float32)
time = 7615	action = 0	current_phase = 0	next_phase = 1	reward = 0.723781	array([[ 2.1483595, -7.5655103]], dtype=float32)
time = 7620	action = 0	current_phase = 0	next_phase = 1	reward = 0.723192	array([[ 2.285051 , -7.5614843]], dtype=float32)
time = 7625	action = 0	current_phase = 0	next_phase = 1	reward = 1.005723	array([[ 2.2763283, -7.559256 ]], dtype=float32)
time = 7630	action = 0	current_phase = 0	next_phase = 1	reward = 0.443787	array([[ 2.3120897, -7.5114613]], dtype=float32)
time = 7635	action = 0	current_phase = 0	next_phase = 1	reward = 1.006851	array([[ 2.1202133, -7.4876595]], dtype=float32)
time = 7640	action = 0	current_phase = 0	next_phase = 1	reward = 0.441534	array([[ 2.218714, -7.497279]], dtype=float32)
time = 7645	action = 0	current_phase = 0	next_phase = 1	reward = 0.732106	array([[ 2.1796677, -7.517668 ]], dtype=float32)
time = 7650	action = 0	current_phase = 0	next_phase = 1	reward = 1.003338	array([[ 2.275594, -7.576926]], dtype=float32)
time = 7655	action = 0	current_phase = 0	next_phase = 1	reward = 0.718610	array([[ 2.3154304, -7.551017 ]], dtype=float32)
time = 7660	action = 0	current_phase = 0	next_phase = 1	reward = 0.717916	array([[ 2.3505857, -7.635394 ]], dtype=float32)
time = 7665	action = 0	current_phase = 0	next_phase = 1	reward = 0.164076	array([[ 2.2018564, -7.479781 ]], dtype=float32)
time = 7670	action = 0	current_phase = 0	next_phase = 1	reward = 1.016369	array([[ 2.1843917, -7.5502324]], dtype=float32)
time = 7675	action = 0	current_phase = 0	next_phase = 1	reward = 0.725621	array([[ 2.2721417, -7.5765796]], dtype=float32)
time = 7680	action = 0	current_phase = 0	next_phase = 1	reward = 0.999071	array([[ 2.3158739, -7.6151342]], dtype=float32)
time = 7685	action = 0	current_phase = 0	next_phase = 1	reward = 0.717323	array([[ 2.2265837, -7.581859 ]], dtype=float32)
time = 7690	action = 0	current_phase = 0	next_phase = 1	reward = 0.441241	array([[ 2.2355506, -7.5319223]], dtype=float32)
time = 7695	action = 0	current_phase = 0	next_phase = 1	reward = 0.735220	array([[ 2.2290413, -7.6774387]], dtype=float32)
time = 7700	action = 0	current_phase = 0	next_phase = 1	reward = 1.013771	array([[ 2.2696211, -7.5394306]], dtype=float32)
time = 7705	action = 0	current_phase = 0	next_phase = 1	reward = 0.733280	array([[ 2.2669823, -7.542431 ]], dtype=float32)
time = 7710	action = 0	current_phase = 0	next_phase = 1	reward = 0.727201	array([[ 2.2856529, -7.561782 ]], dtype=float32)
time = 7715	action = 0	current_phase = 0	next_phase = 1	reward = 0.724226	array([[ 2.178816, -7.530143]], dtype=float32)
time = 7720	action = 0	current_phase = 0	next_phase = 1	reward = 0.722382	array([[ 2.2460039, -7.5197544]], dtype=float32)
time = 7725	action = 0	current_phase = 0	next_phase = 1	reward = 0.725920	array([[ 2.2532442, -7.515547 ]], dtype=float32)
time = 7730	action = 0	current_phase = 0	next_phase = 1	reward = 0.722895	array([[ 2.318958, -7.557601]], dtype=float32)
time = 7735	action = 0	current_phase = 0	next_phase = 1	reward = 0.444703	array([[ 2.157431, -7.500881]], dtype=float32)
time = 7740	action = 0	current_phase = 0	next_phase = 1	reward = 1.000048	array([[ 2.2805498, -7.515535 ]], dtype=float32)
time = 7745	action = 0	current_phase = 0	next_phase = 1	reward = 0.724814	array([[ 2.2912261, -7.518685 ]], dtype=float32)
time = 7750	action = 0	current_phase = 0	next_phase = 1	reward = 0.721713	array([[ 2.2432263, -7.5323668]], dtype=float32)
time = 7755	action = 0	current_phase = 0	next_phase = 1	reward = 0.440436	array([[ 2.2655108, -7.505785 ]], dtype=float32)
time = 7760	action = 0	current_phase = 0	next_phase = 1	reward = 0.995498	array([[ 2.1474192, -7.680026 ]], dtype=float32)
time = 7765	action = 0	current_phase = 0	next_phase = 1	reward = 0.431452	array([[ 2.2985256, -7.5682526]], dtype=float32)
time = 7770	action = 0	current_phase = 0	next_phase = 1	reward = 0.437339	array([[ 2.272587, -7.523425]], dtype=float32)
time = 7775	action = 0	current_phase = 0	next_phase = 1	reward = 1.002611	array([[ 2.2241642, -7.611744 ]], dtype=float32)
time = 7780	action = 0	current_phase = 0	next_phase = 1	reward = 0.736060	array([[ 2.1681087, -7.5432568]], dtype=float32)
time = 7785	action = 0	current_phase = 0	next_phase = 1	reward = 1.002569	array([[ 2.2561572, -7.533632 ]], dtype=float32)
time = 7790	action = 0	current_phase = 0	next_phase = 1	reward = 0.727185	array([[ 2.3242238, -7.5670867]], dtype=float32)
time = 7795	action = 0	current_phase = 0	next_phase = 1	reward = 0.447392	array([[ 2.1004593, -7.492714 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 6.4484 - val_loss: 5.2167
Epoch 2/50
 - 4s - loss: 6.2407 - val_loss: 5.2137
Epoch 3/50
 - 4s - loss: 5.9427 - val_loss: 4.8011
Epoch 4/50
 - 4s - loss: 6.7205 - val_loss: 4.6794
Epoch 5/50
 - 4s - loss: 6.1707 - val_loss: 4.6364
Epoch 6/50
 - 4s - loss: 5.2697 - val_loss: 4.3855
Epoch 7/50
 - 4s - loss: 5.8361 - val_loss: 4.2660
Epoch 8/50
 - 4s - loss: 5.7662 - val_loss: 4.5082
Epoch 9/50
 - 4s - loss: 5.3071 - val_loss: 4.8931
Epoch 10/50
 - 4s - loss: 5.6584 - val_loss: 4.6340
Epoch 11/50
 - 4s - loss: 5.2435 - val_loss: 4.4392
Epoch 12/50
 - 4s - loss: 5.0909 - val_loss: 4.8965
Epoch 13/50
 - 4s - loss: 5.2868 - val_loss: 4.4371
Epoch 14/50
 - 4s - loss: 5.2490 - val_loss: 4.0570
Epoch 15/50
 - 4s - loss: 5.3712 - val_loss: 4.3141
Epoch 16/50
 - 4s - loss: 4.1715 - val_loss: 3.7667
Epoch 17/50
 - 4s - loss: 4.4135 - val_loss: 4.4440
Epoch 18/50
 - 4s - loss: 5.5747 - val_loss: 5.5550
Epoch 19/50
 - 4s - loss: 5.3507 - val_loss: 5.1149
Epoch 20/50
 - 4s - loss: 5.8595 - val_loss: 4.3661
Epoch 21/50
 - 4s - loss: 4.8450 - val_loss: 4.4693
Epoch 22/50
 - 4s - loss: 5.1426 - val_loss: 4.4136
Epoch 23/50
 - 4s - loss: 5.4678 - val_loss: 4.8746
Epoch 24/50
 - 4s - loss: 4.5144 - val_loss: 5.8870
Epoch 25/50
 - 4s - loss: 4.6185 - val_loss: 5.8534
Epoch 26/50
 - 4s - loss: 4.6470 - val_loss: 5.1542
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 7800	action = 0	current_phase = 0	next_phase = 1	reward = 1.006637	array([[ 2.4462497, -7.6696486]], dtype=float32)
time = 7805	action = 0	current_phase = 0	next_phase = 1	reward = 0.717242	array([[ 2.5474784, -7.568179 ]], dtype=float32)
time = 7810	action = 0	current_phase = 0	next_phase = 1	reward = 0.719634	array([[ 2.5137074, -7.559821 ]], dtype=float32)
time = 7815	action = 0	current_phase = 0	next_phase = 1	reward = 0.171401	array([[ 2.3948734, -7.6283073]], dtype=float32)
time = 7820	action = 0	current_phase = 0	next_phase = 1	reward = 1.016565	array([[ 2.4995859, -7.845925 ]], dtype=float32)
time = 7825	action = 0	current_phase = 0	next_phase = 1	reward = 1.005909	array([[ 2.5679076, -8.30602  ]], dtype=float32)
time = 7830	action = 0	current_phase = 0	next_phase = 1	reward = 0.714855	array([[ 2.5148137, -7.631029 ]], dtype=float32)
time = 7835	action = 0	current_phase = 0	next_phase = 1	reward = 0.712572	array([[ 2.5743992, -7.6701365]], dtype=float32)
time = 7840	action = 0	current_phase = 0	next_phase = 1	reward = 0.724451	array([[ 2.3495944, -7.600152 ]], dtype=float32)
time = 7845	action = 0	current_phase = 0	next_phase = 1	reward = 0.724954	array([[ 2.453942, -7.611243]], dtype=float32)
time = 7850	action = 0	current_phase = 0	next_phase = 1	reward = 0.709389	array([[ 2.4783475, -7.600889 ]], dtype=float32)
time = 7855	action = 0	current_phase = 0	next_phase = 1	reward = 0.448738	array([[ 2.5426838, -7.6592445]], dtype=float32)
time = 7860	action = 0	current_phase = 0	next_phase = 1	reward = 1.002754	array([[ 2.516659, -7.676464]], dtype=float32)
time = 7865	action = 0	current_phase = 0	next_phase = 1	reward = 0.718138	array([[ 2.5516136, -7.738365 ]], dtype=float32)
time = 7870	action = 0	current_phase = 0	next_phase = 1	reward = 0.718386	array([[ 2.5149262, -7.7038393]], dtype=float32)
time = 7875	action = 0	current_phase = 0	next_phase = 1	reward = 0.728353	array([[ 2.5064895, -7.6409664]], dtype=float32)
time = 7880	action = 0	current_phase = 0	next_phase = 1	reward = 0.726791	array([[ 2.3698738, -7.660919 ]], dtype=float32)
time = 7885	action = 0	current_phase = 0	next_phase = 1	reward = 0.441990	array([[ 2.4413917, -7.601897 ]], dtype=float32)
time = 7890	action = 0	current_phase = 0	next_phase = 1	reward = 1.003780	array([[ 2.4571774, -7.7474513]], dtype=float32)
time = 7895	action = 0	current_phase = 0	next_phase = 1	reward = 0.726771	array([[ 2.525182 , -7.5636415]], dtype=float32)
time = 7900	action = 0	current_phase = 0	next_phase = 1	reward = 0.444834	array([[ 2.5589054, -7.799716 ]], dtype=float32)
time = 7905	action = 0	current_phase = 0	next_phase = 1	reward = 0.723675	array([[ 2.4603164, -7.79543  ]], dtype=float32)
time = 7910	action = 0	current_phase = 0	next_phase = 1	reward = 0.999699	array([[ 2.4338524, -7.8376145]], dtype=float32)
time = 7915	action = 0	current_phase = 0	next_phase = 1	reward = 0.715544	array([[ 2.6440933, -7.810113 ]], dtype=float32)
time = 7920	action = 0	current_phase = 0	next_phase = 1	reward = 0.162428	array([[ 2.5312154, -7.636636 ]], dtype=float32)
time = 7925	action = 0	current_phase = 0	next_phase = 1	reward = 1.005878	array([[ 2.3874214, -7.76003  ]], dtype=float32)
time = 7930	action = 0	current_phase = 0	next_phase = 1	reward = 0.720321	array([[ 2.5411775, -7.608554 ]], dtype=float32)
time = 7935	action = 0	current_phase = 0	next_phase = 1	reward = 1.000971	array([[ 2.7113721, -7.8778048]], dtype=float32)
time = 7940	action = 0	current_phase = 0	next_phase = 1	reward = 0.448781	array([[ 2.5630524, -7.674817 ]], dtype=float32)
time = 7945	action = 0	current_phase = 0	next_phase = 1	reward = 0.733138	array([[ 2.4529126, -7.8003216]], dtype=float32)
time = 7950	action = 0	current_phase = 0	next_phase = 1	reward = 1.009526	array([[ 2.499254, -7.588144]], dtype=float32)
time = 7955	action = 0	current_phase = 0	next_phase = 1	reward = 0.718185	array([[ 2.4600818, -7.599038 ]], dtype=float32)
time = 7960	action = 0	current_phase = 0	next_phase = 1	reward = 0.162844	array([[ 2.473067, -7.645298]], dtype=float32)
time = 7965	action = 0	current_phase = 0	next_phase = 1	reward = 1.292350	array([[ 2.3630602, -7.74497  ]], dtype=float32)
time = 7970	action = 0	current_phase = 0	next_phase = 1	reward = 0.727582	array([[ 2.5138261, -7.6737328]], dtype=float32)
time = 7975	action = 0	current_phase = 0	next_phase = 1	reward = 0.722130	array([[ 2.454662, -7.664412]], dtype=float32)
time = 7980	action = 0	current_phase = 0	next_phase = 1	reward = 0.722823	array([[ 2.4893935, -7.625815 ]], dtype=float32)
time = 7985	action = 0	current_phase = 0	next_phase = 1	reward = 0.721438	array([[ 2.496309 , -7.6022234]], dtype=float32)
time = 7990	action = 0	current_phase = 0	next_phase = 1	reward = 0.715609	array([[ 2.5880897, -7.6667004]], dtype=float32)
time = 7995	action = 0	current_phase = 0	next_phase = 1	reward = 0.161699	array([[ 2.5225236, -7.6041646]], dtype=float32)
time = 8000	action = 0	current_phase = 0	next_phase = 1	reward = 1.007865	array([[ 2.411681, -7.674203]], dtype=float32)
time = 8005	action = 0	current_phase = 0	next_phase = 1	reward = 1.002338	array([[ 2.416806 , -7.6520443]], dtype=float32)
time = 8010	action = 0	current_phase = 0	next_phase = 1	reward = 0.444036	array([[ 2.443517, -7.567794]], dtype=float32)
time = 8015	action = 0	current_phase = 0	next_phase = 1	reward = 1.008592	array([[ 2.393253, -7.751997]], dtype=float32)
time = 8020	action = 0	current_phase = 0	next_phase = 1	reward = 0.452898	array([[ 2.5668447, -7.7586117]], dtype=float32)
time = 8025	action = 0	current_phase = 0	next_phase = 1	reward = 0.998351	array([[ 2.4968364, -7.5846343]], dtype=float32)
time = 8030	action = 0	current_phase = 0	next_phase = 1	reward = 0.716032	array([[ 2.4382427, -7.6453314]], dtype=float32)
time = 8035	action = 0	current_phase = 0	next_phase = 1	reward = 0.718318	array([[ 2.5786111, -7.669288 ]], dtype=float32)
time = 8040	action = 0	current_phase = 0	next_phase = 1	reward = 0.447037	array([[ 2.5001142, -7.5892973]], dtype=float32)
time = 8045	action = 0	current_phase = 0	next_phase = 1	reward = 0.999290	array([[ 2.4998624, -7.585578 ]], dtype=float32)
time = 8050	action = 0	current_phase = 0	next_phase = 1	reward = 0.715212	array([[ 2.623564, -7.730094]], dtype=float32)
time = 8055	action = 0	current_phase = 0	next_phase = 1	reward = 0.165498	array([[ 2.6055071, -7.680045 ]], dtype=float32)
time = 8060	action = 0	current_phase = 0	next_phase = 1	reward = 1.020615	array([[ 2.3880527, -7.9500694]], dtype=float32)
time = 8065	action = 0	current_phase = 0	next_phase = 1	reward = 1.012003	array([[ 2.523268 , -7.7149286]], dtype=float32)
time = 8070	action = 0	current_phase = 0	next_phase = 1	reward = 0.718532	array([[ 2.3263881, -7.5470543]], dtype=float32)
time = 8075	action = 0	current_phase = 0	next_phase = 1	reward = 0.714612	array([[ 2.4904053, -7.576061 ]], dtype=float32)
time = 8080	action = 0	current_phase = 0	next_phase = 1	reward = 0.431782	array([[ 2.3398998, -7.5503182]], dtype=float32)
time = 8085	action = 0	current_phase = 0	next_phase = 1	reward = 0.718513	array([[ 2.482878, -7.608282]], dtype=float32)
time = 8090	action = 0	current_phase = 0	next_phase = 1	reward = 0.724666	array([[ 2.2483704, -8.302759 ]], dtype=float32)
time = 8095	action = 0	current_phase = 0	next_phase = 1	reward = 0.735326	array([[ 2.4470885, -7.768854 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 6.0186 - val_loss: 3.4220
Epoch 2/50
 - 4s - loss: 6.1974 - val_loss: 4.0719
Epoch 3/50
 - 4s - loss: 4.7370 - val_loss: 4.0517
Epoch 4/50
 - 4s - loss: 4.2701 - val_loss: 3.6810
Epoch 5/50
 - 4s - loss: 5.6536 - val_loss: 3.4137
Epoch 6/50
 - 4s - loss: 5.2721 - val_loss: 3.0937
Epoch 7/50
 - 4s - loss: 4.0159 - val_loss: 3.8349
Epoch 8/50
 - 4s - loss: 4.0472 - val_loss: 2.8597
Epoch 9/50
 - 4s - loss: 5.1899 - val_loss: 3.7532
Epoch 10/50
 - 4s - loss: 4.5443 - val_loss: 4.0859
Epoch 11/50
 - 4s - loss: 4.2554 - val_loss: 5.2554
Epoch 12/50
 - 4s - loss: 4.3698 - val_loss: 3.7613
Epoch 13/50
 - 4s - loss: 5.1575 - val_loss: 3.5342
Epoch 14/50
 - 4s - loss: 3.9789 - val_loss: 4.1602
Epoch 15/50
 - 4s - loss: 5.6266 - val_loss: 4.4307
Epoch 16/50
 - 4s - loss: 4.9708 - val_loss: 4.4435
Epoch 17/50
 - 4s - loss: 4.2522 - val_loss: 3.2782
Epoch 18/50
 - 4s - loss: 4.7372 - val_loss: 3.4689
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 8100	action = 0	current_phase = 0	next_phase = 1	reward = 0.724447	array([[ 2.3920896, -7.7934217]], dtype=float32)
time = 8105	action = 0	current_phase = 0	next_phase = 1	reward = 1.000734	array([[ 2.5291617, -7.702141 ]], dtype=float32)
time = 8110	action = 0	current_phase = 0	next_phase = 1	reward = 0.445037	array([[ 2.5800316, -7.6993494]], dtype=float32)
time = 8115	action = 0	current_phase = 0	next_phase = 1	reward = 1.002408	array([[ 2.544667, -7.675837]], dtype=float32)
time = 8120	action = 0	current_phase = 0	next_phase = 1	reward = 0.724081	array([[ 2.5452135, -7.7416267]], dtype=float32)
time = 8125	action = 0	current_phase = 0	next_phase = 1	reward = 0.443198	array([[ 2.612159, -7.784644]], dtype=float32)
time = 8130	action = 0	current_phase = 0	next_phase = 1	reward = 0.728975	array([[ 2.4754903, -7.7314863]], dtype=float32)
time = 8135	action = 0	current_phase = 0	next_phase = 1	reward = 1.005653	array([[ 2.4966805, -7.6295576]], dtype=float32)
time = 8140	action = 0	current_phase = 0	next_phase = 1	reward = 0.725662	array([[ 2.4054153, -7.6843405]], dtype=float32)
time = 8145	action = 0	current_phase = 0	next_phase = 1	reward = 0.717104	array([[ 2.6079676, -7.749644 ]], dtype=float32)
time = 8150	action = 0	current_phase = 0	next_phase = 1	reward = 0.439325	array([[ 2.5061638, -7.6501894]], dtype=float32)
time = 8155	action = 0	current_phase = 0	next_phase = 1	reward = 0.726981	array([[ 2.5107133, -7.6591387]], dtype=float32)
time = 8160	action = 0	current_phase = 0	next_phase = 1	reward = 1.010714	array([[ 2.674178, -8.050661]], dtype=float32)
time = 8165	action = 0	current_phase = 0	next_phase = 1	reward = 0.442031	array([[ 2.6942914, -7.9276524]], dtype=float32)
time = 8170	action = 0	current_phase = 0	next_phase = 1	reward = 1.003262	array([[ 2.5471122, -7.6610575]], dtype=float32)
time = 8175	action = 0	current_phase = 0	next_phase = 1	reward = 0.442260	array([[ 2.515848, -7.687482]], dtype=float32)
time = 8180	action = 0	current_phase = 0	next_phase = 1	reward = 1.003051	array([[ 2.5597103, -7.658719 ]], dtype=float32)
time = 8185	action = 0	current_phase = 0	next_phase = 1	reward = 0.726646	array([[ 2.5235207, -7.659216 ]], dtype=float32)
time = 8190	action = 0	current_phase = 0	next_phase = 1	reward = 0.726579	array([[ 2.5787346, -7.691484 ]], dtype=float32)
time = 8195	action = 0	current_phase = 0	next_phase = 1	reward = 0.719446	array([[ 2.5081313, -7.6287813]], dtype=float32)
time = 8200	action = 0	current_phase = 0	next_phase = 1	reward = 0.715416	array([[ 2.5565221, -7.662632 ]], dtype=float32)
time = 8205	action = 0	current_phase = 0	next_phase = 1	reward = 0.722781	array([[ 2.5473282, -7.71456  ]], dtype=float32)
time = 8210	action = 0	current_phase = 0	next_phase = 1	reward = 0.721870	array([[ 2.5556371, -7.649617 ]], dtype=float32)
time = 8215	action = 0	current_phase = 0	next_phase = 1	reward = 0.455487	array([[ 2.5528796, -7.6642246]], dtype=float32)
time = 8220	action = 0	current_phase = 0	next_phase = 1	reward = 1.011549	array([[ 2.4380739, -7.678894 ]], dtype=float32)
time = 8225	action = 0	current_phase = 0	next_phase = 1	reward = 0.718645	array([[ 2.5890982, -7.6845355]], dtype=float32)
time = 8230	action = 0	current_phase = 0	next_phase = 1	reward = 0.719557	array([[ 2.5089762, -7.634651 ]], dtype=float32)
time = 8235	action = 0	current_phase = 0	next_phase = 1	reward = 0.718101	array([[ 2.5852187, -7.6702824]], dtype=float32)
time = 8240	action = 0	current_phase = 0	next_phase = 1	reward = 0.719586	array([[ 2.5596526, -7.6747494]], dtype=float32)
time = 8245	action = 0	current_phase = 0	next_phase = 1	reward = 0.718078	array([[ 2.5263484, -7.642939 ]], dtype=float32)
time = 8250	action = 0	current_phase = 0	next_phase = 1	reward = 0.725172	array([[ 2.4956014, -7.661618 ]], dtype=float32)
time = 8255	action = 0	current_phase = 0	next_phase = 1	reward = 0.720999	array([[ 2.5567558, -7.8438416]], dtype=float32)
time = 8260	action = 0	current_phase = 0	next_phase = 1	reward = 0.443501	array([[ 2.5941346, -7.726144 ]], dtype=float32)
time = 8265	action = 0	current_phase = 0	next_phase = 1	reward = 1.005907	array([[ 2.5052874, -7.6855135]], dtype=float32)
time = 8270	action = 0	current_phase = 0	next_phase = 1	reward = 0.723140	array([[ 2.4130409, -7.65736  ]], dtype=float32)
time = 8275	action = 0	current_phase = 0	next_phase = 1	reward = 0.723892	array([[ 2.5509546, -7.705859 ]], dtype=float32)
time = 8280	action = 0	current_phase = 0	next_phase = 1	reward = 0.167136	array([[ 2.4552176, -7.6855335]], dtype=float32)
time = 8285	action = 0	current_phase = 0	next_phase = 1	reward = 1.275118	array([[ 2.2615855, -7.54185  ]], dtype=float32)
time = 8290	action = 0	current_phase = 0	next_phase = 1	reward = 0.722061	array([[ 2.5639203, -7.711737 ]], dtype=float32)
time = 8295	action = 0	current_phase = 0	next_phase = 1	reward = 0.720759	array([[ 2.7124712, -7.885443 ]], dtype=float32)
time = 8300	action = 0	current_phase = 0	next_phase = 1	reward = 0.441897	array([[ 2.8428447, -8.141664 ]], dtype=float32)
time = 8305	action = 0	current_phase = 0	next_phase = 1	reward = 1.010351	array([[ 2.338157, -7.624053]], dtype=float32)
time = 8310	action = 0	current_phase = 0	next_phase = 1	reward = 0.723255	array([[ 2.4098952, -7.6501102]], dtype=float32)
time = 8315	action = 0	current_phase = 0	next_phase = 1	reward = 0.443302	array([[ 2.5301473, -7.645032 ]], dtype=float32)
time = 8320	action = 0	current_phase = 0	next_phase = 1	reward = 1.006016	array([[ 2.583485, -7.726756]], dtype=float32)
time = 8325	action = 0	current_phase = 0	next_phase = 1	reward = 0.724867	array([[ 2.5615351, -7.6722383]], dtype=float32)
time = 8330	action = 0	current_phase = 0	next_phase = 1	reward = 0.728150	array([[ 2.5155103, -7.67418  ]], dtype=float32)
time = 8335	action = 0	current_phase = 0	next_phase = 1	reward = 0.725126	array([[ 2.362117, -7.578446]], dtype=float32)
time = 8340	action = 0	current_phase = 0	next_phase = 1	reward = 0.725677	array([[ 2.5131505, -7.626795 ]], dtype=float32)
time = 8345	action = 0	current_phase = 0	next_phase = 1	reward = 0.723647	array([[ 2.7326033, -7.9293585]], dtype=float32)
time = 8350	action = 0	current_phase = 0	next_phase = 1	reward = 0.721594	array([[ 2.539059 , -7.6723948]], dtype=float32)
time = 8355	action = 0	current_phase = 0	next_phase = 1	reward = 0.451397	array([[ 2.5402658, -7.7159996]], dtype=float32)
time = 8360	action = 0	current_phase = 0	next_phase = 1	reward = 1.003865	array([[ 2.5654051, -7.6738935]], dtype=float32)
time = 8365	action = 0	current_phase = 0	next_phase = 1	reward = 0.720039	array([[ 2.5526278, -7.6526814]], dtype=float32)
time = 8370	action = 0	current_phase = 0	next_phase = 1	reward = 0.443121	array([[ 2.582084, -7.668028]], dtype=float32)
time = 8375	action = 0	current_phase = 0	next_phase = 1	reward = 0.997179	array([[ 2.5510557, -7.776708 ]], dtype=float32)
time = 8380	action = 0	current_phase = 0	next_phase = 1	reward = 0.442244	array([[ 2.5448654, -7.6853065]], dtype=float32)
time = 8385	action = 0	current_phase = 0	next_phase = 1	reward = 0.725274	array([[ 2.1387613, -7.6507893]], dtype=float32)
time = 8390	action = 0	current_phase = 0	next_phase = 1	reward = 1.012201	array([[ 2.5091145, -7.6542673]], dtype=float32)
time = 8395	action = 0	current_phase = 0	next_phase = 1	reward = 0.713915	array([[ 2.5709455, -7.6761923]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 6.2011 - val_loss: 4.0449
Epoch 2/50
 - 4s - loss: 5.2496 - val_loss: 3.8625
Epoch 3/50
 - 4s - loss: 4.7013 - val_loss: 4.8447
Epoch 4/50
 - 4s - loss: 4.6400 - val_loss: 4.1797
Epoch 5/50
 - 4s - loss: 5.5077 - val_loss: 4.2145
Epoch 6/50
 - 4s - loss: 4.8201 - val_loss: 4.0563
Epoch 7/50
 - 4s - loss: 5.1216 - val_loss: 4.3541
Epoch 8/50
 - 4s - loss: 6.1758 - val_loss: 3.8380
Epoch 9/50
 - 4s - loss: 4.8956 - val_loss: 4.3514
Epoch 10/50
 - 4s - loss: 4.5047 - val_loss: 4.7790
Epoch 11/50
 - 4s - loss: 5.4022 - val_loss: 3.9273
Epoch 12/50
 - 4s - loss: 4.8900 - val_loss: 4.5708
Epoch 13/50
 - 4s - loss: 5.4902 - val_loss: 4.7889
Epoch 14/50
 - 4s - loss: 4.5346 - val_loss: 3.9353
Epoch 15/50
 - 4s - loss: 4.9564 - val_loss: 7.5608
Epoch 16/50
 - 4s - loss: 4.6378 - val_loss: 4.1736
Epoch 17/50
 - 4s - loss: 4.6672 - val_loss: 4.3197
Epoch 18/50
 - 4s - loss: 4.8321 - val_loss: 4.3144
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 8400	action = 0	current_phase = 0	next_phase = 1	reward = 0.442151	array([[ 2.4287255, -7.7513027]], dtype=float32)
time = 8405	action = 0	current_phase = 0	next_phase = 1	reward = 0.727932	array([[ 2.4003813, -7.605366 ]], dtype=float32)
time = 8410	action = 0	current_phase = 0	next_phase = 1	reward = 1.010494	array([[ 2.4679582, -7.7103753]], dtype=float32)
time = 8415	action = 0	current_phase = 0	next_phase = 1	reward = 0.455088	array([[ 2.4767978, -7.7127943]], dtype=float32)
time = 8420	action = 0	current_phase = 0	next_phase = 1	reward = 1.015447	array([[ 2.3600671, -7.7991676]], dtype=float32)
time = 8425	action = 0	current_phase = 0	next_phase = 1	reward = 0.728698	array([[ 2.486914 , -7.6908035]], dtype=float32)
time = 8430	action = 0	current_phase = 0	next_phase = 1	reward = 0.725890	array([[ 2.5288265, -7.640256 ]], dtype=float32)
time = 8435	action = 0	current_phase = 0	next_phase = 1	reward = 0.721208	array([[ 2.4744513, -7.720169 ]], dtype=float32)
time = 8440	action = 0	current_phase = 0	next_phase = 1	reward = 0.725487	array([[ 2.5288703, -7.7050943]], dtype=float32)
time = 8445	action = 0	current_phase = 0	next_phase = 1	reward = 0.721246	array([[ 2.5451581, -7.6968055]], dtype=float32)
time = 8450	action = 0	current_phase = 0	next_phase = 1	reward = 0.443473	array([[ 2.5133092, -7.674156 ]], dtype=float32)
time = 8455	action = 0	current_phase = 0	next_phase = 1	reward = 1.004094	array([[ 2.2593496, -7.6390285]], dtype=float32)
time = 8460	action = 0	current_phase = 0	next_phase = 1	reward = 0.717947	array([[ 2.5220697, -7.755913 ]], dtype=float32)
time = 8465	action = 0	current_phase = 0	next_phase = 1	reward = 0.717463	array([[ 2.5234015, -7.7273455]], dtype=float32)
time = 8470	action = 0	current_phase = 0	next_phase = 1	reward = 0.439575	array([[ 2.693454, -7.981889]], dtype=float32)
time = 8475	action = 0	current_phase = 0	next_phase = 1	reward = 1.002353	array([[ 2.4184034, -7.7367268]], dtype=float32)
time = 8480	action = 0	current_phase = 0	next_phase = 1	reward = 0.447880	array([[ 2.4835923, -7.757856 ]], dtype=float32)
time = 8485	action = 0	current_phase = 0	next_phase = 1	reward = 1.001834	array([[ 2.4372857, -7.690488 ]], dtype=float32)
time = 8490	action = 0	current_phase = 0	next_phase = 1	reward = 0.724121	array([[ 2.5492795, -7.7437463]], dtype=float32)
time = 8495	action = 0	current_phase = 0	next_phase = 1	reward = 0.715693	array([[ 2.5813143, -7.7862654]], dtype=float32)
time = 8500	action = 0	current_phase = 0	next_phase = 1	reward = 0.732204	array([[ 2.413607 , -7.6292934]], dtype=float32)
time = 8505	action = 0	current_phase = 0	next_phase = 1	reward = 0.726751	array([[ 2.6304305, -7.789816 ]], dtype=float32)
time = 8510	action = 0	current_phase = 0	next_phase = 1	reward = 0.724400	array([[ 2.3778222, -7.7239275]], dtype=float32)
time = 8515	action = 0	current_phase = 0	next_phase = 1	reward = 0.720572	array([[ 2.49634  , -7.6950216]], dtype=float32)
time = 8520	action = 0	current_phase = 0	next_phase = 1	reward = 0.720916	array([[ 2.531267 , -7.6794567]], dtype=float32)
time = 8525	action = 0	current_phase = 0	next_phase = 1	reward = 0.729085	array([[ 2.5344117, -7.6595297]], dtype=float32)
time = 8530	action = 0	current_phase = 0	next_phase = 1	reward = 0.446215	array([[ 2.344631, -7.697814]], dtype=float32)
time = 8535	action = 0	current_phase = 0	next_phase = 1	reward = 1.003923	array([[ 2.3574922, -7.5620766]], dtype=float32)
time = 8540	action = 0	current_phase = 0	next_phase = 1	reward = 0.449890	array([[ 2.4556625, -7.625994 ]], dtype=float32)
time = 8545	action = 0	current_phase = 0	next_phase = 1	reward = 1.009280	array([[ 2.5343945, -7.677746 ]], dtype=float32)
time = 8550	action = 0	current_phase = 0	next_phase = 1	reward = 0.450079	array([[ 2.4284828, -7.648614 ]], dtype=float32)
time = 8555	action = 0	current_phase = 0	next_phase = 1	reward = 1.006681	array([[ 2.5069892, -7.673732 ]], dtype=float32)
time = 8560	action = 0	current_phase = 0	next_phase = 1	reward = 0.718863	array([[ 2.5273664, -7.701842 ]], dtype=float32)
time = 8565	action = 0	current_phase = 0	next_phase = 1	reward = 0.726846	array([[ 2.5824292, -7.710645 ]], dtype=float32)
time = 8570	action = 0	current_phase = 0	next_phase = 1	reward = 0.723223	array([[ 2.414501 , -7.6888084]], dtype=float32)
time = 8575	action = 0	current_phase = 0	next_phase = 1	reward = 0.710785	array([[ 2.52056  , -7.6449265]], dtype=float32)
time = 8580	action = 0	current_phase = 0	next_phase = 1	reward = 0.712092	array([[ 2.5181339, -7.6672287]], dtype=float32)
time = 8585	action = 0	current_phase = 0	next_phase = 1	reward = 0.718581	array([[ 2.4810221, -7.6996994]], dtype=float32)
time = 8590	action = 0	current_phase = 0	next_phase = 1	reward = 0.724875	array([[ 2.5796812, -7.743428 ]], dtype=float32)
time = 8595	action = 0	current_phase = 0	next_phase = 1	reward = 0.446290	array([[ 2.5282981, -7.6873293]], dtype=float32)
time = 8600	action = 0	current_phase = 0	next_phase = 1	reward = 0.997651	array([[ 2.3911521, -7.6582265]], dtype=float32)
time = 8605	action = 0	current_phase = 0	next_phase = 1	reward = 0.435365	array([[ 2.4864876, -7.67875  ]], dtype=float32)
time = 8610	action = 0	current_phase = 0	next_phase = 1	reward = 0.725225	array([[ 2.5260074, -7.6794796]], dtype=float32)
time = 8615	action = 0	current_phase = 0	next_phase = 1	reward = 0.723329	array([[ 2.4755151, -7.7964354]], dtype=float32)
time = 8620	action = 0	current_phase = 0	next_phase = 1	reward = 1.015271	array([[ 2.5221555, -7.6955166]], dtype=float32)
time = 8625	action = 0	current_phase = 0	next_phase = 1	reward = 0.725360	array([[ 2.5194185, -7.6548142]], dtype=float32)
time = 8630	action = 0	current_phase = 0	next_phase = 1	reward = 0.721464	array([[ 2.466118 , -7.6628456]], dtype=float32)
time = 8635	action = 0	current_phase = 0	next_phase = 1	reward = 0.726149	array([[ 2.5090263, -7.6376657]], dtype=float32)
time = 8640	action = 0	current_phase = 0	next_phase = 1	reward = 0.717583	array([[ 2.4860518, -7.7646585]], dtype=float32)
time = 8645	action = 0	current_phase = 0	next_phase = 1	reward = 0.716049	array([[ 2.5203211, -7.6648655]], dtype=float32)
time = 8650	action = 0	current_phase = 0	next_phase = 1	reward = 0.448120	array([[ 2.481395, -7.64481 ]], dtype=float32)
time = 8655	action = 0	current_phase = 0	next_phase = 1	reward = 1.012426	array([[ 2.559519, -7.761547]], dtype=float32)
time = 8660	action = 0	current_phase = 0	next_phase = 1	reward = 0.725119	array([[ 2.5374172, -7.7205496]], dtype=float32)
time = 8665	action = 0	current_phase = 0	next_phase = 1	reward = 0.723784	array([[ 2.5267942, -7.6942625]], dtype=float32)
time = 8670	action = 0	current_phase = 0	next_phase = 1	reward = 0.445374	array([[ 2.5284865, -7.685789 ]], dtype=float32)
time = 8675	action = 0	current_phase = 0	next_phase = 1	reward = 1.006407	array([[ 2.516153, -7.698845]], dtype=float32)
time = 8680	action = 0	current_phase = 0	next_phase = 1	reward = 0.717019	array([[ 2.5941894, -7.7358384]], dtype=float32)
time = 8685	action = 0	current_phase = 0	next_phase = 1	reward = 0.725920	array([[ 2.5158765, -7.6884365]], dtype=float32)
time = 8690	action = 0	current_phase = 0	next_phase = 1	reward = 0.735153	array([[ 2.532678, -7.720454]], dtype=float32)
time = 8695	action = 0	current_phase = 0	next_phase = 1	reward = 0.722770	array([[ 2.4891622, -7.6957417]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.9171 - val_loss: 2.7980
Epoch 2/50
 - 4s - loss: 5.6775 - val_loss: 4.6172
Epoch 3/50
 - 4s - loss: 5.4758 - val_loss: 3.6017
Epoch 4/50
 - 4s - loss: 5.6067 - val_loss: 3.4689
Epoch 5/50
 - 4s - loss: 4.7614 - val_loss: 3.0443
Epoch 6/50
 - 4s - loss: 5.2604 - val_loss: 3.7313
Epoch 7/50
 - 4s - loss: 5.0694 - val_loss: 3.9799
Epoch 8/50
 - 4s - loss: 5.3542 - val_loss: 3.4965
Epoch 9/50
 - 8s - loss: 6.2010 - val_loss: 4.0276
Epoch 10/50
 - 5s - loss: 4.9207 - val_loss: 3.8444
Epoch 11/50
 - 5s - loss: 4.7532 - val_loss: 3.5138
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 8700	action = 0	current_phase = 0	next_phase = 1	reward = 0.728099	array([[ 2.6121733, -7.7413654]], dtype=float32)
time = 8705	action = 0	current_phase = 0	next_phase = 1	reward = 0.721560	array([[ 2.567084, -7.725315]], dtype=float32)
time = 8710	action = 0	current_phase = 0	next_phase = 1	reward = 0.435976	array([[ 2.4858162, -7.639785 ]], dtype=float32)
time = 8715	action = 0	current_phase = 0	next_phase = 1	reward = 1.000383	array([[ 2.5185282, -7.745421 ]], dtype=float32)
time = 8720	action = 0	current_phase = 0	next_phase = 1	reward = 0.725672	array([[ 2.4965842, -7.649479 ]], dtype=float32)
time = 8725	action = 0	current_phase = 0	next_phase = 1	reward = 0.725890	array([[ 2.585871, -7.750729]], dtype=float32)
time = 8730	action = 0	current_phase = 0	next_phase = 1	reward = 0.448983	array([[ 2.4753726, -7.63702  ]], dtype=float32)
time = 8735	action = 0	current_phase = 0	next_phase = 1	reward = 1.002829	array([[ 2.3916695, -7.7534337]], dtype=float32)
time = 8740	action = 0	current_phase = 0	next_phase = 1	reward = 0.717942	array([[ 2.5703304, -7.9271107]], dtype=float32)
time = 8745	action = 0	current_phase = 0	next_phase = 1	reward = 0.440217	array([[ 2.4572585, -7.659052 ]], dtype=float32)
time = 8750	action = 0	current_phase = 0	next_phase = 1	reward = 1.001978	array([[ 2.401695 , -7.7846756]], dtype=float32)
time = 8755	action = 0	current_phase = 0	next_phase = 1	reward = 0.720820	array([[ 2.5170057, -7.684745 ]], dtype=float32)
time = 8760	action = 0	current_phase = 0	next_phase = 1	reward = 0.726328	array([[ 2.5077522, -7.7957816]], dtype=float32)
time = 8765	action = 0	current_phase = 0	next_phase = 1	reward = 0.446073	array([[ 2.4219377, -7.6149855]], dtype=float32)
time = 8770	action = 0	current_phase = 0	next_phase = 1	reward = 1.007570	array([[ 2.324774, -7.681739]], dtype=float32)
time = 8775	action = 0	current_phase = 0	next_phase = 1	reward = 0.721516	array([[ 2.6660092, -7.87568  ]], dtype=float32)
time = 8780	action = 0	current_phase = 0	next_phase = 1	reward = 0.722805	array([[ 2.6244318, -7.959979 ]], dtype=float32)
time = 8785	action = 0	current_phase = 0	next_phase = 1	reward = 0.730134	array([[ 2.490391 , -7.6909356]], dtype=float32)
time = 8790	action = 0	current_phase = 0	next_phase = 1	reward = 0.445561	array([[ 2.4710968, -7.6564555]], dtype=float32)
time = 8795	action = 0	current_phase = 0	next_phase = 1	reward = 0.985560	array([[ 2.4604132, -7.711149 ]], dtype=float32)
time = 8800	action = 0	current_phase = 0	next_phase = 1	reward = 0.713907	array([[ 2.4409049, -7.6665754]], dtype=float32)
time = 8805	action = 0	current_phase = 0	next_phase = 1	reward = 0.444515	array([[ 2.5124795, -7.661935 ]], dtype=float32)
time = 8810	action = 0	current_phase = 0	next_phase = 1	reward = 1.005811	array([[ 2.5372336, -7.7524147]], dtype=float32)
time = 8815	action = 0	current_phase = 0	next_phase = 1	reward = 0.727659	array([[ 2.5595477, -7.778347 ]], dtype=float32)
time = 8820	action = 0	current_phase = 0	next_phase = 1	reward = 0.448436	array([[ 2.4156578, -7.6445174]], dtype=float32)
time = 8825	action = 0	current_phase = 0	next_phase = 1	reward = 0.728708	array([[ 2.4889286, -7.7011156]], dtype=float32)
time = 8830	action = 0	current_phase = 0	next_phase = 1	reward = 1.003100	array([[ 2.5307682, -7.7171154]], dtype=float32)
time = 8835	action = 0	current_phase = 0	next_phase = 1	reward = 0.718370	array([[ 2.4130328, -7.693323 ]], dtype=float32)
time = 8840	action = 0	current_phase = 0	next_phase = 1	reward = 0.447128	array([[ 2.407932, -7.693262]], dtype=float32)
time = 8845	action = 0	current_phase = 0	next_phase = 1	reward = 1.005745	array([[ 2.4462354, -7.841011 ]], dtype=float32)
time = 8850	action = 0	current_phase = 0	next_phase = 1	reward = 0.717947	array([[ 2.590812, -7.733138]], dtype=float32)
time = 8855	action = 0	current_phase = 0	next_phase = 1	reward = 0.720330	array([[ 2.4248297, -7.562186 ]], dtype=float32)
time = 8860	action = 0	current_phase = 0	next_phase = 1	reward = 0.723546	array([[ 2.4279368, -7.6674943]], dtype=float32)
time = 8865	action = 0	current_phase = 0	next_phase = 1	reward = 0.444322	array([[ 2.5307133, -7.666856 ]], dtype=float32)
time = 8870	action = 0	current_phase = 0	next_phase = 1	reward = 1.005029	array([[ 2.4057467, -7.8316627]], dtype=float32)
time = 8875	action = 0	current_phase = 0	next_phase = 1	reward = 0.445376	array([[ 2.5765316, -7.721781 ]], dtype=float32)
time = 8880	action = 0	current_phase = 0	next_phase = 1	reward = 1.004260	array([[ 2.6170795, -7.795198 ]], dtype=float32)
time = 8885	action = 0	current_phase = 0	next_phase = 1	reward = 0.446968	array([[ 2.5175745, -7.6781816]], dtype=float32)
time = 8890	action = 0	current_phase = 0	next_phase = 1	reward = 1.006355	array([[ 2.6011498, -7.81225  ]], dtype=float32)
time = 8895	action = 0	current_phase = 0	next_phase = 1	reward = 0.719264	array([[ 2.504598 , -7.7406197]], dtype=float32)
time = 8900	action = 0	current_phase = 0	next_phase = 1	reward = 0.717476	array([[ 2.4128954, -7.608717 ]], dtype=float32)
time = 8905	action = 0	current_phase = 0	next_phase = 1	reward = 0.440477	array([[ 2.4270303, -7.747671 ]], dtype=float32)
time = 8910	action = 0	current_phase = 0	next_phase = 1	reward = 1.006471	array([[ 2.5411737, -7.716197 ]], dtype=float32)
time = 8915	action = 0	current_phase = 0	next_phase = 1	reward = 0.720144	array([[ 2.4708679, -7.664726 ]], dtype=float32)
time = 8920	action = 0	current_phase = 0	next_phase = 1	reward = 0.166932	array([[ 2.5832565, -7.7791433]], dtype=float32)
time = 8925	action = 0	current_phase = 0	next_phase = 1	reward = 1.010732	array([[ 2.340799, -7.693411]], dtype=float32)
time = 8930	action = 0	current_phase = 0	next_phase = 1	reward = 1.009034	array([[ 2.330157 , -7.6442976]], dtype=float32)
time = 8935	action = 0	current_phase = 0	next_phase = 1	reward = 0.442217	array([[ 2.6165035, -7.7383804]], dtype=float32)
time = 8940	action = 0	current_phase = 0	next_phase = 1	reward = 1.006430	array([[ 2.4442074, -7.6745405]], dtype=float32)
time = 8945	action = 0	current_phase = 0	next_phase = 1	reward = 0.726348	array([[ 2.481662, -7.692893]], dtype=float32)
time = 8950	action = 0	current_phase = 0	next_phase = 1	reward = 0.717700	array([[ 2.5912564, -7.700453 ]], dtype=float32)
time = 8955	action = 0	current_phase = 0	next_phase = 1	reward = 0.718477	array([[ 2.4888403, -7.7431493]], dtype=float32)
time = 8960	action = 0	current_phase = 0	next_phase = 1	reward = 0.449253	array([[ 2.565848, -7.723789]], dtype=float32)
time = 8965	action = 0	current_phase = 0	next_phase = 1	reward = 1.016884	array([[ 2.1951377, -7.5573654]], dtype=float32)
time = 8970	action = 0	current_phase = 0	next_phase = 1	reward = 0.720963	array([[ 2.5418675, -7.6828203]], dtype=float32)
time = 8975	action = 0	current_phase = 0	next_phase = 1	reward = 0.716959	array([[ 2.4631183, -7.644193 ]], dtype=float32)
time = 8980	action = 0	current_phase = 0	next_phase = 1	reward = 0.436879	array([[ 2.5747235, -7.7073407]], dtype=float32)
time = 8985	action = 0	current_phase = 0	next_phase = 1	reward = 0.723338	array([[ 2.4380214, -7.7113266]], dtype=float32)
time = 8990	action = 0	current_phase = 0	next_phase = 1	reward = 0.721860	array([[ 2.5543282, -7.7746897]], dtype=float32)
time = 8995	action = 0	current_phase = 0	next_phase = 1	reward = 1.000222	array([[ 2.406741, -7.733039]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 6.0344 - val_loss: 3.6556
Epoch 2/50
 - 4s - loss: 6.2380 - val_loss: 4.2358
Epoch 3/50
 - 5s - loss: 5.0928 - val_loss: 4.3952
Epoch 4/50
 - 6s - loss: 5.1914 - val_loss: 5.4605
Epoch 5/50
 - 4s - loss: 4.8794 - val_loss: 4.5525
Epoch 6/50
 - 4s - loss: 5.8036 - val_loss: 3.6297
Epoch 7/50
 - 4s - loss: 5.4742 - val_loss: 3.8360
Epoch 8/50
 - 4s - loss: 5.0966 - val_loss: 4.7957
Epoch 9/50
 - 4s - loss: 6.3030 - val_loss: 4.5690
Epoch 10/50
 - 4s - loss: 4.3981 - val_loss: 4.2048
Epoch 11/50
 - 5s - loss: 4.5712 - val_loss: 4.4572
Epoch 12/50
 - 4s - loss: 4.0033 - val_loss: 4.3811
Epoch 13/50
 - 4s - loss: 4.5875 - val_loss: 4.1593
Epoch 14/50
 - 4s - loss: 5.0216 - val_loss: 4.6835
Epoch 15/50
 - 4s - loss: 5.1090 - val_loss: 5.0168
Epoch 16/50
 - 4s - loss: 4.7260 - val_loss: 4.6214
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 9000	action = 0	current_phase = 0	next_phase = 1	reward = 0.722124	array([[ 2.5268745, -7.718636 ]], dtype=float32)
time = 9005	action = 0	current_phase = 0	next_phase = 1	reward = 0.433659	array([[ 2.4723659, -7.6651363]], dtype=float32)
time = 9010	action = 0	current_phase = 0	next_phase = 1	reward = 0.732613	array([[ 2.52135, -7.71527]], dtype=float32)
time = 9015	action = 0	current_phase = 0	next_phase = 1	reward = 1.011405	array([[ 2.476554, -7.755554]], dtype=float32)
time = 9020	action = 0	current_phase = 0	next_phase = 1	reward = 0.735003	array([[ 2.5654097, -7.7119875]], dtype=float32)
time = 9025	action = 0	current_phase = 0	next_phase = 1	reward = 0.716379	array([[ 2.49968  , -7.6633215]], dtype=float32)
time = 9030	action = 0	current_phase = 0	next_phase = 1	reward = 0.721865	array([[ 2.2434874, -7.735999 ]], dtype=float32)
time = 9035	action = 0	current_phase = 0	next_phase = 1	reward = 0.444838	array([[ 2.516181 , -7.7547784]], dtype=float32)
time = 9040	action = 0	current_phase = 0	next_phase = 1	reward = 1.004754	array([[ 2.5247698, -7.8474226]], dtype=float32)
time = 9045	action = 0	current_phase = 0	next_phase = 1	reward = 0.722259	array([[ 2.5349731, -7.722907 ]], dtype=float32)
time = 9050	action = 0	current_phase = 0	next_phase = 1	reward = 0.724934	array([[ 2.4915042, -7.7077637]], dtype=float32)
time = 9055	action = 0	current_phase = 0	next_phase = 1	reward = 0.727294	array([[ 2.537012 , -7.7169085]], dtype=float32)
time = 9060	action = 0	current_phase = 0	next_phase = 1	reward = 0.715330	array([[ 2.5247798, -7.723994 ]], dtype=float32)
time = 9065	action = 0	current_phase = 0	next_phase = 1	reward = 0.726556	array([[ 2.5029173, -7.697884 ]], dtype=float32)
time = 9070	action = 0	current_phase = 0	next_phase = 1	reward = 0.724440	array([[ 2.5365868, -7.7446632]], dtype=float32)
time = 9075	action = 0	current_phase = 0	next_phase = 1	reward = 0.726012	array([[ 2.5101347, -7.714034 ]], dtype=float32)
time = 9080	action = 0	current_phase = 0	next_phase = 1	reward = 0.720502	array([[ 2.4966607, -7.6775227]], dtype=float32)
time = 9085	action = 0	current_phase = 0	next_phase = 1	reward = 0.446151	array([[ 2.5119429, -7.7036242]], dtype=float32)
time = 9090	action = 0	current_phase = 0	next_phase = 1	reward = 1.008572	array([[ 2.5241084, -7.7584934]], dtype=float32)
time = 9095	action = 0	current_phase = 0	next_phase = 1	reward = 0.728229	array([[ 2.5485625, -7.7428093]], dtype=float32)
time = 9100	action = 0	current_phase = 0	next_phase = 1	reward = 0.726480	array([[ 2.5314403, -7.746583 ]], dtype=float32)
time = 9105	action = 0	current_phase = 0	next_phase = 1	reward = 0.724157	array([[ 2.4675283, -7.7460985]], dtype=float32)
time = 9110	action = 0	current_phase = 0	next_phase = 1	reward = 0.720562	array([[ 2.4991293, -7.6813097]], dtype=float32)
time = 9115	action = 0	current_phase = 0	next_phase = 1	reward = 0.715337	array([[ 2.5350971, -7.690585 ]], dtype=float32)
time = 9120	action = 0	current_phase = 0	next_phase = 1	reward = 0.720214	array([[ 2.5464344, -7.7658243]], dtype=float32)
time = 9125	action = 0	current_phase = 0	next_phase = 1	reward = 0.715194	array([[ 2.5954533, -7.7931213]], dtype=float32)
time = 9130	action = 0	current_phase = 0	next_phase = 1	reward = 0.436782	array([[ 2.4160142, -7.7955704]], dtype=float32)
time = 9135	action = 0	current_phase = 0	next_phase = 1	reward = 0.730152	array([[ 2.4482212, -7.717492 ]], dtype=float32)
time = 9140	action = 0	current_phase = 0	next_phase = 1	reward = 1.010213	array([[ 2.4633522, -7.7108984]], dtype=float32)
time = 9145	action = 0	current_phase = 0	next_phase = 1	reward = 0.451697	array([[ 2.5033522, -7.738114 ]], dtype=float32)
time = 9150	action = 0	current_phase = 0	next_phase = 1	reward = 1.017878	array([[ 2.4933863, -7.7318354]], dtype=float32)
time = 9155	action = 0	current_phase = 0	next_phase = 1	reward = 0.724338	array([[ 2.4479089, -7.7491193]], dtype=float32)
time = 9160	action = 0	current_phase = 0	next_phase = 1	reward = 0.710442	array([[ 2.5829062, -7.727615 ]], dtype=float32)
time = 9165	action = 0	current_phase = 0	next_phase = 1	reward = 0.162141	array([[ 2.5139346, -7.727928 ]], dtype=float32)
time = 9170	action = 0	current_phase = 0	next_phase = 1	reward = 1.008610	array([[ 2.476318 , -7.8340387]], dtype=float32)
time = 9175	action = 0	current_phase = 0	next_phase = 1	reward = 0.728892	array([[ 2.501617 , -7.6775665]], dtype=float32)
time = 9180	action = 0	current_phase = 0	next_phase = 1	reward = 1.008409	array([[ 2.3734212, -7.77277  ]], dtype=float32)
time = 9185	action = 0	current_phase = 0	next_phase = 1	reward = 0.437788	array([[ 2.428772 , -7.6633277]], dtype=float32)
time = 9190	action = 0	current_phase = 0	next_phase = 1	reward = 0.723101	array([[ 2.5219474, -7.765173 ]], dtype=float32)
time = 9195	action = 0	current_phase = 0	next_phase = 1	reward = 1.006867	array([[ 2.359383, -7.793086]], dtype=float32)
time = 9200	action = 0	current_phase = 0	next_phase = 1	reward = 0.447801	array([[ 2.4839516, -7.699024 ]], dtype=float32)
time = 9205	action = 0	current_phase = 0	next_phase = 1	reward = 1.003383	array([[ 2.4689188, -7.755685 ]], dtype=float32)
time = 9210	action = 0	current_phase = 0	next_phase = 1	reward = 0.445147	array([[ 2.5094123, -7.702832 ]], dtype=float32)
time = 9215	action = 0	current_phase = 0	next_phase = 1	reward = 0.728616	array([[ 2.4558806, -7.7596874]], dtype=float32)
time = 9220	action = 0	current_phase = 0	next_phase = 1	reward = 0.726631	array([[ 2.4654956, -7.7647533]], dtype=float32)
time = 9225	action = 0	current_phase = 0	next_phase = 1	reward = 1.000664	array([[ 2.7184262, -7.9934206]], dtype=float32)
time = 9230	action = 0	current_phase = 0	next_phase = 1	reward = 0.170273	array([[ 2.4924679, -7.719101 ]], dtype=float32)
time = 9235	action = 0	current_phase = 0	next_phase = 1	reward = 1.015441	array([[ 2.442883, -7.81069 ]], dtype=float32)
time = 9240	action = 0	current_phase = 0	next_phase = 1	reward = 1.016987	array([[ 2.5089426, -7.7314963]], dtype=float32)
time = 9245	action = 0	current_phase = 0	next_phase = 1	reward = 0.721862	array([[ 2.6642442, -7.817009 ]], dtype=float32)
time = 9250	action = 0	current_phase = 0	next_phase = 1	reward = 0.720555	array([[ 2.429522 , -7.8332176]], dtype=float32)
time = 9255	action = 0	current_phase = 0	next_phase = 1	reward = 0.716506	array([[ 2.4388695, -7.8133445]], dtype=float32)
time = 9260	action = 0	current_phase = 0	next_phase = 1	reward = 0.434767	array([[ 2.5424385, -7.730859 ]], dtype=float32)
time = 9265	action = 0	current_phase = 0	next_phase = 1	reward = 0.993656	array([[ 2.4995027, -7.7298775]], dtype=float32)
time = 9270	action = 0	current_phase = 0	next_phase = 1	reward = 0.448184	array([[ 2.5026288, -7.697908 ]], dtype=float32)
time = 9275	action = 0	current_phase = 0	next_phase = 1	reward = 1.011059	array([[ 2.4527006, -7.7312155]], dtype=float32)
time = 9280	action = 0	current_phase = 0	next_phase = 1	reward = 0.445852	array([[ 2.5747633, -7.832776 ]], dtype=float32)
time = 9285	action = 0	current_phase = 0	next_phase = 1	reward = 0.726808	array([[ 2.492558 , -7.7098303]], dtype=float32)
time = 9290	action = 0	current_phase = 0	next_phase = 1	reward = 0.727279	array([[ 2.2004242, -7.808703 ]], dtype=float32)
time = 9295	action = 0	current_phase = 0	next_phase = 1	reward = 0.999361	array([[ 2.4033566, -7.7406545]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 6s - loss: 8.3788 - val_loss: 5.7593
Epoch 2/50
 - 4s - loss: 6.1719 - val_loss: 6.3160
Epoch 3/50
 - 5s - loss: 5.6960 - val_loss: 5.7475
Epoch 4/50
 - 7s - loss: 6.5530 - val_loss: 5.5871
Epoch 5/50
 - 5s - loss: 4.8445 - val_loss: 6.0072
Epoch 6/50
 - 5s - loss: 5.6366 - val_loss: 5.8943
Epoch 7/50
 - 5s - loss: 5.3955 - val_loss: 5.9344
Epoch 8/50
 - 5s - loss: 5.8328 - val_loss: 5.7458
Epoch 9/50
 - 5s - loss: 4.9836 - val_loss: 5.0246
Epoch 10/50
 - 5s - loss: 4.7998 - val_loss: 4.8967
Epoch 11/50
 - 4s - loss: 5.3621 - val_loss: 5.5196
Epoch 12/50
 - 5s - loss: 4.9059 - val_loss: 6.4110
Epoch 13/50
 - 5s - loss: 4.6465 - val_loss: 5.2044
Epoch 14/50
 - 5s - loss: 4.4742 - val_loss: 6.3424
Epoch 15/50
 - 5s - loss: 4.1511 - val_loss: 6.3072
Epoch 16/50
 - 4s - loss: 5.1788 - val_loss: 7.6806
Epoch 17/50
 - 5s - loss: 4.9209 - val_loss: 6.4898
Epoch 18/50
 - 5s - loss: 5.0913 - val_loss: 4.9025
Epoch 19/50
 - 5s - loss: 4.2585 - val_loss: 6.7945
Epoch 20/50
 - 5s - loss: 4.3623 - val_loss: 5.0853
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 9300	action = 0	current_phase = 0	next_phase = 1	reward = 0.442081	array([[ 2.7266016, -7.722699 ]], dtype=float32)
time = 9305	action = 0	current_phase = 0	next_phase = 1	reward = 0.730203	array([[ 2.7505102, -7.7529488]], dtype=float32)
time = 9310	action = 0	current_phase = 0	next_phase = 1	reward = 0.994351	array([[ 2.7164583, -7.9449196]], dtype=float32)
time = 9315	action = 0	current_phase = 0	next_phase = 1	reward = 0.442071	array([[ 2.630063 , -7.7427483]], dtype=float32)
time = 9320	action = 0	current_phase = 0	next_phase = 1	reward = 0.727405	array([[ 2.6697097, -7.7355185]], dtype=float32)
time = 9325	action = 0	current_phase = 0	next_phase = 1	reward = 0.729597	array([[ 2.5494208, -7.947009 ]], dtype=float32)
time = 9330	action = 0	current_phase = 0	next_phase = 1	reward = 1.000384	array([[ 2.675632, -7.858097]], dtype=float32)
time = 9335	action = 0	current_phase = 0	next_phase = 1	reward = 0.722174	array([[ 2.71595  , -7.7452183]], dtype=float32)
time = 9340	action = 0	current_phase = 0	next_phase = 1	reward = 0.723664	array([[ 2.8029847, -7.7987914]], dtype=float32)
time = 9345	action = 0	current_phase = 0	next_phase = 1	reward = 0.722388	array([[ 2.6559095, -7.7042637]], dtype=float32)
time = 9350	action = 0	current_phase = 0	next_phase = 1	reward = 0.438799	array([[ 2.734715 , -7.6891384]], dtype=float32)
time = 9355	action = 0	current_phase = 0	next_phase = 1	reward = 0.724280	array([[ 2.6966286, -7.6967125]], dtype=float32)
time = 9360	action = 0	current_phase = 0	next_phase = 1	reward = 0.725656	array([[ 2.8054862, -7.902665 ]], dtype=float32)
time = 9365	action = 0	current_phase = 0	next_phase = 1	reward = 1.015352	array([[ 2.5579257, -7.7338753]], dtype=float32)
time = 9370	action = 0	current_phase = 0	next_phase = 1	reward = 0.728559	array([[ 2.4886084, -7.742792 ]], dtype=float32)
time = 9375	action = 0	current_phase = 0	next_phase = 1	reward = 0.720558	array([[ 2.6831331, -7.693361 ]], dtype=float32)
time = 9380	action = 0	current_phase = 0	next_phase = 1	reward = 0.714218	array([[ 2.6954312, -7.7085495]], dtype=float32)
time = 9385	action = 0	current_phase = 0	next_phase = 1	reward = 0.441420	array([[ 2.684578, -7.780325]], dtype=float32)
time = 9390	action = 0	current_phase = 0	next_phase = 1	reward = 0.724174	array([[ 2.7326107, -7.7559857]], dtype=float32)
time = 9395	action = 0	current_phase = 0	next_phase = 1	reward = 1.002806	array([[ 2.6162996, -7.789604 ]], dtype=float32)
time = 9400	action = 0	current_phase = 0	next_phase = 1	reward = 0.722392	array([[ 2.7026544, -7.7200866]], dtype=float32)
time = 9405	action = 0	current_phase = 0	next_phase = 1	reward = 0.726601	array([[ 2.6907039, -7.726426 ]], dtype=float32)
time = 9410	action = 0	current_phase = 0	next_phase = 1	reward = 0.726724	array([[ 2.8066883, -7.8159947]], dtype=float32)
time = 9415	action = 0	current_phase = 0	next_phase = 1	reward = 0.722062	array([[ 2.6833062, -7.691059 ]], dtype=float32)
time = 9420	action = 0	current_phase = 0	next_phase = 1	reward = 0.442478	array([[ 2.733563 , -7.7344637]], dtype=float32)
time = 9425	action = 0	current_phase = 0	next_phase = 1	reward = 0.454112	array([[ 2.7394547, -7.757144 ]], dtype=float32)
time = 9430	action = 0	current_phase = 0	next_phase = 1	reward = 1.282464	array([[ 2.6304998, -7.8158026]], dtype=float32)
time = 9435	action = 0	current_phase = 0	next_phase = 1	reward = 0.447236	array([[ 2.6912522, -7.739981 ]], dtype=float32)
time = 9440	action = 0	current_phase = 0	next_phase = 1	reward = 0.729904	array([[ 2.674344 , -7.8027554]], dtype=float32)
time = 9445	action = 0	current_phase = 0	next_phase = 1	reward = 1.009846	array([[ 2.688076, -7.73361 ]], dtype=float32)
time = 9450	action = 0	current_phase = 0	next_phase = 1	reward = 0.440854	array([[ 2.715755 , -7.7616735]], dtype=float32)
time = 9455	action = 0	current_phase = 0	next_phase = 1	reward = 1.002880	array([[ 2.567235 , -7.7495103]], dtype=float32)
time = 9460	action = 0	current_phase = 0	next_phase = 1	reward = 0.442550	array([[ 2.7211876, -7.72513  ]], dtype=float32)
time = 9465	action = 0	current_phase = 0	next_phase = 1	reward = 1.000892	array([[ 2.461762 , -7.7896657]], dtype=float32)
time = 9470	action = 0	current_phase = 0	next_phase = 1	reward = 0.443455	array([[ 2.7337933, -7.7518044]], dtype=float32)
time = 9475	action = 0	current_phase = 0	next_phase = 1	reward = 1.010889	array([[ 2.7055812, -7.6998825]], dtype=float32)
time = 9480	action = 0	current_phase = 0	next_phase = 1	reward = 0.722337	array([[ 2.732295 , -7.7397475]], dtype=float32)
time = 9485	action = 0	current_phase = 0	next_phase = 1	reward = 0.439459	array([[ 2.6965556, -7.755831 ]], dtype=float32)
time = 9490	action = 0	current_phase = 0	next_phase = 1	reward = 1.006245	array([[ 2.6602335, -7.738734 ]], dtype=float32)
time = 9495	action = 0	current_phase = 0	next_phase = 1	reward = 0.718385	array([[ 2.6674762, -7.7563815]], dtype=float32)
time = 9500	action = 0	current_phase = 0	next_phase = 1	reward = 0.444040	array([[ 2.717606, -7.739891]], dtype=float32)
time = 9505	action = 0	current_phase = 0	next_phase = 1	reward = 0.731863	array([[ 2.6905465, -7.74111  ]], dtype=float32)
time = 9510	action = 0	current_phase = 0	next_phase = 1	reward = 1.002292	array([[ 2.7033725, -7.7529917]], dtype=float32)
time = 9515	action = 0	current_phase = 0	next_phase = 1	reward = 0.445731	array([[ 2.7369556, -7.716235 ]], dtype=float32)
time = 9520	action = 0	current_phase = 0	next_phase = 1	reward = 1.000507	array([[ 2.670467, -7.798716]], dtype=float32)
time = 9525	action = 0	current_phase = 0	next_phase = 1	reward = 0.714389	array([[ 2.6913066, -7.7657366]], dtype=float32)
time = 9530	action = 0	current_phase = 0	next_phase = 1	reward = 0.437236	array([[ 2.7391195, -7.71741  ]], dtype=float32)
time = 9535	action = 0	current_phase = 0	next_phase = 1	reward = 0.731675	array([[ 2.639841, -7.709363]], dtype=float32)
time = 9540	action = 0	current_phase = 0	next_phase = 1	reward = 0.726661	array([[ 2.705409, -7.75821 ]], dtype=float32)
time = 9545	action = 0	current_phase = 0	next_phase = 1	reward = 1.005468	array([[ 2.576837, -7.836434]], dtype=float32)
time = 9550	action = 0	current_phase = 0	next_phase = 1	reward = 0.717534	array([[ 2.6963892, -7.707588 ]], dtype=float32)
time = 9555	action = 0	current_phase = 0	next_phase = 1	reward = 0.722360	array([[ 2.6988606, -7.724686 ]], dtype=float32)
time = 9560	action = 0	current_phase = 0	next_phase = 1	reward = 0.736327	array([[ 2.7156553, -7.7366676]], dtype=float32)
time = 9565	action = 0	current_phase = 0	next_phase = 1	reward = 0.731110	array([[ 2.7469301, -7.77983  ]], dtype=float32)
time = 9570	action = 0	current_phase = 0	next_phase = 1	reward = 0.724702	array([[ 2.6779542, -7.7518716]], dtype=float32)
time = 9575	action = 0	current_phase = 0	next_phase = 1	reward = 0.721202	array([[ 2.738181, -7.829425]], dtype=float32)
time = 9580	action = 0	current_phase = 0	next_phase = 1	reward = 0.719228	array([[ 2.7069182, -7.7289925]], dtype=float32)
time = 9585	action = 0	current_phase = 0	next_phase = 1	reward = 0.725020	array([[ 2.670814, -7.692501]], dtype=float32)
time = 9590	action = 0	current_phase = 0	next_phase = 1	reward = 0.448075	array([[ 2.6463513, -7.7191925]], dtype=float32)
time = 9595	action = 0	current_phase = 0	next_phase = 1	reward = 0.723274	array([[ 2.6671162, -7.7502785]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 5s - loss: 7.0901 - val_loss: 2.4026
Epoch 2/50
 - 5s - loss: 5.3032 - val_loss: 2.5646
Epoch 3/50
 - 5s - loss: 6.0399 - val_loss: 2.9764
Epoch 4/50
 - 5s - loss: 5.3864 - val_loss: 3.0582
Epoch 5/50
 - 5s - loss: 4.6403 - val_loss: 2.7117
Epoch 6/50
 - 5s - loss: 4.2502 - val_loss: 2.6924
Epoch 7/50
 - 5s - loss: 5.0625 - val_loss: 2.8421
Epoch 8/50
 - 4s - loss: 5.7542 - val_loss: 2.8834
Epoch 9/50
 - 5s - loss: 5.7709 - val_loss: 2.4489
Epoch 10/50
 - 5s - loss: 4.9166 - val_loss: 2.9005
Epoch 11/50
 - 5s - loss: 5.2945 - val_loss: 3.7373
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 9600	action = 0	current_phase = 0	next_phase = 1	reward = 1.001092	array([[ 2.7167594, -7.765048 ]], dtype=float32)
time = 9605	action = 0	current_phase = 0	next_phase = 1	reward = 0.723528	array([[ 2.7719886, -7.801174 ]], dtype=float32)
time = 9610	action = 0	current_phase = 0	next_phase = 1	reward = 0.719288	array([[ 2.6860578, -7.790854 ]], dtype=float32)
time = 9615	action = 0	current_phase = 0	next_phase = 1	reward = 0.447151	array([[ 2.7696397, -7.726901 ]], dtype=float32)
time = 9620	action = 0	current_phase = 0	next_phase = 1	reward = 1.012934	array([[ 2.7206042, -7.751462 ]], dtype=float32)
time = 9625	action = 0	current_phase = 0	next_phase = 1	reward = 0.722191	array([[ 2.766537, -7.86477 ]], dtype=float32)
time = 9630	action = 0	current_phase = 0	next_phase = 1	reward = 0.721617	array([[ 2.755068 , -7.7957716]], dtype=float32)
time = 9635	action = 0	current_phase = 0	next_phase = 1	reward = 0.720657	array([[ 2.724179, -7.838068]], dtype=float32)
time = 9640	action = 0	current_phase = 0	next_phase = 1	reward = 0.716268	array([[ 2.7083871, -7.829444 ]], dtype=float32)
time = 9645	action = 0	current_phase = 0	next_phase = 1	reward = 0.717149	array([[ 2.7742054, -7.760724 ]], dtype=float32)
time = 9650	action = 0	current_phase = 0	next_phase = 1	reward = 0.708976	array([[ 2.69115  , -7.8048334]], dtype=float32)
time = 9655	action = 0	current_phase = 0	next_phase = 1	reward = 0.441675	array([[ 2.705922, -7.89104 ]], dtype=float32)
time = 9660	action = 0	current_phase = 0	next_phase = 1	reward = 0.729761	array([[ 2.6730516, -7.924752 ]], dtype=float32)
time = 9665	action = 0	current_phase = 0	next_phase = 1	reward = 1.011433	array([[ 2.5980508, -7.80525  ]], dtype=float32)
time = 9670	action = 0	current_phase = 0	next_phase = 1	reward = 0.722559	array([[ 2.734206, -7.704668]], dtype=float32)
time = 9675	action = 0	current_phase = 0	next_phase = 1	reward = 0.442265	array([[ 2.692579, -7.734928]], dtype=float32)
time = 9680	action = 0	current_phase = 0	next_phase = 1	reward = 0.727008	array([[ 2.7660906, -7.9566336]], dtype=float32)
time = 9685	action = 0	current_phase = 0	next_phase = 1	reward = 1.013869	array([[ 2.718682 , -7.7400155]], dtype=float32)
time = 9690	action = 0	current_phase = 0	next_phase = 1	reward = 0.723297	array([[ 2.7184303, -7.733296 ]], dtype=float32)
time = 9695	action = 0	current_phase = 0	next_phase = 1	reward = 0.443853	array([[ 2.705877, -7.763406]], dtype=float32)
time = 9700	action = 0	current_phase = 0	next_phase = 1	reward = 1.004132	array([[ 2.6304696, -7.698079 ]], dtype=float32)
time = 9705	action = 0	current_phase = 0	next_phase = 1	reward = 0.445160	array([[ 2.7688353, -7.7742186]], dtype=float32)
time = 9710	action = 0	current_phase = 0	next_phase = 1	reward = 1.009334	array([[ 2.7462819, -7.7580614]], dtype=float32)
time = 9715	action = 0	current_phase = 0	next_phase = 1	reward = 0.714920	array([[ 2.7168953, -7.7604585]], dtype=float32)
time = 9720	action = 0	current_phase = 0	next_phase = 1	reward = 0.718052	array([[ 2.704292 , -7.7234163]], dtype=float32)
time = 9725	action = 0	current_phase = 0	next_phase = 1	reward = 0.436470	array([[ 2.7177756, -7.733773 ]], dtype=float32)
time = 9730	action = 0	current_phase = 0	next_phase = 1	reward = 0.995202	array([[ 2.7338836, -7.973547 ]], dtype=float32)
time = 9735	action = 0	current_phase = 0	next_phase = 1	reward = 0.171788	array([[ 2.6816804, -7.702882 ]], dtype=float32)
time = 9740	action = 0	current_phase = 0	next_phase = 1	reward = 1.004793	array([[ 2.5808904, -7.918743 ]], dtype=float32)
time = 9745	action = 0	current_phase = 0	next_phase = 1	reward = 0.440619	array([[ 2.803035, -7.948579]], dtype=float32)
time = 9750	action = 0	current_phase = 0	next_phase = 1	reward = 1.289937	array([[ 2.633023, -7.783342]], dtype=float32)
time = 9755	action = 0	current_phase = 0	next_phase = 1	reward = 0.727176	array([[ 2.595904 , -7.8597655]], dtype=float32)
time = 9760	action = 0	current_phase = 0	next_phase = 1	reward = 0.729480	array([[ 2.730964 , -7.8005824]], dtype=float32)
time = 9765	action = 0	current_phase = 0	next_phase = 1	reward = 0.723475	array([[ 2.7317574, -7.9167547]], dtype=float32)
time = 9770	action = 0	current_phase = 0	next_phase = 1	reward = 0.721792	array([[ 2.7038743, -7.737383 ]], dtype=float32)
time = 9775	action = 0	current_phase = 0	next_phase = 1	reward = 0.717461	array([[ 2.6949828, -7.7138243]], dtype=float32)
time = 9780	action = 0	current_phase = 0	next_phase = 1	reward = 0.440823	array([[ 2.6843288, -7.7500744]], dtype=float32)
time = 9785	action = 0	current_phase = 0	next_phase = 1	reward = 1.012175	array([[ 2.741151, -7.851062]], dtype=float32)
time = 9790	action = 0	current_phase = 0	next_phase = 1	reward = 0.715538	array([[ 2.762122, -7.739867]], dtype=float32)
time = 9795	action = 0	current_phase = 0	next_phase = 1	reward = 0.717204	array([[ 2.5763175, -7.8160534]], dtype=float32)
time = 9800	action = 0	current_phase = 0	next_phase = 1	reward = 0.166274	array([[ 2.516485 , -7.6944838]], dtype=float32)
time = 9805	action = 0	current_phase = 0	next_phase = 1	reward = 1.286739	array([[ 2.597081, -7.780591]], dtype=float32)
time = 9810	action = 0	current_phase = 0	next_phase = 1	reward = 0.446218	array([[ 2.7432797, -7.8163095]], dtype=float32)
time = 9815	action = 0	current_phase = 0	next_phase = 1	reward = 0.728088	array([[ 2.826774 , -7.8954935]], dtype=float32)
time = 9820	action = 0	current_phase = 0	next_phase = 1	reward = 0.725426	array([[ 2.6396844, -7.814005 ]], dtype=float32)
time = 9825	action = 0	current_phase = 0	next_phase = 1	reward = 1.002066	array([[ 2.6861503, -7.861639 ]], dtype=float32)
time = 9830	action = 0	current_phase = 0	next_phase = 1	reward = 0.723003	array([[ 2.757078, -7.72093 ]], dtype=float32)
time = 9835	action = 0	current_phase = 0	next_phase = 1	reward = 0.724153	array([[ 2.5682662, -7.800475 ]], dtype=float32)
time = 9840	action = 0	current_phase = 0	next_phase = 1	reward = 0.443639	array([[ 2.7572672, -7.7711225]], dtype=float32)
time = 9845	action = 0	current_phase = 0	next_phase = 1	reward = 1.004888	array([[ 2.7360504, -7.7835503]], dtype=float32)
time = 9850	action = 0	current_phase = 0	next_phase = 1	reward = 0.726191	array([[ 2.7354462, -7.8749914]], dtype=float32)
time = 9855	action = 0	current_phase = 0	next_phase = 1	reward = 0.442612	array([[ 2.7656314, -7.7225657]], dtype=float32)
time = 9860	action = 0	current_phase = 0	next_phase = 1	reward = 1.008446	array([[ 2.6034195, -7.9167686]], dtype=float32)
time = 9865	action = 0	current_phase = 0	next_phase = 1	reward = 0.720617	array([[ 2.7351906, -7.7810535]], dtype=float32)
time = 9870	action = 0	current_phase = 0	next_phase = 1	reward = 0.717737	array([[ 2.7506177, -7.7548027]], dtype=float32)
time = 9875	action = 0	current_phase = 0	next_phase = 1	reward = 0.717233	array([[ 2.7424638, -7.762152 ]], dtype=float32)
time = 9880	action = 0	current_phase = 0	next_phase = 1	reward = 0.716285	array([[ 2.6978595, -7.759513 ]], dtype=float32)
time = 9885	action = 0	current_phase = 0	next_phase = 1	reward = 0.724924	array([[ 2.56162 , -7.677547]], dtype=float32)
time = 9890	action = 0	current_phase = 0	next_phase = 1	reward = 0.448170	array([[ 2.7147954, -7.771179 ]], dtype=float32)
time = 9895	action = 0	current_phase = 0	next_phase = 1	reward = 1.006689	array([[ 2.8509123, -7.880741 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 6s - loss: 6.4736 - val_loss: 4.5511
Epoch 2/50
 - 6s - loss: 5.6503 - val_loss: 5.0604
Epoch 3/50
 - 6s - loss: 5.3353 - val_loss: 4.6369
Epoch 4/50
 - 6s - loss: 4.7497 - val_loss: 4.3075
Epoch 5/50
 - 6s - loss: 4.7550 - val_loss: 4.8126
Epoch 6/50
 - 5s - loss: 5.0674 - val_loss: 4.6552
Epoch 7/50
 - 6s - loss: 4.9707 - val_loss: 4.5800
Epoch 8/50
 - 6s - loss: 5.1444 - val_loss: 4.3566
Epoch 9/50
 - 6s - loss: 6.3051 - val_loss: 4.8426
Epoch 10/50
 - 5s - loss: 4.8994 - val_loss: 4.4448
Epoch 11/50
 - 5s - loss: 4.6191 - val_loss: 5.1744
Epoch 12/50
 - 5s - loss: 4.4655 - val_loss: 5.3356
Epoch 13/50
 - 6s - loss: 4.7825 - val_loss: 5.1510
Epoch 14/50
 - 5s - loss: 5.0790 - val_loss: 5.5581
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 9900	action = 0	current_phase = 0	next_phase = 1	reward = 0.444662	array([[ 2.682116 , -7.8522005]], dtype=float32)
time = 9905	action = 0	current_phase = 0	next_phase = 1	reward = 0.726133	array([[ 2.7100782, -7.790122 ]], dtype=float32)
time = 9910	action = 0	current_phase = 0	next_phase = 1	reward = 0.998930	array([[ 2.5284 , -7.88393]], dtype=float32)
time = 9915	action = 0	current_phase = 0	next_phase = 1	reward = 0.440952	array([[ 2.7424607, -7.8634796]], dtype=float32)
time = 9920	action = 0	current_phase = 0	next_phase = 1	reward = 1.003101	array([[ 2.6233816, -7.9053154]], dtype=float32)
time = 9925	action = 0	current_phase = 0	next_phase = 1	reward = 0.160497	array([[ 2.736104 , -7.8113055]], dtype=float32)
time = 9930	action = 0	current_phase = 0	next_phase = 1	reward = 1.015088	array([[ 2.530551 , -7.9959626]], dtype=float32)
time = 9935	action = 0	current_phase = 0	next_phase = 1	reward = 0.724078	array([[ 2.7223473, -7.9224167]], dtype=float32)
time = 9940	action = 0	current_phase = 0	next_phase = 1	reward = 0.718625	array([[ 2.6828327, -7.852492 ]], dtype=float32)
time = 9945	action = 0	current_phase = 0	next_phase = 1	reward = 1.000774	array([[ 2.7363038, -7.815402 ]], dtype=float32)
time = 9950	action = 0	current_phase = 0	next_phase = 1	reward = 0.729212	array([[ 2.4579582, -7.900982 ]], dtype=float32)
time = 9955	action = 0	current_phase = 0	next_phase = 1	reward = 0.722225	array([[ 2.6855168, -7.8023033]], dtype=float32)
time = 9960	action = 0	current_phase = 0	next_phase = 1	reward = 0.721596	array([[ 2.727869 , -7.7991533]], dtype=float32)
time = 9965	action = 0	current_phase = 0	next_phase = 1	reward = 0.721117	array([[ 2.700778 , -7.7710805]], dtype=float32)
time = 9970	action = 0	current_phase = 0	next_phase = 1	reward = 0.726911	array([[ 2.6517425, -7.882161 ]], dtype=float32)
time = 9975	action = 0	current_phase = 0	next_phase = 1	reward = 0.730327	array([[ 2.6918144, -7.8911552]], dtype=float32)
time = 9980	action = 0	current_phase = 0	next_phase = 1	reward = 0.712953	array([[ 2.6243901, -7.746943 ]], dtype=float32)
time = 9985	action = 0	current_phase = 0	next_phase = 1	reward = 0.716630	array([[ 2.6565385, -7.831972 ]], dtype=float32)
time = 9990	action = 0	current_phase = 0	next_phase = 1	reward = 0.440903	array([[ 2.7087626, -7.8567653]], dtype=float32)
time = 9995	action = 0	current_phase = 0	next_phase = 1	reward = 1.004075	array([[ 2.6395001, -7.9138684]], dtype=float32)
time = 10000	action = 0	current_phase = 0	next_phase = 1	reward = 0.728928	array([[ 2.5578065, -7.7753778]], dtype=float32)
time = 10005	action = 0	current_phase = 0	next_phase = 1	reward = 0.725240	array([[ 2.694992 , -7.7523375]], dtype=float32)
time = 10010	action = 0	current_phase = 0	next_phase = 1	reward = 0.731228	array([[ 2.5952587, -7.8036504]], dtype=float32)
time = 10015	action = 0	current_phase = 0	next_phase = 1	reward = 0.713957	array([[ 2.7354722, -7.804841 ]], dtype=float32)
time = 10020	action = 0	current_phase = 0	next_phase = 1	reward = 0.440956	array([[ 2.6882968, -7.7228923]], dtype=float32)
time = 10025	action = 0	current_phase = 0	next_phase = 1	reward = 0.731185	array([[ 2.6364293, -7.8231406]], dtype=float32)
time = 10030	action = 0	current_phase = 0	next_phase = 1	reward = 0.727399	array([[ 2.6672373, -7.9135556]], dtype=float32)
time = 10035	action = 0	current_phase = 0	next_phase = 1	reward = 1.006292	array([[ 2.6639953, -7.845528 ]], dtype=float32)
time = 10040	action = 0	current_phase = 0	next_phase = 1	reward = 0.725716	array([[ 2.7404308, -7.8366575]], dtype=float32)
time = 10045	action = 0	current_phase = 0	next_phase = 1	reward = 0.721410	array([[ 2.7362032, -7.853647 ]], dtype=float32)
time = 10050	action = 0	current_phase = 0	next_phase = 1	reward = 0.442672	array([[ 2.6519952, -7.824143 ]], dtype=float32)
time = 10055	action = 0	current_phase = 0	next_phase = 1	reward = 1.003459	array([[ 2.565349, -7.779661]], dtype=float32)
time = 10060	action = 0	current_phase = 0	next_phase = 1	reward = 0.720290	array([[ 2.7286897, -7.749305 ]], dtype=float32)
time = 10065	action = 0	current_phase = 0	next_phase = 1	reward = 0.726417	array([[ 2.747272, -7.820718]], dtype=float32)
time = 10070	action = 0	current_phase = 0	next_phase = 1	reward = 0.732176	array([[ 2.68467  , -7.8384943]], dtype=float32)
time = 10075	action = 0	current_phase = 0	next_phase = 1	reward = 0.712971	array([[ 2.6913705, -7.782639 ]], dtype=float32)
time = 10080	action = 0	current_phase = 0	next_phase = 1	reward = 0.438448	array([[ 2.7249112, -7.996227 ]], dtype=float32)
time = 10085	action = 0	current_phase = 0	next_phase = 1	reward = 0.724453	array([[ 2.663313 , -7.7352934]], dtype=float32)
time = 10090	action = 0	current_phase = 0	next_phase = 1	reward = 1.009258	array([[ 2.6658058, -7.824245 ]], dtype=float32)
time = 10095	action = 0	current_phase = 0	next_phase = 1	reward = 0.722332	array([[ 2.727553, -7.807968]], dtype=float32)
time = 10100	action = 0	current_phase = 0	next_phase = 1	reward = 0.724504	array([[ 2.652626 , -7.7840157]], dtype=float32)
time = 10105	action = 0	current_phase = 0	next_phase = 1	reward = 0.711555	array([[ 2.6464067, -7.932009 ]], dtype=float32)
time = 10110	action = 0	current_phase = 0	next_phase = 1	reward = 0.724798	array([[ 2.7186255, -7.7543025]], dtype=float32)
time = 10115	action = 0	current_phase = 0	next_phase = 1	reward = 0.724412	array([[ 2.7735834, -8.024893 ]], dtype=float32)
time = 10120	action = 0	current_phase = 0	next_phase = 1	reward = 0.448811	array([[ 2.7622905, -7.8615627]], dtype=float32)
time = 10125	action = 0	current_phase = 0	next_phase = 1	reward = 1.007074	array([[ 2.6591315, -7.897619 ]], dtype=float32)
time = 10130	action = 0	current_phase = 0	next_phase = 1	reward = 0.711990	array([[ 2.729823, -7.80976 ]], dtype=float32)
time = 10135	action = 0	current_phase = 0	next_phase = 1	reward = 0.714053	array([[ 2.7553496, -7.8450727]], dtype=float32)
time = 10140	action = 0	current_phase = 0	next_phase = 1	reward = 0.432505	array([[ 2.700502, -7.849249]], dtype=float32)
time = 10145	action = 0	current_phase = 0	next_phase = 1	reward = 1.007930	array([[ 2.6546388, -7.8287144]], dtype=float32)
time = 10150	action = 0	current_phase = 0	next_phase = 1	reward = 0.725654	array([[ 2.6765847, -7.767697 ]], dtype=float32)
time = 10155	action = 0	current_phase = 0	next_phase = 1	reward = 0.444196	array([[ 2.6885362, -7.837985 ]], dtype=float32)
time = 10160	action = 0	current_phase = 0	next_phase = 1	reward = 1.011836	array([[ 2.6430812, -7.8427854]], dtype=float32)
time = 10165	action = 0	current_phase = 0	next_phase = 1	reward = 0.723076	array([[ 2.7586336, -7.8599944]], dtype=float32)
time = 10170	action = 0	current_phase = 0	next_phase = 1	reward = 0.723962	array([[ 2.7746887, -7.827237 ]], dtype=float32)
time = 10175	action = 0	current_phase = 0	next_phase = 1	reward = 0.722439	array([[ 2.7313313, -7.7845106]], dtype=float32)
time = 10180	action = 0	current_phase = 0	next_phase = 1	reward = 0.726109	array([[ 2.6741495, -7.816967 ]], dtype=float32)
time = 10185	action = 0	current_phase = 0	next_phase = 1	reward = 0.721137	array([[ 2.7050877, -7.7466345]], dtype=float32)
time = 10190	action = 0	current_phase = 0	next_phase = 1	reward = 0.443301	array([[ 2.730134, -7.804677]], dtype=float32)
time = 10195	action = 0	current_phase = 0	next_phase = 1	reward = 0.725406	array([[ 2.7389164, -7.854308 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 5s - loss: 6.8958 - val_loss: 3.1701
Epoch 2/50
 - 5s - loss: 5.3162 - val_loss: 4.0691
Epoch 3/50
 - 5s - loss: 5.0539 - val_loss: 3.9801
Epoch 4/50
 - 5s - loss: 5.8363 - val_loss: 3.5822
Epoch 5/50
 - 5s - loss: 4.9125 - val_loss: 3.8752
Epoch 6/50
 - 5s - loss: 5.2263 - val_loss: 3.9307
Epoch 7/50
 - 5s - loss: 4.8705 - val_loss: 4.0534
Epoch 8/50
 - 4s - loss: 4.7611 - val_loss: 3.6443
Epoch 9/50
 - 5s - loss: 4.8609 - val_loss: 4.2580
Epoch 10/50
 - 5s - loss: 5.4315 - val_loss: 3.1967
Epoch 11/50
 - 4s - loss: 5.1091 - val_loss: 3.0768
Epoch 12/50
 - 5s - loss: 4.8105 - val_loss: 3.3960
Epoch 13/50
 - 5s - loss: 4.7850 - val_loss: 3.8086
Epoch 14/50
 - 4s - loss: 5.1367 - val_loss: 3.5263
Epoch 15/50
 - 4s - loss: 4.8233 - val_loss: 3.1319
Epoch 16/50
 - 5s - loss: 4.7910 - val_loss: 3.9987
Epoch 17/50
 - 4s - loss: 4.8045 - val_loss: 5.8615
Epoch 18/50
 - 4s - loss: 5.7453 - val_loss: 3.6380
Epoch 19/50
 - 4s - loss: 4.4487 - val_loss: 3.6313
Epoch 20/50
 - 4s - loss: 4.5892 - val_loss: 3.4153
Epoch 21/50
 - 4s - loss: 4.4030 - val_loss: 3.3082
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 10200	action = 0	current_phase = 0	next_phase = 1	reward = 1.010987	array([[ 2.596368, -8.071135]], dtype=float32)
time = 10205	action = 0	current_phase = 0	next_phase = 1	reward = 0.722931	array([[ 2.7005365, -7.8775077]], dtype=float32)
time = 10210	action = 0	current_phase = 0	next_phase = 1	reward = 0.722581	array([[ 2.6391509, -7.9432745]], dtype=float32)
time = 10215	action = 0	current_phase = 0	next_phase = 1	reward = 0.725019	array([[ 2.7046273, -7.969921 ]], dtype=float32)
time = 10220	action = 0	current_phase = 0	next_phase = 1	reward = 0.725069	array([[ 2.5040538, -7.9749293]], dtype=float32)
time = 10225	action = 0	current_phase = 0	next_phase = 1	reward = 0.721019	array([[ 2.8230484, -7.9606357]], dtype=float32)
time = 10230	action = 0	current_phase = 0	next_phase = 1	reward = 0.724342	array([[ 2.707555, -7.884593]], dtype=float32)
time = 10235	action = 0	current_phase = 0	next_phase = 1	reward = 0.444953	array([[ 2.6793487, -7.8754144]], dtype=float32)
time = 10240	action = 0	current_phase = 0	next_phase = 1	reward = 1.004462	array([[ 2.5252244, -8.1085615]], dtype=float32)
time = 10245	action = 0	current_phase = 0	next_phase = 1	reward = 0.717428	array([[ 2.6965816, -7.9431543]], dtype=float32)
time = 10250	action = 0	current_phase = 0	next_phase = 1	reward = 0.726700	array([[ 2.682964 , -7.9322815]], dtype=float32)
time = 10255	action = 0	current_phase = 0	next_phase = 1	reward = 0.455431	array([[ 2.706248 , -7.8131466]], dtype=float32)
time = 10260	action = 0	current_phase = 0	next_phase = 1	reward = 1.009943	array([[ 2.6501715, -7.90316  ]], dtype=float32)
time = 10265	action = 0	current_phase = 0	next_phase = 1	reward = 0.440340	array([[ 2.748852, -7.812267]], dtype=float32)
time = 10270	action = 0	current_phase = 0	next_phase = 1	reward = 1.006429	array([[ 2.6319087, -8.175042 ]], dtype=float32)
time = 10275	action = 0	current_phase = 0	next_phase = 1	reward = 0.720637	array([[ 2.6291425, -8.068473 ]], dtype=float32)
time = 10280	action = 0	current_phase = 0	next_phase = 1	reward = 0.718911	array([[ 2.6857908, -7.9129744]], dtype=float32)
time = 10285	action = 0	current_phase = 0	next_phase = 1	reward = 0.716486	array([[ 2.674403, -7.866329]], dtype=float32)
time = 10290	action = 0	current_phase = 0	next_phase = 1	reward = 0.723609	array([[ 2.665931 , -7.9186306]], dtype=float32)
time = 10295	action = 0	current_phase = 0	next_phase = 1	reward = 0.720119	array([[ 2.5649974, -7.852685 ]], dtype=float32)
time = 10300	action = 0	current_phase = 0	next_phase = 1	reward = 0.449248	array([[ 2.6353695, -7.9435725]], dtype=float32)
time = 10305	action = 0	current_phase = 0	next_phase = 1	reward = 1.009419	array([[ 2.7311404, -8.334757 ]], dtype=float32)
time = 10310	action = 0	current_phase = 0	next_phase = 1	reward = 0.724938	array([[ 2.7062514, -7.955933 ]], dtype=float32)
time = 10315	action = 0	current_phase = 0	next_phase = 1	reward = 0.715911	array([[ 2.7231185, -7.891943 ]], dtype=float32)
time = 10320	action = 0	current_phase = 0	next_phase = 1	reward = 0.709938	array([[ 2.649234 , -7.9018364]], dtype=float32)
time = 10325	action = 0	current_phase = 0	next_phase = 1	reward = 0.719790	array([[ 2.7119815, -7.8367295]], dtype=float32)
time = 10330	action = 0	current_phase = 0	next_phase = 1	reward = 0.720730	array([[ 2.513981, -7.902424]], dtype=float32)
time = 10335	action = 0	current_phase = 0	next_phase = 1	reward = 0.443222	array([[ 2.7114236, -7.95892  ]], dtype=float32)
time = 10340	action = 0	current_phase = 0	next_phase = 1	reward = 1.000993	array([[ 2.5922248, -8.11514  ]], dtype=float32)
time = 10345	action = 0	current_phase = 0	next_phase = 1	reward = 0.722235	array([[ 2.6911147, -7.9407306]], dtype=float32)
time = 10350	action = 0	current_phase = 0	next_phase = 1	reward = 0.161734	array([[ 2.7337477, -7.8645544]], dtype=float32)
time = 10355	action = 0	current_phase = 0	next_phase = 1	reward = 1.290028	array([[ 2.5483363, -8.047752 ]], dtype=float32)
time = 10360	action = 0	current_phase = 0	next_phase = 1	reward = 0.448800	array([[ 2.6988184, -7.8511076]], dtype=float32)
time = 10365	action = 0	current_phase = 0	next_phase = 1	reward = 1.004764	array([[ 2.7527916, -8.027253 ]], dtype=float32)
time = 10370	action = 0	current_phase = 0	next_phase = 1	reward = 0.721201	array([[ 2.5964096, -8.131514 ]], dtype=float32)
time = 10375	action = 0	current_phase = 0	next_phase = 1	reward = 0.718709	array([[ 2.5742977, -8.178058 ]], dtype=float32)
time = 10380	action = 0	current_phase = 0	next_phase = 1	reward = 0.718295	array([[ 2.7380989, -7.911702 ]], dtype=float32)
time = 10385	action = 0	current_phase = 0	next_phase = 1	reward = 0.450231	array([[ 2.709655, -7.960678]], dtype=float32)
time = 10390	action = 0	current_phase = 0	next_phase = 1	reward = 0.739994	array([[ 2.5567896, -7.9964347]], dtype=float32)
time = 10395	action = 0	current_phase = 0	next_phase = 1	reward = 1.007392	array([[ 2.5124133, -7.962145 ]], dtype=float32)
time = 10400	action = 0	current_phase = 0	next_phase = 1	reward = 0.724771	array([[ 2.694402 , -7.8632045]], dtype=float32)
time = 10405	action = 0	current_phase = 0	next_phase = 1	reward = 0.725101	array([[ 2.637962 , -7.9902163]], dtype=float32)
time = 10410	action = 0	current_phase = 0	next_phase = 1	reward = 0.721807	array([[ 2.6783578, -7.90629  ]], dtype=float32)
time = 10415	action = 0	current_phase = 0	next_phase = 1	reward = 0.720800	array([[ 2.6819918, -7.877824 ]], dtype=float32)
time = 10420	action = 0	current_phase = 0	next_phase = 1	reward = 0.720979	array([[ 2.6841414, -7.946219 ]], dtype=float32)
time = 10425	action = 0	current_phase = 0	next_phase = 1	reward = 0.722627	array([[ 2.6703203, -7.9337316]], dtype=float32)
time = 10430	action = 0	current_phase = 0	next_phase = 1	reward = 0.728445	array([[ 2.7188566, -7.8673644]], dtype=float32)
time = 10435	action = 0	current_phase = 0	next_phase = 1	reward = 0.724565	array([[ 2.6544936, -7.893664 ]], dtype=float32)
time = 10440	action = 0	current_phase = 0	next_phase = 1	reward = 0.439917	array([[ 2.6492565, -7.9537983]], dtype=float32)
time = 10445	action = 0	current_phase = 0	next_phase = 1	reward = 1.003721	array([[ 2.760505, -8.21814 ]], dtype=float32)
time = 10450	action = 0	current_phase = 0	next_phase = 1	reward = 0.444406	array([[ 2.7225277, -7.849945 ]], dtype=float32)
time = 10455	action = 0	current_phase = 0	next_phase = 1	reward = 0.731138	array([[ 2.6571724, -7.8197284]], dtype=float32)
time = 10460	action = 0	current_phase = 0	next_phase = 1	reward = 0.995756	array([[ 2.6926763, -7.826582 ]], dtype=float32)
time = 10465	action = 0	current_phase = 0	next_phase = 1	reward = 0.445260	array([[ 2.8681514, -8.009495 ]], dtype=float32)
time = 10470	action = 0	current_phase = 0	next_phase = 1	reward = 1.004337	array([[ 2.5997245, -8.045824 ]], dtype=float32)
time = 10475	action = 0	current_phase = 0	next_phase = 1	reward = 0.446447	array([[ 2.7290165, -7.8901644]], dtype=float32)
time = 10480	action = 0	current_phase = 0	next_phase = 1	reward = 1.010864	array([[ 2.6810157, -7.863551 ]], dtype=float32)
time = 10485	action = 0	current_phase = 0	next_phase = 1	reward = 0.732126	array([[ 2.6051538, -8.217332 ]], dtype=float32)
time = 10490	action = 0	current_phase = 0	next_phase = 1	reward = 0.725565	array([[ 2.763219, -7.983203]], dtype=float32)
time = 10495	action = 0	current_phase = 0	next_phase = 1	reward = 0.727494	array([[ 2.6391733, -7.9941254]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.7665 - val_loss: 3.2683
Epoch 2/50
 - 4s - loss: 4.9025 - val_loss: 3.0744
Epoch 3/50
 - 5s - loss: 5.2101 - val_loss: 2.7643
Epoch 4/50
 - 5s - loss: 4.8269 - val_loss: 2.6927
Epoch 5/50
 - 5s - loss: 4.7688 - val_loss: 2.9932
Epoch 6/50
 - 4s - loss: 5.0612 - val_loss: 3.1052
Epoch 7/50
 - 4s - loss: 3.9613 - val_loss: 3.4854
Epoch 8/50
 - 5s - loss: 4.3051 - val_loss: 3.2410
Epoch 9/50
 - 4s - loss: 4.3403 - val_loss: 3.3247
Epoch 10/50
 - 4s - loss: 4.8697 - val_loss: 3.6904
Epoch 11/50
 - 4s - loss: 4.5545 - val_loss: 3.4061
Epoch 12/50
 - 4s - loss: 4.1406 - val_loss: 3.1254
Epoch 13/50
 - 4s - loss: 5.1614 - val_loss: 3.2875
Epoch 14/50
 - 4s - loss: 4.6631 - val_loss: 2.6423
Epoch 15/50
 - 4s - loss: 4.3982 - val_loss: 2.6752
Epoch 16/50
 - 5s - loss: 4.5609 - val_loss: 2.7423
Epoch 17/50
 - 4s - loss: 4.5342 - val_loss: 2.7825
Epoch 18/50
 - 4s - loss: 5.1777 - val_loss: 3.1353
Epoch 19/50
 - 4s - loss: 4.1825 - val_loss: 3.1507
Epoch 20/50
 - 4s - loss: 4.2348 - val_loss: 3.3413
Epoch 21/50
 - 4s - loss: 4.4911 - val_loss: 3.6724
Epoch 22/50
 - 4s - loss: 4.1853 - val_loss: 3.6869
Epoch 23/50
 - 5s - loss: 4.3042 - val_loss: 3.4069
Epoch 24/50
 - 5s - loss: 4.7159 - val_loss: 3.1490
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 10500	action = 0	current_phase = 0	next_phase = 1	reward = 0.724033	array([[ 2.5981812, -8.076792 ]], dtype=float32)
time = 10505	action = 0	current_phase = 0	next_phase = 1	reward = 0.715455	array([[ 2.690134 , -7.9153194]], dtype=float32)
time = 10510	action = 0	current_phase = 0	next_phase = 1	reward = 0.442730	array([[ 2.5889125, -7.985979 ]], dtype=float32)
time = 10515	action = 0	current_phase = 0	next_phase = 1	reward = 0.726790	array([[ 2.6588082, -7.9981246]], dtype=float32)
time = 10520	action = 0	current_phase = 0	next_phase = 1	reward = 1.007888	array([[ 2.5060163, -8.087796 ]], dtype=float32)
time = 10525	action = 0	current_phase = 0	next_phase = 1	reward = 0.724515	array([[ 2.6449704, -7.900076 ]], dtype=float32)
time = 10530	action = 0	current_phase = 0	next_phase = 1	reward = 0.718556	array([[ 2.5370145, -8.022075 ]], dtype=float32)
time = 10535	action = 0	current_phase = 0	next_phase = 1	reward = 0.443673	array([[ 2.4226937, -7.9414673]], dtype=float32)
time = 10540	action = 0	current_phase = 0	next_phase = 1	reward = 1.006875	array([[ 2.6870837, -7.95335  ]], dtype=float32)
time = 10545	action = 0	current_phase = 0	next_phase = 1	reward = 0.440508	array([[ 2.587233, -8.023863]], dtype=float32)
time = 10550	action = 0	current_phase = 0	next_phase = 1	reward = 1.009676	array([[ 2.4668136, -8.003689 ]], dtype=float32)
time = 10555	action = 0	current_phase = 0	next_phase = 1	reward = 0.725878	array([[ 2.7693362, -7.9645815]], dtype=float32)
time = 10560	action = 0	current_phase = 0	next_phase = 1	reward = 0.723862	array([[ 2.563764, -8.040504]], dtype=float32)
time = 10565	action = 0	current_phase = 0	next_phase = 1	reward = 0.716593	array([[ 2.5831676, -8.042411 ]], dtype=float32)
time = 10570	action = 0	current_phase = 0	next_phase = 1	reward = 0.709022	array([[ 2.6212754, -7.962391 ]], dtype=float32)
time = 10575	action = 0	current_phase = 0	next_phase = 1	reward = 0.727760	array([[ 2.6415033, -7.9878693]], dtype=float32)
time = 10580	action = 0	current_phase = 0	next_phase = 1	reward = 0.445957	array([[ 2.603221, -8.077068]], dtype=float32)
time = 10585	action = 0	current_phase = 0	next_phase = 1	reward = 1.012775	array([[ 2.5910568, -8.00867  ]], dtype=float32)
time = 10590	action = 0	current_phase = 0	next_phase = 1	reward = 0.721403	array([[ 2.6582294, -7.9377522]], dtype=float32)
time = 10595	action = 0	current_phase = 0	next_phase = 1	reward = 0.718174	array([[ 2.620655, -8.047003]], dtype=float32)
time = 10600	action = 0	current_phase = 0	next_phase = 1	reward = 0.722392	array([[ 2.6225348, -7.936808 ]], dtype=float32)
time = 10605	action = 0	current_phase = 0	next_phase = 1	reward = 0.723040	array([[ 2.679122, -7.893609]], dtype=float32)
time = 10610	action = 0	current_phase = 0	next_phase = 1	reward = 0.739421	array([[ 2.6763248, -7.945262 ]], dtype=float32)
time = 10615	action = 0	current_phase = 0	next_phase = 1	reward = 0.725010	array([[ 2.6739182, -7.923266 ]], dtype=float32)
time = 10620	action = 0	current_phase = 0	next_phase = 1	reward = 0.723026	array([[ 2.6684475, -7.883854 ]], dtype=float32)
time = 10625	action = 0	current_phase = 0	next_phase = 1	reward = 0.722847	array([[ 2.7211933, -7.8976417]], dtype=float32)
time = 10630	action = 0	current_phase = 0	next_phase = 1	reward = 0.445179	array([[ 2.6485906, -7.961605 ]], dtype=float32)
time = 10635	action = 0	current_phase = 0	next_phase = 1	reward = 1.005695	array([[ 2.6036997, -7.9887133]], dtype=float32)
time = 10640	action = 0	current_phase = 0	next_phase = 1	reward = 0.717512	array([[ 2.5843225, -8.102694 ]], dtype=float32)
time = 10645	action = 0	current_phase = 0	next_phase = 1	reward = 0.442137	array([[ 2.8029943, -8.039139 ]], dtype=float32)
time = 10650	action = 0	current_phase = 0	next_phase = 1	reward = 1.002653	array([[ 2.635714, -8.079878]], dtype=float32)
time = 10655	action = 0	current_phase = 0	next_phase = 1	reward = 0.723503	array([[ 2.6504002, -7.936413 ]], dtype=float32)
time = 10660	action = 0	current_phase = 0	next_phase = 1	reward = 0.441963	array([[ 2.6899853, -8.097248 ]], dtype=float32)
time = 10665	action = 0	current_phase = 0	next_phase = 1	reward = 1.011290	array([[ 2.6548033, -7.909966 ]], dtype=float32)
time = 10670	action = 0	current_phase = 0	next_phase = 1	reward = 0.721505	array([[ 2.6238713, -8.210203 ]], dtype=float32)
time = 10675	action = 0	current_phase = 0	next_phase = 1	reward = 0.728023	array([[ 2.6769853, -7.9196825]], dtype=float32)
time = 10680	action = 0	current_phase = 0	next_phase = 1	reward = 0.719390	array([[ 2.7193441, -8.148901 ]], dtype=float32)
time = 10685	action = 0	current_phase = 0	next_phase = 1	reward = 0.726884	array([[ 2.6875238, -7.9664946]], dtype=float32)
time = 10690	action = 0	current_phase = 0	next_phase = 1	reward = 0.444347	array([[ 2.6213841, -7.865292 ]], dtype=float32)
time = 10695	action = 0	current_phase = 0	next_phase = 1	reward = 0.724692	array([[ 2.5563846, -8.098623 ]], dtype=float32)
time = 10700	action = 0	current_phase = 0	next_phase = 1	reward = 0.732031	array([[ 2.6912847, -7.9649057]], dtype=float32)
time = 10705	action = 0	current_phase = 0	next_phase = 1	reward = 1.000953	array([[ 2.3719358, -8.254656 ]], dtype=float32)
time = 10710	action = 0	current_phase = 0	next_phase = 1	reward = 0.714104	array([[ 2.668107, -7.93817 ]], dtype=float32)
time = 10715	action = 0	current_phase = 0	next_phase = 1	reward = 0.712462	array([[ 2.6074805, -7.9012175]], dtype=float32)
time = 10720	action = 0	current_phase = 0	next_phase = 1	reward = 0.163863	array([[ 2.6400447, -7.9836197]], dtype=float32)
time = 10725	action = 0	current_phase = 0	next_phase = 1	reward = 1.281403	array([[ 2.5152287, -8.320386 ]], dtype=float32)
time = 10730	action = 0	current_phase = 0	next_phase = 1	reward = 0.448737	array([[ 2.7352576, -8.058103 ]], dtype=float32)
time = 10735	action = 0	current_phase = 0	next_phase = 1	reward = 1.002106	array([[ 2.5788293, -7.967911 ]], dtype=float32)
time = 10740	action = 0	current_phase = 0	next_phase = 1	reward = 0.725223	array([[ 2.642498, -7.946109]], dtype=float32)
time = 10745	action = 0	current_phase = 0	next_phase = 1	reward = 0.448389	array([[ 2.623477 , -7.9422255]], dtype=float32)
time = 10750	action = 0	current_phase = 0	next_phase = 1	reward = 1.004269	array([[ 2.5601754, -8.011443 ]], dtype=float32)
time = 10755	action = 0	current_phase = 0	next_phase = 1	reward = 0.446899	array([[ 2.704761, -7.992604]], dtype=float32)
time = 10760	action = 0	current_phase = 0	next_phase = 1	reward = 1.003945	array([[ 2.693358, -7.906601]], dtype=float32)
time = 10765	action = 0	current_phase = 0	next_phase = 1	reward = 0.722485	array([[ 2.582862, -8.048247]], dtype=float32)
time = 10770	action = 0	current_phase = 0	next_phase = 1	reward = 0.718353	array([[ 2.6562877, -7.987147 ]], dtype=float32)
time = 10775	action = 0	current_phase = 0	next_phase = 1	reward = 0.716009	array([[ 2.732842, -8.145508]], dtype=float32)
time = 10780	action = 0	current_phase = 0	next_phase = 1	reward = 0.718110	array([[ 2.670476, -8.063192]], dtype=float32)
time = 10785	action = 0	current_phase = 0	next_phase = 1	reward = 0.441719	array([[ 2.5757494, -8.10467  ]], dtype=float32)
time = 10790	action = 0	current_phase = 0	next_phase = 1	reward = 0.722556	array([[ 2.5852628, -7.998824 ]], dtype=float32)
time = 10795	action = 0	current_phase = 0	next_phase = 1	reward = 1.005849	array([[ 2.6895647, -7.873727 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.4498 - val_loss: 6.0197
Epoch 2/50
 - 4s - loss: 6.2582 - val_loss: 5.3055
Epoch 3/50
 - 4s - loss: 4.4989 - val_loss: 5.4446
Epoch 4/50
 - 4s - loss: 4.8471 - val_loss: 5.1162
Epoch 5/50
 - 4s - loss: 4.8458 - val_loss: 5.8091
Epoch 6/50
 - 4s - loss: 4.3028 - val_loss: 5.1949
Epoch 7/50
 - 4s - loss: 4.1606 - val_loss: 5.6340
Epoch 8/50
 - 4s - loss: 4.8562 - val_loss: 5.7710
Epoch 9/50
 - 4s - loss: 4.4491 - val_loss: 5.7117
Epoch 10/50
 - 4s - loss: 4.1322 - val_loss: 5.2076
Epoch 11/50
 - 4s - loss: 3.4746 - val_loss: 5.0940
Epoch 12/50
 - 4s - loss: 5.0021 - val_loss: 5.9842
Epoch 13/50
 - 4s - loss: 3.8650 - val_loss: 5.7395
Epoch 14/50
 - 4s - loss: 4.9750 - val_loss: 5.2756
Epoch 15/50
 - 4s - loss: 4.5813 - val_loss: 5.4200
Epoch 16/50
 - 4s - loss: 3.5234 - val_loss: 5.8981
Epoch 17/50
 - 4s - loss: 3.8704 - val_loss: 5.2752
Epoch 18/50
 - 4s - loss: 3.9311 - val_loss: 7.0023
Epoch 19/50
 - 5s - loss: 3.7707 - val_loss: 5.7228
Epoch 20/50
 - 5s - loss: 4.5646 - val_loss: 5.8386
Epoch 21/50
 - 4s - loss: 4.1117 - val_loss: 5.5459
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 10800	action = 0	current_phase = 0	next_phase = 1	reward = 0.719257	array([[ 2.8335238, -8.060267 ]], dtype=float32)
time = 10805	action = 0	current_phase = 0	next_phase = 1	reward = 0.437377	array([[ 2.8396416, -8.0272665]], dtype=float32)
time = 10810	action = 0	current_phase = 0	next_phase = 1	reward = 0.717666	array([[ 2.8229704, -8.059427 ]], dtype=float32)
time = 10815	action = 0	current_phase = 0	next_phase = 1	reward = 0.998438	array([[ 2.8581896, -8.008741 ]], dtype=float32)
time = 10820	action = 0	current_phase = 0	next_phase = 1	reward = 0.724862	array([[ 2.7834158, -8.1605835]], dtype=float32)
time = 10825	action = 0	current_phase = 0	next_phase = 1	reward = 0.454989	array([[ 2.8254132, -8.0079   ]], dtype=float32)
time = 10830	action = 0	current_phase = 0	next_phase = 1	reward = 1.001938	array([[ 2.860577 , -7.9942975]], dtype=float32)
time = 10835	action = 0	current_phase = 0	next_phase = 1	reward = 0.720845	array([[ 2.864365 , -7.9983478]], dtype=float32)
time = 10840	action = 0	current_phase = 0	next_phase = 1	reward = 0.720966	array([[ 2.8192549, -8.066238 ]], dtype=float32)
time = 10845	action = 0	current_phase = 0	next_phase = 1	reward = 0.439005	array([[ 2.8240914, -8.100233 ]], dtype=float32)
time = 10850	action = 0	current_phase = 0	next_phase = 1	reward = 1.006011	array([[ 2.834025, -8.034479]], dtype=float32)
time = 10855	action = 0	current_phase = 0	next_phase = 1	reward = 0.714825	array([[ 2.8418832, -7.975876 ]], dtype=float32)
time = 10860	action = 0	current_phase = 0	next_phase = 1	reward = 0.445376	array([[ 2.8376079, -7.999977 ]], dtype=float32)
time = 10865	action = 0	current_phase = 0	next_phase = 1	reward = 0.720091	array([[ 2.84832 , -8.005116]], dtype=float32)
time = 10870	action = 0	current_phase = 0	next_phase = 1	reward = 0.722257	array([[ 2.76619 , -8.099556]], dtype=float32)
time = 10875	action = 0	current_phase = 0	next_phase = 1	reward = 0.734538	array([[ 2.7536206, -8.201882 ]], dtype=float32)
time = 10880	action = 0	current_phase = 0	next_phase = 1	reward = 1.012913	array([[ 2.8600569, -7.9690948]], dtype=float32)
time = 10885	action = 0	current_phase = 0	next_phase = 1	reward = 0.442317	array([[ 2.8392467, -8.016905 ]], dtype=float32)
time = 10890	action = 0	current_phase = 0	next_phase = 1	reward = 0.999210	array([[ 2.8013968, -8.053164 ]], dtype=float32)
time = 10895	action = 0	current_phase = 0	next_phase = 1	reward = 0.717950	array([[ 2.829548, -8.005104]], dtype=float32)
time = 10900	action = 0	current_phase = 0	next_phase = 1	reward = 0.440100	array([[ 2.8585148, -8.025906 ]], dtype=float32)
time = 10905	action = 0	current_phase = 0	next_phase = 1	reward = 0.452088	array([[ 2.8121257, -8.085699 ]], dtype=float32)
time = 10910	action = 0	current_phase = 0	next_phase = 1	reward = 1.285665	array([[ 2.814435 , -8.0498905]], dtype=float32)
time = 10915	action = 0	current_phase = 0	next_phase = 1	reward = 0.713128	array([[ 2.91578 , -8.063139]], dtype=float32)
time = 10920	action = 0	current_phase = 0	next_phase = 1	reward = 0.440687	array([[ 2.785118, -7.989904]], dtype=float32)
time = 10925	action = 0	current_phase = 0	next_phase = 1	reward = 0.726157	array([[ 2.7906275, -8.100658 ]], dtype=float32)
time = 10930	action = 0	current_phase = 0	next_phase = 1	reward = 1.002642	array([[ 2.786096, -8.079956]], dtype=float32)
time = 10935	action = 0	current_phase = 0	next_phase = 1	reward = 0.724749	array([[ 2.8332515, -8.059679 ]], dtype=float32)
time = 10940	action = 0	current_phase = 0	next_phase = 1	reward = 0.714226	array([[ 2.869629 , -7.9702187]], dtype=float32)
time = 10945	action = 0	current_phase = 0	next_phase = 1	reward = 0.717230	array([[ 2.7997227, -8.006793 ]], dtype=float32)
time = 10950	action = 0	current_phase = 0	next_phase = 1	reward = 0.443416	array([[ 2.8605757, -7.970805 ]], dtype=float32)
time = 10955	action = 0	current_phase = 0	next_phase = 1	reward = 0.724741	array([[ 2.760387, -8.077137]], dtype=float32)
time = 10960	action = 0	current_phase = 0	next_phase = 1	reward = 0.724958	array([[ 2.8283439, -8.19626  ]], dtype=float32)
time = 10965	action = 0	current_phase = 0	next_phase = 1	reward = 0.719471	array([[ 2.811504, -8.113024]], dtype=float32)
time = 10970	action = 0	current_phase = 0	next_phase = 1	reward = 0.997752	array([[ 2.8365989, -7.997801 ]], dtype=float32)
time = 10975	action = 0	current_phase = 0	next_phase = 1	reward = 0.451174	array([[ 2.8230476, -8.01842  ]], dtype=float32)
time = 10980	action = 0	current_phase = 0	next_phase = 1	reward = 0.730004	array([[ 2.7677836, -8.131075 ]], dtype=float32)
time = 10985	action = 0	current_phase = 0	next_phase = 1	reward = 1.001729	array([[ 2.7924204, -8.066275 ]], dtype=float32)
time = 10990	action = 0	current_phase = 0	next_phase = 1	reward = 0.729673	array([[ 2.822782, -7.977865]], dtype=float32)
time = 10995	action = 0	current_phase = 0	next_phase = 1	reward = 0.717919	array([[ 2.8393226, -8.03434  ]], dtype=float32)
time = 11000	action = 0	current_phase = 0	next_phase = 1	reward = 0.727385	array([[ 2.8675995, -7.965042 ]], dtype=float32)
time = 11005	action = 0	current_phase = 0	next_phase = 1	reward = 0.727322	array([[ 2.7843418, -8.032954 ]], dtype=float32)
time = 11010	action = 0	current_phase = 0	next_phase = 1	reward = 0.713862	array([[ 2.899118, -8.088605]], dtype=float32)
time = 11015	action = 0	current_phase = 0	next_phase = 1	reward = 0.723145	array([[ 2.8493137, -8.043762 ]], dtype=float32)
time = 11020	action = 0	current_phase = 0	next_phase = 1	reward = 0.731923	array([[ 2.843481, -8.025701]], dtype=float32)
time = 11025	action = 0	current_phase = 0	next_phase = 1	reward = 0.727309	array([[ 2.8248262, -8.0366535]], dtype=float32)
time = 11030	action = 0	current_phase = 0	next_phase = 1	reward = 0.718103	array([[ 2.8620887, -8.041676 ]], dtype=float32)
time = 11035	action = 0	current_phase = 0	next_phase = 1	reward = 0.715243	array([[ 2.8087454, -8.062166 ]], dtype=float32)
time = 11040	action = 0	current_phase = 0	next_phase = 1	reward = 0.721033	array([[ 2.9073815, -8.04927  ]], dtype=float32)
time = 11045	action = 0	current_phase = 0	next_phase = 1	reward = 0.445482	array([[ 2.8226695, -8.003152 ]], dtype=float32)
time = 11050	action = 0	current_phase = 0	next_phase = 1	reward = 0.728630	array([[ 2.8499289, -8.072508 ]], dtype=float32)
time = 11055	action = 0	current_phase = 0	next_phase = 1	reward = 0.722323	array([[ 2.8407335, -8.017317 ]], dtype=float32)
time = 11060	action = 0	current_phase = 0	next_phase = 1	reward = 1.000060	array([[ 2.6939607, -8.156681 ]], dtype=float32)
time = 11065	action = 0	current_phase = 0	next_phase = 1	reward = 0.727940	array([[ 2.8435612, -8.022996 ]], dtype=float32)
time = 11070	action = 0	current_phase = 0	next_phase = 1	reward = 0.444346	array([[ 2.809781, -8.055776]], dtype=float32)
time = 11075	action = 0	current_phase = 0	next_phase = 1	reward = 1.002607	array([[ 2.84242, -8.02828]], dtype=float32)
time = 11080	action = 0	current_phase = 0	next_phase = 1	reward = 0.718550	array([[ 2.8211293, -7.963125 ]], dtype=float32)
time = 11085	action = 0	current_phase = 0	next_phase = 1	reward = 0.445150	array([[ 2.9094396, -7.990596 ]], dtype=float32)
time = 11090	action = 0	current_phase = 0	next_phase = 1	reward = 1.009939	array([[ 2.7883677, -8.088797 ]], dtype=float32)
time = 11095	action = 0	current_phase = 0	next_phase = 1	reward = 0.716977	array([[ 2.8093538, -8.296529 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.3462 - val_loss: 3.0289
Epoch 2/50
 - 4s - loss: 5.4356 - val_loss: 2.9688
Epoch 3/50
 - 4s - loss: 5.7101 - val_loss: 2.1735
Epoch 4/50
 - 4s - loss: 5.4417 - val_loss: 2.3208
Epoch 5/50
 - 4s - loss: 5.1872 - val_loss: 2.1310
Epoch 6/50
 - 4s - loss: 5.0951 - val_loss: 2.8934
Epoch 7/50
 - 4s - loss: 5.4057 - val_loss: 3.0655
Epoch 8/50
 - 4s - loss: 5.9921 - val_loss: 3.8161
Epoch 9/50
 - 4s - loss: 5.8444 - val_loss: 2.3218
Epoch 10/50
 - 4s - loss: 5.7917 - val_loss: 2.5168
Epoch 11/50
 - 4s - loss: 5.1234 - val_loss: 2.3782
Epoch 12/50
 - 4s - loss: 4.9554 - val_loss: 2.2472
Epoch 13/50
 - 4s - loss: 5.8508 - val_loss: 2.1629
Epoch 14/50
 - 4s - loss: 5.2739 - val_loss: 2.0283
Epoch 15/50
 - 4s - loss: 5.4517 - val_loss: 2.2883
Epoch 16/50
 - 4s - loss: 5.6612 - val_loss: 2.0277
Epoch 17/50
 - 4s - loss: 5.2032 - val_loss: 3.1700
Epoch 18/50
 - 4s - loss: 5.6297 - val_loss: 2.4986
Epoch 19/50
 - 4s - loss: 4.8649 - val_loss: 2.2506
Epoch 20/50
 - 4s - loss: 4.8403 - val_loss: 2.1501
Epoch 21/50
 - 4s - loss: 4.9433 - val_loss: 3.0056
Epoch 22/50
 - 4s - loss: 5.3354 - val_loss: 3.0404
Epoch 23/50
 - 4s - loss: 4.5645 - val_loss: 2.4200
Epoch 24/50
 - 4s - loss: 5.1119 - val_loss: 1.9143
Epoch 25/50
 - 4s - loss: 4.6054 - val_loss: 2.1010
Epoch 26/50
 - 4s - loss: 4.9964 - val_loss: 2.1113
Epoch 27/50
 - 4s - loss: 4.4578 - val_loss: 2.0565
Epoch 28/50
 - 4s - loss: 4.9086 - val_loss: 3.8285
Epoch 29/50
 - 4s - loss: 4.5288 - val_loss: 2.0849
Epoch 30/50
 - 4s - loss: 4.7108 - val_loss: 1.9605
Epoch 31/50
 - 5s - loss: 5.5736 - val_loss: 2.2091
Epoch 32/50
 - 4s - loss: 5.5720 - val_loss: 2.8399
Epoch 33/50
 - 5s - loss: 4.3926 - val_loss: 2.4513
Epoch 34/50
 - 4s - loss: 4.8277 - val_loss: 2.6246
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 11100	action = 0	current_phase = 0	next_phase = 1	reward = 0.726599	array([[ 2.6576345, -8.112041 ]], dtype=float32)
time = 11105	action = 0	current_phase = 0	next_phase = 1	reward = 0.440005	array([[ 2.81649 , -8.034631]], dtype=float32)
time = 11110	action = 0	current_phase = 0	next_phase = 1	reward = 0.995726	array([[ 2.807408, -8.089987]], dtype=float32)
time = 11115	action = 0	current_phase = 0	next_phase = 1	reward = 0.716037	array([[ 2.8109725, -8.047122 ]], dtype=float32)
time = 11120	action = 0	current_phase = 0	next_phase = 1	reward = 0.448403	array([[ 2.7538536, -8.186792 ]], dtype=float32)
time = 11125	action = 0	current_phase = 0	next_phase = 1	reward = 1.005462	array([[ 2.7808468, -8.129034 ]], dtype=float32)
time = 11130	action = 0	current_phase = 0	next_phase = 1	reward = 0.168499	array([[ 2.8051374, -8.048826 ]], dtype=float32)
time = 11135	action = 0	current_phase = 0	next_phase = 1	reward = 1.003385	array([[ 2.811886, -8.077274]], dtype=float32)
time = 11140	action = 0	current_phase = 0	next_phase = 1	reward = 0.999147	array([[ 2.7697952, -8.270747 ]], dtype=float32)
time = 11145	action = 0	current_phase = 0	next_phase = 1	reward = 0.719884	array([[ 2.7761977, -8.134148 ]], dtype=float32)
time = 11150	action = 0	current_phase = 0	next_phase = 1	reward = 0.443483	array([[ 2.8573349, -8.170368 ]], dtype=float32)
time = 11155	action = 0	current_phase = 0	next_phase = 1	reward = 0.723355	array([[ 2.8208234, -8.055732 ]], dtype=float32)
time = 11160	action = 0	current_phase = 0	next_phase = 1	reward = 1.007928	array([[ 2.7619321, -8.117252 ]], dtype=float32)
time = 11165	action = 0	current_phase = 0	next_phase = 1	reward = 0.714538	array([[ 2.8197482, -8.053817 ]], dtype=float32)
time = 11170	action = 0	current_phase = 0	next_phase = 1	reward = 0.450555	array([[ 2.7866328, -8.126403 ]], dtype=float32)
time = 11175	action = 0	current_phase = 0	next_phase = 1	reward = 0.999039	array([[ 2.796888, -8.089656]], dtype=float32)
time = 11180	action = 0	current_phase = 0	next_phase = 1	reward = 0.437579	array([[ 2.789952 , -8.0625925]], dtype=float32)
time = 11185	action = 0	current_phase = 0	next_phase = 1	reward = 0.725019	array([[ 2.5849292, -8.1611185]], dtype=float32)
time = 11190	action = 0	current_phase = 0	next_phase = 1	reward = 1.001861	array([[ 2.7514322, -8.200408 ]], dtype=float32)
time = 11195	action = 0	current_phase = 0	next_phase = 1	reward = 0.723066	array([[ 2.7360723, -8.308922 ]], dtype=float32)
time = 11200	action = 0	current_phase = 0	next_phase = 1	reward = 0.721048	array([[ 2.7852304, -8.086807 ]], dtype=float32)
time = 11205	action = 0	current_phase = 0	next_phase = 1	reward = 0.714652	array([[ 2.8056853, -8.082334 ]], dtype=float32)
time = 11210	action = 0	current_phase = 0	next_phase = 1	reward = 0.729118	array([[ 2.7781117, -8.031956 ]], dtype=float32)
time = 11215	action = 0	current_phase = 0	next_phase = 1	reward = 0.448081	array([[ 2.7873895, -8.112551 ]], dtype=float32)
time = 11220	action = 0	current_phase = 0	next_phase = 1	reward = 1.002429	array([[ 2.7591484, -8.137172 ]], dtype=float32)
time = 11225	action = 0	current_phase = 0	next_phase = 1	reward = 0.719733	array([[ 2.8160102, -8.067171 ]], dtype=float32)
time = 11230	action = 0	current_phase = 0	next_phase = 1	reward = 0.723962	array([[ 2.877526, -8.15114 ]], dtype=float32)
time = 11235	action = 0	current_phase = 0	next_phase = 1	reward = 0.164733	array([[ 2.8175528, -8.062186 ]], dtype=float32)
time = 11240	action = 0	current_phase = 0	next_phase = 1	reward = 1.010103	array([[ 2.7174332, -8.198099 ]], dtype=float32)
time = 11245	action = 0	current_phase = 0	next_phase = 1	reward = 0.723761	array([[ 2.8784473, -8.160028 ]], dtype=float32)
time = 11250	action = 0	current_phase = 0	next_phase = 1	reward = 0.999351	array([[ 2.7894127, -8.367414 ]], dtype=float32)
time = 11255	action = 0	current_phase = 0	next_phase = 1	reward = 0.436954	array([[ 2.7518585, -8.232043 ]], dtype=float32)
time = 11260	action = 0	current_phase = 0	next_phase = 1	reward = 0.443966	array([[ 2.8122876, -8.048313 ]], dtype=float32)
time = 11265	action = 0	current_phase = 0	next_phase = 1	reward = 1.004812	array([[ 2.7512162, -8.153801 ]], dtype=float32)
time = 11270	action = 0	current_phase = 0	next_phase = 1	reward = 0.725877	array([[ 2.7766225, -8.21041  ]], dtype=float32)
time = 11275	action = 0	current_phase = 0	next_phase = 1	reward = 0.723531	array([[ 2.860469, -8.093025]], dtype=float32)
time = 11280	action = 0	current_phase = 0	next_phase = 1	reward = 1.003838	array([[ 2.7458003, -8.416648 ]], dtype=float32)
time = 11285	action = 0	current_phase = 0	next_phase = 1	reward = 0.717471	array([[ 2.783592, -8.12627 ]], dtype=float32)
time = 11290	action = 0	current_phase = 0	next_phase = 1	reward = 0.440937	array([[ 2.690162, -8.077386]], dtype=float32)
time = 11295	action = 0	current_phase = 0	next_phase = 1	reward = 0.728265	array([[ 2.7959082, -8.130942 ]], dtype=float32)
time = 11300	action = 0	current_phase = 0	next_phase = 1	reward = 0.999105	array([[ 2.7646081, -8.159825 ]], dtype=float32)
time = 11305	action = 0	current_phase = 0	next_phase = 1	reward = 0.435767	array([[ 2.8138392, -8.079572 ]], dtype=float32)
time = 11310	action = 0	current_phase = 0	next_phase = 1	reward = 0.999069	array([[ 2.8128111, -8.054977 ]], dtype=float32)
time = 11315	action = 0	current_phase = 0	next_phase = 1	reward = 0.451953	array([[ 2.7361257, -8.132646 ]], dtype=float32)
time = 11320	action = 0	current_phase = 0	next_phase = 1	reward = 1.003477	array([[ 2.7912514, -8.120602 ]], dtype=float32)
time = 11325	action = 0	current_phase = 0	next_phase = 1	reward = 0.443208	array([[ 2.7288215, -8.13567  ]], dtype=float32)
time = 11330	action = 0	current_phase = 0	next_phase = 1	reward = 0.724239	array([[ 2.78428 , -8.096355]], dtype=float32)
time = 11335	action = 0	current_phase = 0	next_phase = 1	reward = 0.723326	array([[ 2.7567112, -8.120634 ]], dtype=float32)
time = 11340	action = 0	current_phase = 0	next_phase = 1	reward = 1.005965	array([[ 2.8103259, -8.087739 ]], dtype=float32)
time = 11345	action = 0	current_phase = 0	next_phase = 1	reward = 0.440427	array([[ 2.7868707, -8.119191 ]], dtype=float32)
time = 11350	action = 0	current_phase = 0	next_phase = 1	reward = 0.723287	array([[ 2.776653, -8.093473]], dtype=float32)
time = 11355	action = 0	current_phase = 0	next_phase = 1	reward = 1.006619	array([[ 2.7300484, -8.14113  ]], dtype=float32)
time = 11360	action = 0	current_phase = 0	next_phase = 1	reward = 0.727695	array([[ 2.8144 , -8.04845]], dtype=float32)
time = 11365	action = 0	current_phase = 0	next_phase = 1	reward = 0.449283	array([[ 2.8207762, -8.045816 ]], dtype=float32)
time = 11370	action = 0	current_phase = 0	next_phase = 1	reward = 0.728718	array([[ 2.735317, -8.121165]], dtype=float32)
time = 11375	action = 0	current_phase = 0	next_phase = 1	reward = 1.003371	array([[ 2.794349, -8.123829]], dtype=float32)
time = 11380	action = 0	current_phase = 0	next_phase = 1	reward = 0.718851	array([[ 2.8315852, -8.068859 ]], dtype=float32)
time = 11385	action = 0	current_phase = 0	next_phase = 1	reward = 0.723503	array([[ 2.8567264, -8.172652 ]], dtype=float32)
time = 11390	action = 0	current_phase = 0	next_phase = 1	reward = 0.731643	array([[ 2.7873561, -8.108702 ]], dtype=float32)
time = 11395	action = 0	current_phase = 0	next_phase = 1	reward = 0.712754	array([[ 2.7791307, -8.094814 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 5s - loss: 3.7829 - val_loss: 2.5730
Epoch 2/50
 - 7s - loss: 4.6513 - val_loss: 2.8112
Epoch 3/50
 - 8s - loss: 4.3071 - val_loss: 2.8282
Epoch 4/50
 - 7s - loss: 3.6132 - val_loss: 2.3456
Epoch 5/50
 - 5s - loss: 4.4158 - val_loss: 2.5440
Epoch 6/50
 - 5s - loss: 3.8132 - val_loss: 3.2764
Epoch 7/50
 - 6s - loss: 4.3422 - val_loss: 2.8685
Epoch 8/50
 - 5s - loss: 3.2917 - val_loss: 2.2863
Epoch 9/50
 - 4s - loss: 3.3836 - val_loss: 2.7150
Epoch 10/50
 - 4s - loss: 3.6011 - val_loss: 2.1596
Epoch 11/50
 - 4s - loss: 3.2983 - val_loss: 2.3511
Epoch 12/50
 - 4s - loss: 4.1598 - val_loss: 2.6057
Epoch 13/50
 - 4s - loss: 3.5789 - val_loss: 2.1745
Epoch 14/50
 - 4s - loss: 4.1189 - val_loss: 2.8352
Epoch 15/50
 - 4s - loss: 3.5828 - val_loss: 2.9017
Epoch 16/50
 - 4s - loss: 3.6240 - val_loss: 2.7283
Epoch 17/50
 - 4s - loss: 3.8963 - val_loss: 1.8603
Epoch 18/50
 - 4s - loss: 3.1639 - val_loss: 2.2542
Epoch 19/50
 - 4s - loss: 2.7965 - val_loss: 2.5064
Epoch 20/50
 - 4s - loss: 3.7550 - val_loss: 2.4210
Epoch 21/50
 - 4s - loss: 3.7502 - val_loss: 2.8475
Epoch 22/50
 - 4s - loss: 3.8821 - val_loss: 2.3223
Epoch 23/50
 - 4s - loss: 3.9399 - val_loss: 2.4898
Epoch 24/50
 - 4s - loss: 3.4247 - val_loss: 3.2583
Epoch 25/50
 - 4s - loss: 3.6049 - val_loss: 2.5293
Epoch 26/50
 - 4s - loss: 3.6806 - val_loss: 2.9984
Epoch 27/50
 - 4s - loss: 3.6105 - val_loss: 2.9665
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 11400	action = 0	current_phase = 0	next_phase = 1	reward = 0.716858	array([[ 2.760325, -8.136824]], dtype=float32)
time = 11405	action = 0	current_phase = 0	next_phase = 1	reward = 0.710523	array([[ 2.792552, -8.135645]], dtype=float32)
time = 11410	action = 0	current_phase = 0	next_phase = 1	reward = 0.447584	array([[ 2.714406, -8.317758]], dtype=float32)
time = 11415	action = 0	current_phase = 0	next_phase = 1	reward = 1.000738	array([[ 2.8087635, -8.182684 ]], dtype=float32)
time = 11420	action = 0	current_phase = 0	next_phase = 1	reward = 0.717624	array([[ 2.7601352, -8.145814 ]], dtype=float32)
time = 11425	action = 0	current_phase = 0	next_phase = 1	reward = 0.723006	array([[ 2.8146687, -8.17816  ]], dtype=float32)
time = 11430	action = 0	current_phase = 0	next_phase = 1	reward = 0.718626	array([[ 2.7117534, -8.261429 ]], dtype=float32)
time = 11435	action = 0	current_phase = 0	next_phase = 1	reward = 0.732724	array([[ 2.8065672, -8.120361 ]], dtype=float32)
time = 11440	action = 0	current_phase = 0	next_phase = 1	reward = 0.445624	array([[ 2.8203192, -8.154779 ]], dtype=float32)
time = 11445	action = 0	current_phase = 0	next_phase = 1	reward = 1.005830	array([[ 2.766405, -8.249804]], dtype=float32)
time = 11450	action = 0	current_phase = 0	next_phase = 1	reward = 0.725018	array([[ 2.8376174, -8.144728 ]], dtype=float32)
time = 11455	action = 0	current_phase = 0	next_phase = 1	reward = 0.733099	array([[ 2.8013558, -8.192093 ]], dtype=float32)
time = 11460	action = 0	current_phase = 0	next_phase = 1	reward = 0.729175	array([[ 2.7688708, -8.209681 ]], dtype=float32)
time = 11465	action = 0	current_phase = 0	next_phase = 1	reward = 0.726813	array([[ 2.7833385, -8.182419 ]], dtype=float32)
time = 11470	action = 0	current_phase = 0	next_phase = 1	reward = 0.724858	array([[ 2.7552872, -8.139119 ]], dtype=float32)
time = 11475	action = 0	current_phase = 0	next_phase = 1	reward = 0.723483	array([[ 2.8141384, -8.11769  ]], dtype=float32)
time = 11480	action = 0	current_phase = 0	next_phase = 1	reward = 0.723471	array([[ 2.763466, -8.200835]], dtype=float32)
time = 11485	action = 0	current_phase = 0	next_phase = 1	reward = 0.721310	array([[ 2.7976327, -8.180607 ]], dtype=float32)
time = 11490	action = 0	current_phase = 0	next_phase = 1	reward = 0.720167	array([[ 2.7983003, -8.134854 ]], dtype=float32)
time = 11495	action = 0	current_phase = 0	next_phase = 1	reward = 0.729932	array([[ 2.7809997, -8.131852 ]], dtype=float32)
time = 11500	action = 0	current_phase = 0	next_phase = 1	reward = 0.722721	array([[ 2.7603183, -8.135935 ]], dtype=float32)
time = 11505	action = 0	current_phase = 0	next_phase = 1	reward = 0.725444	array([[ 2.8396769, -8.188734 ]], dtype=float32)
time = 11510	action = 0	current_phase = 0	next_phase = 1	reward = 0.442160	array([[ 2.742525, -8.133146]], dtype=float32)
time = 11515	action = 0	current_phase = 0	next_phase = 1	reward = 0.724629	array([[ 2.836505, -8.231003]], dtype=float32)
time = 11520	action = 0	current_phase = 0	next_phase = 1	reward = 0.721602	array([[ 2.7739072, -8.157673 ]], dtype=float32)
time = 11525	action = 0	current_phase = 0	next_phase = 1	reward = 1.006499	array([[ 2.754734, -8.285803]], dtype=float32)
time = 11530	action = 0	current_phase = 0	next_phase = 1	reward = 0.723741	array([[ 2.8204956, -8.121588 ]], dtype=float32)
time = 11535	action = 0	current_phase = 0	next_phase = 1	reward = 0.719974	array([[ 2.8977056, -8.192054 ]], dtype=float32)
time = 11540	action = 0	current_phase = 0	next_phase = 1	reward = 0.715181	array([[ 2.7512474, -8.100133 ]], dtype=float32)
time = 11545	action = 0	current_phase = 0	next_phase = 1	reward = 0.720470	array([[ 2.766532, -8.1338  ]], dtype=float32)
time = 11550	action = 0	current_phase = 0	next_phase = 1	reward = 0.439848	array([[ 2.7685795, -8.2437935]], dtype=float32)
time = 11555	action = 0	current_phase = 0	next_phase = 1	reward = 0.446829	array([[ 2.8074799, -8.3276   ]], dtype=float32)
time = 11560	action = 0	current_phase = 0	next_phase = 1	reward = 1.287512	array([[ 2.7379537, -8.341881 ]], dtype=float32)
time = 11565	action = 0	current_phase = 0	next_phase = 1	reward = 0.722416	array([[ 2.8279147, -8.287888 ]], dtype=float32)
time = 11570	action = 0	current_phase = 0	next_phase = 1	reward = 0.444844	array([[ 2.778214, -8.176716]], dtype=float32)
time = 11575	action = 0	current_phase = 0	next_phase = 1	reward = 1.004793	array([[ 2.7324176, -8.242506 ]], dtype=float32)
time = 11580	action = 0	current_phase = 0	next_phase = 1	reward = 0.718751	array([[ 2.8290792, -8.1956215]], dtype=float32)
time = 11585	action = 0	current_phase = 0	next_phase = 1	reward = 0.714488	array([[ 2.7920022, -8.175648 ]], dtype=float32)
time = 11590	action = 0	current_phase = 0	next_phase = 1	reward = 0.442240	array([[ 2.7257676, -8.17355  ]], dtype=float32)
time = 11595	action = 0	current_phase = 0	next_phase = 1	reward = 0.733774	array([[ 2.765017, -8.220312]], dtype=float32)
time = 11600	action = 0	current_phase = 0	next_phase = 1	reward = 0.735262	array([[ 2.7896466, -8.228346 ]], dtype=float32)
time = 11605	action = 0	current_phase = 0	next_phase = 1	reward = 1.002384	array([[ 2.7920747, -8.193649 ]], dtype=float32)
time = 11610	action = 0	current_phase = 0	next_phase = 1	reward = 0.716492	array([[ 2.8415499, -8.144916 ]], dtype=float32)
time = 11615	action = 0	current_phase = 0	next_phase = 1	reward = 0.717361	array([[ 2.8059673, -8.16724  ]], dtype=float32)
time = 11620	action = 0	current_phase = 0	next_phase = 1	reward = 0.445989	array([[ 2.8591466, -8.213351 ]], dtype=float32)
time = 11625	action = 0	current_phase = 0	next_phase = 1	reward = 0.731843	array([[ 2.6984282, -8.353222 ]], dtype=float32)
time = 11630	action = 0	current_phase = 0	next_phase = 1	reward = 1.002818	array([[ 2.7463703, -8.291857 ]], dtype=float32)
time = 11635	action = 0	current_phase = 0	next_phase = 1	reward = 0.720761	array([[ 2.7314906, -8.133266 ]], dtype=float32)
time = 11640	action = 0	current_phase = 0	next_phase = 1	reward = 0.732095	array([[ 2.652924, -8.146156]], dtype=float32)
time = 11645	action = 0	current_phase = 0	next_phase = 1	reward = 0.457374	array([[ 2.6965709, -8.274033 ]], dtype=float32)
time = 11650	action = 0	current_phase = 0	next_phase = 1	reward = 1.003504	array([[ 2.7441502, -8.231035 ]], dtype=float32)
time = 11655	action = 0	current_phase = 0	next_phase = 1	reward = 0.716393	array([[ 2.748083, -8.147924]], dtype=float32)
time = 11660	action = 0	current_phase = 0	next_phase = 1	reward = 0.719832	array([[ 2.891696, -8.209221]], dtype=float32)
time = 11665	action = 0	current_phase = 0	next_phase = 1	reward = 0.719982	array([[ 2.7745104, -8.180598 ]], dtype=float32)
time = 11670	action = 0	current_phase = 0	next_phase = 1	reward = 0.441944	array([[ 2.818462, -8.115738]], dtype=float32)
time = 11675	action = 0	current_phase = 0	next_phase = 1	reward = 0.998573	array([[ 2.7302976, -8.171833 ]], dtype=float32)
time = 11680	action = 0	current_phase = 0	next_phase = 1	reward = 0.438055	array([[ 2.7485318, -8.3445835]], dtype=float32)
time = 11685	action = 0	current_phase = 0	next_phase = 1	reward = 0.997061	array([[ 2.7533965, -8.191636 ]], dtype=float32)
time = 11690	action = 0	current_phase = 0	next_phase = 1	reward = 0.439415	array([[ 2.795897, -8.16621 ]], dtype=float32)
time = 11695	action = 0	current_phase = 0	next_phase = 1	reward = 1.002517	array([[ 2.8197994, -8.115182 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.8179 - val_loss: 2.6124
Epoch 2/50
 - 4s - loss: 5.6631 - val_loss: 2.8746
Epoch 3/50
 - 4s - loss: 4.4924 - val_loss: 2.6392
Epoch 4/50
 - 4s - loss: 4.7485 - val_loss: 2.4821
Epoch 5/50
 - 4s - loss: 5.7551 - val_loss: 2.7731
Epoch 6/50
 - 4s - loss: 4.6628 - val_loss: 2.8451
Epoch 7/50
 - 4s - loss: 4.7505 - val_loss: 2.7709
Epoch 8/50
 - 4s - loss: 4.5325 - val_loss: 3.2108
Epoch 9/50
 - 4s - loss: 5.2160 - val_loss: 3.0426
Epoch 10/50
 - 4s - loss: 4.6653 - val_loss: 2.5346
Epoch 11/50
 - 4s - loss: 4.7116 - val_loss: 2.8817
Epoch 12/50
 - 4s - loss: 4.4528 - val_loss: 2.5743
Epoch 13/50
 - 4s - loss: 4.5701 - val_loss: 2.5902
Epoch 14/50
 - 4s - loss: 4.5732 - val_loss: 2.6259
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 11700	action = 0	current_phase = 0	next_phase = 1	reward = 0.732143	array([[ 2.7621942, -8.261839 ]], dtype=float32)
time = 11705	action = 0	current_phase = 0	next_phase = 1	reward = 0.719611	array([[ 2.8932385, -8.223391 ]], dtype=float32)
time = 11710	action = 0	current_phase = 0	next_phase = 1	reward = 0.717668	array([[ 2.8498774, -8.206026 ]], dtype=float32)
time = 11715	action = 0	current_phase = 0	next_phase = 1	reward = 0.715155	array([[ 2.8151445, -8.201663 ]], dtype=float32)
time = 11720	action = 0	current_phase = 0	next_phase = 1	reward = 0.717961	array([[ 2.7323966, -8.289787 ]], dtype=float32)
time = 11725	action = 0	current_phase = 0	next_phase = 1	reward = 0.450746	array([[ 2.8309832, -8.172512 ]], dtype=float32)
time = 11730	action = 0	current_phase = 0	next_phase = 1	reward = 1.008812	array([[ 2.5787888, -8.832439 ]], dtype=float32)
time = 11735	action = 0	current_phase = 0	next_phase = 1	reward = 0.719444	array([[ 2.8341947, -8.22534  ]], dtype=float32)
time = 11740	action = 0	current_phase = 0	next_phase = 1	reward = 0.439413	array([[ 2.8327436, -8.246717 ]], dtype=float32)
time = 11745	action = 0	current_phase = 0	next_phase = 1	reward = 0.722227	array([[ 2.8237453, -8.187425 ]], dtype=float32)
time = 11750	action = 0	current_phase = 0	next_phase = 1	reward = 1.002757	array([[ 2.7903652, -8.394096 ]], dtype=float32)
time = 11755	action = 0	current_phase = 0	next_phase = 1	reward = 0.456650	array([[ 2.7910848, -8.398619 ]], dtype=float32)
time = 11760	action = 0	current_phase = 0	next_phase = 1	reward = 1.007223	array([[ 2.8581738, -8.225536 ]], dtype=float32)
time = 11765	action = 0	current_phase = 0	next_phase = 1	reward = 0.722095	array([[ 2.8372464, -8.17783  ]], dtype=float32)
time = 11770	action = 0	current_phase = 0	next_phase = 1	reward = 0.717822	array([[ 2.8190594, -8.192297 ]], dtype=float32)
time = 11775	action = 0	current_phase = 0	next_phase = 1	reward = 0.717974	array([[ 2.7739482, -8.217078 ]], dtype=float32)
time = 11780	action = 0	current_phase = 0	next_phase = 1	reward = 0.717855	array([[ 2.7591639, -8.259701 ]], dtype=float32)
time = 11785	action = 0	current_phase = 0	next_phase = 1	reward = 0.447894	array([[ 2.757657, -8.24535 ]], dtype=float32)
time = 11790	action = 0	current_phase = 0	next_phase = 1	reward = 1.006509	array([[ 2.767992, -8.218014]], dtype=float32)
time = 11795	action = 0	current_phase = 0	next_phase = 1	reward = 0.731987	array([[ 2.8097997, -8.208914 ]], dtype=float32)
time = 11800	action = 0	current_phase = 0	next_phase = 1	reward = 0.725594	array([[ 2.8225307, -8.195215 ]], dtype=float32)
time = 11805	action = 0	current_phase = 0	next_phase = 1	reward = 0.728379	array([[ 2.8504362, -8.14919  ]], dtype=float32)
time = 11810	action = 0	current_phase = 0	next_phase = 1	reward = 0.729393	array([[ 2.8702536, -8.205988 ]], dtype=float32)
time = 11815	action = 0	current_phase = 0	next_phase = 1	reward = 0.717314	array([[ 2.8029552, -8.209936 ]], dtype=float32)
time = 11820	action = 0	current_phase = 0	next_phase = 1	reward = 0.445539	array([[ 2.7721558, -8.222552 ]], dtype=float32)
time = 11825	action = 0	current_phase = 0	next_phase = 1	reward = 1.003043	array([[ 2.9321318, -8.391704 ]], dtype=float32)
time = 11830	action = 0	current_phase = 0	next_phase = 1	reward = 0.444737	array([[ 2.7808905, -8.220913 ]], dtype=float32)
time = 11835	action = 0	current_phase = 0	next_phase = 1	reward = 1.004230	array([[ 2.7293682, -8.365371 ]], dtype=float32)
time = 11840	action = 0	current_phase = 0	next_phase = 1	reward = 0.719078	array([[ 2.8161197, -8.255486 ]], dtype=float32)
time = 11845	action = 0	current_phase = 0	next_phase = 1	reward = 0.439782	array([[ 2.7200766, -8.36917  ]], dtype=float32)
time = 11850	action = 0	current_phase = 0	next_phase = 1	reward = 0.999555	array([[ 2.711419, -8.322868]], dtype=float32)
time = 11855	action = 0	current_phase = 0	next_phase = 1	reward = 0.721297	array([[ 2.8053732, -8.224339 ]], dtype=float32)
time = 11860	action = 0	current_phase = 0	next_phase = 1	reward = 0.438889	array([[ 2.7980347, -8.214325 ]], dtype=float32)
time = 11865	action = 0	current_phase = 0	next_phase = 1	reward = 1.003342	array([[ 2.7654352, -8.267855 ]], dtype=float32)
time = 11870	action = 0	current_phase = 0	next_phase = 1	reward = 0.725465	array([[ 2.7514162, -8.238067 ]], dtype=float32)
time = 11875	action = 0	current_phase = 0	next_phase = 1	reward = 0.718653	array([[ 2.9315  , -8.321306]], dtype=float32)
time = 11880	action = 0	current_phase = 0	next_phase = 1	reward = 0.719154	array([[ 2.799693, -8.215292]], dtype=float32)
time = 11885	action = 0	current_phase = 0	next_phase = 1	reward = 0.441995	array([[ 2.827064, -8.234005]], dtype=float32)
time = 11890	action = 0	current_phase = 0	next_phase = 1	reward = 0.729579	array([[ 2.8049016, -8.200818 ]], dtype=float32)
time = 11895	action = 0	current_phase = 0	next_phase = 1	reward = 1.010712	array([[ 2.720295, -8.410224]], dtype=float32)
time = 11900	action = 0	current_phase = 0	next_phase = 1	reward = 0.718329	array([[ 2.8267636, -8.231718 ]], dtype=float32)
time = 11905	action = 0	current_phase = 0	next_phase = 1	reward = 0.727086	array([[ 2.8079462, -8.184809 ]], dtype=float32)
time = 11910	action = 0	current_phase = 0	next_phase = 1	reward = 0.716936	array([[ 2.7511034, -8.388322 ]], dtype=float32)
time = 11915	action = 0	current_phase = 0	next_phase = 1	reward = 0.708262	array([[ 2.8160028, -8.254623 ]], dtype=float32)
time = 11920	action = 0	current_phase = 0	next_phase = 1	reward = 0.446659	array([[ 2.7960997, -8.202696 ]], dtype=float32)
time = 11925	action = 0	current_phase = 0	next_phase = 1	reward = 0.733376	array([[ 2.790247, -8.210083]], dtype=float32)
time = 11930	action = 0	current_phase = 0	next_phase = 1	reward = 0.731589	array([[ 2.8285403, -8.303307 ]], dtype=float32)
time = 11935	action = 0	current_phase = 0	next_phase = 1	reward = 1.007445	array([[ 2.7864509, -8.245796 ]], dtype=float32)
time = 11940	action = 0	current_phase = 0	next_phase = 1	reward = 0.724626	array([[ 2.8023229, -8.2557955]], dtype=float32)
time = 11945	action = 0	current_phase = 0	next_phase = 1	reward = 0.724382	array([[ 2.8179255, -8.221569 ]], dtype=float32)
time = 11950	action = 0	current_phase = 0	next_phase = 1	reward = 0.718442	array([[ 2.8138838, -8.212988 ]], dtype=float32)
time = 11955	action = 0	current_phase = 0	next_phase = 1	reward = 0.726094	array([[ 2.8177395, -8.217672 ]], dtype=float32)
time = 11960	action = 0	current_phase = 0	next_phase = 1	reward = 0.719223	array([[ 2.7211003, -8.243777 ]], dtype=float32)
time = 11965	action = 0	current_phase = 0	next_phase = 1	reward = 0.717326	array([[ 2.745844, -8.255192]], dtype=float32)
time = 11970	action = 0	current_phase = 0	next_phase = 1	reward = 0.725086	array([[ 2.8161302, -8.225979 ]], dtype=float32)
time = 11975	action = 0	current_phase = 0	next_phase = 1	reward = 0.727055	array([[ 2.8988204, -8.216643 ]], dtype=float32)
time = 11980	action = 0	current_phase = 0	next_phase = 1	reward = 0.730671	array([[ 2.8296647, -8.187272 ]], dtype=float32)
time = 11985	action = 0	current_phase = 0	next_phase = 1	reward = 0.447939	array([[ 2.7950344, -8.193962 ]], dtype=float32)
time = 11990	action = 0	current_phase = 0	next_phase = 1	reward = 1.007322	array([[ 2.7383804, -8.274717 ]], dtype=float32)
time = 11995	action = 0	current_phase = 0	next_phase = 1	reward = 0.724114	array([[ 2.8890128, -8.262883 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.7893 - val_loss: 2.2363
Epoch 2/50
 - 4s - loss: 6.0015 - val_loss: 2.3207
Epoch 3/50
 - 4s - loss: 5.6984 - val_loss: 2.8620
Epoch 4/50
 - 4s - loss: 5.0367 - val_loss: 3.2425
Epoch 5/50
 - 4s - loss: 4.3967 - val_loss: 3.3413
Epoch 6/50
 - 4s - loss: 4.1284 - val_loss: 2.3303
Epoch 7/50
 - 4s - loss: 4.1380 - val_loss: 3.3593
Epoch 8/50
 - 4s - loss: 4.1676 - val_loss: 2.3366
Epoch 9/50
 - 4s - loss: 4.5539 - val_loss: 3.1273
Epoch 10/50
 - 4s - loss: 4.0023 - val_loss: 3.3062
Epoch 11/50
 - 4s - loss: 5.3495 - val_loss: 3.3924
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 12000	action = 0	current_phase = 0	next_phase = 1	reward = 0.713670	array([[ 2.7770948, -8.438887 ]], dtype=float32)
time = 12005	action = 0	current_phase = 0	next_phase = 1	reward = 0.715397	array([[ 2.7893953, -8.313101 ]], dtype=float32)
time = 12010	action = 0	current_phase = 0	next_phase = 1	reward = 0.719637	array([[ 2.8348603, -8.276319 ]], dtype=float32)
time = 12015	action = 0	current_phase = 0	next_phase = 1	reward = 0.718715	array([[ 2.7080026, -8.338757 ]], dtype=float32)
time = 12020	action = 0	current_phase = 0	next_phase = 1	reward = 0.159537	array([[ 2.8415513, -8.284323 ]], dtype=float32)
time = 12025	action = 0	current_phase = 0	next_phase = 1	reward = 1.014119	array([[ 2.738783, -8.355685]], dtype=float32)
time = 12030	action = 0	current_phase = 0	next_phase = 1	reward = 0.733554	array([[ 2.8286839, -8.265318 ]], dtype=float32)
time = 12035	action = 0	current_phase = 0	next_phase = 1	reward = 1.011649	array([[ 2.817348, -8.264857]], dtype=float32)
time = 12040	action = 0	current_phase = 0	next_phase = 1	reward = 0.718031	array([[ 2.8374805, -8.260857 ]], dtype=float32)
time = 12045	action = 0	current_phase = 0	next_phase = 1	reward = 0.720475	array([[ 2.8300753, -8.2799835]], dtype=float32)
time = 12050	action = 0	current_phase = 0	next_phase = 1	reward = 0.450246	array([[ 2.8402739, -8.262878 ]], dtype=float32)
time = 12055	action = 0	current_phase = 0	next_phase = 1	reward = 1.013351	array([[ 2.8144069, -8.3044815]], dtype=float32)
time = 12060	action = 0	current_phase = 0	next_phase = 1	reward = 0.724127	array([[ 2.8383603, -8.315406 ]], dtype=float32)
time = 12065	action = 0	current_phase = 0	next_phase = 1	reward = 0.722056	array([[ 2.8877096, -8.243197 ]], dtype=float32)
time = 12070	action = 0	current_phase = 0	next_phase = 1	reward = 0.723930	array([[ 2.8194022, -8.275448 ]], dtype=float32)
time = 12075	action = 0	current_phase = 0	next_phase = 1	reward = 0.724332	array([[ 2.8318143, -8.266021 ]], dtype=float32)
time = 12080	action = 0	current_phase = 0	next_phase = 1	reward = 0.705381	array([[ 2.8275642, -8.261305 ]], dtype=float32)
time = 12085	action = 0	current_phase = 0	next_phase = 1	reward = 0.440803	array([[ 2.8462324, -8.24687  ]], dtype=float32)
time = 12090	action = 0	current_phase = 0	next_phase = 1	reward = 1.007452	array([[ 2.886479 , -8.3404255]], dtype=float32)
time = 12095	action = 0	current_phase = 0	next_phase = 1	reward = 0.449754	array([[ 2.7657552, -8.261628 ]], dtype=float32)
time = 12100	action = 0	current_phase = 0	next_phase = 1	reward = 1.012060	array([[ 2.8051267, -8.309137 ]], dtype=float32)
time = 12105	action = 0	current_phase = 0	next_phase = 1	reward = 0.444618	array([[ 2.8473096, -8.245705 ]], dtype=float32)
time = 12110	action = 0	current_phase = 0	next_phase = 1	reward = 1.002519	array([[ 2.8290524, -8.239873 ]], dtype=float32)
time = 12115	action = 0	current_phase = 0	next_phase = 1	reward = 0.721534	array([[ 2.9328547, -8.288883 ]], dtype=float32)
time = 12120	action = 0	current_phase = 0	next_phase = 1	reward = 0.725327	array([[ 2.826387, -8.285119]], dtype=float32)
time = 12125	action = 0	current_phase = 0	next_phase = 1	reward = 0.441465	array([[ 2.7917204, -8.357888 ]], dtype=float32)
time = 12130	action = 0	current_phase = 0	next_phase = 1	reward = 1.007280	array([[ 2.827496, -8.258889]], dtype=float32)
time = 12135	action = 0	current_phase = 0	next_phase = 1	reward = 0.716605	array([[ 2.8137932, -8.292204 ]], dtype=float32)
time = 12140	action = 0	current_phase = 0	next_phase = 1	reward = 0.716290	array([[ 2.8537483, -8.387534 ]], dtype=float32)
time = 12145	action = 0	current_phase = 0	next_phase = 1	reward = 0.445697	array([[ 2.8353953, -8.306751 ]], dtype=float32)
time = 12150	action = 0	current_phase = 0	next_phase = 1	reward = 1.003404	array([[ 2.6201863, -8.546147 ]], dtype=float32)
time = 12155	action = 0	current_phase = 0	next_phase = 1	reward = 0.440797	array([[ 2.8320465, -8.265976 ]], dtype=float32)
time = 12160	action = 0	current_phase = 0	next_phase = 1	reward = 1.001406	array([[ 2.5992718, -8.406124 ]], dtype=float32)
time = 12165	action = 0	current_phase = 0	next_phase = 1	reward = 0.443458	array([[ 2.8337789, -8.253469 ]], dtype=float32)
time = 12170	action = 0	current_phase = 0	next_phase = 1	reward = 0.733350	array([[ 2.7960649, -8.379184 ]], dtype=float32)
time = 12175	action = 0	current_phase = 0	next_phase = 1	reward = 0.728414	array([[ 2.8077006, -8.329191 ]], dtype=float32)
time = 12180	action = 0	current_phase = 0	next_phase = 1	reward = 1.012108	array([[ 2.8022313, -8.323606 ]], dtype=float32)
time = 12185	action = 0	current_phase = 0	next_phase = 1	reward = 0.723986	array([[ 2.8288527, -8.30019  ]], dtype=float32)
time = 12190	action = 0	current_phase = 0	next_phase = 1	reward = 0.729123	array([[ 2.8543353, -8.233566 ]], dtype=float32)
time = 12195	action = 0	current_phase = 0	next_phase = 1	reward = 0.718897	array([[ 2.811739, -8.279537]], dtype=float32)
time = 12200	action = 0	current_phase = 0	next_phase = 1	reward = 0.443637	array([[ 2.759007, -8.321895]], dtype=float32)
time = 12205	action = 0	current_phase = 0	next_phase = 1	reward = 1.001565	array([[ 2.8858585, -8.28135  ]], dtype=float32)
time = 12210	action = 0	current_phase = 0	next_phase = 1	reward = 0.437317	array([[ 2.8529954, -8.224639 ]], dtype=float32)
time = 12215	action = 0	current_phase = 0	next_phase = 1	reward = 0.723297	array([[ 2.8077583, -8.285701 ]], dtype=float32)
time = 12220	action = 0	current_phase = 0	next_phase = 1	reward = 1.010318	array([[ 2.8301868, -8.373927 ]], dtype=float32)
time = 12225	action = 0	current_phase = 0	next_phase = 1	reward = 0.447988	array([[ 2.8385763, -8.289689 ]], dtype=float32)
time = 12230	action = 0	current_phase = 0	next_phase = 1	reward = 0.726259	array([[ 2.8776164, -8.298849 ]], dtype=float32)
time = 12235	action = 0	current_phase = 0	next_phase = 1	reward = 1.007122	array([[ 2.789164, -8.323192]], dtype=float32)
time = 12240	action = 0	current_phase = 0	next_phase = 1	reward = 0.443262	array([[ 2.780448, -8.280089]], dtype=float32)
time = 12245	action = 0	current_phase = 0	next_phase = 1	reward = 1.007462	array([[ 2.8143706, -8.292759 ]], dtype=float32)
time = 12250	action = 0	current_phase = 0	next_phase = 1	reward = 0.729295	array([[ 2.8145452, -8.331087 ]], dtype=float32)
time = 12255	action = 0	current_phase = 0	next_phase = 1	reward = 0.721308	array([[ 2.825664, -8.317126]], dtype=float32)
time = 12260	action = 0	current_phase = 0	next_phase = 1	reward = 0.721262	array([[ 2.8219652, -8.316887 ]], dtype=float32)
time = 12265	action = 0	current_phase = 0	next_phase = 1	reward = 0.711729	array([[ 2.8435912, -8.285442 ]], dtype=float32)
time = 12270	action = 0	current_phase = 0	next_phase = 1	reward = 0.718173	array([[ 2.8480334, -8.22805  ]], dtype=float32)
time = 12275	action = 0	current_phase = 0	next_phase = 1	reward = 0.443958	array([[ 2.8399496, -8.229603 ]], dtype=float32)
time = 12280	action = 0	current_phase = 0	next_phase = 1	reward = 0.737419	array([[ 2.7568831, -8.389516 ]], dtype=float32)
time = 12285	action = 0	current_phase = 0	next_phase = 1	reward = 1.001523	array([[ 2.9281778, -8.377958 ]], dtype=float32)
time = 12290	action = 0	current_phase = 0	next_phase = 1	reward = 0.441214	array([[ 2.8241415, -8.296626 ]], dtype=float32)
time = 12295	action = 0	current_phase = 0	next_phase = 1	reward = 1.006243	array([[ 2.776554, -8.301406]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.1856 - val_loss: 6.0446
Epoch 2/50
 - 4s - loss: 3.5210 - val_loss: 5.6144
Epoch 3/50
 - 4s - loss: 4.8292 - val_loss: 6.6659
Epoch 4/50
 - 4s - loss: 3.2058 - val_loss: 6.1839
Epoch 5/50
 - 4s - loss: 3.6074 - val_loss: 6.1316
Epoch 6/50
 - 4s - loss: 3.8046 - val_loss: 6.1269
Epoch 7/50
 - 4s - loss: 2.9224 - val_loss: 5.9344
Epoch 8/50
 - 4s - loss: 2.8863 - val_loss: 5.9385
Epoch 9/50
 - 4s - loss: 3.5264 - val_loss: 5.8569
Epoch 10/50
 - 4s - loss: 3.7565 - val_loss: 5.8539
Epoch 11/50
 - 4s - loss: 3.3180 - val_loss: 5.9342
Epoch 12/50
 - 4s - loss: 3.3718 - val_loss: 5.8781
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 12300	action = 0	current_phase = 0	next_phase = 1	reward = 0.717714	array([[ 3.0406525, -8.296729 ]], dtype=float32)
time = 12305	action = 0	current_phase = 0	next_phase = 1	reward = 0.170804	array([[ 2.938183, -8.256146]], dtype=float32)
time = 12310	action = 0	current_phase = 0	next_phase = 1	reward = 1.286328	array([[ 2.9539912, -8.34431  ]], dtype=float32)
time = 12315	action = 0	current_phase = 0	next_phase = 1	reward = 0.719132	array([[ 2.8635633, -8.369865 ]], dtype=float32)
time = 12320	action = 0	current_phase = 0	next_phase = 1	reward = 0.445839	array([[ 3.0746915, -8.347828 ]], dtype=float32)
time = 12325	action = 0	current_phase = 0	next_phase = 1	reward = 0.721347	array([[ 2.9972837, -8.251907 ]], dtype=float32)
time = 12330	action = 0	current_phase = 0	next_phase = 1	reward = 0.721230	array([[ 2.9767945, -8.348657 ]], dtype=float32)
time = 12335	action = 0	current_phase = 0	next_phase = 1	reward = 0.727295	array([[ 2.803076, -8.641073]], dtype=float32)
time = 12340	action = 0	current_phase = 0	next_phase = 1	reward = 0.716811	array([[ 2.9877517, -8.245105 ]], dtype=float32)
time = 12345	action = 0	current_phase = 0	next_phase = 1	reward = 1.008271	array([[ 2.9377697, -8.293191 ]], dtype=float32)
time = 12350	action = 0	current_phase = 0	next_phase = 1	reward = 0.457827	array([[ 2.8244274, -8.433289 ]], dtype=float32)
time = 12355	action = 0	current_phase = 0	next_phase = 1	reward = 1.012926	array([[ 2.9382718, -8.2755165]], dtype=float32)
time = 12360	action = 0	current_phase = 0	next_phase = 1	reward = 0.727607	array([[ 2.9685638, -8.25614  ]], dtype=float32)
time = 12365	action = 0	current_phase = 0	next_phase = 1	reward = 0.447687	array([[ 2.973313, -8.224517]], dtype=float32)
time = 12370	action = 0	current_phase = 0	next_phase = 1	reward = 1.005439	array([[ 2.8690665, -8.2560005]], dtype=float32)
time = 12375	action = 0	current_phase = 0	next_phase = 1	reward = 0.722827	array([[ 2.9493906, -8.236871 ]], dtype=float32)
time = 12380	action = 0	current_phase = 0	next_phase = 1	reward = 0.730841	array([[ 3.026148, -8.31213 ]], dtype=float32)
time = 12385	action = 0	current_phase = 0	next_phase = 1	reward = 0.717349	array([[ 2.95669 , -8.259132]], dtype=float32)
time = 12390	action = 0	current_phase = 0	next_phase = 1	reward = 0.437945	array([[ 2.921922, -8.251503]], dtype=float32)
time = 12395	action = 0	current_phase = 0	next_phase = 1	reward = 0.724985	array([[ 2.8995988, -8.404316 ]], dtype=float32)
time = 12400	action = 0	current_phase = 0	next_phase = 1	reward = 1.009257	array([[ 2.9311965, -8.453684 ]], dtype=float32)
time = 12405	action = 0	current_phase = 0	next_phase = 1	reward = 0.720130	array([[ 2.9966981, -8.271125 ]], dtype=float32)
time = 12410	action = 0	current_phase = 0	next_phase = 1	reward = 0.720701	array([[ 2.9041154, -8.37682  ]], dtype=float32)
time = 12415	action = 0	current_phase = 0	next_phase = 1	reward = 0.728305	array([[ 2.9448164, -8.252885 ]], dtype=float32)
time = 12420	action = 0	current_phase = 0	next_phase = 1	reward = 0.732024	array([[ 2.9846566, -8.222801 ]], dtype=float32)
time = 12425	action = 0	current_phase = 0	next_phase = 1	reward = 0.727283	array([[ 2.9775589, -8.233509 ]], dtype=float32)
time = 12430	action = 0	current_phase = 0	next_phase = 1	reward = 0.725230	array([[ 2.8701618, -8.450858 ]], dtype=float32)
time = 12435	action = 0	current_phase = 0	next_phase = 1	reward = 0.723964	array([[ 2.9266212, -8.2586975]], dtype=float32)
time = 12440	action = 0	current_phase = 0	next_phase = 1	reward = 0.718049	array([[ 2.9566324, -8.289543 ]], dtype=float32)
time = 12445	action = 0	current_phase = 0	next_phase = 1	reward = 0.707206	array([[ 2.9870389, -8.282927 ]], dtype=float32)
time = 12450	action = 0	current_phase = 0	next_phase = 1	reward = 0.715779	array([[ 2.938226, -8.315971]], dtype=float32)
time = 12455	action = 0	current_phase = 0	next_phase = 1	reward = 0.447008	array([[ 2.971955, -8.268775]], dtype=float32)
time = 12460	action = 0	current_phase = 0	next_phase = 1	reward = 1.002368	array([[ 2.7659214, -8.379126 ]], dtype=float32)
time = 12465	action = 0	current_phase = 0	next_phase = 1	reward = 0.447513	array([[ 2.976516, -8.288271]], dtype=float32)
time = 12470	action = 0	current_phase = 0	next_phase = 1	reward = 1.000132	array([[ 2.9510496, -8.255199 ]], dtype=float32)
time = 12475	action = 0	current_phase = 0	next_phase = 1	reward = 0.444834	array([[ 2.8459527, -8.480196 ]], dtype=float32)
time = 12480	action = 0	current_phase = 0	next_phase = 1	reward = 0.736821	array([[ 2.8887432, -8.4115925]], dtype=float32)
time = 12485	action = 0	current_phase = 0	next_phase = 1	reward = 1.006134	array([[ 2.9799497, -8.329469 ]], dtype=float32)
time = 12490	action = 0	current_phase = 0	next_phase = 1	reward = 0.726006	array([[ 2.9408433, -8.276454 ]], dtype=float32)
time = 12495	action = 0	current_phase = 0	next_phase = 1	reward = 0.717159	array([[ 2.9340327, -8.350242 ]], dtype=float32)
time = 12500	action = 0	current_phase = 0	next_phase = 1	reward = 0.722104	array([[ 2.8949215, -8.29201  ]], dtype=float32)
time = 12505	action = 0	current_phase = 0	next_phase = 1	reward = 0.719386	array([[ 2.9343698, -8.3365135]], dtype=float32)
time = 12510	action = 0	current_phase = 0	next_phase = 1	reward = 0.717613	array([[ 2.9038942, -8.355968 ]], dtype=float32)
time = 12515	action = 0	current_phase = 0	next_phase = 1	reward = 0.716442	array([[ 2.5924308, -8.340984 ]], dtype=float32)
time = 12520	action = 0	current_phase = 0	next_phase = 1	reward = 0.723055	array([[ 2.9722922, -8.299482 ]], dtype=float32)
time = 12525	action = 0	current_phase = 0	next_phase = 1	reward = 0.724315	array([[ 2.9457867, -8.290339 ]], dtype=float32)
time = 12530	action = 0	current_phase = 0	next_phase = 1	reward = 0.720830	array([[ 2.9669182, -8.258357 ]], dtype=float32)
time = 12535	action = 0	current_phase = 0	next_phase = 1	reward = 0.437677	array([[ 2.830468, -8.324898]], dtype=float32)
time = 12540	action = 0	current_phase = 0	next_phase = 1	reward = 0.996542	array([[ 2.820707, -8.430437]], dtype=float32)
time = 12545	action = 0	current_phase = 0	next_phase = 1	reward = 0.720779	array([[ 3.0101488, -8.320546 ]], dtype=float32)
time = 12550	action = 0	current_phase = 0	next_phase = 1	reward = 0.447597	array([[ 2.9795678, -8.298635 ]], dtype=float32)
time = 12555	action = 0	current_phase = 0	next_phase = 1	reward = 0.727520	array([[ 2.9418285, -8.321325 ]], dtype=float32)
time = 12560	action = 0	current_phase = 0	next_phase = 1	reward = 1.009559	array([[ 2.8694165, -8.3370695]], dtype=float32)
time = 12565	action = 0	current_phase = 0	next_phase = 1	reward = 0.721187	array([[ 2.984277 , -8.2406845]], dtype=float32)
time = 12570	action = 0	current_phase = 0	next_phase = 1	reward = 0.444332	array([[ 2.9364278, -8.258858 ]], dtype=float32)
time = 12575	action = 0	current_phase = 0	next_phase = 1	reward = 1.001569	array([[ 2.8723524, -8.3467245]], dtype=float32)
time = 12580	action = 0	current_phase = 0	next_phase = 1	reward = 0.720204	array([[ 2.975496, -8.272886]], dtype=float32)
time = 12585	action = 0	current_phase = 0	next_phase = 1	reward = 0.714580	array([[ 2.8916147, -8.284591 ]], dtype=float32)
time = 12590	action = 0	current_phase = 0	next_phase = 1	reward = 0.441143	array([[ 2.9604928, -8.272024 ]], dtype=float32)
time = 12595	action = 0	current_phase = 0	next_phase = 1	reward = 0.721659	array([[ 3.0168836, -8.415135 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.1837 - val_loss: 5.4243
Epoch 2/50
 - 4s - loss: 4.0896 - val_loss: 4.9745
Epoch 3/50
 - 4s - loss: 4.2117 - val_loss: 4.8990
Epoch 4/50
 - 4s - loss: 3.3608 - val_loss: 4.7758
Epoch 5/50
 - 4s - loss: 3.0890 - val_loss: 4.7633
Epoch 6/50
 - 4s - loss: 3.8318 - val_loss: 4.9571
Epoch 7/50
 - 4s - loss: 4.2278 - val_loss: 4.8445
Epoch 8/50
 - 4s - loss: 3.8251 - val_loss: 5.4717
Epoch 9/50
 - 4s - loss: 4.3436 - val_loss: 5.5692
Epoch 10/50
 - 4s - loss: 3.5968 - val_loss: 6.0156
Epoch 11/50
 - 4s - loss: 3.6490 - val_loss: 5.4444
Epoch 12/50
 - 4s - loss: 3.2683 - val_loss: 4.8465
Epoch 13/50
 - 4s - loss: 3.9929 - val_loss: 5.1197
Epoch 14/50
 - 4s - loss: 3.6458 - val_loss: 5.8293
Epoch 15/50
 - 4s - loss: 3.1628 - val_loss: 4.7352
Epoch 16/50
 - 4s - loss: 3.4168 - val_loss: 5.1839
Epoch 17/50
 - 4s - loss: 3.2527 - val_loss: 5.1658
Epoch 18/50
 - 4s - loss: 3.3781 - val_loss: 5.4334
Epoch 19/50
 - 4s - loss: 2.9298 - val_loss: 5.0180
Epoch 20/50
 - 4s - loss: 3.1812 - val_loss: 5.2313
Epoch 21/50
 - 4s - loss: 3.0280 - val_loss: 4.6239
Epoch 22/50
 - 4s - loss: 3.1649 - val_loss: 4.7662
Epoch 23/50
 - 4s - loss: 3.1561 - val_loss: 4.9830
Epoch 24/50
 - 4s - loss: 3.4335 - val_loss: 5.0321
Epoch 25/50
 - 4s - loss: 2.8649 - val_loss: 5.6149
Epoch 26/50
 - 4s - loss: 3.4489 - val_loss: 4.7791
Epoch 27/50
 - 4s - loss: 3.6070 - val_loss: 5.1955
Epoch 28/50
 - 4s - loss: 3.2800 - val_loss: 5.2309
Epoch 29/50
 - 4s - loss: 3.0683 - val_loss: 5.0001
Epoch 30/50
 - 4s - loss: 3.3969 - val_loss: 5.2835
Epoch 31/50
 - 4s - loss: 2.8297 - val_loss: 5.7259
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 12600	action = 0	current_phase = 0	next_phase = 1	reward = 0.723592	array([[ 2.708902, -8.786987]], dtype=float32)
time = 12605	action = 0	current_phase = 0	next_phase = 1	reward = 1.003503	array([[ 2.9081483, -8.480848 ]], dtype=float32)
time = 12610	action = 0	current_phase = 0	next_phase = 1	reward = 0.732050	array([[ 2.9206657, -8.307579 ]], dtype=float32)
time = 12615	action = 0	current_phase = 0	next_phase = 1	reward = 0.735125	array([[ 2.9121566, -8.350075 ]], dtype=float32)
time = 12620	action = 0	current_phase = 0	next_phase = 1	reward = 0.450455	array([[ 2.9629025, -8.292837 ]], dtype=float32)
time = 12625	action = 0	current_phase = 0	next_phase = 1	reward = 1.001954	array([[ 2.8226843, -8.33107  ]], dtype=float32)
time = 12630	action = 0	current_phase = 0	next_phase = 1	reward = 0.728127	array([[ 2.9496546, -8.425416 ]], dtype=float32)
time = 12635	action = 0	current_phase = 0	next_phase = 1	reward = 0.726200	array([[ 2.9873571, -8.365948 ]], dtype=float32)
time = 12640	action = 0	current_phase = 0	next_phase = 1	reward = 0.725543	array([[ 2.9679847, -8.296289 ]], dtype=float32)
time = 12645	action = 0	current_phase = 0	next_phase = 1	reward = 0.721849	array([[ 2.9621153, -8.296668 ]], dtype=float32)
time = 12650	action = 0	current_phase = 0	next_phase = 1	reward = 0.720829	array([[ 3.0935097, -8.528426 ]], dtype=float32)
time = 12655	action = 0	current_phase = 0	next_phase = 1	reward = 0.723175	array([[ 2.959775, -8.370692]], dtype=float32)
time = 12660	action = 0	current_phase = 0	next_phase = 1	reward = 0.723587	array([[ 3.0091438, -8.401494 ]], dtype=float32)
time = 12665	action = 0	current_phase = 0	next_phase = 1	reward = 0.722850	array([[ 2.9253292, -8.311279 ]], dtype=float32)
time = 12670	action = 0	current_phase = 0	next_phase = 1	reward = 0.723691	array([[ 2.9056149, -8.378182 ]], dtype=float32)
time = 12675	action = 0	current_phase = 0	next_phase = 1	reward = 0.724699	array([[ 2.966545, -8.467323]], dtype=float32)
time = 12680	action = 0	current_phase = 0	next_phase = 1	reward = 0.730801	array([[ 2.9424644, -8.367921 ]], dtype=float32)
time = 12685	action = 0	current_phase = 0	next_phase = 1	reward = 0.724280	array([[ 2.9246879, -8.382135 ]], dtype=float32)
time = 12690	action = 0	current_phase = 0	next_phase = 1	reward = 0.724759	array([[ 2.9813652, -8.301672 ]], dtype=float32)
time = 12695	action = 0	current_phase = 0	next_phase = 1	reward = 0.727123	array([[ 2.89571  , -8.4203205]], dtype=float32)
time = 12700	action = 0	current_phase = 0	next_phase = 1	reward = 0.721521	array([[ 2.927885, -8.316508]], dtype=float32)
time = 12705	action = 0	current_phase = 0	next_phase = 1	reward = 0.441274	array([[ 2.8535752, -8.444075 ]], dtype=float32)
time = 12710	action = 0	current_phase = 0	next_phase = 1	reward = 0.998477	array([[ 2.9415512, -8.364857 ]], dtype=float32)
time = 12715	action = 0	current_phase = 0	next_phase = 1	reward = 0.723777	array([[ 2.9991999, -8.335365 ]], dtype=float32)
time = 12720	action = 0	current_phase = 0	next_phase = 1	reward = 0.718728	array([[ 2.9891362, -8.310963 ]], dtype=float32)
time = 12725	action = 0	current_phase = 0	next_phase = 1	reward = 0.720969	array([[ 2.9007578, -8.408985 ]], dtype=float32)
time = 12730	action = 0	current_phase = 0	next_phase = 1	reward = 0.449800	array([[ 2.9183354, -8.347662 ]], dtype=float32)
time = 12735	action = 0	current_phase = 0	next_phase = 1	reward = 1.003996	array([[ 2.868176, -8.360832]], dtype=float32)
time = 12740	action = 0	current_phase = 0	next_phase = 1	reward = 0.719782	array([[ 2.9239483, -8.39026  ]], dtype=float32)
time = 12745	action = 0	current_phase = 0	next_phase = 1	reward = 0.441037	array([[ 3.002737, -8.449409]], dtype=float32)
time = 12750	action = 0	current_phase = 0	next_phase = 1	reward = 1.004313	array([[ 2.9479952, -8.3417225]], dtype=float32)
time = 12755	action = 0	current_phase = 0	next_phase = 1	reward = 0.722229	array([[ 3.0045457, -8.536788 ]], dtype=float32)
time = 12760	action = 0	current_phase = 0	next_phase = 1	reward = 0.443934	array([[ 2.9265208, -8.354979 ]], dtype=float32)
time = 12765	action = 0	current_phase = 0	next_phase = 1	reward = 1.006053	array([[ 2.8568683, -8.521317 ]], dtype=float32)
time = 12770	action = 0	current_phase = 0	next_phase = 1	reward = 0.717897	array([[ 2.9085765, -8.329555 ]], dtype=float32)
time = 12775	action = 0	current_phase = 0	next_phase = 1	reward = 0.711166	array([[ 2.9268184, -8.309005 ]], dtype=float32)
time = 12780	action = 0	current_phase = 0	next_phase = 1	reward = 0.439057	array([[ 2.9720578, -8.332553 ]], dtype=float32)
time = 12785	action = 0	current_phase = 0	next_phase = 1	reward = 0.730423	array([[ 2.7777267, -8.618477 ]], dtype=float32)
time = 12790	action = 0	current_phase = 0	next_phase = 1	reward = 1.011771	array([[ 2.7350965, -8.376232 ]], dtype=float32)
time = 12795	action = 0	current_phase = 0	next_phase = 1	reward = 0.447998	array([[ 3.0093837, -8.378689 ]], dtype=float32)
time = 12800	action = 0	current_phase = 0	next_phase = 1	reward = 1.012032	array([[ 2.8893294, -8.533833 ]], dtype=float32)
time = 12805	action = 0	current_phase = 0	next_phase = 1	reward = 0.733152	array([[ 2.945764, -8.410523]], dtype=float32)
time = 12810	action = 0	current_phase = 0	next_phase = 1	reward = 0.727391	array([[ 2.9457827, -8.33544  ]], dtype=float32)
time = 12815	action = 0	current_phase = 0	next_phase = 1	reward = 0.724355	array([[ 3.0207386, -8.283864 ]], dtype=float32)
time = 12820	action = 0	current_phase = 0	next_phase = 1	reward = 0.708224	array([[ 2.9684925, -8.2654705]], dtype=float32)
time = 12825	action = 0	current_phase = 0	next_phase = 1	reward = 0.434502	array([[ 3.0189452, -8.3951845]], dtype=float32)
time = 12830	action = 0	current_phase = 0	next_phase = 1	reward = 0.724282	array([[ 2.9491353, -8.323782 ]], dtype=float32)
time = 12835	action = 0	current_phase = 0	next_phase = 1	reward = 1.000229	array([[ 2.8555927, -8.523664 ]], dtype=float32)
time = 12840	action = 0	current_phase = 0	next_phase = 1	reward = 0.723136	array([[ 2.942482, -8.356976]], dtype=float32)
time = 12845	action = 0	current_phase = 0	next_phase = 1	reward = 0.723345	array([[ 2.8522687, -8.381194 ]], dtype=float32)
time = 12850	action = 0	current_phase = 0	next_phase = 1	reward = 0.719228	array([[ 2.9799585, -8.317251 ]], dtype=float32)
time = 12855	action = 0	current_phase = 0	next_phase = 1	reward = 0.721512	array([[ 2.9582977, -8.415859 ]], dtype=float32)
time = 12860	action = 0	current_phase = 0	next_phase = 1	reward = 0.452382	array([[ 2.9272256, -8.455551 ]], dtype=float32)
time = 12865	action = 0	current_phase = 0	next_phase = 1	reward = 1.001441	array([[ 2.956006, -8.465384]], dtype=float32)
time = 12870	action = 0	current_phase = 0	next_phase = 1	reward = 0.715189	array([[ 2.963304, -8.329047]], dtype=float32)
time = 12875	action = 0	current_phase = 0	next_phase = 1	reward = 0.722275	array([[ 3.0042348, -8.316039 ]], dtype=float32)
time = 12880	action = 0	current_phase = 0	next_phase = 1	reward = 0.717925	array([[ 2.9776974, -8.3917675]], dtype=float32)
time = 12885	action = 0	current_phase = 0	next_phase = 1	reward = 0.172406	array([[ 2.9221182, -8.388414 ]], dtype=float32)
time = 12890	action = 0	current_phase = 0	next_phase = 1	reward = 1.288222	array([[ 2.888299, -8.467636]], dtype=float32)
time = 12895	action = 0	current_phase = 0	next_phase = 1	reward = 0.729178	array([[ 2.9385505, -8.3821   ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 3s - loss: 4.7915 - val_loss: 2.2897
Epoch 2/50
 - 4s - loss: 4.7927 - val_loss: 4.9263
Epoch 3/50
 - 4s - loss: 5.2127 - val_loss: 3.5322
Epoch 4/50
 - 4s - loss: 4.5888 - val_loss: 11.5161
Epoch 5/50
 - 4s - loss: 5.0587 - val_loss: 2.1375
Epoch 6/50
 - 4s - loss: 5.4376 - val_loss: 2.3691
Epoch 7/50
 - 6s - loss: 4.2141 - val_loss: 2.8760
Epoch 8/50
 - 4s - loss: 4.1120 - val_loss: 2.3119
Epoch 9/50
 - 4s - loss: 5.0717 - val_loss: 2.6738
Epoch 10/50
 - 4s - loss: 4.8697 - val_loss: 2.2640
Epoch 11/50
 - 4s - loss: 5.1790 - val_loss: 2.2888
Epoch 12/50
 - 4s - loss: 4.1485 - val_loss: 2.6216
Epoch 13/50
 - 4s - loss: 4.4651 - val_loss: 2.1498
Epoch 14/50
 - 4s - loss: 4.2264 - val_loss: 3.3235
Epoch 15/50
 - 4s - loss: 4.2111 - val_loss: 3.4022
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 12900	action = 0	current_phase = 0	next_phase = 1	reward = 0.726589	array([[ 2.9506674, -8.299108 ]], dtype=float32)
time = 12905	action = 0	current_phase = 0	next_phase = 1	reward = 0.714244	array([[ 2.9825454, -8.351255 ]], dtype=float32)
time = 12910	action = 0	current_phase = 0	next_phase = 1	reward = 0.710911	array([[ 2.9453416, -8.337773 ]], dtype=float32)
time = 12915	action = 0	current_phase = 0	next_phase = 1	reward = 0.714647	array([[ 2.855822 , -8.3839245]], dtype=float32)
time = 12920	action = 0	current_phase = 0	next_phase = 1	reward = 0.440714	array([[ 2.9760804, -8.376875 ]], dtype=float32)
time = 12925	action = 0	current_phase = 0	next_phase = 1	reward = 1.013642	array([[ 2.9088273, -8.406799 ]], dtype=float32)
time = 12930	action = 0	current_phase = 0	next_phase = 1	reward = 0.724529	array([[ 2.9337277, -8.3395605]], dtype=float32)
time = 12935	action = 0	current_phase = 0	next_phase = 1	reward = 0.725665	array([[ 2.953896, -8.354425]], dtype=float32)
time = 12940	action = 0	current_phase = 0	next_phase = 1	reward = 0.728885	array([[ 2.9649763, -8.3297825]], dtype=float32)
time = 12945	action = 0	current_phase = 0	next_phase = 1	reward = 0.726341	array([[ 2.9289875, -8.351507 ]], dtype=float32)
time = 12950	action = 0	current_phase = 0	next_phase = 1	reward = 0.717397	array([[ 2.9357224, -8.381717 ]], dtype=float32)
time = 12955	action = 0	current_phase = 0	next_phase = 1	reward = 0.719605	array([[ 3.0137615, -8.349021 ]], dtype=float32)
time = 12960	action = 0	current_phase = 0	next_phase = 1	reward = 0.724371	array([[ 2.940611, -8.388419]], dtype=float32)
time = 12965	action = 0	current_phase = 0	next_phase = 1	reward = 0.717437	array([[ 2.975028, -8.345998]], dtype=float32)
time = 12970	action = 0	current_phase = 0	next_phase = 1	reward = 0.729922	array([[ 2.9419441, -8.3326025]], dtype=float32)
time = 12975	action = 0	current_phase = 0	next_phase = 1	reward = 0.720418	array([[ 2.9650712, -8.365497 ]], dtype=float32)
time = 12980	action = 0	current_phase = 0	next_phase = 1	reward = 0.722197	array([[ 2.9222364, -8.375536 ]], dtype=float32)
time = 12985	action = 0	current_phase = 0	next_phase = 1	reward = 0.443326	array([[ 2.9295564, -8.371792 ]], dtype=float32)
time = 12990	action = 0	current_phase = 0	next_phase = 1	reward = 1.007710	array([[ 2.8890214, -8.378872 ]], dtype=float32)
time = 12995	action = 0	current_phase = 0	next_phase = 1	reward = 0.716966	array([[ 3.0437593, -8.352847 ]], dtype=float32)
time = 13000	action = 0	current_phase = 0	next_phase = 1	reward = 0.440380	array([[ 3.0139408, -8.423971 ]], dtype=float32)
time = 13005	action = 0	current_phase = 0	next_phase = 1	reward = 0.447321	array([[ 2.91743  , -8.3954735]], dtype=float32)
time = 13010	action = 0	current_phase = 0	next_phase = 1	reward = 1.283577	array([[ 2.9129395, -8.400864 ]], dtype=float32)
time = 13015	action = 0	current_phase = 0	next_phase = 1	reward = 0.725052	array([[ 2.9555192, -8.378028 ]], dtype=float32)
time = 13020	action = 0	current_phase = 0	next_phase = 1	reward = 0.722149	array([[ 2.8863363, -8.448126 ]], dtype=float32)
time = 13025	action = 0	current_phase = 0	next_phase = 1	reward = 0.724333	array([[ 2.9749742, -8.39561  ]], dtype=float32)
time = 13030	action = 0	current_phase = 0	next_phase = 1	reward = 0.164816	array([[ 2.9044738, -8.385223 ]], dtype=float32)
time = 13035	action = 0	current_phase = 0	next_phase = 1	reward = 1.287457	array([[ 2.8138466, -8.508542 ]], dtype=float32)
time = 13040	action = 0	current_phase = 0	next_phase = 1	reward = 0.712974	array([[ 2.9704986, -8.338791 ]], dtype=float32)
time = 13045	action = 0	current_phase = 0	next_phase = 1	reward = 0.442992	array([[ 2.9568744, -8.3511   ]], dtype=float32)
time = 13050	action = 0	current_phase = 0	next_phase = 1	reward = 1.015575	array([[ 2.9678712, -8.420693 ]], dtype=float32)
time = 13055	action = 0	current_phase = 0	next_phase = 1	reward = 0.727214	array([[ 3.0050812, -8.327845 ]], dtype=float32)
time = 13060	action = 0	current_phase = 0	next_phase = 1	reward = 0.717234	array([[ 2.936452, -8.366634]], dtype=float32)
time = 13065	action = 0	current_phase = 0	next_phase = 1	reward = 0.717666	array([[ 2.8855634, -8.3960085]], dtype=float32)
time = 13070	action = 0	current_phase = 0	next_phase = 1	reward = 0.709833	array([[ 2.884242, -8.362868]], dtype=float32)
time = 13075	action = 0	current_phase = 0	next_phase = 1	reward = 0.714026	array([[ 2.9575534, -8.345274 ]], dtype=float32)
time = 13080	action = 0	current_phase = 0	next_phase = 1	reward = 0.442503	array([[ 2.9306111, -8.39114  ]], dtype=float32)
time = 13085	action = 0	current_phase = 0	next_phase = 1	reward = 0.738829	array([[ 2.8764367, -8.479798 ]], dtype=float32)
time = 13090	action = 0	current_phase = 0	next_phase = 1	reward = 1.006733	array([[ 2.8271637, -8.571638 ]], dtype=float32)
time = 13095	action = 0	current_phase = 0	next_phase = 1	reward = 0.719413	array([[ 3.0015035, -8.363332 ]], dtype=float32)
time = 13100	action = 0	current_phase = 0	next_phase = 1	reward = 0.719145	array([[ 2.9614868, -8.363503 ]], dtype=float32)
time = 13105	action = 0	current_phase = 0	next_phase = 1	reward = 0.724050	array([[ 2.9551663, -8.375964 ]], dtype=float32)
time = 13110	action = 0	current_phase = 0	next_phase = 1	reward = 0.723270	array([[ 2.942459, -8.365072]], dtype=float32)
time = 13115	action = 0	current_phase = 0	next_phase = 1	reward = 0.721697	array([[ 2.9281168, -8.35756  ]], dtype=float32)
time = 13120	action = 0	current_phase = 0	next_phase = 1	reward = 0.445188	array([[ 2.8303642, -8.392731 ]], dtype=float32)
time = 13125	action = 0	current_phase = 0	next_phase = 1	reward = 1.002015	array([[ 2.974658, -8.36838 ]], dtype=float32)
time = 13130	action = 0	current_phase = 0	next_phase = 1	reward = 0.722653	array([[ 3.0354538, -8.419175 ]], dtype=float32)
time = 13135	action = 0	current_phase = 0	next_phase = 1	reward = 0.445588	array([[ 2.9697175, -8.346724 ]], dtype=float32)
time = 13140	action = 0	current_phase = 0	next_phase = 1	reward = 1.007968	array([[ 2.8888812, -8.395784 ]], dtype=float32)
time = 13145	action = 0	current_phase = 0	next_phase = 1	reward = 0.438106	array([[ 2.9373155, -8.35309  ]], dtype=float32)
time = 13150	action = 0	current_phase = 0	next_phase = 1	reward = 1.005464	array([[ 3.0166836, -8.343021 ]], dtype=float32)
time = 13155	action = 0	current_phase = 0	next_phase = 1	reward = 0.444811	array([[ 3.0132217, -8.38769  ]], dtype=float32)
time = 13160	action = 0	current_phase = 0	next_phase = 1	reward = 1.002947	array([[ 2.923592, -8.384499]], dtype=float32)
time = 13165	action = 0	current_phase = 0	next_phase = 1	reward = 0.720085	array([[ 2.9298244, -8.351384 ]], dtype=float32)
time = 13170	action = 0	current_phase = 0	next_phase = 1	reward = 0.721626	array([[ 3.0084324, -8.357261 ]], dtype=float32)
time = 13175	action = 0	current_phase = 0	next_phase = 1	reward = 0.449879	array([[ 2.9496202, -8.3547945]], dtype=float32)
time = 13180	action = 0	current_phase = 0	next_phase = 1	reward = 1.003779	array([[ 2.8988428, -8.466279 ]], dtype=float32)
time = 13185	action = 0	current_phase = 0	next_phase = 1	reward = 0.440416	array([[ 2.964263, -8.33177 ]], dtype=float32)
time = 13190	action = 0	current_phase = 0	next_phase = 1	reward = 0.998039	array([[ 2.934651 , -8.3855915]], dtype=float32)
time = 13195	action = 0	current_phase = 0	next_phase = 1	reward = 0.444855	array([[ 2.9669619, -8.335497 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.2647 - val_loss: 4.0795
Epoch 2/50
 - 4s - loss: 4.5937 - val_loss: 2.5152
Epoch 3/50
 - 4s - loss: 4.9833 - val_loss: 3.3227
Epoch 4/50
 - 4s - loss: 4.5071 - val_loss: 3.3113
Epoch 5/50
 - 4s - loss: 4.2529 - val_loss: 3.5459
Epoch 6/50
 - 4s - loss: 4.8160 - val_loss: 3.4862
Epoch 7/50
 - 4s - loss: 4.9196 - val_loss: 3.4853
Epoch 8/50
 - 4s - loss: 4.4027 - val_loss: 3.6118
Epoch 9/50
 - 4s - loss: 4.6122 - val_loss: 4.4445
Epoch 10/50
 - 4s - loss: 4.4976 - val_loss: 3.0999
Epoch 11/50
 - 4s - loss: 3.7164 - val_loss: 2.8733
Epoch 12/50
 - 4s - loss: 4.1501 - val_loss: 2.6447
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 13200	action = 0	current_phase = 0	next_phase = 1	reward = 0.724097	array([[ 3.0132985, -8.385062 ]], dtype=float32)
time = 13205	action = 0	current_phase = 0	next_phase = 1	reward = 0.725888	array([[ 3.0689921, -8.456385 ]], dtype=float32)
time = 13210	action = 0	current_phase = 0	next_phase = 1	reward = 0.721283	array([[ 2.961944, -8.395244]], dtype=float32)
time = 13215	action = 0	current_phase = 0	next_phase = 1	reward = 1.011394	array([[ 2.9381013, -8.426622 ]], dtype=float32)
time = 13220	action = 0	current_phase = 0	next_phase = 1	reward = 0.725615	array([[ 3.0070019, -8.365747 ]], dtype=float32)
time = 13225	action = 0	current_phase = 0	next_phase = 1	reward = 0.718814	array([[ 2.962513 , -8.4002495]], dtype=float32)
time = 13230	action = 0	current_phase = 0	next_phase = 1	reward = 0.726270	array([[ 3.043477, -8.366692]], dtype=float32)
time = 13235	action = 0	current_phase = 0	next_phase = 1	reward = 0.172334	array([[ 2.9726982, -8.391843 ]], dtype=float32)
time = 13240	action = 0	current_phase = 0	next_phase = 1	reward = 1.010133	array([[ 2.890502 , -8.5660095]], dtype=float32)
time = 13245	action = 0	current_phase = 0	next_phase = 1	reward = 0.994289	array([[ 2.9577794, -8.459704 ]], dtype=float32)
time = 13250	action = 0	current_phase = 0	next_phase = 1	reward = 0.448823	array([[ 3.090867, -8.49835 ]], dtype=float32)
time = 13255	action = 0	current_phase = 0	next_phase = 1	reward = 1.007357	array([[ 2.9646454, -8.399985 ]], dtype=float32)
time = 13260	action = 0	current_phase = 0	next_phase = 1	reward = 0.724321	array([[ 2.9677234, -8.408945 ]], dtype=float32)
time = 13265	action = 0	current_phase = 0	next_phase = 1	reward = 0.713687	array([[ 2.963478, -8.362621]], dtype=float32)
time = 13270	action = 0	current_phase = 0	next_phase = 1	reward = 0.437122	array([[ 2.9846182, -8.442093 ]], dtype=float32)
time = 13275	action = 0	current_phase = 0	next_phase = 1	reward = 0.726849	array([[ 2.9462285, -8.430406 ]], dtype=float32)
time = 13280	action = 0	current_phase = 0	next_phase = 1	reward = 1.005672	array([[ 2.9767241, -8.448405 ]], dtype=float32)
time = 13285	action = 0	current_phase = 0	next_phase = 1	reward = 0.722376	array([[ 2.8994946, -8.388246 ]], dtype=float32)
time = 13290	action = 0	current_phase = 0	next_phase = 1	reward = 0.719424	array([[ 3.0173392, -8.359896 ]], dtype=float32)
time = 13295	action = 0	current_phase = 0	next_phase = 1	reward = 0.727018	array([[ 3.0196648, -8.395645 ]], dtype=float32)
time = 13300	action = 0	current_phase = 0	next_phase = 1	reward = 0.163332	array([[ 2.9944701, -8.364541 ]], dtype=float32)
time = 13305	action = 0	current_phase = 0	next_phase = 1	reward = 1.283200	array([[ 2.919725, -8.519991]], dtype=float32)
time = 13310	action = 0	current_phase = 0	next_phase = 1	reward = 0.444570	array([[ 3.0159712, -8.374287 ]], dtype=float32)
time = 13315	action = 0	current_phase = 0	next_phase = 1	reward = 1.011252	array([[ 2.9398232, -8.442372 ]], dtype=float32)
time = 13320	action = 0	current_phase = 0	next_phase = 1	reward = 0.720664	array([[ 3.0508366, -8.4189   ]], dtype=float32)
time = 13325	action = 0	current_phase = 0	next_phase = 1	reward = 0.719667	array([[ 2.9385052, -8.397713 ]], dtype=float32)
time = 13330	action = 0	current_phase = 0	next_phase = 1	reward = 0.454639	array([[ 2.9626198, -8.439475 ]], dtype=float32)
time = 13335	action = 0	current_phase = 0	next_phase = 1	reward = 1.006804	array([[ 2.9391913, -8.436188 ]], dtype=float32)
time = 13340	action = 0	current_phase = 0	next_phase = 1	reward = 0.716025	array([[ 3.009766, -8.377181]], dtype=float32)
time = 13345	action = 0	current_phase = 0	next_phase = 1	reward = 0.442225	array([[ 2.994432, -8.401831]], dtype=float32)
time = 13350	action = 0	current_phase = 0	next_phase = 1	reward = 1.005643	array([[ 2.9605865, -8.530632 ]], dtype=float32)
time = 13355	action = 0	current_phase = 0	next_phase = 1	reward = 0.165196	array([[ 2.9842362, -8.379709 ]], dtype=float32)
time = 13360	action = 0	current_phase = 0	next_phase = 1	reward = 1.285296	array([[ 2.905254, -8.53017 ]], dtype=float32)
time = 13365	action = 0	current_phase = 0	next_phase = 1	reward = 0.727750	array([[ 3.069024, -8.405701]], dtype=float32)
time = 13370	action = 0	current_phase = 0	next_phase = 1	reward = 0.724813	array([[ 2.8898387, -8.486943 ]], dtype=float32)
time = 13375	action = 0	current_phase = 0	next_phase = 1	reward = 0.713881	array([[ 2.9923391, -8.415458 ]], dtype=float32)
time = 13380	action = 0	current_phase = 0	next_phase = 1	reward = 0.713931	array([[ 2.9947147, -8.363892 ]], dtype=float32)
time = 13385	action = 0	current_phase = 0	next_phase = 1	reward = 0.449990	array([[ 2.925438 , -8.3658285]], dtype=float32)
time = 13390	action = 0	current_phase = 0	next_phase = 1	reward = 1.006521	array([[ 2.9271374, -8.483768 ]], dtype=float32)
time = 13395	action = 0	current_phase = 0	next_phase = 1	reward = 0.713987	array([[ 2.9879694, -8.370635 ]], dtype=float32)
time = 13400	action = 0	current_phase = 0	next_phase = 1	reward = 0.713035	array([[ 3.0286374, -8.374902 ]], dtype=float32)
time = 13405	action = 0	current_phase = 0	next_phase = 1	reward = 0.445968	array([[ 2.9933357, -8.438605 ]], dtype=float32)
time = 13410	action = 0	current_phase = 0	next_phase = 1	reward = 1.015165	array([[ 2.9779716, -8.406858 ]], dtype=float32)
time = 13415	action = 0	current_phase = 0	next_phase = 1	reward = 0.443607	array([[ 2.9779758, -8.4372225]], dtype=float32)
time = 13420	action = 0	current_phase = 0	next_phase = 1	reward = 0.727500	array([[ 2.9603238, -8.478718 ]], dtype=float32)
time = 13425	action = 0	current_phase = 0	next_phase = 1	reward = 0.999522	array([[ 2.9044113, -8.533887 ]], dtype=float32)
time = 13430	action = 0	current_phase = 0	next_phase = 1	reward = 0.452159	array([[ 2.9859219, -8.387218 ]], dtype=float32)
time = 13435	action = 0	current_phase = 0	next_phase = 1	reward = 1.005621	array([[ 2.9296222, -8.4562845]], dtype=float32)
time = 13440	action = 0	current_phase = 0	next_phase = 1	reward = 0.730713	array([[ 3.0368562, -8.380087 ]], dtype=float32)
time = 13445	action = 0	current_phase = 0	next_phase = 1	reward = 0.444430	array([[ 2.9637942, -8.404353 ]], dtype=float32)
time = 13450	action = 0	current_phase = 0	next_phase = 1	reward = 1.002438	array([[ 2.8879447, -8.495245 ]], dtype=float32)
time = 13455	action = 0	current_phase = 0	next_phase = 1	reward = 0.726119	array([[ 3.0415912, -8.447726 ]], dtype=float32)
time = 13460	action = 0	current_phase = 0	next_phase = 1	reward = 0.450072	array([[ 2.9697828, -8.404348 ]], dtype=float32)
time = 13465	action = 0	current_phase = 0	next_phase = 1	reward = 0.999616	array([[ 2.9523869, -8.460968 ]], dtype=float32)
time = 13470	action = 0	current_phase = 0	next_phase = 1	reward = 0.714588	array([[ 3.0174503, -8.380173 ]], dtype=float32)
time = 13475	action = 0	current_phase = 0	next_phase = 1	reward = 0.722128	array([[ 3.0629764, -8.381483 ]], dtype=float32)
time = 13480	action = 0	current_phase = 0	next_phase = 1	reward = 0.443461	array([[ 2.9219599, -8.465621 ]], dtype=float32)
time = 13485	action = 0	current_phase = 0	next_phase = 1	reward = 1.004835	array([[ 2.9659057, -8.413916 ]], dtype=float32)
time = 13490	action = 0	current_phase = 0	next_phase = 1	reward = 0.716695	array([[ 3.033917, -8.382704]], dtype=float32)
time = 13495	action = 0	current_phase = 0	next_phase = 1	reward = 0.715721	array([[ 2.9702225, -8.385841 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.5602 - val_loss: 2.0328
Epoch 2/50
 - 4s - loss: 4.7983 - val_loss: 2.3409
Epoch 3/50
 - 4s - loss: 4.2278 - val_loss: 2.0724
Epoch 4/50
 - 4s - loss: 4.1720 - val_loss: 1.9509
Epoch 5/50
 - 4s - loss: 4.2486 - val_loss: 2.6103
Epoch 6/50
 - 4s - loss: 4.2129 - val_loss: 2.0563
Epoch 7/50
 - 4s - loss: 3.8122 - val_loss: 2.1066
Epoch 8/50
 - 4s - loss: 3.8751 - val_loss: 2.1123
Epoch 9/50
 - 4s - loss: 4.2839 - val_loss: 2.3609
Epoch 10/50
 - 4s - loss: 5.8747 - val_loss: 2.5395
Epoch 11/50
 - 4s - loss: 3.8779 - val_loss: 2.1038
Epoch 12/50
 - 4s - loss: 3.8161 - val_loss: 2.5605
Epoch 13/50
 - 4s - loss: 4.2489 - val_loss: 2.4071
Epoch 14/50
 - 4s - loss: 3.9519 - val_loss: 2.1668
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 13500	action = 0	current_phase = 0	next_phase = 1	reward = 0.723944	array([[ 3.0023537, -8.408432 ]], dtype=float32)
time = 13505	action = 0	current_phase = 0	next_phase = 1	reward = 0.448846	array([[ 3.0543485, -8.472393 ]], dtype=float32)
time = 13510	action = 0	current_phase = 0	next_phase = 1	reward = 1.011134	array([[ 2.9402976, -8.448694 ]], dtype=float32)
time = 13515	action = 0	current_phase = 0	next_phase = 1	reward = 0.723844	array([[ 3.0440931, -8.452513 ]], dtype=float32)
time = 13520	action = 0	current_phase = 0	next_phase = 1	reward = 0.719433	array([[ 3.020059, -8.409001]], dtype=float32)
time = 13525	action = 0	current_phase = 0	next_phase = 1	reward = 0.711525	array([[ 3.0747924, -8.473614 ]], dtype=float32)
time = 13530	action = 0	current_phase = 0	next_phase = 1	reward = 0.718729	array([[ 3.1388898, -8.463909 ]], dtype=float32)
time = 13535	action = 0	current_phase = 0	next_phase = 1	reward = 0.446961	array([[ 3.0192652, -8.440732 ]], dtype=float32)
time = 13540	action = 0	current_phase = 0	next_phase = 1	reward = 1.000482	array([[ 2.9659472, -8.556215 ]], dtype=float32)
time = 13545	action = 0	current_phase = 0	next_phase = 1	reward = 0.724964	array([[ 2.9697561, -8.505645 ]], dtype=float32)
time = 13550	action = 0	current_phase = 0	next_phase = 1	reward = 0.726002	array([[ 2.9901948, -8.400523 ]], dtype=float32)
time = 13555	action = 0	current_phase = 0	next_phase = 1	reward = 0.721651	array([[ 3.0374975, -8.466138 ]], dtype=float32)
time = 13560	action = 0	current_phase = 0	next_phase = 1	reward = 0.451730	array([[ 3.0117197, -8.456741 ]], dtype=float32)
time = 13565	action = 0	current_phase = 0	next_phase = 1	reward = 1.007946	array([[ 3.0860295, -8.506808 ]], dtype=float32)
time = 13570	action = 0	current_phase = 0	next_phase = 1	reward = 0.721740	array([[ 3.0491085, -8.420479 ]], dtype=float32)
time = 13575	action = 0	current_phase = 0	next_phase = 1	reward = 0.723156	array([[ 3.0053787, -8.417594 ]], dtype=float32)
time = 13580	action = 0	current_phase = 0	next_phase = 1	reward = 0.449392	array([[ 3.0249681, -8.407449 ]], dtype=float32)
time = 13585	action = 0	current_phase = 0	next_phase = 1	reward = 1.002811	array([[ 3.0544705, -8.574374 ]], dtype=float32)
time = 13590	action = 0	current_phase = 0	next_phase = 1	reward = 0.715250	array([[ 3.0498471, -8.408651 ]], dtype=float32)
time = 13595	action = 0	current_phase = 0	next_phase = 1	reward = 0.438518	array([[ 2.9611478, -8.43153  ]], dtype=float32)
time = 13600	action = 0	current_phase = 0	next_phase = 1	reward = 1.007876	array([[ 2.9507613, -8.526001 ]], dtype=float32)
time = 13605	action = 0	current_phase = 0	next_phase = 1	reward = 0.729794	array([[ 3.0745044, -8.436567 ]], dtype=float32)
time = 13610	action = 0	current_phase = 0	next_phase = 1	reward = 0.438470	array([[ 3.0147047, -8.408787 ]], dtype=float32)
time = 13615	action = 0	current_phase = 0	next_phase = 1	reward = 1.014017	array([[ 3.0564017, -8.4798975]], dtype=float32)
time = 13620	action = 0	current_phase = 0	next_phase = 1	reward = 0.446093	array([[ 2.9981966, -8.421017 ]], dtype=float32)
time = 13625	action = 0	current_phase = 0	next_phase = 1	reward = 1.004595	array([[ 2.9971375, -8.44113  ]], dtype=float32)
time = 13630	action = 0	current_phase = 0	next_phase = 1	reward = 0.438352	array([[ 3.1166883, -8.408344 ]], dtype=float32)
time = 13635	action = 0	current_phase = 0	next_phase = 1	reward = 0.711748	array([[ 3.0473366, -8.452161 ]], dtype=float32)
time = 13640	action = 0	current_phase = 0	next_phase = 1	reward = 0.451332	array([[ 3.0289435, -8.479667 ]], dtype=float32)
time = 13645	action = 0	current_phase = 0	next_phase = 1	reward = 1.289406	array([[ 2.9413996, -8.477098 ]], dtype=float32)
time = 13650	action = 0	current_phase = 0	next_phase = 1	reward = 0.442486	array([[ 2.9611192, -8.427511 ]], dtype=float32)
time = 13655	action = 0	current_phase = 0	next_phase = 1	reward = 0.717498	array([[ 3.0123029, -8.450184 ]], dtype=float32)
time = 13660	action = 0	current_phase = 0	next_phase = 1	reward = 1.000384	array([[ 3.0217276, -8.489071 ]], dtype=float32)
time = 13665	action = 0	current_phase = 0	next_phase = 1	reward = 0.163745	array([[ 2.9848804, -8.444166 ]], dtype=float32)
time = 13670	action = 0	current_phase = 0	next_phase = 1	reward = 1.016160	array([[ 3.0014834, -8.59873  ]], dtype=float32)
time = 13675	action = 0	current_phase = 0	next_phase = 1	reward = 1.001060	array([[ 3.0749583, -8.429843 ]], dtype=float32)
time = 13680	action = 0	current_phase = 0	next_phase = 1	reward = 0.718245	array([[ 3.07998 , -8.398986]], dtype=float32)
time = 13685	action = 0	current_phase = 0	next_phase = 1	reward = 0.715552	array([[ 3.0289502, -8.495218 ]], dtype=float32)
time = 13690	action = 0	current_phase = 0	next_phase = 1	reward = 0.442672	array([[ 2.967595 , -8.4407215]], dtype=float32)
time = 13695	action = 0	current_phase = 0	next_phase = 1	reward = 0.729314	array([[ 2.9853153, -8.446673 ]], dtype=float32)
time = 13700	action = 0	current_phase = 0	next_phase = 1	reward = 1.004003	array([[ 3.0819407, -8.452054 ]], dtype=float32)
time = 13705	action = 0	current_phase = 0	next_phase = 1	reward = 0.719325	array([[ 2.9405942, -8.484639 ]], dtype=float32)
time = 13710	action = 0	current_phase = 0	next_phase = 1	reward = 0.444455	array([[ 2.9840975, -8.424324 ]], dtype=float32)
time = 13715	action = 0	current_phase = 0	next_phase = 1	reward = 0.730208	array([[ 2.9854288, -8.488461 ]], dtype=float32)
time = 13720	action = 0	current_phase = 0	next_phase = 1	reward = 0.728007	array([[ 3.0711641, -8.445131 ]], dtype=float32)
time = 13725	action = 0	current_phase = 0	next_phase = 1	reward = 1.002337	array([[ 3.002542, -8.542858]], dtype=float32)
time = 13730	action = 0	current_phase = 0	next_phase = 1	reward = 0.729032	array([[ 3.0586805, -8.420161 ]], dtype=float32)
time = 13735	action = 0	current_phase = 0	next_phase = 1	reward = 0.727902	array([[ 2.9894748, -8.431224 ]], dtype=float32)
time = 13740	action = 0	current_phase = 0	next_phase = 1	reward = 0.442073	array([[ 3.0331287, -8.462234 ]], dtype=float32)
time = 13745	action = 0	current_phase = 0	next_phase = 1	reward = 0.723379	array([[ 2.9902906, -8.429835 ]], dtype=float32)
time = 13750	action = 0	current_phase = 0	next_phase = 1	reward = 0.998425	array([[ 3.0844722, -8.60561  ]], dtype=float32)
time = 13755	action = 0	current_phase = 0	next_phase = 1	reward = 0.436973	array([[ 3.085855, -8.441086]], dtype=float32)
time = 13760	action = 0	current_phase = 0	next_phase = 1	reward = 0.446196	array([[ 2.9870715, -8.4681225]], dtype=float32)
time = 13765	action = 0	current_phase = 0	next_phase = 1	reward = 1.010520	array([[ 2.9325538, -8.491656 ]], dtype=float32)
time = 13770	action = 0	current_phase = 0	next_phase = 1	reward = 0.732577	array([[ 3.0201755, -8.449067 ]], dtype=float32)
time = 13775	action = 0	current_phase = 0	next_phase = 1	reward = 0.999823	array([[ 2.9511738, -8.449744 ]], dtype=float32)
time = 13780	action = 0	current_phase = 0	next_phase = 1	reward = 0.715984	array([[ 3.0083523, -8.453307 ]], dtype=float32)
time = 13785	action = 0	current_phase = 0	next_phase = 1	reward = 0.444461	array([[ 2.9864802, -8.412367 ]], dtype=float32)
time = 13790	action = 0	current_phase = 0	next_phase = 1	reward = 1.007861	array([[ 3.0052605, -8.476722 ]], dtype=float32)
time = 13795	action = 0	current_phase = 0	next_phase = 1	reward = 0.719739	array([[ 3.0288572, -8.40986  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.2916 - val_loss: 2.6215
Epoch 2/50
 - 4s - loss: 5.3173 - val_loss: 3.2577
Epoch 3/50
 - 4s - loss: 4.8197 - val_loss: 3.8358
Epoch 4/50
 - 4s - loss: 4.9223 - val_loss: 2.5905
Epoch 5/50
 - 4s - loss: 3.9991 - val_loss: 2.5226
Epoch 6/50
 - 4s - loss: 4.3460 - val_loss: 2.6491
Epoch 7/50
 - 4s - loss: 5.5768 - val_loss: 2.8712
Epoch 8/50
 - 4s - loss: 5.2339 - val_loss: 2.9035
Epoch 9/50
 - 4s - loss: 4.2986 - val_loss: 3.8099
Epoch 10/50
 - 4s - loss: 4.3717 - val_loss: 2.4967
Epoch 11/50
 - 4s - loss: 4.1435 - val_loss: 2.4953
Epoch 12/50
 - 4s - loss: 4.1171 - val_loss: 2.1576
Epoch 13/50
 - 4s - loss: 4.4944 - val_loss: 2.5670
Epoch 14/50
 - 4s - loss: 4.0283 - val_loss: 2.3679
Epoch 15/50
 - 4s - loss: 3.7924 - val_loss: 2.1632
Epoch 16/50
 - 4s - loss: 4.9097 - val_loss: 3.2052
Epoch 17/50
 - 4s - loss: 4.4244 - val_loss: 2.6635
Epoch 18/50
 - 4s - loss: 3.6981 - val_loss: 2.4085
Epoch 19/50
 - 4s - loss: 4.7365 - val_loss: 2.6634
Epoch 20/50
 - 4s - loss: 4.1265 - val_loss: 2.7833
Epoch 21/50
 - 4s - loss: 3.5767 - val_loss: 2.7002
Epoch 22/50
 - 4s - loss: 4.2366 - val_loss: 3.1223
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 13800	action = 0	current_phase = 0	next_phase = 1	reward = 0.725899	array([[ 3.0896597, -8.491486 ]], dtype=float32)
time = 13805	action = 0	current_phase = 0	next_phase = 1	reward = 0.722371	array([[ 3.0715036, -8.534229 ]], dtype=float32)
time = 13810	action = 0	current_phase = 0	next_phase = 1	reward = 0.701787	array([[ 3.107358, -8.454175]], dtype=float32)
time = 13815	action = 0	current_phase = 0	next_phase = 1	reward = 0.442839	array([[ 3.1140723, -8.460755 ]], dtype=float32)
time = 13820	action = 0	current_phase = 0	next_phase = 1	reward = 1.010599	array([[ 3.134913, -8.557241]], dtype=float32)
time = 13825	action = 0	current_phase = 0	next_phase = 1	reward = 0.445743	array([[ 2.999236, -8.60799 ]], dtype=float32)
time = 13830	action = 0	current_phase = 0	next_phase = 1	reward = 1.014369	array([[ 3.1228075, -8.495985 ]], dtype=float32)
time = 13835	action = 0	current_phase = 0	next_phase = 1	reward = 0.727041	array([[ 3.118806, -8.463692]], dtype=float32)
time = 13840	action = 0	current_phase = 0	next_phase = 1	reward = 0.725428	array([[ 3.1177092, -8.485105 ]], dtype=float32)
time = 13845	action = 0	current_phase = 0	next_phase = 1	reward = 0.722326	array([[ 3.001215, -8.543135]], dtype=float32)
time = 13850	action = 0	current_phase = 0	next_phase = 1	reward = 0.724309	array([[ 3.134015, -8.510286]], dtype=float32)
time = 13855	action = 0	current_phase = 0	next_phase = 1	reward = 0.722685	array([[ 3.1744256, -8.43933  ]], dtype=float32)
time = 13860	action = 0	current_phase = 0	next_phase = 1	reward = 0.718593	array([[ 3.1252956, -8.488988 ]], dtype=float32)
time = 13865	action = 0	current_phase = 0	next_phase = 1	reward = 0.722397	array([[ 3.1387992, -8.483693 ]], dtype=float32)
time = 13870	action = 0	current_phase = 0	next_phase = 1	reward = 0.718860	array([[ 3.0910873, -8.506462 ]], dtype=float32)
time = 13875	action = 0	current_phase = 0	next_phase = 1	reward = 0.718529	array([[ 3.0866995, -8.530009 ]], dtype=float32)
time = 13880	action = 0	current_phase = 0	next_phase = 1	reward = 0.165123	array([[ 3.254486, -8.567515]], dtype=float32)
time = 13885	action = 0	current_phase = 0	next_phase = 1	reward = 1.287074	array([[ 2.924674, -9.006807]], dtype=float32)
time = 13890	action = 0	current_phase = 0	next_phase = 1	reward = 0.718140	array([[ 3.2031794, -8.771954 ]], dtype=float32)
time = 13895	action = 0	current_phase = 0	next_phase = 1	reward = 0.439526	array([[ 3.0144448, -8.557211 ]], dtype=float32)
time = 13900	action = 0	current_phase = 0	next_phase = 1	reward = 0.447203	array([[ 3.0997677, -8.478921 ]], dtype=float32)
time = 13905	action = 0	current_phase = 0	next_phase = 1	reward = 1.009423	array([[ 2.4322786, -9.644463 ]], dtype=float32)
time = 13910	action = 0	current_phase = 0	next_phase = 1	reward = 0.728471	array([[ 3.1466742, -8.48966  ]], dtype=float32)
time = 13915	action = 0	current_phase = 0	next_phase = 1	reward = 1.011643	array([[ 2.9176812, -8.75509  ]], dtype=float32)
time = 13920	action = 0	current_phase = 0	next_phase = 1	reward = 0.728529	array([[ 2.9677186, -8.562784 ]], dtype=float32)
time = 13925	action = 0	current_phase = 0	next_phase = 1	reward = 0.445249	array([[ 3.1578197, -8.475327 ]], dtype=float32)
time = 13930	action = 0	current_phase = 0	next_phase = 1	reward = 1.003269	array([[ 3.071756, -8.506716]], dtype=float32)
time = 13935	action = 0	current_phase = 0	next_phase = 1	reward = 0.717985	array([[ 3.0798602, -8.549515 ]], dtype=float32)
time = 13940	action = 0	current_phase = 0	next_phase = 1	reward = 0.723758	array([[ 3.2058625, -8.490235 ]], dtype=float32)
time = 13945	action = 0	current_phase = 0	next_phase = 1	reward = 0.443533	array([[ 3.154129, -8.470978]], dtype=float32)
time = 13950	action = 0	current_phase = 0	next_phase = 1	reward = 1.005140	array([[ 3.080388, -8.507414]], dtype=float32)
time = 13955	action = 0	current_phase = 0	next_phase = 1	reward = 0.719357	array([[ 2.914043, -8.471096]], dtype=float32)
time = 13960	action = 0	current_phase = 0	next_phase = 1	reward = 0.441575	array([[ 3.084641 , -8.4947405]], dtype=float32)
time = 13965	action = 0	current_phase = 0	next_phase = 1	reward = 0.724225	array([[ 3.1813846, -8.514641 ]], dtype=float32)
time = 13970	action = 0	current_phase = 0	next_phase = 1	reward = 0.729340	array([[ 3.0204072, -8.627828 ]], dtype=float32)
time = 13975	action = 0	current_phase = 0	next_phase = 1	reward = 1.005272	array([[ 3.1023002, -8.497262 ]], dtype=float32)
time = 13980	action = 0	current_phase = 0	next_phase = 1	reward = 0.446410	array([[ 3.0860634, -8.53922  ]], dtype=float32)
time = 13985	action = 0	current_phase = 0	next_phase = 1	reward = 0.726954	array([[ 3.114583, -8.476384]], dtype=float32)
time = 13990	action = 0	current_phase = 0	next_phase = 1	reward = 1.001678	array([[ 3.0693617, -8.809603 ]], dtype=float32)
time = 13995	action = 0	current_phase = 0	next_phase = 1	reward = 0.718441	array([[ 3.1317348, -8.511675 ]], dtype=float32)
time = 14000	action = 0	current_phase = 0	next_phase = 1	reward = 0.718431	array([[ 3.0623522, -8.562977 ]], dtype=float32)
time = 14005	action = 0	current_phase = 0	next_phase = 1	reward = 0.442616	array([[ 3.1391878, -8.471127 ]], dtype=float32)
time = 14010	action = 0	current_phase = 0	next_phase = 1	reward = 0.734358	array([[ 2.9434514, -8.607149 ]], dtype=float32)
time = 14015	action = 0	current_phase = 0	next_phase = 1	reward = 0.998908	array([[ 3.0772653, -8.574087 ]], dtype=float32)
time = 14020	action = 0	current_phase = 0	next_phase = 1	reward = 0.721787	array([[ 3.081314, -8.531983]], dtype=float32)
time = 14025	action = 0	current_phase = 0	next_phase = 1	reward = 0.437973	array([[ 3.14292, -8.4539 ]], dtype=float32)
time = 14030	action = 0	current_phase = 0	next_phase = 1	reward = 0.719123	array([[ 3.0195832, -8.528916 ]], dtype=float32)
time = 14035	action = 0	current_phase = 0	next_phase = 1	reward = 0.999481	array([[ 2.8084307, -8.67518  ]], dtype=float32)
time = 14040	action = 0	current_phase = 0	next_phase = 1	reward = 0.722963	array([[ 3.1168003, -8.545011 ]], dtype=float32)
time = 14045	action = 0	current_phase = 0	next_phase = 1	reward = 0.449043	array([[ 3.1254106, -8.490824 ]], dtype=float32)
time = 14050	action = 0	current_phase = 0	next_phase = 1	reward = 0.724087	array([[ 3.1371903, -8.477217 ]], dtype=float32)
time = 14055	action = 0	current_phase = 0	next_phase = 1	reward = 1.012198	array([[ 3.0967612, -8.483841 ]], dtype=float32)
time = 14060	action = 0	current_phase = 0	next_phase = 1	reward = 0.725416	array([[ 3.1821404, -8.437852 ]], dtype=float32)
time = 14065	action = 0	current_phase = 0	next_phase = 1	reward = 0.724722	array([[ 3.0870433, -8.537548 ]], dtype=float32)
time = 14070	action = 0	current_phase = 0	next_phase = 1	reward = 0.714814	array([[ 3.0776334, -8.51873  ]], dtype=float32)
time = 14075	action = 0	current_phase = 0	next_phase = 1	reward = 0.715210	array([[ 3.1714225, -8.513193 ]], dtype=float32)
time = 14080	action = 0	current_phase = 0	next_phase = 1	reward = 0.163192	array([[ 3.1358967, -8.524774 ]], dtype=float32)
time = 14085	action = 0	current_phase = 0	next_phase = 1	reward = 1.284165	array([[ 2.8585305, -8.903034 ]], dtype=float32)
time = 14090	action = 0	current_phase = 0	next_phase = 1	reward = 0.722360	array([[ 3.10009 , -8.481354]], dtype=float32)
time = 14095	action = 0	current_phase = 0	next_phase = 1	reward = 0.719253	array([[ 2.9728165, -8.577424 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.1466 - val_loss: 2.1409
Epoch 2/50
 - 4s - loss: 5.1903 - val_loss: 2.1344
Epoch 3/50
 - 4s - loss: 4.7751 - val_loss: 2.2973
Epoch 4/50
 - 4s - loss: 5.2332 - val_loss: 2.0997
Epoch 5/50
 - 4s - loss: 5.6491 - val_loss: 2.0241
Epoch 6/50
 - 4s - loss: 5.7707 - val_loss: 1.7935
Epoch 7/50
 - 4s - loss: 4.7971 - val_loss: 1.8772
Epoch 8/50
 - 4s - loss: 4.4497 - val_loss: 2.1301
Epoch 9/50
 - 4s - loss: 5.0200 - val_loss: 2.8131
Epoch 10/50
 - 4s - loss: 5.0673 - val_loss: 3.0618
Epoch 11/50
 - 4s - loss: 3.9431 - val_loss: 2.3262
Epoch 12/50
 - 4s - loss: 4.3950 - val_loss: 2.3825
Epoch 13/50
 - 4s - loss: 4.2041 - val_loss: 2.1464
Epoch 14/50
 - 4s - loss: 4.9887 - val_loss: 2.0787
Epoch 15/50
 - 4s - loss: 4.8398 - val_loss: 2.1887
Epoch 16/50
 - 4s - loss: 4.4542 - val_loss: 2.0344
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 14100	action = 0	current_phase = 0	next_phase = 1	reward = 0.437758	array([[ 3.034041, -8.623256]], dtype=float32)
time = 14105	action = 0	current_phase = 0	next_phase = 1	reward = 0.999897	array([[ 3.1419563, -8.531639 ]], dtype=float32)
time = 14110	action = 0	current_phase = 0	next_phase = 1	reward = 0.449753	array([[ 3.1224842, -8.552409 ]], dtype=float32)
time = 14115	action = 0	current_phase = 0	next_phase = 1	reward = 1.008957	array([[ 3.099112 , -8.5789385]], dtype=float32)
time = 14120	action = 0	current_phase = 0	next_phase = 1	reward = 0.441908	array([[ 3.1483512, -8.5548   ]], dtype=float32)
time = 14125	action = 0	current_phase = 0	next_phase = 1	reward = 1.002916	array([[ 3.0709891, -8.562561 ]], dtype=float32)
time = 14130	action = 0	current_phase = 0	next_phase = 1	reward = 0.718433	array([[ 3.047554, -8.589159]], dtype=float32)
time = 14135	action = 0	current_phase = 0	next_phase = 1	reward = 0.437907	array([[ 3.1859808, -8.498127 ]], dtype=float32)
time = 14140	action = 0	current_phase = 0	next_phase = 1	reward = 0.998952	array([[ 3.1436858, -8.520388 ]], dtype=float32)
time = 14145	action = 0	current_phase = 0	next_phase = 1	reward = 0.444929	array([[ 3.1393366, -8.529169 ]], dtype=float32)
time = 14150	action = 0	current_phase = 0	next_phase = 1	reward = 1.001729	array([[ 3.147715, -8.52655 ]], dtype=float32)
time = 14155	action = 0	current_phase = 0	next_phase = 1	reward = 0.444191	array([[ 3.1406817, -8.530619 ]], dtype=float32)
time = 14160	action = 0	current_phase = 0	next_phase = 1	reward = 1.012583	array([[ 3.1365805, -8.5580015]], dtype=float32)
time = 14165	action = 0	current_phase = 0	next_phase = 1	reward = 0.724358	array([[ 3.136588, -8.563116]], dtype=float32)
time = 14170	action = 0	current_phase = 0	next_phase = 1	reward = 0.717829	array([[ 3.1496592, -8.529219 ]], dtype=float32)
time = 14175	action = 0	current_phase = 0	next_phase = 1	reward = 0.722541	array([[ 3.1920123, -8.518659 ]], dtype=float32)
time = 14180	action = 0	current_phase = 0	next_phase = 1	reward = 0.721648	array([[ 3.125733, -8.538443]], dtype=float32)
time = 14185	action = 0	current_phase = 0	next_phase = 1	reward = 0.714765	array([[ 3.120788, -8.568218]], dtype=float32)
time = 14190	action = 0	current_phase = 0	next_phase = 1	reward = 0.722214	array([[ 3.180304, -8.490236]], dtype=float32)
time = 14195	action = 0	current_phase = 0	next_phase = 1	reward = 0.454000	array([[ 3.1552877, -8.501619 ]], dtype=float32)
time = 14200	action = 0	current_phase = 0	next_phase = 1	reward = 1.007638	array([[ 3.2234688, -8.630865 ]], dtype=float32)
time = 14205	action = 0	current_phase = 0	next_phase = 1	reward = 0.447471	array([[ 3.1810746, -8.530779 ]], dtype=float32)
time = 14210	action = 0	current_phase = 0	next_phase = 1	reward = 1.006513	array([[ 2.9938188, -8.7048855]], dtype=float32)
time = 14215	action = 0	current_phase = 0	next_phase = 1	reward = 0.722260	array([[ 3.2037678, -8.514841 ]], dtype=float32)
time = 14220	action = 0	current_phase = 0	next_phase = 1	reward = 0.718706	array([[ 3.094132, -8.586253]], dtype=float32)
time = 14225	action = 0	current_phase = 0	next_phase = 1	reward = 0.718896	array([[ 3.1710052, -8.547736 ]], dtype=float32)
time = 14230	action = 0	current_phase = 0	next_phase = 1	reward = 0.722154	array([[ 3.1480203, -8.549654 ]], dtype=float32)
time = 14235	action = 0	current_phase = 0	next_phase = 1	reward = 0.439811	array([[ 3.1379313, -8.559444 ]], dtype=float32)
time = 14240	action = 0	current_phase = 0	next_phase = 1	reward = 0.723604	array([[ 3.1142979, -8.584234 ]], dtype=float32)
time = 14245	action = 0	current_phase = 0	next_phase = 1	reward = 1.007579	array([[ 3.0770578, -8.57749  ]], dtype=float32)
time = 14250	action = 0	current_phase = 0	next_phase = 1	reward = 0.721196	array([[ 3.144567, -8.515469]], dtype=float32)
time = 14255	action = 0	current_phase = 0	next_phase = 1	reward = 0.450471	array([[ 3.0722394, -8.622746 ]], dtype=float32)
time = 14260	action = 0	current_phase = 0	next_phase = 1	reward = 1.003929	array([[ 3.16225 , -8.588159]], dtype=float32)
time = 14265	action = 0	current_phase = 0	next_phase = 1	reward = 0.719226	array([[ 3.099185, -8.54935 ]], dtype=float32)
time = 14270	action = 0	current_phase = 0	next_phase = 1	reward = 0.719099	array([[ 3.0696158, -8.558117 ]], dtype=float32)
time = 14275	action = 0	current_phase = 0	next_phase = 1	reward = 0.441825	array([[ 3.1334963, -8.553781 ]], dtype=float32)
time = 14280	action = 0	current_phase = 0	next_phase = 1	reward = 1.002426	array([[ 3.0753694, -8.591753 ]], dtype=float32)
time = 14285	action = 0	current_phase = 0	next_phase = 1	reward = 0.719912	array([[ 3.1209598, -8.539181 ]], dtype=float32)
time = 14290	action = 0	current_phase = 0	next_phase = 1	reward = 0.725819	array([[ 3.1436253, -8.517111 ]], dtype=float32)
time = 14295	action = 0	current_phase = 0	next_phase = 1	reward = 0.444259	array([[ 3.184195, -8.495682]], dtype=float32)
time = 14300	action = 0	current_phase = 0	next_phase = 1	reward = 1.007922	array([[ 3.090979, -8.623208]], dtype=float32)
time = 14305	action = 0	current_phase = 0	next_phase = 1	reward = 0.723447	array([[ 3.1487808, -8.51425  ]], dtype=float32)
time = 14310	action = 0	current_phase = 0	next_phase = 1	reward = 0.722258	array([[ 3.150803, -8.554412]], dtype=float32)
time = 14315	action = 0	current_phase = 0	next_phase = 1	reward = 0.714110	array([[ 3.1781044, -8.505529 ]], dtype=float32)
time = 14320	action = 0	current_phase = 0	next_phase = 1	reward = 0.441959	array([[ 3.057837, -8.616123]], dtype=float32)
time = 14325	action = 0	current_phase = 0	next_phase = 1	reward = 0.720148	array([[ 3.1020703, -8.557038 ]], dtype=float32)
time = 14330	action = 0	current_phase = 0	next_phase = 1	reward = 0.725490	array([[ 3.0705805, -8.6336975]], dtype=float32)
time = 14335	action = 0	current_phase = 0	next_phase = 1	reward = 0.998502	array([[ 3.2005024, -8.541897 ]], dtype=float32)
time = 14340	action = 0	current_phase = 0	next_phase = 1	reward = 0.449767	array([[ 3.112669, -8.569726]], dtype=float32)
time = 14345	action = 0	current_phase = 0	next_phase = 1	reward = 0.726802	array([[ 3.1230822, -8.533045 ]], dtype=float32)
time = 14350	action = 0	current_phase = 0	next_phase = 1	reward = 1.005553	array([[ 3.1700025, -8.552072 ]], dtype=float32)
time = 14355	action = 0	current_phase = 0	next_phase = 1	reward = 0.722044	array([[ 2.848907, -8.729299]], dtype=float32)
time = 14360	action = 0	current_phase = 0	next_phase = 1	reward = 0.443601	array([[ 3.0909986, -8.552839 ]], dtype=float32)
time = 14365	action = 0	current_phase = 0	next_phase = 1	reward = 1.013158	array([[ 3.1190896, -8.534434 ]], dtype=float32)
time = 14370	action = 0	current_phase = 0	next_phase = 1	reward = 0.710761	array([[ 3.1745653, -8.501053 ]], dtype=float32)
time = 14375	action = 0	current_phase = 0	next_phase = 1	reward = 0.715604	array([[ 3.1658173, -8.509512 ]], dtype=float32)
time = 14380	action = 0	current_phase = 0	next_phase = 1	reward = 0.442017	array([[ 3.1234527, -8.532595 ]], dtype=float32)
time = 14385	action = 0	current_phase = 0	next_phase = 1	reward = 1.007008	array([[ 3.0390406, -8.612764 ]], dtype=float32)
time = 14390	action = 0	current_phase = 0	next_phase = 1	reward = 0.729030	array([[ 3.1888447, -8.509924 ]], dtype=float32)
time = 14395	action = 0	current_phase = 0	next_phase = 1	reward = 0.719255	array([[ 3.135756, -8.533548]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.1196 - val_loss: 3.2044
Epoch 2/50
 - 4s - loss: 4.5361 - val_loss: 3.9262
Epoch 3/50
 - 4s - loss: 4.3345 - val_loss: 3.6500
Epoch 4/50
 - 4s - loss: 3.8720 - val_loss: 3.4066
Epoch 5/50
 - 4s - loss: 4.4142 - val_loss: 4.0710
Epoch 6/50
 - 4s - loss: 4.1519 - val_loss: 2.7873
Epoch 7/50
 - 4s - loss: 3.8230 - val_loss: 4.3069
Epoch 8/50
 - 4s - loss: 4.5882 - val_loss: 3.5836
Epoch 9/50
 - 4s - loss: 4.1952 - val_loss: 2.9150
Epoch 10/50
 - 4s - loss: 3.4673 - val_loss: 3.7882
Epoch 11/50
 - 4s - loss: 3.9644 - val_loss: 3.1832
Epoch 12/50
 - 4s - loss: 4.0717 - val_loss: 3.8131
Epoch 13/50
 - 4s - loss: 3.4786 - val_loss: 3.6308
Epoch 14/50
 - 4s - loss: 3.6426 - val_loss: 4.5105
Epoch 15/50
 - 4s - loss: 4.2353 - val_loss: 3.5572
Epoch 16/50
 - 4s - loss: 4.2143 - val_loss: 4.0464
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 14400	action = 0	current_phase = 0	next_phase = 1	reward = 0.724023	array([[ 3.1082058, -8.610496 ]], dtype=float32)
time = 14405	action = 0	current_phase = 0	next_phase = 1	reward = 0.440992	array([[ 3.1605053, -8.603813 ]], dtype=float32)
time = 14410	action = 0	current_phase = 0	next_phase = 1	reward = 0.729264	array([[ 2.920824, -8.729491]], dtype=float32)
time = 14415	action = 0	current_phase = 0	next_phase = 1	reward = 1.006459	array([[ 3.143581 , -8.6565485]], dtype=float32)
time = 14420	action = 0	current_phase = 0	next_phase = 1	reward = 0.456407	array([[ 3.1080809, -8.635452 ]], dtype=float32)
time = 14425	action = 0	current_phase = 0	next_phase = 1	reward = 0.998397	array([[ 3.094286, -8.629921]], dtype=float32)
time = 14430	action = 0	current_phase = 0	next_phase = 1	reward = 0.719974	array([[ 3.1365852, -8.622147 ]], dtype=float32)
time = 14435	action = 0	current_phase = 0	next_phase = 1	reward = 0.719330	array([[ 3.142568, -8.578007]], dtype=float32)
time = 14440	action = 0	current_phase = 0	next_phase = 1	reward = 0.722977	array([[ 3.1080942, -8.638679 ]], dtype=float32)
time = 14445	action = 0	current_phase = 0	next_phase = 1	reward = 0.718368	array([[ 3.104937, -8.650199]], dtype=float32)
time = 14450	action = 0	current_phase = 0	next_phase = 1	reward = 0.713267	array([[ 3.1717439, -8.582979 ]], dtype=float32)
time = 14455	action = 0	current_phase = 0	next_phase = 1	reward = 0.440712	array([[ 3.087912, -8.611948]], dtype=float32)
time = 14460	action = 0	current_phase = 0	next_phase = 1	reward = 0.732492	array([[ 3.1041799, -8.648331 ]], dtype=float32)
time = 14465	action = 0	current_phase = 0	next_phase = 1	reward = 0.733492	array([[ 3.108004, -8.754032]], dtype=float32)
time = 14470	action = 0	current_phase = 0	next_phase = 1	reward = 1.002659	array([[ 3.147163, -8.574152]], dtype=float32)
time = 14475	action = 0	current_phase = 0	next_phase = 1	reward = 0.721699	array([[ 3.2011604, -8.587988 ]], dtype=float32)
time = 14480	action = 0	current_phase = 0	next_phase = 1	reward = 0.174143	array([[ 3.1217246, -8.60852  ]], dtype=float32)
time = 14485	action = 0	current_phase = 0	next_phase = 1	reward = 1.008234	array([[ 2.8476782, -9.125028 ]], dtype=float32)
time = 14490	action = 0	current_phase = 0	next_phase = 1	reward = 1.004043	array([[ 3.134635, -8.590112]], dtype=float32)
time = 14495	action = 0	current_phase = 0	next_phase = 1	reward = 0.720778	array([[ 3.1990986, -8.574731 ]], dtype=float32)
time = 14500	action = 0	current_phase = 0	next_phase = 1	reward = 0.444821	array([[ 3.1189504, -8.612951 ]], dtype=float32)
time = 14505	action = 0	current_phase = 0	next_phase = 1	reward = 1.007944	array([[ 3.12184 , -8.618533]], dtype=float32)
time = 14510	action = 0	current_phase = 0	next_phase = 1	reward = 0.430015	array([[ 3.1515846, -8.560055 ]], dtype=float32)
time = 14515	action = 0	current_phase = 0	next_phase = 1	reward = 0.725652	array([[ 3.1281896, -8.60125  ]], dtype=float32)
time = 14520	action = 0	current_phase = 0	next_phase = 1	reward = 0.729196	array([[ 3.0997028, -8.69605  ]], dtype=float32)
time = 14525	action = 0	current_phase = 0	next_phase = 1	reward = 1.010914	array([[ 3.1758137, -8.585044 ]], dtype=float32)
time = 14530	action = 0	current_phase = 0	next_phase = 1	reward = 0.724301	array([[ 3.0378876, -8.707173 ]], dtype=float32)
time = 14535	action = 0	current_phase = 0	next_phase = 1	reward = 0.721165	array([[ 3.179295, -8.577995]], dtype=float32)
time = 14540	action = 0	current_phase = 0	next_phase = 1	reward = 0.704762	array([[ 3.1812334, -8.607319 ]], dtype=float32)
time = 14545	action = 0	current_phase = 0	next_phase = 1	reward = 0.442326	array([[ 3.0922189, -8.653869 ]], dtype=float32)
time = 14550	action = 0	current_phase = 0	next_phase = 1	reward = 0.740571	array([[ 3.1169696, -8.675947 ]], dtype=float32)
time = 14555	action = 0	current_phase = 0	next_phase = 1	reward = 1.002074	array([[ 3.0880976, -8.634231 ]], dtype=float32)
time = 14560	action = 0	current_phase = 0	next_phase = 1	reward = 0.722328	array([[ 2.9190469, -8.816096 ]], dtype=float32)
time = 14565	action = 0	current_phase = 0	next_phase = 1	reward = 0.721534	array([[ 3.1683474, -8.568285 ]], dtype=float32)
time = 14570	action = 0	current_phase = 0	next_phase = 1	reward = 0.723784	array([[ 3.1457596, -8.582112 ]], dtype=float32)
time = 14575	action = 0	current_phase = 0	next_phase = 1	reward = 0.729540	array([[ 3.1260896, -8.659878 ]], dtype=float32)
time = 14580	action = 0	current_phase = 0	next_phase = 1	reward = 0.720096	array([[ 3.1902256, -8.60865  ]], dtype=float32)
time = 14585	action = 0	current_phase = 0	next_phase = 1	reward = 0.728889	array([[ 3.147468, -8.598985]], dtype=float32)
time = 14590	action = 0	current_phase = 0	next_phase = 1	reward = 0.720855	array([[ 3.1664743, -8.563624 ]], dtype=float32)
time = 14595	action = 0	current_phase = 0	next_phase = 1	reward = 0.715209	array([[ 3.110722 , -8.6262455]], dtype=float32)
time = 14600	action = 0	current_phase = 0	next_phase = 1	reward = 0.726122	array([[ 3.1367326, -8.596894 ]], dtype=float32)
time = 14605	action = 0	current_phase = 0	next_phase = 1	reward = 0.716688	array([[ 3.1263986, -8.644736 ]], dtype=float32)
time = 14610	action = 0	current_phase = 0	next_phase = 1	reward = 0.437724	array([[ 3.1473489, -8.580269 ]], dtype=float32)
time = 14615	action = 0	current_phase = 0	next_phase = 1	reward = 0.998867	array([[ 3.1708221, -8.628048 ]], dtype=float32)
time = 14620	action = 0	current_phase = 0	next_phase = 1	reward = 0.726779	array([[ 3.118198, -8.608067]], dtype=float32)
time = 14625	action = 0	current_phase = 0	next_phase = 1	reward = 0.720961	array([[ 3.1201148, -8.63849  ]], dtype=float32)
time = 14630	action = 0	current_phase = 0	next_phase = 1	reward = 0.719900	array([[ 3.1108513, -8.620844 ]], dtype=float32)
time = 14635	action = 0	current_phase = 0	next_phase = 1	reward = 0.718572	array([[ 3.1387296, -8.600828 ]], dtype=float32)
time = 14640	action = 0	current_phase = 0	next_phase = 1	reward = 0.721862	array([[ 3.03546, -8.74503]], dtype=float32)
time = 14645	action = 0	current_phase = 0	next_phase = 1	reward = 0.448636	array([[ 3.1461906, -8.630926 ]], dtype=float32)
time = 14650	action = 0	current_phase = 0	next_phase = 1	reward = 1.013290	array([[ 3.1318302, -8.687784 ]], dtype=float32)
time = 14655	action = 0	current_phase = 0	next_phase = 1	reward = 0.721417	array([[ 3.211979, -8.558304]], dtype=float32)
time = 14660	action = 0	current_phase = 0	next_phase = 1	reward = 0.719830	array([[ 3.160842, -8.583313]], dtype=float32)
time = 14665	action = 0	current_phase = 0	next_phase = 1	reward = 0.712171	array([[ 3.082883, -8.698002]], dtype=float32)
time = 14670	action = 0	current_phase = 0	next_phase = 1	reward = 0.440258	array([[ 3.1574116, -8.596427 ]], dtype=float32)
time = 14675	action = 0	current_phase = 0	next_phase = 1	reward = 1.004855	array([[ 3.073987, -8.686712]], dtype=float32)
time = 14680	action = 0	current_phase = 0	next_phase = 1	reward = 0.726262	array([[ 3.1486087, -8.586114 ]], dtype=float32)
time = 14685	action = 0	current_phase = 0	next_phase = 1	reward = 0.719364	array([[ 3.132989, -8.586344]], dtype=float32)
time = 14690	action = 0	current_phase = 0	next_phase = 1	reward = 0.441530	array([[ 3.122664, -8.645795]], dtype=float32)
time = 14695	action = 0	current_phase = 0	next_phase = 1	reward = 1.004909	array([[ 3.1297631, -8.601896 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.5108 - val_loss: 2.5283
Epoch 2/50
 - 4s - loss: 4.6483 - val_loss: 2.7192
Epoch 3/50
 - 4s - loss: 4.2056 - val_loss: 4.8517
Epoch 4/50
 - 4s - loss: 4.8413 - val_loss: 2.3356
Epoch 5/50
 - 4s - loss: 3.6458 - val_loss: 3.5122
Epoch 6/50
 - 4s - loss: 3.9650 - val_loss: 2.8445
Epoch 7/50
 - 4s - loss: 4.6200 - val_loss: 2.3680
Epoch 8/50
 - 4s - loss: 3.9131 - val_loss: 2.9968
Epoch 9/50
 - 4s - loss: 3.3692 - val_loss: 2.6806
Epoch 10/50
 - 4s - loss: 4.0295 - val_loss: 2.9213
Epoch 11/50
 - 5s - loss: 3.2980 - val_loss: 2.5951
Epoch 12/50
 - 4s - loss: 3.7782 - val_loss: 2.8506
Epoch 13/50
 - 4s - loss: 3.5038 - val_loss: 2.8167
Epoch 14/50
 - 4s - loss: 4.0020 - val_loss: 3.3250
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 14700	action = 0	current_phase = 0	next_phase = 1	reward = 0.443457	array([[ 3.2071166, -8.626561 ]], dtype=float32)
time = 14705	action = 0	current_phase = 0	next_phase = 1	reward = 1.007517	array([[ 2.8524966, -9.070059 ]], dtype=float32)
time = 14710	action = 0	current_phase = 0	next_phase = 1	reward = 0.446476	array([[ 3.200108, -8.622746]], dtype=float32)
time = 14715	action = 0	current_phase = 0	next_phase = 1	reward = 1.003381	array([[ 3.051958, -8.733019]], dtype=float32)
time = 14720	action = 0	current_phase = 0	next_phase = 1	reward = 0.720066	array([[ 3.0810385, -8.691243 ]], dtype=float32)
time = 14725	action = 0	current_phase = 0	next_phase = 1	reward = 0.445219	array([[ 3.1451788, -8.619465 ]], dtype=float32)
time = 14730	action = 0	current_phase = 0	next_phase = 1	reward = 1.000158	array([[ 3.1380024, -8.729812 ]], dtype=float32)
time = 14735	action = 0	current_phase = 0	next_phase = 1	reward = 0.167681	array([[ 3.1381555, -8.639602 ]], dtype=float32)
time = 14740	action = 0	current_phase = 0	next_phase = 1	reward = 1.016762	array([[ 3.0459065, -8.68041  ]], dtype=float32)
time = 14745	action = 0	current_phase = 0	next_phase = 1	reward = 0.728638	array([[ 3.1069527, -8.69973  ]], dtype=float32)
time = 14750	action = 0	current_phase = 0	next_phase = 1	reward = 0.733656	array([[ 3.0347657, -8.731734 ]], dtype=float32)
time = 14755	action = 0	current_phase = 0	next_phase = 1	reward = 0.729345	array([[ 3.1751676, -8.648254 ]], dtype=float32)
time = 14760	action = 0	current_phase = 0	next_phase = 1	reward = 1.004309	array([[ 3.190772, -8.706718]], dtype=float32)
time = 14765	action = 0	current_phase = 0	next_phase = 1	reward = 0.723071	array([[ 3.1457357, -8.621763 ]], dtype=float32)
time = 14770	action = 0	current_phase = 0	next_phase = 1	reward = 0.724667	array([[ 3.2360806, -8.668088 ]], dtype=float32)
time = 14775	action = 0	current_phase = 0	next_phase = 1	reward = 0.725143	array([[ 3.1186156, -8.680071 ]], dtype=float32)
time = 14780	action = 0	current_phase = 0	next_phase = 1	reward = 0.434506	array([[ 3.1489835, -8.599871 ]], dtype=float32)
time = 14785	action = 0	current_phase = 0	next_phase = 1	reward = 0.731465	array([[ 3.1525965, -8.665992 ]], dtype=float32)
time = 14790	action = 0	current_phase = 0	next_phase = 1	reward = 1.003674	array([[ 3.0905356, -8.722677 ]], dtype=float32)
time = 14795	action = 0	current_phase = 0	next_phase = 1	reward = 0.725079	array([[ 3.124227, -8.675497]], dtype=float32)
time = 14800	action = 0	current_phase = 0	next_phase = 1	reward = 0.452352	array([[ 3.1066074, -8.665263 ]], dtype=float32)
time = 14805	action = 0	current_phase = 0	next_phase = 1	reward = 1.008464	array([[ 3.1385417, -8.640493 ]], dtype=float32)
time = 14810	action = 0	current_phase = 0	next_phase = 1	reward = 0.721703	array([[ 3.1643057, -8.593301 ]], dtype=float32)
time = 14815	action = 0	current_phase = 0	next_phase = 1	reward = 0.713240	array([[ 3.1690278, -8.590549 ]], dtype=float32)
time = 14820	action = 0	current_phase = 0	next_phase = 1	reward = 0.437284	array([[ 3.1173372, -8.667892 ]], dtype=float32)
time = 14825	action = 0	current_phase = 0	next_phase = 1	reward = 0.724824	array([[ 3.1639824, -8.627916 ]], dtype=float32)
time = 14830	action = 0	current_phase = 0	next_phase = 1	reward = 1.005483	array([[ 2.9989572, -8.802202 ]], dtype=float32)
time = 14835	action = 0	current_phase = 0	next_phase = 1	reward = 0.447036	array([[ 3.0905433, -8.796988 ]], dtype=float32)
time = 14840	action = 0	current_phase = 0	next_phase = 1	reward = 1.003265	array([[ 3.1837473, -8.58539  ]], dtype=float32)
time = 14845	action = 0	current_phase = 0	next_phase = 1	reward = 0.437482	array([[ 3.137073, -8.624874]], dtype=float32)
time = 14850	action = 0	current_phase = 0	next_phase = 1	reward = 0.439355	array([[ 3.1471882, -8.631308 ]], dtype=float32)
time = 14855	action = 0	current_phase = 0	next_phase = 1	reward = 1.293995	array([[ 2.9921389, -8.817877 ]], dtype=float32)
time = 14860	action = 0	current_phase = 0	next_phase = 1	reward = 0.449537	array([[ 3.184341, -8.64795 ]], dtype=float32)
time = 14865	action = 0	current_phase = 0	next_phase = 1	reward = 0.714706	array([[ 3.1122618, -8.680696 ]], dtype=float32)
time = 14870	action = 0	current_phase = 0	next_phase = 1	reward = 0.728206	array([[ 2.8864212, -8.852563 ]], dtype=float32)
time = 14875	action = 0	current_phase = 0	next_phase = 1	reward = 1.009241	array([[ 3.1448808, -8.691326 ]], dtype=float32)
time = 14880	action = 0	current_phase = 0	next_phase = 1	reward = 0.718234	array([[ 3.0951915, -8.653994 ]], dtype=float32)
time = 14885	action = 0	current_phase = 0	next_phase = 1	reward = 0.439687	array([[ 3.190651, -8.634584]], dtype=float32)
time = 14890	action = 0	current_phase = 0	next_phase = 1	reward = 1.004524	array([[ 3.155373, -8.703037]], dtype=float32)
time = 14895	action = 0	current_phase = 0	next_phase = 1	reward = 0.445549	array([[ 3.1745744, -8.6480255]], dtype=float32)
time = 14900	action = 0	current_phase = 0	next_phase = 1	reward = 1.005829	array([[ 3.0590067, -8.715616 ]], dtype=float32)
time = 14905	action = 0	current_phase = 0	next_phase = 1	reward = 0.723715	array([[ 3.202578, -8.635532]], dtype=float32)
time = 14910	action = 0	current_phase = 0	next_phase = 1	reward = 0.716122	array([[ 3.1144333, -8.6616335]], dtype=float32)
time = 14915	action = 0	current_phase = 0	next_phase = 1	reward = 0.712526	array([[ 3.169713, -8.622978]], dtype=float32)
time = 14920	action = 0	current_phase = 0	next_phase = 1	reward = 0.444543	array([[ 3.1056747, -8.64471  ]], dtype=float32)
time = 14925	action = 0	current_phase = 0	next_phase = 1	reward = 0.726515	array([[ 3.1442184, -8.622687 ]], dtype=float32)
time = 14930	action = 0	current_phase = 0	next_phase = 1	reward = 1.012313	array([[ 3.0130959, -8.7683525]], dtype=float32)
time = 14935	action = 0	current_phase = 0	next_phase = 1	reward = 0.717716	array([[ 3.1676712, -8.606109 ]], dtype=float32)
time = 14940	action = 0	current_phase = 0	next_phase = 1	reward = 0.709886	array([[ 3.129188, -8.702995]], dtype=float32)
time = 14945	action = 0	current_phase = 0	next_phase = 1	reward = 0.437138	array([[ 3.1876426, -8.65409  ]], dtype=float32)
time = 14950	action = 0	current_phase = 0	next_phase = 1	reward = 0.726764	array([[ 3.099018, -8.675298]], dtype=float32)
time = 14955	action = 0	current_phase = 0	next_phase = 1	reward = 1.001905	array([[ 3.0422487, -8.766872 ]], dtype=float32)
time = 14960	action = 0	current_phase = 0	next_phase = 1	reward = 0.720437	array([[ 3.0874166, -8.693626 ]], dtype=float32)
time = 14965	action = 0	current_phase = 0	next_phase = 1	reward = 0.727752	array([[ 3.035366, -8.697874]], dtype=float32)
time = 14970	action = 0	current_phase = 0	next_phase = 1	reward = 0.719936	array([[ 3.1828923, -8.613626 ]], dtype=float32)
time = 14975	action = 0	current_phase = 0	next_phase = 1	reward = 0.711223	array([[ 3.2252412, -8.602834 ]], dtype=float32)
time = 14980	action = 0	current_phase = 0	next_phase = 1	reward = 0.448896	array([[ 3.13793  , -8.6758585]], dtype=float32)
time = 14985	action = 0	current_phase = 0	next_phase = 1	reward = 0.729078	array([[ 3.176733, -8.728807]], dtype=float32)
time = 14990	action = 0	current_phase = 0	next_phase = 1	reward = 1.011601	array([[ 3.0245051, -8.729481 ]], dtype=float32)
time = 14995	action = 0	current_phase = 0	next_phase = 1	reward = 0.716427	array([[ 3.2307744, -8.607495 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 3s - loss: 4.9445 - val_loss: 1.6409
Epoch 2/50
 - 4s - loss: 4.1542 - val_loss: 1.5896
Epoch 3/50
 - 4s - loss: 3.9191 - val_loss: 1.7747
Epoch 4/50
 - 4s - loss: 4.2944 - val_loss: 1.5417
Epoch 5/50
 - 4s - loss: 3.6544 - val_loss: 1.4503
Epoch 6/50
 - 4s - loss: 4.2825 - val_loss: 1.5539
Epoch 7/50
 - 4s - loss: 4.9318 - val_loss: 1.7778
Epoch 8/50
 - 4s - loss: 3.7692 - val_loss: 1.5854
Epoch 9/50
 - 4s - loss: 4.4966 - val_loss: 1.6471
Epoch 10/50
 - 4s - loss: 4.4805 - val_loss: 1.4938
Epoch 11/50
 - 4s - loss: 4.4083 - val_loss: 1.4439
Epoch 12/50
 - 4s - loss: 4.0388 - val_loss: 1.7788
Epoch 13/50
 - 4s - loss: 3.3103 - val_loss: 1.7472
Epoch 14/50
 - 4s - loss: 4.0898 - val_loss: 1.5513
Epoch 15/50
 - 4s - loss: 3.7616 - val_loss: 1.8902
Epoch 16/50
 - 4s - loss: 4.5416 - val_loss: 2.4370
Epoch 17/50
 - 4s - loss: 4.0085 - val_loss: 1.6557
Epoch 18/50
 - 4s - loss: 3.9210 - val_loss: 1.8666
Epoch 19/50
 - 4s - loss: 3.4848 - val_loss: 1.6558
Epoch 20/50
 - 4s - loss: 3.7023 - val_loss: 1.7208
Epoch 21/50
 - 4s - loss: 3.9936 - val_loss: 2.0298
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 15000	action = 0	current_phase = 0	next_phase = 1	reward = 0.720103	array([[ 3.1336684, -8.699703 ]], dtype=float32)
time = 15005	action = 0	current_phase = 0	next_phase = 1	reward = 0.716457	array([[ 3.249423, -8.688019]], dtype=float32)
time = 15010	action = 0	current_phase = 0	next_phase = 1	reward = 0.720946	array([[ 3.0984068, -8.697009 ]], dtype=float32)
time = 15015	action = 0	current_phase = 0	next_phase = 1	reward = 0.446336	array([[ 3.2188191, -8.664858 ]], dtype=float32)
time = 15020	action = 0	current_phase = 0	next_phase = 1	reward = 1.003621	array([[ 3.1048841, -8.685917 ]], dtype=float32)
time = 15025	action = 0	current_phase = 0	next_phase = 1	reward = 0.725538	array([[ 3.1629448, -8.681584 ]], dtype=float32)
time = 15030	action = 0	current_phase = 0	next_phase = 1	reward = 0.723150	array([[ 3.0715194, -8.707517 ]], dtype=float32)
time = 15035	action = 0	current_phase = 0	next_phase = 1	reward = 0.723958	array([[ 3.1093664, -8.718444 ]], dtype=float32)
time = 15040	action = 0	current_phase = 0	next_phase = 1	reward = 0.715608	array([[ 3.1812544, -8.658034 ]], dtype=float32)
time = 15045	action = 0	current_phase = 0	next_phase = 1	reward = 0.162641	array([[ 3.1999202, -8.656442 ]], dtype=float32)
time = 15050	action = 0	current_phase = 0	next_phase = 1	reward = 1.292372	array([[ 3.0743976, -8.7227125]], dtype=float32)
time = 15055	action = 0	current_phase = 0	next_phase = 1	reward = 0.446513	array([[ 3.063354, -8.847626]], dtype=float32)
time = 15060	action = 0	current_phase = 0	next_phase = 1	reward = 0.729966	array([[ 3.131206 , -8.6832075]], dtype=float32)
time = 15065	action = 0	current_phase = 0	next_phase = 1	reward = 1.005433	array([[ 2.9668727, -8.895551 ]], dtype=float32)
time = 15070	action = 0	current_phase = 0	next_phase = 1	reward = 0.717469	array([[ 3.1321945, -8.6624365]], dtype=float32)
time = 15075	action = 0	current_phase = 0	next_phase = 1	reward = 0.723461	array([[ 3.0548344, -8.726014 ]], dtype=float32)
time = 15080	action = 0	current_phase = 0	next_phase = 1	reward = 0.719737	array([[ 3.0646243, -8.760428 ]], dtype=float32)
time = 15085	action = 0	current_phase = 0	next_phase = 1	reward = 0.719542	array([[ 3.0877633, -8.681337 ]], dtype=float32)
time = 15090	action = 0	current_phase = 0	next_phase = 1	reward = 0.443136	array([[ 3.0778022, -8.709856 ]], dtype=float32)
time = 15095	action = 0	current_phase = 0	next_phase = 1	reward = 0.727474	array([[ 3.139378, -8.855961]], dtype=float32)
time = 15100	action = 0	current_phase = 0	next_phase = 1	reward = 1.005810	array([[ 3.0237331, -8.75867  ]], dtype=float32)
time = 15105	action = 0	current_phase = 0	next_phase = 1	reward = 0.721909	array([[ 3.124878, -8.665662]], dtype=float32)
time = 15110	action = 0	current_phase = 0	next_phase = 1	reward = 0.444110	array([[ 3.1560345, -8.724602 ]], dtype=float32)
time = 15115	action = 0	current_phase = 0	next_phase = 1	reward = 0.731010	array([[ 3.1879659, -8.6808195]], dtype=float32)
time = 15120	action = 0	current_phase = 0	next_phase = 1	reward = 1.000990	array([[ 3.0129623, -8.848118 ]], dtype=float32)
time = 15125	action = 0	current_phase = 0	next_phase = 1	reward = 0.441008	array([[ 3.041523, -8.780686]], dtype=float32)
time = 15130	action = 0	current_phase = 0	next_phase = 1	reward = 0.999252	array([[ 3.0767589, -8.721601 ]], dtype=float32)
time = 15135	action = 0	current_phase = 0	next_phase = 1	reward = 0.719617	array([[ 3.1669908, -8.671011 ]], dtype=float32)
time = 15140	action = 0	current_phase = 0	next_phase = 1	reward = 0.725714	array([[ 2.984068, -8.799448]], dtype=float32)
time = 15145	action = 0	current_phase = 0	next_phase = 1	reward = 0.441878	array([[ 3.1480875, -8.748831 ]], dtype=float32)
time = 15150	action = 0	current_phase = 0	next_phase = 1	reward = 1.002678	array([[ 2.8814335, -9.021399 ]], dtype=float32)
time = 15155	action = 0	current_phase = 0	next_phase = 1	reward = 0.719950	array([[ 2.7300572, -8.948149 ]], dtype=float32)
time = 15160	action = 0	current_phase = 0	next_phase = 1	reward = 0.723698	array([[ 3.1329808, -8.682827 ]], dtype=float32)
time = 15165	action = 0	current_phase = 0	next_phase = 1	reward = 0.726133	array([[ 2.9978766, -8.763737 ]], dtype=float32)
time = 15170	action = 0	current_phase = 0	next_phase = 1	reward = 0.444102	array([[ 3.1649113, -8.705873 ]], dtype=float32)
time = 15175	action = 0	current_phase = 0	next_phase = 1	reward = 0.998642	array([[ 3.0132408, -8.747235 ]], dtype=float32)
time = 15180	action = 0	current_phase = 0	next_phase = 1	reward = 0.436887	array([[ 3.1351342, -8.741602 ]], dtype=float32)
time = 15185	action = 0	current_phase = 0	next_phase = 1	reward = 1.004870	array([[ 3.1457243, -8.648108 ]], dtype=float32)
time = 15190	action = 0	current_phase = 0	next_phase = 1	reward = 0.716568	array([[ 3.023396, -8.90801 ]], dtype=float32)
time = 15195	action = 0	current_phase = 0	next_phase = 1	reward = 0.719648	array([[ 3.1356783, -8.663469 ]], dtype=float32)
time = 15200	action = 0	current_phase = 0	next_phase = 1	reward = 0.719810	array([[ 3.148572, -8.644772]], dtype=float32)
time = 15205	action = 0	current_phase = 0	next_phase = 1	reward = 0.170404	array([[ 3.0187645, -8.835734 ]], dtype=float32)
time = 15210	action = 0	current_phase = 0	next_phase = 1	reward = 1.293073	array([[ 3.12176 , -8.983341]], dtype=float32)
time = 15215	action = 0	current_phase = 0	next_phase = 1	reward = 0.722098	array([[ 3.142085, -8.679304]], dtype=float32)
time = 15220	action = 0	current_phase = 0	next_phase = 1	reward = 0.722020	array([[ 3.0743709, -8.756488 ]], dtype=float32)
time = 15225	action = 0	current_phase = 0	next_phase = 1	reward = 0.729668	array([[ 3.1808696, -8.663267 ]], dtype=float32)
time = 15230	action = 0	current_phase = 0	next_phase = 1	reward = 0.723485	array([[ 3.060689, -8.706209]], dtype=float32)
time = 15235	action = 0	current_phase = 0	next_phase = 1	reward = 0.727538	array([[ 3.103201, -8.693038]], dtype=float32)
time = 15240	action = 0	current_phase = 0	next_phase = 1	reward = 0.443579	array([[ 3.0831985, -8.761101 ]], dtype=float32)
time = 15245	action = 0	current_phase = 0	next_phase = 1	reward = 1.007414	array([[ 3.0248728, -8.791218 ]], dtype=float32)
time = 15250	action = 0	current_phase = 0	next_phase = 1	reward = 0.717473	array([[ 3.2021747, -8.69137  ]], dtype=float32)
time = 15255	action = 0	current_phase = 0	next_phase = 1	reward = 0.438010	array([[ 3.104229, -8.688473]], dtype=float32)
time = 15260	action = 0	current_phase = 0	next_phase = 1	reward = 0.727362	array([[ 2.5237794, -9.031491 ]], dtype=float32)
time = 15265	action = 0	current_phase = 0	next_phase = 1	reward = 0.725238	array([[ 2.532566, -9.112499]], dtype=float32)
time = 15270	action = 0	current_phase = 0	next_phase = 1	reward = 1.003861	array([[ 3.208373, -8.645445]], dtype=float32)
time = 15275	action = 0	current_phase = 0	next_phase = 1	reward = 0.717515	array([[ 3.1784577, -8.728454 ]], dtype=float32)
time = 15280	action = 0	current_phase = 0	next_phase = 1	reward = 0.164374	array([[ 3.1046305, -8.691513 ]], dtype=float32)
time = 15285	action = 0	current_phase = 0	next_phase = 1	reward = 1.284721	array([[ 3.0135903, -8.775689 ]], dtype=float32)
time = 15290	action = 0	current_phase = 0	next_phase = 1	reward = 0.720354	array([[ 3.1289086, -8.679542 ]], dtype=float32)
time = 15295	action = 0	current_phase = 0	next_phase = 1	reward = 0.717449	array([[ 3.1545253, -8.73411  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.9230 - val_loss: 2.3615
Epoch 2/50
 - 4s - loss: 4.5097 - val_loss: 2.0163
Epoch 3/50
 - 4s - loss: 4.2492 - val_loss: 1.9646
Epoch 4/50
 - 6s - loss: 4.2202 - val_loss: 2.0329
Epoch 5/50
 - 7s - loss: 4.4698 - val_loss: 1.8160
Epoch 6/50
 - 5s - loss: 3.9298 - val_loss: 1.6052
Epoch 7/50
 - 4s - loss: 4.3704 - val_loss: 2.0370
Epoch 8/50
 - 5s - loss: 3.8563 - val_loss: 1.8241
Epoch 9/50
 - 4s - loss: 4.2577 - val_loss: 1.8488
Epoch 10/50
 - 4s - loss: 4.0687 - val_loss: 1.7988
Epoch 11/50
 - 5s - loss: 3.5085 - val_loss: 1.7265
Epoch 12/50
 - 4s - loss: 4.1536 - val_loss: 1.9034
Epoch 13/50
 - 4s - loss: 4.1041 - val_loss: 1.8381
Epoch 14/50
 - 4s - loss: 3.8921 - val_loss: 2.2077
Epoch 15/50
 - 4s - loss: 3.7859 - val_loss: 1.9483
Epoch 16/50
 - 4s - loss: 3.7241 - val_loss: 1.6461
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 15300	action = 0	current_phase = 0	next_phase = 1	reward = 0.719247	array([[ 3.247755, -8.733303]], dtype=float32)
time = 15305	action = 0	current_phase = 0	next_phase = 1	reward = 0.726493	array([[ 3.249195, -8.728451]], dtype=float32)
time = 15310	action = 0	current_phase = 0	next_phase = 1	reward = 0.722181	array([[ 3.2263556, -8.744732 ]], dtype=float32)
time = 15315	action = 0	current_phase = 0	next_phase = 1	reward = 0.438059	array([[ 3.2357655, -8.7143955]], dtype=float32)
time = 15320	action = 0	current_phase = 0	next_phase = 1	reward = 1.002414	array([[ 3.2116795, -8.764031 ]], dtype=float32)
time = 15325	action = 0	current_phase = 0	next_phase = 1	reward = 0.435263	array([[ 3.2579713, -8.763659 ]], dtype=float32)
time = 15330	action = 0	current_phase = 0	next_phase = 1	reward = 1.001050	array([[ 3.283268, -8.771913]], dtype=float32)
time = 15335	action = 0	current_phase = 0	next_phase = 1	reward = 0.717775	array([[ 3.2198853, -8.75129  ]], dtype=float32)
time = 15340	action = 0	current_phase = 0	next_phase = 1	reward = 0.177067	array([[ 3.2597294, -8.710642 ]], dtype=float32)
time = 15345	action = 0	current_phase = 0	next_phase = 1	reward = 1.288972	array([[ 3.135262, -8.898422]], dtype=float32)
time = 15350	action = 0	current_phase = 0	next_phase = 1	reward = 0.718225	array([[ 3.2168784, -8.730794 ]], dtype=float32)
time = 15355	action = 0	current_phase = 0	next_phase = 1	reward = 0.447085	array([[ 3.3114285, -8.676593 ]], dtype=float32)
time = 15360	action = 0	current_phase = 0	next_phase = 1	reward = 0.724438	array([[ 3.1030207, -8.827831 ]], dtype=float32)
time = 15365	action = 0	current_phase = 0	next_phase = 1	reward = 0.725560	array([[ 3.1464758, -8.737127 ]], dtype=float32)
time = 15370	action = 0	current_phase = 0	next_phase = 1	reward = 1.001387	array([[ 3.139123, -8.823274]], dtype=float32)
time = 15375	action = 0	current_phase = 0	next_phase = 1	reward = 0.722645	array([[ 3.1396065, -8.814209 ]], dtype=float32)
time = 15380	action = 0	current_phase = 0	next_phase = 1	reward = 0.730319	array([[ 3.1172938, -8.839849 ]], dtype=float32)
time = 15385	action = 0	current_phase = 0	next_phase = 1	reward = 0.725539	array([[ 3.2054296, -8.7946   ]], dtype=float32)
time = 15390	action = 0	current_phase = 0	next_phase = 1	reward = 0.719860	array([[ 3.232575, -8.754354]], dtype=float32)
time = 15395	action = 0	current_phase = 0	next_phase = 1	reward = 0.443491	array([[ 3.32824 , -8.756596]], dtype=float32)
time = 15400	action = 0	current_phase = 0	next_phase = 1	reward = 0.715896	array([[ 3.2726316, -8.70273  ]], dtype=float32)
time = 15405	action = 0	current_phase = 0	next_phase = 1	reward = 0.716546	array([[ 3.2063456, -8.8051405]], dtype=float32)
time = 15410	action = 0	current_phase = 0	next_phase = 1	reward = 0.996879	array([[ 3.2135425, -8.745488 ]], dtype=float32)
time = 15415	action = 0	current_phase = 0	next_phase = 1	reward = 0.160543	array([[ 3.3369465, -8.709404 ]], dtype=float32)
time = 15420	action = 0	current_phase = 0	next_phase = 1	reward = 1.282114	array([[ 3.13481 , -8.893862]], dtype=float32)
time = 15425	action = 0	current_phase = 0	next_phase = 1	reward = 0.715475	array([[ 2.9410467, -8.847666 ]], dtype=float32)
time = 15430	action = 0	current_phase = 0	next_phase = 1	reward = 0.443448	array([[ 3.2343583, -8.742964 ]], dtype=float32)
time = 15435	action = 0	current_phase = 0	next_phase = 1	reward = 0.727036	array([[ 3.2231855, -8.785498 ]], dtype=float32)
time = 15440	action = 0	current_phase = 0	next_phase = 1	reward = 1.007913	array([[ 3.2124362, -8.787792 ]], dtype=float32)
time = 15445	action = 0	current_phase = 0	next_phase = 1	reward = 0.716691	array([[ 3.2615423, -8.728545 ]], dtype=float32)
time = 15450	action = 0	current_phase = 0	next_phase = 1	reward = 0.713322	array([[ 3.2486434, -8.762084 ]], dtype=float32)
time = 15455	action = 0	current_phase = 0	next_phase = 1	reward = 0.441846	array([[ 3.198719, -8.76956 ]], dtype=float32)
time = 15460	action = 0	current_phase = 0	next_phase = 1	reward = 1.000905	array([[ 3.1916833, -8.825935 ]], dtype=float32)
time = 15465	action = 0	current_phase = 0	next_phase = 1	reward = 0.454602	array([[ 3.2483606, -8.719919 ]], dtype=float32)
time = 15470	action = 0	current_phase = 0	next_phase = 1	reward = 1.009839	array([[ 3.2204256, -8.749022 ]], dtype=float32)
time = 15475	action = 0	current_phase = 0	next_phase = 1	reward = 0.711282	array([[ 3.247252, -8.720058]], dtype=float32)
time = 15480	action = 0	current_phase = 0	next_phase = 1	reward = 0.711093	array([[ 3.259798, -8.726337]], dtype=float32)
time = 15485	action = 0	current_phase = 0	next_phase = 1	reward = 0.160612	array([[ 3.275403, -8.685545]], dtype=float32)
time = 15490	action = 0	current_phase = 0	next_phase = 1	reward = 1.011923	array([[ 3.1087422, -8.919076 ]], dtype=float32)
time = 15495	action = 0	current_phase = 0	next_phase = 1	reward = 1.006352	array([[ 3.237732, -8.730577]], dtype=float32)
time = 15500	action = 0	current_phase = 0	next_phase = 1	reward = 0.723165	array([[ 3.2116313, -8.77985  ]], dtype=float32)
time = 15505	action = 0	current_phase = 0	next_phase = 1	reward = 0.155075	array([[ 3.2508206, -8.708355 ]], dtype=float32)
time = 15510	action = 0	current_phase = 0	next_phase = 1	reward = 1.012786	array([[ 3.082304, -8.872901]], dtype=float32)
time = 15515	action = 0	current_phase = 0	next_phase = 1	reward = 0.724984	array([[ 3.3123708, -8.712013 ]], dtype=float32)
time = 15520	action = 0	current_phase = 0	next_phase = 1	reward = 0.993490	array([[ 3.141409, -8.869862]], dtype=float32)
time = 15525	action = 0	current_phase = 0	next_phase = 1	reward = 0.725319	array([[ 3.2247953, -8.77343  ]], dtype=float32)
time = 15530	action = 0	current_phase = 0	next_phase = 1	reward = 0.726617	array([[ 3.1880922, -8.788732 ]], dtype=float32)
time = 15535	action = 0	current_phase = 0	next_phase = 1	reward = 0.721582	array([[ 3.2702193, -8.764931 ]], dtype=float32)
time = 15540	action = 0	current_phase = 0	next_phase = 1	reward = 0.728488	array([[ 3.2185497, -8.7490635]], dtype=float32)
time = 15545	action = 0	current_phase = 0	next_phase = 1	reward = 0.441590	array([[ 3.211494, -8.822845]], dtype=float32)
time = 15550	action = 0	current_phase = 0	next_phase = 1	reward = 1.000268	array([[ 3.1122093, -8.876752 ]], dtype=float32)
time = 15555	action = 0	current_phase = 0	next_phase = 1	reward = 0.716703	array([[ 3.247716, -8.713635]], dtype=float32)
time = 15560	action = 0	current_phase = 0	next_phase = 1	reward = 0.446425	array([[ 3.2124448, -8.762389 ]], dtype=float32)
time = 15565	action = 0	current_phase = 0	next_phase = 1	reward = 0.729704	array([[ 3.2164903, -8.798443 ]], dtype=float32)
time = 15570	action = 0	current_phase = 0	next_phase = 1	reward = 1.001881	array([[ 3.134719 , -8.8198185]], dtype=float32)
time = 15575	action = 0	current_phase = 0	next_phase = 1	reward = 0.445105	array([[ 3.077403, -8.820092]], dtype=float32)
time = 15580	action = 0	current_phase = 0	next_phase = 1	reward = 0.723138	array([[ 3.2591362, -8.724281 ]], dtype=float32)
time = 15585	action = 0	current_phase = 0	next_phase = 1	reward = 0.727342	array([[ 3.116497, -8.831294]], dtype=float32)
time = 15590	action = 0	current_phase = 0	next_phase = 1	reward = 1.011113	array([[ 3.2604666, -8.715754 ]], dtype=float32)
time = 15595	action = 0	current_phase = 0	next_phase = 1	reward = 0.727689	array([[ 3.242021, -8.719686]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.4358 - val_loss: 1.8704
Epoch 2/50
 - 4s - loss: 4.7846 - val_loss: 1.5314
Epoch 3/50
 - 4s - loss: 3.1957 - val_loss: 1.4525
Epoch 4/50
 - 4s - loss: 3.8561 - val_loss: 1.9208
Epoch 5/50
 - 4s - loss: 4.3781 - val_loss: 2.1732
Epoch 6/50
 - 4s - loss: 4.3511 - val_loss: 1.7816
Epoch 7/50
 - 4s - loss: 4.2258 - val_loss: 1.8386
Epoch 8/50
 - 4s - loss: 3.8054 - val_loss: 1.8659
Epoch 9/50
 - 4s - loss: 3.2706 - val_loss: 1.5860
Epoch 10/50
 - 4s - loss: 3.3638 - val_loss: 1.5378
Epoch 11/50
 - 4s - loss: 3.2170 - val_loss: 1.6540
Epoch 12/50
 - 4s - loss: 4.2947 - val_loss: 2.3327
Epoch 13/50
 - 4s - loss: 3.2516 - val_loss: 1.9380
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 15600	action = 0	current_phase = 0	next_phase = 1	reward = 0.726141	array([[ 3.1369457, -8.822907 ]], dtype=float32)
time = 15605	action = 0	current_phase = 0	next_phase = 1	reward = 0.717284	array([[ 3.1814218, -8.821328 ]], dtype=float32)
time = 15610	action = 0	current_phase = 0	next_phase = 1	reward = 0.721940	array([[ 3.1806374, -8.772346 ]], dtype=float32)
time = 15615	action = 0	current_phase = 0	next_phase = 1	reward = 0.441797	array([[ 3.1694922, -8.7660055]], dtype=float32)
time = 15620	action = 0	current_phase = 0	next_phase = 1	reward = 0.725873	array([[ 3.089623, -8.865668]], dtype=float32)
time = 15625	action = 0	current_phase = 0	next_phase = 1	reward = 1.001944	array([[ 3.2468739, -8.769577 ]], dtype=float32)
time = 15630	action = 0	current_phase = 0	next_phase = 1	reward = 0.716930	array([[ 3.1161947, -8.835671 ]], dtype=float32)
time = 15635	action = 0	current_phase = 0	next_phase = 1	reward = 0.715347	array([[ 3.1899376, -8.836516 ]], dtype=float32)
time = 15640	action = 0	current_phase = 0	next_phase = 1	reward = 0.436986	array([[ 3.0368276, -8.933024 ]], dtype=float32)
time = 15645	action = 0	current_phase = 0	next_phase = 1	reward = 1.002651	array([[ 3.0274386, -9.044576 ]], dtype=float32)
time = 15650	action = 0	current_phase = 0	next_phase = 1	reward = 0.164998	array([[ 3.0227509, -8.880735 ]], dtype=float32)
time = 15655	action = 0	current_phase = 0	next_phase = 1	reward = 1.002889	array([[ 3.0361195, -8.955076 ]], dtype=float32)
time = 15660	action = 0	current_phase = 0	next_phase = 1	reward = 0.721677	array([[ 3.0682058, -8.854652 ]], dtype=float32)
time = 15665	action = 0	current_phase = 0	next_phase = 1	reward = 0.736068	array([[ 3.2395754, -9.024065 ]], dtype=float32)
time = 15670	action = 0	current_phase = 0	next_phase = 1	reward = 0.725685	array([[ 3.1989884, -8.85506  ]], dtype=float32)
time = 15675	action = 0	current_phase = 0	next_phase = 1	reward = 1.001542	array([[ 2.9690757, -8.990819 ]], dtype=float32)
time = 15680	action = 0	current_phase = 0	next_phase = 1	reward = 0.725054	array([[ 3.1505513, -8.834059 ]], dtype=float32)
time = 15685	action = 0	current_phase = 0	next_phase = 1	reward = 0.724041	array([[ 3.0701103, -8.872993 ]], dtype=float32)
time = 15690	action = 0	current_phase = 0	next_phase = 1	reward = 0.729386	array([[ 3.1758752, -8.797607 ]], dtype=float32)
time = 15695	action = 0	current_phase = 0	next_phase = 1	reward = 0.450341	array([[ 3.2881331, -8.741256 ]], dtype=float32)
time = 15700	action = 0	current_phase = 0	next_phase = 1	reward = 1.010957	array([[ 3.0083647, -8.958393 ]], dtype=float32)
time = 15705	action = 0	current_phase = 0	next_phase = 1	reward = 0.720894	array([[ 3.131937, -8.833469]], dtype=float32)
time = 15710	action = 0	current_phase = 0	next_phase = 1	reward = 0.730412	array([[ 3.1898665, -8.752951 ]], dtype=float32)
time = 15715	action = 0	current_phase = 0	next_phase = 1	reward = 0.718852	array([[ 3.2092361, -8.787328 ]], dtype=float32)
time = 15720	action = 0	current_phase = 0	next_phase = 1	reward = 0.712815	array([[ 3.2381763, -8.7816515]], dtype=float32)
time = 15725	action = 0	current_phase = 0	next_phase = 1	reward = 0.156629	array([[ 3.0150895, -8.922059 ]], dtype=float32)
time = 15730	action = 0	current_phase = 0	next_phase = 1	reward = 1.001464	array([[ 3.1481547, -8.812312 ]], dtype=float32)
time = 15735	action = 0	current_phase = 0	next_phase = 1	reward = 1.003378	array([[ 3.1279235, -8.901697 ]], dtype=float32)
time = 15740	action = 0	current_phase = 0	next_phase = 1	reward = 0.167767	array([[ 3.1534114, -8.855554 ]], dtype=float32)
time = 15745	action = 0	current_phase = 0	next_phase = 1	reward = 1.013811	array([[ 3.0468225, -8.947674 ]], dtype=float32)
time = 15750	action = 0	current_phase = 0	next_phase = 1	reward = 1.008785	array([[ 2.9652953, -9.043697 ]], dtype=float32)
time = 15755	action = 0	current_phase = 0	next_phase = 1	reward = 0.167477	array([[ 3.2243695, -8.763697 ]], dtype=float32)
time = 15760	action = 0	current_phase = 0	next_phase = 1	reward = 1.286492	array([[ 3.216051, -8.793016]], dtype=float32)
time = 15765	action = 0	current_phase = 0	next_phase = 1	reward = 0.717794	array([[ 3.1396718, -8.8727   ]], dtype=float32)
time = 15770	action = 0	current_phase = 0	next_phase = 1	reward = 0.450549	array([[ 3.1731658, -8.800409 ]], dtype=float32)
time = 15775	action = 0	current_phase = 0	next_phase = 1	reward = 0.721783	array([[ 3.0466685, -8.924779 ]], dtype=float32)
time = 15780	action = 0	current_phase = 0	next_phase = 1	reward = 0.999332	array([[ 3.0858183, -8.901249 ]], dtype=float32)
time = 15785	action = 0	current_phase = 0	next_phase = 1	reward = 0.441658	array([[ 3.1858044, -8.754118 ]], dtype=float32)
time = 15790	action = 0	current_phase = 0	next_phase = 1	reward = 1.009324	array([[ 3.0322056, -9.109859 ]], dtype=float32)
time = 15795	action = 0	current_phase = 0	next_phase = 1	reward = 0.723395	array([[ 3.2487803, -8.80584  ]], dtype=float32)
time = 15800	action = 0	current_phase = 0	next_phase = 1	reward = 0.719637	array([[ 3.0288744, -8.920084 ]], dtype=float32)
time = 15805	action = 0	current_phase = 0	next_phase = 1	reward = 0.447178	array([[ 3.092229, -8.830385]], dtype=float32)
time = 15810	action = 0	current_phase = 0	next_phase = 1	reward = 1.022312	array([[ 3.1222386, -8.82707  ]], dtype=float32)
time = 15815	action = 0	current_phase = 0	next_phase = 1	reward = 0.720013	array([[ 3.2094145, -8.7618685]], dtype=float32)
time = 15820	action = 0	current_phase = 0	next_phase = 1	reward = 0.710048	array([[ 3.2278852, -8.774532 ]], dtype=float32)
time = 15825	action = 0	current_phase = 0	next_phase = 1	reward = 0.718274	array([[ 3.2400227, -8.768902 ]], dtype=float32)
time = 15830	action = 0	current_phase = 0	next_phase = 1	reward = 0.720296	array([[ 3.109054, -8.883987]], dtype=float32)
time = 15835	action = 0	current_phase = 0	next_phase = 1	reward = 0.444175	array([[ 3.1745744, -8.790874 ]], dtype=float32)
time = 15840	action = 0	current_phase = 0	next_phase = 1	reward = 0.733119	array([[ 3.182971, -8.825522]], dtype=float32)
time = 15845	action = 0	current_phase = 0	next_phase = 1	reward = 1.007554	array([[ 3.0795217, -8.897801 ]], dtype=float32)
time = 15850	action = 0	current_phase = 0	next_phase = 1	reward = 0.720022	array([[ 3.2471142, -8.728521 ]], dtype=float32)
time = 15855	action = 0	current_phase = 0	next_phase = 1	reward = 0.442343	array([[ 3.18854 , -8.783864]], dtype=float32)
time = 15860	action = 0	current_phase = 0	next_phase = 1	reward = 0.999018	array([[ 3.0948973, -8.8541155]], dtype=float32)
time = 15865	action = 0	current_phase = 0	next_phase = 1	reward = 0.435851	array([[ 3.1520677, -8.8363   ]], dtype=float32)
time = 15870	action = 0	current_phase = 0	next_phase = 1	reward = 0.725062	array([[ 3.04318 , -8.965092]], dtype=float32)
time = 15875	action = 0	current_phase = 0	next_phase = 1	reward = 0.720466	array([[ 3.1569176, -8.86233  ]], dtype=float32)
time = 15880	action = 0	current_phase = 0	next_phase = 1	reward = 0.724222	array([[ 2.849958, -9.180716]], dtype=float32)
time = 15885	action = 0	current_phase = 0	next_phase = 1	reward = 1.006140	array([[ 3.174233, -8.797956]], dtype=float32)
time = 15890	action = 0	current_phase = 0	next_phase = 1	reward = 0.720323	array([[ 3.2290497, -8.741865 ]], dtype=float32)
time = 15895	action = 0	current_phase = 0	next_phase = 1	reward = 0.447475	array([[ 3.1773138, -8.7612705]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.4355 - val_loss: 3.8787
Epoch 2/50
 - 4s - loss: 3.8138 - val_loss: 4.5471
Epoch 3/50
 - 4s - loss: 4.6464 - val_loss: 3.0351
Epoch 4/50
 - 4s - loss: 3.6342 - val_loss: 2.8904
Epoch 5/50
 - 4s - loss: 3.9734 - val_loss: 3.0287
Epoch 6/50
 - 4s - loss: 3.0985 - val_loss: 3.1630
Epoch 7/50
 - 4s - loss: 3.3361 - val_loss: 2.8152
Epoch 8/50
 - 4s - loss: 3.6537 - val_loss: 3.5534
Epoch 9/50
 - 4s - loss: 3.0351 - val_loss: 3.1464
Epoch 10/50
 - 4s - loss: 3.2970 - val_loss: 2.7737
Epoch 11/50
 - 4s - loss: 3.5852 - val_loss: 2.8305
Epoch 12/50
 - 4s - loss: 3.5119 - val_loss: 3.3257
Epoch 13/50
 - 4s - loss: 3.8898 - val_loss: 3.2281
Epoch 14/50
 - 4s - loss: 3.1954 - val_loss: 3.4167
Epoch 15/50
 - 4s - loss: 3.1532 - val_loss: 3.0588
Epoch 16/50
 - 4s - loss: 3.2020 - val_loss: 2.9508
Epoch 17/50
 - 4s - loss: 3.4248 - val_loss: 3.1014
Epoch 18/50
 - 4s - loss: 2.8855 - val_loss: 3.3627
Epoch 19/50
 - 4s - loss: 3.0538 - val_loss: 3.1539
Epoch 20/50
 - 4s - loss: 4.0992 - val_loss: 3.2393
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 15900	action = 0	current_phase = 0	next_phase = 1	reward = 0.724422	array([[ 3.1673326, -8.855286 ]], dtype=float32)
time = 15905	action = 0	current_phase = 0	next_phase = 1	reward = 1.011404	array([[ 3.132831, -8.935133]], dtype=float32)
time = 15910	action = 0	current_phase = 0	next_phase = 1	reward = 0.727591	array([[ 3.1543393, -8.925285 ]], dtype=float32)
time = 15915	action = 0	current_phase = 0	next_phase = 1	reward = 0.713504	array([[ 3.1805358, -8.82337  ]], dtype=float32)
time = 15920	action = 0	current_phase = 0	next_phase = 1	reward = 0.440058	array([[ 3.1171174, -8.910493 ]], dtype=float32)
time = 15925	action = 0	current_phase = 0	next_phase = 1	reward = 1.001299	array([[ 3.1097383, -8.96226  ]], dtype=float32)
time = 15930	action = 0	current_phase = 0	next_phase = 1	reward = 0.713816	array([[ 3.2031555, -8.818792 ]], dtype=float32)
time = 15935	action = 0	current_phase = 0	next_phase = 1	reward = 0.715623	array([[ 3.1744165, -8.833382 ]], dtype=float32)
time = 15940	action = 0	current_phase = 0	next_phase = 1	reward = 0.720621	array([[ 3.109346, -8.918587]], dtype=float32)
time = 15945	action = 0	current_phase = 0	next_phase = 1	reward = 0.433471	array([[ 3.1534066, -8.87063  ]], dtype=float32)
time = 15950	action = 0	current_phase = 0	next_phase = 1	reward = 1.002723	array([[ 3.1740637, -8.902075 ]], dtype=float32)
time = 15955	action = 0	current_phase = 0	next_phase = 1	reward = 0.443813	array([[ 3.0906172, -8.926878 ]], dtype=float32)
time = 15960	action = 0	current_phase = 0	next_phase = 1	reward = 0.734311	array([[ 3.058889, -8.974313]], dtype=float32)
time = 15965	action = 0	current_phase = 0	next_phase = 1	reward = 0.723571	array([[ 3.2667994, -8.838766 ]], dtype=float32)
time = 15970	action = 0	current_phase = 0	next_phase = 1	reward = 1.000960	array([[ 3.1883001, -8.835589 ]], dtype=float32)
time = 15975	action = 0	current_phase = 0	next_phase = 1	reward = 0.167071	array([[ 3.2176595, -8.842471 ]], dtype=float32)
time = 15980	action = 0	current_phase = 0	next_phase = 1	reward = 1.292100	array([[ 3.1085067, -8.9755   ]], dtype=float32)
time = 15985	action = 0	current_phase = 0	next_phase = 1	reward = 0.721458	array([[ 3.1527576, -8.898285 ]], dtype=float32)
time = 15990	action = 0	current_phase = 0	next_phase = 1	reward = 0.722788	array([[ 3.1294594, -8.881194 ]], dtype=float32)
time = 15995	action = 0	current_phase = 0	next_phase = 1	reward = 0.721113	array([[ 3.1849399, -8.881878 ]], dtype=float32)
time = 16000	action = 0	current_phase = 0	next_phase = 1	reward = 0.724241	array([[ 3.2368398, -8.906794 ]], dtype=float32)
time = 16005	action = 0	current_phase = 0	next_phase = 1	reward = 0.723666	array([[ 3.23974 , -8.778536]], dtype=float32)
time = 16010	action = 0	current_phase = 0	next_phase = 1	reward = 0.440547	array([[ 3.1419387, -8.871201 ]], dtype=float32)
time = 16015	action = 0	current_phase = 0	next_phase = 1	reward = 0.995440	array([[ 3.0817904, -8.929794 ]], dtype=float32)
time = 16020	action = 0	current_phase = 0	next_phase = 1	reward = 0.167211	array([[ 3.150361, -8.883035]], dtype=float32)
time = 16025	action = 0	current_phase = 0	next_phase = 1	reward = 1.276123	array([[ 2.916893, -9.21346 ]], dtype=float32)
time = 16030	action = 0	current_phase = 0	next_phase = 1	reward = 0.714213	array([[ 3.1945353, -8.837081 ]], dtype=float32)
time = 16035	action = 0	current_phase = 0	next_phase = 1	reward = 0.717580	array([[ 3.2061157, -8.815247 ]], dtype=float32)
time = 16040	action = 0	current_phase = 0	next_phase = 1	reward = 0.446799	array([[ 3.120524, -8.920293]], dtype=float32)
time = 16045	action = 0	current_phase = 0	next_phase = 1	reward = 1.006690	array([[ 3.1435256, -8.906903 ]], dtype=float32)
time = 16050	action = 0	current_phase = 0	next_phase = 1	reward = 0.723728	array([[ 3.156787, -8.886829]], dtype=float32)
time = 16055	action = 0	current_phase = 0	next_phase = 1	reward = 0.716171	array([[ 3.1026769, -8.92759  ]], dtype=float32)
time = 16060	action = 0	current_phase = 0	next_phase = 1	reward = 0.447006	array([[ 3.1296272, -8.905746 ]], dtype=float32)
time = 16065	action = 0	current_phase = 0	next_phase = 1	reward = 0.726276	array([[ 3.0749736, -9.085289 ]], dtype=float32)
time = 16070	action = 0	current_phase = 0	next_phase = 1	reward = 1.007082	array([[ 3.1861577, -8.891729 ]], dtype=float32)
time = 16075	action = 0	current_phase = 0	next_phase = 1	reward = 0.442994	array([[ 3.23808 , -8.795016]], dtype=float32)
time = 16080	action = 0	current_phase = 0	next_phase = 1	reward = 1.012089	array([[ 3.0573273, -9.000715 ]], dtype=float32)
time = 16085	action = 0	current_phase = 0	next_phase = 1	reward = 0.726098	array([[ 3.1901755, -8.860043 ]], dtype=float32)
time = 16090	action = 0	current_phase = 0	next_phase = 1	reward = 0.718072	array([[ 3.0905519, -8.950163 ]], dtype=float32)
time = 16095	action = 0	current_phase = 0	next_phase = 1	reward = 0.428280	array([[ 3.1381826, -8.904089 ]], dtype=float32)
time = 16100	action = 0	current_phase = 0	next_phase = 1	reward = 0.726467	array([[ 3.1098003, -8.913441 ]], dtype=float32)
time = 16105	action = 0	current_phase = 0	next_phase = 1	reward = 0.448147	array([[ 3.1929784, -8.924227 ]], dtype=float32)
time = 16110	action = 0	current_phase = 0	next_phase = 1	reward = 1.296604	array([[ 3.119794, -8.896996]], dtype=float32)
time = 16115	action = 0	current_phase = 0	next_phase = 1	reward = 0.721664	array([[ 3.1953287, -8.854595 ]], dtype=float32)
time = 16120	action = 0	current_phase = 0	next_phase = 1	reward = 0.722120	array([[ 3.1912093, -8.8239565]], dtype=float32)
time = 16125	action = 0	current_phase = 0	next_phase = 1	reward = 0.721427	array([[ 3.2630157, -8.790705 ]], dtype=float32)
time = 16130	action = 0	current_phase = 0	next_phase = 1	reward = 0.443638	array([[ 3.182043, -8.866751]], dtype=float32)
time = 16135	action = 0	current_phase = 0	next_phase = 1	reward = 0.725925	array([[ 3.137454, -8.878381]], dtype=float32)
time = 16140	action = 0	current_phase = 0	next_phase = 1	reward = 1.005853	array([[ 3.1621127, -8.87233  ]], dtype=float32)
time = 16145	action = 0	current_phase = 0	next_phase = 1	reward = 0.442173	array([[ 3.1855078, -8.881884 ]], dtype=float32)
time = 16150	action = 0	current_phase = 0	next_phase = 1	reward = 1.001726	array([[ 3.0743723, -8.978373 ]], dtype=float32)
time = 16155	action = 0	current_phase = 0	next_phase = 1	reward = 0.432909	array([[ 3.1990356, -8.81971  ]], dtype=float32)
time = 16160	action = 0	current_phase = 0	next_phase = 1	reward = 0.719868	array([[ 3.0461183, -9.09316  ]], dtype=float32)
time = 16165	action = 0	current_phase = 0	next_phase = 1	reward = 0.726325	array([[ 3.1356497, -9.043722 ]], dtype=float32)
time = 16170	action = 0	current_phase = 0	next_phase = 1	reward = 1.002078	array([[ 3.198372, -8.975979]], dtype=float32)
time = 16175	action = 0	current_phase = 0	next_phase = 1	reward = 0.720744	array([[ 3.1674628, -8.867223 ]], dtype=float32)
time = 16180	action = 0	current_phase = 0	next_phase = 1	reward = 0.718523	array([[ 3.1905851, -8.840912 ]], dtype=float32)
time = 16185	action = 0	current_phase = 0	next_phase = 1	reward = 0.719132	array([[ 3.1990452, -8.846799 ]], dtype=float32)
time = 16190	action = 0	current_phase = 0	next_phase = 1	reward = 0.719417	array([[ 3.1692228, -8.870265 ]], dtype=float32)
time = 16195	action = 0	current_phase = 0	next_phase = 1	reward = 0.713477	array([[ 3.1569796, -8.933775 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.0820 - val_loss: 2.5365
Epoch 2/50
 - 4s - loss: 4.4872 - val_loss: 2.6499
Epoch 3/50
 - 4s - loss: 3.5648 - val_loss: 1.9772
Epoch 4/50
 - 4s - loss: 3.8266 - val_loss: 2.6231
Epoch 5/50
 - 4s - loss: 4.2750 - val_loss: 2.5269
Epoch 6/50
 - 4s - loss: 3.8539 - val_loss: 2.5071
Epoch 7/50
 - 4s - loss: 4.0688 - val_loss: 2.7910
Epoch 8/50
 - 4s - loss: 4.3890 - val_loss: 2.6801
Epoch 9/50
 - 4s - loss: 2.9020 - val_loss: 2.5998
Epoch 10/50
 - 4s - loss: 4.0770 - val_loss: 2.5331
Epoch 11/50
 - 5s - loss: 3.5475 - val_loss: 2.4094
Epoch 12/50
 - 4s - loss: 3.5540 - val_loss: 2.2394
Epoch 13/50
 - 4s - loss: 3.3303 - val_loss: 2.8521
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 16200	action = 0	current_phase = 0	next_phase = 1	reward = 0.714244	array([[ 3.1880379, -8.910795 ]], dtype=float32)
time = 16205	action = 0	current_phase = 0	next_phase = 1	reward = 0.445761	array([[ 3.1816397, -9.008462 ]], dtype=float32)
time = 16210	action = 0	current_phase = 0	next_phase = 1	reward = 0.727847	array([[ 3.2514606, -8.900957 ]], dtype=float32)
time = 16215	action = 0	current_phase = 0	next_phase = 1	reward = 0.997358	array([[ 3.1766543, -8.993902 ]], dtype=float32)
time = 16220	action = 0	current_phase = 0	next_phase = 1	reward = 0.444567	array([[ 3.2081661, -8.906164 ]], dtype=float32)
time = 16225	action = 0	current_phase = 0	next_phase = 1	reward = 1.002274	array([[ 2.8996272, -9.402428 ]], dtype=float32)
time = 16230	action = 0	current_phase = 0	next_phase = 1	reward = 0.174346	array([[ 3.2161112, -8.893104 ]], dtype=float32)
time = 16235	action = 0	current_phase = 0	next_phase = 1	reward = 1.290418	array([[ 3.177969, -8.94397 ]], dtype=float32)
time = 16240	action = 0	current_phase = 0	next_phase = 1	reward = 0.719139	array([[ 3.1203842, -8.99397  ]], dtype=float32)
time = 16245	action = 0	current_phase = 0	next_phase = 1	reward = 0.718201	array([[ 3.1422844, -8.95612  ]], dtype=float32)
time = 16250	action = 0	current_phase = 0	next_phase = 1	reward = 0.725856	array([[ 3.1852827, -8.922016 ]], dtype=float32)
time = 16255	action = 0	current_phase = 0	next_phase = 1	reward = 0.724986	array([[ 3.199963, -8.898064]], dtype=float32)
time = 16260	action = 0	current_phase = 0	next_phase = 1	reward = 0.726983	array([[ 3.187893, -8.926031]], dtype=float32)
time = 16265	action = 0	current_phase = 0	next_phase = 1	reward = 0.730945	array([[ 3.2313552, -8.877899 ]], dtype=float32)
time = 16270	action = 0	current_phase = 0	next_phase = 1	reward = 0.720178	array([[ 3.2225738, -8.890614 ]], dtype=float32)
time = 16275	action = 0	current_phase = 0	next_phase = 1	reward = 0.723089	array([[ 3.1679616, -8.945688 ]], dtype=float32)
time = 16280	action = 0	current_phase = 0	next_phase = 1	reward = 0.717669	array([[ 3.2441034, -8.961829 ]], dtype=float32)
time = 16285	action = 0	current_phase = 0	next_phase = 1	reward = 0.724334	array([[ 3.1951404, -8.911743 ]], dtype=float32)
time = 16290	action = 0	current_phase = 0	next_phase = 1	reward = 0.723527	array([[ 3.2175121, -8.918983 ]], dtype=float32)
time = 16295	action = 0	current_phase = 0	next_phase = 1	reward = 0.436821	array([[ 3.1987205, -8.913164 ]], dtype=float32)
time = 16300	action = 0	current_phase = 0	next_phase = 1	reward = 0.999306	array([[ 3.2891517, -8.878408 ]], dtype=float32)
time = 16305	action = 0	current_phase = 0	next_phase = 1	reward = 0.727224	array([[ 3.2445803, -8.88698  ]], dtype=float32)
time = 16310	action = 0	current_phase = 0	next_phase = 1	reward = 0.447485	array([[ 3.1911187, -8.942322 ]], dtype=float32)
time = 16315	action = 0	current_phase = 0	next_phase = 1	reward = 1.007604	array([[ 3.1390624, -8.960934 ]], dtype=float32)
time = 16320	action = 0	current_phase = 0	next_phase = 1	reward = 0.442299	array([[ 3.2815428, -8.856024 ]], dtype=float32)
time = 16325	action = 0	current_phase = 0	next_phase = 1	reward = 1.007453	array([[ 3.1502752, -8.980534 ]], dtype=float32)
time = 16330	action = 0	current_phase = 0	next_phase = 1	reward = 0.163785	array([[ 3.3314462, -8.878326 ]], dtype=float32)
time = 16335	action = 0	current_phase = 0	next_phase = 1	reward = 1.287125	array([[ 3.172165, -8.938049]], dtype=float32)
time = 16340	action = 0	current_phase = 0	next_phase = 1	reward = 0.714934	array([[ 3.2088284, -8.909922 ]], dtype=float32)
time = 16345	action = 0	current_phase = 0	next_phase = 1	reward = 0.440357	array([[ 3.1967506, -8.924707 ]], dtype=float32)
time = 16350	action = 0	current_phase = 0	next_phase = 1	reward = 1.006409	array([[ 3.2042594, -8.936941 ]], dtype=float32)
time = 16355	action = 0	current_phase = 0	next_phase = 1	reward = 0.441396	array([[ 3.2216992, -8.897516 ]], dtype=float32)
time = 16360	action = 0	current_phase = 0	next_phase = 1	reward = 0.723293	array([[ 3.212185, -8.891993]], dtype=float32)
time = 16365	action = 0	current_phase = 0	next_phase = 1	reward = 1.000405	array([[ 3.1763854, -8.950816 ]], dtype=float32)
time = 16370	action = 0	current_phase = 0	next_phase = 1	reward = 0.439843	array([[ 3.1920357, -8.936111 ]], dtype=float32)
time = 16375	action = 0	current_phase = 0	next_phase = 1	reward = 0.725854	array([[ 3.2593718, -8.90922  ]], dtype=float32)
time = 16380	action = 0	current_phase = 0	next_phase = 1	reward = 0.727979	array([[ 3.1429286, -8.997249 ]], dtype=float32)
time = 16385	action = 0	current_phase = 0	next_phase = 1	reward = 1.001290	array([[ 3.1563435, -8.996126 ]], dtype=float32)
time = 16390	action = 0	current_phase = 0	next_phase = 1	reward = 0.441636	array([[ 3.2177033, -8.89912  ]], dtype=float32)
time = 16395	action = 0	current_phase = 0	next_phase = 1	reward = 1.005868	array([[ 3.2043176, -8.939936 ]], dtype=float32)
time = 16400	action = 0	current_phase = 0	next_phase = 1	reward = 0.717425	array([[ 3.2279105, -8.890966 ]], dtype=float32)
time = 16405	action = 0	current_phase = 0	next_phase = 1	reward = 0.722478	array([[ 3.1909342, -8.89377  ]], dtype=float32)
time = 16410	action = 0	current_phase = 0	next_phase = 1	reward = 0.720833	array([[ 3.2610736, -8.895983 ]], dtype=float32)
time = 16415	action = 0	current_phase = 0	next_phase = 1	reward = 0.438714	array([[ 3.1642609, -8.946314 ]], dtype=float32)
time = 16420	action = 0	current_phase = 0	next_phase = 1	reward = 0.730218	array([[ 3.2294526, -8.85413  ]], dtype=float32)
time = 16425	action = 0	current_phase = 0	next_phase = 1	reward = 1.004142	array([[ 3.1295805, -9.019077 ]], dtype=float32)
time = 16430	action = 0	current_phase = 0	next_phase = 1	reward = 0.442169	array([[ 3.2305331, -8.870495 ]], dtype=float32)
time = 16435	action = 0	current_phase = 0	next_phase = 1	reward = 0.999550	array([[ 3.116588, -8.983695]], dtype=float32)
time = 16440	action = 0	current_phase = 0	next_phase = 1	reward = 0.439267	array([[ 3.2450743, -8.890045 ]], dtype=float32)
time = 16445	action = 0	current_phase = 0	next_phase = 1	reward = 0.724996	array([[ 3.1705842, -8.968662 ]], dtype=float32)
time = 16450	action = 0	current_phase = 0	next_phase = 1	reward = 0.721660	array([[ 3.1605487, -8.966328 ]], dtype=float32)
time = 16455	action = 0	current_phase = 0	next_phase = 1	reward = 0.729024	array([[ 3.0709157, -9.147203 ]], dtype=float32)
time = 16460	action = 0	current_phase = 0	next_phase = 1	reward = 0.725765	array([[ 3.1083622, -8.983894 ]], dtype=float32)
time = 16465	action = 0	current_phase = 0	next_phase = 1	reward = 0.719232	array([[ 3.2522655, -8.971374 ]], dtype=float32)
time = 16470	action = 0	current_phase = 0	next_phase = 1	reward = 0.723333	array([[ 3.1760101, -8.958387 ]], dtype=float32)
time = 16475	action = 0	current_phase = 0	next_phase = 1	reward = 1.003431	array([[ 3.2385006, -8.905441 ]], dtype=float32)
time = 16480	action = 0	current_phase = 0	next_phase = 1	reward = 0.727840	array([[ 3.176334, -8.922132]], dtype=float32)
time = 16485	action = 0	current_phase = 0	next_phase = 1	reward = 0.727342	array([[ 3.2410073, -8.866685 ]], dtype=float32)
time = 16490	action = 0	current_phase = 0	next_phase = 1	reward = 0.445047	array([[ 3.2314773, -8.900322 ]], dtype=float32)
time = 16495	action = 0	current_phase = 0	next_phase = 1	reward = 1.004637	array([[ 3.2048383, -8.905201 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.0517 - val_loss: 1.7267
Epoch 2/50
 - 4s - loss: 4.2574 - val_loss: 2.0875
Epoch 3/50
 - 4s - loss: 4.1793 - val_loss: 1.8979
Epoch 4/50
 - 4s - loss: 3.9834 - val_loss: 2.2227
Epoch 5/50
 - 4s - loss: 4.4509 - val_loss: 2.0865
Epoch 6/50
 - 4s - loss: 3.8650 - val_loss: 1.9359
Epoch 7/50
 - 4s - loss: 3.9032 - val_loss: 1.8895
Epoch 8/50
 - 4s - loss: 3.0737 - val_loss: 2.8633
Epoch 9/50
 - 4s - loss: 3.5203 - val_loss: 2.1948
Epoch 10/50
 - 4s - loss: 3.5787 - val_loss: 1.7712
Epoch 11/50
 - 4s - loss: 4.1542 - val_loss: 2.2241
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 16500	action = 0	current_phase = 0	next_phase = 1	reward = 0.724266	array([[ 3.0925746, -8.992912 ]], dtype=float32)
time = 16505	action = 0	current_phase = 0	next_phase = 1	reward = 0.451317	array([[ 3.3049498, -8.980933 ]], dtype=float32)
time = 16510	action = 0	current_phase = 0	next_phase = 1	reward = 0.728070	array([[ 3.1678214, -8.943398 ]], dtype=float32)
time = 16515	action = 0	current_phase = 0	next_phase = 1	reward = 1.004518	array([[ 3.0956712, -9.064057 ]], dtype=float32)
time = 16520	action = 0	current_phase = 0	next_phase = 1	reward = 0.441860	array([[ 3.1984363, -8.922636 ]], dtype=float32)
time = 16525	action = 0	current_phase = 0	next_phase = 1	reward = 1.001323	array([[ 3.1124868, -9.052977 ]], dtype=float32)
time = 16530	action = 0	current_phase = 0	next_phase = 1	reward = 0.722477	array([[ 3.1684995, -8.943304 ]], dtype=float32)
time = 16535	action = 0	current_phase = 0	next_phase = 1	reward = 0.712469	array([[ 3.128758, -8.975746]], dtype=float32)
time = 16540	action = 0	current_phase = 0	next_phase = 1	reward = 0.437581	array([[ 3.1852808, -9.005985 ]], dtype=float32)
time = 16545	action = 0	current_phase = 0	next_phase = 1	reward = 1.006837	array([[ 3.2519398, -8.885808 ]], dtype=float32)
time = 16550	action = 0	current_phase = 0	next_phase = 1	reward = 0.440418	array([[ 3.0956793, -8.983473 ]], dtype=float32)
time = 16555	action = 0	current_phase = 0	next_phase = 1	reward = 0.722072	array([[ 3.2247558, -8.954175 ]], dtype=float32)
time = 16560	action = 0	current_phase = 0	next_phase = 1	reward = 0.736743	array([[ 3.1833267, -8.928026 ]], dtype=float32)
time = 16565	action = 0	current_phase = 0	next_phase = 1	reward = 1.013151	array([[ 3.1587625, -9.020685 ]], dtype=float32)
time = 16570	action = 0	current_phase = 0	next_phase = 1	reward = 0.717272	array([[ 3.176208, -8.95379 ]], dtype=float32)
time = 16575	action = 0	current_phase = 0	next_phase = 1	reward = 0.717458	array([[ 3.1762185, -8.940201 ]], dtype=float32)
time = 16580	action = 0	current_phase = 0	next_phase = 1	reward = 0.717106	array([[ 3.2922144, -8.8830805]], dtype=float32)
time = 16585	action = 0	current_phase = 0	next_phase = 1	reward = 0.448877	array([[ 3.1505523, -8.971155 ]], dtype=float32)
time = 16590	action = 0	current_phase = 0	next_phase = 1	reward = 1.006687	array([[ 3.178712, -8.969463]], dtype=float32)
time = 16595	action = 0	current_phase = 0	next_phase = 1	reward = 0.721214	array([[ 3.1526089, -8.990722 ]], dtype=float32)
time = 16600	action = 0	current_phase = 0	next_phase = 1	reward = 0.721592	array([[ 3.1784482, -8.912862 ]], dtype=float32)
time = 16605	action = 0	current_phase = 0	next_phase = 1	reward = 0.716421	array([[ 3.2255616, -8.901331 ]], dtype=float32)
time = 16610	action = 0	current_phase = 0	next_phase = 1	reward = 0.714583	array([[ 3.2224302, -8.9146385]], dtype=float32)
time = 16615	action = 0	current_phase = 0	next_phase = 1	reward = 0.161784	array([[ 3.2284317, -8.885873 ]], dtype=float32)
time = 16620	action = 0	current_phase = 0	next_phase = 1	reward = 1.283270	array([[ 2.9542513, -9.274366 ]], dtype=float32)
time = 16625	action = 0	current_phase = 0	next_phase = 1	reward = 0.715363	array([[ 3.2305522, -8.909927 ]], dtype=float32)
time = 16630	action = 0	current_phase = 0	next_phase = 1	reward = 0.719288	array([[ 3.163818, -8.940415]], dtype=float32)
time = 16635	action = 0	current_phase = 0	next_phase = 1	reward = 0.167772	array([[ 3.1555276, -8.977023 ]], dtype=float32)
time = 16640	action = 0	current_phase = 0	next_phase = 1	reward = 1.005766	array([[ 2.9951568, -9.238414 ]], dtype=float32)
time = 16645	action = 0	current_phase = 0	next_phase = 1	reward = 0.722080	array([[ 3.1690388, -8.958573 ]], dtype=float32)
time = 16650	action = 0	current_phase = 0	next_phase = 1	reward = 1.001743	array([[ 3.2013907, -8.920233 ]], dtype=float32)
time = 16655	action = 0	current_phase = 0	next_phase = 1	reward = 0.723788	array([[ 3.1696997, -8.962634 ]], dtype=float32)
time = 16660	action = 0	current_phase = 0	next_phase = 1	reward = 0.437459	array([[ 3.1516461, -8.942962 ]], dtype=float32)
time = 16665	action = 0	current_phase = 0	next_phase = 1	reward = 0.722623	array([[ 3.1589584, -8.955528 ]], dtype=float32)
time = 16670	action = 0	current_phase = 0	next_phase = 1	reward = 1.010587	array([[ 3.1785278, -8.945629 ]], dtype=float32)
time = 16675	action = 0	current_phase = 0	next_phase = 1	reward = 0.723174	array([[ 3.223247, -8.90351 ]], dtype=float32)
time = 16680	action = 0	current_phase = 0	next_phase = 1	reward = 0.722377	array([[ 3.1251526, -8.99873  ]], dtype=float32)
time = 16685	action = 0	current_phase = 0	next_phase = 1	reward = 0.727779	array([[ 3.2799692, -8.903202 ]], dtype=float32)
time = 16690	action = 0	current_phase = 0	next_phase = 1	reward = 0.725173	array([[ 3.2073917, -8.912738 ]], dtype=float32)
time = 16695	action = 0	current_phase = 0	next_phase = 1	reward = 0.717014	array([[ 3.2164464, -8.891619 ]], dtype=float32)
time = 16700	action = 0	current_phase = 0	next_phase = 1	reward = 0.721172	array([[ 3.1678839, -8.89818  ]], dtype=float32)
time = 16705	action = 0	current_phase = 0	next_phase = 1	reward = 0.726931	array([[ 3.2959118, -8.904202 ]], dtype=float32)
time = 16710	action = 0	current_phase = 0	next_phase = 1	reward = 0.717128	array([[ 3.2043538, -8.905577 ]], dtype=float32)
time = 16715	action = 0	current_phase = 0	next_phase = 1	reward = 0.723242	array([[ 3.170806, -8.930707]], dtype=float32)
time = 16720	action = 0	current_phase = 0	next_phase = 1	reward = 0.714791	array([[ 3.2308583, -8.861137 ]], dtype=float32)
time = 16725	action = 0	current_phase = 0	next_phase = 1	reward = 0.172143	array([[ 3.1874871, -8.908567 ]], dtype=float32)
time = 16730	action = 0	current_phase = 0	next_phase = 1	reward = 1.293333	array([[ 3.172772, -9.010092]], dtype=float32)
time = 16735	action = 0	current_phase = 0	next_phase = 1	reward = 0.721576	array([[ 3.1641936, -8.931938 ]], dtype=float32)
time = 16740	action = 0	current_phase = 0	next_phase = 1	reward = 0.728706	array([[ 3.27629 , -8.902624]], dtype=float32)
time = 16745	action = 0	current_phase = 0	next_phase = 1	reward = 0.724634	array([[ 3.2288008, -8.894171 ]], dtype=float32)
time = 16750	action = 0	current_phase = 0	next_phase = 1	reward = 0.726853	array([[ 3.140059, -9.071552]], dtype=float32)
time = 16755	action = 0	current_phase = 0	next_phase = 1	reward = 0.716798	array([[ 3.2534885, -8.929386 ]], dtype=float32)
time = 16760	action = 0	current_phase = 0	next_phase = 1	reward = 0.715668	array([[ 3.1905384, -8.895302 ]], dtype=float32)
time = 16765	action = 0	current_phase = 0	next_phase = 1	reward = 0.437144	array([[ 3.1444283, -9.008705 ]], dtype=float32)
time = 16770	action = 0	current_phase = 0	next_phase = 1	reward = 0.453292	array([[ 3.124341, -8.986039]], dtype=float32)
time = 16775	action = 0	current_phase = 0	next_phase = 1	reward = 1.277256	array([[ 3.125342, -8.961143]], dtype=float32)
time = 16780	action = 0	current_phase = 0	next_phase = 1	reward = 0.440900	array([[ 3.162723, -8.954027]], dtype=float32)
time = 16785	action = 0	current_phase = 0	next_phase = 1	reward = 1.000052	array([[ 2.9697266, -9.174274 ]], dtype=float32)
time = 16790	action = 0	current_phase = 0	next_phase = 1	reward = 0.442817	array([[ 3.1565762, -8.965384 ]], dtype=float32)
time = 16795	action = 0	current_phase = 0	next_phase = 1	reward = 0.998755	array([[ 3.1874332, -8.926598 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.4072 - val_loss: 1.6982
Epoch 2/50
 - 4s - loss: 4.2712 - val_loss: 2.0024
Epoch 3/50
 - 4s - loss: 3.8767 - val_loss: 1.9364
Epoch 4/50
 - 4s - loss: 3.8247 - val_loss: 1.7900
Epoch 5/50
 - 4s - loss: 4.3670 - val_loss: 1.8612
Epoch 6/50
 - 4s - loss: 3.6789 - val_loss: 1.8923
Epoch 7/50
 - 4s - loss: 4.3781 - val_loss: 1.9229
Epoch 8/50
 - 4s - loss: 3.5645 - val_loss: 2.6720
Epoch 9/50
 - 4s - loss: 3.5311 - val_loss: 1.4596
Epoch 10/50
 - 4s - loss: 4.8072 - val_loss: 1.8505
Epoch 11/50
 - 4s - loss: 3.9289 - val_loss: 1.8597
Epoch 12/50
 - 4s - loss: 3.5629 - val_loss: 3.0403
Epoch 13/50
 - 4s - loss: 3.7036 - val_loss: 2.2077
Epoch 14/50
 - 4s - loss: 4.1525 - val_loss: 2.3118
Epoch 15/50
 - 4s - loss: 4.0057 - val_loss: 3.9927
Epoch 16/50
 - 4s - loss: 3.0425 - val_loss: 1.6525
Epoch 17/50
 - 5s - loss: 3.9264 - val_loss: 1.4750
Epoch 18/50
 - 5s - loss: 3.9759 - val_loss: 1.5229
Epoch 19/50
 - 6s - loss: 4.0264 - val_loss: 2.2109
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 16800	action = 0	current_phase = 0	next_phase = 1	reward = 0.428786	array([[ 3.1869388, -9.042023 ]], dtype=float32)
time = 16805	action = 0	current_phase = 0	next_phase = 1	reward = 1.001843	array([[ 3.2428231, -8.9958725]], dtype=float32)
time = 16810	action = 0	current_phase = 0	next_phase = 1	reward = 0.725721	array([[ 3.2128096, -8.989939 ]], dtype=float32)
time = 16815	action = 0	current_phase = 0	next_phase = 1	reward = 0.441732	array([[ 3.2299914, -9.029574 ]], dtype=float32)
time = 16820	action = 0	current_phase = 0	next_phase = 1	reward = 0.725330	array([[ 3.0844817, -9.165237 ]], dtype=float32)
time = 16825	action = 0	current_phase = 0	next_phase = 1	reward = 1.003783	array([[ 3.3703475, -8.8933525]], dtype=float32)
time = 16830	action = 0	current_phase = 0	next_phase = 1	reward = 0.728652	array([[ 3.280254, -8.959239]], dtype=float32)
time = 16835	action = 0	current_phase = 0	next_phase = 1	reward = 0.726184	array([[ 3.1674204, -9.039824 ]], dtype=float32)
time = 16840	action = 0	current_phase = 0	next_phase = 1	reward = 0.722586	array([[ 3.194518, -9.029835]], dtype=float32)
time = 16845	action = 0	current_phase = 0	next_phase = 1	reward = 0.442268	array([[ 3.1948872, -9.004391 ]], dtype=float32)
time = 16850	action = 0	current_phase = 0	next_phase = 1	reward = 0.726141	array([[ 3.2630467, -8.944976 ]], dtype=float32)
time = 16855	action = 0	current_phase = 0	next_phase = 1	reward = 1.002872	array([[ 3.2463298, -9.055502 ]], dtype=float32)
time = 16860	action = 0	current_phase = 0	next_phase = 1	reward = 0.717325	array([[ 3.2382903, -8.982077 ]], dtype=float32)
time = 16865	action = 0	current_phase = 0	next_phase = 1	reward = 0.720272	array([[ 3.2100034, -8.98258  ]], dtype=float32)
time = 16870	action = 0	current_phase = 0	next_phase = 1	reward = 0.441644	array([[ 3.2811942, -8.96013  ]], dtype=float32)
time = 16875	action = 0	current_phase = 0	next_phase = 1	reward = 1.001025	array([[ 3.158288, -9.078447]], dtype=float32)
time = 16880	action = 0	current_phase = 0	next_phase = 1	reward = 0.436810	array([[ 3.2740808, -8.976542 ]], dtype=float32)
time = 16885	action = 0	current_phase = 0	next_phase = 1	reward = 0.731100	array([[ 3.2293077, -8.978379 ]], dtype=float32)
time = 16890	action = 0	current_phase = 0	next_phase = 1	reward = 1.009481	array([[ 3.2492652, -8.994753 ]], dtype=float32)
time = 16895	action = 0	current_phase = 0	next_phase = 1	reward = 0.723296	array([[ 3.258265, -9.007076]], dtype=float32)
time = 16900	action = 0	current_phase = 0	next_phase = 1	reward = 0.716215	array([[ 3.3108392, -8.986235 ]], dtype=float32)
time = 16905	action = 0	current_phase = 0	next_phase = 1	reward = 0.169525	array([[ 3.1866527, -9.054005 ]], dtype=float32)
time = 16910	action = 0	current_phase = 0	next_phase = 1	reward = 1.290035	array([[ 3.1577463, -9.120531 ]], dtype=float32)
time = 16915	action = 0	current_phase = 0	next_phase = 1	reward = 0.731258	array([[ 3.2512727, -8.96806  ]], dtype=float32)
time = 16920	action = 0	current_phase = 0	next_phase = 1	reward = 0.725029	array([[ 3.2209382, -9.048601 ]], dtype=float32)
time = 16925	action = 0	current_phase = 0	next_phase = 1	reward = 0.724942	array([[ 3.172924, -9.008715]], dtype=float32)
time = 16930	action = 0	current_phase = 0	next_phase = 1	reward = 0.728731	array([[ 3.2000318, -9.007805 ]], dtype=float32)
time = 16935	action = 0	current_phase = 0	next_phase = 1	reward = 0.731134	array([[ 3.1038008, -9.076738 ]], dtype=float32)
time = 16940	action = 0	current_phase = 0	next_phase = 1	reward = 0.721555	array([[ 3.2799945, -8.982189 ]], dtype=float32)
time = 16945	action = 0	current_phase = 0	next_phase = 1	reward = 0.711160	array([[ 3.167616, -9.046292]], dtype=float32)
time = 16950	action = 0	current_phase = 0	next_phase = 1	reward = 0.717695	array([[ 3.2695575, -8.990694 ]], dtype=float32)
time = 16955	action = 0	current_phase = 0	next_phase = 1	reward = 0.724089	array([[ 3.176374, -9.014567]], dtype=float32)
time = 16960	action = 0	current_phase = 0	next_phase = 1	reward = 0.729001	array([[ 3.2000284, -8.999082 ]], dtype=float32)
time = 16965	action = 0	current_phase = 0	next_phase = 1	reward = 0.716928	array([[ 3.1803613, -9.028648 ]], dtype=float32)
time = 16970	action = 0	current_phase = 0	next_phase = 1	reward = 0.720131	array([[ 3.2769656, -8.963703 ]], dtype=float32)
time = 16975	action = 0	current_phase = 0	next_phase = 1	reward = 0.439456	array([[ 3.3088489, -8.92518  ]], dtype=float32)
time = 16980	action = 0	current_phase = 0	next_phase = 1	reward = 1.001478	array([[ 3.2429566, -9.038479 ]], dtype=float32)
time = 16985	action = 0	current_phase = 0	next_phase = 1	reward = 0.435487	array([[ 3.3305697, -8.940246 ]], dtype=float32)
time = 16990	action = 0	current_phase = 0	next_phase = 1	reward = 0.445582	array([[ 3.1485486, -9.136541 ]], dtype=float32)
time = 16995	action = 0	current_phase = 0	next_phase = 1	reward = 1.283649	array([[ 3.2269263, -9.125204 ]], dtype=float32)
time = 17000	action = 0	current_phase = 0	next_phase = 1	reward = 0.441198	array([[ 3.3584085, -8.9368   ]], dtype=float32)
time = 17005	action = 0	current_phase = 0	next_phase = 1	reward = 1.015588	array([[ 3.0209336, -9.190273 ]], dtype=float32)
time = 17010	action = 0	current_phase = 0	next_phase = 1	reward = 0.439185	array([[ 3.106707, -9.134243]], dtype=float32)
time = 17015	action = 0	current_phase = 0	next_phase = 1	reward = 1.004199	array([[ 3.0825672, -9.084424 ]], dtype=float32)
time = 17020	action = 0	current_phase = 0	next_phase = 1	reward = 0.438531	array([[ 3.300425, -8.98514 ]], dtype=float32)
time = 17025	action = 0	current_phase = 0	next_phase = 1	reward = 0.732921	array([[ 3.1671066, -9.071697 ]], dtype=float32)
time = 17030	action = 0	current_phase = 0	next_phase = 1	reward = 0.735743	array([[ 3.2578807, -8.975534 ]], dtype=float32)
time = 17035	action = 0	current_phase = 0	next_phase = 1	reward = 1.003992	array([[ 3.1774945, -9.033903 ]], dtype=float32)
time = 17040	action = 0	current_phase = 0	next_phase = 1	reward = 0.712087	array([[ 3.2224908, -8.97894  ]], dtype=float32)
time = 17045	action = 0	current_phase = 0	next_phase = 1	reward = 0.723767	array([[ 3.2971292, -8.963354 ]], dtype=float32)
time = 17050	action = 0	current_phase = 0	next_phase = 1	reward = 0.717051	array([[ 3.2756238, -9.061035 ]], dtype=float32)
time = 17055	action = 0	current_phase = 0	next_phase = 1	reward = 0.437805	array([[ 3.2356362, -8.988151 ]], dtype=float32)
time = 17060	action = 0	current_phase = 0	next_phase = 1	reward = 0.728662	array([[ 3.035015, -9.18238 ]], dtype=float32)
time = 17065	action = 0	current_phase = 0	next_phase = 1	reward = 1.004956	array([[ 3.223929, -9.002829]], dtype=float32)
time = 17070	action = 0	current_phase = 0	next_phase = 1	reward = 0.443936	array([[ 3.2232203, -8.98231  ]], dtype=float32)
time = 17075	action = 0	current_phase = 0	next_phase = 1	reward = 1.006633	array([[ 3.2009068, -9.010745 ]], dtype=float32)
time = 17080	action = 0	current_phase = 0	next_phase = 1	reward = 0.721527	array([[ 3.1884027, -9.019813 ]], dtype=float32)
time = 17085	action = 0	current_phase = 0	next_phase = 1	reward = 0.719699	array([[ 3.3086247, -8.925724 ]], dtype=float32)
time = 17090	action = 0	current_phase = 0	next_phase = 1	reward = 0.436378	array([[ 3.223415, -9.014046]], dtype=float32)
time = 17095	action = 0	current_phase = 0	next_phase = 1	reward = 0.454567	array([[ 3.2097874, -9.000557 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 7s - loss: 4.1574 - val_loss: 1.6757
Epoch 2/50
 - 7s - loss: 3.7082 - val_loss: 1.7968
Epoch 3/50
 - 6s - loss: 3.8561 - val_loss: 2.0459
Epoch 4/50
 - 8s - loss: 4.4872 - val_loss: 1.3936
Epoch 5/50
 - 6s - loss: 4.5258 - val_loss: 2.8388
Epoch 6/50
 - 4s - loss: 3.4822 - val_loss: 1.6844
Epoch 7/50
 - 4s - loss: 4.0766 - val_loss: 2.1613
Epoch 8/50
 - 4s - loss: 4.1995 - val_loss: 2.1231
Epoch 9/50
 - 4s - loss: 4.3844 - val_loss: 1.5421
Epoch 10/50
 - 4s - loss: 4.0601 - val_loss: 2.1507
Epoch 11/50
 - 4s - loss: 4.3017 - val_loss: 1.8172
Epoch 12/50
 - 4s - loss: 4.1734 - val_loss: 2.5811
Epoch 13/50
 - 4s - loss: 3.0878 - val_loss: 1.8418
Epoch 14/50
 - 4s - loss: 3.3756 - val_loss: 2.5337
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 17100	action = 0	current_phase = 0	next_phase = 1	reward = 1.287672	array([[ 3.2467384, -9.091816 ]], dtype=float32)
time = 17105	action = 0	current_phase = 0	next_phase = 1	reward = 0.443375	array([[ 3.2839317, -9.008158 ]], dtype=float32)
time = 17110	action = 0	current_phase = 0	next_phase = 1	reward = 1.005910	array([[ 3.2262754, -9.104827 ]], dtype=float32)
time = 17115	action = 0	current_phase = 0	next_phase = 1	reward = 0.726314	array([[ 3.182393, -9.100241]], dtype=float32)
time = 17120	action = 0	current_phase = 0	next_phase = 1	reward = 0.445752	array([[ 3.2016754, -9.072763 ]], dtype=float32)
time = 17125	action = 0	current_phase = 0	next_phase = 1	reward = 1.004929	array([[ 3.338564, -8.981073]], dtype=float32)
time = 17130	action = 0	current_phase = 0	next_phase = 1	reward = 0.441531	array([[ 3.1549134, -9.096238 ]], dtype=float32)
time = 17135	action = 0	current_phase = 0	next_phase = 1	reward = 1.002583	array([[ 3.1655474, -9.0911255]], dtype=float32)
time = 17140	action = 0	current_phase = 0	next_phase = 1	reward = 0.711288	array([[ 3.2766542, -9.004612 ]], dtype=float32)
time = 17145	action = 0	current_phase = 0	next_phase = 1	reward = 0.168756	array([[ 3.2792482, -8.978575 ]], dtype=float32)
time = 17150	action = 0	current_phase = 0	next_phase = 1	reward = 1.296567	array([[ 3.1478405, -9.117752 ]], dtype=float32)
time = 17155	action = 0	current_phase = 0	next_phase = 1	reward = 0.727465	array([[ 3.1581764, -9.035887 ]], dtype=float32)
time = 17160	action = 0	current_phase = 0	next_phase = 1	reward = 0.720591	array([[ 3.3548107, -8.953258 ]], dtype=float32)
time = 17165	action = 0	current_phase = 0	next_phase = 1	reward = 0.728138	array([[ 3.2865257, -8.980755 ]], dtype=float32)
time = 17170	action = 0	current_phase = 0	next_phase = 1	reward = 0.727796	array([[ 3.2291431, -9.0242605]], dtype=float32)
time = 17175	action = 0	current_phase = 0	next_phase = 1	reward = 0.159413	array([[ 3.270876, -8.998934]], dtype=float32)
time = 17180	action = 0	current_phase = 0	next_phase = 1	reward = 1.281807	array([[ 3.2346277, -9.036234 ]], dtype=float32)
time = 17185	action = 0	current_phase = 0	next_phase = 1	reward = 0.713033	array([[ 3.261469, -9.002287]], dtype=float32)
time = 17190	action = 0	current_phase = 0	next_phase = 1	reward = 0.726693	array([[ 3.2748995, -9.0102415]], dtype=float32)
time = 17195	action = 0	current_phase = 0	next_phase = 1	reward = 0.164794	array([[ 3.2174854, -9.050628 ]], dtype=float32)
time = 17200	action = 0	current_phase = 0	next_phase = 1	reward = 1.295865	array([[ 3.3329496, -9.035927 ]], dtype=float32)
time = 17205	action = 0	current_phase = 0	next_phase = 1	reward = 0.719073	array([[ 3.266963, -9.018105]], dtype=float32)
time = 17210	action = 0	current_phase = 0	next_phase = 1	reward = 0.440559	array([[ 3.2611628, -9.011549 ]], dtype=float32)
time = 17215	action = 0	current_phase = 0	next_phase = 1	reward = 1.002569	array([[ 3.2547846, -9.028498 ]], dtype=float32)
time = 17220	action = 0	current_phase = 0	next_phase = 1	reward = 0.721113	array([[ 3.2122536, -9.049161 ]], dtype=float32)
time = 17225	action = 0	current_phase = 0	next_phase = 1	reward = 0.445369	array([[ 3.2774239, -9.001108 ]], dtype=float32)
time = 17230	action = 0	current_phase = 0	next_phase = 1	reward = 1.009274	array([[ 3.3080673, -8.964423 ]], dtype=float32)
time = 17235	action = 0	current_phase = 0	next_phase = 1	reward = 0.731805	array([[ 3.2886333, -8.975598 ]], dtype=float32)
time = 17240	action = 0	current_phase = 0	next_phase = 1	reward = 0.723539	array([[ 3.2843866, -9.020564 ]], dtype=float32)
time = 17245	action = 0	current_phase = 0	next_phase = 1	reward = 0.714917	array([[ 3.3035173, -8.983799 ]], dtype=float32)
time = 17250	action = 0	current_phase = 0	next_phase = 1	reward = 0.435893	array([[ 3.254902, -9.006842]], dtype=float32)
time = 17255	action = 0	current_phase = 0	next_phase = 1	reward = 0.995916	array([[ 3.2205496, -9.053314 ]], dtype=float32)
time = 17260	action = 0	current_phase = 0	next_phase = 1	reward = 0.720409	array([[ 3.314231, -8.965862]], dtype=float32)
time = 17265	action = 0	current_phase = 0	next_phase = 1	reward = 0.446172	array([[ 3.2246618, -9.032138 ]], dtype=float32)
time = 17270	action = 0	current_phase = 0	next_phase = 1	reward = 0.723838	array([[ 3.2538738, -9.0147   ]], dtype=float32)
time = 17275	action = 0	current_phase = 0	next_phase = 1	reward = 1.006384	array([[ 3.177518, -9.096038]], dtype=float32)
time = 17280	action = 0	current_phase = 0	next_phase = 1	reward = 0.440397	array([[ 3.3495464, -8.991483 ]], dtype=float32)
time = 17285	action = 0	current_phase = 0	next_phase = 1	reward = 0.998043	array([[ 3.2304506, -9.089376 ]], dtype=float32)
time = 17290	action = 0	current_phase = 0	next_phase = 1	reward = 0.714106	array([[ 3.3458443, -8.945778 ]], dtype=float32)
time = 17295	action = 0	current_phase = 0	next_phase = 1	reward = 0.449731	array([[ 3.2047834, -9.067244 ]], dtype=float32)
time = 17300	action = 0	current_phase = 0	next_phase = 1	reward = 0.726776	array([[ 3.3388586, -9.003556 ]], dtype=float32)
time = 17305	action = 0	current_phase = 0	next_phase = 1	reward = 0.721610	array([[ 3.255786, -9.065586]], dtype=float32)
time = 17310	action = 0	current_phase = 0	next_phase = 1	reward = 0.722341	array([[ 3.295823 , -8.9852495]], dtype=float32)
time = 17315	action = 0	current_phase = 0	next_phase = 1	reward = 1.011266	array([[ 3.2076092, -9.052801 ]], dtype=float32)
time = 17320	action = 0	current_phase = 0	next_phase = 1	reward = 0.726776	array([[ 3.210888, -9.059131]], dtype=float32)
time = 17325	action = 0	current_phase = 0	next_phase = 1	reward = 0.730907	array([[ 3.2175283, -9.042077 ]], dtype=float32)
time = 17330	action = 0	current_phase = 0	next_phase = 1	reward = 0.726131	array([[ 3.245513, -9.042582]], dtype=float32)
time = 17335	action = 0	current_phase = 0	next_phase = 1	reward = 0.722557	array([[ 3.17309 , -9.079426]], dtype=float32)
time = 17340	action = 0	current_phase = 0	next_phase = 1	reward = 0.710824	array([[ 3.1983023, -9.066135 ]], dtype=float32)
time = 17345	action = 0	current_phase = 0	next_phase = 1	reward = 0.717251	array([[ 3.24825 , -9.035458]], dtype=float32)
time = 17350	action = 0	current_phase = 0	next_phase = 1	reward = 0.717700	array([[ 3.2323513, -9.043945 ]], dtype=float32)
time = 17355	action = 0	current_phase = 0	next_phase = 1	reward = 0.717467	array([[ 3.2935028, -8.975672 ]], dtype=float32)
time = 17360	action = 0	current_phase = 0	next_phase = 1	reward = 0.453522	array([[ 3.2663088, -9.009003 ]], dtype=float32)
time = 17365	action = 0	current_phase = 0	next_phase = 1	reward = 1.002094	array([[ 3.2441797, -9.041124 ]], dtype=float32)
time = 17370	action = 0	current_phase = 0	next_phase = 1	reward = 0.717670	array([[ 3.2036753, -9.048807 ]], dtype=float32)
time = 17375	action = 0	current_phase = 0	next_phase = 1	reward = 0.724533	array([[ 3.2838335, -8.994254 ]], dtype=float32)
time = 17380	action = 0	current_phase = 0	next_phase = 1	reward = 0.441511	array([[ 3.2484608, -9.024179 ]], dtype=float32)
time = 17385	action = 0	current_phase = 0	next_phase = 1	reward = 0.722786	array([[ 3.1989193, -9.108828 ]], dtype=float32)
time = 17390	action = 0	current_phase = 0	next_phase = 1	reward = 1.000524	array([[ 3.2786293, -9.067892 ]], dtype=float32)
time = 17395	action = 0	current_phase = 0	next_phase = 1	reward = 0.448372	array([[ 3.2647142, -9.0091915]], dtype=float32)

Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.1117 - val_loss: 2.3819
Epoch 2/50
 - 4s - loss: 3.9105 - val_loss: 2.7284
Epoch 3/50
 - 4s - loss: 3.3158 - val_loss: 2.6004
Epoch 4/50
 - 5s - loss: 3.5391 - val_loss: 2.8025
Epoch 5/50
 - 4s - loss: 3.6005 - val_loss: 3.2956
Epoch 6/50
 - 4s - loss: 4.5258 - val_loss: 2.7516
Epoch 7/50
 - 4s - loss: 3.9133 - val_loss: 2.2779
Epoch 8/50
 - 4s - loss: 3.3416 - val_loss: 3.8057
Epoch 9/50
 - 14s - loss: 3.5890 - val_loss: 2.3404
Epoch 10/50
 - 4s - loss: 3.4246 - val_loss: 2.2207
Epoch 11/50
 - 4s - loss: 4.2360 - val_loss: 2.4786
Epoch 12/50
 - 4s - loss: 4.9318 - val_loss: 2.9351
Epoch 13/50
 - 4s - loss: 3.2932 - val_loss: 2.4965
Epoch 14/50
 - 4s - loss: 3.0237 - val_loss: 3.2619
Epoch 15/50
 - 4s - loss: 2.8887 - val_loss: 3.0847
Epoch 16/50
 - 4s - loss: 3.4430 - val_loss: 2.1986
Epoch 17/50
 - 4s - loss: 3.6875 - val_loss: 2.3331
Epoch 18/50
 - 4s - loss: 3.5279 - val_loss: 2.2503
Epoch 19/50
 - 4s - loss: 3.6426 - val_loss: 2.4177
Epoch 20/50
 - 4s - loss: 3.4060 - val_loss: 2.4463
Epoch 21/50
 - 5s - loss: 3.4361 - val_loss: 3.7692
Epoch 22/50
 - 4s - loss: 3.1882 - val_loss: 3.3311
Epoch 23/50
 - 5s - loss: 4.7991 - val_loss: 3.5967
Epoch 24/50
 - 4s - loss: 2.9149 - val_loss: 3.2944
Epoch 25/50
 - 5s - loss: 3.0322 - val_loss: 3.6245
Epoch 26/50
 - 4s - loss: 3.1313 - val_loss: 3.0998
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 17400	action = 0	current_phase = 0	next_phase = 1	reward = 1.005808	array([[ 3.2285972, -9.134243 ]], dtype=float32)
time = 17405	action = 0	current_phase = 0	next_phase = 1	reward = 0.727899	array([[ 3.2882953, -9.0756   ]], dtype=float32)
time = 17410	action = 0	current_phase = 0	next_phase = 1	reward = 0.728605	array([[ 3.3431382, -9.0236225]], dtype=float32)
time = 17415	action = 0	current_phase = 0	next_phase = 1	reward = 0.720819	array([[ 3.3265586, -9.171902 ]], dtype=float32)
time = 17420	action = 0	current_phase = 0	next_phase = 1	reward = 0.442340	array([[ 3.2992625, -9.06111  ]], dtype=float32)
time = 17425	action = 0	current_phase = 0	next_phase = 1	reward = 1.003823	array([[ 3.3362374, -9.077238 ]], dtype=float32)
time = 17430	action = 0	current_phase = 0	next_phase = 1	reward = 0.729275	array([[ 3.3629622, -9.003817 ]], dtype=float32)
time = 17435	action = 0	current_phase = 0	next_phase = 1	reward = 0.723687	array([[ 3.2796454, -9.08876  ]], dtype=float32)
time = 17440	action = 0	current_phase = 0	next_phase = 1	reward = 0.720603	array([[ 3.276567, -9.113327]], dtype=float32)
time = 17445	action = 0	current_phase = 0	next_phase = 1	reward = 0.728686	array([[ 3.2681117, -9.07303  ]], dtype=float32)
time = 17450	action = 0	current_phase = 0	next_phase = 1	reward = 0.724463	array([[ 3.2257895, -9.11293  ]], dtype=float32)
time = 17455	action = 0	current_phase = 0	next_phase = 1	reward = 0.720181	array([[ 3.340919, -9.034488]], dtype=float32)
time = 17460	action = 0	current_phase = 0	next_phase = 1	reward = 0.444399	array([[ 3.2316823, -9.120674 ]], dtype=float32)
time = 17465	action = 0	current_phase = 0	next_phase = 1	reward = 1.005514	array([[ 3.281322, -9.101212]], dtype=float32)
time = 17470	action = 0	current_phase = 0	next_phase = 1	reward = 0.442830	array([[ 3.286017 , -9.0612545]], dtype=float32)
time = 17475	action = 0	current_phase = 0	next_phase = 1	reward = 1.002137	array([[ 3.30444 , -9.038274]], dtype=float32)
time = 17480	action = 0	current_phase = 0	next_phase = 1	reward = 0.719304	array([[ 3.3737702, -9.042239 ]], dtype=float32)
time = 17485	action = 0	current_phase = 0	next_phase = 1	reward = 0.437980	array([[ 3.3569093, -9.034933 ]], dtype=float32)
time = 17490	action = 0	current_phase = 0	next_phase = 1	reward = 0.723898	array([[ 3.323997, -9.094754]], dtype=float32)
time = 17495	action = 0	current_phase = 0	next_phase = 1	reward = 1.009164	array([[ 3.3054242, -9.056957 ]], dtype=float32)
time = 17500	action = 0	current_phase = 0	next_phase = 1	reward = 0.716584	array([[ 3.2894092, -9.055382 ]], dtype=float32)
time = 17505	action = 0	current_phase = 0	next_phase = 1	reward = 0.726482	array([[ 3.333325, -9.025269]], dtype=float32)
time = 17510	action = 0	current_phase = 0	next_phase = 1	reward = 0.443355	array([[ 3.3478007, -9.010004 ]], dtype=float32)
time = 17515	action = 0	current_phase = 0	next_phase = 1	reward = 0.721611	array([[ 3.2775807, -9.127035 ]], dtype=float32)
time = 17520	action = 0	current_phase = 0	next_phase = 1	reward = 0.999969	array([[ 3.3499875, -9.082867 ]], dtype=float32)
time = 17525	action = 0	current_phase = 0	next_phase = 1	reward = 0.724676	array([[ 3.3021874, -9.074265 ]], dtype=float32)
time = 17530	action = 0	current_phase = 0	next_phase = 1	reward = 0.444471	array([[ 3.3017669, -9.125599 ]], dtype=float32)
time = 17535	action = 0	current_phase = 0	next_phase = 1	reward = 1.005038	array([[ 3.3394122, -9.101454 ]], dtype=float32)
time = 17540	action = 0	current_phase = 0	next_phase = 1	reward = 0.442544	array([[ 3.3329415, -9.055671 ]], dtype=float32)
time = 17545	action = 0	current_phase = 0	next_phase = 1	reward = 1.004285	array([[ 3.3362164, -9.023495 ]], dtype=float32)
time = 17550	action = 0	current_phase = 0	next_phase = 1	reward = 0.718975	array([[ 3.2281766, -9.142788 ]], dtype=float32)
time = 17555	action = 0	current_phase = 0	next_phase = 1	reward = 0.718770	array([[ 3.390387, -9.013308]], dtype=float32)
time = 17560	action = 0	current_phase = 0	next_phase = 1	reward = 0.725369	array([[ 3.2827802, -9.073432 ]], dtype=float32)
time = 17565	action = 0	current_phase = 0	next_phase = 1	reward = 0.723837	array([[ 3.2630696, -9.096797 ]], dtype=float32)
time = 17570	action = 0	current_phase = 0	next_phase = 1	reward = 0.715994	array([[ 3.3754916, -8.999728 ]], dtype=float32)
time = 17575	action = 0	current_phase = 0	next_phase = 1	reward = 0.434432	array([[ 3.2510152, -9.082905 ]], dtype=float32)
time = 17580	action = 0	current_phase = 0	next_phase = 1	reward = 0.721989	array([[ 3.325561, -9.207291]], dtype=float32)
time = 17585	action = 0	current_phase = 0	next_phase = 1	reward = 0.447784	array([[ 3.2754607, -9.125452 ]], dtype=float32)
time = 17590	action = 0	current_phase = 0	next_phase = 1	reward = 1.285137	array([[ 3.3328404, -9.084737 ]], dtype=float32)
time = 17595	action = 0	current_phase = 0	next_phase = 1	reward = 0.443860	array([[ 3.339562, -9.067336]], dtype=float32)
time = 17600	action = 0	current_phase = 0	next_phase = 1	reward = 0.999156	array([[ 3.3726668, -9.013561 ]], dtype=float32)
time = 17605	action = 0	current_phase = 0	next_phase = 1	reward = 0.434642	array([[ 3.3024802, -9.10466  ]], dtype=float32)
time = 17610	action = 0	current_phase = 0	next_phase = 1	reward = 1.001901	array([[ 3.320703, -9.041634]], dtype=float32)
time = 17615	action = 0	current_phase = 0	next_phase = 1	reward = 0.735096	array([[ 3.3102708, -9.073305 ]], dtype=float32)
time = 17620	action = 0	current_phase = 0	next_phase = 1	reward = 0.736451	array([[ 3.2704453, -9.064786 ]], dtype=float32)
time = 17625	action = 0	current_phase = 0	next_phase = 1	reward = 0.724905	array([[ 3.288692, -9.082491]], dtype=float32)
time = 17630	action = 0	current_phase = 0	next_phase = 1	reward = 0.446619	array([[ 3.2715898, -9.050579 ]], dtype=float32)
time = 17635	action = 0	current_phase = 0	next_phase = 1	reward = 1.003940	array([[ 3.2910972, -9.094036 ]], dtype=float32)
time = 17640	action = 0	current_phase = 0	next_phase = 1	reward = 0.438779	array([[ 3.3862615, -9.040144 ]], dtype=float32)
time = 17645	action = 0	current_phase = 0	next_phase = 1	reward = 0.727184	array([[ 3.1974435, -9.224176 ]], dtype=float32)
time = 17650	action = 0	current_phase = 0	next_phase = 1	reward = 0.731669	array([[ 3.3696618, -9.025213 ]], dtype=float32)
time = 17655	action = 0	current_phase = 0	next_phase = 1	reward = 1.002784	array([[ 3.2646089, -9.080444 ]], dtype=float32)
time = 17660	action = 0	current_phase = 0	next_phase = 1	reward = 0.723782	array([[ 3.321033, -9.073753]], dtype=float32)
time = 17665	action = 0	current_phase = 0	next_phase = 1	reward = 0.441945	array([[ 3.236404, -9.105389]], dtype=float32)
time = 17670	action = 0	current_phase = 0	next_phase = 1	reward = 1.004764	array([[ 3.2122703, -9.127832 ]], dtype=float32)
time = 17675	action = 0	current_phase = 0	next_phase = 1	reward = 0.446173	array([[ 3.3208308, -9.02804  ]], dtype=float32)
time = 17680	action = 0	current_phase = 0	next_phase = 1	reward = 1.006827	array([[ 3.252027, -9.101124]], dtype=float32)
time = 17685	action = 0	current_phase = 0	next_phase = 1	reward = 0.444663	array([[ 3.312347, -9.056269]], dtype=float32)
time = 17690	action = 0	current_phase = 0	next_phase = 1	reward = 1.003396	array([[ 3.287681, -9.085776]], dtype=float32)
time = 17695	action = 0	current_phase = 0	next_phase = 1	reward = 0.718376	array([[ 3.3602605, -9.063162 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.6351 - val_loss: 2.2837
Epoch 2/50
 - 4s - loss: 3.9690 - val_loss: 2.2438
Epoch 3/50
 - 4s - loss: 2.9281 - val_loss: 1.8043
Epoch 4/50
 - 4s - loss: 3.1282 - val_loss: 2.2094
Epoch 5/50
 - 4s - loss: 2.8564 - val_loss: 1.6639
Epoch 6/50
 - 4s - loss: 3.1459 - val_loss: 1.8097
Epoch 7/50
 - 4s - loss: 3.0321 - val_loss: 1.8723
Epoch 8/50
 - 4s - loss: 3.1227 - val_loss: 2.1592
Epoch 9/50
 - 4s - loss: 3.0393 - val_loss: 2.1201
Epoch 10/50
 - 4s - loss: 3.3671 - val_loss: 1.7515
Epoch 11/50
 - 4s - loss: 3.3190 - val_loss: 2.0495
Epoch 12/50
 - 4s - loss: 2.6872 - val_loss: 2.0569
Epoch 13/50
 - 4s - loss: 2.8798 - val_loss: 1.8295
Epoch 14/50
 - 4s - loss: 3.0999 - val_loss: 1.7427
Epoch 15/50
 - 4s - loss: 3.7018 - val_loss: 1.8194
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 17700	action = 0	current_phase = 0	next_phase = 1	reward = 0.720492	array([[ 3.2550526, -9.066894 ]], dtype=float32)
time = 17705	action = 0	current_phase = 0	next_phase = 1	reward = 0.720532	array([[ 3.3318577, -9.044096 ]], dtype=float32)
time = 17710	action = 0	current_phase = 0	next_phase = 1	reward = 0.443651	array([[ 3.217061, -9.114519]], dtype=float32)
time = 17715	action = 0	current_phase = 0	next_phase = 1	reward = 1.005445	array([[ 3.2193584, -9.102707 ]], dtype=float32)
time = 17720	action = 0	current_phase = 0	next_phase = 1	reward = 0.725686	array([[ 3.2329283, -9.082834 ]], dtype=float32)
time = 17725	action = 0	current_phase = 0	next_phase = 1	reward = 0.721956	array([[ 3.2155151, -9.109564 ]], dtype=float32)
time = 17730	action = 0	current_phase = 0	next_phase = 1	reward = 0.718844	array([[ 3.2548704, -9.05769  ]], dtype=float32)
time = 17735	action = 0	current_phase = 0	next_phase = 1	reward = 0.723403	array([[ 3.2456493, -9.091946 ]], dtype=float32)
time = 17740	action = 0	current_phase = 0	next_phase = 1	reward = 0.443004	array([[ 3.3017616, -9.003862 ]], dtype=float32)
time = 17745	action = 0	current_phase = 0	next_phase = 1	reward = 1.001743	array([[ 3.2680979, -9.102871 ]], dtype=float32)
time = 17750	action = 0	current_phase = 0	next_phase = 1	reward = 0.718095	array([[ 3.3473024, -9.021057 ]], dtype=float32)
time = 17755	action = 0	current_phase = 0	next_phase = 1	reward = 0.728558	array([[ 3.2539587, -9.064289 ]], dtype=float32)
time = 17760	action = 0	current_phase = 0	next_phase = 1	reward = 0.728912	array([[ 3.2115192, -9.091622 ]], dtype=float32)
time = 17765	action = 0	current_phase = 0	next_phase = 1	reward = 0.725608	array([[ 3.2545328, -9.089098 ]], dtype=float32)
time = 17770	action = 0	current_phase = 0	next_phase = 1	reward = 0.441384	array([[ 3.2975616, -9.017117 ]], dtype=float32)
time = 17775	action = 0	current_phase = 0	next_phase = 1	reward = 0.724502	array([[ 3.166441, -9.148301]], dtype=float32)
time = 17780	action = 0	current_phase = 0	next_phase = 1	reward = 0.724074	array([[ 3.2774363, -9.064892 ]], dtype=float32)
time = 17785	action = 0	current_phase = 0	next_phase = 1	reward = 1.012442	array([[ 3.3126698, -9.048244 ]], dtype=float32)
time = 17790	action = 0	current_phase = 0	next_phase = 1	reward = 0.729580	array([[ 3.3432207, -9.043625 ]], dtype=float32)
time = 17795	action = 0	current_phase = 0	next_phase = 1	reward = 0.721188	array([[ 3.351201, -9.280882]], dtype=float32)
time = 17800	action = 0	current_phase = 0	next_phase = 1	reward = 0.718673	array([[ 3.3175974, -9.018523 ]], dtype=float32)
time = 17805	action = 0	current_phase = 0	next_phase = 1	reward = 0.712924	array([[ 3.251525, -9.079739]], dtype=float32)
time = 17810	action = 0	current_phase = 0	next_phase = 1	reward = 0.442111	array([[ 3.3037977, -9.029509 ]], dtype=float32)
time = 17815	action = 0	current_phase = 0	next_phase = 1	reward = 1.001852	array([[ 3.2769327, -9.073414 ]], dtype=float32)
time = 17820	action = 0	current_phase = 0	next_phase = 1	reward = 0.716182	array([[ 3.271617, -9.085452]], dtype=float32)
time = 17825	action = 0	current_phase = 0	next_phase = 1	reward = 0.439103	array([[ 3.2647629, -9.047483 ]], dtype=float32)
time = 17830	action = 0	current_phase = 0	next_phase = 1	reward = 0.727793	array([[ 3.2746458, -9.05246  ]], dtype=float32)
time = 17835	action = 0	current_phase = 0	next_phase = 1	reward = 0.739730	array([[ 3.2856665, -9.1400585]], dtype=float32)
time = 17840	action = 0	current_phase = 0	next_phase = 1	reward = 1.008620	array([[ 3.3468952, -9.122631 ]], dtype=float32)
time = 17845	action = 0	current_phase = 0	next_phase = 1	reward = 0.723613	array([[ 3.270215, -9.058571]], dtype=float32)
time = 17850	action = 0	current_phase = 0	next_phase = 1	reward = 0.722106	array([[ 3.3287363, -9.012517 ]], dtype=float32)
time = 17855	action = 0	current_phase = 0	next_phase = 1	reward = 0.714568	array([[ 3.3211231, -9.171282 ]], dtype=float32)
time = 17860	action = 0	current_phase = 0	next_phase = 1	reward = 0.719621	array([[ 3.3277178, -9.063259 ]], dtype=float32)
time = 17865	action = 0	current_phase = 0	next_phase = 1	reward = 0.725378	array([[ 3.1907053, -9.11998  ]], dtype=float32)
time = 17870	action = 0	current_phase = 0	next_phase = 1	reward = 0.720474	array([[ 3.1937037, -9.117344 ]], dtype=float32)
time = 17875	action = 0	current_phase = 0	next_phase = 1	reward = 0.722819	array([[ 3.253521, -9.063547]], dtype=float32)
time = 17880	action = 0	current_phase = 0	next_phase = 1	reward = 0.722872	array([[ 3.35808 , -9.034378]], dtype=float32)
time = 17885	action = 0	current_phase = 0	next_phase = 1	reward = 0.722109	array([[ 3.2924519, -9.0213375]], dtype=float32)
time = 17890	action = 0	current_phase = 0	next_phase = 1	reward = 0.732656	array([[ 3.2682943, -9.051554 ]], dtype=float32)
time = 17895	action = 0	current_phase = 0	next_phase = 1	reward = 0.724712	array([[ 3.2601662, -9.106094 ]], dtype=float32)
time = 17900	action = 0	current_phase = 0	next_phase = 1	reward = 0.724819	array([[ 3.3323975, -9.03149  ]], dtype=float32)
time = 17905	action = 0	current_phase = 0	next_phase = 1	reward = 0.723146	array([[ 3.3069458, -9.033201 ]], dtype=float32)
time = 17910	action = 0	current_phase = 0	next_phase = 1	reward = 0.726740	array([[ 3.2908678, -9.028563 ]], dtype=float32)
time = 17915	action = 0	current_phase = 0	next_phase = 1	reward = 0.725140	array([[ 3.255208, -9.0892  ]], dtype=float32)
time = 17920	action = 0	current_phase = 0	next_phase = 1	reward = 0.734149	array([[ 3.2142973, -9.077205 ]], dtype=float32)
time = 17925	action = 0	current_phase = 0	next_phase = 1	reward = 0.725823	array([[ 3.331092, -9.068726]], dtype=float32)
time = 17930	action = 0	current_phase = 0	next_phase = 1	reward = 0.716944	array([[ 3.2602892, -9.038881 ]], dtype=float32)
time = 17935	action = 0	current_phase = 0	next_phase = 1	reward = 0.720377	array([[ 3.335701, -9.064935]], dtype=float32)
time = 17940	action = 0	current_phase = 0	next_phase = 1	reward = 0.443015	array([[ 3.3378868, -9.007999 ]], dtype=float32)
time = 17945	action = 0	current_phase = 0	next_phase = 1	reward = 1.006329	array([[ 3.383748, -9.026188]], dtype=float32)
time = 17950	action = 0	current_phase = 0	next_phase = 1	reward = 0.723720	array([[ 3.271923, -9.039152]], dtype=float32)
time = 17955	action = 0	current_phase = 0	next_phase = 1	reward = 0.722781	array([[ 3.2953749, -9.043034 ]], dtype=float32)
time = 17960	action = 0	current_phase = 0	next_phase = 1	reward = 0.449142	array([[ 3.2248697, -9.082678 ]], dtype=float32)
time = 17965	action = 0	current_phase = 0	next_phase = 1	reward = 1.009711	array([[ 3.2535543, -9.057608 ]], dtype=float32)
time = 17970	action = 0	current_phase = 0	next_phase = 1	reward = 0.722409	array([[ 3.229762, -9.101982]], dtype=float32)
time = 17975	action = 0	current_phase = 0	next_phase = 1	reward = 0.724247	array([[ 3.3487787, -9.002338 ]], dtype=float32)
time = 17980	action = 0	current_phase = 0	next_phase = 1	reward = 0.729493	array([[ 3.2481089, -9.093893 ]], dtype=float32)
time = 17985	action = 0	current_phase = 0	next_phase = 1	reward = 0.718605	array([[ 3.3719597, -9.00415  ]], dtype=float32)
time = 17990	action = 0	current_phase = 0	next_phase = 1	reward = 0.723437	array([[ 3.3128014, -9.005264 ]], dtype=float32)
time = 17995	action = 0	current_phase = 0	next_phase = 1	reward = 0.716621	array([[ 3.256669, -9.074324]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.9721 - val_loss: 3.0578
Epoch 2/50
 - 4s - loss: 4.5523 - val_loss: 2.2113
Epoch 3/50
 - 4s - loss: 3.6874 - val_loss: 1.8971
Epoch 4/50
 - 4s - loss: 3.3897 - val_loss: 2.4167
Epoch 5/50
 - 4s - loss: 4.5713 - val_loss: 2.4692
Epoch 6/50
 - 4s - loss: 4.3771 - val_loss: 2.8572
Epoch 7/50
 - 4s - loss: 4.0440 - val_loss: 1.7709
Epoch 8/50
 - 4s - loss: 4.0755 - val_loss: 2.2306
Epoch 9/50
 - 4s - loss: 3.6213 - val_loss: 2.4193
Epoch 10/50
 - 4s - loss: 3.6829 - val_loss: 2.1227
Epoch 11/50
 - 4s - loss: 3.9268 - val_loss: 2.4621
Epoch 12/50
 - 4s - loss: 3.9608 - val_loss: 2.6186
Epoch 13/50
 - 4s - loss: 3.4170 - val_loss: 1.8581
Epoch 14/50
 - 4s - loss: 4.1768 - val_loss: 2.3413
Epoch 15/50
 - 4s - loss: 3.9933 - val_loss: 2.8841
Epoch 16/50
 - 4s - loss: 3.7598 - val_loss: 3.0013
Epoch 17/50
 - 4s - loss: 3.4478 - val_loss: 2.1295
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 18000	action = 0	current_phase = 0	next_phase = 1	reward = 0.447276	array([[ 3.2650318, -9.157276 ]], dtype=float32)
time = 18005	action = 0	current_phase = 0	next_phase = 1	reward = 1.001116	array([[ 3.323825, -9.146746]], dtype=float32)
time = 18010	action = 0	current_phase = 0	next_phase = 1	reward = 0.715244	array([[ 3.235797, -9.152744]], dtype=float32)
time = 18015	action = 0	current_phase = 0	next_phase = 1	reward = 0.441984	array([[ 3.30659 , -9.079079]], dtype=float32)
time = 18020	action = 0	current_phase = 0	next_phase = 1	reward = 1.010091	array([[ 3.2703962, -9.120472 ]], dtype=float32)
time = 18025	action = 0	current_phase = 0	next_phase = 1	reward = 0.730213	array([[ 3.3492079, -9.093466 ]], dtype=float32)
time = 18030	action = 0	current_phase = 0	next_phase = 1	reward = 0.725848	array([[ 3.3370752, -9.083769 ]], dtype=float32)
time = 18035	action = 0	current_phase = 0	next_phase = 1	reward = 0.722730	array([[ 3.3407688, -9.071808 ]], dtype=float32)
time = 18040	action = 0	current_phase = 0	next_phase = 1	reward = 0.720925	array([[ 3.2636843, -9.136393 ]], dtype=float32)
time = 18045	action = 0	current_phase = 0	next_phase = 1	reward = 0.725061	array([[ 3.3138561, -9.118917 ]], dtype=float32)
time = 18050	action = 0	current_phase = 0	next_phase = 1	reward = 0.721190	array([[ 3.300418, -9.164547]], dtype=float32)
time = 18055	action = 0	current_phase = 0	next_phase = 1	reward = 0.725588	array([[ 3.3366718, -9.081625 ]], dtype=float32)
time = 18060	action = 0	current_phase = 0	next_phase = 1	reward = 0.719574	array([[ 3.3234415, -9.139324 ]], dtype=float32)
time = 18065	action = 0	current_phase = 0	next_phase = 1	reward = 0.720711	array([[ 3.3006926, -9.108726 ]], dtype=float32)
time = 18070	action = 0	current_phase = 0	next_phase = 1	reward = 0.726918	array([[ 3.2955542, -9.121061 ]], dtype=float32)
time = 18075	action = 0	current_phase = 0	next_phase = 1	reward = 0.723672	array([[ 3.2987642, -9.126993 ]], dtype=float32)
time = 18080	action = 0	current_phase = 0	next_phase = 1	reward = 0.734319	array([[ 3.2697945, -9.136494 ]], dtype=float32)
time = 18085	action = 0	current_phase = 0	next_phase = 1	reward = 0.721914	array([[ 3.2579184, -9.165282 ]], dtype=float32)
time = 18090	action = 0	current_phase = 0	next_phase = 1	reward = 0.443580	array([[ 3.271058, -9.131321]], dtype=float32)
time = 18095	action = 0	current_phase = 0	next_phase = 1	reward = 1.004625	array([[ 3.2641697, -9.177839 ]], dtype=float32)
time = 18100	action = 0	current_phase = 0	next_phase = 1	reward = 0.170213	array([[ 3.3276148, -9.147822 ]], dtype=float32)
time = 18105	action = 0	current_phase = 0	next_phase = 1	reward = 1.010295	array([[ 3.2758083, -9.148113 ]], dtype=float32)
time = 18110	action = 0	current_phase = 0	next_phase = 1	reward = 1.000957	array([[ 3.2596226, -9.164339 ]], dtype=float32)
time = 18115	action = 0	current_phase = 0	next_phase = 1	reward = 0.442461	array([[ 3.2589025, -9.133524 ]], dtype=float32)
time = 18120	action = 0	current_phase = 0	next_phase = 1	reward = 0.726711	array([[ 3.204939, -9.199783]], dtype=float32)
time = 18125	action = 0	current_phase = 0	next_phase = 1	reward = 1.004893	array([[ 3.3367863, -9.133634 ]], dtype=float32)
time = 18130	action = 0	current_phase = 0	next_phase = 1	reward = 0.719188	array([[ 3.3218393, -9.097328 ]], dtype=float32)
time = 18135	action = 0	current_phase = 0	next_phase = 1	reward = 0.722306	array([[ 3.2677774, -9.140995 ]], dtype=float32)
time = 18140	action = 0	current_phase = 0	next_phase = 1	reward = 0.716309	array([[ 3.3845644, -9.3784   ]], dtype=float32)
time = 18145	action = 0	current_phase = 0	next_phase = 1	reward = 0.447871	array([[ 3.2824202, -9.122927 ]], dtype=float32)
time = 18150	action = 0	current_phase = 0	next_phase = 1	reward = 0.735577	array([[ 3.2986116, -9.144699 ]], dtype=float32)
time = 18155	action = 0	current_phase = 0	next_phase = 1	reward = 1.004552	array([[ 3.3411188, -9.112982 ]], dtype=float32)
time = 18160	action = 0	current_phase = 0	next_phase = 1	reward = 0.446673	array([[ 3.310524, -9.08522 ]], dtype=float32)
time = 18165	action = 0	current_phase = 0	next_phase = 1	reward = 1.004295	array([[ 3.2473755, -9.152134 ]], dtype=float32)
time = 18170	action = 0	current_phase = 0	next_phase = 1	reward = 0.718194	array([[ 3.2753448, -9.153202 ]], dtype=float32)
time = 18175	action = 0	current_phase = 0	next_phase = 1	reward = 0.727178	array([[ 3.3046227, -9.120716 ]], dtype=float32)
time = 18180	action = 0	current_phase = 0	next_phase = 1	reward = 0.725471	array([[ 3.3109808, -9.082769 ]], dtype=float32)
time = 18185	action = 0	current_phase = 0	next_phase = 1	reward = 0.723524	array([[ 3.3337402, -9.110069 ]], dtype=float32)
time = 18190	action = 0	current_phase = 0	next_phase = 1	reward = 0.720562	array([[ 3.3083792, -9.087791 ]], dtype=float32)
time = 18195	action = 0	current_phase = 0	next_phase = 1	reward = 0.724525	array([[ 3.2870312, -9.133039 ]], dtype=float32)
time = 18200	action = 0	current_phase = 0	next_phase = 1	reward = 0.721164	array([[ 3.272458, -9.118815]], dtype=float32)
time = 18205	action = 0	current_phase = 0	next_phase = 1	reward = 0.729765	array([[ 3.3869019, -9.070896 ]], dtype=float32)
time = 18210	action = 0	current_phase = 0	next_phase = 1	reward = 0.731441	array([[ 3.2414427, -9.173684 ]], dtype=float32)
time = 18215	action = 0	current_phase = 0	next_phase = 1	reward = 0.441075	array([[ 3.3064651, -9.109775 ]], dtype=float32)
time = 18220	action = 0	current_phase = 0	next_phase = 1	reward = 1.008123	array([[ 3.3176327, -9.139004 ]], dtype=float32)
time = 18225	action = 0	current_phase = 0	next_phase = 1	reward = 0.722443	array([[ 3.3743486, -9.129494 ]], dtype=float32)
time = 18230	action = 0	current_phase = 0	next_phase = 1	reward = 0.440045	array([[ 3.3073263, -9.087682 ]], dtype=float32)
time = 18235	action = 0	current_phase = 0	next_phase = 1	reward = 0.729516	array([[ 3.241661, -9.178581]], dtype=float32)
time = 18240	action = 0	current_phase = 0	next_phase = 1	reward = 0.726873	array([[ 3.264017, -9.13883 ]], dtype=float32)
time = 18245	action = 0	current_phase = 0	next_phase = 1	reward = 1.003833	array([[ 3.2440844, -9.174423 ]], dtype=float32)
time = 18250	action = 0	current_phase = 0	next_phase = 1	reward = 0.725874	array([[ 3.2857656, -9.195831 ]], dtype=float32)
time = 18255	action = 0	current_phase = 0	next_phase = 1	reward = 0.444017	array([[ 3.27631 , -9.193705]], dtype=float32)
time = 18260	action = 0	current_phase = 0	next_phase = 1	reward = 0.725762	array([[ 3.2318478, -9.154839 ]], dtype=float32)
time = 18265	action = 0	current_phase = 0	next_phase = 1	reward = 0.726386	array([[ 3.2034664, -9.220797 ]], dtype=float32)
time = 18270	action = 0	current_phase = 0	next_phase = 1	reward = 1.007559	array([[ 3.2718678, -9.145529 ]], dtype=float32)
time = 18275	action = 0	current_phase = 0	next_phase = 1	reward = 0.720967	array([[ 3.363181, -9.086185]], dtype=float32)
time = 18280	action = 0	current_phase = 0	next_phase = 1	reward = 0.722922	array([[ 3.2950487, -9.096268 ]], dtype=float32)
time = 18285	action = 0	current_phase = 0	next_phase = 1	reward = 0.441205	array([[ 3.316329, -9.170113]], dtype=float32)
time = 18290	action = 0	current_phase = 0	next_phase = 1	reward = 1.002299	array([[ 3.239606, -9.142904]], dtype=float32)
time = 18295	action = 0	current_phase = 0	next_phase = 1	reward = 0.442964	array([[ 3.3328762, -9.068575 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.0267 - val_loss: 3.1806
Epoch 2/50
 - 4s - loss: 5.5394 - val_loss: 2.6760
Epoch 3/50
 - 4s - loss: 4.4721 - val_loss: 3.0082
Epoch 4/50
 - 4s - loss: 4.1298 - val_loss: 3.2956
Epoch 5/50
 - 4s - loss: 3.5023 - val_loss: 3.7906
Epoch 6/50
 - 4s - loss: 4.0434 - val_loss: 3.1505
Epoch 7/50
 - 4s - loss: 4.1650 - val_loss: 3.0174
Epoch 8/50
 - 4s - loss: 3.8319 - val_loss: 2.7083
Epoch 9/50
 - 4s - loss: 3.3204 - val_loss: 3.2361
Epoch 10/50
 - 4s - loss: 3.9597 - val_loss: 3.0769
Epoch 11/50
 - 4s - loss: 4.3922 - val_loss: 2.8279
Epoch 12/50
 - 4s - loss: 4.5065 - val_loss: 2.8588
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 18300	action = 0	current_phase = 0	next_phase = 1	reward = 1.004413	array([[ 3.209014, -9.402515]], dtype=float32)
time = 18305	action = 0	current_phase = 0	next_phase = 1	reward = 0.442618	array([[ 3.4623327, -9.127719 ]], dtype=float32)
time = 18310	action = 0	current_phase = 0	next_phase = 1	reward = 1.003661	array([[ 3.382162, -9.183674]], dtype=float32)
time = 18315	action = 0	current_phase = 0	next_phase = 1	reward = 0.720734	array([[ 3.5092201, -9.111633 ]], dtype=float32)
time = 18320	action = 0	current_phase = 0	next_phase = 1	reward = 0.719940	array([[ 3.407895, -9.162484]], dtype=float32)
time = 18325	action = 0	current_phase = 0	next_phase = 1	reward = 0.442327	array([[ 3.3947115, -9.169984 ]], dtype=float32)
time = 18330	action = 0	current_phase = 0	next_phase = 1	reward = 0.728721	array([[ 3.3848333, -9.188997 ]], dtype=float32)
time = 18335	action = 0	current_phase = 0	next_phase = 1	reward = 0.731754	array([[ 3.3296976, -9.230265 ]], dtype=float32)
time = 18340	action = 0	current_phase = 0	next_phase = 1	reward = 1.000110	array([[ 3.4460087, -9.185785 ]], dtype=float32)
time = 18345	action = 0	current_phase = 0	next_phase = 1	reward = 0.725657	array([[ 3.448491, -9.129616]], dtype=float32)
time = 18350	action = 0	current_phase = 0	next_phase = 1	reward = 0.448956	array([[ 3.4203768, -9.163423 ]], dtype=float32)
time = 18355	action = 0	current_phase = 0	next_phase = 1	reward = 1.002032	array([[ 3.3233109, -9.242972 ]], dtype=float32)
time = 18360	action = 0	current_phase = 0	next_phase = 1	reward = 0.724337	array([[ 3.4185524, -9.173771 ]], dtype=float32)
time = 18365	action = 0	current_phase = 0	next_phase = 1	reward = 0.441852	array([[ 3.4478827, -9.161938 ]], dtype=float32)
time = 18370	action = 0	current_phase = 0	next_phase = 1	reward = 0.723989	array([[ 3.3348255, -9.216498 ]], dtype=float32)
time = 18375	action = 0	current_phase = 0	next_phase = 1	reward = 0.723427	array([[ 3.3824062, -9.202087 ]], dtype=float32)
time = 18380	action = 0	current_phase = 0	next_phase = 1	reward = 1.003631	array([[ 3.2810974, -9.335351 ]], dtype=float32)
time = 18385	action = 0	current_phase = 0	next_phase = 1	reward = 0.719419	array([[ 3.350896, -9.2297  ]], dtype=float32)
time = 18390	action = 0	current_phase = 0	next_phase = 1	reward = 0.737295	array([[ 3.2632046, -9.303817 ]], dtype=float32)
time = 18395	action = 0	current_phase = 0	next_phase = 1	reward = 0.726588	array([[ 3.35501 , -9.204548]], dtype=float32)
time = 18400	action = 0	current_phase = 0	next_phase = 1	reward = 0.718389	array([[ 3.3179665, -9.235712 ]], dtype=float32)
time = 18405	action = 0	current_phase = 0	next_phase = 1	reward = 0.712441	array([[ 3.3385115, -9.223626 ]], dtype=float32)
time = 18410	action = 0	current_phase = 0	next_phase = 1	reward = 0.728163	array([[ 3.4443283, -9.116912 ]], dtype=float32)
time = 18415	action = 0	current_phase = 0	next_phase = 1	reward = 0.724067	array([[ 3.4198637, -9.153418 ]], dtype=float32)
time = 18420	action = 0	current_phase = 0	next_phase = 1	reward = 0.709862	array([[ 3.420679, -9.152897]], dtype=float32)
time = 18425	action = 0	current_phase = 0	next_phase = 1	reward = 0.722933	array([[ 3.3669558, -9.202102 ]], dtype=float32)
time = 18430	action = 0	current_phase = 0	next_phase = 1	reward = 0.718101	array([[ 3.4342833, -9.127424 ]], dtype=float32)
time = 18435	action = 0	current_phase = 0	next_phase = 1	reward = 0.445027	array([[ 3.4431705, -9.151712 ]], dtype=float32)
time = 18440	action = 0	current_phase = 0	next_phase = 1	reward = 1.008352	array([[ 3.4326353, -9.1568575]], dtype=float32)
time = 18445	action = 0	current_phase = 0	next_phase = 1	reward = 0.723619	array([[ 3.4199972, -9.202075 ]], dtype=float32)
time = 18450	action = 0	current_phase = 0	next_phase = 1	reward = 0.171584	array([[ 3.3870068, -9.176109 ]], dtype=float32)
time = 18455	action = 0	current_phase = 0	next_phase = 1	reward = 1.292751	array([[ 3.3715343, -9.234539 ]], dtype=float32)
time = 18460	action = 0	current_phase = 0	next_phase = 1	reward = 0.720261	array([[ 3.5011559, -9.117346 ]], dtype=float32)
time = 18465	action = 0	current_phase = 0	next_phase = 1	reward = 0.445439	array([[ 3.3888454, -9.186449 ]], dtype=float32)
time = 18470	action = 0	current_phase = 0	next_phase = 1	reward = 0.727814	array([[ 3.1993074, -9.474556 ]], dtype=float32)
time = 18475	action = 0	current_phase = 0	next_phase = 1	reward = 1.004139	array([[ 3.3208752, -9.274857 ]], dtype=float32)
time = 18480	action = 0	current_phase = 0	next_phase = 1	reward = 0.440542	array([[ 3.4201775, -9.181462 ]], dtype=float32)
time = 18485	action = 0	current_phase = 0	next_phase = 1	reward = 0.727007	array([[ 3.2875662, -9.311029 ]], dtype=float32)
time = 18490	action = 0	current_phase = 0	next_phase = 1	reward = 0.736459	array([[ 3.241499, -9.337225]], dtype=float32)
time = 18495	action = 0	current_phase = 0	next_phase = 1	reward = 1.004802	array([[ 3.427267, -9.142139]], dtype=float32)
time = 18500	action = 0	current_phase = 0	next_phase = 1	reward = 0.718619	array([[ 3.394085, -9.160744]], dtype=float32)
time = 18505	action = 0	current_phase = 0	next_phase = 1	reward = 0.447192	array([[ 3.359313 , -9.2076435]], dtype=float32)
time = 18510	action = 0	current_phase = 0	next_phase = 1	reward = 0.999988	array([[ 3.303711, -9.342214]], dtype=float32)
time = 18515	action = 0	current_phase = 0	next_phase = 1	reward = 0.164792	array([[ 3.4451866, -9.134227 ]], dtype=float32)
time = 18520	action = 0	current_phase = 0	next_phase = 1	reward = 1.296331	array([[ 3.285161, -9.284376]], dtype=float32)
time = 18525	action = 0	current_phase = 0	next_phase = 1	reward = 0.728590	array([[ 3.5084877, -9.157789 ]], dtype=float32)
time = 18530	action = 0	current_phase = 0	next_phase = 1	reward = 0.717916	array([[ 3.4025736, -9.169635 ]], dtype=float32)
time = 18535	action = 0	current_phase = 0	next_phase = 1	reward = 0.720070	array([[ 3.4432325, -9.146365 ]], dtype=float32)
time = 18540	action = 0	current_phase = 0	next_phase = 1	reward = 0.718756	array([[ 3.4213066, -9.163219 ]], dtype=float32)
time = 18545	action = 0	current_phase = 0	next_phase = 1	reward = 0.726336	array([[ 3.4031477, -9.165046 ]], dtype=float32)
time = 18550	action = 0	current_phase = 0	next_phase = 1	reward = 0.445382	array([[ 3.384347, -9.197044]], dtype=float32)
time = 18555	action = 0	current_phase = 0	next_phase = 1	reward = 0.726630	array([[ 3.3594294, -9.198369 ]], dtype=float32)
time = 18560	action = 0	current_phase = 0	next_phase = 1	reward = 1.000823	array([[ 3.400876, -9.169987]], dtype=float32)
time = 18565	action = 0	current_phase = 0	next_phase = 1	reward = 0.723187	array([[ 3.3119974, -9.2572   ]], dtype=float32)
time = 18570	action = 0	current_phase = 0	next_phase = 1	reward = 0.440545	array([[ 3.3693075, -9.219675 ]], dtype=float32)
time = 18575	action = 0	current_phase = 0	next_phase = 1	reward = 0.720806	array([[ 3.3823147, -9.261874 ]], dtype=float32)
time = 18580	action = 0	current_phase = 0	next_phase = 1	reward = 0.720702	array([[ 3.301406, -9.256398]], dtype=float32)
time = 18585	action = 0	current_phase = 0	next_phase = 1	reward = 0.723810	array([[ 3.2688837, -9.345946 ]], dtype=float32)
time = 18590	action = 0	current_phase = 0	next_phase = 1	reward = 0.733100	array([[ 3.3278484, -9.303616 ]], dtype=float32)
time = 18595	action = 0	current_phase = 0	next_phase = 1	reward = 1.017635	array([[ 3.3752155, -9.228775 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.1476 - val_loss: 1.7232
Epoch 2/50
 - 4s - loss: 4.2372 - val_loss: 1.9209
Epoch 3/50
 - 4s - loss: 3.6683 - val_loss: 1.8315
Epoch 4/50
 - 4s - loss: 5.1920 - val_loss: 2.1257
Epoch 5/50
 - 4s - loss: 4.0809 - val_loss: 2.0512
Epoch 6/50
 - 4s - loss: 4.6149 - val_loss: 2.2102
Epoch 7/50
 - 4s - loss: 4.2210 - val_loss: 2.7950
Epoch 8/50
 - 4s - loss: 4.7634 - val_loss: 2.4174
Epoch 9/50
 - 4s - loss: 4.3875 - val_loss: 2.5599
Epoch 10/50
 - 4s - loss: 4.3976 - val_loss: 2.1748
Epoch 11/50
 - 4s - loss: 3.3216 - val_loss: 2.0928
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 18600	action = 0	current_phase = 0	next_phase = 1	reward = 0.725348	array([[ 3.4149747, -9.143415 ]], dtype=float32)
time = 18605	action = 0	current_phase = 0	next_phase = 1	reward = 0.724104	array([[ 3.3636508, -9.187738 ]], dtype=float32)
time = 18610	action = 0	current_phase = 0	next_phase = 1	reward = 0.719101	array([[ 3.3547034, -9.223679 ]], dtype=float32)
time = 18615	action = 0	current_phase = 0	next_phase = 1	reward = 0.717384	array([[ 3.3779378, -9.172617 ]], dtype=float32)
time = 18620	action = 0	current_phase = 0	next_phase = 1	reward = 0.712977	array([[ 3.3418593, -9.21512  ]], dtype=float32)
time = 18625	action = 0	current_phase = 0	next_phase = 1	reward = 0.730933	array([[ 3.2989812, -9.223635 ]], dtype=float32)
time = 18630	action = 0	current_phase = 0	next_phase = 1	reward = 0.727435	array([[ 3.323461, -9.229807]], dtype=float32)
time = 18635	action = 0	current_phase = 0	next_phase = 1	reward = 0.726345	array([[ 3.3483958, -9.1827135]], dtype=float32)
time = 18640	action = 0	current_phase = 0	next_phase = 1	reward = 0.721680	array([[ 3.39988 , -9.155775]], dtype=float32)
time = 18645	action = 0	current_phase = 0	next_phase = 1	reward = 0.723123	array([[ 3.3516135, -9.209269 ]], dtype=float32)
time = 18650	action = 0	current_phase = 0	next_phase = 1	reward = 0.725436	array([[ 3.3844218, -9.183212 ]], dtype=float32)
time = 18655	action = 0	current_phase = 0	next_phase = 1	reward = 0.731815	array([[ 3.4696555, -9.130237 ]], dtype=float32)
time = 18660	action = 0	current_phase = 0	next_phase = 1	reward = 0.714072	array([[ 3.3181787, -9.215853 ]], dtype=float32)
time = 18665	action = 0	current_phase = 0	next_phase = 1	reward = 0.720427	array([[ 3.2732005, -9.243287 ]], dtype=float32)
time = 18670	action = 0	current_phase = 0	next_phase = 1	reward = 0.731612	array([[ 3.2925782, -9.248539 ]], dtype=float32)
time = 18675	action = 0	current_phase = 0	next_phase = 1	reward = 0.734538	array([[ 3.3048081, -9.235819 ]], dtype=float32)
time = 18680	action = 0	current_phase = 0	next_phase = 1	reward = 0.720030	array([[ 3.2778096, -9.262011 ]], dtype=float32)
time = 18685	action = 0	current_phase = 0	next_phase = 1	reward = 0.719156	array([[ 3.3674798, -9.183561 ]], dtype=float32)
time = 18690	action = 0	current_phase = 0	next_phase = 1	reward = 0.719797	array([[ 3.3769898, -9.204604 ]], dtype=float32)
time = 18695	action = 0	current_phase = 0	next_phase = 1	reward = 0.439428	array([[ 3.3901362, -9.178846 ]], dtype=float32)
time = 18700	action = 0	current_phase = 0	next_phase = 1	reward = 0.444077	array([[ 3.2762074, -9.321361 ]], dtype=float32)
time = 18705	action = 0	current_phase = 0	next_phase = 1	reward = 0.724603	array([[ 3.3095803, -9.339859 ]], dtype=float32)
time = 18710	action = 0	current_phase = 0	next_phase = 1	reward = 1.280483	array([[ 3.2868562, -9.2960415]], dtype=float32)
time = 18715	action = 0	current_phase = 0	next_phase = 1	reward = 0.439939	array([[ 3.3374095, -9.227774 ]], dtype=float32)
time = 18720	action = 0	current_phase = 0	next_phase = 1	reward = 0.732292	array([[ 3.3902287, -9.15872  ]], dtype=float32)
time = 18725	action = 0	current_phase = 0	next_phase = 1	reward = 0.728997	array([[ 3.1590638, -9.423262 ]], dtype=float32)
time = 18730	action = 0	current_phase = 0	next_phase = 1	reward = 1.010032	array([[ 3.3700595, -9.151087 ]], dtype=float32)
time = 18735	action = 0	current_phase = 0	next_phase = 1	reward = 0.448406	array([[ 3.3073277, -9.244353 ]], dtype=float32)
time = 18740	action = 0	current_phase = 0	next_phase = 1	reward = 0.722925	array([[ 3.3562188, -9.187319 ]], dtype=float32)
time = 18745	action = 0	current_phase = 0	next_phase = 1	reward = 1.004200	array([[ 3.2437205, -9.304395 ]], dtype=float32)
time = 18750	action = 0	current_phase = 0	next_phase = 1	reward = 0.713791	array([[ 3.4232469, -9.163611 ]], dtype=float32)
time = 18755	action = 0	current_phase = 0	next_phase = 1	reward = 0.716744	array([[ 3.2424874, -9.279377 ]], dtype=float32)
time = 18760	action = 0	current_phase = 0	next_phase = 1	reward = 0.441284	array([[ 3.4005103, -9.1697235]], dtype=float32)
time = 18765	action = 0	current_phase = 0	next_phase = 1	reward = 0.459205	array([[ 3.2936378, -9.258017 ]], dtype=float32)
time = 18770	action = 0	current_phase = 0	next_phase = 1	reward = 1.284988	array([[ 3.3378644, -9.279854 ]], dtype=float32)
time = 18775	action = 0	current_phase = 0	next_phase = 1	reward = 0.433589	array([[ 3.4143405, -9.171261 ]], dtype=float32)
time = 18780	action = 0	current_phase = 0	next_phase = 1	reward = 1.004726	array([[ 3.3922276, -9.163586 ]], dtype=float32)
time = 18785	action = 0	current_phase = 0	next_phase = 1	reward = 0.445879	array([[ 3.3198714, -9.223235 ]], dtype=float32)
time = 18790	action = 0	current_phase = 0	next_phase = 1	reward = 1.009319	array([[ 3.24573 , -9.351482]], dtype=float32)
time = 18795	action = 0	current_phase = 0	next_phase = 1	reward = 0.733462	array([[ 3.4383044, -9.159742 ]], dtype=float32)
time = 18800	action = 0	current_phase = 0	next_phase = 1	reward = 0.729922	array([[ 3.3507152, -9.183344 ]], dtype=float32)
time = 18805	action = 0	current_phase = 0	next_phase = 1	reward = 0.713177	array([[ 3.3138165, -9.23209  ]], dtype=float32)
time = 18810	action = 0	current_phase = 0	next_phase = 1	reward = 0.719879	array([[ 3.3364863, -9.228176 ]], dtype=float32)
time = 18815	action = 0	current_phase = 0	next_phase = 1	reward = 0.717802	array([[ 3.4391065, -9.148105 ]], dtype=float32)
time = 18820	action = 0	current_phase = 0	next_phase = 1	reward = 0.725496	array([[ 3.3954625, -9.225994 ]], dtype=float32)
time = 18825	action = 0	current_phase = 0	next_phase = 1	reward = 0.724570	array([[ 3.3262916, -9.224476 ]], dtype=float32)
time = 18830	action = 0	current_phase = 0	next_phase = 1	reward = 0.721485	array([[ 3.4027581, -9.184059 ]], dtype=float32)
time = 18835	action = 0	current_phase = 0	next_phase = 1	reward = 0.437040	array([[ 3.2982106, -9.259536 ]], dtype=float32)
time = 18840	action = 0	current_phase = 0	next_phase = 1	reward = 1.001131	array([[ 3.3426728, -9.222025 ]], dtype=float32)
time = 18845	action = 0	current_phase = 0	next_phase = 1	reward = 0.450171	array([[ 3.3074222, -9.276398 ]], dtype=float32)
time = 18850	action = 0	current_phase = 0	next_phase = 1	reward = 0.728666	array([[ 3.3596177, -9.246872 ]], dtype=float32)
time = 18855	action = 0	current_phase = 0	next_phase = 1	reward = 1.010429	array([[ 3.3369145, -9.256189 ]], dtype=float32)
time = 18860	action = 0	current_phase = 0	next_phase = 1	reward = 0.714393	array([[ 3.3292174, -9.172253 ]], dtype=float32)
time = 18865	action = 0	current_phase = 0	next_phase = 1	reward = 0.719898	array([[ 3.2478948, -9.291298 ]], dtype=float32)
time = 18870	action = 0	current_phase = 0	next_phase = 1	reward = 0.441083	array([[ 3.2482944, -9.280644 ]], dtype=float32)
time = 18875	action = 0	current_phase = 0	next_phase = 1	reward = 1.011120	array([[ 3.265593, -9.285128]], dtype=float32)
time = 18880	action = 0	current_phase = 0	next_phase = 1	reward = 0.723711	array([[ 3.3729215, -9.188165 ]], dtype=float32)
time = 18885	action = 0	current_phase = 0	next_phase = 1	reward = 0.729326	array([[ 3.306229, -9.240927]], dtype=float32)
time = 18890	action = 0	current_phase = 0	next_phase = 1	reward = 0.722131	array([[ 3.3991752, -9.166862 ]], dtype=float32)
time = 18895	action = 0	current_phase = 0	next_phase = 1	reward = 0.719545	array([[ 3.331781, -9.215305]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.8857 - val_loss: 2.5667
Epoch 2/50
 - 4s - loss: 4.4398 - val_loss: 2.6973
Epoch 3/50
 - 4s - loss: 4.1515 - val_loss: 2.5694
Epoch 4/50
 - 4s - loss: 4.4088 - val_loss: 2.4843
Epoch 5/50
 - 4s - loss: 4.1299 - val_loss: 2.3923
Epoch 6/50
 - 4s - loss: 5.3250 - val_loss: 2.2366
Epoch 7/50
 - 4s - loss: 4.5377 - val_loss: 1.8900
Epoch 8/50
 - 4s - loss: 3.2815 - val_loss: 2.3023
Epoch 9/50
 - 4s - loss: 4.7079 - val_loss: 2.6326
Epoch 10/50
 - 4s - loss: 3.4801 - val_loss: 1.9072
Epoch 11/50
 - 4s - loss: 3.6038 - val_loss: 1.9509
Epoch 12/50
 - 4s - loss: 3.5969 - val_loss: 1.9661
Epoch 13/50
 - 4s - loss: 4.1350 - val_loss: 1.9263
Epoch 14/50
 - 4s - loss: 3.1614 - val_loss: 2.4318
Epoch 15/50
 - 4s - loss: 3.8052 - val_loss: 1.7656
Epoch 16/50
 - 4s - loss: 4.2018 - val_loss: 1.9607
Epoch 17/50
 - 4s - loss: 3.7983 - val_loss: 2.0155
Epoch 18/50
 - 4s - loss: 3.6723 - val_loss: 2.2875
Epoch 19/50
 - 4s - loss: 4.2958 - val_loss: 2.5421
Epoch 20/50
 - 4s - loss: 3.8204 - val_loss: 2.0003
Epoch 21/50
 - 4s - loss: 3.9680 - val_loss: 2.0531
Epoch 22/50
 - 4s - loss: 3.4232 - val_loss: 2.2641
Epoch 23/50
 - 4s - loss: 3.5422 - val_loss: 2.2628
Epoch 24/50
 - 4s - loss: 3.2216 - val_loss: 1.7193
Epoch 25/50
 - 4s - loss: 3.0578 - val_loss: 2.1630
Epoch 26/50
 - 4s - loss: 4.0285 - val_loss: 2.2840
Epoch 27/50
 - 5s - loss: 3.8179 - val_loss: 3.5019
Epoch 28/50
 - 4s - loss: 3.6501 - val_loss: 2.7239
Epoch 29/50
 - 4s - loss: 4.7126 - val_loss: 2.0054
Epoch 30/50
 - 4s - loss: 3.3332 - val_loss: 1.8827
Epoch 31/50
 - 4s - loss: 3.5892 - val_loss: 2.1252
Epoch 32/50
 - 4s - loss: 3.4872 - val_loss: 2.0603
Epoch 33/50
 - 4s - loss: 3.4993 - val_loss: 2.1065
Epoch 34/50
 - 4s - loss: 3.6236 - val_loss: 2.7258
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 18900	action = 0	current_phase = 0	next_phase = 1	reward = 0.445817	array([[ 3.4032497, -9.195799 ]], dtype=float32)
time = 18905	action = 0	current_phase = 0	next_phase = 1	reward = 1.004972	array([[ 3.3523188, -9.300171 ]], dtype=float32)
time = 18910	action = 0	current_phase = 0	next_phase = 1	reward = 0.444910	array([[ 3.4620285, -9.189225 ]], dtype=float32)
time = 18915	action = 0	current_phase = 0	next_phase = 1	reward = 1.004891	array([[ 3.3761158, -9.256113 ]], dtype=float32)
time = 18920	action = 0	current_phase = 0	next_phase = 1	reward = 0.722781	array([[ 3.4184046, -9.21809  ]], dtype=float32)
time = 18925	action = 0	current_phase = 0	next_phase = 1	reward = 0.431756	array([[ 3.3184948, -9.292276 ]], dtype=float32)
time = 18930	action = 0	current_phase = 0	next_phase = 1	reward = 0.997019	array([[ 3.3745146, -9.243649 ]], dtype=float32)
time = 18935	action = 0	current_phase = 0	next_phase = 1	reward = 0.445027	array([[ 3.4248018, -9.213959 ]], dtype=float32)
time = 18940	action = 0	current_phase = 0	next_phase = 1	reward = 1.003465	array([[ 3.3882427, -9.252026 ]], dtype=float32)
time = 18945	action = 0	current_phase = 0	next_phase = 1	reward = 0.448330	array([[ 3.3767786, -9.227238 ]], dtype=float32)
time = 18950	action = 0	current_phase = 0	next_phase = 1	reward = 1.008246	array([[ 3.43684 , -9.184754]], dtype=float32)
time = 18955	action = 0	current_phase = 0	next_phase = 1	reward = 0.728078	array([[ 3.4240656, -9.195001 ]], dtype=float32)
time = 18960	action = 0	current_phase = 0	next_phase = 1	reward = 0.724639	array([[ 3.3924036, -9.241274 ]], dtype=float32)
time = 18965	action = 0	current_phase = 0	next_phase = 1	reward = 0.728039	array([[ 3.3892822, -9.22599  ]], dtype=float32)
time = 18970	action = 0	current_phase = 0	next_phase = 1	reward = 0.722078	array([[ 3.3635473, -9.24476  ]], dtype=float32)
time = 18975	action = 0	current_phase = 0	next_phase = 1	reward = 0.718569	array([[ 3.3483667, -9.267072 ]], dtype=float32)
time = 18980	action = 0	current_phase = 0	next_phase = 1	reward = 0.442574	array([[ 3.3934145, -9.246326 ]], dtype=float32)
time = 18985	action = 0	current_phase = 0	next_phase = 1	reward = 0.997425	array([[ 3.3988523, -9.243399 ]], dtype=float32)
time = 18990	action = 0	current_phase = 0	next_phase = 1	reward = 0.162440	array([[ 3.4355984, -9.189289 ]], dtype=float32)
time = 18995	action = 0	current_phase = 0	next_phase = 1	reward = 1.009827	array([[ 3.3329515, -9.34113  ]], dtype=float32)
time = 19000	action = 0	current_phase = 0	next_phase = 1	reward = 0.727970	array([[ 3.3643427, -9.297502 ]], dtype=float32)
time = 19005	action = 0	current_phase = 0	next_phase = 1	reward = 1.006000	array([[ 3.3507805, -9.286503 ]], dtype=float32)
time = 19010	action = 0	current_phase = 0	next_phase = 1	reward = 0.720904	array([[ 3.398673, -9.236154]], dtype=float32)
time = 19015	action = 0	current_phase = 0	next_phase = 1	reward = 0.714932	array([[ 3.4578  , -9.192652]], dtype=float32)
time = 19020	action = 0	current_phase = 0	next_phase = 1	reward = 0.719224	array([[ 3.3772326, -9.232962 ]], dtype=float32)
time = 19025	action = 0	current_phase = 0	next_phase = 1	reward = 0.438580	array([[ 3.373951, -9.282845]], dtype=float32)
time = 19030	action = 0	current_phase = 0	next_phase = 1	reward = 0.719321	array([[ 3.4162216, -9.21011  ]], dtype=float32)
time = 19035	action = 0	current_phase = 0	next_phase = 1	reward = 0.729087	array([[ 3.4009438, -9.241705 ]], dtype=float32)
time = 19040	action = 0	current_phase = 0	next_phase = 1	reward = 1.010633	array([[ 3.3470964, -9.271554 ]], dtype=float32)
time = 19045	action = 0	current_phase = 0	next_phase = 1	reward = 0.717646	array([[ 3.3461676, -9.268379 ]], dtype=float32)
time = 19050	action = 0	current_phase = 0	next_phase = 1	reward = 0.442510	array([[ 3.3837843, -9.221657 ]], dtype=float32)
time = 19055	action = 0	current_phase = 0	next_phase = 1	reward = 1.011079	array([[ 3.3720112, -9.242451 ]], dtype=float32)
time = 19060	action = 0	current_phase = 0	next_phase = 1	reward = 0.725073	array([[ 3.4127483, -9.221048 ]], dtype=float32)
time = 19065	action = 0	current_phase = 0	next_phase = 1	reward = 0.443678	array([[ 3.4133587, -9.208548 ]], dtype=float32)
time = 19070	action = 0	current_phase = 0	next_phase = 1	reward = 1.004597	array([[ 3.332035, -9.287796]], dtype=float32)
time = 19075	action = 0	current_phase = 0	next_phase = 1	reward = 0.723235	array([[ 3.441452, -9.183451]], dtype=float32)
time = 19080	action = 0	current_phase = 0	next_phase = 1	reward = 0.723678	array([[ 3.4197016, -9.197722 ]], dtype=float32)
time = 19085	action = 0	current_phase = 0	next_phase = 1	reward = 0.721659	array([[ 3.4171476, -9.198414 ]], dtype=float32)
time = 19090	action = 0	current_phase = 0	next_phase = 1	reward = 0.717477	array([[ 3.3789291, -9.236464 ]], dtype=float32)
time = 19095	action = 0	current_phase = 0	next_phase = 1	reward = 0.437454	array([[ 3.453494, -9.211622]], dtype=float32)
time = 19100	action = 0	current_phase = 0	next_phase = 1	reward = 1.012885	array([[ 3.35427 , -9.283008]], dtype=float32)
time = 19105	action = 0	current_phase = 0	next_phase = 1	reward = 0.721403	array([[ 3.367878, -9.239671]], dtype=float32)
time = 19110	action = 0	current_phase = 0	next_phase = 1	reward = 0.713286	array([[ 3.3933992, -9.244551 ]], dtype=float32)
time = 19115	action = 0	current_phase = 0	next_phase = 1	reward = 0.718606	array([[ 3.337285, -9.268616]], dtype=float32)
time = 19120	action = 0	current_phase = 0	next_phase = 1	reward = 0.718676	array([[ 3.336071, -9.287291]], dtype=float32)
time = 19125	action = 0	current_phase = 0	next_phase = 1	reward = 0.448808	array([[ 3.3520002, -9.255911 ]], dtype=float32)
time = 19130	action = 0	current_phase = 0	next_phase = 1	reward = 1.009609	array([[ 3.3242273, -9.286362 ]], dtype=float32)
time = 19135	action = 0	current_phase = 0	next_phase = 1	reward = 0.717765	array([[ 3.3387203, -9.271195 ]], dtype=float32)
time = 19140	action = 0	current_phase = 0	next_phase = 1	reward = 0.724099	array([[ 3.4352665, -9.184982 ]], dtype=float32)
time = 19145	action = 0	current_phase = 0	next_phase = 1	reward = 0.720040	array([[ 3.4394493, -9.195864 ]], dtype=float32)
time = 19150	action = 0	current_phase = 0	next_phase = 1	reward = 0.722096	array([[ 3.4452715, -9.195271 ]], dtype=float32)
time = 19155	action = 0	current_phase = 0	next_phase = 1	reward = 0.449840	array([[ 3.3431692, -9.271156 ]], dtype=float32)
time = 19160	action = 0	current_phase = 0	next_phase = 1	reward = 1.007094	array([[ 3.4255915, -9.216305 ]], dtype=float32)
time = 19165	action = 0	current_phase = 0	next_phase = 1	reward = 0.716430	array([[ 3.3672543, -9.251884 ]], dtype=float32)
time = 19170	action = 0	current_phase = 0	next_phase = 1	reward = 0.439952	array([[ 3.3776894, -9.244434 ]], dtype=float32)
time = 19175	action = 0	current_phase = 0	next_phase = 1	reward = 1.005776	array([[ 3.3646908, -9.283319 ]], dtype=float32)
time = 19180	action = 0	current_phase = 0	next_phase = 1	reward = 0.440358	array([[ 3.3519487, -9.271303 ]], dtype=float32)
time = 19185	action = 0	current_phase = 0	next_phase = 1	reward = 0.722071	array([[ 3.3383265, -9.2764225]], dtype=float32)
time = 19190	action = 0	current_phase = 0	next_phase = 1	reward = 1.002679	array([[ 3.400794, -9.221709]], dtype=float32)
time = 19195	action = 0	current_phase = 0	next_phase = 1	reward = 0.726797	array([[ 3.3392076, -9.272043 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.3943 - val_loss: 1.6678
Epoch 2/50
 - 4s - loss: 4.3563 - val_loss: 1.3818
Epoch 3/50
 - 4s - loss: 3.8598 - val_loss: 1.3340
Epoch 4/50
 - 4s - loss: 4.0622 - val_loss: 1.3086
Epoch 5/50
 - 4s - loss: 3.8508 - val_loss: 1.5441
Epoch 6/50
 - 5s - loss: 3.3940 - val_loss: 2.1566
Epoch 7/50
 - 5s - loss: 3.6429 - val_loss: 1.3779
Epoch 8/50
 - 4s - loss: 4.3841 - val_loss: 1.3348
Epoch 9/50
 - 4s - loss: 3.7602 - val_loss: 1.7020
Epoch 10/50
 - 4s - loss: 3.5077 - val_loss: 1.5805
Epoch 11/50
 - 4s - loss: 3.4067 - val_loss: 1.7547
Epoch 12/50
 - 4s - loss: 3.7821 - val_loss: 2.0347
Epoch 13/50
 - 4s - loss: 3.7397 - val_loss: 1.5687
Epoch 14/50
 - 4s - loss: 4.2069 - val_loss: 2.1120
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 19200	action = 0	current_phase = 0	next_phase = 1	reward = 0.445667	array([[ 3.3907342, -9.246046 ]], dtype=float32)
time = 19205	action = 0	current_phase = 0	next_phase = 1	reward = 0.736212	array([[ 3.3599124, -9.215311 ]], dtype=float32)
time = 19210	action = 0	current_phase = 0	next_phase = 1	reward = 1.004305	array([[ 3.3660836, -9.210857 ]], dtype=float32)
time = 19215	action = 0	current_phase = 0	next_phase = 1	reward = 0.729910	array([[ 3.341228, -9.234376]], dtype=float32)
time = 19220	action = 0	current_phase = 0	next_phase = 1	reward = 0.721562	array([[ 3.445538, -9.161555]], dtype=float32)
time = 19225	action = 0	current_phase = 0	next_phase = 1	reward = 0.725135	array([[ 3.3908477, -9.216306 ]], dtype=float32)
time = 19230	action = 0	current_phase = 0	next_phase = 1	reward = 0.723725	array([[ 3.3872733, -9.235521 ]], dtype=float32)
time = 19235	action = 0	current_phase = 0	next_phase = 1	reward = 0.728690	array([[ 3.38452 , -9.189792]], dtype=float32)
time = 19240	action = 0	current_phase = 0	next_phase = 1	reward = 0.721064	array([[ 3.4653134, -9.144091 ]], dtype=float32)
time = 19245	action = 0	current_phase = 0	next_phase = 1	reward = 0.718538	array([[ 3.325152, -9.258347]], dtype=float32)
time = 19250	action = 0	current_phase = 0	next_phase = 1	reward = 0.439937	array([[ 3.4207845, -9.18038  ]], dtype=float32)
time = 19255	action = 0	current_phase = 0	next_phase = 1	reward = 0.997904	array([[ 3.3280463, -9.262323 ]], dtype=float32)
time = 19260	action = 0	current_phase = 0	next_phase = 1	reward = 0.716885	array([[ 3.3428912, -9.2490635]], dtype=float32)
time = 19265	action = 0	current_phase = 0	next_phase = 1	reward = 0.432882	array([[ 3.292953, -9.285236]], dtype=float32)
time = 19270	action = 0	current_phase = 0	next_phase = 1	reward = 0.448056	array([[ 3.3130527, -9.267372 ]], dtype=float32)
time = 19275	action = 0	current_phase = 0	next_phase = 1	reward = 0.727194	array([[ 3.2921033, -9.308651 ]], dtype=float32)
time = 19280	action = 0	current_phase = 0	next_phase = 1	reward = 1.009566	array([[ 3.3010068, -9.314766 ]], dtype=float32)
time = 19285	action = 0	current_phase = 0	next_phase = 1	reward = 1.009089	array([[ 3.358006, -9.230365]], dtype=float32)
time = 19290	action = 0	current_phase = 0	next_phase = 1	reward = 0.725036	array([[ 3.322682, -9.284567]], dtype=float32)
time = 19295	action = 0	current_phase = 0	next_phase = 1	reward = 0.721209	array([[ 3.4240804, -9.21561  ]], dtype=float32)
time = 19300	action = 0	current_phase = 0	next_phase = 1	reward = 0.436055	array([[ 3.4134564, -9.188408 ]], dtype=float32)
time = 19305	action = 0	current_phase = 0	next_phase = 1	reward = 0.731006	array([[ 3.3361678, -9.263545 ]], dtype=float32)
time = 19310	action = 0	current_phase = 0	next_phase = 1	reward = 0.728301	array([[ 3.2443156, -9.391037 ]], dtype=float32)
time = 19315	action = 0	current_phase = 0	next_phase = 1	reward = 0.724555	array([[ 3.388022, -9.194532]], dtype=float32)
time = 19320	action = 0	current_phase = 0	next_phase = 1	reward = 0.720319	array([[ 3.3303094, -9.246245 ]], dtype=float32)
time = 19325	action = 0	current_phase = 0	next_phase = 1	reward = 0.728834	array([[ 3.378924, -9.237337]], dtype=float32)
time = 19330	action = 0	current_phase = 0	next_phase = 1	reward = 1.007768	array([[ 3.3177924, -9.27593  ]], dtype=float32)
time = 19335	action = 0	current_phase = 0	next_phase = 1	reward = 0.720302	array([[ 3.3787465, -9.215573 ]], dtype=float32)
time = 19340	action = 0	current_phase = 0	next_phase = 1	reward = 0.720113	array([[ 3.3744063, -9.196304 ]], dtype=float32)
time = 19345	action = 0	current_phase = 0	next_phase = 1	reward = 0.721180	array([[ 3.3902612, -9.207573 ]], dtype=float32)
time = 19350	action = 0	current_phase = 0	next_phase = 1	reward = 0.445827	array([[ 3.3770194, -9.218151 ]], dtype=float32)
time = 19355	action = 0	current_phase = 0	next_phase = 1	reward = 1.002724	array([[ 3.2533803, -9.372354 ]], dtype=float32)
time = 19360	action = 0	current_phase = 0	next_phase = 1	reward = 0.722160	array([[ 3.4274268, -9.183254 ]], dtype=float32)
time = 19365	action = 0	current_phase = 0	next_phase = 1	reward = 0.719924	array([[ 3.3422627, -9.237953 ]], dtype=float32)
time = 19370	action = 0	current_phase = 0	next_phase = 1	reward = 0.725395	array([[ 3.4137225, -9.193892 ]], dtype=float32)
time = 19375	action = 0	current_phase = 0	next_phase = 1	reward = 0.441960	array([[ 3.36416 , -9.194998]], dtype=float32)
time = 19380	action = 0	current_phase = 0	next_phase = 1	reward = 1.010472	array([[ 3.2726274, -9.343357 ]], dtype=float32)
time = 19385	action = 0	current_phase = 0	next_phase = 1	reward = 0.721929	array([[ 3.4075809, -9.200941 ]], dtype=float32)
time = 19390	action = 0	current_phase = 0	next_phase = 1	reward = 0.719631	array([[ 3.3822799, -9.188164 ]], dtype=float32)
time = 19395	action = 0	current_phase = 0	next_phase = 1	reward = 0.451395	array([[ 3.3199105, -9.259879 ]], dtype=float32)
time = 19400	action = 0	current_phase = 0	next_phase = 1	reward = 1.004021	array([[ 3.3414998, -9.279312 ]], dtype=float32)
time = 19405	action = 0	current_phase = 0	next_phase = 1	reward = 0.715511	array([[ 3.4000688, -9.200934 ]], dtype=float32)
time = 19410	action = 0	current_phase = 0	next_phase = 1	reward = 0.714887	array([[ 3.3761897, -9.240082 ]], dtype=float32)
time = 19415	action = 0	current_phase = 0	next_phase = 1	reward = 0.445443	array([[ 3.3562074, -9.233023 ]], dtype=float32)
time = 19420	action = 0	current_phase = 0	next_phase = 1	reward = 0.726445	array([[ 3.3417315, -9.256921 ]], dtype=float32)
time = 19425	action = 0	current_phase = 0	next_phase = 1	reward = 1.003799	array([[ 3.20898 , -9.432812]], dtype=float32)
time = 19430	action = 0	current_phase = 0	next_phase = 1	reward = 0.717851	array([[ 3.3871007, -9.188744 ]], dtype=float32)
time = 19435	action = 0	current_phase = 0	next_phase = 1	reward = 0.720010	array([[ 3.3504596, -9.247602 ]], dtype=float32)
time = 19440	action = 0	current_phase = 0	next_phase = 1	reward = 0.444198	array([[ 3.3140187, -9.2546835]], dtype=float32)
time = 19445	action = 0	current_phase = 0	next_phase = 1	reward = 1.002451	array([[ 3.2621999, -9.349822 ]], dtype=float32)
time = 19450	action = 0	current_phase = 0	next_phase = 1	reward = 0.718645	array([[ 3.3837638, -9.201229 ]], dtype=float32)
time = 19455	action = 0	current_phase = 0	next_phase = 1	reward = 0.446833	array([[ 3.3802314, -9.215959 ]], dtype=float32)
time = 19460	action = 0	current_phase = 0	next_phase = 1	reward = 1.010493	array([[ 3.3629136, -9.31649  ]], dtype=float32)
time = 19465	action = 0	current_phase = 0	next_phase = 1	reward = 0.723500	array([[ 3.3670669, -9.246203 ]], dtype=float32)
time = 19470	action = 0	current_phase = 0	next_phase = 1	reward = 0.722900	array([[ 3.3741517, -9.201729 ]], dtype=float32)
time = 19475	action = 0	current_phase = 0	next_phase = 1	reward = 0.721978	array([[ 3.3184314, -9.266528 ]], dtype=float32)
time = 19480	action = 0	current_phase = 0	next_phase = 1	reward = 0.720713	array([[ 3.3881917, -9.196815 ]], dtype=float32)
time = 19485	action = 0	current_phase = 0	next_phase = 1	reward = 0.719444	array([[ 3.3054433, -9.266617 ]], dtype=float32)
time = 19490	action = 0	current_phase = 0	next_phase = 1	reward = 0.715679	array([[ 3.3336549, -9.274386 ]], dtype=float32)
time = 19495	action = 0	current_phase = 0	next_phase = 1	reward = 0.711428	array([[ 3.4518714, -9.171757 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 5s - loss: 4.7904 - val_loss: 1.8483
Epoch 2/50
 - 4s - loss: 4.2843 - val_loss: 2.3389
Epoch 3/50
 - 5s - loss: 4.3937 - val_loss: 2.0173
Epoch 4/50
 - 4s - loss: 4.0820 - val_loss: 2.3137
Epoch 5/50
 - 4s - loss: 3.3510 - val_loss: 2.7112
Epoch 6/50
 - 4s - loss: 3.4798 - val_loss: 2.4551
Epoch 7/50
 - 5s - loss: 3.2489 - val_loss: 2.3024
Epoch 8/50
 - 5s - loss: 3.5350 - val_loss: 2.2081
Epoch 9/50
 - 4s - loss: 3.6990 - val_loss: 1.8430
Epoch 10/50
 - 4s - loss: 3.4282 - val_loss: 1.8818
Epoch 11/50
 - 4s - loss: 4.8215 - val_loss: 2.5920
Epoch 12/50
 - 4s - loss: 3.7384 - val_loss: 3.2567
Epoch 13/50
 - 4s - loss: 3.7407 - val_loss: 2.7497
Epoch 14/50
 - 4s - loss: 4.0737 - val_loss: 2.6892
Epoch 15/50
 - 4s - loss: 3.8965 - val_loss: 2.0915
Epoch 16/50
 - 4s - loss: 3.3637 - val_loss: 2.6922
Epoch 17/50
 - 4s - loss: 4.4936 - val_loss: 2.4652
Epoch 18/50
 - 4s - loss: 3.5589 - val_loss: 2.0402
Epoch 19/50
 - 4s - loss: 3.8663 - val_loss: 2.5495
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 19500	action = 0	current_phase = 0	next_phase = 1	reward = 0.166963	array([[ 3.2718391, -9.295626 ]], dtype=float32)
time = 19505	action = 0	current_phase = 0	next_phase = 1	reward = 1.285034	array([[ 3.3217354, -9.275335 ]], dtype=float32)
time = 19510	action = 0	current_phase = 0	next_phase = 1	reward = 0.450982	array([[ 3.3474464, -9.306152 ]], dtype=float32)
time = 19515	action = 0	current_phase = 0	next_phase = 1	reward = 1.008485	array([[ 3.3019829, -9.277724 ]], dtype=float32)
time = 19520	action = 0	current_phase = 0	next_phase = 1	reward = 0.713661	array([[ 3.2948074, -9.2915   ]], dtype=float32)
time = 19525	action = 0	current_phase = 0	next_phase = 1	reward = 0.157963	array([[ 3.3541145, -9.282368 ]], dtype=float32)
time = 19530	action = 0	current_phase = 0	next_phase = 1	reward = 1.004614	array([[ 3.3624249, -9.251956 ]], dtype=float32)
time = 19535	action = 0	current_phase = 0	next_phase = 1	reward = 0.723740	array([[ 3.3590593, -9.247841 ]], dtype=float32)
time = 19540	action = 0	current_phase = 0	next_phase = 1	reward = 0.730741	array([[ 3.3668814, -9.220759 ]], dtype=float32)
time = 19545	action = 0	current_phase = 0	next_phase = 1	reward = 1.000085	array([[ 3.315421, -9.318074]], dtype=float32)
time = 19550	action = 0	current_phase = 0	next_phase = 1	reward = 0.716900	array([[ 3.3613634, -9.246679 ]], dtype=float32)
time = 19555	action = 0	current_phase = 0	next_phase = 1	reward = 0.722775	array([[ 3.335247, -9.254162]], dtype=float32)
time = 19560	action = 0	current_phase = 0	next_phase = 1	reward = 0.445552	array([[ 3.3301096, -9.264067 ]], dtype=float32)
time = 19565	action = 0	current_phase = 0	next_phase = 1	reward = 0.734095	array([[ 3.3267317, -9.258671 ]], dtype=float32)
time = 19570	action = 0	current_phase = 0	next_phase = 1	reward = 1.005133	array([[ 3.3628473, -9.219851 ]], dtype=float32)
time = 19575	action = 0	current_phase = 0	next_phase = 1	reward = 0.725306	array([[ 3.3995304, -9.209436 ]], dtype=float32)
time = 19580	action = 0	current_phase = 0	next_phase = 1	reward = 0.731221	array([[ 3.3038416, -9.268082 ]], dtype=float32)
time = 19585	action = 0	current_phase = 0	next_phase = 1	reward = 0.723676	array([[ 3.4078112, -9.185734 ]], dtype=float32)
time = 19590	action = 0	current_phase = 0	next_phase = 1	reward = 0.723087	array([[ 3.391531, -9.181505]], dtype=float32)
time = 19595	action = 0	current_phase = 0	next_phase = 1	reward = 0.721183	array([[ 3.3890772, -9.22811  ]], dtype=float32)
time = 19600	action = 0	current_phase = 0	next_phase = 1	reward = 0.724027	array([[ 3.331707, -9.246135]], dtype=float32)
time = 19605	action = 0	current_phase = 0	next_phase = 1	reward = 0.723294	array([[ 3.4231606, -9.2053795]], dtype=float32)
time = 19610	action = 0	current_phase = 0	next_phase = 1	reward = 0.445543	array([[ 3.311678, -9.292763]], dtype=float32)
time = 19615	action = 0	current_phase = 0	next_phase = 1	reward = 0.728329	array([[ 3.4217863, -9.237053 ]], dtype=float32)
time = 19620	action = 0	current_phase = 0	next_phase = 1	reward = 0.997726	array([[ 3.3604708, -9.221277 ]], dtype=float32)
time = 19625	action = 0	current_phase = 0	next_phase = 1	reward = 0.704965	array([[ 3.3857431, -9.220678 ]], dtype=float32)
time = 19630	action = 0	current_phase = 0	next_phase = 1	reward = 0.167025	array([[ 3.4136257, -9.228469 ]], dtype=float32)
time = 19635	action = 0	current_phase = 0	next_phase = 1	reward = 1.020014	array([[ 3.2063875, -9.448855 ]], dtype=float32)
time = 19640	action = 0	current_phase = 0	next_phase = 1	reward = 1.011736	array([[ 3.2741785, -9.309055 ]], dtype=float32)
time = 19645	action = 0	current_phase = 0	next_phase = 1	reward = 0.722191	array([[ 3.3669033, -9.192415 ]], dtype=float32)
time = 19650	action = 0	current_phase = 0	next_phase = 1	reward = 0.719978	array([[ 3.3420486, -9.235383 ]], dtype=float32)
time = 19655	action = 0	current_phase = 0	next_phase = 1	reward = 0.724844	array([[ 3.3458023, -9.267496 ]], dtype=float32)
time = 19660	action = 0	current_phase = 0	next_phase = 1	reward = 0.727257	array([[ 3.396593, -9.199151]], dtype=float32)
time = 19665	action = 0	current_phase = 0	next_phase = 1	reward = 0.720070	array([[ 3.3530579, -9.22345  ]], dtype=float32)
time = 19670	action = 0	current_phase = 0	next_phase = 1	reward = 0.437548	array([[ 3.3751564, -9.218121 ]], dtype=float32)
time = 19675	action = 0	current_phase = 0	next_phase = 1	reward = 0.993065	array([[ 3.3489962, -9.293103 ]], dtype=float32)
time = 19680	action = 0	current_phase = 0	next_phase = 1	reward = 0.442900	array([[ 3.3585691, -9.239872 ]], dtype=float32)
time = 19685	action = 0	current_phase = 0	next_phase = 1	reward = 1.000014	array([[ 3.363327, -9.263891]], dtype=float32)
time = 19690	action = 0	current_phase = 0	next_phase = 1	reward = 0.446617	array([[ 3.3535652, -9.26459  ]], dtype=float32)
time = 19695	action = 0	current_phase = 0	next_phase = 1	reward = 0.727684	array([[ 3.3803673, -9.187401 ]], dtype=float32)
time = 19700	action = 0	current_phase = 0	next_phase = 1	reward = 1.002295	array([[ 3.1037407, -9.421106 ]], dtype=float32)
time = 19705	action = 0	current_phase = 0	next_phase = 1	reward = 0.716138	array([[ 3.3631115, -9.224428 ]], dtype=float32)
time = 19710	action = 0	current_phase = 0	next_phase = 1	reward = 0.718367	array([[ 3.3920336, -9.199455 ]], dtype=float32)
time = 19715	action = 0	current_phase = 0	next_phase = 1	reward = 0.722712	array([[ 3.3151217, -9.271099 ]], dtype=float32)
time = 19720	action = 0	current_phase = 0	next_phase = 1	reward = 0.456909	array([[ 3.3645077, -9.221364 ]], dtype=float32)
time = 19725	action = 0	current_phase = 0	next_phase = 1	reward = 0.999642	array([[ 3.35038 , -9.216152]], dtype=float32)
time = 19730	action = 0	current_phase = 0	next_phase = 1	reward = 0.726652	array([[ 3.3433733, -9.242335 ]], dtype=float32)
time = 19735	action = 0	current_phase = 0	next_phase = 1	reward = 0.718882	array([[ 3.3546047, -9.260256 ]], dtype=float32)
time = 19740	action = 0	current_phase = 0	next_phase = 1	reward = 0.713650	array([[ 3.3920393, -9.19895  ]], dtype=float32)
time = 19745	action = 0	current_phase = 0	next_phase = 1	reward = 0.435773	array([[ 3.3317509, -9.268601 ]], dtype=float32)
time = 19750	action = 0	current_phase = 0	next_phase = 1	reward = 0.728309	array([[ 3.292471, -9.3055  ]], dtype=float32)
time = 19755	action = 0	current_phase = 0	next_phase = 1	reward = 0.721424	array([[ 3.3595972, -9.230394 ]], dtype=float32)
time = 19760	action = 0	current_phase = 0	next_phase = 1	reward = 0.726615	array([[ 3.4019213, -9.221916 ]], dtype=float32)
time = 19765	action = 0	current_phase = 0	next_phase = 1	reward = 1.011211	array([[ 3.3615742, -9.241482 ]], dtype=float32)
time = 19770	action = 0	current_phase = 0	next_phase = 1	reward = 0.442571	array([[ 3.3563948, -9.245911 ]], dtype=float32)
time = 19775	action = 0	current_phase = 0	next_phase = 1	reward = 1.005407	array([[ 3.3636255, -9.209028 ]], dtype=float32)
time = 19780	action = 0	current_phase = 0	next_phase = 1	reward = 0.715814	array([[ 3.3495169, -9.237759 ]], dtype=float32)
time = 19785	action = 0	current_phase = 0	next_phase = 1	reward = 0.439437	array([[ 3.350646, -9.258785]], dtype=float32)
time = 19790	action = 0	current_phase = 0	next_phase = 1	reward = 0.722336	array([[ 3.3625517, -9.224829 ]], dtype=float32)
time = 19795	action = 0	current_phase = 0	next_phase = 1	reward = 1.009709	array([[ 3.276597, -9.349703]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 7.2676 - val_loss: 2.4330
Epoch 2/50
 - 4s - loss: 7.8602 - val_loss: 2.2064
Epoch 3/50
 - 4s - loss: 5.2611 - val_loss: 2.9515
Epoch 4/50
 - 4s - loss: 5.7090 - val_loss: 2.8185
Epoch 5/50
 - 4s - loss: 4.9078 - val_loss: 2.4648
Epoch 6/50
 - 4s - loss: 5.2982 - val_loss: 2.3253
Epoch 7/50
 - 4s - loss: 4.4854 - val_loss: 2.5156
Epoch 8/50
 - 5s - loss: 5.0369 - val_loss: 2.5795
Epoch 9/50
 - 5s - loss: 5.7615 - val_loss: 2.5153
Epoch 10/50
 - 5s - loss: 4.8926 - val_loss: 2.4395
Epoch 11/50
 - 6s - loss: 4.8333 - val_loss: 2.4299
Epoch 12/50
 - 5s - loss: 4.1388 - val_loss: 2.5201
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 19800	action = 0	current_phase = 0	next_phase = 1	reward = 0.450666	array([[ 3.4114585, -9.24024  ]], dtype=float32)
time = 19805	action = 0	current_phase = 0	next_phase = 1	reward = 1.015462	array([[ 3.388289, -9.2726  ]], dtype=float32)
time = 19810	action = 0	current_phase = 0	next_phase = 1	reward = 0.723453	array([[ 3.4746633, -9.207856 ]], dtype=float32)
time = 19815	action = 0	current_phase = 0	next_phase = 1	reward = 0.717142	array([[ 3.4142108, -9.275145 ]], dtype=float32)
time = 19820	action = 0	current_phase = 0	next_phase = 1	reward = 0.714029	array([[ 3.4152675, -9.253649 ]], dtype=float32)
time = 19825	action = 0	current_phase = 0	next_phase = 1	reward = 0.445928	array([[ 3.357019, -9.294636]], dtype=float32)
time = 19830	action = 0	current_phase = 0	next_phase = 1	reward = 0.449866	array([[ 3.3916783, -9.278543 ]], dtype=float32)
time = 19835	action = 0	current_phase = 0	next_phase = 1	reward = 1.290933	array([[ 3.3572516, -9.312504 ]], dtype=float32)
time = 19840	action = 0	current_phase = 0	next_phase = 1	reward = 0.713954	array([[ 3.3827338, -9.291027 ]], dtype=float32)
time = 19845	action = 0	current_phase = 0	next_phase = 1	reward = 0.720748	array([[ 3.3465657, -9.296049 ]], dtype=float32)
time = 19850	action = 0	current_phase = 0	next_phase = 1	reward = 0.450937	array([[ 3.4113488, -9.252136 ]], dtype=float32)
time = 19855	action = 0	current_phase = 0	next_phase = 1	reward = 0.728872	array([[ 3.3683286, -9.299814 ]], dtype=float32)
time = 19860	action = 0	current_phase = 0	next_phase = 1	reward = 0.729472	array([[ 3.428184, -9.236536]], dtype=float32)
time = 19865	action = 0	current_phase = 0	next_phase = 1	reward = 1.010905	array([[ 3.4129567, -9.248733 ]], dtype=float32)
time = 19870	action = 0	current_phase = 0	next_phase = 1	reward = 0.726458	array([[ 3.4133153, -9.285919 ]], dtype=float32)
time = 19875	action = 0	current_phase = 0	next_phase = 1	reward = 0.436386	array([[ 3.4062896, -9.273937 ]], dtype=float32)
time = 19880	action = 0	current_phase = 0	next_phase = 1	reward = 1.002411	array([[ 3.3660207, -9.294189 ]], dtype=float32)
time = 19885	action = 0	current_phase = 0	next_phase = 1	reward = 0.443560	array([[ 3.4122481, -9.254901 ]], dtype=float32)
time = 19890	action = 0	current_phase = 0	next_phase = 1	reward = 0.731118	array([[ 3.365089, -9.349058]], dtype=float32)
time = 19895	action = 0	current_phase = 0	next_phase = 1	reward = 1.009252	array([[ 3.447948, -9.261814]], dtype=float32)
time = 19900	action = 0	current_phase = 0	next_phase = 1	reward = 0.714441	array([[ 3.337461, -9.314846]], dtype=float32)
time = 19905	action = 0	current_phase = 0	next_phase = 1	reward = 0.723677	array([[ 3.3996787, -9.262396 ]], dtype=float32)
time = 19910	action = 0	current_phase = 0	next_phase = 1	reward = 0.441269	array([[ 3.4546008, -9.2144375]], dtype=float32)
time = 19915	action = 0	current_phase = 0	next_phase = 1	reward = 1.002423	array([[ 3.3727002, -9.28696  ]], dtype=float32)
time = 19920	action = 0	current_phase = 0	next_phase = 1	reward = 0.724208	array([[ 3.4385238, -9.246742 ]], dtype=float32)
time = 19925	action = 0	current_phase = 0	next_phase = 1	reward = 0.716467	array([[ 3.3951898, -9.276739 ]], dtype=float32)
time = 19930	action = 0	current_phase = 0	next_phase = 1	reward = 0.724188	array([[ 3.3382163, -9.326447 ]], dtype=float32)
time = 19935	action = 0	current_phase = 0	next_phase = 1	reward = 0.452526	array([[ 3.440227, -9.253411]], dtype=float32)
time = 19940	action = 0	current_phase = 0	next_phase = 1	reward = 0.735318	array([[ 3.3727975, -9.292866 ]], dtype=float32)
time = 19945	action = 0	current_phase = 0	next_phase = 1	reward = 1.015773	array([[ 3.4431062, -9.259853 ]], dtype=float32)
time = 19950	action = 0	current_phase = 0	next_phase = 1	reward = 0.717683	array([[ 3.4078202, -9.256285 ]], dtype=float32)
time = 19955	action = 0	current_phase = 0	next_phase = 1	reward = 0.712714	array([[ 3.380571, -9.288602]], dtype=float32)
time = 19960	action = 0	current_phase = 0	next_phase = 1	reward = 0.721529	array([[ 3.441609, -9.241374]], dtype=float32)
time = 19965	action = 0	current_phase = 0	next_phase = 1	reward = 0.441505	array([[ 3.4168983, -9.256863 ]], dtype=float32)
time = 19970	action = 0	current_phase = 0	next_phase = 1	reward = 0.730339	array([[ 3.4036431, -9.253068 ]], dtype=float32)
time = 19975	action = 0	current_phase = 0	next_phase = 1	reward = 1.002137	array([[ 3.4471736, -9.262083 ]], dtype=float32)
time = 19980	action = 0	current_phase = 0	next_phase = 1	reward = 0.726050	array([[ 3.399835, -9.27659 ]], dtype=float32)
time = 19985	action = 0	current_phase = 0	next_phase = 1	reward = 0.443807	array([[ 3.4005618, -9.264557 ]], dtype=float32)
time = 19990	action = 0	current_phase = 0	next_phase = 1	reward = 1.009035	array([[ 3.3624034, -9.314613 ]], dtype=float32)
time = 19995	action = 0	current_phase = 0	next_phase = 1	reward = 0.727823	array([[ 3.4392123, -9.242425 ]], dtype=float32)
time = 20000	action = 0	current_phase = 0	next_phase = 1	reward = 0.450344	array([[ 3.3926396, -9.288166 ]], dtype=float32)
time = 20005	action = 0	current_phase = 0	next_phase = 1	reward = 1.002459	array([[ 3.3717065, -9.279678 ]], dtype=float32)
time = 20010	action = 0	current_phase = 0	next_phase = 1	reward = 0.724871	array([[ 3.3959947, -9.301805 ]], dtype=float32)
time = 20015	action = 0	current_phase = 0	next_phase = 1	reward = 0.443102	array([[ 3.4666944, -9.218875 ]], dtype=float32)
time = 20020	action = 0	current_phase = 0	next_phase = 1	reward = 1.002174	array([[ 3.3646502, -9.31773  ]], dtype=float32)
time = 20025	action = 0	current_phase = 0	next_phase = 1	reward = 0.441052	array([[ 3.3956923, -9.268064 ]], dtype=float32)
time = 20030	action = 0	current_phase = 0	next_phase = 1	reward = 0.727597	array([[ 3.3839507, -9.270365 ]], dtype=float32)
time = 20035	action = 0	current_phase = 0	next_phase = 1	reward = 1.008215	array([[ 3.3302684, -9.372588 ]], dtype=float32)
time = 20040	action = 0	current_phase = 0	next_phase = 1	reward = 0.729126	array([[ 3.3900657, -9.263893 ]], dtype=float32)
time = 20045	action = 0	current_phase = 0	next_phase = 1	reward = 0.720987	array([[ 3.4180827, -9.247137 ]], dtype=float32)
time = 20050	action = 0	current_phase = 0	next_phase = 1	reward = 0.722169	array([[ 3.3708434, -9.286532 ]], dtype=float32)
time = 20055	action = 0	current_phase = 0	next_phase = 1	reward = 0.724840	array([[ 3.380056, -9.273797]], dtype=float32)
time = 20060	action = 0	current_phase = 0	next_phase = 1	reward = 0.449709	array([[ 3.406345, -9.277404]], dtype=float32)
time = 20065	action = 0	current_phase = 0	next_phase = 1	reward = 1.003358	array([[ 3.3968377, -9.26515  ]], dtype=float32)
time = 20070	action = 0	current_phase = 0	next_phase = 1	reward = 0.716128	array([[ 3.4554362, -9.216917 ]], dtype=float32)
time = 20075	action = 0	current_phase = 0	next_phase = 1	reward = 0.445249	array([[ 3.4085717, -9.251778 ]], dtype=float32)
time = 20080	action = 0	current_phase = 0	next_phase = 1	reward = 1.007034	array([[ 3.3440871, -9.341477 ]], dtype=float32)
time = 20085	action = 0	current_phase = 0	next_phase = 1	reward = 0.454577	array([[ 3.3704286, -9.292154 ]], dtype=float32)
time = 20090	action = 0	current_phase = 0	next_phase = 1	reward = 1.009344	array([[ 3.3886333, -9.281355 ]], dtype=float32)
time = 20095	action = 0	current_phase = 0	next_phase = 1	reward = 0.717283	array([[ 3.4017472, -9.250236 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 5s - loss: 5.2883 - val_loss: 2.4060
Epoch 2/50
 - 5s - loss: 4.6984 - val_loss: 3.1281
Epoch 3/50
 - 4s - loss: 4.2935 - val_loss: 3.3658
Epoch 4/50
 - 5s - loss: 4.4831 - val_loss: 2.2027
Epoch 5/50
 - 5s - loss: 5.3419 - val_loss: 3.1258
Epoch 6/50
 - 6s - loss: 5.3124 - val_loss: 2.9036
Epoch 7/50
 - 5s - loss: 3.8889 - val_loss: 2.3003
Epoch 8/50
 - 5s - loss: 4.1259 - val_loss: 2.5940
Epoch 9/50
 - 5s - loss: 4.2106 - val_loss: 4.2941
Epoch 10/50
 - 5s - loss: 4.2926 - val_loss: 2.3975
Epoch 11/50
 - 5s - loss: 4.3101 - val_loss: 4.2799
Epoch 12/50
 - 5s - loss: 4.1393 - val_loss: 3.1034
Epoch 13/50
 - 5s - loss: 3.6882 - val_loss: 2.8979
Epoch 14/50
 - 5s - loss: 4.8498 - val_loss: 2.5737
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 20100	action = 0	current_phase = 0	next_phase = 1	reward = 0.719242	array([[ 3.4259644, -9.270865 ]], dtype=float32)
time = 20105	action = 0	current_phase = 0	next_phase = 1	reward = 0.715225	array([[ 3.390067 , -9.3207245]], dtype=float32)
time = 20110	action = 0	current_phase = 0	next_phase = 1	reward = 0.434792	array([[ 3.4047585, -9.302558 ]], dtype=float32)
time = 20115	action = 0	current_phase = 0	next_phase = 1	reward = 1.001268	array([[ 3.3880854, -9.307983 ]], dtype=float32)
time = 20120	action = 0	current_phase = 0	next_phase = 1	reward = 0.436393	array([[ 3.3811398, -9.312052 ]], dtype=float32)
time = 20125	action = 0	current_phase = 0	next_phase = 1	reward = 0.720180	array([[ 3.3748226, -9.326375 ]], dtype=float32)
time = 20130	action = 0	current_phase = 0	next_phase = 1	reward = 0.722161	array([[ 3.4007998, -9.3063965]], dtype=float32)
time = 20135	action = 0	current_phase = 0	next_phase = 1	reward = 0.725720	array([[ 3.382967, -9.322092]], dtype=float32)
time = 20140	action = 0	current_phase = 0	next_phase = 1	reward = 0.729534	array([[ 3.314268, -9.409784]], dtype=float32)
time = 20145	action = 0	current_phase = 0	next_phase = 1	reward = 1.001801	array([[ 3.4528646, -9.275644 ]], dtype=float32)
time = 20150	action = 0	current_phase = 0	next_phase = 1	reward = 0.715757	array([[ 3.412404, -9.331984]], dtype=float32)
time = 20155	action = 0	current_phase = 0	next_phase = 1	reward = 0.718327	array([[ 3.3624697, -9.334766 ]], dtype=float32)
time = 20160	action = 0	current_phase = 0	next_phase = 1	reward = 0.449234	array([[ 3.4090767, -9.299264 ]], dtype=float32)
time = 20165	action = 0	current_phase = 0	next_phase = 1	reward = 1.006462	array([[ 3.3609457, -9.354155 ]], dtype=float32)
time = 20170	action = 0	current_phase = 0	next_phase = 1	reward = 0.717591	array([[ 3.403389, -9.30065 ]], dtype=float32)
time = 20175	action = 0	current_phase = 0	next_phase = 1	reward = 0.161299	array([[ 3.4406052, -9.291567 ]], dtype=float32)
time = 20180	action = 0	current_phase = 0	next_phase = 1	reward = 1.003321	array([[ 3.3611479, -9.411037 ]], dtype=float32)
time = 20185	action = 0	current_phase = 0	next_phase = 1	reward = 0.726344	array([[ 3.3812218, -9.32844  ]], dtype=float32)
time = 20190	action = 0	current_phase = 0	next_phase = 1	reward = 1.012157	array([[ 3.3492422, -9.3528   ]], dtype=float32)
time = 20195	action = 0	current_phase = 0	next_phase = 1	reward = 0.442367	array([[ 3.4427795, -9.283751 ]], dtype=float32)
time = 20200	action = 0	current_phase = 0	next_phase = 1	reward = 0.999286	array([[ 3.0013933, -9.683598 ]], dtype=float32)
time = 20205	action = 0	current_phase = 0	next_phase = 1	reward = 0.437537	array([[ 3.3813858, -9.350161 ]], dtype=float32)
time = 20210	action = 0	current_phase = 0	next_phase = 1	reward = 0.723235	array([[ 3.3299427, -9.371808 ]], dtype=float32)
time = 20215	action = 0	current_phase = 0	next_phase = 1	reward = 0.730290	array([[ 3.3366737, -9.378696 ]], dtype=float32)
77time = 20220	action = 0	current_phase = 0	next_phase = 1	reward = 1.011890	array([[ 3.3973646, -9.303041 ]], dtype=float32)
time = 20225	action = 0	current_phase = 0	next_phase = 1	reward = 0.723634	array([[ 3.4319725, -9.276688 ]], dtype=float32)
time = 20230	action = 0	current_phase = 0	next_phase = 1	reward = 0.721778	array([[ 3.4204292, -9.278315 ]], dtype=float32)
 time = 20235	action = 0	current_phase = 0	next_phase = 1	reward = 0.445700	array([[ 3.3819036, -9.325479 ]], dtype=float32)
time = 20240	action = 0	current_phase = 0	next_phase = 1	reward = 1.004667	array([[ 3.410842, -9.297045]], dtype=float32)
time = 20245	action = 0	current_phase = 0	next_phase = 1	reward = 0.441452	array([[ 3.4259243, -9.30514  ]], dtype=float32)
time = 20250	action = 0	current_phase = 0	next_phase = 1	reward = 0.731106	array([[ 3.3880215, -9.322626 ]], dtype=float32)
time = 20255	action = 0	current_phase = 0	next_phase = 1	reward = 0.998656	array([[ 3.3456955, -9.3661375]], dtype=float32)
time = 20260	action = 0	current_phase = 0	next_phase = 1	reward = 0.442038	array([[ 3.3525858, -9.365089 ]], dtype=float32)
time = 20265	action = 0	current_phase = 0	next_phase = 1	reward = 1.007380	array([[ 3.4264126, -9.265722 ]], dtype=float32)
time = 20270	action = 0	current_phase = 0	next_phase = 1	reward = 0.440774	array([[ 3.3914795, -9.306051 ]], dtype=float32)
time = 20275	action = 0	current_phase = 0	next_phase = 1	reward = 0.999437	array([[ 3.4421682, -9.301117 ]], dtype=float32)
time = 20280	action = 0	current_phase = 0	next_phase = 1	reward = 0.442087	array([[ 3.41008, -9.29628]], dtype=float32)
time = 20285	action = 0	current_phase = 0	next_phase = 1	reward = 1.006829	array([[ 3.4164734, -9.280872 ]], dtype=float32)
time = 20290	action = 0	current_phase = 0	next_phase = 1	reward = 0.716478	array([[ 3.3843946, -9.34248  ]], dtype=float32)
time = 20295	action = 0	current_phase = 0	next_phase = 1	reward = 0.438635	array([[ 3.3973932, -9.306893 ]], dtype=float32)
time = 20300	action = 0	current_phase = 0	next_phase = 1	reward = 0.991554	array([[ 3.3728256, -9.346033 ]], dtype=float32)
time = 20305	action = 0	current_phase = 0	next_phase = 1	reward = 0.724079	array([[ 3.4404354, -9.2678585]], dtype=float32)
time = 20310	action = 0	current_phase = 0	next_phase = 1	reward = 0.726091	array([[ 3.366951, -9.350002]], dtype=float32)
time = 20315	action = 0	current_phase = 0	next_phase = 1	reward = 0.718068	array([[ 3.3975563, -9.341629 ]], dtype=float32)
time = 20320	action = 0	current_phase = 0	next_phase = 1	reward = 0.715714	array([[ 3.441287, -9.2621  ]], dtype=float32)
time = 20325	action = 0	current_phase = 0	next_phase = 1	reward = 0.434304	array([[ 3.4134226, -9.285349 ]], dtype=float32)
time = 20330	action = 0	current_phase = 0	next_phase = 1	reward = 0.724836	array([[ 3.421073, -9.288584]], dtype=float32)
time = 20335	action = 0	current_phase = 0	next_phase = 1	reward = 1.012564	array([[ 3.3972569, -9.305241 ]], dtype=float32)
time = 20340	action = 0	current_phase = 0	next_phase = 1	reward = 0.720389	array([[ 3.2496586, -9.566469 ]], dtype=float32)
time = 20345	action = 0	current_phase = 0	next_phase = 1	reward = 0.438861	array([[ 3.478673, -9.265224]], dtype=float32)
time = 20350	action = 0	current_phase = 0	next_phase = 1	reward = 1.004672	array([[ 3.367303, -9.354635]], dtype=float32)
time = 20355	action = 0	current_phase = 0	next_phase = 1	reward = 0.714885	array([[ 3.398965, -9.309231]], dtype=float32)
time = 20360	action = 0	current_phase = 0	next_phase = 1	reward = 0.724359	array([[ 3.4219484, -9.280699 ]], dtype=float32)
time = 20365	action = 0	current_phase = 0	next_phase = 1	reward = 0.442921	array([[ 3.4282522, -9.269296 ]], dtype=float32)
time = 20370	action = 0	current_phase = 0	next_phase = 1	reward = 1.008995	array([[ 3.3915615, -9.344749 ]], dtype=float32)
time = 20375	action = 0	current_phase = 0	next_phase = 1	reward = 0.442940	array([[ 3.4157248, -9.292882 ]], dtype=float32)
time = 20380	action = 0	current_phase = 0	next_phase = 1	reward = 1.002008	array([[ 3.3454628, -9.37426  ]], dtype=float32)
time = 20385	action = 0	current_phase = 0	next_phase = 1	reward = 0.721670	array([[ 3.422038, -9.266096]], dtype=float32)
time = 20390	action = 0	current_phase = 0	next_phase = 1	reward = 0.718912	array([[ 3.407671, -9.282885]], dtype=float32)
time = 20395	action = 0	current_phase = 0	next_phase = 1	reward = 0.160974	array([[ 3.4044142, -9.295294 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 5s - loss: 4.7995 - val_loss: 2.1664
Epoch 2/50
 - 4s - loss: 4.9690 - val_loss: 1.8104
Epoch 3/50
 - 5s - loss: 4.0118 - val_loss: 2.2855
Epoch 4/50
 - 5s - loss: 4.3497 - val_loss: 2.9032
Epoch 5/50
 - 4s - loss: 4.3720 - val_loss: 2.0978
Epoch 6/50
 - 5s - loss: 4.2233 - val_loss: 2.4343
Epoch 7/50
 - 5s - loss: 4.3729 - val_loss: 2.7095
Epoch 8/50
 - 5s - loss: 3.8997 - val_loss: 1.6723
Epoch 9/50
 - 5s - loss: 4.2055 - val_loss: 2.8053
Epoch 10/50
 - 5s - loss: 3.8443 - val_loss: 2.0665
Epoch 11/50
 - 5s - loss: 3.8547 - val_loss: 1.9728
Epoch 12/50
 - 5s - loss: 4.6095 - val_loss: 2.3693
Epoch 13/50
 - 5s - loss: 4.2841 - val_loss: 3.4612
Epoch 14/50
 - 5s - loss: 3.7535 - val_loss: 2.7311
Epoch 15/50
 - 5s - loss: 4.6004 - val_loss: 2.3674
Epoch 16/50
 - 5s - loss: 4.9988 - val_loss: 2.2391
Epoch 17/50
 - 5s - loss: 3.8812 - val_loss: 2.5126
Epoch 18/50
 - 5s - loss: 3.8124 - val_loss: 2.4246
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 20400	action = 0	current_phase = 0	next_phase = 1	reward = 1.003135	array([[ 3.2461314, -9.501518 ]], dtype=float32)
time = 20405	action = 0	current_phase = 0	next_phase = 1	reward = 0.724942	array([[ 3.3578305, -9.389408 ]], dtype=float32)
time = 20410	action = 0	current_phase = 0	next_phase = 1	reward = 0.721519	array([[ 3.2971349, -9.456278 ]], dtype=float32)
time = 20415	action = 0	current_phase = 0	next_phase = 1	reward = 1.004461	array([[ 3.3565955, -9.386582 ]], dtype=float32)
time = 20420	action = 0	current_phase = 0	next_phase = 1	reward = 0.447426	array([[ 3.412375, -9.339784]], dtype=float32)
time = 20425	action = 0	current_phase = 0	next_phase = 1	reward = 1.005079	array([[ 3.391913, -9.335463]], dtype=float32)
time = 20430	action = 0	current_phase = 0	next_phase = 1	reward = 0.729026	array([[ 3.4388442, -9.364943 ]], dtype=float32)
time = 20435	action = 0	current_phase = 0	next_phase = 1	reward = 0.443069	array([[ 3.3854642, -9.34656  ]], dtype=float32)
time = 20440	action = 0	current_phase = 0	next_phase = 1	reward = 0.998843	array([[ 3.229693, -9.65057 ]], dtype=float32)
time = 20445	action = 0	current_phase = 0	next_phase = 1	reward = 0.162784	array([[ 3.404036 , -9.3217125]], dtype=float32)
time = 20450	action = 0	current_phase = 0	next_phase = 1	reward = 0.732539	array([[ 3.3524404, -9.3906765]], dtype=float32)
time = 20455	action = 0	current_phase = 0	next_phase = 1	reward = 1.011017	array([[ 3.2635627, -9.57556  ]], dtype=float32)
time = 20460	action = 0	current_phase = 0	next_phase = 1	reward = 1.006532	array([[ 3.3228202, -9.508772 ]], dtype=float32)
time = 20465	action = 0	current_phase = 0	next_phase = 1	reward = 0.725948	array([[ 3.4172473, -9.311865 ]], dtype=float32)
time = 20470	action = 0	current_phase = 0	next_phase = 1	reward = 0.719791	array([[ 3.348724, -9.386083]], dtype=float32)
time = 20475	action = 0	current_phase = 0	next_phase = 1	reward = 0.444338	array([[ 3.3268476, -9.414804 ]], dtype=float32)
time = 20480	action = 0	current_phase = 0	next_phase = 1	reward = 1.002494	array([[ 3.374104, -9.362412]], dtype=float32)
time = 20485	action = 0	current_phase = 0	next_phase = 1	reward = 0.720693	array([[ 3.3311925, -9.455591 ]], dtype=float32)
time = 20490	action = 0	current_phase = 0	next_phase = 1	reward = 0.445887	array([[ 3.3741498, -9.3631935]], dtype=float32)
time = 20495	action = 0	current_phase = 0	next_phase = 1	reward = 1.000761	array([[ 3.4749608, -9.271762 ]], dtype=float32)
time = 20500	action = 0	current_phase = 0	next_phase = 1	reward = 0.437121	array([[ 3.427156, -9.329696]], dtype=float32)
time = 20505	action = 0	current_phase = 0	next_phase = 1	reward = 0.996447	array([[ 3.3259873, -9.425236 ]], dtype=float32)
time = 20510	action = 0	current_phase = 0	next_phase = 1	reward = 0.718484	array([[ 3.3455386, -9.392084 ]], dtype=float32)
time = 20515	action = 0	current_phase = 0	next_phase = 1	reward = 0.159791	array([[ 3.3892512, -9.338699 ]], dtype=float32)
time = 20520	action = 0	current_phase = 0	next_phase = 1	reward = 1.012294	array([[ 3.309507, -9.466635]], dtype=float32)
time = 20525	action = 0	current_phase = 0	next_phase = 1	reward = 1.007441	array([[ 3.4241652, -9.333595 ]], dtype=float32)
time = 20530	action = 0	current_phase = 0	next_phase = 1	reward = 0.457686	array([[ 3.3830037, -9.3416395]], dtype=float32)
time = 20535	action = 0	current_phase = 0	next_phase = 1	reward = 1.006134	array([[ 3.3870807, -9.346119 ]], dtype=float32)
time = 20540	action = 0	current_phase = 0	next_phase = 1	reward = 0.722267	array([[ 3.3773122, -9.368086 ]], dtype=float32)
time = 20545	action = 0	current_phase = 0	next_phase = 1	reward = 0.722366	array([[ 3.3812861, -9.357256 ]], dtype=float32)
time = 20550	action = 0	current_phase = 0	next_phase = 1	reward = 0.720325	array([[ 3.3771224, -9.365849 ]], dtype=float32)
time = 20555	action = 0	current_phase = 0	next_phase = 1	reward = 0.721422	array([[ 3.4188352, -9.328312 ]], dtype=float32)
time = 20560	action = 0	current_phase = 0	next_phase = 1	reward = 0.444320	array([[ 3.343203, -9.416575]], dtype=float32)
time = 20565	action = 0	current_phase = 0	next_phase = 1	reward = 0.728936	array([[ 3.4013133, -9.345245 ]], dtype=float32)
time = 20570	action = 0	current_phase = 0	next_phase = 1	reward = 1.003729	array([[ 3.3181272, -9.41279  ]], dtype=float32)
time = 20575	action = 0	current_phase = 0	next_phase = 1	reward = 0.715257	array([[ 3.3457246, -9.526482 ]], dtype=float32)
time = 20580	action = 0	current_phase = 0	next_phase = 1	reward = 0.713237	array([[ 3.3938613, -9.379087 ]], dtype=float32)
time = 20585	action = 0	current_phase = 0	next_phase = 1	reward = 0.446826	array([[ 3.4212098, -9.312586 ]], dtype=float32)
time = 20590	action = 0	current_phase = 0	next_phase = 1	reward = 0.727380	array([[ 3.34438 , -9.605369]], dtype=float32)
time = 20595	action = 0	current_phase = 0	next_phase = 1	reward = 1.006258	array([[ 3.3409505, -9.484621 ]], dtype=float32)
time = 20600	action = 0	current_phase = 0	next_phase = 1	reward = 0.719967	array([[ 3.4012113, -9.358343 ]], dtype=float32)
time = 20605	action = 0	current_phase = 0	next_phase = 1	reward = 0.719477	array([[ 3.3953624, -9.33832  ]], dtype=float32)
time = 20610	action = 0	current_phase = 0	next_phase = 1	reward = 0.443554	array([[ 3.3731875, -9.364001 ]], dtype=float32)
time = 20615	action = 0	current_phase = 0	next_phase = 1	reward = 1.001670	array([[ 3.3820271, -9.370842 ]], dtype=float32)
time = 20620	action = 0	current_phase = 0	next_phase = 1	reward = 0.719319	array([[ 3.3966079, -9.3572445]], dtype=float32)
time = 20625	action = 0	current_phase = 0	next_phase = 1	reward = 0.726801	array([[ 3.377192, -9.371197]], dtype=float32)
time = 20630	action = 0	current_phase = 0	next_phase = 1	reward = 0.721726	array([[ 3.3996577, -9.339476 ]], dtype=float32)
time = 20635	action = 0	current_phase = 0	next_phase = 1	reward = 0.725294	array([[ 3.3972106, -9.357288 ]], dtype=float32)
time = 20640	action = 0	current_phase = 0	next_phase = 1	reward = 0.718903	array([[ 3.4055905, -9.324853 ]], dtype=float32)
time = 20645	action = 0	current_phase = 0	next_phase = 1	reward = 0.443743	array([[ 3.369946, -9.366365]], dtype=float32)
time = 20650	action = 0	current_phase = 0	next_phase = 1	reward = 1.013381	array([[ 3.3883405, -9.34025  ]], dtype=float32)
time = 20655	action = 0	current_phase = 0	next_phase = 1	reward = 0.729076	array([[ 3.4225945, -9.313719 ]], dtype=float32)
time = 20660	action = 0	current_phase = 0	next_phase = 1	reward = 0.446808	array([[ 3.3599286, -9.366337 ]], dtype=float32)
time = 20665	action = 0	current_phase = 0	next_phase = 1	reward = 1.005763	array([[ 3.4044852, -9.324666 ]], dtype=float32)
time = 20670	action = 0	current_phase = 0	next_phase = 1	reward = 0.723936	array([[ 3.4735742, -9.285699 ]], dtype=float32)
time = 20675	action = 0	current_phase = 0	next_phase = 1	reward = 0.723134	array([[ 3.4512296, -9.289349 ]], dtype=float32)
time = 20680	action = 0	current_phase = 0	next_phase = 1	reward = 0.721469	array([[ 3.399055, -9.345512]], dtype=float32)
time = 20685	action = 0	current_phase = 0	next_phase = 1	reward = 0.720987	array([[ 3.302711, -9.482651]], dtype=float32)
time = 20690	action = 0	current_phase = 0	next_phase = 1	reward = 0.721613	array([[ 3.344336, -9.395815]], dtype=float32)
time = 20695	action = 0	current_phase = 0	next_phase = 1	reward = 0.718448	array([[ 3.4076772, -9.33756  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.5172 - val_loss: 2.5277
Epoch 2/50
 - 4s - loss: 4.5448 - val_loss: 3.1235
Epoch 3/50
 - 4s - loss: 4.7203 - val_loss: 2.7447
Epoch 4/50
 - 4s - loss: 3.9111 - val_loss: 3.2055
Epoch 5/50
 - 4s - loss: 4.7479 - val_loss: 2.4370
Epoch 6/50
 - 4s - loss: 4.3037 - val_loss: 2.7933
Epoch 7/50
 - 4s - loss: 4.2147 - val_loss: 2.5119
Epoch 8/50
 - 4s - loss: 3.6736 - val_loss: 3.0039
Epoch 9/50
 - 4s - loss: 3.9439 - val_loss: 3.3798
Epoch 10/50
 - 4s - loss: 3.8864 - val_loss: 3.0212
Epoch 11/50
 - 4s - loss: 4.1363 - val_loss: 3.0831
Epoch 12/50
 - 4s - loss: 5.3469 - val_loss: 2.7171
Epoch 13/50
 - 4s - loss: 3.4073 - val_loss: 2.3124
Epoch 14/50
 - 4s - loss: 4.3141 - val_loss: 2.7206
Epoch 15/50
 - 4s - loss: 4.2034 - val_loss: 2.4262
Epoch 16/50
 - 4s - loss: 3.1339 - val_loss: 3.7230
Epoch 17/50
 - 4s - loss: 3.5046 - val_loss: 2.6206
Epoch 18/50
 - 4s - loss: 3.6427 - val_loss: 3.5176
Epoch 19/50
 - 4s - loss: 3.4530 - val_loss: 3.4432
Epoch 20/50
 - 4s - loss: 3.3631 - val_loss: 3.1811
Epoch 21/50
 - 4s - loss: 3.4324 - val_loss: 3.0213
Epoch 22/50
 - 4s - loss: 3.1855 - val_loss: 2.3417
Epoch 23/50
 - 4s - loss: 4.6977 - val_loss: 2.1474
Epoch 24/50
 - 4s - loss: 3.7904 - val_loss: 2.4163
Epoch 25/50
 - 4s - loss: 3.0364 - val_loss: 3.8393
Epoch 26/50
 - 4s - loss: 3.5088 - val_loss: 3.0303
Epoch 27/50
 - 4s - loss: 2.8856 - val_loss: 3.9970
Epoch 28/50
 - 4s - loss: 3.9078 - val_loss: 2.9352
Epoch 29/50
 - 4s - loss: 2.8110 - val_loss: 3.5789
Epoch 30/50
 - 4s - loss: 3.2908 - val_loss: 2.7336
Epoch 31/50
 - 4s - loss: 3.4935 - val_loss: 3.2479
Epoch 32/50
 - 4s - loss: 3.5422 - val_loss: 2.5620
Epoch 33/50
 - 4s - loss: 2.8057 - val_loss: 2.4539
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 20700	action = 0	current_phase = 0	next_phase = 1	reward = 0.717579	array([[ 3.4155765, -9.355995 ]], dtype=float32)
time = 20705	action = 0	current_phase = 0	next_phase = 1	reward = 0.727481	array([[ 3.4184852, -9.342579 ]], dtype=float32)
time = 20710	action = 0	current_phase = 0	next_phase = 1	reward = 0.723391	array([[ 3.4341397, -9.382247 ]], dtype=float32)
time = 20715	action = 0	current_phase = 0	next_phase = 1	reward = 0.727275	array([[ 3.4224524, -9.3480625]], dtype=float32)
time = 20720	action = 0	current_phase = 0	next_phase = 1	reward = 0.724293	array([[ 3.453568, -9.359351]], dtype=float32)
time = 20725	action = 0	current_phase = 0	next_phase = 1	reward = 0.444180	array([[ 3.4755292, -9.325634 ]], dtype=float32)
time = 20730	action = 0	current_phase = 0	next_phase = 1	reward = 0.999622	array([[ 3.306109, -9.48906 ]], dtype=float32)
time = 20735	action = 0	current_phase = 0	next_phase = 1	reward = 0.714892	array([[ 3.4892316, -9.386372 ]], dtype=float32)
time = 20740	action = 0	current_phase = 0	next_phase = 1	reward = 0.719665	array([[ 3.430369, -9.337816]], dtype=float32)
time = 20745	action = 0	current_phase = 0	next_phase = 1	reward = 0.443609	array([[ 3.4524846, -9.367811 ]], dtype=float32)
time = 20750	action = 0	current_phase = 0	next_phase = 1	reward = 0.728158	array([[ 3.4057565, -9.4626465]], dtype=float32)
time = 20755	action = 0	current_phase = 0	next_phase = 1	reward = 1.003060	array([[ 3.5283513, -9.297825 ]], dtype=float32)
time = 20760	action = 0	current_phase = 0	next_phase = 1	reward = 0.166806	array([[ 3.3890557, -9.361561 ]], dtype=float32)
time = 20765	action = 0	current_phase = 0	next_phase = 1	reward = 1.011071	array([[ 3.3223453, -9.516369 ]], dtype=float32)
time = 20770	action = 0	current_phase = 0	next_phase = 1	reward = 0.725580	array([[ 3.4247193, -9.392016 ]], dtype=float32)
time = 20775	action = 0	current_phase = 0	next_phase = 1	reward = 1.000466	array([[ 3.4625764, -9.366423 ]], dtype=float32)
time = 20780	action = 0	current_phase = 0	next_phase = 1	reward = 0.443139	array([[ 3.433516, -9.323376]], dtype=float32)
time = 20785	action = 0	current_phase = 0	next_phase = 1	reward = 1.009725	array([[ 3.3704915, -9.399217 ]], dtype=float32)
time = 20790	action = 0	current_phase = 0	next_phase = 1	reward = 0.730554	array([[ 3.4616055, -9.344187 ]], dtype=float32)
time = 20795	action = 0	current_phase = 0	next_phase = 1	reward = 0.731080	array([[ 3.4308553, -9.336042 ]], dtype=float32)
time = 20800	action = 0	current_phase = 0	next_phase = 1	reward = 0.719580	array([[ 3.4793658, -9.3142395]], dtype=float32)
time = 20805	action = 0	current_phase = 0	next_phase = 1	reward = 0.713974	array([[ 3.4775815, -9.375185 ]], dtype=float32)
time = 20810	action = 0	current_phase = 0	next_phase = 1	reward = 0.440032	array([[ 3.5024295, -9.286877 ]], dtype=float32)
time = 20815	action = 0	current_phase = 0	next_phase = 1	reward = 1.005110	array([[ 3.4685264, -9.365751 ]], dtype=float32)
time = 20820	action = 0	current_phase = 0	next_phase = 1	reward = 0.714028	array([[ 3.4604497, -9.357983 ]], dtype=float32)
time = 20825	action = 0	current_phase = 0	next_phase = 1	reward = 0.442526	array([[ 3.4136539, -9.366726 ]], dtype=float32)
time = 20830	action = 0	current_phase = 0	next_phase = 1	reward = 0.729246	array([[ 3.4168057, -9.383574 ]], dtype=float32)
time = 20835	action = 0	current_phase = 0	next_phase = 1	reward = 1.001210	array([[ 3.471435, -9.334448]], dtype=float32)
time = 20840	action = 0	current_phase = 0	next_phase = 1	reward = 0.720463	array([[ 3.4070792, -9.361229 ]], dtype=float32)
time = 20845	action = 0	current_phase = 0	next_phase = 1	reward = 0.444842	array([[ 3.3464522, -9.452753 ]], dtype=float32)
time = 20850	action = 0	current_phase = 0	next_phase = 1	reward = 1.005795	array([[ 3.4566875, -9.357689 ]], dtype=float32)
time = 20855	action = 0	current_phase = 0	next_phase = 1	reward = 0.718417	array([[ 3.4678712, -9.300411 ]], dtype=float32)
time = 20860	action = 0	current_phase = 0	next_phase = 1	reward = 0.714889	array([[ 3.3964925, -9.424154 ]], dtype=float32)
time = 20865	action = 0	current_phase = 0	next_phase = 1	reward = 0.440639	array([[ 3.4692101, -9.333632 ]], dtype=float32)
time = 20870	action = 0	current_phase = 0	next_phase = 1	reward = 1.008688	array([[ 3.4138684, -9.429071 ]], dtype=float32)
time = 20875	action = 0	current_phase = 0	next_phase = 1	reward = 0.720001	array([[ 3.4107337, -9.388239 ]], dtype=float32)
time = 20880	action = 0	current_phase = 0	next_phase = 1	reward = 0.725199	array([[ 3.4771657, -9.348778 ]], dtype=float32)
time = 20885	action = 0	current_phase = 0	next_phase = 1	reward = 0.455026	array([[ 3.441483, -9.314751]], dtype=float32)
time = 20890	action = 0	current_phase = 0	next_phase = 1	reward = 1.010617	array([[ 3.4235072, -9.36915  ]], dtype=float32)
time = 20895	action = 0	current_phase = 0	next_phase = 1	reward = 0.725759	array([[ 3.4098144, -9.385334 ]], dtype=float32)
time = 20900	action = 0	current_phase = 0	next_phase = 1	reward = 0.715217	array([[ 3.4391866, -9.3317175]], dtype=float32)
time = 20905	action = 0	current_phase = 0	next_phase = 1	reward = 0.719984	array([[ 3.4240546, -9.371826 ]], dtype=float32)
time = 20910	action = 0	current_phase = 0	next_phase = 1	reward = 0.726012	array([[ 3.4220538, -9.399171 ]], dtype=float32)
time = 20915	action = 0	current_phase = 0	next_phase = 1	reward = 0.719975	array([[ 3.4642606, -9.341228 ]], dtype=float32)
time = 20920	action = 0	current_phase = 0	next_phase = 1	reward = 0.724156	array([[ 3.4466767, -9.342265 ]], dtype=float32)
time = 20925	action = 0	current_phase = 0	next_phase = 1	reward = 0.725332	array([[ 3.4533944, -9.325476 ]], dtype=float32)
time = 20930	action = 0	current_phase = 0	next_phase = 1	reward = 0.721565	array([[ 3.4981942, -9.308094 ]], dtype=float32)
time = 20935	action = 0	current_phase = 0	next_phase = 1	reward = 0.723497	array([[ 3.4100175, -9.369537 ]], dtype=float32)
time = 20940	action = 0	current_phase = 0	next_phase = 1	reward = 0.710115	array([[ 3.4847884, -9.324448 ]], dtype=float32)
time = 20945	action = 0	current_phase = 0	next_phase = 1	reward = 0.717526	array([[ 3.430901, -9.384792]], dtype=float32)
time = 20950	action = 0	current_phase = 0	next_phase = 1	reward = 0.717128	array([[ 3.4371648, -9.383895 ]], dtype=float32)
time = 20955	action = 0	current_phase = 0	next_phase = 1	reward = 0.725441	array([[ 3.4177651, -9.333231 ]], dtype=float32)
time = 20960	action = 0	current_phase = 0	next_phase = 1	reward = 0.736359	array([[ 3.4276004, -9.336231 ]], dtype=float32)
time = 20965	action = 0	current_phase = 0	next_phase = 1	reward = 0.722915	array([[ 3.429871, -9.342308]], dtype=float32)
time = 20970	action = 0	current_phase = 0	next_phase = 1	reward = 0.719421	array([[ 3.4153113, -9.398816 ]], dtype=float32)
time = 20975	action = 0	current_phase = 0	next_phase = 1	reward = 0.449783	array([[ 3.4721265, -9.306049 ]], dtype=float32)
time = 20980	action = 0	current_phase = 0	next_phase = 1	reward = 0.724116	array([[ 3.4031959, -9.421564 ]], dtype=float32)
time = 20985	action = 0	current_phase = 0	next_phase = 1	reward = 0.997897	array([[ 3.442614, -9.3759  ]], dtype=float32)
time = 20990	action = 0	current_phase = 0	next_phase = 1	reward = 0.721284	array([[ 3.4807153, -9.31081  ]], dtype=float32)
time = 20995	action = 0	current_phase = 0	next_phase = 1	reward = 0.438286	array([[ 3.4302955, -9.371146 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.5969 - val_loss: 1.9261
Epoch 2/50
 - 4s - loss: 3.2647 - val_loss: 2.2246
Epoch 3/50
 - 4s - loss: 4.1873 - val_loss: 2.0418
Epoch 4/50
 - 4s - loss: 3.5531 - val_loss: 2.5556
Epoch 5/50
 - 4s - loss: 4.1230 - val_loss: 1.8866
Epoch 6/50
 - 4s - loss: 6.2918 - val_loss: 2.4034
Epoch 7/50
 - 4s - loss: 3.9935 - val_loss: 2.4302
Epoch 8/50
 - 4s - loss: 3.0242 - val_loss: 2.5295
Epoch 9/50
 - 4s - loss: 3.6230 - val_loss: 2.7360
Epoch 10/50
 - 4s - loss: 3.0848 - val_loss: 2.2764
Epoch 11/50
 - 4s - loss: 3.5912 - val_loss: 2.3363
Epoch 12/50
 - 4s - loss: 3.4162 - val_loss: 1.9323
Epoch 13/50
 - 4s - loss: 3.4718 - val_loss: 2.5913
Epoch 14/50
 - 4s - loss: 3.6828 - val_loss: 2.2681
Epoch 15/50
 - 4s - loss: 2.8497 - val_loss: 2.1886
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 21000	action = 0	current_phase = 0	next_phase = 1	reward = 0.725247	array([[ 3.3449636, -9.43529  ]], dtype=float32)
time = 21005	action = 0	current_phase = 0	next_phase = 1	reward = 1.015403	array([[ 3.3572936, -9.42429  ]], dtype=float32)
time = 21010	action = 0	current_phase = 0	next_phase = 1	reward = 0.712154	array([[ 3.3972058, -9.36356  ]], dtype=float32)
time = 21015	action = 0	current_phase = 0	next_phase = 1	reward = 0.722771	array([[ 3.3691602, -9.424431 ]], dtype=float32)
time = 21020	action = 0	current_phase = 0	next_phase = 1	reward = 0.715874	array([[ 3.4485116, -9.321287 ]], dtype=float32)
time = 21025	action = 0	current_phase = 0	next_phase = 1	reward = 0.712781	array([[ 3.4233184, -9.370606 ]], dtype=float32)
time = 21030	action = 0	current_phase = 0	next_phase = 1	reward = 0.438068	array([[ 3.4050813, -9.386757 ]], dtype=float32)
time = 21035	action = 0	current_phase = 0	next_phase = 1	reward = 0.727426	array([[ 3.3485055, -9.428788 ]], dtype=float32)
time = 21040	action = 0	current_phase = 0	next_phase = 1	reward = 0.728342	array([[ 3.2782578, -9.59359  ]], dtype=float32)
time = 21045	action = 0	current_phase = 0	next_phase = 1	reward = 1.006988	array([[ 3.4476686, -9.333521 ]], dtype=float32)
time = 21050	action = 0	current_phase = 0	next_phase = 1	reward = 0.721950	array([[ 3.451078, -9.302416]], dtype=float32)
time = 21055	action = 0	current_phase = 0	next_phase = 1	reward = 0.720517	array([[ 3.3684115, -9.403698 ]], dtype=float32)
time = 21060	action = 0	current_phase = 0	next_phase = 1	reward = 0.728363	array([[ 3.4033532, -9.371814 ]], dtype=float32)
time = 21065	action = 0	current_phase = 0	next_phase = 1	reward = 0.444624	array([[ 3.3537107, -9.395304 ]], dtype=float32)
time = 21070	action = 0	current_phase = 0	next_phase = 1	reward = 1.006232	array([[ 3.4031482, -9.380385 ]], dtype=float32)
time = 21075	action = 0	current_phase = 0	next_phase = 1	reward = 0.717398	array([[ 3.4003787, -9.360777 ]], dtype=float32)
time = 21080	action = 0	current_phase = 0	next_phase = 1	reward = 0.439973	array([[ 3.4001365, -9.351648 ]], dtype=float32)
time = 21085	action = 0	current_phase = 0	next_phase = 1	reward = 0.998889	array([[ 3.4245954, -9.341324 ]], dtype=float32)
time = 21090	action = 0	current_phase = 0	next_phase = 1	reward = 0.717208	array([[ 3.354486, -9.427687]], dtype=float32)
time = 21095	action = 0	current_phase = 0	next_phase = 1	reward = 0.175042	array([[ 3.4435277, -9.33477  ]], dtype=float32)
time = 21100	action = 0	current_phase = 0	next_phase = 1	reward = 1.283937	array([[ 3.2879767, -9.499201 ]], dtype=float32)
time = 21105	action = 0	current_phase = 0	next_phase = 1	reward = 0.716328	array([[ 3.4319272, -9.347333 ]], dtype=float32)
time = 21110	action = 0	current_phase = 0	next_phase = 1	reward = 0.165352	array([[ 3.4913144, -9.28657  ]], dtype=float32)
time = 21115	action = 0	current_phase = 0	next_phase = 1	reward = 1.298923	array([[ 3.3871684, -9.403225 ]], dtype=float32)
time = 21120	action = 0	current_phase = 0	next_phase = 1	reward = 0.727441	array([[ 3.3360476, -9.440073 ]], dtype=float32)
time = 21125	action = 0	current_phase = 0	next_phase = 1	reward = 0.723252	array([[ 3.358111, -9.410646]], dtype=float32)
time = 21130	action = 0	current_phase = 0	next_phase = 1	reward = 0.717281	array([[ 3.4031587, -9.359591 ]], dtype=float32)
time = 21135	action = 0	current_phase = 0	next_phase = 1	reward = 0.710159	array([[ 3.4523168, -9.315416 ]], dtype=float32)
time = 21140	action = 0	current_phase = 0	next_phase = 1	reward = 0.439671	array([[ 3.4446683, -9.330423 ]], dtype=float32)
time = 21145	action = 0	current_phase = 0	next_phase = 1	reward = 1.015020	array([[ 3.1127257, -9.6764965]], dtype=float32)
time = 21150	action = 0	current_phase = 0	next_phase = 1	reward = 0.717411	array([[ 3.44706 , -9.327396]], dtype=float32)
time = 21155	action = 0	current_phase = 0	next_phase = 1	reward = 0.719480	array([[ 3.3773646, -9.375227 ]], dtype=float32)
time = 21160	action = 0	current_phase = 0	next_phase = 1	reward = 0.447877	array([[ 3.4076867, -9.359007 ]], dtype=float32)
time = 21165	action = 0	current_phase = 0	next_phase = 1	reward = 1.012530	array([[ 3.372521, -9.387142]], dtype=float32)
time = 21170	action = 0	current_phase = 0	next_phase = 1	reward = 0.718086	array([[ 3.3726163, -9.404118 ]], dtype=float32)
time = 21175	action = 0	current_phase = 0	next_phase = 1	reward = 0.164120	array([[ 3.397882, -9.377895]], dtype=float32)
time = 21180	action = 0	current_phase = 0	next_phase = 1	reward = 1.284244	array([[ 3.4101987, -9.367343 ]], dtype=float32)
time = 21185	action = 0	current_phase = 0	next_phase = 1	reward = 0.432640	array([[ 3.4406915, -9.400967 ]], dtype=float32)
time = 21190	action = 0	current_phase = 0	next_phase = 1	reward = 1.001839	array([[ 3.3659148, -9.414837 ]], dtype=float32)
time = 21195	action = 0	current_phase = 0	next_phase = 1	reward = 0.434961	array([[ 3.4078135, -9.346418 ]], dtype=float32)
time = 21200	action = 0	current_phase = 0	next_phase = 1	reward = 1.003971	array([[ 3.4203925, -9.358481 ]], dtype=float32)
time = 21205	action = 0	current_phase = 0	next_phase = 1	reward = 0.441246	array([[ 3.4628358, -9.321287 ]], dtype=float32)
time = 21210	action = 0	current_phase = 0	next_phase = 1	reward = 1.007359	array([[ 3.3870025, -9.436896 ]], dtype=float32)
time = 21215	action = 0	current_phase = 0	next_phase = 1	reward = 0.721468	array([[ 3.41394 , -9.330454]], dtype=float32)
time = 21220	action = 0	current_phase = 0	next_phase = 1	reward = 0.713255	array([[ 3.361074, -9.43055 ]], dtype=float32)
time = 21225	action = 0	current_phase = 0	next_phase = 1	reward = 0.160131	array([[ 3.4709334, -9.303892 ]], dtype=float32)
time = 21230	action = 0	current_phase = 0	next_phase = 1	reward = 1.012534	array([[ 3.265491, -9.576128]], dtype=float32)
time = 21235	action = 0	current_phase = 0	next_phase = 1	reward = 0.725000	array([[ 3.3502192, -9.42601  ]], dtype=float32)
time = 21240	action = 0	current_phase = 0	next_phase = 1	reward = 1.010152	array([[ 3.3683991, -9.440046 ]], dtype=float32)
time = 21245	action = 0	current_phase = 0	next_phase = 1	reward = 0.729514	array([[ 3.3735118, -9.395609 ]], dtype=float32)
time = 21250	action = 0	current_phase = 0	next_phase = 1	reward = 0.717633	array([[ 3.3668122, -9.400196 ]], dtype=float32)
time = 21255	action = 0	current_phase = 0	next_phase = 1	reward = 0.717308	array([[ 3.416224, -9.40749 ]], dtype=float32)
time = 21260	action = 0	current_phase = 0	next_phase = 1	reward = 0.442769	array([[ 3.3997512, -9.359125 ]], dtype=float32)
time = 21265	action = 0	current_phase = 0	next_phase = 1	reward = 0.451622	array([[ 3.2935128, -9.499716 ]], dtype=float32)
time = 21270	action = 0	current_phase = 0	next_phase = 1	reward = 1.290691	array([[ 3.2764049, -9.508692 ]], dtype=float32)
time = 21275	action = 0	current_phase = 0	next_phase = 1	reward = 0.444105	array([[ 3.4198117, -9.328299 ]], dtype=float32)
time = 21280	action = 0	current_phase = 0	next_phase = 1	reward = 1.004095	array([[ 3.367432, -9.404111]], dtype=float32)
time = 21285	action = 0	current_phase = 0	next_phase = 1	reward = 0.723056	array([[ 3.4023871, -9.403961 ]], dtype=float32)
time = 21290	action = 0	current_phase = 0	next_phase = 1	reward = 0.725366	array([[ 3.393046, -9.361053]], dtype=float32)
time = 21295	action = 0	current_phase = 0	next_phase = 1	reward = 0.723346	array([[ 3.370275, -9.410589]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.5850 - val_loss: 4.4135
Epoch 2/50
 - 4s - loss: 4.4760 - val_loss: 3.8826
Epoch 3/50
 - 4s - loss: 5.2675 - val_loss: 3.9096
Epoch 4/50
 - 4s - loss: 5.0006 - val_loss: 3.4901
Epoch 5/50
 - 4s - loss: 5.1211 - val_loss: 3.9476
Epoch 6/50
 - 4s - loss: 4.4808 - val_loss: 3.4136
Epoch 7/50
 - 4s - loss: 4.3006 - val_loss: 3.5765
Epoch 8/50
 - 4s - loss: 3.6328 - val_loss: 3.1043
Epoch 9/50
 - 4s - loss: 4.5990 - val_loss: 3.3803
Epoch 10/50
 - 4s - loss: 3.9368 - val_loss: 3.6574
Epoch 11/50
 - 4s - loss: 4.6965 - val_loss: 4.2719
Epoch 12/50
 - 4s - loss: 4.3077 - val_loss: 3.3492
Epoch 13/50
 - 4s - loss: 3.4027 - val_loss: 3.0949
Epoch 14/50
 - 4s - loss: 4.7895 - val_loss: 3.5132
Epoch 15/50
 - 4s - loss: 4.9306 - val_loss: 4.5730
Epoch 16/50
 - 4s - loss: 3.8620 - val_loss: 3.9876
Epoch 17/50
 - 4s - loss: 3.4933 - val_loss: 3.8310
Epoch 18/50
 - 4s - loss: 3.9757 - val_loss: 3.6835
Epoch 19/50
 - 4s - loss: 3.7929 - val_loss: 3.0173
Epoch 20/50
 - 4s - loss: 4.0524 - val_loss: 3.6809
Epoch 21/50
 - 4s - loss: 5.7720 - val_loss: 4.3499
Epoch 22/50
 - 4s - loss: 3.1827 - val_loss: 3.5616
Epoch 23/50
 - 4s - loss: 3.5749 - val_loss: 4.2065
Epoch 24/50
 - 4s - loss: 4.3170 - val_loss: 3.5682
Epoch 25/50
 - 5s - loss: 5.5787 - val_loss: 4.1803
Epoch 26/50
 - 4s - loss: 3.9134 - val_loss: 3.0297
Epoch 27/50
 - 4s - loss: 3.8778 - val_loss: 4.2336
Epoch 28/50
 - 4s - loss: 3.4942 - val_loss: 3.4200
Epoch 29/50
 - 4s - loss: 4.3935 - val_loss: 3.4883
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 21300	action = 0	current_phase = 0	next_phase = 1	reward = 0.714655	array([[ 3.4672217, -9.367395 ]], dtype=float32)
time = 21305	action = 0	current_phase = 0	next_phase = 1	reward = 0.716543	array([[ 3.4380927, -9.397068 ]], dtype=float32)
time = 21310	action = 0	current_phase = 0	next_phase = 1	reward = 0.437695	array([[ 3.4599166, -9.395415 ]], dtype=float32)
time = 21315	action = 0	current_phase = 0	next_phase = 1	reward = 0.998568	array([[ 3.4021869, -9.463131 ]], dtype=float32)
time = 21320	action = 0	current_phase = 0	next_phase = 1	reward = 0.717864	array([[ 3.4474683, -9.3824215]], dtype=float32)
time = 21325	action = 0	current_phase = 0	next_phase = 1	reward = 0.731310	array([[ 3.4100747, -9.474554 ]], dtype=float32)
time = 21330	action = 0	current_phase = 0	next_phase = 1	reward = 0.166919	array([[ 3.3769794, -9.489265 ]], dtype=float32)
time = 21335	action = 0	current_phase = 0	next_phase = 1	reward = 1.294663	array([[ 3.16777 , -9.772865]], dtype=float32)
time = 21340	action = 0	current_phase = 0	next_phase = 1	reward = 0.726390	array([[ 3.3717942, -9.454905 ]], dtype=float32)
time = 21345	action = 0	current_phase = 0	next_phase = 1	reward = 0.450346	array([[ 3.411076, -9.466303]], dtype=float32)
time = 21350	action = 0	current_phase = 0	next_phase = 1	reward = 1.008249	array([[ 3.4241633, -9.45171  ]], dtype=float32)
time = 21355	action = 0	current_phase = 0	next_phase = 1	reward = 0.722256	array([[ 3.3996053, -9.438983 ]], dtype=float32)
time = 21360	action = 0	current_phase = 0	next_phase = 1	reward = 0.717836	array([[ 3.3962445, -9.422256 ]], dtype=float32)
time = 21365	action = 0	current_phase = 0	next_phase = 1	reward = 0.716385	array([[ 3.5045896, -9.375891 ]], dtype=float32)
time = 21370	action = 0	current_phase = 0	next_phase = 1	reward = 0.711815	array([[ 3.45163 , -9.385473]], dtype=float32)
time = 21375	action = 0	current_phase = 0	next_phase = 1	reward = 0.718925	array([[ 3.4468484, -9.368612 ]], dtype=float32)
time = 21380	action = 0	current_phase = 0	next_phase = 1	reward = 0.721845	array([[ 3.424335, -9.449114]], dtype=float32)
time = 21385	action = 0	current_phase = 0	next_phase = 1	reward = 0.717888	array([[ 3.4170632, -9.432037 ]], dtype=float32)
time = 21390	action = 0	current_phase = 0	next_phase = 1	reward = 0.715865	array([[ 3.4323936, -9.678652 ]], dtype=float32)
time = 21395	action = 0	current_phase = 0	next_phase = 1	reward = 0.440462	array([[ 3.4341846, -9.445005 ]], dtype=float32)
time = 21400	action = 0	current_phase = 0	next_phase = 1	reward = 0.729022	array([[ 3.4047189, -9.444889 ]], dtype=float32)
time = 21405	action = 0	current_phase = 0	next_phase = 1	reward = 1.009766	array([[ 3.359116, -9.503487]], dtype=float32)
time = 21410	action = 0	current_phase = 0	next_phase = 1	reward = 0.442144	array([[ 3.4002929, -9.464535 ]], dtype=float32)
time = 21415	action = 0	current_phase = 0	next_phase = 1	reward = 1.007855	array([[ 3.4111838, -9.419247 ]], dtype=float32)
time = 21420	action = 0	current_phase = 0	next_phase = 1	reward = 0.443956	array([[ 3.458465, -9.386391]], dtype=float32)
time = 21425	action = 0	current_phase = 0	next_phase = 1	reward = 1.010373	array([[ 3.2496495, -9.71109  ]], dtype=float32)
time = 21430	action = 0	current_phase = 0	next_phase = 1	reward = 0.722382	array([[ 3.4943233, -9.349131 ]], dtype=float32)
time = 21435	action = 0	current_phase = 0	next_phase = 1	reward = 0.170073	array([[ 3.4492164, -9.386429 ]], dtype=float32)
time = 21440	action = 0	current_phase = 0	next_phase = 1	reward = 1.284117	array([[ 3.2779155, -9.641749 ]], dtype=float32)
time = 21445	action = 0	current_phase = 0	next_phase = 1	reward = 0.439304	array([[ 3.45009 , -9.394372]], dtype=float32)
time = 21450	action = 0	current_phase = 0	next_phase = 1	reward = 1.004595	array([[ 3.457893, -9.374359]], dtype=float32)
time = 21455	action = 0	current_phase = 0	next_phase = 1	reward = 0.447837	array([[ 3.4307122, -9.396348 ]], dtype=float32)
time = 21460	action = 0	current_phase = 0	next_phase = 1	reward = 0.736510	array([[ 3.4186215, -9.459551 ]], dtype=float32)
time = 21465	action = 0	current_phase = 0	next_phase = 1	reward = 0.996788	array([[ 3.3300118, -9.518513 ]], dtype=float32)
time = 21470	action = 0	current_phase = 0	next_phase = 1	reward = 0.712983	array([[ 3.4507976, -9.446791 ]], dtype=float32)
time = 21475	action = 0	current_phase = 0	next_phase = 1	reward = 0.445311	array([[ 3.4069514, -9.4412   ]], dtype=float32)
time = 21480	action = 0	current_phase = 0	next_phase = 1	reward = 1.008247	array([[ 3.4035869, -9.463755 ]], dtype=float32)
time = 21485	action = 0	current_phase = 0	next_phase = 1	reward = 0.718755	array([[ 3.441153, -9.38463 ]], dtype=float32)
time = 21490	action = 0	current_phase = 0	next_phase = 1	reward = 0.720615	array([[ 3.4923882, -9.379052 ]], dtype=float32)
time = 21495	action = 0	current_phase = 0	next_phase = 1	reward = 0.718240	array([[ 3.3897023, -9.444545 ]], dtype=float32)
time = 21500	action = 0	current_phase = 0	next_phase = 1	reward = 0.157486	array([[ 3.5169387, -9.318057 ]], dtype=float32)
time = 21505	action = 0	current_phase = 0	next_phase = 1	reward = 1.287836	array([[ 3.2770114, -9.615757 ]], dtype=float32)
time = 21510	action = 0	current_phase = 0	next_phase = 1	reward = 0.729545	array([[ 3.4820752, -9.359325 ]], dtype=float32)
time = 21515	action = 0	current_phase = 0	next_phase = 1	reward = 0.729156	array([[ 3.450891 , -9.3714695]], dtype=float32)
time = 21520	action = 0	current_phase = 0	next_phase = 1	reward = 0.729199	array([[ 3.4428391, -9.3942375]], dtype=float32)
time = 21525	action = 0	current_phase = 0	next_phase = 1	reward = 0.708775	array([[ 3.4200244, -9.431696 ]], dtype=float32)
time = 21530	action = 0	current_phase = 0	next_phase = 1	reward = 0.435995	array([[ 3.4638906, -9.360218 ]], dtype=float32)
time = 21535	action = 0	current_phase = 0	next_phase = 1	reward = 0.999218	array([[ 3.4447522, -9.395176 ]], dtype=float32)
time = 21540	action = 0	current_phase = 0	next_phase = 1	reward = 0.172772	array([[ 3.396626, -9.453182]], dtype=float32)
time = 21545	action = 0	current_phase = 0	next_phase = 1	reward = 1.286493	array([[ 3.3687358, -9.600256 ]], dtype=float32)
time = 21550	action = 0	current_phase = 0	next_phase = 1	reward = 0.440829	array([[ 3.4505076, -9.403147 ]], dtype=float32)
time = 21555	action = 0	current_phase = 0	next_phase = 1	reward = 1.009701	array([[ 3.3903747, -9.309324 ]], dtype=float32)
time = 21560	action = 0	current_phase = 0	next_phase = 1	reward = 0.714702	array([[ 3.3010716, -9.582201 ]], dtype=float32)
time = 21565	action = 0	current_phase = 0	next_phase = 1	reward = 0.431030	array([[ 3.4535804, -9.365345 ]], dtype=float32)
time = 21570	action = 0	current_phase = 0	next_phase = 1	reward = 0.718945	array([[ 3.4236712, -9.407234 ]], dtype=float32)
time = 21575	action = 0	current_phase = 0	next_phase = 1	reward = 0.732016	array([[ 3.4176974, -9.438547 ]], dtype=float32)
time = 21580	action = 0	current_phase = 0	next_phase = 1	reward = 0.728770	array([[ 3.437673, -9.492506]], dtype=float32)
time = 21585	action = 0	current_phase = 0	next_phase = 1	reward = 1.011247	array([[ 3.4127603, -9.435323 ]], dtype=float32)
time = 21590	action = 0	current_phase = 0	next_phase = 1	reward = 0.718946	array([[ 3.4962363, -9.3449955]], dtype=float32)
time = 21595	action = 0	current_phase = 0	next_phase = 1	reward = 0.719250	array([[ 3.3851771, -9.459992 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.6691 - val_loss: 3.1374
Epoch 2/50
 - 4s - loss: 5.3184 - val_loss: 3.4633
Epoch 3/50
 - 5s - loss: 4.9493 - val_loss: 2.8808
Epoch 4/50
 - 5s - loss: 3.4580 - val_loss: 2.9134
Epoch 5/50
 - 4s - loss: 4.0566 - val_loss: 2.4604
Epoch 6/50
 - 4s - loss: 3.7439 - val_loss: 2.1334
Epoch 7/50
 - 4s - loss: 3.9155 - val_loss: 3.5269
Epoch 8/50
 - 4s - loss: 5.2352 - val_loss: 2.0303
Epoch 9/50
 - 5s - loss: 3.8757 - val_loss: 2.7439
Epoch 10/50
 - 5s - loss: 5.1955 - val_loss: 2.3725
Epoch 11/50
 - 4s - loss: 4.1352 - val_loss: 2.7845
Epoch 12/50
 - 4s - loss: 3.5493 - val_loss: 2.6497
Epoch 13/50
 - 4s - loss: 3.7011 - val_loss: 2.7455
Epoch 14/50
 - 4s - loss: 3.4765 - val_loss: 3.5419
Epoch 15/50
 - 5s - loss: 3.7980 - val_loss: 3.4813
Epoch 16/50
 - 5s - loss: 3.4923 - val_loss: 2.7959
Epoch 17/50
 - 5s - loss: 3.6762 - val_loss: 3.0487
Epoch 18/50
 - 4s - loss: 3.3340 - val_loss: 3.2361
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 21600	action = 0	current_phase = 0	next_phase = 1	reward = 0.719062	array([[ 3.5530596, -9.365822 ]], dtype=float32)
time = 21605	action = 0	current_phase = 0	next_phase = 1	reward = 0.721448	array([[ 3.4632444, -9.467604 ]], dtype=float32)
time = 21610	action = 0	current_phase = 0	next_phase = 1	reward = 0.723294	array([[ 3.5272236, -9.374594 ]], dtype=float32)
time = 21615	action = 0	current_phase = 0	next_phase = 1	reward = 0.720258	array([[ 3.5540953, -9.370998 ]], dtype=float32)
time = 21620	action = 0	current_phase = 0	next_phase = 1	reward = 0.718560	array([[ 3.4964714, -9.397441 ]], dtype=float32)
time = 21625	action = 0	current_phase = 0	next_phase = 1	reward = 0.440569	array([[ 3.4938917, -9.407947 ]], dtype=float32)
time = 21630	action = 0	current_phase = 0	next_phase = 1	reward = 0.733189	array([[ 3.511547, -9.40885 ]], dtype=float32)
time = 21635	action = 0	current_phase = 0	next_phase = 1	reward = 1.008387	array([[ 3.464364, -9.446888]], dtype=float32)
time = 21640	action = 0	current_phase = 0	next_phase = 1	reward = 0.729211	array([[ 3.4461012, -9.461185 ]], dtype=float32)
time = 21645	action = 0	current_phase = 0	next_phase = 1	reward = 0.710398	array([[ 3.4598904, -9.420435 ]], dtype=float32)
time = 21650	action = 0	current_phase = 0	next_phase = 1	reward = 0.444577	array([[ 3.4656982, -9.459259 ]], dtype=float32)
time = 21655	action = 0	current_phase = 0	next_phase = 1	reward = 0.724697	array([[ 3.5587978, -9.389261 ]], dtype=float32)
time = 21660	action = 0	current_phase = 0	next_phase = 1	reward = 1.004039	array([[ 3.5301256, -9.382668 ]], dtype=float32)
time = 21665	action = 0	current_phase = 0	next_phase = 1	reward = 0.725992	array([[ 3.525486, -9.382948]], dtype=float32)
time = 21670	action = 0	current_phase = 0	next_phase = 1	reward = 0.720282	array([[ 3.460826, -9.445929]], dtype=float32)
time = 21675	action = 0	current_phase = 0	next_phase = 1	reward = 0.451085	array([[ 3.52526 , -9.389069]], dtype=float32)
time = 21680	action = 0	current_phase = 0	next_phase = 1	reward = 0.722915	array([[ 3.4697065, -9.445232 ]], dtype=float32)
time = 21685	action = 0	current_phase = 0	next_phase = 1	reward = 1.005277	array([[ 3.3452444, -9.606733 ]], dtype=float32)
time = 21690	action = 0	current_phase = 0	next_phase = 1	reward = 0.721702	array([[ 3.532405, -9.37022 ]], dtype=float32)
time = 21695	action = 0	current_phase = 0	next_phase = 1	reward = 0.715571	array([[ 3.5686188, -9.330397 ]], dtype=float32)
time = 21700	action = 0	current_phase = 0	next_phase = 1	reward = 0.722457	array([[ 3.5030031, -9.3916445]], dtype=float32)
time = 21705	action = 0	current_phase = 0	next_phase = 1	reward = 0.716405	array([[ 3.560234, -9.409521]], dtype=float32)
time = 21710	action = 0	current_phase = 0	next_phase = 1	reward = 0.440060	array([[ 3.5587273, -9.367826 ]], dtype=float32)
time = 21715	action = 0	current_phase = 0	next_phase = 1	reward = 0.999101	array([[ 3.5409508, -9.376539 ]], dtype=float32)
time = 21720	action = 0	current_phase = 0	next_phase = 1	reward = 0.440348	array([[ 3.5511465, -9.335428 ]], dtype=float32)
time = 21725	action = 0	current_phase = 0	next_phase = 1	reward = 0.445758	array([[ 3.242425, -9.852653]], dtype=float32)
time = 21730	action = 0	current_phase = 0	next_phase = 1	reward = 1.016693	array([[ 3.194625, -9.818563]], dtype=float32)
time = 21735	action = 0	current_phase = 0	next_phase = 1	reward = 1.012022	array([[ 3.5132914, -9.40982  ]], dtype=float32)
time = 21740	action = 0	current_phase = 0	next_phase = 1	reward = 0.737532	array([[ 3.4809208, -9.4136505]], dtype=float32)
time = 21745	action = 0	current_phase = 0	next_phase = 1	reward = 0.723362	array([[ 3.4643898, -9.456905 ]], dtype=float32)
time = 21750	action = 0	current_phase = 0	next_phase = 1	reward = 0.718581	array([[ 3.4064808, -9.51958  ]], dtype=float32)
time = 21755	action = 0	current_phase = 0	next_phase = 1	reward = 0.718127	array([[ 3.4731197, -9.433363 ]], dtype=float32)
time = 21760	action = 0	current_phase = 0	next_phase = 1	reward = 0.445622	array([[ 3.510418, -9.392916]], dtype=float32)
time = 21765	action = 0	current_phase = 0	next_phase = 1	reward = 1.000811	array([[ 3.48131 , -9.430437]], dtype=float32)
time = 21770	action = 0	current_phase = 0	next_phase = 1	reward = 0.439230	array([[ 3.475895, -9.432715]], dtype=float32)
time = 21775	action = 0	current_phase = 0	next_phase = 1	reward = 1.006325	array([[ 3.2292004, -9.77108  ]], dtype=float32)
time = 21780	action = 0	current_phase = 0	next_phase = 1	reward = 0.167733	array([[ 3.5216722, -9.374098 ]], dtype=float32)
time = 21785	action = 0	current_phase = 0	next_phase = 1	reward = 1.283736	array([[ 3.4384537, -9.492233 ]], dtype=float32)
time = 21790	action = 0	current_phase = 0	next_phase = 1	reward = 0.448245	array([[ 3.5081863, -9.426216 ]], dtype=float32)
time = 21795	action = 0	current_phase = 0	next_phase = 1	reward = 0.723782	array([[ 3.4328575, -9.4712515]], dtype=float32)
time = 21800	action = 0	current_phase = 0	next_phase = 1	reward = 1.002260	array([[ 3.40061  , -9.4467125]], dtype=float32)
time = 21805	action = 0	current_phase = 0	next_phase = 1	reward = 0.445964	array([[ 3.511548, -9.388763]], dtype=float32)
time = 21810	action = 0	current_phase = 0	next_phase = 1	reward = 1.006558	array([[ 3.4239817, -9.552183 ]], dtype=float32)
time = 21815	action = 0	current_phase = 0	next_phase = 1	reward = 0.723822	array([[ 3.5529976, -9.364244 ]], dtype=float32)
time = 21820	action = 0	current_phase = 0	next_phase = 1	reward = 0.729810	array([[ 3.5403404, -9.379933 ]], dtype=float32)
time = 21825	action = 0	current_phase = 0	next_phase = 1	reward = 0.445935	array([[ 3.4663801, -9.423189 ]], dtype=float32)
time = 21830	action = 0	current_phase = 0	next_phase = 1	reward = 0.731471	array([[ 3.476447, -9.469438]], dtype=float32)
time = 21835	action = 0	current_phase = 0	next_phase = 1	reward = 1.004517	array([[ 3.466979, -9.461477]], dtype=float32)
time = 21840	action = 0	current_phase = 0	next_phase = 1	reward = 0.722230	array([[ 3.50591 , -9.395372]], dtype=float32)
time = 21845	action = 0	current_phase = 0	next_phase = 1	reward = 0.725255	array([[ 3.5427732, -9.361206 ]], dtype=float32)
time = 21850	action = 0	current_phase = 0	next_phase = 1	reward = 0.718792	array([[ 3.42768 , -9.497522]], dtype=float32)
time = 21855	action = 0	current_phase = 0	next_phase = 1	reward = 0.720460	array([[ 3.5011387, -9.380579 ]], dtype=float32)
time = 21860	action = 0	current_phase = 0	next_phase = 1	reward = 0.438255	array([[ 3.5364237, -9.38639  ]], dtype=float32)
time = 21865	action = 0	current_phase = 0	next_phase = 1	reward = 1.006055	array([[ 3.5036697, -9.384201 ]], dtype=float32)
time = 21870	action = 0	current_phase = 0	next_phase = 1	reward = 0.445400	array([[ 3.5025187, -9.410362 ]], dtype=float32)
time = 21875	action = 0	current_phase = 0	next_phase = 1	reward = 1.005859	array([[ 3.4942703, -9.40704  ]], dtype=float32)
time = 21880	action = 0	current_phase = 0	next_phase = 1	reward = 0.715298	array([[ 3.4836235, -9.4145775]], dtype=float32)
time = 21885	action = 0	current_phase = 0	next_phase = 1	reward = 0.164479	array([[ 3.5387878, -9.403423 ]], dtype=float32)
time = 21890	action = 0	current_phase = 0	next_phase = 1	reward = 1.285935	array([[ 3.3828173, -9.597328 ]], dtype=float32)
time = 21895	action = 0	current_phase = 0	next_phase = 1	reward = 0.721048	array([[ 3.4508743, -9.446507 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.9389 - val_loss: 2.6215
Epoch 2/50
 - 4s - loss: 4.3100 - val_loss: 2.4573
Epoch 3/50
 - 4s - loss: 4.4513 - val_loss: 1.9047
Epoch 4/50
 - 4s - loss: 4.6157 - val_loss: 2.0888
Epoch 5/50
 - 4s - loss: 4.8812 - val_loss: 2.6880
Epoch 6/50
 - 4s - loss: 3.9668 - val_loss: 2.3334
Epoch 7/50
 - 4s - loss: 3.8579 - val_loss: 3.2870
Epoch 8/50
 - 4s - loss: 4.0880 - val_loss: 2.8998
Epoch 9/50
 - 4s - loss: 5.1200 - val_loss: 2.7120
Epoch 10/50
 - 4s - loss: 4.3810 - val_loss: 2.5719
Epoch 11/50
 - 4s - loss: 4.1259 - val_loss: 2.6796
Epoch 12/50
 - 4s - loss: 4.9961 - val_loss: 2.4319
Epoch 13/50
 - 4s - loss: 4.4914 - val_loss: 2.3616
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 21900	action = 0	current_phase = 0	next_phase = 1	reward = 0.713923	array([[ 3.3625054, -9.470487 ]], dtype=float32)
time = 21905	action = 0	current_phase = 0	next_phase = 1	reward = 0.442152	array([[ 3.3698077, -9.447308 ]], dtype=float32)
time = 21910	action = 0	current_phase = 0	next_phase = 1	reward = 0.721547	array([[ 3.3860965, -9.4320135]], dtype=float32)
time = 21915	action = 0	current_phase = 0	next_phase = 1	reward = 1.002333	array([[ 3.4365745, -9.41011  ]], dtype=float32)
time = 21920	action = 0	current_phase = 0	next_phase = 1	reward = 0.726979	array([[ 3.4160132, -9.4479885]], dtype=float32)
time = 21925	action = 0	current_phase = 0	next_phase = 1	reward = 0.442347	array([[ 3.3461804, -9.505107 ]], dtype=float32)
time = 21930	action = 0	current_phase = 0	next_phase = 1	reward = 1.012745	array([[ 3.3640752, -9.469376 ]], dtype=float32)
time = 21935	action = 0	current_phase = 0	next_phase = 1	reward = 0.720438	array([[ 3.4717813, -9.387701 ]], dtype=float32)
time = 21940	action = 0	current_phase = 0	next_phase = 1	reward = 0.711637	array([[ 3.3030229, -9.5588045]], dtype=float32)
time = 21945	action = 0	current_phase = 0	next_phase = 1	reward = 0.439464	array([[ 3.4170842, -9.43199  ]], dtype=float32)
time = 21950	action = 0	current_phase = 0	next_phase = 1	reward = 0.998973	array([[ 3.4056993, -9.45606  ]], dtype=float32)
time = 21955	action = 0	current_phase = 0	next_phase = 1	reward = 0.722756	array([[ 3.297855, -9.580517]], dtype=float32)
time = 21960	action = 0	current_phase = 0	next_phase = 1	reward = 0.455856	array([[ 3.4131713, -9.382313 ]], dtype=float32)
time = 21965	action = 0	current_phase = 0	next_phase = 1	reward = 1.008189	array([[ 3.3796353, -9.465363 ]], dtype=float32)
time = 21970	action = 0	current_phase = 0	next_phase = 1	reward = 0.714492	array([[ 3.432961, -9.406244]], dtype=float32)
time = 21975	action = 0	current_phase = 0	next_phase = 1	reward = 0.722659	array([[ 3.4896016, -9.376048 ]], dtype=float32)
time = 21980	action = 0	current_phase = 0	next_phase = 1	reward = 0.439375	array([[ 3.3835568, -9.444872 ]], dtype=float32)
time = 21985	action = 0	current_phase = 0	next_phase = 1	reward = 0.735040	array([[ 3.3451934, -9.501644 ]], dtype=float32)
time = 21990	action = 0	current_phase = 0	next_phase = 1	reward = 1.011686	array([[ 3.1753888, -9.711618 ]], dtype=float32)
time = 21995	action = 0	current_phase = 0	next_phase = 1	reward = 0.443343	array([[ 3.4052787, -9.412781 ]], dtype=float32)
time = 22000	action = 0	current_phase = 0	next_phase = 1	reward = 0.995999	array([[ 3.402061, -9.461323]], dtype=float32)
time = 22005	action = 0	current_phase = 0	next_phase = 1	reward = 0.712859	array([[ 3.3993087, -9.463821 ]], dtype=float32)
time = 22010	action = 0	current_phase = 0	next_phase = 1	reward = 0.442619	array([[ 3.4188075, -9.409641 ]], dtype=float32)
time = 22015	action = 0	current_phase = 0	next_phase = 1	reward = 1.013708	array([[ 3.4106135, -9.435433 ]], dtype=float32)
time = 22020	action = 0	current_phase = 0	next_phase = 1	reward = 0.442498	array([[ 3.4507508, -9.430252 ]], dtype=float32)
time = 22025	action = 0	current_phase = 0	next_phase = 1	reward = 1.007784	array([[ 3.4204507, -9.44655  ]], dtype=float32)
time = 22030	action = 0	current_phase = 0	next_phase = 1	reward = 0.729408	array([[ 3.3746915, -9.472896 ]], dtype=float32)
time = 22035	action = 0	current_phase = 0	next_phase = 1	reward = 0.445627	array([[ 3.3924603, -9.434744 ]], dtype=float32)
time = 22040	action = 0	current_phase = 0	next_phase = 1	reward = 1.001562	array([[ 3.2901301, -9.578165 ]], dtype=float32)
time = 22045	action = 0	current_phase = 0	next_phase = 1	reward = 0.719862	array([[ 3.3391156, -9.530066 ]], dtype=float32)
time = 22050	action = 0	current_phase = 0	next_phase = 1	reward = 0.734466	array([[ 3.3903317, -9.458979 ]], dtype=float32)
time = 22055	action = 0	current_phase = 0	next_phase = 1	reward = 0.714288	array([[ 3.345509, -9.489248]], dtype=float32)
time = 22060	action = 0	current_phase = 0	next_phase = 1	reward = 0.721750	array([[ 3.3901362, -9.408258 ]], dtype=float32)
time = 22065	action = 0	current_phase = 0	next_phase = 1	reward = 0.724471	array([[ 3.3895202, -9.435785 ]], dtype=float32)
time = 22070	action = 0	current_phase = 0	next_phase = 1	reward = 0.727735	array([[ 3.3917994, -9.426775 ]], dtype=float32)
time = 22075	action = 0	current_phase = 0	next_phase = 1	reward = 0.714766	array([[ 3.4266515, -9.439611 ]], dtype=float32)
time = 22080	action = 0	current_phase = 0	next_phase = 1	reward = 0.714090	array([[ 3.39397 , -9.455725]], dtype=float32)
time = 22085	action = 0	current_phase = 0	next_phase = 1	reward = 0.722756	array([[ 3.4380765, -9.419653 ]], dtype=float32)
time = 22090	action = 0	current_phase = 0	next_phase = 1	reward = 0.449321	array([[ 3.3629928, -9.462751 ]], dtype=float32)
time = 22095	action = 0	current_phase = 0	next_phase = 1	reward = 1.014158	array([[ 3.3536353, -9.4981365]], dtype=float32)
time = 22100	action = 0	current_phase = 0	next_phase = 1	reward = 0.722785	array([[ 3.4456038, -9.414372 ]], dtype=float32)
time = 22105	action = 0	current_phase = 0	next_phase = 1	reward = 0.723757	array([[ 3.4038815, -9.422381 ]], dtype=float32)
time = 22110	action = 0	current_phase = 0	next_phase = 1	reward = 0.724173	array([[ 3.3790965, -9.4591255]], dtype=float32)
time = 22115	action = 0	current_phase = 0	next_phase = 1	reward = 0.718478	array([[ 3.4658256, -9.44372  ]], dtype=float32)
time = 22120	action = 0	current_phase = 0	next_phase = 1	reward = 0.722148	array([[ 3.3553195, -9.472745 ]], dtype=float32)
time = 22125	action = 0	current_phase = 0	next_phase = 1	reward = 0.723679	array([[ 3.406446, -9.433474]], dtype=float32)
time = 22130	action = 0	current_phase = 0	next_phase = 1	reward = 0.713355	array([[ 3.3514285, -9.4656315]], dtype=float32)
time = 22135	action = 0	current_phase = 0	next_phase = 1	reward = 0.448956	array([[ 3.4758162, -9.380355 ]], dtype=float32)
time = 22140	action = 0	current_phase = 0	next_phase = 1	reward = 1.004424	array([[ 3.2822356, -9.575319 ]], dtype=float32)
time = 22145	action = 0	current_phase = 0	next_phase = 1	reward = 0.443444	array([[ 3.389233, -9.433611]], dtype=float32)
time = 22150	action = 0	current_phase = 0	next_phase = 1	reward = 0.729340	array([[ 3.2968802, -9.543812 ]], dtype=float32)
time = 22155	action = 0	current_phase = 0	next_phase = 1	reward = 1.010976	array([[ 3.2463164, -9.622158 ]], dtype=float32)
time = 22160	action = 0	current_phase = 0	next_phase = 1	reward = 0.442443	array([[ 3.384313, -9.520884]], dtype=float32)
time = 22165	action = 0	current_phase = 0	next_phase = 1	reward = 1.008213	array([[ 3.3871846, -9.432724 ]], dtype=float32)
time = 22170	action = 0	current_phase = 0	next_phase = 1	reward = 0.715114	array([[ 3.338735 , -9.5354395]], dtype=float32)
time = 22175	action = 0	current_phase = 0	next_phase = 1	reward = 0.441217	array([[ 3.3990445, -9.41514  ]], dtype=float32)
time = 22180	action = 0	current_phase = 0	next_phase = 1	reward = 1.015208	array([[ 3.3936238, -9.4475   ]], dtype=float32)
time = 22185	action = 0	current_phase = 0	next_phase = 1	reward = 0.447162	array([[ 3.3842807, -9.422611 ]], dtype=float32)
time = 22190	action = 0	current_phase = 0	next_phase = 1	reward = 0.728457	array([[ 3.3604417, -9.462261 ]], dtype=float32)
time = 22195	action = 0	current_phase = 0	next_phase = 1	reward = 1.002761	array([[ 3.3945003, -9.456247 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.2787 - val_loss: 2.4517
Epoch 2/50
 - 4s - loss: 4.8082 - val_loss: 2.3568
Epoch 3/50
 - 4s - loss: 4.6310 - val_loss: 2.5850
Epoch 4/50
 - 5s - loss: 5.3934 - val_loss: 2.5241
Epoch 5/50
 - 4s - loss: 4.1341 - val_loss: 3.0356
Epoch 6/50
 - 5s - loss: 4.6801 - val_loss: 2.8495
Epoch 7/50
 - 4s - loss: 4.2548 - val_loss: 2.6188
Epoch 8/50
 - 5s - loss: 4.1440 - val_loss: 2.6926
Epoch 9/50
 - 5s - loss: 4.4592 - val_loss: 2.1637
Epoch 10/50
 - 5s - loss: 5.0301 - val_loss: 2.1635
Epoch 11/50
 - 4s - loss: 4.3822 - val_loss: 3.3105
Epoch 12/50
 - 4s - loss: 5.2013 - val_loss: 2.4252
Epoch 13/50
 - 4s - loss: 4.5225 - val_loss: 2.5622
Epoch 14/50
 - 4s - loss: 3.7243 - val_loss: 2.3209
Epoch 15/50
 - 4s - loss: 3.7438 - val_loss: 2.3655
Epoch 16/50
 - 4s - loss: 4.1912 - val_loss: 2.4089
Epoch 17/50
 - 4s - loss: 6.1640 - val_loss: 2.7377
Epoch 18/50
 - 4s - loss: 4.4894 - val_loss: 2.9796
Epoch 19/50
 - 4s - loss: 3.9744 - val_loss: 2.8920
Epoch 20/50
 - 4s - loss: 4.3781 - val_loss: 2.5413
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 22200	action = 0	current_phase = 0	next_phase = 1	reward = 0.723402	array([[ 3.470345, -9.410704]], dtype=float32)
time = 22205	action = 0	current_phase = 0	next_phase = 1	reward = 0.721416	array([[ 3.4455972, -9.428209 ]], dtype=float32)
time = 22210	action = 0	current_phase = 0	next_phase = 1	reward = 0.452492	array([[ 3.4317021, -9.416094 ]], dtype=float32)
time = 22215	action = 0	current_phase = 0	next_phase = 1	reward = 0.997819	array([[ 3.4164739, -9.448101 ]], dtype=float32)
time = 22220	action = 0	current_phase = 0	next_phase = 1	reward = 0.721213	array([[ 3.4084697, -9.464001 ]], dtype=float32)
time = 22225	action = 0	current_phase = 0	next_phase = 1	reward = 0.165811	array([[ 3.4254212, -9.453135 ]], dtype=float32)
time = 22230	action = 0	current_phase = 0	next_phase = 1	reward = 1.291681	array([[ 3.3986707, -9.476613 ]], dtype=float32)
time = 22235	action = 0	current_phase = 0	next_phase = 1	reward = 0.731991	array([[ 3.4275413, -9.429815 ]], dtype=float32)
time = 22240	action = 0	current_phase = 0	next_phase = 1	reward = 0.716927	array([[ 3.3986506, -9.489696 ]], dtype=float32)
time = 22245	action = 0	current_phase = 0	next_phase = 1	reward = 0.720564	array([[ 3.4805827, -9.441988 ]], dtype=float32)
time = 22250	action = 0	current_phase = 0	next_phase = 1	reward = 0.718161	array([[ 3.4013638, -9.461298 ]], dtype=float32)
time = 22255	action = 0	current_phase = 0	next_phase = 1	reward = 0.451024	array([[ 3.3920932, -9.491529 ]], dtype=float32)
time = 22260	action = 0	current_phase = 0	next_phase = 1	reward = 0.728818	array([[ 3.4397674, -9.472748 ]], dtype=float32)
time = 22265	action = 0	current_phase = 0	next_phase = 1	reward = 1.005958	array([[ 3.4221997, -9.44541  ]], dtype=float32)
time = 22270	action = 0	current_phase = 0	next_phase = 1	reward = 0.719532	array([[ 3.4077811, -9.439299 ]], dtype=float32)
time = 22275	action = 0	current_phase = 0	next_phase = 1	reward = 0.717195	array([[ 3.405272, -9.463375]], dtype=float32)
time = 22280	action = 0	current_phase = 0	next_phase = 1	reward = 0.447281	array([[ 3.4138722, -9.462311 ]], dtype=float32)
time = 22285	action = 0	current_phase = 0	next_phase = 1	reward = 1.001918	array([[ 3.4325967, -9.426575 ]], dtype=float32)
time = 22290	action = 0	current_phase = 0	next_phase = 1	reward = 0.444970	array([[ 3.4387422, -9.516747 ]], dtype=float32)
time = 22295	action = 0	current_phase = 0	next_phase = 1	reward = 0.992912	array([[ 3.3537402, -9.514673 ]], dtype=float32)
time = 22300	action = 0	current_phase = 0	next_phase = 1	reward = 0.167781	array([[ 3.4793763, -9.454778 ]], dtype=float32)
time = 22305	action = 0	current_phase = 0	next_phase = 1	reward = 1.010944	array([[ 3.3624082, -9.53006  ]], dtype=float32)
time = 22310	action = 0	current_phase = 0	next_phase = 1	reward = 0.452472	array([[ 3.4104438, -9.465729 ]], dtype=float32)
time = 22315	action = 0	current_phase = 0	next_phase = 1	reward = 1.288175	array([[ 3.4028373, -9.456606 ]], dtype=float32)
time = 22320	action = 0	current_phase = 0	next_phase = 1	reward = 0.712195	array([[ 3.4203439, -9.442387 ]], dtype=float32)
time = 22325	action = 0	current_phase = 0	next_phase = 1	reward = 0.433762	array([[ 3.3799243, -9.474504 ]], dtype=float32)
time = 22330	action = 0	current_phase = 0	next_phase = 1	reward = 0.444591	array([[ 3.36447 , -9.509209]], dtype=float32)
time = 22335	action = 0	current_phase = 0	next_phase = 1	reward = 1.011596	array([[ 3.112718, -9.656642]], dtype=float32)
time = 22340	action = 0	current_phase = 0	next_phase = 1	reward = 1.004296	array([[ 3.4501166, -9.460801 ]], dtype=float32)
time = 22345	action = 0	current_phase = 0	next_phase = 1	reward = 0.726045	array([[ 3.4051118, -9.493883 ]], dtype=float32)
time = 22350	action = 0	current_phase = 0	next_phase = 1	reward = 0.441855	array([[ 3.4744325, -9.431342 ]], dtype=float32)
time = 22355	action = 0	current_phase = 0	next_phase = 1	reward = 0.997059	array([[ 3.3912606, -9.467751 ]], dtype=float32)
time = 22360	action = 0	current_phase = 0	next_phase = 1	reward = 0.713881	array([[ 3.4466405, -9.443216 ]], dtype=float32)
time = 22365	action = 0	current_phase = 0	next_phase = 1	reward = 0.721117	array([[ 3.3909717, -9.471681 ]], dtype=float32)
time = 22370	action = 0	current_phase = 0	next_phase = 1	reward = 0.449961	array([[ 3.3676324, -9.498348 ]], dtype=float32)
time = 22375	action = 0	current_phase = 0	next_phase = 1	reward = 0.448499	array([[ 3.3440938, -9.557802 ]], dtype=float32)
time = 22380	action = 0	current_phase = 0	next_phase = 1	reward = 1.284977	array([[ 3.31957, -9.64764]], dtype=float32)
time = 22385	action = 0	current_phase = 0	next_phase = 1	reward = 0.442236	array([[ 3.4838977, -9.406484 ]], dtype=float32)
time = 22390	action = 0	current_phase = 0	next_phase = 1	reward = 0.997511	array([[ 3.3935847, -9.479058 ]], dtype=float32)
time = 22395	action = 0	current_phase = 0	next_phase = 1	reward = 0.445771	array([[ 3.4627824, -9.459238 ]], dtype=float32)
time = 22400	action = 0	current_phase = 0	next_phase = 1	reward = 0.723589	array([[ 3.416881, -9.464457]], dtype=float32)
time = 22405	action = 0	current_phase = 0	next_phase = 1	reward = 1.001107	array([[ 3.4106097, -9.450013 ]], dtype=float32)
time = 22410	action = 0	current_phase = 0	next_phase = 1	reward = 0.725046	array([[ 3.427895, -9.424183]], dtype=float32)
time = 22415	action = 0	current_phase = 0	next_phase = 1	reward = 0.724761	array([[ 3.3846726, -9.49158  ]], dtype=float32)
time = 22420	action = 0	current_phase = 0	next_phase = 1	reward = 0.724184	array([[ 3.4197736, -9.459753 ]], dtype=float32)
time = 22425	action = 0	current_phase = 0	next_phase = 1	reward = 0.445941	array([[ 3.4447398, -9.412616 ]], dtype=float32)
time = 22430	action = 0	current_phase = 0	next_phase = 1	reward = 1.003035	array([[ 3.3551545, -9.514089 ]], dtype=float32)
time = 22435	action = 0	current_phase = 0	next_phase = 1	reward = 0.710668	array([[ 3.4327073, -9.452138 ]], dtype=float32)
time = 22440	action = 0	current_phase = 0	next_phase = 1	reward = 0.713638	array([[ 3.4642653, -9.409559 ]], dtype=float32)
time = 22445	action = 0	current_phase = 0	next_phase = 1	reward = 0.158781	array([[ 3.4655738, -9.430017 ]], dtype=float32)
time = 22450	action = 0	current_phase = 0	next_phase = 1	reward = 1.007210	array([[ 3.455008, -9.428536]], dtype=float32)
time = 22455	action = 0	current_phase = 0	next_phase = 1	reward = 0.728036	array([[ 3.2538466, -9.7111845]], dtype=float32)
time = 22460	action = 0	current_phase = 0	next_phase = 1	reward = 0.727219	array([[ 3.3963695, -9.478724 ]], dtype=float32)
time = 22465	action = 0	current_phase = 0	next_phase = 1	reward = 0.995231	array([[ 3.2981515, -9.628833 ]], dtype=float32)
time = 22470	action = 0	current_phase = 0	next_phase = 1	reward = 0.450665	array([[ 3.4215732, -9.441846 ]], dtype=float32)
time = 22475	action = 0	current_phase = 0	next_phase = 1	reward = 1.001641	array([[ 3.3558955, -9.530203 ]], dtype=float32)
time = 22480	action = 0	current_phase = 0	next_phase = 1	reward = 0.441847	array([[ 3.4117455, -9.5295315]], dtype=float32)
time = 22485	action = 0	current_phase = 0	next_phase = 1	reward = 0.732361	array([[ 3.4014592, -9.468134 ]], dtype=float32)
time = 22490	action = 0	current_phase = 0	next_phase = 1	reward = 1.001451	array([[ 3.4272847, -9.478554 ]], dtype=float32)
time = 22495	action = 0	current_phase = 0	next_phase = 1	reward = 0.723260	array([[ 3.3486562, -9.538403 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.0213 - val_loss: 3.0926
Epoch 2/50
 - 4s - loss: 4.5404 - val_loss: 3.4121
Epoch 3/50
 - 4s - loss: 4.0287 - val_loss: 2.5777
Epoch 4/50
 - 4s - loss: 3.7124 - val_loss: 3.0499
Epoch 5/50
 - 4s - loss: 3.8597 - val_loss: 3.3562
Epoch 6/50
 - 4s - loss: 4.3781 - val_loss: 3.2841
Epoch 7/50
 - 4s - loss: 4.9542 - val_loss: 3.5222
Epoch 8/50
 - 4s - loss: 4.5316 - val_loss: 3.1191
Epoch 9/50
 - 4s - loss: 2.9499 - val_loss: 3.8947
Epoch 10/50
 - 4s - loss: 4.0884 - val_loss: 3.3456
Epoch 11/50
 - 4s - loss: 3.0211 - val_loss: 2.9837
Epoch 12/50
 - 4s - loss: 3.3472 - val_loss: 2.6653
Epoch 13/50
 - 4s - loss: 4.3005 - val_loss: 3.3793
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 22500	action = 0	current_phase = 0	next_phase = 1	reward = 0.162646	array([[ 3.3748608, -9.512217 ]], dtype=float32)
time = 22505	action = 0	current_phase = 0	next_phase = 1	reward = 0.728936	array([[ 3.3398504, -9.540356 ]], dtype=float32)
time = 22510	action = 0	current_phase = 0	next_phase = 1	reward = 1.279552	array([[ 3.309866, -9.698643]], dtype=float32)
time = 22515	action = 0	current_phase = 0	next_phase = 1	reward = 0.167669	array([[ 3.3912573, -9.497271 ]], dtype=float32)
time = 22520	action = 0	current_phase = 0	next_phase = 1	reward = 1.285451	array([[ 3.3648062, -9.534316 ]], dtype=float32)
time = 22525	action = 0	current_phase = 0	next_phase = 1	reward = 0.725491	array([[ 3.4105377, -9.526339 ]], dtype=float32)
time = 22530	action = 0	current_phase = 0	next_phase = 1	reward = 0.724960	array([[ 3.4092321, -9.464487 ]], dtype=float32)
time = 22535	action = 0	current_phase = 0	next_phase = 1	reward = 0.724111	array([[ 3.382022, -9.509205]], dtype=float32)
time = 22540	action = 0	current_phase = 0	next_phase = 1	reward = 0.723433	array([[ 3.4286776, -9.45026  ]], dtype=float32)
time = 22545	action = 0	current_phase = 0	next_phase = 1	reward = 0.731246	array([[ 3.3916168, -9.490822 ]], dtype=float32)
time = 22550	action = 0	current_phase = 0	next_phase = 1	reward = 0.721076	array([[ 3.4832897, -9.425308 ]], dtype=float32)
time = 22555	action = 0	current_phase = 0	next_phase = 1	reward = 0.718643	array([[ 3.405551, -9.481367]], dtype=float32)
time = 22560	action = 0	current_phase = 0	next_phase = 1	reward = 0.726594	array([[ 3.461073, -9.404364]], dtype=float32)
time = 22565	action = 0	current_phase = 0	next_phase = 1	reward = 0.445130	array([[ 3.4536715, -9.461281 ]], dtype=float32)
time = 22570	action = 0	current_phase = 0	next_phase = 1	reward = 0.999842	array([[ 3.470254, -9.389929]], dtype=float32)
time = 22575	action = 0	current_phase = 0	next_phase = 1	reward = 0.719331	array([[ 3.4460993, -9.424639 ]], dtype=float32)
time = 22580	action = 0	current_phase = 0	next_phase = 1	reward = 0.736248	array([[ 3.4752493, -9.424525 ]], dtype=float32)
time = 22585	action = 0	current_phase = 0	next_phase = 1	reward = 0.449953	array([[ 3.428524, -9.433944]], dtype=float32)
time = 22590	action = 0	current_phase = 0	next_phase = 1	reward = 0.999865	array([[ 3.3810081, -9.497559 ]], dtype=float32)
time = 22595	action = 0	current_phase = 0	next_phase = 1	reward = 0.714660	array([[ 3.4691763, -9.39431  ]], dtype=float32)
time = 22600	action = 0	current_phase = 0	next_phase = 1	reward = 0.437273	array([[ 3.414524, -9.480895]], dtype=float32)
time = 22605	action = 0	current_phase = 0	next_phase = 1	reward = 1.006343	array([[ 3.3755064, -9.503166 ]], dtype=float32)
time = 22610	action = 0	current_phase = 0	next_phase = 1	reward = 0.713843	array([[ 3.4641943, -9.436714 ]], dtype=float32)
time = 22615	action = 0	current_phase = 0	next_phase = 1	reward = 0.441248	array([[ 3.4596014, -9.457726 ]], dtype=float32)
time = 22620	action = 0	current_phase = 0	next_phase = 1	reward = 0.723833	array([[ 3.466198, -9.408037]], dtype=float32)
time = 22625	action = 0	current_phase = 0	next_phase = 1	reward = 0.723116	array([[ 3.443883, -9.441547]], dtype=float32)
time = 22630	action = 0	current_phase = 0	next_phase = 1	reward = 0.730917	array([[ 3.4314194, -9.444175 ]], dtype=float32)
time = 22635	action = 0	current_phase = 0	next_phase = 1	reward = 1.005716	array([[ 3.3485556, -9.578053 ]], dtype=float32)
time = 22640	action = 0	current_phase = 0	next_phase = 1	reward = 0.451100	array([[ 3.4405394, -9.442497 ]], dtype=float32)
time = 22645	action = 0	current_phase = 0	next_phase = 1	reward = 1.004419	array([[ 3.4183474, -9.479993 ]], dtype=float32)
time = 22650	action = 0	current_phase = 0	next_phase = 1	reward = 0.723647	array([[ 3.4151115, -9.458832 ]], dtype=float32)
time = 22655	action = 0	current_phase = 0	next_phase = 1	reward = 0.723488	array([[ 3.507701, -9.384928]], dtype=float32)
time = 22660	action = 0	current_phase = 0	next_phase = 1	reward = 0.448876	array([[ 3.448494 , -9.4182205]], dtype=float32)
time = 22665	action = 0	current_phase = 0	next_phase = 1	reward = 1.004788	array([[ 3.4460602, -9.442726 ]], dtype=float32)
time = 22670	action = 0	current_phase = 0	next_phase = 1	reward = 0.721760	array([[ 3.3915482, -9.486763 ]], dtype=float32)
time = 22675	action = 0	current_phase = 0	next_phase = 1	reward = 0.450251	array([[ 3.453888, -9.409948]], dtype=float32)
time = 22680	action = 0	current_phase = 0	next_phase = 1	reward = 1.005984	array([[ 3.3669271, -9.534319 ]], dtype=float32)
time = 22685	action = 0	current_phase = 0	next_phase = 1	reward = 0.710217	array([[ 3.434287, -9.451288]], dtype=float32)
time = 22690	action = 0	current_phase = 0	next_phase = 1	reward = 0.716355	array([[ 3.4634714, -9.422647 ]], dtype=float32)
time = 22695	action = 0	current_phase = 0	next_phase = 1	reward = 0.440080	array([[ 3.475398, -9.41948 ]], dtype=float32)
time = 22700	action = 0	current_phase = 0	next_phase = 1	reward = 1.010268	array([[ 3.4395247, -9.431153 ]], dtype=float32)
time = 22705	action = 0	current_phase = 0	next_phase = 1	reward = 0.720217	array([[ 3.5068207, -9.420374 ]], dtype=float32)
time = 22710	action = 0	current_phase = 0	next_phase = 1	reward = 0.720386	array([[ 3.426446, -9.440622]], dtype=float32)
time = 22715	action = 0	current_phase = 0	next_phase = 1	reward = 0.716092	array([[ 3.4688683, -9.440307 ]], dtype=float32)
time = 22720	action = 0	current_phase = 0	next_phase = 1	reward = 0.718076	array([[ 3.424735, -9.468098]], dtype=float32)
time = 22725	action = 0	current_phase = 0	next_phase = 1	reward = 0.452404	array([[ 3.4348116, -9.454884 ]], dtype=float32)
time = 22730	action = 0	current_phase = 0	next_phase = 1	reward = 1.012372	array([[ 3.4338665, -9.447646 ]], dtype=float32)
time = 22735	action = 0	current_phase = 0	next_phase = 1	reward = 0.730110	array([[ 3.4100895, -9.482549 ]], dtype=float32)
time = 22740	action = 0	current_phase = 0	next_phase = 1	reward = 0.722408	array([[ 3.4869814, -9.400507 ]], dtype=float32)
time = 22745	action = 0	current_phase = 0	next_phase = 1	reward = 0.717148	array([[ 3.3996239, -9.498384 ]], dtype=float32)
time = 22750	action = 0	current_phase = 0	next_phase = 1	reward = 0.438737	array([[ 3.4333935, -9.455996 ]], dtype=float32)
time = 22755	action = 0	current_phase = 0	next_phase = 1	reward = 0.999679	array([[ 3.3930101, -9.496414 ]], dtype=float32)
time = 22760	action = 0	current_phase = 0	next_phase = 1	reward = 0.454254	array([[ 3.4840708, -9.402441 ]], dtype=float32)
time = 22765	action = 0	current_phase = 0	next_phase = 1	reward = 0.739669	array([[ 3.4692993, -9.4529   ]], dtype=float32)
time = 22770	action = 0	current_phase = 0	next_phase = 1	reward = 1.002337	array([[ 3.4208136, -9.435802 ]], dtype=float32)
time = 22775	action = 0	current_phase = 0	next_phase = 1	reward = 0.720597	array([[ 3.4690285, -9.417444 ]], dtype=float32)
time = 22780	action = 0	current_phase = 0	next_phase = 1	reward = 0.718676	array([[ 3.434536, -9.458784]], dtype=float32)
time = 22785	action = 0	current_phase = 0	next_phase = 1	reward = 0.440355	array([[ 3.433301, -9.470936]], dtype=float32)
time = 22790	action = 0	current_phase = 0	next_phase = 1	reward = 1.002341	array([[ 3.478423, -9.401772]], dtype=float32)
time = 22795	action = 0	current_phase = 0	next_phase = 1	reward = 0.729289	array([[ 3.4659786, -9.394935 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.5128 - val_loss: 2.2103
Epoch 2/50
 - 4s - loss: 4.1385 - val_loss: 2.2696
Epoch 3/50
 - 4s - loss: 3.9076 - val_loss: 2.6153
Epoch 4/50
 - 4s - loss: 3.7845 - val_loss: 2.5251
Epoch 5/50
 - 4s - loss: 3.5841 - val_loss: 2.4734
Epoch 6/50
 - 4s - loss: 3.3437 - val_loss: 3.1025
Epoch 7/50
 - 4s - loss: 3.7017 - val_loss: 3.4343
Epoch 8/50
 - 4s - loss: 3.7254 - val_loss: 2.3128
Epoch 9/50
 - 4s - loss: 3.0813 - val_loss: 2.1381
Epoch 10/50
 - 4s - loss: 3.7319 - val_loss: 2.9853
Epoch 11/50
 - 4s - loss: 3.9255 - val_loss: 3.0566
Epoch 12/50
 - 4s - loss: 3.3493 - val_loss: 2.7312
Epoch 13/50
 - 4s - loss: 3.0042 - val_loss: 2.2232
Epoch 14/50
 - 4s - loss: 3.1318 - val_loss: 2.2311
Epoch 15/50
 - 4s - loss: 4.0617 - val_loss: 2.3142
Epoch 16/50
 - 4s - loss: 3.4424 - val_loss: 2.0810
Epoch 17/50
 - 4s - loss: 4.0366 - val_loss: 3.1634
Epoch 18/50
 - 4s - loss: 3.4519 - val_loss: 3.0100
Epoch 19/50
 - 5s - loss: 3.6823 - val_loss: 2.4707
Epoch 20/50
 - 4s - loss: 3.5759 - val_loss: 2.7610
Epoch 21/50
 - 4s - loss: 3.7916 - val_loss: 2.9556
Epoch 22/50
 - 4s - loss: 3.6785 - val_loss: 2.0172
Epoch 23/50
 - 4s - loss: 3.0319 - val_loss: 2.5699
Epoch 24/50
 - 4s - loss: 3.2465 - val_loss: 2.3180
Epoch 25/50
 - 4s - loss: 4.9509 - val_loss: 2.1455
Epoch 26/50
 - 4s - loss: 3.0903 - val_loss: 2.5013
Epoch 27/50
 - 4s - loss: 3.5778 - val_loss: 2.2427
Epoch 28/50
 - 4s - loss: 3.2842 - val_loss: 2.8149
Epoch 29/50
 - 4s - loss: 4.2424 - val_loss: 3.6910
Epoch 30/50
 - 4s - loss: 2.6439 - val_loss: 2.5262
Epoch 31/50
 - 4s - loss: 2.8964 - val_loss: 2.5110
Epoch 32/50
 - 4s - loss: 3.2212 - val_loss: 2.4785
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 22800	action = 0	current_phase = 0	next_phase = 1	reward = 0.165037	array([[ 3.5648365, -9.409702 ]], dtype=float32)
time = 22805	action = 0	current_phase = 0	next_phase = 1	reward = 1.277893	array([[ 3.482479, -9.489323]], dtype=float32)
time = 22810	action = 0	current_phase = 0	next_phase = 1	reward = 0.726350	array([[ 3.475747, -9.495997]], dtype=float32)
time = 22815	action = 0	current_phase = 0	next_phase = 1	reward = 0.163455	array([[ 3.4809866, -9.49436  ]], dtype=float32)
time = 22820	action = 0	current_phase = 0	next_phase = 1	reward = 1.284006	array([[ 3.4877443, -9.490778 ]], dtype=float32)
time = 22825	action = 0	current_phase = 0	next_phase = 1	reward = 0.440063	array([[ 3.5436525, -9.439861 ]], dtype=float32)
time = 22830	action = 0	current_phase = 0	next_phase = 1	reward = 1.001897	array([[ 3.5010033, -9.466879 ]], dtype=float32)
time = 22835	action = 0	current_phase = 0	next_phase = 1	reward = 0.722396	array([[ 3.48903 , -9.464586]], dtype=float32)
time = 22840	action = 0	current_phase = 0	next_phase = 1	reward = 0.720991	array([[ 3.475419, -9.485286]], dtype=float32)
time = 22845	action = 0	current_phase = 0	next_phase = 1	reward = 0.438049	array([[ 3.4808626, -9.470053 ]], dtype=float32)
time = 22850	action = 0	current_phase = 0	next_phase = 1	reward = 0.998723	array([[ 3.499875, -9.474297]], dtype=float32)
time = 22855	action = 0	current_phase = 0	next_phase = 1	reward = 0.448195	array([[ 3.5556355, -9.448465 ]], dtype=float32)
time = 22860	action = 0	current_phase = 0	next_phase = 1	reward = 1.008035	array([[ 3.5659761, -9.431839 ]], dtype=float32)
time = 22865	action = 0	current_phase = 0	next_phase = 1	reward = 0.439874	array([[ 3.5090876, -9.467458 ]], dtype=float32)
time = 22870	action = 0	current_phase = 0	next_phase = 1	reward = 0.723945	array([[ 3.5074577, -9.46883  ]], dtype=float32)
time = 22875	action = 0	current_phase = 0	next_phase = 1	reward = 1.004690	array([[ 3.515297, -9.4545  ]], dtype=float32)
time = 22880	action = 0	current_phase = 0	next_phase = 1	reward = 0.719016	array([[ 3.5413017, -9.420029 ]], dtype=float32)
time = 22885	action = 0	current_phase = 0	next_phase = 1	reward = 0.717510	array([[ 3.514042, -9.435321]], dtype=float32)
time = 22890	action = 0	current_phase = 0	next_phase = 1	reward = 0.717254	array([[ 3.551115, -9.44136 ]], dtype=float32)
time = 22895	action = 0	current_phase = 0	next_phase = 1	reward = 0.446727	array([[ 3.5224276, -9.460176 ]], dtype=float32)
time = 22900	action = 0	current_phase = 0	next_phase = 1	reward = 1.002572	array([[ 3.4909658, -9.473707 ]], dtype=float32)
time = 22905	action = 0	current_phase = 0	next_phase = 1	reward = 0.163968	array([[ 3.526618, -9.410187]], dtype=float32)
time = 22910	action = 0	current_phase = 0	next_phase = 1	reward = 1.282920	array([[ 3.3778744, -9.695708 ]], dtype=float32)
time = 22915	action = 0	current_phase = 0	next_phase = 1	reward = 0.449386	array([[ 3.502553, -9.475773]], dtype=float32)
time = 22920	action = 0	current_phase = 0	next_phase = 1	reward = 1.006581	array([[ 3.5433884, -9.466428 ]], dtype=float32)
time = 22925	action = 0	current_phase = 0	next_phase = 1	reward = 0.719853	array([[ 3.467863, -9.53036 ]], dtype=float32)
time = 22930	action = 0	current_phase = 0	next_phase = 1	reward = 0.451346	array([[ 3.4958916, -9.468286 ]], dtype=float32)
time = 22935	action = 0	current_phase = 0	next_phase = 1	reward = 1.006979	array([[ 3.451313, -9.543715]], dtype=float32)
time = 22940	action = 0	current_phase = 0	next_phase = 1	reward = 0.730242	array([[ 3.5132484, -9.4750805]], dtype=float32)
time = 22945	action = 0	current_phase = 0	next_phase = 1	reward = 0.721427	array([[ 3.5212412, -9.433073 ]], dtype=float32)
time = 22950	action = 0	current_phase = 0	next_phase = 1	reward = 0.716478	array([[ 3.5252123, -9.431324 ]], dtype=float32)
time = 22955	action = 0	current_phase = 0	next_phase = 1	reward = 0.453462	array([[ 3.4923992, -9.477556 ]], dtype=float32)
time = 22960	action = 0	current_phase = 0	next_phase = 1	reward = 1.006465	array([[ 3.523571, -9.444918]], dtype=float32)
time = 22965	action = 0	current_phase = 0	next_phase = 1	reward = 0.722659	array([[ 3.5034285, -9.468639 ]], dtype=float32)
time = 22970	action = 0	current_phase = 0	next_phase = 1	reward = 0.721878	array([[ 3.5349588, -9.426235 ]], dtype=float32)
time = 22975	action = 0	current_phase = 0	next_phase = 1	reward = 0.721594	array([[ 3.5824385, -9.416662 ]], dtype=float32)
time = 22980	action = 0	current_phase = 0	next_phase = 1	reward = 0.723124	array([[ 3.5229387, -9.443426 ]], dtype=float32)
time = 22985	action = 0	current_phase = 0	next_phase = 1	reward = 0.442369	array([[ 3.5049276, -9.4616165]], dtype=float32)
time = 22990	action = 0	current_phase = 0	next_phase = 1	reward = 0.732446	array([[ 3.396041, -9.644669]], dtype=float32)
time = 22995	action = 0	current_phase = 0	next_phase = 1	reward = 1.005433	array([[ 3.4968328, -9.499241 ]], dtype=float32)
time = 23000	action = 0	current_phase = 0	next_phase = 1	reward = 0.729180	array([[ 3.5203686, -9.439567 ]], dtype=float32)
time = 23005	action = 0	current_phase = 0	next_phase = 1	reward = 0.723681	array([[ 3.5279016, -9.425764 ]], dtype=float32)
time = 23010	action = 0	current_phase = 0	next_phase = 1	reward = 0.718245	array([[ 3.5073261, -9.447525 ]], dtype=float32)
time = 23015	action = 0	current_phase = 0	next_phase = 1	reward = 0.717461	array([[ 3.5811062, -9.412857 ]], dtype=float32)
time = 23020	action = 0	current_phase = 0	next_phase = 1	reward = 0.715855	array([[ 3.4877777, -9.493904 ]], dtype=float32)
time = 23025	action = 0	current_phase = 0	next_phase = 1	reward = 0.443107	array([[ 3.4791145, -9.485878 ]], dtype=float32)
time = 23030	action = 0	current_phase = 0	next_phase = 1	reward = 0.721140	array([[ 3.420166, -9.556352]], dtype=float32)
time = 23035	action = 0	current_phase = 0	next_phase = 1	reward = 0.725619	array([[ 3.4170523, -9.491203 ]], dtype=float32)
time = 23040	action = 0	current_phase = 0	next_phase = 1	reward = 0.440815	array([[ 3.5039759, -9.498377 ]], dtype=float32)
time = 23045	action = 0	current_phase = 0	next_phase = 1	reward = 0.724687	array([[ 3.3424368, -9.682529 ]], dtype=float32)
time = 23050	action = 0	current_phase = 0	next_phase = 1	reward = 1.281589	array([[ 3.4157372, -9.542746 ]], dtype=float32)
time = 23055	action = 0	current_phase = 0	next_phase = 1	reward = 0.458359	array([[ 3.4999123, -9.454428 ]], dtype=float32)
time = 23060	action = 0	current_phase = 0	next_phase = 1	reward = 1.021073	array([[ 3.4385433, -9.545015 ]], dtype=float32)
time = 23065	action = 0	current_phase = 0	next_phase = 1	reward = 0.727088	array([[ 3.4938688, -9.483774 ]], dtype=float32)
time = 23070	action = 0	current_phase = 0	next_phase = 1	reward = 0.722337	array([[ 3.5047512, -9.452057 ]], dtype=float32)
time = 23075	action = 0	current_phase = 0	next_phase = 1	reward = 0.723263	array([[ 3.5502577, -9.448065 ]], dtype=float32)
time = 23080	action = 0	current_phase = 0	next_phase = 1	reward = 0.434846	array([[ 3.5273151, -9.411047 ]], dtype=float32)
time = 23085	action = 0	current_phase = 0	next_phase = 1	reward = 1.001238	array([[ 3.5240068, -9.496056 ]], dtype=float32)
time = 23090	action = 0	current_phase = 0	next_phase = 1	reward = 0.712031	array([[ 3.4977894, -9.458193 ]], dtype=float32)
time = 23095	action = 0	current_phase = 0	next_phase = 1	reward = 0.442017	array([[ 3.4764023, -9.471825 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.6169 - val_loss: 2.3004
Epoch 2/50
 - 4s - loss: 3.6809 - val_loss: 1.5792
Epoch 3/50
 - 4s - loss: 4.1502 - val_loss: 1.6707
Epoch 4/50
 - 4s - loss: 4.4088 - val_loss: 1.7662
Epoch 5/50
 - 4s - loss: 3.2181 - val_loss: 1.4486
Epoch 6/50
 - 4s - loss: 3.6413 - val_loss: 1.6040
Epoch 7/50
 - 4s - loss: 3.0816 - val_loss: 2.1374
Epoch 8/50
 - 4s - loss: 5.1744 - val_loss: 1.7070
Epoch 9/50
 - 4s - loss: 3.7480 - val_loss: 1.6211
Epoch 10/50
 - 4s - loss: 3.2176 - val_loss: 2.3490
Epoch 11/50
 - 4s - loss: 5.0105 - val_loss: 1.8853
Epoch 12/50
 - 4s - loss: 4.6090 - val_loss: 2.6624
Epoch 13/50
 - 4s - loss: 3.2968 - val_loss: 2.1302
Epoch 14/50
 - 4s - loss: 4.8736 - val_loss: 2.2103
Epoch 15/50
 - 4s - loss: 4.6243 - val_loss: 2.2482
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 23100	action = 0	current_phase = 0	next_phase = 1	reward = 0.736116	array([[ 3.3700848, -9.5686245]], dtype=float32)
time = 23105	action = 0	current_phase = 0	next_phase = 1	reward = 1.007551	array([[ 3.5192175, -9.39521  ]], dtype=float32)
time = 23110	action = 0	current_phase = 0	next_phase = 1	reward = 0.724731	array([[ 3.4601097, -9.458351 ]], dtype=float32)
time = 23115	action = 0	current_phase = 0	next_phase = 1	reward = 0.722181	array([[ 3.421567, -9.492088]], dtype=float32)
time = 23120	action = 0	current_phase = 0	next_phase = 1	reward = 0.162606	array([[ 3.419776, -9.490264]], dtype=float32)
time = 23125	action = 0	current_phase = 0	next_phase = 1	reward = 1.295189	array([[ 3.3119898, -9.688398 ]], dtype=float32)
time = 23130	action = 0	current_phase = 0	next_phase = 1	reward = 0.724769	array([[ 3.4349957, -9.525917 ]], dtype=float32)
time = 23135	action = 0	current_phase = 0	next_phase = 1	reward = 0.721969	array([[ 3.455081, -9.429247]], dtype=float32)
time = 23140	action = 0	current_phase = 0	next_phase = 1	reward = 0.720391	array([[ 3.3863707, -9.537727 ]], dtype=float32)
time = 23145	action = 0	current_phase = 0	next_phase = 1	reward = 0.716913	array([[ 3.470213 , -9.4222145]], dtype=float32)
time = 23150	action = 0	current_phase = 0	next_phase = 1	reward = 0.442821	array([[ 3.470415, -9.433994]], dtype=float32)
time = 23155	action = 0	current_phase = 0	next_phase = 1	reward = 0.998302	array([[ 3.45267 , -9.455939]], dtype=float32)
time = 23160	action = 0	current_phase = 0	next_phase = 1	reward = 0.170618	array([[ 3.4815836, -9.427254 ]], dtype=float32)
time = 23165	action = 0	current_phase = 0	next_phase = 1	reward = 1.287537	array([[ 3.3574343, -9.6001005]], dtype=float32)
time = 23170	action = 0	current_phase = 0	next_phase = 1	reward = 0.436853	array([[ 3.4445505, -9.48938  ]], dtype=float32)
time = 23175	action = 0	current_phase = 0	next_phase = 1	reward = 0.722975	array([[ 3.4149294, -9.519489 ]], dtype=float32)
time = 23180	action = 0	current_phase = 0	next_phase = 1	reward = 0.725723	array([[ 3.3877068, -9.580665 ]], dtype=float32)
time = 23185	action = 0	current_phase = 0	next_phase = 1	reward = 0.726374	array([[ 3.43859 , -9.470169]], dtype=float32)
time = 23190	action = 0	current_phase = 0	next_phase = 1	reward = 1.001373	array([[ 3.4534483, -9.451326 ]], dtype=float32)
time = 23195	action = 0	current_phase = 0	next_phase = 1	reward = 0.715552	array([[ 3.381589, -9.550074]], dtype=float32)
time = 23200	action = 0	current_phase = 0	next_phase = 1	reward = 0.438237	array([[ 3.468358, -9.404562]], dtype=float32)
time = 23205	action = 0	current_phase = 0	next_phase = 1	reward = 0.722202	array([[ 3.4148293, -9.503555 ]], dtype=float32)
time = 23210	action = 0	current_phase = 0	next_phase = 1	reward = 0.999062	array([[ 3.4509506, -9.472458 ]], dtype=float32)
time = 23215	action = 0	current_phase = 0	next_phase = 1	reward = 0.438839	array([[ 3.4548483, -9.435581 ]], dtype=float32)
time = 23220	action = 0	current_phase = 0	next_phase = 1	reward = 0.730975	array([[ 3.4919806, -9.446799 ]], dtype=float32)
time = 23225	action = 0	current_phase = 0	next_phase = 1	reward = 0.727404	array([[ 3.394683, -9.529212]], dtype=float32)
time = 23230	action = 0	current_phase = 0	next_phase = 1	reward = 0.724572	array([[ 3.4403486, -9.453287 ]], dtype=float32)
time = 23235	action = 0	current_phase = 0	next_phase = 1	reward = 0.719025	array([[ 3.4252186, -9.518772 ]], dtype=float32)
time = 23240	action = 0	current_phase = 0	next_phase = 1	reward = 0.996772	array([[ 3.4258757, -9.490438 ]], dtype=float32)
time = 23245	action = 0	current_phase = 0	next_phase = 1	reward = 0.162994	array([[ 3.4392967, -9.4363   ]], dtype=float32)
time = 23250	action = 0	current_phase = 0	next_phase = 1	reward = 1.006801	array([[ 3.1466827, -9.874136 ]], dtype=float32)
time = 23255	action = 0	current_phase = 0	next_phase = 1	reward = 1.002810	array([[ 3.4365692, -9.548168 ]], dtype=float32)
time = 23260	action = 0	current_phase = 0	next_phase = 1	reward = 0.727060	array([[ 3.5073252, -9.420023 ]], dtype=float32)
time = 23265	action = 0	current_phase = 0	next_phase = 1	reward = 0.718443	array([[ 3.4511347, -9.447517 ]], dtype=float32)
time = 23270	action = 0	current_phase = 0	next_phase = 1	reward = 0.716380	array([[ 3.453331, -9.486813]], dtype=float32)
time = 23275	action = 0	current_phase = 0	next_phase = 1	reward = 0.723808	array([[ 3.5077238, -9.404741 ]], dtype=float32)
time = 23280	action = 0	current_phase = 0	next_phase = 1	reward = 0.717905	array([[ 3.4306345, -9.477678 ]], dtype=float32)
time = 23285	action = 0	current_phase = 0	next_phase = 1	reward = 0.444112	array([[ 3.403161, -9.508902]], dtype=float32)
time = 23290	action = 0	current_phase = 0	next_phase = 1	reward = 1.007994	array([[ 3.4074965, -9.50528  ]], dtype=float32)
time = 23295	action = 0	current_phase = 0	next_phase = 1	reward = 0.725735	array([[ 3.4748077, -9.437343 ]], dtype=float32)
time = 23300	action = 0	current_phase = 0	next_phase = 1	reward = 0.449232	array([[ 3.4565554, -9.421273 ]], dtype=float32)
time = 23305	action = 0	current_phase = 0	next_phase = 1	reward = 1.005778	array([[ 3.479579, -9.470252]], dtype=float32)
time = 23310	action = 0	current_phase = 0	next_phase = 1	reward = 0.720194	array([[ 3.4284372, -9.474705 ]], dtype=float32)
time = 23315	action = 0	current_phase = 0	next_phase = 1	reward = 0.722169	array([[ 3.4704885, -9.41537  ]], dtype=float32)
time = 23320	action = 0	current_phase = 0	next_phase = 1	reward = 0.722294	array([[ 3.4984007, -9.440271 ]], dtype=float32)
time = 23325	action = 0	current_phase = 0	next_phase = 1	reward = 0.728038	array([[ 3.4706755, -9.439783 ]], dtype=float32)
time = 23330	action = 0	current_phase = 0	next_phase = 1	reward = 0.719961	array([[ 3.4286766, -9.472466 ]], dtype=float32)
time = 23335	action = 0	current_phase = 0	next_phase = 1	reward = 0.718463	array([[ 3.4451313, -9.448219 ]], dtype=float32)
time = 23340	action = 0	current_phase = 0	next_phase = 1	reward = 0.723241	array([[ 3.4216127, -9.462149 ]], dtype=float32)
time = 23345	action = 0	current_phase = 0	next_phase = 1	reward = 0.726224	array([[ 3.4725819, -9.41806  ]], dtype=float32)
time = 23350	action = 0	current_phase = 0	next_phase = 1	reward = 0.732080	array([[ 3.4813719, -9.423076 ]], dtype=float32)
time = 23355	action = 0	current_phase = 0	next_phase = 1	reward = 0.723498	array([[ 3.4631271, -9.484789 ]], dtype=float32)
time = 23360	action = 0	current_phase = 0	next_phase = 1	reward = 0.708762	array([[ 3.4320316, -9.455301 ]], dtype=float32)
time = 23365	action = 0	current_phase = 0	next_phase = 1	reward = 0.162698	array([[ 3.510397 , -9.3966465]], dtype=float32)
time = 23370	action = 0	current_phase = 0	next_phase = 1	reward = 1.009027	array([[ 3.4257526, -9.47822  ]], dtype=float32)
time = 23375	action = 0	current_phase = 0	next_phase = 1	reward = 0.724320	array([[ 3.4441843, -9.503301 ]], dtype=float32)
time = 23380	action = 0	current_phase = 0	next_phase = 1	reward = 1.000257	array([[ 3.3927412, -9.598772 ]], dtype=float32)
time = 23385	action = 0	current_phase = 0	next_phase = 1	reward = 0.717898	array([[ 3.5009155, -9.3891325]], dtype=float32)
time = 23390	action = 0	current_phase = 0	next_phase = 1	reward = 0.165352	array([[ 3.4828272, -9.404561 ]], dtype=float32)
time = 23395	action = 0	current_phase = 0	next_phase = 1	reward = 1.289487	array([[ 3.4147806, -9.587578 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.1085 - val_loss: 2.0182
Epoch 2/50
 - 4s - loss: 6.3061 - val_loss: 2.4880
Epoch 3/50
 - 4s - loss: 4.0564 - val_loss: 1.6425
Epoch 4/50
 - 4s - loss: 6.0158 - val_loss: 1.9518
Epoch 5/50
 - 4s - loss: 4.5820 - val_loss: 1.9153
Epoch 6/50
 - 4s - loss: 3.5835 - val_loss: 1.7474
Epoch 7/50
 - 4s - loss: 3.6997 - val_loss: 1.6652
Epoch 8/50
 - 4s - loss: 3.6987 - val_loss: 1.6629
Epoch 9/50
 - 4s - loss: 4.2479 - val_loss: 1.3109
Epoch 10/50
 - 4s - loss: 3.7109 - val_loss: 3.0087
Epoch 11/50
 - 4s - loss: 6.3347 - val_loss: 2.2936
Epoch 12/50
 - 5s - loss: 3.8630 - val_loss: 2.0122
Epoch 13/50
 - 5s - loss: 3.9006 - val_loss: 2.0570
Epoch 14/50
 - 4s - loss: 3.8459 - val_loss: 2.3622
Epoch 15/50
 - 4s - loss: 3.7437 - val_loss: 2.9120
Epoch 16/50
 - 4s - loss: 3.7094 - val_loss: 2.5099
Epoch 17/50
 - 4s - loss: 3.3944 - val_loss: 2.0252
Epoch 18/50
 - 4s - loss: 3.6791 - val_loss: 2.0634
Epoch 19/50
 - 4s - loss: 5.1933 - val_loss: 1.7884
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 23400	action = 0	current_phase = 0	next_phase = 1	reward = 0.722438	array([[ 3.4721718, -9.4640875]], dtype=float32)
time = 23405	action = 0	current_phase = 0	next_phase = 1	reward = 0.723640	array([[ 3.471177, -9.441963]], dtype=float32)
time = 23410	action = 0	current_phase = 0	next_phase = 1	reward = 0.724028	array([[ 3.4378595, -9.503799 ]], dtype=float32)
time = 23415	action = 0	current_phase = 0	next_phase = 1	reward = 0.725586	array([[ 3.445403, -9.488066]], dtype=float32)
time = 23420	action = 0	current_phase = 0	next_phase = 1	reward = 0.724164	array([[ 3.4541378, -9.46315  ]], dtype=float32)
time = 23425	action = 0	current_phase = 0	next_phase = 1	reward = 0.721728	array([[ 3.4764519, -9.47281  ]], dtype=float32)
time = 23430	action = 0	current_phase = 0	next_phase = 1	reward = 0.721023	array([[ 3.4777412, -9.450063 ]], dtype=float32)
time = 23435	action = 0	current_phase = 0	next_phase = 1	reward = 0.729170	array([[ 3.530285, -9.432287]], dtype=float32)
time = 23440	action = 0	current_phase = 0	next_phase = 1	reward = 0.728256	array([[ 3.455101, -9.498631]], dtype=float32)
time = 23445	action = 0	current_phase = 0	next_phase = 1	reward = 0.722445	array([[ 3.5158453, -9.445559 ]], dtype=float32)
time = 23450	action = 0	current_phase = 0	next_phase = 1	reward = 0.718915	array([[ 3.4703636, -9.443106 ]], dtype=float32)
time = 23455	action = 0	current_phase = 0	next_phase = 1	reward = 0.720990	array([[ 3.447918, -9.451805]], dtype=float32)
time = 23460	action = 0	current_phase = 0	next_phase = 1	reward = 0.721118	array([[ 3.4192839, -9.490446 ]], dtype=float32)
time = 23465	action = 0	current_phase = 0	next_phase = 1	reward = 0.445170	array([[ 3.3845434, -9.572887 ]], dtype=float32)
time = 23470	action = 0	current_phase = 0	next_phase = 1	reward = 0.448175	array([[ 3.4075518, -9.618647 ]], dtype=float32)
time = 23475	action = 0	current_phase = 0	next_phase = 1	reward = 1.284777	array([[ 3.4265366, -9.603544 ]], dtype=float32)
time = 23480	action = 0	current_phase = 0	next_phase = 1	reward = 0.727187	array([[ 3.494174, -9.401486]], dtype=float32)
time = 23485	action = 0	current_phase = 0	next_phase = 1	reward = 0.169481	array([[ 3.4615917, -9.438623 ]], dtype=float32)
time = 23490	action = 0	current_phase = 0	next_phase = 1	reward = 1.291490	array([[ 3.3621387, -9.596016 ]], dtype=float32)
time = 23495	action = 0	current_phase = 0	next_phase = 1	reward = 0.722844	array([[ 3.4731178, -9.441947 ]], dtype=float32)
time = 23500	action = 0	current_phase = 0	next_phase = 1	reward = 0.720454	array([[ 3.4867973, -9.433189 ]], dtype=float32)
time = 23505	action = 0	current_phase = 0	next_phase = 1	reward = 0.716363	array([[ 3.4417381, -9.524986 ]], dtype=float32)
time = 23510	action = 0	current_phase = 0	next_phase = 1	reward = 0.716910	array([[ 3.489335, -9.425793]], dtype=float32)
time = 23515	action = 0	current_phase = 0	next_phase = 1	reward = 0.453877	array([[ 3.4987726, -9.44012  ]], dtype=float32)
time = 23520	action = 0	current_phase = 0	next_phase = 1	reward = 1.004845	array([[ 3.4961863, -9.434755 ]], dtype=float32)
time = 23525	action = 0	current_phase = 0	next_phase = 1	reward = 0.730780	array([[ 3.4801702, -9.439316 ]], dtype=float32)
time = 23530	action = 0	current_phase = 0	next_phase = 1	reward = 0.456551	array([[ 3.48808 , -9.461046]], dtype=float32)
time = 23535	action = 0	current_phase = 0	next_phase = 1	reward = 1.004619	array([[ 3.4452276, -9.498095 ]], dtype=float32)
time = 23540	action = 0	current_phase = 0	next_phase = 1	reward = 0.701996	array([[ 3.4708405, -9.447039 ]], dtype=float32)
time = 23545	action = 0	current_phase = 0	next_phase = 1	reward = 0.715430	array([[ 3.4700146, -9.430571 ]], dtype=float32)
time = 23550	action = 0	current_phase = 0	next_phase = 1	reward = 0.723987	array([[ 3.4427614, -9.469666 ]], dtype=float32)
time = 23555	action = 0	current_phase = 0	next_phase = 1	reward = 0.448942	array([[ 3.4417372, -9.470465 ]], dtype=float32)
time = 23560	action = 0	current_phase = 0	next_phase = 1	reward = 0.731952	array([[ 3.5127544, -9.418555 ]], dtype=float32)
time = 23565	action = 0	current_phase = 0	next_phase = 1	reward = 1.013220	array([[ 3.5220366, -9.409672 ]], dtype=float32)
time = 23570	action = 0	current_phase = 0	next_phase = 1	reward = 0.718645	array([[ 3.478466, -9.450921]], dtype=float32)
time = 23575	action = 0	current_phase = 0	next_phase = 1	reward = 0.718519	array([[ 3.4611864, -9.443721 ]], dtype=float32)
time = 23580	action = 0	current_phase = 0	next_phase = 1	reward = 0.725615	array([[ 3.472971, -9.447526]], dtype=float32)
time = 23585	action = 0	current_phase = 0	next_phase = 1	reward = 0.439475	array([[ 3.4606457, -9.566166 ]], dtype=float32)
time = 23590	action = 0	current_phase = 0	next_phase = 1	reward = 1.004017	array([[ 3.3432512, -9.638591 ]], dtype=float32)
time = 23595	action = 0	current_phase = 0	next_phase = 1	reward = 0.443997	array([[ 3.4755592, -9.439865 ]], dtype=float32)
time = 23600	action = 0	current_phase = 0	next_phase = 1	reward = 0.457663	array([[ 3.3111544, -9.651946 ]], dtype=float32)
time = 23605	action = 0	current_phase = 0	next_phase = 1	reward = 1.292616	array([[ 3.366212, -9.599522]], dtype=float32)
time = 23610	action = 0	current_phase = 0	next_phase = 1	reward = 0.724942	array([[ 3.4458008, -9.480543 ]], dtype=float32)
time = 23615	action = 0	current_phase = 0	next_phase = 1	reward = 0.724445	array([[ 3.4659634, -9.449571 ]], dtype=float32)
time = 23620	action = 0	current_phase = 0	next_phase = 1	reward = 0.717011	array([[ 3.4214783, -9.507422 ]], dtype=float32)
time = 23625	action = 0	current_phase = 0	next_phase = 1	reward = 0.443428	array([[ 3.5169086, -9.416252 ]], dtype=float32)
time = 23630	action = 0	current_phase = 0	next_phase = 1	reward = 1.006811	array([[ 3.386098 , -9.5723505]], dtype=float32)
time = 23635	action = 0	current_phase = 0	next_phase = 1	reward = 0.716172	array([[ 3.4660835, -9.453396 ]], dtype=float32)
time = 23640	action = 0	current_phase = 0	next_phase = 1	reward = 0.446013	array([[ 3.4991035, -9.438585 ]], dtype=float32)
time = 23645	action = 0	current_phase = 0	next_phase = 1	reward = 0.726490	array([[ 3.422452, -9.501173]], dtype=float32)
time = 23650	action = 0	current_phase = 0	next_phase = 1	reward = 0.999814	array([[ 3.4576511, -9.441391 ]], dtype=float32)
time = 23655	action = 0	current_phase = 0	next_phase = 1	reward = 0.440294	array([[ 3.4648829, -9.438286 ]], dtype=float32)
time = 23660	action = 0	current_phase = 0	next_phase = 1	reward = 1.007199	array([[ 3.4060726, -9.647438 ]], dtype=float32)
time = 23665	action = 0	current_phase = 0	next_phase = 1	reward = 0.715513	array([[ 3.5051384, -9.4486885]], dtype=float32)
time = 23670	action = 0	current_phase = 0	next_phase = 1	reward = 0.716061	array([[ 3.5125923, -9.43394  ]], dtype=float32)
time = 23675	action = 0	current_phase = 0	next_phase = 1	reward = 0.716408	array([[ 3.467267, -9.42942 ]], dtype=float32)
time = 23680	action = 0	current_phase = 0	next_phase = 1	reward = 0.723291	array([[ 3.466794, -9.461039]], dtype=float32)
time = 23685	action = 0	current_phase = 0	next_phase = 1	reward = 0.725070	array([[ 3.4340801, -9.51651  ]], dtype=float32)
time = 23690	action = 0	current_phase = 0	next_phase = 1	reward = 0.716728	array([[ 3.403615, -9.522409]], dtype=float32)
time = 23695	action = 0	current_phase = 0	next_phase = 1	reward = 0.447859	array([[ 3.4367666, -9.485087 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.5849 - val_loss: 1.5380
Epoch 2/50
 - 4s - loss: 4.5416 - val_loss: 1.3908
Epoch 3/50
 - 4s - loss: 3.2560 - val_loss: 1.3051
Epoch 4/50
 - 4s - loss: 3.4779 - val_loss: 1.1779
Epoch 5/50
 - 4s - loss: 4.8772 - val_loss: 1.5832
Epoch 6/50
 - 4s - loss: 3.2714 - val_loss: 2.9556
Epoch 7/50
 - 4s - loss: 3.8228 - val_loss: 1.6675
Epoch 8/50
 - 4s - loss: 3.8664 - val_loss: 1.7783
Epoch 9/50
 - 4s - loss: 3.7423 - val_loss: 1.6122
Epoch 10/50
 - 4s - loss: 3.2852 - val_loss: 1.7200
Epoch 11/50
 - 4s - loss: 3.5547 - val_loss: 1.4333
Epoch 12/50
 - 4s - loss: 3.8864 - val_loss: 1.5597
Epoch 13/50
 - 4s - loss: 3.0019 - val_loss: 1.5180
Epoch 14/50
 - 4s - loss: 3.7263 - val_loss: 1.4400
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 23700	action = 0	current_phase = 0	next_phase = 1	reward = 0.723157	array([[ 3.5313497, -9.380507 ]], dtype=float32)
time = 23705	action = 0	current_phase = 0	next_phase = 1	reward = 0.723035	array([[ 3.488832, -9.410772]], dtype=float32)
time = 23710	action = 0	current_phase = 0	next_phase = 1	reward = 1.002246	array([[ 3.47298 , -9.435749]], dtype=float32)
time = 23715	action = 0	current_phase = 0	next_phase = 1	reward = 0.721750	array([[ 3.4519334, -9.468908 ]], dtype=float32)
time = 23720	action = 0	current_phase = 0	next_phase = 1	reward = 0.444930	array([[ 3.4848418, -9.423414 ]], dtype=float32)
time = 23725	action = 0	current_phase = 0	next_phase = 1	reward = 1.009752	array([[ 3.0644555, -9.6184845]], dtype=float32)
time = 23730	action = 0	current_phase = 0	next_phase = 1	reward = 0.447282	array([[ 3.5130439, -9.378838 ]], dtype=float32)
time = 23735	action = 0	current_phase = 0	next_phase = 1	reward = 1.010373	array([[ 3.4654412, -9.452799 ]], dtype=float32)
time = 23740	action = 0	current_phase = 0	next_phase = 1	reward = 0.720098	array([[ 3.4712758, -9.435886 ]], dtype=float32)
time = 23745	action = 0	current_phase = 0	next_phase = 1	reward = 0.726612	array([[ 3.494411, -9.457428]], dtype=float32)
time = 23750	action = 0	current_phase = 0	next_phase = 1	reward = 0.720146	array([[ 3.497148, -9.386723]], dtype=float32)
time = 23755	action = 0	current_phase = 0	next_phase = 1	reward = 0.441841	array([[ 3.457971, -9.463341]], dtype=float32)
time = 23760	action = 0	current_phase = 0	next_phase = 1	reward = 0.731284	array([[ 3.462297, -9.443072]], dtype=float32)
time = 23765	action = 0	current_phase = 0	next_phase = 1	reward = 1.001673	array([[ 3.5274596, -9.4217205]], dtype=float32)
time = 23770	action = 0	current_phase = 0	next_phase = 1	reward = 0.439404	array([[ 3.544334, -9.404018]], dtype=float32)
time = 23775	action = 0	current_phase = 0	next_phase = 1	reward = 1.004348	array([[ 3.5019622, -9.434149 ]], dtype=float32)
time = 23780	action = 0	current_phase = 0	next_phase = 1	reward = 0.727497	array([[ 3.562984, -9.371026]], dtype=float32)
time = 23785	action = 0	current_phase = 0	next_phase = 1	reward = 0.446301	array([[ 3.4975266, -9.427307 ]], dtype=float32)
time = 23790	action = 0	current_phase = 0	next_phase = 1	reward = 0.445173	array([[ 3.5040488, -9.404745 ]], dtype=float32)
time = 23795	action = 0	current_phase = 0	next_phase = 1	reward = 1.286257	array([[ 3.4720035, -9.479052 ]], dtype=float32)
time = 23800	action = 0	current_phase = 0	next_phase = 1	reward = 0.721207	array([[ 3.469129, -9.457243]], dtype=float32)
time = 23805	action = 0	current_phase = 0	next_phase = 1	reward = 0.717524	array([[ 3.462831, -9.435819]], dtype=float32)
time = 23810	action = 0	current_phase = 0	next_phase = 1	reward = 0.720561	array([[ 3.4670053, -9.432243 ]], dtype=float32)
time = 23815	action = 0	current_phase = 0	next_phase = 1	reward = 0.727433	array([[ 3.4515157, -9.456451 ]], dtype=float32)
time = 23820	action = 0	current_phase = 0	next_phase = 1	reward = 0.726242	array([[ 3.4469771, -9.443775 ]], dtype=float32)
time = 23825	action = 0	current_phase = 0	next_phase = 1	reward = 0.722562	array([[ 3.4898047, -9.404751 ]], dtype=float32)
time = 23830	action = 0	current_phase = 0	next_phase = 1	reward = 0.726434	array([[ 3.5089755, -9.402626 ]], dtype=float32)
time = 23835	action = 0	current_phase = 0	next_phase = 1	reward = 0.718112	array([[ 3.5173411, -9.368101 ]], dtype=float32)
time = 23840	action = 0	current_phase = 0	next_phase = 1	reward = 0.718471	array([[ 3.5032334, -9.392253 ]], dtype=float32)
time = 23845	action = 0	current_phase = 0	next_phase = 1	reward = 0.727937	array([[ 3.5102124, -9.412407 ]], dtype=float32)
time = 23850	action = 0	current_phase = 0	next_phase = 1	reward = 0.719786	array([[ 3.507112, -9.430826]], dtype=float32)
time = 23855	action = 0	current_phase = 0	next_phase = 1	reward = 0.444333	array([[ 3.5063138, -9.407531 ]], dtype=float32)
time = 23860	action = 0	current_phase = 0	next_phase = 1	reward = 1.008598	array([[ 3.4932761, -9.409605 ]], dtype=float32)
time = 23865	action = 0	current_phase = 0	next_phase = 1	reward = 0.728302	array([[ 3.4595456, -9.426853 ]], dtype=float32)
time = 23870	action = 0	current_phase = 0	next_phase = 1	reward = 0.730791	array([[ 3.4717288, -9.479136 ]], dtype=float32)
time = 23875	action = 0	current_phase = 0	next_phase = 1	reward = 0.728454	array([[ 3.4547544, -9.457127 ]], dtype=float32)
time = 23880	action = 0	current_phase = 0	next_phase = 1	reward = 0.717450	array([[ 3.488648, -9.397197]], dtype=float32)
time = 23885	action = 0	current_phase = 0	next_phase = 1	reward = 0.719079	array([[ 3.49375 , -9.410493]], dtype=float32)
time = 23890	action = 0	current_phase = 0	next_phase = 1	reward = 0.432545	array([[ 3.475182 , -9.4237175]], dtype=float32)
time = 23895	action = 0	current_phase = 0	next_phase = 1	reward = 0.725712	array([[ 3.4508586, -9.453114 ]], dtype=float32)
time = 23900	action = 0	current_phase = 0	next_phase = 1	reward = 0.730346	array([[ 3.403172, -9.534971]], dtype=float32)
time = 23905	action = 0	current_phase = 0	next_phase = 1	reward = 1.002910	array([[ 3.4621482, -9.4283085]], dtype=float32)
time = 23910	action = 0	current_phase = 0	next_phase = 1	reward = 0.729919	array([[ 3.501924, -9.422556]], dtype=float32)
time = 23915	action = 0	current_phase = 0	next_phase = 1	reward = 0.447833	array([[ 3.513022, -9.392311]], dtype=float32)
time = 23920	action = 0	current_phase = 0	next_phase = 1	reward = 1.011890	array([[ 3.4549298, -9.46356  ]], dtype=float32)
time = 23925	action = 0	current_phase = 0	next_phase = 1	reward = 0.721033	array([[ 3.5117154, -9.391336 ]], dtype=float32)
time = 23930	action = 0	current_phase = 0	next_phase = 1	reward = 0.719577	array([[ 3.5098338, -9.415672 ]], dtype=float32)
time = 23935	action = 0	current_phase = 0	next_phase = 1	reward = 0.722645	array([[ 3.4903312, -9.439676 ]], dtype=float32)
time = 23940	action = 0	current_phase = 0	next_phase = 1	reward = 0.728721	array([[ 3.5269818, -9.391708 ]], dtype=float32)
time = 23945	action = 0	current_phase = 0	next_phase = 1	reward = 0.721127	array([[ 3.4467072, -9.443928 ]], dtype=float32)
time = 23950	action = 0	current_phase = 0	next_phase = 1	reward = 0.443448	array([[ 3.4536548, -9.432886 ]], dtype=float32)
time = 23955	action = 0	current_phase = 0	next_phase = 1	reward = 1.007662	array([[ 3.4885097, -9.429255 ]], dtype=float32)
time = 23960	action = 0	current_phase = 0	next_phase = 1	reward = 0.715715	array([[ 3.5326352, -9.400654 ]], dtype=float32)
time = 23965	action = 0	current_phase = 0	next_phase = 1	reward = 0.445318	array([[ 3.4773898, -9.427058 ]], dtype=float32)
time = 23970	action = 0	current_phase = 0	next_phase = 1	reward = 1.009053	array([[ 3.4278998, -9.518394 ]], dtype=float32)
time = 23975	action = 0	current_phase = 0	next_phase = 1	reward = 0.715513	array([[ 3.3959184, -9.512482 ]], dtype=float32)
time = 23980	action = 0	current_phase = 0	next_phase = 1	reward = 0.444860	array([[ 3.4908032, -9.410778 ]], dtype=float32)
time = 23985	action = 0	current_phase = 0	next_phase = 1	reward = 0.724771	array([[ 3.472134, -9.483702]], dtype=float32)
time = 23990	action = 0	current_phase = 0	next_phase = 1	reward = 1.001164	array([[ 3.4654737, -9.4485035]], dtype=float32)
time = 23995	action = 0	current_phase = 0	next_phase = 1	reward = 0.723665	array([[ 3.5141282, -9.396079 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 6.1412 - val_loss: 2.4667
Epoch 2/50
 - 4s - loss: 4.9187 - val_loss: 2.2505
Epoch 3/50
 - 4s - loss: 3.2620 - val_loss: 2.0362
Epoch 4/50
 - 4s - loss: 3.7801 - val_loss: 2.5378
Epoch 5/50
 - 4s - loss: 3.2285 - val_loss: 2.2001
Epoch 6/50
 - 4s - loss: 3.3131 - val_loss: 1.9884
Epoch 7/50
 - 4s - loss: 4.4256 - val_loss: 2.2296
Epoch 8/50
 - 4s - loss: 3.5765 - val_loss: 2.3014
Epoch 9/50
 - 4s - loss: 3.1765 - val_loss: 2.4095
Epoch 10/50
 - 4s - loss: 4.5233 - val_loss: 2.1180
Epoch 11/50
 - 4s - loss: 2.8091 - val_loss: 2.2858
Epoch 12/50
 - 4s - loss: 4.4448 - val_loss: 2.0397
Epoch 13/50
 - 4s - loss: 3.5198 - val_loss: 1.9426
Epoch 14/50
 - 4s - loss: 4.0082 - val_loss: 2.2125
Epoch 15/50
 - 4s - loss: 3.4444 - val_loss: 2.0804
Epoch 16/50
 - 4s - loss: 2.9981 - val_loss: 2.1444
Epoch 17/50
 - 4s - loss: 3.9353 - val_loss: 2.4684
Epoch 18/50
 - 4s - loss: 2.6718 - val_loss: 2.3171
Epoch 19/50
 - 4s - loss: 3.1717 - val_loss: 2.5250
Epoch 20/50
 - 4s - loss: 3.7457 - val_loss: 2.0934
Epoch 21/50
 - 4s - loss: 3.9220 - val_loss: 2.4021
Epoch 22/50
 - 5s - loss: 2.6225 - val_loss: 2.2991
Epoch 23/50
 - 4s - loss: 3.1780 - val_loss: 2.1925
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 24000	action = 0	current_phase = 0	next_phase = 1	reward = 0.713463	array([[ 3.429904, -9.487968]], dtype=float32)
time = 24005	action = 0	current_phase = 0	next_phase = 1	reward = 0.438095	array([[ 3.4567528, -9.480009 ]], dtype=float32)
time = 24010	action = 0	current_phase = 0	next_phase = 1	reward = 1.007857	array([[ 3.4411907, -9.506819 ]], dtype=float32)
time = 24015	action = 0	current_phase = 0	next_phase = 1	reward = 0.159747	array([[ 3.4448805, -9.508791 ]], dtype=float32)
time = 24020	action = 0	current_phase = 0	next_phase = 1	reward = 1.284257	array([[ 3.408413, -9.591769]], dtype=float32)
time = 24025	action = 0	current_phase = 0	next_phase = 1	reward = 0.163283	array([[ 3.4435654, -9.511824 ]], dtype=float32)
time = 24030	action = 0	current_phase = 0	next_phase = 1	reward = 0.720069	array([[ 3.3656635, -9.588063 ]], dtype=float32)
time = 24035	action = 0	current_phase = 0	next_phase = 1	reward = 1.284447	array([[ 3.4985056, -9.447449 ]], dtype=float32)
time = 24040	action = 0	current_phase = 0	next_phase = 1	reward = 0.435250	array([[ 3.43223  , -9.5131855]], dtype=float32)
time = 24045	action = 0	current_phase = 0	next_phase = 1	reward = 0.722805	array([[ 3.4824524, -9.449907 ]], dtype=float32)
time = 24050	action = 0	current_phase = 0	next_phase = 1	reward = 1.001826	array([[ 3.4643354, -9.570469 ]], dtype=float32)
time = 24055	action = 0	current_phase = 0	next_phase = 1	reward = 0.726632	array([[ 3.473775, -9.45623 ]], dtype=float32)
time = 24060	action = 0	current_phase = 0	next_phase = 1	reward = 0.454324	array([[ 3.4755611, -9.471771 ]], dtype=float32)
time = 24065	action = 0	current_phase = 0	next_phase = 1	reward = 0.998953	array([[ 3.4878664, -9.453993 ]], dtype=float32)
time = 24070	action = 0	current_phase = 0	next_phase = 1	reward = 0.435120	array([[ 3.535287, -9.42893 ]], dtype=float32)
time = 24075	action = 0	current_phase = 0	next_phase = 1	reward = 0.440386	array([[ 3.5911913, -9.408002 ]], dtype=float32)
time = 24080	action = 0	current_phase = 0	next_phase = 1	reward = 1.013508	array([[ 3.4653578, -9.481995 ]], dtype=float32)
time = 24085	action = 0	current_phase = 0	next_phase = 1	reward = 1.007303	array([[ 3.5014381, -9.419186 ]], dtype=float32)
time = 24090	action = 0	current_phase = 0	next_phase = 1	reward = 0.166695	array([[ 3.4857388, -9.447156 ]], dtype=float32)
time = 24095	action = 0	current_phase = 0	next_phase = 1	reward = 1.012753	array([[ 3.473487, -9.478328]], dtype=float32)
time = 24100	action = 0	current_phase = 0	next_phase = 1	reward = 1.004146	array([[ 3.4546442, -9.49645  ]], dtype=float32)
time = 24105	action = 0	current_phase = 0	next_phase = 1	reward = 0.722508	array([[ 3.4650135, -9.467543 ]], dtype=float32)
time = 24110	action = 0	current_phase = 0	next_phase = 1	reward = 0.717128	array([[ 3.4959354, -9.428625 ]], dtype=float32)
time = 24115	action = 0	current_phase = 0	next_phase = 1	reward = 0.719464	array([[ 3.4718313, -9.45537  ]], dtype=float32)
time = 24120	action = 0	current_phase = 0	next_phase = 1	reward = 0.437246	array([[ 3.5010033, -9.44307  ]], dtype=float32)
time = 24125	action = 0	current_phase = 0	next_phase = 1	reward = 0.452415	array([[ 3.5078268, -9.425425 ]], dtype=float32)
time = 24130	action = 0	current_phase = 0	next_phase = 1	reward = 1.285213	array([[ 3.438899, -9.499337]], dtype=float32)
time = 24135	action = 0	current_phase = 0	next_phase = 1	reward = 0.438813	array([[ 3.4996328, -9.447904 ]], dtype=float32)
time = 24140	action = 0	current_phase = 0	next_phase = 1	reward = 0.999207	array([[ 3.4569712, -9.483709 ]], dtype=float32)
time = 24145	action = 0	current_phase = 0	next_phase = 1	reward = 0.443802	array([[ 3.479474, -9.487181]], dtype=float32)
time = 24150	action = 0	current_phase = 0	next_phase = 1	reward = 1.006748	array([[ 3.4712038, -9.504307 ]], dtype=float32)
time = 24155	action = 0	current_phase = 0	next_phase = 1	reward = 0.714194	array([[ 3.471321, -9.432623]], dtype=float32)
time = 24160	action = 0	current_phase = 0	next_phase = 1	reward = 0.438730	array([[ 3.494915, -9.439304]], dtype=float32)
time = 24165	action = 0	current_phase = 0	next_phase = 1	reward = 0.732428	array([[ 3.486662, -9.448769]], dtype=float32)
time = 24170	action = 0	current_phase = 0	next_phase = 1	reward = 1.003806	array([[ 3.4441624, -9.501734 ]], dtype=float32)
time = 24175	action = 0	current_phase = 0	next_phase = 1	reward = 0.165072	array([[ 3.4645958, -9.451057 ]], dtype=float32)
time = 24180	action = 0	current_phase = 0	next_phase = 1	reward = 1.292751	array([[ 3.42212 , -9.533102]], dtype=float32)
time = 24185	action = 0	current_phase = 0	next_phase = 1	reward = 0.724574	array([[ 3.4852476, -9.438807 ]], dtype=float32)
time = 24190	action = 0	current_phase = 0	next_phase = 1	reward = 0.165719	array([[ 3.4816914, -9.47897  ]], dtype=float32)
time = 24195	action = 0	current_phase = 0	next_phase = 1	reward = 1.290971	array([[ 3.4184713, -9.5016575]], dtype=float32)
time = 24200	action = 0	current_phase = 0	next_phase = 1	reward = 0.725709	array([[ 3.4882631, -9.4378395]], dtype=float32)
time = 24205	action = 0	current_phase = 0	next_phase = 1	reward = 0.717876	array([[ 3.492031, -9.4266  ]], dtype=float32)
time = 24210	action = 0	current_phase = 0	next_phase = 1	reward = 0.724553	array([[ 3.4994097, -9.432195 ]], dtype=float32)
time = 24215	action = 0	current_phase = 0	next_phase = 1	reward = 0.721494	array([[ 3.5228071, -9.435797 ]], dtype=float32)
time = 24220	action = 0	current_phase = 0	next_phase = 1	reward = 0.451443	array([[ 3.4895077, -9.41406  ]], dtype=float32)
time = 24225	action = 0	current_phase = 0	next_phase = 1	reward = 1.010508	array([[ 3.5016937, -9.471468 ]], dtype=float32)
time = 24230	action = 0	current_phase = 0	next_phase = 1	reward = 0.727663	array([[ 3.487526, -9.442581]], dtype=float32)
time = 24235	action = 0	current_phase = 0	next_phase = 1	reward = 0.713375	array([[ 3.497779, -9.472956]], dtype=float32)
time = 24240	action = 0	current_phase = 0	next_phase = 1	reward = 0.719626	array([[ 3.558611, -9.406195]], dtype=float32)
time = 24245	action = 0	current_phase = 0	next_phase = 1	reward = 0.723470	array([[ 3.4668283, -9.460967 ]], dtype=float32)
time = 24250	action = 0	current_phase = 0	next_phase = 1	reward = 0.442702	array([[ 3.4665337, -9.457609 ]], dtype=float32)
time = 24255	action = 0	current_phase = 0	next_phase = 1	reward = 1.000443	array([[ 3.4728832, -9.511507 ]], dtype=float32)
time = 24260	action = 0	current_phase = 0	next_phase = 1	reward = 0.438678	array([[ 3.501831, -9.408887]], dtype=float32)
time = 24265	action = 0	current_phase = 0	next_phase = 1	reward = 1.006693	array([[ 3.3768005, -9.626311 ]], dtype=float32)
time = 24270	action = 0	current_phase = 0	next_phase = 1	reward = 0.717174	array([[ 3.317483, -9.826931]], dtype=float32)
time = 24275	action = 0	current_phase = 0	next_phase = 1	reward = 0.438787	array([[ 3.503727, -9.422683]], dtype=float32)
time = 24280	action = 0	current_phase = 0	next_phase = 1	reward = 0.720823	array([[ 3.510872, -9.408098]], dtype=float32)
time = 24285	action = 0	current_phase = 0	next_phase = 1	reward = 0.447561	array([[ 3.5007095, -9.434473 ]], dtype=float32)
time = 24290	action = 0	current_phase = 0	next_phase = 1	reward = 1.017040	array([[ 3.4417496, -9.500175 ]], dtype=float32)
time = 24295	action = 0	current_phase = 0	next_phase = 1	reward = 1.005007	array([[ 3.519658, -9.393535]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.4557 - val_loss: 1.8894
Epoch 2/50
 - 4s - loss: 4.9655 - val_loss: 2.3006
Epoch 3/50
 - 4s - loss: 3.5912 - val_loss: 1.9783
Epoch 4/50
 - 4s - loss: 4.8101 - val_loss: 2.5422
Epoch 5/50
 - 4s - loss: 3.7785 - val_loss: 2.0050
Epoch 6/50
 - 4s - loss: 3.7145 - val_loss: 2.7440
Epoch 7/50
 - 4s - loss: 3.9505 - val_loss: 2.7775
Epoch 8/50
 - 4s - loss: 5.1755 - val_loss: 1.6835
Epoch 9/50
 - 4s - loss: 3.3173 - val_loss: 2.1945
Epoch 10/50
 - 4s - loss: 4.1129 - val_loss: 2.2496
Epoch 11/50
 - 4s - loss: 3.4517 - val_loss: 1.9151
Epoch 12/50
 - 4s - loss: 4.4810 - val_loss: 2.1396
Epoch 13/50
 - 4s - loss: 3.6194 - val_loss: 2.5191
Epoch 14/50
 - 4s - loss: 4.0284 - val_loss: 2.1055
Epoch 15/50
 - 4s - loss: 4.2473 - val_loss: 2.8536
Epoch 16/50
 - 4s - loss: 3.0198 - val_loss: 1.7319
Epoch 17/50
 - 4s - loss: 3.2738 - val_loss: 1.8490
Epoch 18/50
 - 4s - loss: 3.9937 - val_loss: 1.9489
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 24300	action = 0	current_phase = 0	next_phase = 1	reward = 0.726981	array([[ 3.5182228, -9.448079 ]], dtype=float32)
time = 24305	action = 0	current_phase = 0	next_phase = 1	reward = 0.442972	array([[ 3.5581589, -9.425895 ]], dtype=float32)
time = 24310	action = 0	current_phase = 0	next_phase = 1	reward = 0.995944	array([[ 3.543624, -9.484886]], dtype=float32)
time = 24315	action = 0	current_phase = 0	next_phase = 1	reward = 0.711695	array([[ 3.5720348, -9.408813 ]], dtype=float32)
time = 24320	action = 0	current_phase = 0	next_phase = 1	reward = 0.157825	array([[ 3.572836, -9.438927]], dtype=float32)
time = 24325	action = 0	current_phase = 0	next_phase = 1	reward = 1.011787	array([[ 3.475916, -9.530129]], dtype=float32)
time = 24330	action = 0	current_phase = 0	next_phase = 1	reward = 0.722088	array([[ 3.5229244, -9.448072 ]], dtype=float32)
time = 24335	action = 0	current_phase = 0	next_phase = 1	reward = 0.724645	array([[ 3.556612, -9.445217]], dtype=float32)
time = 24340	action = 0	current_phase = 0	next_phase = 1	reward = 0.728539	array([[ 3.4659586, -9.49929  ]], dtype=float32)
time = 24345	action = 0	current_phase = 0	next_phase = 1	reward = 0.723590	array([[ 3.5515451, -9.431681 ]], dtype=float32)
time = 24350	action = 0	current_phase = 0	next_phase = 1	reward = 1.000044	array([[ 3.5313225, -9.441395 ]], dtype=float32)
time = 24355	action = 0	current_phase = 0	next_phase = 1	reward = 0.441739	array([[ 3.581953, -9.41694 ]], dtype=float32)
time = 24360	action = 0	current_phase = 0	next_phase = 1	reward = 0.721114	array([[ 3.5017567, -9.477712 ]], dtype=float32)
time = 24365	action = 0	current_phase = 0	next_phase = 1	reward = 0.727850	array([[ 3.5321121, -9.43721  ]], dtype=float32)
time = 24370	action = 0	current_phase = 0	next_phase = 1	reward = 1.000988	array([[ 3.4571714, -9.534788 ]], dtype=float32)
time = 24375	action = 0	current_phase = 0	next_phase = 1	reward = 0.437784	array([[ 3.5371876, -9.445124 ]], dtype=float32)
time = 24380	action = 0	current_phase = 0	next_phase = 1	reward = 0.724229	array([[ 3.5199633, -9.5198345]], dtype=float32)
time = 24385	action = 0	current_phase = 0	next_phase = 1	reward = 1.011623	array([[ 3.5375605, -9.48197  ]], dtype=float32)
time = 24390	action = 0	current_phase = 0	next_phase = 1	reward = 0.730696	array([[ 3.5411253, -9.439487 ]], dtype=float32)
time = 24395	action = 0	current_phase = 0	next_phase = 1	reward = 0.445252	array([[ 3.544444, -9.436037]], dtype=float32)
time = 24400	action = 0	current_phase = 0	next_phase = 1	reward = 1.005205	array([[ 3.432126, -9.411535]], dtype=float32)
time = 24405	action = 0	current_phase = 0	next_phase = 1	reward = 0.720127	array([[ 3.5870237, -9.3936405]], dtype=float32)
time = 24410	action = 0	current_phase = 0	next_phase = 1	reward = 0.716278	array([[ 3.507701, -9.481161]], dtype=float32)
time = 24415	action = 0	current_phase = 0	next_phase = 1	reward = 0.443540	array([[ 3.5466232, -9.439243 ]], dtype=float32)
time = 24420	action = 0	current_phase = 0	next_phase = 1	reward = 0.999751	array([[ 3.5325432, -9.441572 ]], dtype=float32)
time = 24425	action = 0	current_phase = 0	next_phase = 1	reward = 0.444294	array([[ 3.5026407, -9.50094  ]], dtype=float32)
time = 24430	action = 0	current_phase = 0	next_phase = 1	reward = 0.446525	array([[ 3.4988747, -9.483862 ]], dtype=float32)
time = 24435	action = 0	current_phase = 0	next_phase = 1	reward = 1.006239	array([[ 3.4707546, -9.559099 ]], dtype=float32)
time = 24440	action = 0	current_phase = 0	next_phase = 1	reward = 0.720089	array([[ 3.5447454, -9.464724 ]], dtype=float32)
time = 24445	action = 0	current_phase = 0	next_phase = 1	reward = 0.727963	array([[ 3.5039186, -9.462955 ]], dtype=float32)
time = 24450	action = 0	current_phase = 0	next_phase = 1	reward = 0.452142	array([[ 3.5354548, -9.447017 ]], dtype=float32)
time = 24455	action = 0	current_phase = 0	next_phase = 1	reward = 1.292303	array([[ 3.461381, -9.540674]], dtype=float32)
time = 24460	action = 0	current_phase = 0	next_phase = 1	reward = 0.726006	array([[ 3.5393429, -9.442694 ]], dtype=float32)
time = 24465	action = 0	current_phase = 0	next_phase = 1	reward = 0.444459	array([[ 3.533845, -9.434219]], dtype=float32)
time = 24470	action = 0	current_phase = 0	next_phase = 1	reward = 0.738587	array([[ 3.517395, -9.458666]], dtype=float32)
time = 24475	action = 0	current_phase = 0	next_phase = 1	reward = 0.732021	array([[ 3.5792122, -9.413134 ]], dtype=float32)
time = 24480	action = 0	current_phase = 0	next_phase = 1	reward = 1.002132	array([[ 3.566246, -9.422762]], dtype=float32)
time = 24485	action = 0	current_phase = 0	next_phase = 1	reward = 0.439796	array([[ 3.4962263, -9.466675 ]], dtype=float32)
time = 24490	action = 0	current_phase = 0	next_phase = 1	reward = 0.717786	array([[ 3.5096188, -9.472153 ]], dtype=float32)
time = 24495	action = 0	current_phase = 0	next_phase = 1	reward = 0.726730	array([[ 3.5143414, -9.480596 ]], dtype=float32)
time = 24500	action = 0	current_phase = 0	next_phase = 1	reward = 1.011576	array([[ 3.5780315, -9.416227 ]], dtype=float32)
time = 24505	action = 0	current_phase = 0	next_phase = 1	reward = 0.725822	array([[ 3.5938625, -9.418413 ]], dtype=float32)
time = 24510	action = 0	current_phase = 0	next_phase = 1	reward = 0.716471	array([[ 3.5490122, -9.423424 ]], dtype=float32)
time = 24515	action = 0	current_phase = 0	next_phase = 1	reward = 0.721889	array([[ 3.521882, -9.472229]], dtype=float32)
time = 24520	action = 0	current_phase = 0	next_phase = 1	reward = 0.718557	array([[ 3.574335, -9.420469]], dtype=float32)
time = 24525	action = 0	current_phase = 0	next_phase = 1	reward = 0.442671	array([[ 3.5966644, -9.405485 ]], dtype=float32)
time = 24530	action = 0	current_phase = 0	next_phase = 1	reward = 1.003864	array([[ 3.5729284, -9.415001 ]], dtype=float32)
time = 24535	action = 0	current_phase = 0	next_phase = 1	reward = 0.720954	array([[ 3.5569544, -9.40023  ]], dtype=float32)
time = 24540	action = 0	current_phase = 0	next_phase = 1	reward = 0.448797	array([[ 3.5901136, -9.394934 ]], dtype=float32)
time = 24545	action = 0	current_phase = 0	next_phase = 1	reward = 1.000107	array([[ 3.5776634, -9.42782  ]], dtype=float32)
time = 24550	action = 0	current_phase = 0	next_phase = 1	reward = 0.714652	array([[ 3.6278963, -9.378643 ]], dtype=float32)
time = 24555	action = 0	current_phase = 0	next_phase = 1	reward = 0.723376	array([[ 3.5817413, -9.41458  ]], dtype=float32)
time = 24560	action = 0	current_phase = 0	next_phase = 1	reward = 0.161248	array([[ 3.5273466, -9.454393 ]], dtype=float32)
time = 24565	action = 0	current_phase = 0	next_phase = 1	reward = 1.005670	array([[ 3.3015356, -9.621441 ]], dtype=float32)
time = 24570	action = 0	current_phase = 0	next_phase = 1	reward = 0.721361	array([[ 3.596259, -9.375986]], dtype=float32)
time = 24575	action = 0	current_phase = 0	next_phase = 1	reward = 0.722102	array([[ 3.5624247, -9.4276705]], dtype=float32)
time = 24580	action = 0	current_phase = 0	next_phase = 1	reward = 0.728368	array([[ 3.5262032, -9.4726925]], dtype=float32)
time = 24585	action = 0	current_phase = 0	next_phase = 1	reward = 1.002393	array([[ 3.5169344, -9.472986 ]], dtype=float32)
time = 24590	action = 0	current_phase = 0	next_phase = 1	reward = 0.725683	array([[ 3.6026201, -9.400375 ]], dtype=float32)
time = 24595	action = 0	current_phase = 0	next_phase = 1	reward = 0.726331	array([[ 3.6139793, -9.393063 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.9529 - val_loss: 2.0031
Epoch 2/50
 - 4s - loss: 3.5500 - val_loss: 1.7098
Epoch 3/50
 - 4s - loss: 4.9494 - val_loss: 2.6202
Epoch 4/50
 - 4s - loss: 5.0481 - val_loss: 1.9217
Epoch 5/50
 - 4s - loss: 3.1457 - val_loss: 2.0838
Epoch 6/50
 - 4s - loss: 4.5077 - val_loss: 2.2910
Epoch 7/50
 - 4s - loss: 3.2722 - val_loss: 1.7277
Epoch 8/50
 - 4s - loss: 3.9668 - val_loss: 2.3130
Epoch 9/50
 - 4s - loss: 5.0984 - val_loss: 2.5188
Epoch 10/50
 - 4s - loss: 3.2200 - val_loss: 2.0968
Epoch 11/50
 - 4s - loss: 3.1452 - val_loss: 2.0041
Epoch 12/50
 - 4s - loss: 4.0120 - val_loss: 1.9859
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 24600	action = 0	current_phase = 0	next_phase = 1	reward = 0.720917	array([[ 3.5158696, -9.487658 ]], dtype=float32)
time = 24605	action = 0	current_phase = 0	next_phase = 1	reward = 0.713352	array([[ 3.5315003, -9.452387 ]], dtype=float32)
time = 24610	action = 0	current_phase = 0	next_phase = 1	reward = 0.448497	array([[ 3.5779862, -9.405775 ]], dtype=float32)
time = 24615	action = 0	current_phase = 0	next_phase = 1	reward = 1.007948	array([[ 3.536612, -9.451529]], dtype=float32)
time = 24620	action = 0	current_phase = 0	next_phase = 1	reward = 0.443477	array([[ 3.530356, -9.452733]], dtype=float32)
time = 24625	action = 0	current_phase = 0	next_phase = 1	reward = 1.006753	array([[ 3.5324416, -9.434572 ]], dtype=float32)
time = 24630	action = 0	current_phase = 0	next_phase = 1	reward = 0.727160	array([[ 3.5940137, -9.405502 ]], dtype=float32)
time = 24635	action = 0	current_phase = 0	next_phase = 1	reward = 0.722023	array([[ 3.544313, -9.435772]], dtype=float32)
time = 24640	action = 0	current_phase = 0	next_phase = 1	reward = 0.727948	array([[ 3.5220714, -9.451765 ]], dtype=float32)
time = 24645	action = 0	current_phase = 0	next_phase = 1	reward = 0.721815	array([[ 3.5992436, -9.413774 ]], dtype=float32)
time = 24650	action = 0	current_phase = 0	next_phase = 1	reward = 0.725477	array([[ 3.4526362, -9.522434 ]], dtype=float32)
time = 24655	action = 0	current_phase = 0	next_phase = 1	reward = 0.718507	array([[ 3.540279, -9.430027]], dtype=float32)
time = 24660	action = 0	current_phase = 0	next_phase = 1	reward = 0.442625	array([[ 3.588385, -9.408972]], dtype=float32)
time = 24665	action = 0	current_phase = 0	next_phase = 1	reward = 1.003191	array([[ 3.5690017, -9.39524  ]], dtype=float32)
time = 24670	action = 0	current_phase = 0	next_phase = 1	reward = 0.720597	array([[ 3.505381, -9.46793 ]], dtype=float32)
time = 24675	action = 0	current_phase = 0	next_phase = 1	reward = 0.724351	array([[ 3.5458283, -9.4287815]], dtype=float32)
time = 24680	action = 0	current_phase = 0	next_phase = 1	reward = 0.719331	array([[ 3.5302606, -9.435113 ]], dtype=float32)
time = 24685	action = 0	current_phase = 0	next_phase = 1	reward = 0.718271	array([[ 3.536655, -9.455556]], dtype=float32)
time = 24690	action = 0	current_phase = 0	next_phase = 1	reward = 0.718555	array([[ 3.5508494, -9.420138 ]], dtype=float32)
time = 24695	action = 0	current_phase = 0	next_phase = 1	reward = 0.446277	array([[ 3.5959888, -9.411022 ]], dtype=float32)
time = 24700	action = 0	current_phase = 0	next_phase = 1	reward = 1.007668	array([[ 3.5376763, -9.448479 ]], dtype=float32)
time = 24705	action = 0	current_phase = 0	next_phase = 1	reward = 0.445402	array([[ 3.5594144, -9.400084 ]], dtype=float32)
time = 24710	action = 0	current_phase = 0	next_phase = 1	reward = 1.006026	array([[ 3.4941201, -9.493355 ]], dtype=float32)
time = 24715	action = 0	current_phase = 0	next_phase = 1	reward = 0.721624	array([[ 3.562058 , -9.4146385]], dtype=float32)
time = 24720	action = 0	current_phase = 0	next_phase = 1	reward = 0.719917	array([[ 3.5423608, -9.431697 ]], dtype=float32)
time = 24725	action = 0	current_phase = 0	next_phase = 1	reward = 0.709857	array([[ 3.5486903, -9.464088 ]], dtype=float32)
time = 24730	action = 0	current_phase = 0	next_phase = 1	reward = 0.723296	array([[ 3.5668244, -9.387484 ]], dtype=float32)
time = 24735	action = 0	current_phase = 0	next_phase = 1	reward = 0.439380	array([[ 3.5574346, -9.404707 ]], dtype=float32)
time = 24740	action = 0	current_phase = 0	next_phase = 1	reward = 1.006942	array([[ 3.548205, -9.44162 ]], dtype=float32)
time = 24745	action = 0	current_phase = 0	next_phase = 1	reward = 0.718067	array([[ 3.5236926, -9.4546385]], dtype=float32)
time = 24750	action = 0	current_phase = 0	next_phase = 1	reward = 0.715267	array([[ 3.5650096, -9.439945 ]], dtype=float32)
time = 24755	action = 0	current_phase = 0	next_phase = 1	reward = 0.446437	array([[ 3.5262704, -9.440523 ]], dtype=float32)
time = 24760	action = 0	current_phase = 0	next_phase = 1	reward = 0.734704	array([[ 3.5274415, -9.441617 ]], dtype=float32)
time = 24765	action = 0	current_phase = 0	next_phase = 1	reward = 1.001227	array([[ 3.3999438, -9.653161 ]], dtype=float32)
time = 24770	action = 0	current_phase = 0	next_phase = 1	reward = 0.442879	array([[ 3.5496783, -9.424199 ]], dtype=float32)
time = 24775	action = 0	current_phase = 0	next_phase = 1	reward = 0.725965	array([[ 3.585693, -9.413579]], dtype=float32)
time = 24780	action = 0	current_phase = 0	next_phase = 1	reward = 1.010099	array([[ 3.492206, -9.475655]], dtype=float32)
time = 24785	action = 0	current_phase = 0	next_phase = 1	reward = 0.723745	array([[ 3.5292125, -9.453837 ]], dtype=float32)
time = 24790	action = 0	current_phase = 0	next_phase = 1	reward = 0.725018	array([[ 3.5010562, -9.479354 ]], dtype=float32)
time = 24795	action = 0	current_phase = 0	next_phase = 1	reward = 0.730660	array([[ 3.545569, -9.426418]], dtype=float32)
time = 24800	action = 0	current_phase = 0	next_phase = 1	reward = 0.721151	array([[ 3.489555, -9.584541]], dtype=float32)
time = 24805	action = 0	current_phase = 0	next_phase = 1	reward = 0.443963	array([[ 3.5326123, -9.449332 ]], dtype=float32)
time = 24810	action = 0	current_phase = 0	next_phase = 1	reward = 1.012114	array([[ 3.5313706, -9.4441185]], dtype=float32)
time = 24815	action = 0	current_phase = 0	next_phase = 1	reward = 0.724058	array([[ 3.539061, -9.429144]], dtype=float32)
time = 24820	action = 0	current_phase = 0	next_phase = 1	reward = 0.726186	array([[ 3.5368857, -9.447399 ]], dtype=float32)
time = 24825	action = 0	current_phase = 0	next_phase = 1	reward = 0.727147	array([[ 3.5536695, -9.415449 ]], dtype=float32)
time = 24830	action = 0	current_phase = 0	next_phase = 1	reward = 0.718787	array([[ 3.52593 , -9.451095]], dtype=float32)
time = 24835	action = 0	current_phase = 0	next_phase = 1	reward = 0.718489	array([[ 3.5265079, -9.448069 ]], dtype=float32)
time = 24840	action = 0	current_phase = 0	next_phase = 1	reward = 0.717679	array([[ 3.5651145, -9.413392 ]], dtype=float32)
time = 24845	action = 0	current_phase = 0	next_phase = 1	reward = 0.724236	array([[ 3.5198092, -9.448028 ]], dtype=float32)
time = 24850	action = 0	current_phase = 0	next_phase = 1	reward = 0.444988	array([[ 3.5505166, -9.414385 ]], dtype=float32)
time = 24855	action = 0	current_phase = 0	next_phase = 1	reward = 0.732156	array([[ 3.5231109, -9.452724 ]], dtype=float32)
time = 24860	action = 0	current_phase = 0	next_phase = 1	reward = 1.003083	array([[ 3.5798945, -9.437925 ]], dtype=float32)
time = 24865	action = 0	current_phase = 0	next_phase = 1	reward = 0.720385	array([[ 3.5616307, -9.414981 ]], dtype=float32)
time = 24870	action = 0	current_phase = 0	next_phase = 1	reward = 0.722930	array([[ 3.5584903, -9.429321 ]], dtype=float32)
time = 24875	action = 0	current_phase = 0	next_phase = 1	reward = 0.723898	array([[ 3.510447, -9.472482]], dtype=float32)
time = 24880	action = 0	current_phase = 0	next_phase = 1	reward = 0.723608	array([[ 3.550899, -9.437748]], dtype=float32)
time = 24885	action = 0	current_phase = 0	next_phase = 1	reward = 0.721884	array([[ 3.5513892, -9.414528 ]], dtype=float32)
time = 24890	action = 0	current_phase = 0	next_phase = 1	reward = 0.723050	array([[ 3.554233, -9.411486]], dtype=float32)
time = 24895	action = 0	current_phase = 0	next_phase = 1	reward = 0.717338	array([[ 3.5403962, -9.413105 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.2175 - val_loss: 2.3097
Epoch 2/50
 - 4s - loss: 4.7983 - val_loss: 1.9625
Epoch 3/50
 - 4s - loss: 3.4502 - val_loss: 2.0797
Epoch 4/50
 - 5s - loss: 4.2525 - val_loss: 2.3514
Epoch 5/50
 - 4s - loss: 5.4555 - val_loss: 2.2913
Epoch 6/50
 - 4s - loss: 4.1603 - val_loss: 2.1477
Epoch 7/50
 - 4s - loss: 3.0521 - val_loss: 2.0359
Epoch 8/50
 - 5s - loss: 4.4015 - val_loss: 2.7724
Epoch 9/50
 - 4s - loss: 3.0666 - val_loss: 2.3907
Epoch 10/50
 - 4s - loss: 2.8633 - val_loss: 2.5159
Epoch 11/50
 - 4s - loss: 3.8941 - val_loss: 2.2397
Epoch 12/50
 - 4s - loss: 3.4604 - val_loss: 2.6753
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 24900	action = 0	current_phase = 0	next_phase = 1	reward = 0.723594	array([[ 3.4757  , -9.372185]], dtype=float32)
time = 24905	action = 0	current_phase = 0	next_phase = 1	reward = 0.439481	array([[ 3.394032, -9.471752]], dtype=float32)
time = 24910	action = 0	current_phase = 0	next_phase = 1	reward = 0.449826	array([[ 3.4311328, -9.4172125]], dtype=float32)
time = 24915	action = 0	current_phase = 0	next_phase = 1	reward = 1.020794	array([[ 3.4235682, -9.401434 ]], dtype=float32)
time = 24920	action = 0	current_phase = 0	next_phase = 1	reward = 0.454176	array([[ 3.4517417, -9.392697 ]], dtype=float32)
time = 24925	action = 0	current_phase = 0	next_phase = 1	reward = 1.290252	array([[ 3.4266467, -9.439003 ]], dtype=float32)
time = 24930	action = 0	current_phase = 0	next_phase = 1	reward = 0.716164	array([[ 3.4806638, -9.373407 ]], dtype=float32)
time = 24935	action = 0	current_phase = 0	next_phase = 1	reward = 0.719336	array([[ 3.4618087, -9.408049 ]], dtype=float32)
time = 24940	action = 0	current_phase = 0	next_phase = 1	reward = 0.723754	array([[ 3.4937415, -9.358366 ]], dtype=float32)
time = 24945	action = 0	current_phase = 0	next_phase = 1	reward = 0.721077	array([[ 3.474955, -9.379774]], dtype=float32)
time = 24950	action = 0	current_phase = 0	next_phase = 1	reward = 0.727638	array([[ 3.4577317, -9.403362 ]], dtype=float32)
time = 24955	action = 0	current_phase = 0	next_phase = 1	reward = 0.725887	array([[ 3.4717717, -9.391428 ]], dtype=float32)
time = 24960	action = 0	current_phase = 0	next_phase = 1	reward = 0.719546	array([[ 3.4385886, -9.416069 ]], dtype=float32)
time = 24965	action = 0	current_phase = 0	next_phase = 1	reward = 0.730735	array([[ 3.5095658, -9.322313 ]], dtype=float32)
time = 24970	action = 0	current_phase = 0	next_phase = 1	reward = 0.732426	array([[ 3.4545112, -9.393646 ]], dtype=float32)
time = 24975	action = 0	current_phase = 0	next_phase = 1	reward = 0.724308	array([[ 3.4681344, -9.422729 ]], dtype=float32)
time = 24980	action = 0	current_phase = 0	next_phase = 1	reward = 0.716519	array([[ 3.5026174, -9.343927 ]], dtype=float32)
time = 24985	action = 0	current_phase = 0	next_phase = 1	reward = 0.718890	array([[ 3.4586368, -9.407094 ]], dtype=float32)
time = 24990	action = 0	current_phase = 0	next_phase = 1	reward = 0.720633	array([[ 3.4755378, -9.356339 ]], dtype=float32)
time = 24995	action = 0	current_phase = 0	next_phase = 1	reward = 0.163537	array([[ 3.447494, -9.399018]], dtype=float32)
time = 25000	action = 0	current_phase = 0	next_phase = 1	reward = 1.003990	array([[ 3.4317517, -9.44231  ]], dtype=float32)
time = 25005	action = 0	current_phase = 0	next_phase = 1	reward = 0.995527	array([[ 3.548285, -9.315043]], dtype=float32)
time = 25010	action = 0	current_phase = 0	next_phase = 1	reward = 0.442067	array([[ 3.5210528, -9.336161 ]], dtype=float32)
time = 25015	action = 0	current_phase = 0	next_phase = 1	reward = 0.725689	array([[ 3.4174008, -9.437929 ]], dtype=float32)
time = 25020	action = 0	current_phase = 0	next_phase = 1	reward = 0.717954	array([[ 3.4200692, -9.442438 ]], dtype=float32)
time = 25025	action = 0	current_phase = 0	next_phase = 1	reward = 0.451068	array([[ 3.4540353, -9.4222555]], dtype=float32)
time = 25030	action = 0	current_phase = 0	next_phase = 1	reward = 1.291638	array([[ 3.3751712, -9.501438 ]], dtype=float32)
time = 25035	action = 0	current_phase = 0	next_phase = 1	reward = 0.448328	array([[ 3.4700208, -9.385066 ]], dtype=float32)
time = 25040	action = 0	current_phase = 0	next_phase = 1	reward = 1.003803	array([[ 3.469976, -9.364979]], dtype=float32)
time = 25045	action = 0	current_phase = 0	next_phase = 1	reward = 0.450888	array([[ 3.4920907, -9.395704 ]], dtype=float32)
time = 25050	action = 0	current_phase = 0	next_phase = 1	reward = 1.003762	array([[ 3.4652963, -9.408203 ]], dtype=float32)
time = 25055	action = 0	current_phase = 0	next_phase = 1	reward = 0.723021	array([[ 3.4820743, -9.374701 ]], dtype=float32)
time = 25060	action = 0	current_phase = 0	next_phase = 1	reward = 0.723221	array([[ 3.4856954, -9.361395 ]], dtype=float32)
time = 25065	action = 0	current_phase = 0	next_phase = 1	reward = 0.443730	array([[ 3.4621243, -9.395316 ]], dtype=float32)
time = 25070	action = 0	current_phase = 0	next_phase = 1	reward = 1.001423	array([[ 3.4781528, -9.378754 ]], dtype=float32)
time = 25075	action = 0	current_phase = 0	next_phase = 1	reward = 0.712753	array([[ 3.4787097, -9.367466 ]], dtype=float32)
time = 25080	action = 0	current_phase = 0	next_phase = 1	reward = 0.433726	array([[ 3.3943362, -9.434491 ]], dtype=float32)
time = 25085	action = 0	current_phase = 0	next_phase = 1	reward = 0.442511	array([[ 3.428388, -9.423943]], dtype=float32)
time = 25090	action = 0	current_phase = 0	next_phase = 1	reward = 0.732438	array([[ 3.3927722, -9.477512 ]], dtype=float32)
time = 25095	action = 0	current_phase = 0	next_phase = 1	reward = 0.736289	array([[ 3.4136386, -9.506845 ]], dtype=float32)
time = 25100	action = 0	current_phase = 0	next_phase = 1	reward = 1.280624	array([[ 3.0879407, -9.8257   ]], dtype=float32)
time = 25105	action = 0	current_phase = 0	next_phase = 1	reward = 0.722085	array([[ 3.4740005, -9.36538  ]], dtype=float32)
time = 25110	action = 0	current_phase = 0	next_phase = 1	reward = 0.728239	array([[ 3.4719071, -9.382329 ]], dtype=float32)
time = 25115	action = 0	current_phase = 0	next_phase = 1	reward = 0.724423	array([[ 3.5516086, -9.30917  ]], dtype=float32)
time = 25120	action = 0	current_phase = 0	next_phase = 1	reward = 0.724597	array([[ 3.3470426, -9.505968 ]], dtype=float32)
time = 25125	action = 0	current_phase = 0	next_phase = 1	reward = 0.723641	array([[ 3.4104123, -9.467408 ]], dtype=float32)
time = 25130	action = 0	current_phase = 0	next_phase = 1	reward = 0.445666	array([[ 3.474094, -9.375107]], dtype=float32)
time = 25135	action = 0	current_phase = 0	next_phase = 1	reward = 0.722805	array([[ 3.4911695, -9.346815 ]], dtype=float32)
time = 25140	action = 0	current_phase = 0	next_phase = 1	reward = 0.994069	array([[ 3.4575315, -9.3665285]], dtype=float32)
time = 25145	action = 0	current_phase = 0	next_phase = 1	reward = 0.448871	array([[ 3.3578305, -9.486041 ]], dtype=float32)
time = 25150	action = 0	current_phase = 0	next_phase = 1	reward = 1.000670	array([[ 3.1295466, -9.826641 ]], dtype=float32)
time = 25155	action = 0	current_phase = 0	next_phase = 1	reward = 0.720348	array([[ 3.4989667, -9.357462 ]], dtype=float32)
time = 25160	action = 0	current_phase = 0	next_phase = 1	reward = 0.441163	array([[ 3.4634366, -9.387208 ]], dtype=float32)
time = 25165	action = 0	current_phase = 0	next_phase = 1	reward = 0.726494	array([[ 3.4123302, -9.459171 ]], dtype=float32)
time = 25170	action = 0	current_phase = 0	next_phase = 1	reward = 1.003390	array([[ 3.4428716, -9.396343 ]], dtype=float32)
time = 25175	action = 0	current_phase = 0	next_phase = 1	reward = 0.439792	array([[ 3.4443974, -9.385376 ]], dtype=float32)
time = 25180	action = 0	current_phase = 0	next_phase = 1	reward = 1.002526	array([[ 3.3931012, -9.509875 ]], dtype=float32)
time = 25185	action = 0	current_phase = 0	next_phase = 1	reward = 0.727312	array([[ 3.5061126, -9.370919 ]], dtype=float32)
time = 25190	action = 0	current_phase = 0	next_phase = 1	reward = 0.441893	array([[ 3.530542, -9.342619]], dtype=float32)
time = 25195	action = 0	current_phase = 0	next_phase = 1	reward = 1.014022	array([[ 3.3928466, -9.50704  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.4696 - val_loss: 3.3272
Epoch 2/50
 - 4s - loss: 4.6477 - val_loss: 3.4033
Epoch 3/50
 - 4s - loss: 4.3378 - val_loss: 3.1758
Epoch 4/50
 - 5s - loss: 3.2861 - val_loss: 3.3015
Epoch 5/50
 - 5s - loss: 4.0797 - val_loss: 3.7383
Epoch 6/50
 - 4s - loss: 4.0406 - val_loss: 3.1627
Epoch 7/50
 - 5s - loss: 4.2733 - val_loss: 2.9846
Epoch 8/50
 - 5s - loss: 3.9408 - val_loss: 4.0568
Epoch 9/50
 - 5s - loss: 4.6007 - val_loss: 3.2159
Epoch 10/50
 - 4s - loss: 3.3003 - val_loss: 2.7234
Epoch 11/50
 - 4s - loss: 3.2301 - val_loss: 2.9833
Epoch 12/50
 - 4s - loss: 4.6303 - val_loss: 3.0170
Epoch 13/50
 - 4s - loss: 3.7135 - val_loss: 3.2501
Epoch 14/50
 - 4s - loss: 2.9895 - val_loss: 2.8805
Epoch 15/50
 - 4s - loss: 3.7827 - val_loss: 3.2827
Epoch 16/50
 - 4s - loss: 3.2540 - val_loss: 2.7280
Epoch 17/50
 - 4s - loss: 2.6837 - val_loss: 3.3833
Epoch 18/50
 - 4s - loss: 2.7507 - val_loss: 3.4890
Epoch 19/50
 - 4s - loss: 2.7415 - val_loss: 3.0577
Epoch 20/50
 - 4s - loss: 3.1239 - val_loss: 2.8971
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 25200	action = 0	current_phase = 0	next_phase = 1	reward = 0.449876	array([[ 3.5704646, -9.366137 ]], dtype=float32)
time = 25205	action = 0	current_phase = 0	next_phase = 1	reward = 1.003489	array([[ 3.50746, -9.40365]], dtype=float32)
time = 25210	action = 0	current_phase = 0	next_phase = 1	reward = 0.717696	array([[ 3.572287, -9.364601]], dtype=float32)
time = 25215	action = 0	current_phase = 0	next_phase = 1	reward = 0.715136	array([[ 3.536736, -9.396129]], dtype=float32)
time = 25220	action = 0	current_phase = 0	next_phase = 1	reward = 0.731961	array([[ 3.4697223, -9.434054 ]], dtype=float32)
time = 25225	action = 0	current_phase = 0	next_phase = 1	reward = 0.735721	array([[ 3.496879, -9.410677]], dtype=float32)
time = 25230	action = 0	current_phase = 0	next_phase = 1	reward = 0.720675	array([[ 3.5328412, -9.391434 ]], dtype=float32)
time = 25235	action = 0	current_phase = 0	next_phase = 1	reward = 0.721333	array([[ 3.5868163, -9.360299 ]], dtype=float32)
time = 25240	action = 0	current_phase = 0	next_phase = 1	reward = 0.721805	array([[ 3.5129323, -9.388601 ]], dtype=float32)
time = 25245	action = 0	current_phase = 0	next_phase = 1	reward = 0.714648	array([[ 3.5521798, -9.369835 ]], dtype=float32)
time = 25250	action = 0	current_phase = 0	next_phase = 1	reward = 0.443146	array([[ 3.5282006, -9.399498 ]], dtype=float32)
time = 25255	action = 0	current_phase = 0	next_phase = 1	reward = 1.020747	array([[ 3.4860826, -9.42008  ]], dtype=float32)
time = 25260	action = 0	current_phase = 0	next_phase = 1	reward = 0.448100	array([[ 3.5085702, -9.407812 ]], dtype=float32)
time = 25265	action = 0	current_phase = 0	next_phase = 1	reward = 1.009862	array([[ 3.4929843, -9.451553 ]], dtype=float32)
time = 25270	action = 0	current_phase = 0	next_phase = 1	reward = 0.449070	array([[ 3.5358367, -9.373468 ]], dtype=float32)
time = 25275	action = 0	current_phase = 0	next_phase = 1	reward = 1.008346	array([[ 3.387385, -9.495451]], dtype=float32)
time = 25280	action = 0	current_phase = 0	next_phase = 1	reward = 0.723082	array([[ 3.4757762, -9.458915 ]], dtype=float32)
time = 25285	action = 0	current_phase = 0	next_phase = 1	reward = 0.721496	array([[ 3.5384984, -9.397091 ]], dtype=float32)
time = 25290	action = 0	current_phase = 0	next_phase = 1	reward = 0.723598	array([[ 3.5630555, -9.378977 ]], dtype=float32)
time = 25295	action = 0	current_phase = 0	next_phase = 1	reward = 0.450828	array([[ 3.5212407, -9.40904  ]], dtype=float32)
time = 25300	action = 0	current_phase = 0	next_phase = 1	reward = 1.014992	array([[ 3.4907098, -9.4341755]], dtype=float32)
time = 25305	action = 0	current_phase = 0	next_phase = 1	reward = 0.721348	array([[ 3.526773, -9.397712]], dtype=float32)
time = 25310	action = 0	current_phase = 0	next_phase = 1	reward = 0.719828	array([[ 3.5778613, -9.354171 ]], dtype=float32)
time = 25315	action = 0	current_phase = 0	next_phase = 1	reward = 0.445008	array([[ 3.5579772, -9.388311 ]], dtype=float32)
time = 25320	action = 0	current_phase = 0	next_phase = 1	reward = 0.727990	array([[ 3.506513, -9.411589]], dtype=float32)
time = 25325	action = 0	current_phase = 0	next_phase = 1	reward = 1.000408	array([[ 3.5411906, -9.369215 ]], dtype=float32)
time = 25330	action = 0	current_phase = 0	next_phase = 1	reward = 0.438025	array([[ 3.5463834, -9.37873  ]], dtype=float32)
time = 25335	action = 0	current_phase = 0	next_phase = 1	reward = 0.726929	array([[ 3.5197797, -9.395985 ]], dtype=float32)
time = 25340	action = 0	current_phase = 0	next_phase = 1	reward = 1.001737	array([[ 3.595265, -9.330439]], dtype=float32)
time = 25345	action = 0	current_phase = 0	next_phase = 1	reward = 0.440801	array([[ 3.5747867, -9.356544 ]], dtype=float32)
time = 25350	action = 0	current_phase = 0	next_phase = 1	reward = 1.012274	array([[ 3.4626899, -9.463866 ]], dtype=float32)
time = 25355	action = 0	current_phase = 0	next_phase = 1	reward = 0.726439	array([[ 3.5958142, -9.343831 ]], dtype=float32)
time = 25360	action = 0	current_phase = 0	next_phase = 1	reward = 0.717426	array([[ 3.5353332, -9.380881 ]], dtype=float32)
time = 25365	action = 0	current_phase = 0	next_phase = 1	reward = 0.440564	array([[ 3.526444, -9.393537]], dtype=float32)
time = 25370	action = 0	current_phase = 0	next_phase = 1	reward = 1.004769	array([[ 3.4883723, -9.461999 ]], dtype=float32)
time = 25375	action = 0	current_phase = 0	next_phase = 1	reward = 0.729752	array([[ 3.5497317, -9.3722925]], dtype=float32)
time = 25380	action = 0	current_phase = 0	next_phase = 1	reward = 0.443806	array([[ 3.585688, -9.36429 ]], dtype=float32)
time = 25385	action = 0	current_phase = 0	next_phase = 1	reward = 1.003434	array([[ 3.545672, -9.390051]], dtype=float32)
time = 25390	action = 0	current_phase = 0	next_phase = 1	reward = 0.725104	array([[ 3.542708, -9.377893]], dtype=float32)
time = 25395	action = 0	current_phase = 0	next_phase = 1	reward = 0.723416	array([[ 3.5547976, -9.368156 ]], dtype=float32)
time = 25400	action = 0	current_phase = 0	next_phase = 1	reward = 0.724869	array([[ 3.5066514, -9.395786 ]], dtype=float32)
time = 25405	action = 0	current_phase = 0	next_phase = 1	reward = 0.447709	array([[ 3.5191035, -9.385735 ]], dtype=float32)
time = 25410	action = 0	current_phase = 0	next_phase = 1	reward = 1.008846	array([[ 3.5198398, -9.418142 ]], dtype=float32)
time = 25415	action = 0	current_phase = 0	next_phase = 1	reward = 0.723380	array([[ 3.5854764, -9.354184 ]], dtype=float32)
time = 25420	action = 0	current_phase = 0	next_phase = 1	reward = 0.721172	array([[ 3.53554 , -9.369064]], dtype=float32)
time = 25425	action = 0	current_phase = 0	next_phase = 1	reward = 0.722358	array([[ 3.5246854, -9.387399 ]], dtype=float32)
time = 25430	action = 0	current_phase = 0	next_phase = 1	reward = 0.728285	array([[ 3.5690446, -9.363965 ]], dtype=float32)
time = 25435	action = 0	current_phase = 0	next_phase = 1	reward = 0.723132	array([[ 3.5430446, -9.354275 ]], dtype=float32)
time = 25440	action = 0	current_phase = 0	next_phase = 1	reward = 0.721535	array([[ 3.4479775, -9.531507 ]], dtype=float32)
time = 25445	action = 0	current_phase = 0	next_phase = 1	reward = 0.721292	array([[ 3.5255818, -9.379257 ]], dtype=float32)
time = 25450	action = 0	current_phase = 0	next_phase = 1	reward = 0.440352	array([[ 3.590304, -9.348017]], dtype=float32)
time = 25455	action = 0	current_phase = 0	next_phase = 1	reward = 1.001223	array([[ 3.5306497, -9.3901825]], dtype=float32)
time = 25460	action = 0	current_phase = 0	next_phase = 1	reward = 0.720502	array([[ 3.5562015, -9.368229 ]], dtype=float32)
time = 25465	action = 0	current_phase = 0	next_phase = 1	reward = 0.446654	array([[ 3.5154672, -9.411566 ]], dtype=float32)
time = 25470	action = 0	current_phase = 0	next_phase = 1	reward = 1.004468	array([[ 3.498941, -9.460501]], dtype=float32)
time = 25475	action = 0	current_phase = 0	next_phase = 1	reward = 0.719866	array([[ 3.5485663, -9.374054 ]], dtype=float32)
time = 25480	action = 0	current_phase = 0	next_phase = 1	reward = 0.438500	array([[ 3.5149064, -9.390031 ]], dtype=float32)
time = 25485	action = 0	current_phase = 0	next_phase = 1	reward = 0.999959	array([[ 3.3417487, -9.594027 ]], dtype=float32)
time = 25490	action = 0	current_phase = 0	next_phase = 1	reward = 0.718087	array([[ 3.5313306, -9.40477  ]], dtype=float32)
time = 25495	action = 0	current_phase = 0	next_phase = 1	reward = 0.725083	array([[ 3.5458074, -9.3767395]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.7196 - val_loss: 1.5489
Epoch 2/50
 - 4s - loss: 3.3783 - val_loss: 1.2088
Epoch 3/50
 - 4s - loss: 4.3216 - val_loss: 1.0624
Epoch 4/50
 - 4s - loss: 3.6360 - val_loss: 1.7642
Epoch 5/50
 - 4s - loss: 5.1223 - val_loss: 1.2728
Epoch 6/50
 - 4s - loss: 5.0154 - val_loss: 1.4830
Epoch 7/50
 - 4s - loss: 4.0134 - val_loss: 1.1037
Epoch 8/50
 - 4s - loss: 4.0001 - val_loss: 1.7135
Epoch 9/50
 - 4s - loss: 4.1937 - val_loss: 1.4101
Epoch 10/50
 - 4s - loss: 5.5066 - val_loss: 1.1778
Epoch 11/50
 - 4s - loss: 4.1914 - val_loss: 1.3123
Epoch 12/50
 - 4s - loss: 3.9727 - val_loss: 1.1985
Epoch 13/50
 - 4s - loss: 3.6587 - val_loss: 1.0360
Epoch 14/50
 - 4s - loss: 3.1724 - val_loss: 1.3583
Epoch 15/50
 - 4s - loss: 4.2912 - val_loss: 1.5353
Epoch 16/50
 - 4s - loss: 4.1247 - val_loss: 1.1850
Epoch 17/50
 - 4s - loss: 5.5088 - val_loss: 1.3608
Epoch 18/50
 - 4s - loss: 4.2930 - val_loss: 1.6248
Epoch 19/50
 - 4s - loss: 5.5959 - val_loss: 1.6948
Epoch 20/50
 - 4s - loss: 3.4513 - val_loss: 1.2261
Epoch 21/50
 - 4s - loss: 4.3223 - val_loss: 1.3466
Epoch 22/50
 - 4s - loss: 3.6018 - val_loss: 0.9181
Epoch 23/50
 - 4s - loss: 3.3057 - val_loss: 1.3086
Epoch 24/50
 - 4s - loss: 4.2798 - val_loss: 1.2761
Epoch 25/50
 - 4s - loss: 4.5846 - val_loss: 1.3028
Epoch 26/50
 - 4s - loss: 4.1019 - val_loss: 1.0626
Epoch 27/50
 - 4s - loss: 3.8309 - val_loss: 1.4210
Epoch 28/50
 - 4s - loss: 3.9057 - val_loss: 1.7941
Epoch 29/50
 - 4s - loss: 3.7738 - val_loss: 1.3611
Epoch 30/50
 - 4s - loss: 3.6772 - val_loss: 2.0778
Epoch 31/50
 - 4s - loss: 3.7702 - val_loss: 1.1823
Epoch 32/50
 - 4s - loss: 2.8706 - val_loss: 1.7251
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 25500	action = 0	current_phase = 0	next_phase = 1	reward = 0.449444	array([[ 3.5339246, -9.426012 ]], dtype=float32)
time = 25505	action = 0	current_phase = 0	next_phase = 1	reward = 1.005971	array([[ 3.5283961, -9.394684 ]], dtype=float32)
time = 25510	action = 0	current_phase = 0	next_phase = 1	reward = 0.719444	array([[ 3.5127444, -9.393342 ]], dtype=float32)
time = 25515	action = 0	current_phase = 0	next_phase = 1	reward = 0.442107	array([[ 3.5319257, -9.388236 ]], dtype=float32)
time = 25520	action = 0	current_phase = 0	next_phase = 1	reward = 1.000176	array([[ 3.464788, -9.451337]], dtype=float32)
time = 25525	action = 0	current_phase = 0	next_phase = 1	reward = 0.438054	array([[ 3.5331187, -9.430813 ]], dtype=float32)
time = 25530	action = 0	current_phase = 0	next_phase = 1	reward = 0.730882	array([[ 3.4823928, -9.448959 ]], dtype=float32)
time = 25535	action = 0	current_phase = 0	next_phase = 1	reward = 0.724995	array([[ 3.4977498, -9.443982 ]], dtype=float32)
time = 25540	action = 0	current_phase = 0	next_phase = 1	reward = 1.005496	array([[ 3.5508552, -9.399145 ]], dtype=float32)
time = 25545	action = 0	current_phase = 0	next_phase = 1	reward = 0.721507	array([[ 3.529489, -9.370924]], dtype=float32)
time = 25550	action = 0	current_phase = 0	next_phase = 1	reward = 0.446668	array([[ 3.4795775, -9.419193 ]], dtype=float32)
time = 25555	action = 0	current_phase = 0	next_phase = 1	reward = 0.451932	array([[ 3.5545297, -9.415327 ]], dtype=float32)
time = 25560	action = 0	current_phase = 0	next_phase = 1	reward = 1.294419	array([[ 3.5462184, -9.403201 ]], dtype=float32)
time = 25565	action = 0	current_phase = 0	next_phase = 1	reward = 0.731100	array([[ 3.5224643, -9.419174 ]], dtype=float32)
time = 25570	action = 0	current_phase = 0	next_phase = 1	reward = 0.717258	array([[ 3.5234914, -9.389201 ]], dtype=float32)
time = 25575	action = 0	current_phase = 0	next_phase = 1	reward = 0.719157	array([[ 3.4766135, -9.429159 ]], dtype=float32)
time = 25580	action = 0	current_phase = 0	next_phase = 1	reward = 0.453302	array([[ 3.509439, -9.416677]], dtype=float32)
time = 25585	action = 0	current_phase = 0	next_phase = 1	reward = 1.015276	array([[ 3.345306 , -9.6486225]], dtype=float32)
time = 25590	action = 0	current_phase = 0	next_phase = 1	reward = 0.721531	array([[ 3.5115724, -9.452553 ]], dtype=float32)
time = 25595	action = 0	current_phase = 0	next_phase = 1	reward = 0.722390	array([[ 3.536796, -9.387815]], dtype=float32)
time = 25600	action = 0	current_phase = 0	next_phase = 1	reward = 0.724047	array([[ 3.5179543, -9.398052 ]], dtype=float32)
time = 25605	action = 0	current_phase = 0	next_phase = 1	reward = 0.446572	array([[ 3.512939, -9.389475]], dtype=float32)
time = 25610	action = 0	current_phase = 0	next_phase = 1	reward = 1.008187	array([[ 3.518724, -9.400808]], dtype=float32)
time = 25615	action = 0	current_phase = 0	next_phase = 1	reward = 0.717944	array([[ 3.5581527, -9.388048 ]], dtype=float32)
time = 25620	action = 0	current_phase = 0	next_phase = 1	reward = 0.444568	array([[ 3.3632197, -9.563644 ]], dtype=float32)
time = 25625	action = 0	current_phase = 0	next_phase = 1	reward = 1.008623	array([[ 3.4809556, -9.45264  ]], dtype=float32)
time = 25630	action = 0	current_phase = 0	next_phase = 1	reward = 0.721713	array([[ 3.5581203, -9.348709 ]], dtype=float32)
time = 25635	action = 0	current_phase = 0	next_phase = 1	reward = 0.441817	array([[ 3.5633454, -9.354759 ]], dtype=float32)
time = 25640	action = 0	current_phase = 0	next_phase = 1	reward = 1.003814	array([[ 3.5134149, -9.422964 ]], dtype=float32)
time = 25645	action = 0	current_phase = 0	next_phase = 1	reward = 0.718329	array([[ 3.5705523, -9.352606 ]], dtype=float32)
time = 25650	action = 0	current_phase = 0	next_phase = 1	reward = 0.717829	array([[ 3.5394301, -9.375799 ]], dtype=float32)
time = 25655	action = 0	current_phase = 0	next_phase = 1	reward = 0.725720	array([[ 3.515101, -9.385761]], dtype=float32)
time = 25660	action = 0	current_phase = 0	next_phase = 1	reward = 0.716774	array([[ 3.5258698, -9.398818 ]], dtype=float32)
time = 25665	action = 0	current_phase = 0	next_phase = 1	reward = 0.717798	array([[ 3.5378518, -9.401827 ]], dtype=float32)
time = 25670	action = 0	current_phase = 0	next_phase = 1	reward = 0.440105	array([[ 3.4553828, -9.480339 ]], dtype=float32)
time = 25675	action = 0	current_phase = 0	next_phase = 1	reward = 0.731337	array([[ 3.4906821, -9.441812 ]], dtype=float32)
time = 25680	action = 0	current_phase = 0	next_phase = 1	reward = 1.010679	array([[ 3.5408902, -9.381583 ]], dtype=float32)
time = 25685	action = 0	current_phase = 0	next_phase = 1	reward = 0.443837	array([[ 3.5322204, -9.424844 ]], dtype=float32)
time = 25690	action = 0	current_phase = 0	next_phase = 1	reward = 1.005892	array([[ 3.5252986, -9.385166 ]], dtype=float32)
time = 25695	action = 0	current_phase = 0	next_phase = 1	reward = 0.724869	array([[ 3.5421462, -9.376876 ]], dtype=float32)
time = 25700	action = 0	current_phase = 0	next_phase = 1	reward = 0.726066	array([[ 3.5385756, -9.396746 ]], dtype=float32)
time = 25705	action = 0	current_phase = 0	next_phase = 1	reward = 0.723796	array([[ 3.5413241, -9.366293 ]], dtype=float32)
time = 25710	action = 0	current_phase = 0	next_phase = 1	reward = 0.720282	array([[ 3.5675693, -9.381964 ]], dtype=float32)
time = 25715	action = 0	current_phase = 0	next_phase = 1	reward = 0.728009	array([[ 3.496879, -9.416599]], dtype=float32)
time = 25720	action = 0	current_phase = 0	next_phase = 1	reward = 0.724011	array([[ 3.4878764, -9.420265 ]], dtype=float32)
time = 25725	action = 0	current_phase = 0	next_phase = 1	reward = 0.444411	array([[ 3.5822358, -9.357679 ]], dtype=float32)
time = 25730	action = 0	current_phase = 0	next_phase = 1	reward = 0.999137	array([[ 3.5147052, -9.399279 ]], dtype=float32)
time = 25735	action = 0	current_phase = 0	next_phase = 1	reward = 0.718054	array([[ 3.5326085, -9.384937 ]], dtype=float32)
time = 25740	action = 0	current_phase = 0	next_phase = 1	reward = 0.455083	array([[ 3.5007644, -9.421634 ]], dtype=float32)
time = 25745	action = 0	current_phase = 0	next_phase = 1	reward = 1.003332	array([[ 3.4973283, -9.4313965]], dtype=float32)
time = 25750	action = 0	current_phase = 0	next_phase = 1	reward = 0.726150	array([[ 3.5879874, -9.352697 ]], dtype=float32)
time = 25755	action = 0	current_phase = 0	next_phase = 1	reward = 0.723362	array([[ 3.5638957, -9.344227 ]], dtype=float32)
time = 25760	action = 0	current_phase = 0	next_phase = 1	reward = 0.730003	array([[ 3.5117211, -9.399178 ]], dtype=float32)
time = 25765	action = 0	current_phase = 0	next_phase = 1	reward = 0.446165	array([[ 3.5313048, -9.4184475]], dtype=float32)
time = 25770	action = 0	current_phase = 0	next_phase = 1	reward = 1.008640	array([[ 3.569981 , -9.3665695]], dtype=float32)
time = 25775	action = 0	current_phase = 0	next_phase = 1	reward = 0.720097	array([[ 3.567038, -9.370116]], dtype=float32)
time = 25780	action = 0	current_phase = 0	next_phase = 1	reward = 0.444256	array([[ 3.5249314, -9.374784 ]], dtype=float32)
time = 25785	action = 0	current_phase = 0	next_phase = 1	reward = 1.001377	array([[ 3.540259, -9.358453]], dtype=float32)
time = 25790	action = 0	current_phase = 0	next_phase = 1	reward = 0.721678	array([[ 3.5564523, -9.388629 ]], dtype=float32)
time = 25795	action = 0	current_phase = 0	next_phase = 1	reward = 0.722455	array([[ 3.4737258, -9.514105 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 5s - loss: 6.6124 - val_loss: 3.0557
Epoch 2/50
 - 5s - loss: 6.2518 - val_loss: 3.3129
Epoch 3/50
 - 5s - loss: 6.1371 - val_loss: 2.9387
Epoch 4/50
 - 4s - loss: 4.4372 - val_loss: 2.9511
Epoch 5/50
 - 5s - loss: 5.1981 - val_loss: 2.9777
Epoch 6/50
 - 5s - loss: 4.8566 - val_loss: 3.0941
Epoch 7/50
 - 4s - loss: 6.6193 - val_loss: 3.3547
Epoch 8/50
 - 5s - loss: 4.7269 - val_loss: 3.0338
Epoch 9/50
 - 6s - loss: 3.8043 - val_loss: 2.9406
Epoch 10/50
 - 5s - loss: 3.7752 - val_loss: 3.0890
Epoch 11/50
 - 5s - loss: 4.5910 - val_loss: 3.2358
Epoch 12/50
 - 4s - loss: 4.5998 - val_loss: 2.7389
Epoch 13/50
 - 4s - loss: 4.5403 - val_loss: 3.3735
Epoch 14/50
 - 4s - loss: 4.2755 - val_loss: 3.1105
Epoch 15/50
 - 4s - loss: 5.1052 - val_loss: 3.4292
Epoch 16/50
 - 4s - loss: 4.8624 - val_loss: 3.3727
Epoch 17/50
 - 4s - loss: 4.6325 - val_loss: 2.9706
Epoch 18/50
 - 4s - loss: 4.6682 - val_loss: 3.0373
Epoch 19/50
 - 4s - loss: 4.9217 - val_loss: 3.0060
Epoch 20/50
 - 4s - loss: 3.3533 - val_loss: 3.0318
Epoch 21/50
 - 4s - loss: 3.3808 - val_loss: 3.2669
Epoch 22/50
 - 4s - loss: 3.6017 - val_loss: 2.8407
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 25800	action = 0	current_phase = 0	next_phase = 1	reward = 0.445048	array([[ 3.5940852, -9.309041 ]], dtype=float32)
time = 25805	action = 0	current_phase = 0	next_phase = 1	reward = 1.007966	array([[ 3.5470996, -9.378336 ]], dtype=float32)
time = 25810	action = 0	current_phase = 0	next_phase = 1	reward = 0.723542	array([[ 3.5801568, -9.324582 ]], dtype=float32)
time = 25815	action = 0	current_phase = 0	next_phase = 1	reward = 0.731171	array([[ 3.5144267, -9.36691  ]], dtype=float32)
time = 25820	action = 0	current_phase = 0	next_phase = 1	reward = 0.727808	array([[ 3.5226817, -9.401043 ]], dtype=float32)
time = 25825	action = 0	current_phase = 0	next_phase = 1	reward = 0.715748	array([[ 3.558   , -9.364553]], dtype=float32)
time = 25830	action = 0	current_phase = 0	next_phase = 1	reward = 0.433966	array([[ 3.6040654, -9.330917 ]], dtype=float32)
time = 25835	action = 0	current_phase = 0	next_phase = 1	reward = 1.000802	array([[ 3.5823731, -9.300013 ]], dtype=float32)
time = 25840	action = 0	current_phase = 0	next_phase = 1	reward = 0.438255	array([[ 3.5434651, -9.361952 ]], dtype=float32)
time = 25845	action = 0	current_phase = 0	next_phase = 1	reward = 0.995250	array([[ 3.5378737, -9.372308 ]], dtype=float32)
time = 25850	action = 0	current_phase = 0	next_phase = 1	reward = 0.164529	array([[ 3.4048324, -9.412361 ]], dtype=float32)
time = 25855	action = 0	current_phase = 0	next_phase = 1	reward = 1.281160	array([[ 3.3984056, -9.461771 ]], dtype=float32)
time = 25860	action = 0	current_phase = 0	next_phase = 1	reward = 0.156331	array([[ 3.502067, -9.392019]], dtype=float32)
time = 25865	action = 0	current_phase = 0	next_phase = 1	reward = 0.730643	array([[ 3.520331, -9.406411]], dtype=float32)
time = 25870	action = 0	current_phase = 0	next_phase = 1	reward = 1.292882	array([[ 3.3744998, -9.634065 ]], dtype=float32)
time = 25875	action = 0	current_phase = 0	next_phase = 1	reward = 0.438247	array([[ 3.5344348, -9.367901 ]], dtype=float32)
time = 25880	action = 0	current_phase = 0	next_phase = 1	reward = 1.005596	array([[ 3.51971 , -9.359216]], dtype=float32)
time = 25885	action = 0	current_phase = 0	next_phase = 1	reward = 0.732000	array([[ 3.478353, -9.455398]], dtype=float32)
time = 25890	action = 0	current_phase = 0	next_phase = 1	reward = 0.731661	array([[ 3.537476, -9.385796]], dtype=float32)
time = 25895	action = 0	current_phase = 0	next_phase = 1	reward = 0.732759	array([[ 3.5405478, -9.357288 ]], dtype=float32)
time = 25900	action = 0	current_phase = 0	next_phase = 1	reward = 0.727414	array([[ 3.5460687, -9.334045 ]], dtype=float32)
time = 25905	action = 0	current_phase = 0	next_phase = 1	reward = 0.723742	array([[ 3.5192113, -9.392565 ]], dtype=float32)
time = 25910	action = 0	current_phase = 0	next_phase = 1	reward = 0.711998	array([[ 3.538319, -9.360615]], dtype=float32)
time = 25915	action = 0	current_phase = 0	next_phase = 1	reward = 0.724387	array([[ 3.529489, -9.365398]], dtype=float32)
time = 25920	action = 0	current_phase = 0	next_phase = 1	reward = 0.444753	array([[ 3.6043773, -9.288898 ]], dtype=float32)
time = 25925	action = 0	current_phase = 0	next_phase = 1	reward = 1.010601	array([[ 3.5339732, -9.3694935]], dtype=float32)
time = 25930	action = 0	current_phase = 0	next_phase = 1	reward = 0.437934	array([[ 3.5066943, -9.386936 ]], dtype=float32)
time = 25935	action = 0	current_phase = 0	next_phase = 1	reward = 0.999782	array([[ 3.5445075, -9.33592  ]], dtype=float32)
time = 25940	action = 0	current_phase = 0	next_phase = 1	reward = 0.442783	array([[ 3.5783906, -9.303728 ]], dtype=float32)
time = 25945	action = 0	current_phase = 0	next_phase = 1	reward = 0.724598	array([[ 3.5171552, -9.378742 ]], dtype=float32)
time = 25950	action = 0	current_phase = 0	next_phase = 1	reward = 0.724566	array([[ 3.5573115, -9.374438 ]], dtype=float32)
time = 25955	action = 0	current_phase = 0	next_phase = 1	reward = 1.006486	array([[ 3.5476108, -9.332764 ]], dtype=float32)
time = 25960	action = 0	current_phase = 0	next_phase = 1	reward = 0.439095	array([[ 3.5312123, -9.385473 ]], dtype=float32)
time = 25965	action = 0	current_phase = 0	next_phase = 1	reward = 0.727480	array([[ 3.5851274, -9.285233 ]], dtype=float32)
time = 25970	action = 0	current_phase = 0	next_phase = 1	reward = 1.004282	array([[ 3.478991, -9.412098]], dtype=float32)
time = 25975	action = 0	current_phase = 0	next_phase = 1	reward = 0.718375	array([[ 3.4480815, -9.446771 ]], dtype=float32)
time = 25980	action = 0	current_phase = 0	next_phase = 1	reward = 0.442530	array([[ 3.4779992, -9.417841 ]], dtype=float32)
time = 25985	action = 0	current_phase = 0	next_phase = 1	reward = 0.724725	array([[ 3.530208, -9.347975]], dtype=float32)
time = 25990	action = 0	current_phase = 0	next_phase = 1	reward = 0.726456	array([[ 3.3178592, -9.717014 ]], dtype=float32)
time = 25995	action = 0	current_phase = 0	next_phase = 1	reward = 1.008263	array([[ 3.5453782, -9.3256855]], dtype=float32)
time = 26000	action = 0	current_phase = 0	next_phase = 1	reward = 0.732353	array([[ 3.5620208, -9.338814 ]], dtype=float32)
time = 26005	action = 0	current_phase = 0	next_phase = 1	reward = 0.723270	array([[ 3.5263686, -9.362406 ]], dtype=float32)
time = 26010	action = 0	current_phase = 0	next_phase = 1	reward = 0.437026	array([[ 3.4784503, -9.438424 ]], dtype=float32)
time = 26015	action = 0	current_phase = 0	next_phase = 1	reward = 1.001595	array([[ 3.5669036, -9.33629  ]], dtype=float32)
time = 26020	action = 0	current_phase = 0	next_phase = 1	reward = 0.730955	array([[ 3.5592637, -9.320715 ]], dtype=float32)
time = 26025	action = 0	current_phase = 0	next_phase = 1	reward = 0.448266	array([[ 3.5379386, -9.337181 ]], dtype=float32)
time = 26030	action = 0	current_phase = 0	next_phase = 1	reward = 1.001570	array([[ 3.460012, -9.458618]], dtype=float32)
time = 26035	action = 0	current_phase = 0	next_phase = 1	reward = 0.715585	array([[ 3.4713578, -9.405699 ]], dtype=float32)
time = 26040	action = 0	current_phase = 0	next_phase = 1	reward = 0.724095	array([[ 3.5323434, -9.337632 ]], dtype=float32)
time = 26045	action = 0	current_phase = 0	next_phase = 1	reward = 0.445218	array([[ 3.5063539, -9.394489 ]], dtype=float32)
time = 26050	action = 0	current_phase = 0	next_phase = 1	reward = 0.730567	array([[ 3.4795232, -9.4783535]], dtype=float32)
time = 26055	action = 0	current_phase = 0	next_phase = 1	reward = 1.020233	array([[ 3.4798017, -9.4424095]], dtype=float32)
time = 26060	action = 0	current_phase = 0	next_phase = 1	reward = 0.722389	array([[ 3.5881076, -9.332108 ]], dtype=float32)
time = 26065	action = 0	current_phase = 0	next_phase = 1	reward = 0.447880	array([[ 3.545611, -9.323838]], dtype=float32)
time = 26070	action = 0	current_phase = 0	next_phase = 1	reward = 1.008002	array([[ 3.494944, -9.416874]], dtype=float32)
time = 26075	action = 0	current_phase = 0	next_phase = 1	reward = 0.722828	array([[ 3.5877576, -9.301764 ]], dtype=float32)
time = 26080	action = 0	current_phase = 0	next_phase = 1	reward = 0.714571	array([[ 3.5370421, -9.374001 ]], dtype=float32)
time = 26085	action = 0	current_phase = 0	next_phase = 1	reward = 0.726307	array([[ 3.5608764, -9.346792 ]], dtype=float32)
time = 26090	action = 0	current_phase = 0	next_phase = 1	reward = 0.450751	array([[ 3.606935, -9.314767]], dtype=float32)
time = 26095	action = 0	current_phase = 0	next_phase = 1	reward = 1.000674	array([[ 3.5077338, -9.3846   ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.7898 - val_loss: 2.0698
Epoch 2/50
 - 4s - loss: 3.7392 - val_loss: 2.8331
Epoch 3/50
 - 4s - loss: 3.8900 - val_loss: 2.4180
Epoch 4/50
 - 4s - loss: 4.5469 - val_loss: 2.5363
Epoch 5/50
 - 4s - loss: 3.0355 - val_loss: 3.3064
Epoch 6/50
 - 4s - loss: 3.3564 - val_loss: 2.1137
Epoch 7/50
 - 4s - loss: 5.1033 - val_loss: 2.1000
Epoch 8/50
 - 4s - loss: 4.1234 - val_loss: 3.1091
Epoch 9/50
 - 4s - loss: 2.8676 - val_loss: 2.4961
Epoch 10/50
 - 4s - loss: 4.1315 - val_loss: 3.1036
Epoch 11/50
 - 4s - loss: 3.8669 - val_loss: 3.2846
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 26100	action = 0	current_phase = 0	next_phase = 1	reward = 0.716759	array([[ 3.5841436, -9.379069 ]], dtype=float32)
time = 26105	action = 0	current_phase = 0	next_phase = 1	reward = 0.440829	array([[ 3.5595207, -9.40287  ]], dtype=float32)
time = 26110	action = 0	current_phase = 0	next_phase = 1	reward = 1.009020	array([[ 3.611578, -9.363616]], dtype=float32)
time = 26115	action = 0	current_phase = 0	next_phase = 1	reward = 0.722340	array([[ 3.6013546, -9.358357 ]], dtype=float32)
time = 26120	action = 0	current_phase = 0	next_phase = 1	reward = 0.437431	array([[ 3.5694475, -9.366862 ]], dtype=float32)
time = 26125	action = 0	current_phase = 0	next_phase = 1	reward = 0.999894	array([[ 3.6046944, -9.369884 ]], dtype=float32)
time = 26130	action = 0	current_phase = 0	next_phase = 1	reward = 0.724109	array([[ 3.6081676, -9.327419 ]], dtype=float32)
time = 26135	action = 0	current_phase = 0	next_phase = 1	reward = 0.719099	array([[ 3.593624, -9.392462]], dtype=float32)
time = 26140	action = 0	current_phase = 0	next_phase = 1	reward = 0.727218	array([[ 3.6188269, -9.3378315]], dtype=float32)
time = 26145	action = 0	current_phase = 0	next_phase = 1	reward = 0.731059	array([[ 3.5986872, -9.357171 ]], dtype=float32)
time = 26150	action = 0	current_phase = 0	next_phase = 1	reward = 0.719685	array([[ 3.6088686, -9.328836 ]], dtype=float32)
time = 26155	action = 0	current_phase = 0	next_phase = 1	reward = 0.440902	array([[ 3.5800095, -9.40595  ]], dtype=float32)
time = 26160	action = 0	current_phase = 0	next_phase = 1	reward = 0.996268	array([[ 3.5715313, -9.375821 ]], dtype=float32)
time = 26165	action = 0	current_phase = 0	next_phase = 1	reward = 0.715041	array([[ 3.5863667, -9.356794 ]], dtype=float32)
time = 26170	action = 0	current_phase = 0	next_phase = 1	reward = 0.723458	array([[ 3.5147848, -9.427611 ]], dtype=float32)
time = 26175	action = 0	current_phase = 0	next_phase = 1	reward = 0.440231	array([[ 3.6230507, -9.359814 ]], dtype=float32)
time = 26180	action = 0	current_phase = 0	next_phase = 1	reward = 1.003563	array([[ 3.5926352, -9.396807 ]], dtype=float32)
time = 26185	action = 0	current_phase = 0	next_phase = 1	reward = 0.439680	array([[ 3.6178617, -9.371536 ]], dtype=float32)
time = 26190	action = 0	current_phase = 0	next_phase = 1	reward = 1.000117	array([[ 3.5726242, -9.398842 ]], dtype=float32)
time = 26195	action = 0	current_phase = 0	next_phase = 1	reward = 0.443352	array([[ 3.603322, -9.345947]], dtype=float32)
time = 26200	action = 0	current_phase = 0	next_phase = 1	reward = 1.009492	array([[ 3.56137, -9.41276]], dtype=float32)
time = 26205	action = 0	current_phase = 0	next_phase = 1	reward = 0.718303	array([[ 3.6034622, -9.34144  ]], dtype=float32)
time = 26210	action = 0	current_phase = 0	next_phase = 1	reward = 0.718037	array([[ 3.5629597, -9.405827 ]], dtype=float32)
time = 26215	action = 0	current_phase = 0	next_phase = 1	reward = 0.723310	array([[ 3.5491667, -9.421602 ]], dtype=float32)
time = 26220	action = 0	current_phase = 0	next_phase = 1	reward = 0.716751	array([[ 3.595749, -9.390952]], dtype=float32)
time = 26225	action = 0	current_phase = 0	next_phase = 1	reward = 0.716237	array([[ 3.558591, -9.404278]], dtype=float32)
time = 26230	action = 0	current_phase = 0	next_phase = 1	reward = 0.721350	array([[ 3.52526, -9.41831]], dtype=float32)
time = 26235	action = 0	current_phase = 0	next_phase = 1	reward = 0.451437	array([[ 3.4602242, -9.473541 ]], dtype=float32)
time = 26240	action = 0	current_phase = 0	next_phase = 1	reward = 1.005863	array([[ 3.5476437, -9.443231 ]], dtype=float32)
time = 26245	action = 0	current_phase = 0	next_phase = 1	reward = 0.726903	array([[ 3.5423164, -9.435726 ]], dtype=float32)
time = 26250	action = 0	current_phase = 0	next_phase = 1	reward = 0.720024	array([[ 3.619501, -9.361221]], dtype=float32)
time = 26255	action = 0	current_phase = 0	next_phase = 1	reward = 0.725582	array([[ 3.5935488, -9.341064 ]], dtype=float32)
time = 26260	action = 0	current_phase = 0	next_phase = 1	reward = 0.714767	array([[ 3.6117506, -9.350702 ]], dtype=float32)
time = 26265	action = 0	current_phase = 0	next_phase = 1	reward = 0.717358	array([[ 3.5744143, -9.352814 ]], dtype=float32)
time = 26270	action = 0	current_phase = 0	next_phase = 1	reward = 0.718015	array([[ 3.5807877, -9.379671 ]], dtype=float32)
time = 26275	action = 0	current_phase = 0	next_phase = 1	reward = 0.710926	array([[ 3.492237, -9.416927]], dtype=float32)
time = 26280	action = 0	current_phase = 0	next_phase = 1	reward = 0.725997	array([[ 3.584032, -9.362888]], dtype=float32)
time = 26285	action = 0	current_phase = 0	next_phase = 1	reward = 0.171310	array([[ 3.5583448, -9.399424 ]], dtype=float32)
time = 26290	action = 0	current_phase = 0	next_phase = 1	reward = 1.299382	array([[ 3.5093718, -9.42404  ]], dtype=float32)
time = 26295	action = 0	current_phase = 0	next_phase = 1	reward = 0.735251	array([[ 3.6332216, -9.322809 ]], dtype=float32)
time = 26300	action = 0	current_phase = 0	next_phase = 1	reward = 0.724166	array([[ 3.5775871, -9.379528 ]], dtype=float32)
time = 26305	action = 0	current_phase = 0	next_phase = 1	reward = 0.723897	array([[ 3.6172733, -9.34918  ]], dtype=float32)
time = 26310	action = 0	current_phase = 0	next_phase = 1	reward = 0.731423	array([[ 3.5654116, -9.364143 ]], dtype=float32)
time = 26315	action = 0	current_phase = 0	next_phase = 1	reward = 0.722798	array([[ 3.5799637, -9.345732 ]], dtype=float32)
time = 26320	action = 0	current_phase = 0	next_phase = 1	reward = 0.716023	array([[ 3.6278334, -9.326473 ]], dtype=float32)
time = 26325	action = 0	current_phase = 0	next_phase = 1	reward = 0.714388	array([[ 3.5747948, -9.371281 ]], dtype=float32)
time = 26330	action = 0	current_phase = 0	next_phase = 1	reward = 0.711770	array([[ 3.564989, -9.420812]], dtype=float32)
time = 26335	action = 0	current_phase = 0	next_phase = 1	reward = 0.441857	array([[ 3.5518084, -9.386327 ]], dtype=float32)
time = 26340	action = 0	current_phase = 0	next_phase = 1	reward = 0.722361	array([[ 3.6126719, -9.351563 ]], dtype=float32)
time = 26345	action = 0	current_phase = 0	next_phase = 1	reward = 1.008874	array([[ 3.51651 , -9.433292]], dtype=float32)
time = 26350	action = 0	current_phase = 0	next_phase = 1	reward = 0.719341	array([[ 3.5197544, -9.442884 ]], dtype=float32)
time = 26355	action = 0	current_phase = 0	next_phase = 1	reward = 0.716879	array([[ 3.628726, -9.344471]], dtype=float32)
time = 26360	action = 0	current_phase = 0	next_phase = 1	reward = 0.716985	array([[ 3.531313, -9.422363]], dtype=float32)
time = 26365	action = 0	current_phase = 0	next_phase = 1	reward = 0.440973	array([[ 3.5112019, -9.471689 ]], dtype=float32)
time = 26370	action = 0	current_phase = 0	next_phase = 1	reward = 0.729994	array([[ 3.5569534, -9.410585 ]], dtype=float32)
time = 26375	action = 0	current_phase = 0	next_phase = 1	reward = 0.733115	array([[ 3.597621, -9.416969]], dtype=float32)
time = 26380	action = 0	current_phase = 0	next_phase = 1	reward = 1.011905	array([[ 3.591692, -9.376103]], dtype=float32)
time = 26385	action = 0	current_phase = 0	next_phase = 1	reward = 0.720022	array([[ 3.569231, -9.360374]], dtype=float32)
time = 26390	action = 0	current_phase = 0	next_phase = 1	reward = 0.443175	array([[ 3.5786228, -9.377581 ]], dtype=float32)
time = 26395	action = 0	current_phase = 0	next_phase = 1	reward = 1.001552	array([[ 3.5637617, -9.402397 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.1750 - val_loss: 3.2784
Epoch 2/50
 - 4s - loss: 5.7907 - val_loss: 2.7945
Epoch 3/50
 - 4s - loss: 3.5043 - val_loss: 2.6405
Epoch 4/50
 - 4s - loss: 4.5599 - val_loss: 3.0026
Epoch 5/50
 - 4s - loss: 4.5337 - val_loss: 2.9611
Epoch 6/50
 - 4s - loss: 4.0368 - val_loss: 3.6526
Epoch 7/50
 - 4s - loss: 3.6256 - val_loss: 2.7199
Epoch 8/50
 - 4s - loss: 4.3867 - val_loss: 3.0246
Epoch 9/50
 - 4s - loss: 4.8034 - val_loss: 2.5334
Epoch 10/50
 - 4s - loss: 5.7087 - val_loss: 2.7334
Epoch 11/50
 - 4s - loss: 3.9499 - val_loss: 2.9946
Epoch 12/50
 - 4s - loss: 4.3113 - val_loss: 2.6491
Epoch 13/50
 - 4s - loss: 4.3684 - val_loss: 3.1587
Epoch 14/50
 - 4s - loss: 4.3078 - val_loss: 2.6560
Epoch 15/50
 - 4s - loss: 3.1025 - val_loss: 2.7725
Epoch 16/50
 - 4s - loss: 3.7513 - val_loss: 2.5488
Epoch 17/50
 - 4s - loss: 5.6012 - val_loss: 2.5927
Epoch 18/50
 - 4s - loss: 5.6456 - val_loss: 2.9939
Epoch 19/50
 - 4s - loss: 4.8036 - val_loss: 2.3089
Epoch 20/50
 - 4s - loss: 4.2818 - val_loss: 2.9816
Epoch 21/50
 - 4s - loss: 4.5186 - val_loss: 4.2876
Epoch 22/50
 - 4s - loss: 2.6813 - val_loss: 2.7577
Epoch 23/50
 - 4s - loss: 3.9312 - val_loss: 3.2128
Epoch 24/50
 - 4s - loss: 5.4335 - val_loss: 3.4179
Epoch 25/50
 - 4s - loss: 5.0856 - val_loss: 2.5207
Epoch 26/50
 - 4s - loss: 2.6572 - val_loss: 3.2120
Epoch 27/50
 - 4s - loss: 3.4975 - val_loss: 2.4076
Epoch 28/50
 - 4s - loss: 4.2591 - val_loss: 2.5736
Epoch 29/50
 - 4s - loss: 6.2359 - val_loss: 2.9856
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 26400	action = 0	current_phase = 0	next_phase = 1	reward = 0.443928	array([[ 3.6075406, -9.285637 ]], dtype=float32)
time = 26405	action = 0	current_phase = 0	next_phase = 1	reward = 1.003149	array([[ 3.5523486, -9.377474 ]], dtype=float32)
time = 26410	action = 0	current_phase = 0	next_phase = 1	reward = 0.715624	array([[ 3.496037, -9.318937]], dtype=float32)
time = 26415	action = 0	current_phase = 0	next_phase = 1	reward = 0.433797	array([[ 3.5023026, -9.402763 ]], dtype=float32)
time = 26420	action = 0	current_phase = 0	next_phase = 1	reward = 0.721639	array([[ 3.5629392, -9.337948 ]], dtype=float32)
time = 26425	action = 0	current_phase = 0	next_phase = 1	reward = 0.731781	array([[ 3.5496488, -9.352882 ]], dtype=float32)
time = 26430	action = 0	current_phase = 0	next_phase = 1	reward = 1.006457	array([[ 3.5477862, -9.290115 ]], dtype=float32)
time = 26435	action = 0	current_phase = 0	next_phase = 1	reward = 0.444345	array([[ 3.5811734, -9.280469 ]], dtype=float32)
time = 26440	action = 0	current_phase = 0	next_phase = 1	reward = 1.006843	array([[ 3.5523248, -9.332776 ]], dtype=float32)
time = 26445	action = 0	current_phase = 0	next_phase = 1	reward = 0.442711	array([[ 3.585732, -9.296504]], dtype=float32)
time = 26450	action = 0	current_phase = 0	next_phase = 1	reward = 1.006005	array([[ 3.5690637, -9.332469 ]], dtype=float32)
time = 26455	action = 0	current_phase = 0	next_phase = 1	reward = 0.722197	array([[ 3.5569701, -9.296215 ]], dtype=float32)
time = 26460	action = 0	current_phase = 0	next_phase = 1	reward = 0.720954	array([[ 3.60457, -9.31418]], dtype=float32)
time = 26465	action = 0	current_phase = 0	next_phase = 1	reward = 0.719723	array([[ 3.5586028, -9.347424 ]], dtype=float32)
time = 26470	action = 0	current_phase = 0	next_phase = 1	reward = 0.720533	array([[ 3.555265, -9.332245]], dtype=float32)
time = 26475	action = 0	current_phase = 0	next_phase = 1	reward = 0.722240	array([[ 3.5525146, -9.379666 ]], dtype=float32)
time = 26480	action = 0	current_phase = 0	next_phase = 1	reward = 0.723830	array([[ 3.5168395, -9.400829 ]], dtype=float32)
time = 26485	action = 0	current_phase = 0	next_phase = 1	reward = 0.446397	array([[ 3.5425754, -9.341438 ]], dtype=float32)
time = 26490	action = 0	current_phase = 0	next_phase = 1	reward = 1.003221	array([[ 3.5813537, -9.3412   ]], dtype=float32)
time = 26495	action = 0	current_phase = 0	next_phase = 1	reward = 0.438899	array([[ 3.5927873, -9.287854 ]], dtype=float32)
time = 26500	action = 0	current_phase = 0	next_phase = 1	reward = 1.000406	array([[ 3.5137744, -9.324444 ]], dtype=float32)
time = 26505	action = 0	current_phase = 0	next_phase = 1	reward = 0.714548	array([[ 3.5006766, -9.339638 ]], dtype=float32)
time = 26510	action = 0	current_phase = 0	next_phase = 1	reward = 0.440156	array([[ 3.572372, -9.323952]], dtype=float32)
time = 26515	action = 0	current_phase = 0	next_phase = 1	reward = 0.732583	array([[ 3.5136504, -9.494421 ]], dtype=float32)
time = 26520	action = 0	current_phase = 0	next_phase = 1	reward = 1.003254	array([[ 3.4797568, -9.366812 ]], dtype=float32)
time = 26525	action = 0	current_phase = 0	next_phase = 1	reward = 0.724711	array([[ 3.5517993, -9.357195 ]], dtype=float32)
time = 26530	action = 0	current_phase = 0	next_phase = 1	reward = 0.719672	array([[ 3.556765, -9.332905]], dtype=float32)
time = 26535	action = 0	current_phase = 0	next_phase = 1	reward = 0.724132	array([[ 3.5541043, -9.293322 ]], dtype=float32)
time = 26540	action = 0	current_phase = 0	next_phase = 1	reward = 0.723450	array([[ 3.52348 , -9.387346]], dtype=float32)
time = 26545	action = 0	current_phase = 0	next_phase = 1	reward = 0.728003	array([[ 3.5401778, -9.347412 ]], dtype=float32)
time = 26550	action = 0	current_phase = 0	next_phase = 1	reward = 0.723433	array([[ 3.5609565, -9.324579 ]], dtype=float32)
time = 26555	action = 0	current_phase = 0	next_phase = 1	reward = 0.721179	array([[ 3.5866656, -9.332047 ]], dtype=float32)
time = 26560	action = 0	current_phase = 0	next_phase = 1	reward = 0.719998	array([[ 3.6055646, -9.311471 ]], dtype=float32)
time = 26565	action = 0	current_phase = 0	next_phase = 1	reward = 0.715503	array([[ 3.5272603, -9.31147  ]], dtype=float32)
time = 26570	action = 0	current_phase = 0	next_phase = 1	reward = 0.442224	array([[ 3.4761176, -9.427984 ]], dtype=float32)
time = 26575	action = 0	current_phase = 0	next_phase = 1	reward = 0.730154	array([[ 3.5731177, -9.31361  ]], dtype=float32)
time = 26580	action = 0	current_phase = 0	next_phase = 1	reward = 0.725464	array([[ 3.477962, -9.456491]], dtype=float32)
time = 26585	action = 0	current_phase = 0	next_phase = 1	reward = 1.005328	array([[ 3.545116, -9.3354  ]], dtype=float32)
time = 26590	action = 0	current_phase = 0	next_phase = 1	reward = 0.731371	array([[ 3.5404925, -9.32712  ]], dtype=float32)
time = 26595	action = 0	current_phase = 0	next_phase = 1	reward = 0.722032	array([[ 3.5176253, -9.34539  ]], dtype=float32)
time = 26600	action = 0	current_phase = 0	next_phase = 1	reward = 0.725770	array([[ 3.497705, -9.404938]], dtype=float32)
time = 26605	action = 0	current_phase = 0	next_phase = 1	reward = 0.726669	array([[ 3.581615, -9.330814]], dtype=float32)
time = 26610	action = 0	current_phase = 0	next_phase = 1	reward = 0.726611	array([[ 3.5483203, -9.287109 ]], dtype=float32)
time = 26615	action = 0	current_phase = 0	next_phase = 1	reward = 0.723545	array([[ 3.5002532, -9.395063 ]], dtype=float32)
time = 26620	action = 0	current_phase = 0	next_phase = 1	reward = 0.724059	array([[ 3.5442185, -9.379645 ]], dtype=float32)
time = 26625	action = 0	current_phase = 0	next_phase = 1	reward = 0.724387	array([[ 3.5054488, -9.3881035]], dtype=float32)
time = 26630	action = 0	current_phase = 0	next_phase = 1	reward = 0.722960	array([[ 3.5818992, -9.306316 ]], dtype=float32)
time = 26635	action = 0	current_phase = 0	next_phase = 1	reward = 0.721211	array([[ 3.6032157, -9.275625 ]], dtype=float32)
time = 26640	action = 0	current_phase = 0	next_phase = 1	reward = 0.715984	array([[ 3.5541425, -9.369824 ]], dtype=float32)
time = 26645	action = 0	current_phase = 0	next_phase = 1	reward = 0.437247	array([[ 3.580192, -9.278296]], dtype=float32)
time = 26650	action = 0	current_phase = 0	next_phase = 1	reward = 0.446537	array([[ 3.5142074, -9.374725 ]], dtype=float32)
time = 26655	action = 0	current_phase = 0	next_phase = 1	reward = 1.296439	array([[ 3.5834966, -9.3323555]], dtype=float32)
time = 26660	action = 0	current_phase = 0	next_phase = 1	reward = 0.727818	array([[ 3.6143003, -9.334114 ]], dtype=float32)
time = 26665	action = 0	current_phase = 0	next_phase = 1	reward = 0.725197	array([[ 3.5374026, -9.313606 ]], dtype=float32)
time = 26670	action = 0	current_phase = 0	next_phase = 1	reward = 0.728696	array([[ 3.4838262, -9.455739 ]], dtype=float32)
time = 26675	action = 0	current_phase = 0	next_phase = 1	reward = 0.715851	array([[ 3.5522408, -9.344123 ]], dtype=float32)
time = 26680	action = 0	current_phase = 0	next_phase = 1	reward = 0.718290	array([[ 3.5221496, -9.339245 ]], dtype=float32)
time = 26685	action = 0	current_phase = 0	next_phase = 1	reward = 0.721561	array([[ 3.543944, -9.298883]], dtype=float32)
time = 26690	action = 0	current_phase = 0	next_phase = 1	reward = 0.722238	array([[ 3.5804486, -9.353191 ]], dtype=float32)
time = 26695	action = 0	current_phase = 0	next_phase = 1	reward = 0.446788	array([[ 3.60012, -9.26567]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.0301 - val_loss: 2.0536
Epoch 2/50
 - 4s - loss: 3.1955 - val_loss: 1.7767
Epoch 3/50
 - 4s - loss: 5.7162 - val_loss: 2.1147
Epoch 4/50
 - 4s - loss: 4.3222 - val_loss: 2.5298
Epoch 5/50
 - 4s - loss: 4.4808 - val_loss: 2.5731
Epoch 6/50
 - 4s - loss: 4.7351 - val_loss: 2.3032
Epoch 7/50
 - 4s - loss: 3.1265 - val_loss: 1.8560
Epoch 8/50
 - 4s - loss: 4.2715 - val_loss: 2.2080
Epoch 9/50
 - 4s - loss: 3.3286 - val_loss: 1.7623
Epoch 10/50
 - 4s - loss: 4.6242 - val_loss: 2.0337
Epoch 11/50
 - 4s - loss: 4.1938 - val_loss: 1.9767
Epoch 12/50
 - 4s - loss: 4.3342 - val_loss: 1.9732
Epoch 13/50
 - 4s - loss: 3.1336 - val_loss: 1.4199
Epoch 14/50
 - 4s - loss: 4.7135 - val_loss: 2.0184
Epoch 15/50
 - 4s - loss: 4.7253 - val_loss: 1.9755
Epoch 16/50
 - 4s - loss: 4.1756 - val_loss: 2.4157
Epoch 17/50
 - 4s - loss: 3.5488 - val_loss: 2.1769
Epoch 18/50
 - 4s - loss: 3.1637 - val_loss: 3.2756
Epoch 19/50
 - 4s - loss: 4.0883 - val_loss: 1.8151
Epoch 20/50
 - 4s - loss: 3.0400 - val_loss: 2.8433
Epoch 21/50
 - 4s - loss: 3.9303 - val_loss: 1.3767
Epoch 22/50
 - 4s - loss: 4.8219 - val_loss: 2.1955
Epoch 23/50
 - 4s - loss: 2.8531 - val_loss: 2.2012
Epoch 24/50
 - 4s - loss: 3.5603 - val_loss: 1.9657
Epoch 25/50
 - 4s - loss: 4.1343 - val_loss: 1.9725
Epoch 26/50
 - 4s - loss: 4.1856 - val_loss: 1.5343
Epoch 27/50
 - 4s - loss: 4.3707 - val_loss: 1.7117
Epoch 28/50
 - 4s - loss: 3.3403 - val_loss: 2.1201
Epoch 29/50
 - 4s - loss: 3.9739 - val_loss: 2.0209
Epoch 30/50
 - 4s - loss: 3.5728 - val_loss: 2.4693
Epoch 31/50
 - 4s - loss: 4.1209 - val_loss: 2.2165
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 26700	action = 0	current_phase = 0	next_phase = 1	reward = 1.007359	array([[ 3.514658, -9.347584]], dtype=float32)
time = 26705	action = 0	current_phase = 0	next_phase = 1	reward = 0.722189	array([[ 3.463665, -9.366526]], dtype=float32)
time = 26710	action = 0	current_phase = 0	next_phase = 1	reward = 0.720735	array([[ 3.53514 , -9.314983]], dtype=float32)
time = 26715	action = 0	current_phase = 0	next_phase = 1	reward = 0.721857	array([[ 3.5090294, -9.342117 ]], dtype=float32)
time = 26720	action = 0	current_phase = 0	next_phase = 1	reward = 0.721627	array([[ 3.4756374, -9.470838 ]], dtype=float32)
time = 26725	action = 0	current_phase = 0	next_phase = 1	reward = 0.734917	array([[ 3.5080786, -9.352995 ]], dtype=float32)
time = 26730	action = 0	current_phase = 0	next_phase = 1	reward = 0.724262	array([[ 3.5127106, -9.360895 ]], dtype=float32)
time = 26735	action = 0	current_phase = 0	next_phase = 1	reward = 0.721076	array([[ 3.5199976, -9.327906 ]], dtype=float32)
time = 26740	action = 0	current_phase = 0	next_phase = 1	reward = 0.443176	array([[ 3.5240622, -9.275984 ]], dtype=float32)
time = 26745	action = 0	current_phase = 0	next_phase = 1	reward = 1.007145	array([[ 3.4907408, -9.398798 ]], dtype=float32)
time = 26750	action = 0	current_phase = 0	next_phase = 1	reward = 0.720978	array([[ 3.4859285, -9.313394 ]], dtype=float32)
time = 26755	action = 0	current_phase = 0	next_phase = 1	reward = 0.166895	array([[ 3.5650997, -9.3231735]], dtype=float32)
time = 26760	action = 0	current_phase = 0	next_phase = 1	reward = 1.287126	array([[ 3.5270567, -9.346956 ]], dtype=float32)
time = 26765	action = 0	current_phase = 0	next_phase = 1	reward = 0.716905	array([[ 3.4124498, -9.408513 ]], dtype=float32)
time = 26770	action = 0	current_phase = 0	next_phase = 1	reward = 0.722083	array([[ 3.5527792, -9.33     ]], dtype=float32)
time = 26775	action = 0	current_phase = 0	next_phase = 1	reward = 0.730423	array([[ 3.5429354, -9.349955 ]], dtype=float32)
time = 26780	action = 0	current_phase = 0	next_phase = 1	reward = 0.445625	array([[ 3.4990091, -9.381065 ]], dtype=float32)
time = 26785	action = 0	current_phase = 0	next_phase = 1	reward = 1.008255	array([[ 3.492959, -9.375555]], dtype=float32)
time = 26790	action = 0	current_phase = 0	next_phase = 1	reward = 0.717689	array([[ 3.5254107, -9.306265 ]], dtype=float32)
time = 26795	action = 0	current_phase = 0	next_phase = 1	reward = 0.721051	array([[ 3.5010443, -9.277662 ]], dtype=float32)
time = 26800	action = 0	current_phase = 0	next_phase = 1	reward = 0.447418	array([[ 3.4906282, -9.393435 ]], dtype=float32)
time = 26805	action = 0	current_phase = 0	next_phase = 1	reward = 0.999962	array([[ 3.5589771, -9.332559 ]], dtype=float32)
time = 26810	action = 0	current_phase = 0	next_phase = 1	reward = 0.727358	array([[ 3.548952, -9.316792]], dtype=float32)
time = 26815	action = 0	current_phase = 0	next_phase = 1	reward = 0.733143	array([[ 3.5332365, -9.328604 ]], dtype=float32)
time = 26820	action = 0	current_phase = 0	next_phase = 1	reward = 0.720905	array([[ 3.4482899, -9.403641 ]], dtype=float32)
time = 26825	action = 0	current_phase = 0	next_phase = 1	reward = 0.713603	array([[ 3.555603, -9.306736]], dtype=float32)
time = 26830	action = 0	current_phase = 0	next_phase = 1	reward = 0.718523	array([[ 3.5405664, -9.329651 ]], dtype=float32)
time = 26835	action = 0	current_phase = 0	next_phase = 1	reward = 0.443725	array([[ 3.5223637, -9.337425 ]], dtype=float32)
time = 26840	action = 0	current_phase = 0	next_phase = 1	reward = 1.007257	array([[ 3.4575644, -9.326548 ]], dtype=float32)
time = 26845	action = 0	current_phase = 0	next_phase = 1	reward = 0.443805	array([[ 3.5186186, -9.375872 ]], dtype=float32)
time = 26850	action = 0	current_phase = 0	next_phase = 1	reward = 1.012146	array([[ 3.5347757, -9.393972 ]], dtype=float32)
time = 26855	action = 0	current_phase = 0	next_phase = 1	reward = 0.723317	array([[ 3.5186157, -9.335007 ]], dtype=float32)
time = 26860	action = 0	current_phase = 0	next_phase = 1	reward = 0.721468	array([[ 3.4900923, -9.407185 ]], dtype=float32)
time = 26865	action = 0	current_phase = 0	next_phase = 1	reward = 0.718378	array([[ 3.541978, -9.307585]], dtype=float32)
time = 26870	action = 0	current_phase = 0	next_phase = 1	reward = 0.717596	array([[ 3.497713, -9.324835]], dtype=float32)
time = 26875	action = 0	current_phase = 0	next_phase = 1	reward = 0.719926	array([[ 3.5161257, -9.346312 ]], dtype=float32)
time = 26880	action = 0	current_phase = 0	next_phase = 1	reward = 0.448841	array([[ 3.4751558, -9.329199 ]], dtype=float32)
time = 26885	action = 0	current_phase = 0	next_phase = 1	reward = 0.726572	array([[ 3.496355 , -9.3144455]], dtype=float32)
time = 26890	action = 0	current_phase = 0	next_phase = 1	reward = 1.007532	array([[ 3.4850798, -9.416437 ]], dtype=float32)
time = 26895	action = 0	current_phase = 0	next_phase = 1	reward = 0.719787	array([[ 3.5732489, -9.256509 ]], dtype=float32)
time = 26900	action = 0	current_phase = 0	next_phase = 1	reward = 0.714715	array([[ 3.5672464, -9.297239 ]], dtype=float32)
time = 26905	action = 0	current_phase = 0	next_phase = 1	reward = 0.713537	array([[ 3.4619875, -9.426407 ]], dtype=float32)
time = 26910	action = 0	current_phase = 0	next_phase = 1	reward = 0.713912	array([[ 3.4531784, -9.45107  ]], dtype=float32)
time = 26915	action = 0	current_phase = 0	next_phase = 1	reward = 0.445296	array([[ 3.512539, -9.29451 ]], dtype=float32)
time = 26920	action = 0	current_phase = 0	next_phase = 1	reward = 1.001190	array([[ 3.5491076, -9.345538 ]], dtype=float32)
time = 26925	action = 0	current_phase = 0	next_phase = 1	reward = 0.718856	array([[ 3.5157957, -9.366426 ]], dtype=float32)
time = 26930	action = 0	current_phase = 0	next_phase = 1	reward = 0.443473	array([[ 3.3997307, -9.425346 ]], dtype=float32)
time = 26935	action = 0	current_phase = 0	next_phase = 1	reward = 0.732921	array([[ 3.5164518, -9.334219 ]], dtype=float32)
time = 26940	action = 0	current_phase = 0	next_phase = 1	reward = 0.729007	array([[ 3.4331274, -9.513346 ]], dtype=float32)
time = 26945	action = 0	current_phase = 0	next_phase = 1	reward = 0.999895	array([[ 3.4879932, -9.364697 ]], dtype=float32)
time = 26950	action = 0	current_phase = 0	next_phase = 1	reward = 0.723932	array([[ 3.4918823, -9.299008 ]], dtype=float32)
time = 26955	action = 0	current_phase = 0	next_phase = 1	reward = 0.442852	array([[ 3.4133348, -9.414286 ]], dtype=float32)
time = 26960	action = 0	current_phase = 0	next_phase = 1	reward = 1.003917	array([[ 3.4588528, -9.501726 ]], dtype=float32)
time = 26965	action = 0	current_phase = 0	next_phase = 1	reward = 0.443813	array([[ 3.5633974, -9.300985 ]], dtype=float32)
time = 26970	action = 0	current_phase = 0	next_phase = 1	reward = 0.721237	array([[ 3.513587, -9.356567]], dtype=float32)
time = 26975	action = 0	current_phase = 0	next_phase = 1	reward = 1.006420	array([[ 3.494502, -9.394144]], dtype=float32)
time = 26980	action = 0	current_phase = 0	next_phase = 1	reward = 0.721922	array([[ 3.4735003, -9.412579 ]], dtype=float32)
time = 26985	action = 0	current_phase = 0	next_phase = 1	reward = 0.719460	array([[ 3.3541784, -9.4899235]], dtype=float32)
time = 26990	action = 0	current_phase = 0	next_phase = 1	reward = 0.442621	array([[ 3.5105658, -9.327951 ]], dtype=float32)
time = 26995	action = 0	current_phase = 0	next_phase = 1	reward = 1.006973	array([[ 3.49125, -9.41209]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.9472 - val_loss: 1.3913
Epoch 2/50
 - 4s - loss: 5.3157 - val_loss: 1.2114
Epoch 3/50
 - 4s - loss: 4.8648 - val_loss: 1.5266
Epoch 4/50
 - 4s - loss: 3.6618 - val_loss: 1.9305
Epoch 5/50
 - 4s - loss: 3.3451 - val_loss: 1.3067
Epoch 6/50
 - 4s - loss: 4.9446 - val_loss: 1.4667
Epoch 7/50
 - 4s - loss: 3.4564 - val_loss: 1.4104
Epoch 8/50
 - 4s - loss: 4.8116 - val_loss: 1.2386
Epoch 9/50
 - 4s - loss: 4.6198 - val_loss: 1.4929
Epoch 10/50
 - 4s - loss: 3.7025 - val_loss: 1.3121
Epoch 11/50
 - 4s - loss: 4.4023 - val_loss: 1.1275
Epoch 12/50
 - 4s - loss: 3.8316 - val_loss: 1.0992
Epoch 13/50
 - 4s - loss: 4.5858 - val_loss: 1.3987
Epoch 14/50
 - 4s - loss: 4.6289 - val_loss: 1.1841
Epoch 15/50
 - 4s - loss: 3.6173 - val_loss: 1.0561
Epoch 16/50
 - 4s - loss: 3.0797 - val_loss: 1.6359
Epoch 17/50
 - 4s - loss: 3.7233 - val_loss: 1.4010
Epoch 18/50
 - 4s - loss: 4.9071 - val_loss: 1.5901
Epoch 19/50
 - 4s - loss: 3.8088 - val_loss: 1.7930
Epoch 20/50
 - 4s - loss: 4.3406 - val_loss: 1.5098
Epoch 21/50
 - 4s - loss: 5.3050 - val_loss: 1.6803
Epoch 22/50
 - 4s - loss: 4.6119 - val_loss: 1.0593
Epoch 23/50
 - 4s - loss: 5.1322 - val_loss: 1.3820
Epoch 24/50
 - 4s - loss: 4.2579 - val_loss: 1.1650
Epoch 25/50
 - 4s - loss: 4.3733 - val_loss: 1.4537
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 27000	action = 0	current_phase = 0	next_phase = 1	reward = 0.446747	array([[ 3.5947428, -9.352507 ]], dtype=float32)
time = 27005	action = 0	current_phase = 0	next_phase = 1	reward = 1.001539	array([[ 3.570489, -9.368099]], dtype=float32)
time = 27010	action = 0	current_phase = 0	next_phase = 1	reward = 0.446298	array([[ 3.6363173, -9.30143  ]], dtype=float32)
time = 27015	action = 0	current_phase = 0	next_phase = 1	reward = 1.011527	array([[ 3.5823612, -9.36352  ]], dtype=float32)
time = 27020	action = 0	current_phase = 0	next_phase = 1	reward = 0.721679	array([[ 3.6315622, -9.340167 ]], dtype=float32)
time = 27025	action = 0	current_phase = 0	next_phase = 1	reward = 0.723613	array([[ 3.57623 , -9.411139]], dtype=float32)
time = 27030	action = 0	current_phase = 0	next_phase = 1	reward = 0.730557	array([[ 3.5561905, -9.455809 ]], dtype=float32)
time = 27035	action = 0	current_phase = 0	next_phase = 1	reward = 0.453411	array([[ 3.568717, -9.378693]], dtype=float32)
time = 27040	action = 0	current_phase = 0	next_phase = 1	reward = 1.004775	array([[ 3.5865927, -9.426323 ]], dtype=float32)
time = 27045	action = 0	current_phase = 0	next_phase = 1	reward = 0.720616	array([[ 3.55334 , -9.349148]], dtype=float32)
time = 27050	action = 0	current_phase = 0	next_phase = 1	reward = 0.161732	array([[ 3.628045, -9.342688]], dtype=float32)
time = 27055	action = 0	current_phase = 0	next_phase = 1	reward = 1.282191	array([[ 3.567215, -9.482307]], dtype=float32)
time = 27060	action = 0	current_phase = 0	next_phase = 1	reward = 0.714320	array([[ 3.6296911, -9.323542 ]], dtype=float32)
time = 27065	action = 0	current_phase = 0	next_phase = 1	reward = 0.721112	array([[ 3.5801525, -9.4219   ]], dtype=float32)
time = 27070	action = 0	current_phase = 0	next_phase = 1	reward = 0.446223	array([[ 3.5740938, -9.391767 ]], dtype=float32)
time = 27075	action = 0	current_phase = 0	next_phase = 1	reward = 1.018008	array([[ 3.589013, -9.415442]], dtype=float32)
time = 27080	action = 0	current_phase = 0	next_phase = 1	reward = 0.729887	array([[ 3.5660477, -9.394716 ]], dtype=float32)
time = 27085	action = 0	current_phase = 0	next_phase = 1	reward = 0.720710	array([[ 3.592332, -9.382557]], dtype=float32)
time = 27090	action = 0	current_phase = 0	next_phase = 1	reward = 0.721791	array([[ 3.6026564, -9.313701 ]], dtype=float32)
time = 27095	action = 0	current_phase = 0	next_phase = 1	reward = 0.714565	array([[ 3.6387558, -9.305441 ]], dtype=float32)
time = 27100	action = 0	current_phase = 0	next_phase = 1	reward = 0.718345	array([[ 3.4465857, -9.46023  ]], dtype=float32)
time = 27105	action = 0	current_phase = 0	next_phase = 1	reward = 0.450144	array([[ 3.6204834, -9.336449 ]], dtype=float32)
time = 27110	action = 0	current_phase = 0	next_phase = 1	reward = 1.013024	array([[ 3.6218328, -9.342846 ]], dtype=float32)
time = 27115	action = 0	current_phase = 0	next_phase = 1	reward = 0.724537	array([[ 3.6091337, -9.3299055]], dtype=float32)
time = 27120	action = 0	current_phase = 0	next_phase = 1	reward = 0.725739	array([[ 3.6054144, -9.378152 ]], dtype=float32)
time = 27125	action = 0	current_phase = 0	next_phase = 1	reward = 0.720840	array([[ 3.593278, -9.353477]], dtype=float32)
time = 27130	action = 0	current_phase = 0	next_phase = 1	reward = 0.716509	array([[ 3.5351715, -9.433094 ]], dtype=float32)
time = 27135	action = 0	current_phase = 0	next_phase = 1	reward = 0.723865	array([[ 3.633937, -9.329465]], dtype=float32)
time = 27140	action = 0	current_phase = 0	next_phase = 1	reward = 0.718808	array([[ 3.6473541, -9.31746  ]], dtype=float32)
time = 27145	action = 0	current_phase = 0	next_phase = 1	reward = 0.724056	array([[ 3.576806, -9.382868]], dtype=float32)
time = 27150	action = 0	current_phase = 0	next_phase = 1	reward = 0.723598	array([[ 3.5494156, -9.404461 ]], dtype=float32)
time = 27155	action = 0	current_phase = 0	next_phase = 1	reward = 0.719213	array([[ 3.5970325, -9.372822 ]], dtype=float32)
time = 27160	action = 0	current_phase = 0	next_phase = 1	reward = 0.442043	array([[ 3.5563183, -9.343735 ]], dtype=float32)
time = 27165	action = 0	current_phase = 0	next_phase = 1	reward = 0.719381	array([[ 3.4553747, -9.490166 ]], dtype=float32)
time = 27170	action = 0	current_phase = 0	next_phase = 1	reward = 0.720318	array([[ 3.4797487, -9.494637 ]], dtype=float32)
time = 27175	action = 0	current_phase = 0	next_phase = 1	reward = 1.008817	array([[ 3.5980787, -9.403476 ]], dtype=float32)
time = 27180	action = 0	current_phase = 0	next_phase = 1	reward = 0.733110	array([[ 3.572585, -9.395943]], dtype=float32)
time = 27185	action = 0	current_phase = 0	next_phase = 1	reward = 0.729763	array([[ 3.519783, -9.366158]], dtype=float32)
time = 27190	action = 0	current_phase = 0	next_phase = 1	reward = 0.445626	array([[ 3.5772457, -9.376995 ]], dtype=float32)
time = 27195	action = 0	current_phase = 0	next_phase = 1	reward = 1.004375	array([[ 3.6033068, -9.366539 ]], dtype=float32)
time = 27200	action = 0	current_phase = 0	next_phase = 1	reward = 0.716969	array([[ 3.565136, -9.408837]], dtype=float32)
time = 27205	action = 0	current_phase = 0	next_phase = 1	reward = 0.723414	array([[ 3.6088734, -9.339023 ]], dtype=float32)
time = 27210	action = 0	current_phase = 0	next_phase = 1	reward = 0.720106	array([[ 3.5871134, -9.393587 ]], dtype=float32)
time = 27215	action = 0	current_phase = 0	next_phase = 1	reward = 0.450912	array([[ 3.582408, -9.414473]], dtype=float32)
time = 27220	action = 0	current_phase = 0	next_phase = 1	reward = 1.008432	array([[ 3.6127129, -9.345839 ]], dtype=float32)
time = 27225	action = 0	current_phase = 0	next_phase = 1	reward = 0.718470	array([[ 3.5127287, -9.41322  ]], dtype=float32)
time = 27230	action = 0	current_phase = 0	next_phase = 1	reward = 0.157085	array([[ 3.5774364, -9.377882 ]], dtype=float32)
time = 27235	action = 0	current_phase = 0	next_phase = 1	reward = 1.007624	array([[ 3.4947414, -9.425674 ]], dtype=float32)
time = 27240	action = 0	current_phase = 0	next_phase = 1	reward = 0.721314	array([[ 3.5956192, -9.373501 ]], dtype=float32)
time = 27245	action = 0	current_phase = 0	next_phase = 1	reward = 1.003312	array([[ 3.544239, -9.41242 ]], dtype=float32)
time = 27250	action = 0	current_phase = 0	next_phase = 1	reward = 0.720409	array([[ 3.5199375, -9.453987 ]], dtype=float32)
time = 27255	action = 0	current_phase = 0	next_phase = 1	reward = 0.162042	array([[ 3.572878, -9.398138]], dtype=float32)
time = 27260	action = 0	current_phase = 0	next_phase = 1	reward = 1.006464	array([[ 3.0358906, -9.991305 ]], dtype=float32)
time = 27265	action = 0	current_phase = 0	next_phase = 1	reward = 1.004428	array([[ 3.5808802, -9.438183 ]], dtype=float32)
time = 27270	action = 0	current_phase = 0	next_phase = 1	reward = 0.722358	array([[ 3.6121664, -9.418112 ]], dtype=float32)
time = 27275	action = 0	current_phase = 0	next_phase = 1	reward = 0.439884	array([[ 3.5588455, -9.353876 ]], dtype=float32)
time = 27280	action = 0	current_phase = 0	next_phase = 1	reward = 0.997385	array([[ 3.5708675, -9.376553 ]], dtype=float32)
time = 27285	action = 0	current_phase = 0	next_phase = 1	reward = 0.446129	array([[ 3.5545082, -9.373582 ]], dtype=float32)
time = 27290	action = 0	current_phase = 0	next_phase = 1	reward = 0.734989	array([[ 3.6143932, -9.40074  ]], dtype=float32)
time = 27295	action = 0	current_phase = 0	next_phase = 1	reward = 1.011519	array([[ 3.5465183, -9.4548235]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.7615 - val_loss: 2.3205
Epoch 2/50
 - 4s - loss: 5.7867 - val_loss: 2.1069
Epoch 3/50
 - 4s - loss: 5.6582 - val_loss: 1.9836
Epoch 4/50
 - 4s - loss: 3.9308 - val_loss: 1.8162
Epoch 5/50
 - 4s - loss: 6.2259 - val_loss: 1.6065
Epoch 6/50
 - 4s - loss: 3.5970 - val_loss: 2.1349
Epoch 7/50
 - 4s - loss: 6.4830 - val_loss: 2.0158
Epoch 8/50
 - 4s - loss: 5.0362 - val_loss: 2.1887
Epoch 9/50
 - 4s - loss: 4.7378 - val_loss: 2.9601
Epoch 10/50
 - 4s - loss: 4.2561 - val_loss: 2.1323
Epoch 11/50
 - 4s - loss: 5.8483 - val_loss: 3.5241
Epoch 12/50
 - 4s - loss: 4.2851 - val_loss: 1.9028
Epoch 13/50
 - 4s - loss: 4.1624 - val_loss: 2.6016
Epoch 14/50
 - 4s - loss: 4.8236 - val_loss: 2.1225
Epoch 15/50
 - 4s - loss: 4.6111 - val_loss: 2.6924
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 27300	action = 0	current_phase = 0	next_phase = 1	reward = 0.719712	array([[ 3.585578, -9.344348]], dtype=float32)
time = 27305	action = 0	current_phase = 0	next_phase = 1	reward = 0.723235	array([[ 3.5938435, -9.420204 ]], dtype=float32)
time = 27310	action = 0	current_phase = 0	next_phase = 1	reward = 0.721762	array([[ 3.61234 , -9.389578]], dtype=float32)
time = 27315	action = 0	current_phase = 0	next_phase = 1	reward = 0.719709	array([[ 3.5515404, -9.375942 ]], dtype=float32)
time = 27320	action = 0	current_phase = 0	next_phase = 1	reward = 0.721469	array([[ 3.5783043, -9.377121 ]], dtype=float32)
time = 27325	action = 0	current_phase = 0	next_phase = 1	reward = 0.717066	array([[ 3.5616665, -9.369196 ]], dtype=float32)
time = 27330	action = 0	current_phase = 0	next_phase = 1	reward = 0.727314	array([[ 3.611537, -9.467753]], dtype=float32)
time = 27335	action = 0	current_phase = 0	next_phase = 1	reward = 0.444530	array([[ 3.553749, -9.381901]], dtype=float32)
time = 27340	action = 0	current_phase = 0	next_phase = 1	reward = 1.009140	array([[ 3.5296335, -9.479115 ]], dtype=float32)
time = 27345	action = 0	current_phase = 0	next_phase = 1	reward = 0.724792	array([[ 3.5743637, -9.405666 ]], dtype=float32)
time = 27350	action = 0	current_phase = 0	next_phase = 1	reward = 0.452791	array([[ 3.556902, -9.419832]], dtype=float32)
time = 27355	action = 0	current_phase = 0	next_phase = 1	reward = 1.001942	array([[ 3.5420303, -9.512927 ]], dtype=float32)
time = 27360	action = 0	current_phase = 0	next_phase = 1	reward = 0.439709	array([[ 3.54702 , -9.412165]], dtype=float32)
time = 27365	action = 0	current_phase = 0	next_phase = 1	reward = 1.005555	array([[ 3.565342, -9.347261]], dtype=float32)
time = 27370	action = 0	current_phase = 0	next_phase = 1	reward = 0.719074	array([[ 3.565178, -9.430265]], dtype=float32)
time = 27375	action = 0	current_phase = 0	next_phase = 1	reward = 0.724523	array([[ 3.6012363, -9.355366 ]], dtype=float32)
time = 27380	action = 0	current_phase = 0	next_phase = 1	reward = 0.718797	array([[ 3.3988218, -9.50959  ]], dtype=float32)
time = 27385	action = 0	current_phase = 0	next_phase = 1	reward = 0.447840	array([[ 3.5710459, -9.420558 ]], dtype=float32)
time = 27390	action = 0	current_phase = 0	next_phase = 1	reward = 1.008375	array([[ 3.5548897, -9.44952  ]], dtype=float32)
time = 27395	action = 0	current_phase = 0	next_phase = 1	reward = 0.448586	array([[ 3.5920181, -9.321892 ]], dtype=float32)
time = 27400	action = 0	current_phase = 0	next_phase = 1	reward = 1.012762	array([[ 3.417571, -9.528887]], dtype=float32)
time = 27405	action = 0	current_phase = 0	next_phase = 1	reward = 0.719092	array([[ 3.529829, -9.446003]], dtype=float32)
time = 27410	action = 0	current_phase = 0	next_phase = 1	reward = 0.438965	array([[ 3.5751534, -9.361414 ]], dtype=float32)
time = 27415	action = 0	current_phase = 0	next_phase = 1	reward = 1.010300	array([[ 3.6190119, -9.354788 ]], dtype=float32)
time = 27420	action = 0	current_phase = 0	next_phase = 1	reward = 0.731857	array([[ 3.6189966, -9.361331 ]], dtype=float32)
time = 27425	action = 0	current_phase = 0	next_phase = 1	reward = 0.731176	array([[ 3.6034489, -9.386773 ]], dtype=float32)
time = 27430	action = 0	current_phase = 0	next_phase = 1	reward = 0.724904	array([[ 3.6066418, -9.406191 ]], dtype=float32)
time = 27435	action = 0	current_phase = 0	next_phase = 1	reward = 0.721566	array([[ 3.5676928, -9.403437 ]], dtype=float32)
time = 27440	action = 0	current_phase = 0	next_phase = 1	reward = 0.710482	array([[ 3.6116629, -9.399972 ]], dtype=float32)
time = 27445	action = 0	current_phase = 0	next_phase = 1	reward = 0.440896	array([[ 3.6266727, -9.335356 ]], dtype=float32)
time = 27450	action = 0	current_phase = 0	next_phase = 1	reward = 1.007499	array([[ 3.5031233, -9.410533 ]], dtype=float32)
time = 27455	action = 0	current_phase = 0	next_phase = 1	reward = 0.168088	array([[ 3.536209, -9.394165]], dtype=float32)
time = 27460	action = 0	current_phase = 0	next_phase = 1	reward = 1.293103	array([[ 3.503911, -9.492668]], dtype=float32)
time = 27465	action = 0	current_phase = 0	next_phase = 1	reward = 0.730774	array([[ 3.5951643, -9.373924 ]], dtype=float32)
time = 27470	action = 0	current_phase = 0	next_phase = 1	reward = 0.446703	array([[ 3.577406, -9.373247]], dtype=float32)
time = 27475	action = 0	current_phase = 0	next_phase = 1	reward = 1.008185	array([[ 3.5413752, -9.45326  ]], dtype=float32)
time = 27480	action = 0	current_phase = 0	next_phase = 1	reward = 0.717893	array([[ 3.589777, -9.353607]], dtype=float32)
time = 27485	action = 0	current_phase = 0	next_phase = 1	reward = 0.715434	array([[ 3.6209373, -9.350401 ]], dtype=float32)
time = 27490	action = 0	current_phase = 0	next_phase = 1	reward = 0.170516	array([[ 3.5356388, -9.473515 ]], dtype=float32)
time = 27495	action = 0	current_phase = 0	next_phase = 1	reward = 1.015708	array([[ 3.5528555, -9.455179 ]], dtype=float32)
time = 27500	action = 0	current_phase = 0	next_phase = 1	reward = 1.004325	array([[ 3.4740763, -9.490726 ]], dtype=float32)
time = 27505	action = 0	current_phase = 0	next_phase = 1	reward = 0.723561	array([[ 3.605054, -9.389746]], dtype=float32)
time = 27510	action = 0	current_phase = 0	next_phase = 1	reward = 0.439568	array([[ 3.355031, -9.59702 ]], dtype=float32)
time = 27515	action = 0	current_phase = 0	next_phase = 1	reward = 0.724965	array([[ 3.5361881, -9.432754 ]], dtype=float32)
time = 27520	action = 0	current_phase = 0	next_phase = 1	reward = 0.725425	array([[ 3.4870834, -9.537427 ]], dtype=float32)
time = 27525	action = 0	current_phase = 0	next_phase = 1	reward = 0.999664	array([[ 3.5183678, -9.469244 ]], dtype=float32)
time = 27530	action = 0	current_phase = 0	next_phase = 1	reward = 0.443181	array([[ 3.5771933, -9.421767 ]], dtype=float32)
time = 27535	action = 0	current_phase = 0	next_phase = 1	reward = 0.728299	array([[ 3.5790482, -9.41037  ]], dtype=float32)
time = 27540	action = 0	current_phase = 0	next_phase = 1	reward = 1.009611	array([[ 3.1632557, -9.855685 ]], dtype=float32)
time = 27545	action = 0	current_phase = 0	next_phase = 1	reward = 0.739508	array([[ 3.5520887, -9.455639 ]], dtype=float32)
time = 27550	action = 0	current_phase = 0	next_phase = 1	reward = 0.727624	array([[ 3.5136414, -9.446087 ]], dtype=float32)
time = 27555	action = 0	current_phase = 0	next_phase = 1	reward = 0.719482	array([[ 3.559824, -9.378868]], dtype=float32)
time = 27560	action = 0	current_phase = 0	next_phase = 1	reward = 0.721381	array([[ 3.5789165, -9.348063 ]], dtype=float32)
time = 27565	action = 0	current_phase = 0	next_phase = 1	reward = 0.719134	array([[ 3.5858583, -9.397312 ]], dtype=float32)
time = 27570	action = 0	current_phase = 0	next_phase = 1	reward = 0.440908	array([[ 3.6022663, -9.323702 ]], dtype=float32)
time = 27575	action = 0	current_phase = 0	next_phase = 1	reward = 1.001351	array([[ 3.4234428, -9.604221 ]], dtype=float32)
time = 27580	action = 0	current_phase = 0	next_phase = 1	reward = 0.450722	array([[ 3.5676298, -9.370379 ]], dtype=float32)
time = 27585	action = 0	current_phase = 0	next_phase = 1	reward = 1.008575	array([[ 3.536684, -9.478024]], dtype=float32)
time = 27590	action = 0	current_phase = 0	next_phase = 1	reward = 0.722281	array([[ 3.5696077, -9.435087 ]], dtype=float32)
time = 27595	action = 0	current_phase = 0	next_phase = 1	reward = 0.720979	array([[ 3.580927, -9.398231]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.0672 - val_loss: 2.3895
Epoch 2/50
 - 5s - loss: 4.2199 - val_loss: 2.0979
Epoch 3/50
 - 4s - loss: 3.5866 - val_loss: 2.3327
Epoch 4/50
 - 4s - loss: 4.8943 - val_loss: 2.2623
Epoch 5/50
 - 5s - loss: 5.1310 - val_loss: 2.5264
Epoch 6/50
 - 4s - loss: 4.4404 - val_loss: 2.0749
Epoch 7/50
 - 4s - loss: 5.0730 - val_loss: 2.4168
Epoch 8/50
 - 4s - loss: 3.6369 - val_loss: 2.5565
Epoch 9/50
 - 4s - loss: 3.5960 - val_loss: 2.1069
Epoch 10/50
 - 4s - loss: 4.0882 - val_loss: 2.6307
Epoch 11/50
 - 4s - loss: 4.9372 - val_loss: 2.1616
Epoch 12/50
 - 4s - loss: 4.1146 - val_loss: 2.5197
Epoch 13/50
 - 4s - loss: 3.7915 - val_loss: 2.4373
Epoch 14/50
 - 4s - loss: 5.4691 - val_loss: 2.7436
Epoch 15/50
 - 4s - loss: 6.6026 - val_loss: 2.5913
Epoch 16/50
 - 4s - loss: 4.1382 - val_loss: 2.1896
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 27600	action = 0	current_phase = 0	next_phase = 1	reward = 0.724716	array([[ 3.617496, -9.338909]], dtype=float32)
time = 27605	action = 0	current_phase = 0	next_phase = 1	reward = 0.729954	array([[ 3.583201, -9.427406]], dtype=float32)
time = 27610	action = 0	current_phase = 0	next_phase = 1	reward = 0.734988	array([[ 3.6194673, -9.418374 ]], dtype=float32)
time = 27615	action = 0	current_phase = 0	next_phase = 1	reward = 0.711060	array([[ 3.6331687, -9.354693 ]], dtype=float32)
time = 27620	action = 0	current_phase = 0	next_phase = 1	reward = 0.439644	array([[ 3.6539178, -9.352867 ]], dtype=float32)
time = 27625	action = 0	current_phase = 0	next_phase = 1	reward = 1.012599	array([[ 3.611734, -9.381283]], dtype=float32)
time = 27630	action = 0	current_phase = 0	next_phase = 1	reward = 0.165338	array([[ 3.6194062, -9.414385 ]], dtype=float32)
time = 27635	action = 0	current_phase = 0	next_phase = 1	reward = 1.287240	array([[ 3.5138707, -9.566832 ]], dtype=float32)
time = 27640	action = 0	current_phase = 0	next_phase = 1	reward = 0.709175	array([[ 3.6034188, -9.366019 ]], dtype=float32)
time = 27645	action = 0	current_phase = 0	next_phase = 1	reward = 0.163583	array([[ 3.5722604, -9.470669 ]], dtype=float32)
time = 27650	action = 0	current_phase = 0	next_phase = 1	reward = 1.303182	array([[ 3.5704637, -9.420549 ]], dtype=float32)
time = 27655	action = 0	current_phase = 0	next_phase = 1	reward = 0.723914	array([[ 3.593534, -9.391212]], dtype=float32)
time = 27660	action = 0	current_phase = 0	next_phase = 1	reward = 0.726981	array([[ 3.597179, -9.392054]], dtype=float32)
time = 27665	action = 0	current_phase = 0	next_phase = 1	reward = 0.720644	array([[ 3.6333356, -9.398323 ]], dtype=float32)
time = 27670	action = 0	current_phase = 0	next_phase = 1	reward = 0.166476	array([[ 3.5979733, -9.348931 ]], dtype=float32)
time = 27675	action = 0	current_phase = 0	next_phase = 1	reward = 1.291032	array([[ 3.518065, -9.549506]], dtype=float32)
time = 27680	action = 0	current_phase = 0	next_phase = 1	reward = 0.723137	array([[ 3.6185842, -9.390257 ]], dtype=float32)
time = 27685	action = 0	current_phase = 0	next_phase = 1	reward = 0.719957	array([[ 3.626658, -9.383406]], dtype=float32)
time = 27690	action = 0	current_phase = 0	next_phase = 1	reward = 0.438289	array([[ 3.5578208, -9.467398 ]], dtype=float32)
time = 27695	action = 0	current_phase = 0	next_phase = 1	reward = 1.002186	array([[ 3.5950255, -9.371384 ]], dtype=float32)
time = 27700	action = 0	current_phase = 0	next_phase = 1	reward = 0.721837	array([[ 3.5969644, -9.459675 ]], dtype=float32)
time = 27705	action = 0	current_phase = 0	next_phase = 1	reward = 0.446892	array([[ 3.5342708, -9.400206 ]], dtype=float32)
time = 27710	action = 0	current_phase = 0	next_phase = 1	reward = 1.004359	array([[ 3.5544763, -9.400354 ]], dtype=float32)
time = 27715	action = 0	current_phase = 0	next_phase = 1	reward = 0.717578	array([[ 3.6628184, -9.41017  ]], dtype=float32)
time = 27720	action = 0	current_phase = 0	next_phase = 1	reward = 0.718989	array([[ 3.6124644, -9.418434 ]], dtype=float32)
time = 27725	action = 0	current_phase = 0	next_phase = 1	reward = 0.710517	array([[ 3.6254258, -9.344124 ]], dtype=float32)
time = 27730	action = 0	current_phase = 0	next_phase = 1	reward = 0.717493	array([[ 3.598536, -9.38596 ]], dtype=float32)
time = 27735	action = 0	current_phase = 0	next_phase = 1	reward = 0.452672	array([[ 3.6271415, -9.388966 ]], dtype=float32)
time = 27740	action = 0	current_phase = 0	next_phase = 1	reward = 1.016303	array([[ 3.3283439, -9.709704 ]], dtype=float32)
time = 27745	action = 0	current_phase = 0	next_phase = 1	reward = 0.445914	array([[ 3.6124759, -9.475625 ]], dtype=float32)
time = 27750	action = 0	current_phase = 0	next_phase = 1	reward = 1.010293	array([[ 3.5300183, -9.476593 ]], dtype=float32)
time = 27755	action = 0	current_phase = 0	next_phase = 1	reward = 0.719217	array([[ 3.5840135, -9.441334 ]], dtype=float32)
time = 27760	action = 0	current_phase = 0	next_phase = 1	reward = 0.441101	array([[ 3.6111703, -9.423912 ]], dtype=float32)
time = 27765	action = 0	current_phase = 0	next_phase = 1	reward = 0.999361	array([[ 3.6498494, -9.40077  ]], dtype=float32)
time = 27770	action = 0	current_phase = 0	next_phase = 1	reward = 0.723698	array([[ 3.6223836, -9.416328 ]], dtype=float32)
time = 27775	action = 0	current_phase = 0	next_phase = 1	reward = 0.722047	array([[ 3.5800233, -9.418515 ]], dtype=float32)
time = 27780	action = 0	current_phase = 0	next_phase = 1	reward = 0.722302	array([[ 3.5759654, -9.385268 ]], dtype=float32)
time = 27785	action = 0	current_phase = 0	next_phase = 1	reward = 0.450344	array([[ 3.6489663, -9.323538 ]], dtype=float32)
time = 27790	action = 0	current_phase = 0	next_phase = 1	reward = 1.012889	array([[ 3.581204, -9.462088]], dtype=float32)
time = 27795	action = 0	current_phase = 0	next_phase = 1	reward = 0.717624	array([[ 3.6380715, -9.38044  ]], dtype=float32)
time = 27800	action = 0	current_phase = 0	next_phase = 1	reward = 0.713700	array([[ 3.6398225, -9.359249 ]], dtype=float32)
time = 27805	action = 0	current_phase = 0	next_phase = 1	reward = 0.442113	array([[ 3.6045003, -9.402327 ]], dtype=float32)
time = 27810	action = 0	current_phase = 0	next_phase = 1	reward = 0.733216	array([[ 3.5962214, -9.434326 ]], dtype=float32)
time = 27815	action = 0	current_phase = 0	next_phase = 1	reward = 1.003094	array([[ 3.5949597, -9.437992 ]], dtype=float32)
time = 27820	action = 0	current_phase = 0	next_phase = 1	reward = 0.718415	array([[ 3.5552106, -9.44001  ]], dtype=float32)
time = 27825	action = 0	current_phase = 0	next_phase = 1	reward = 0.444233	array([[ 3.592029, -9.411047]], dtype=float32)
time = 27830	action = 0	current_phase = 0	next_phase = 1	reward = 1.011529	array([[ 3.6015573, -9.370772 ]], dtype=float32)
time = 27835	action = 0	current_phase = 0	next_phase = 1	reward = 0.723585	array([[ 3.592854, -9.391155]], dtype=float32)
time = 27840	action = 0	current_phase = 0	next_phase = 1	reward = 0.719156	array([[ 3.5713534, -9.429026 ]], dtype=float32)
time = 27845	action = 0	current_phase = 0	next_phase = 1	reward = 0.719482	array([[ 3.6181426, -9.40479  ]], dtype=float32)
time = 27850	action = 0	current_phase = 0	next_phase = 1	reward = 0.726720	array([[ 3.622992, -9.429033]], dtype=float32)
time = 27855	action = 0	current_phase = 0	next_phase = 1	reward = 0.440393	array([[ 3.6432672, -9.347513 ]], dtype=float32)
time = 27860	action = 0	current_phase = 0	next_phase = 1	reward = 1.004281	array([[ 3.5659547, -9.450421 ]], dtype=float32)
time = 27865	action = 0	current_phase = 0	next_phase = 1	reward = 0.725552	array([[ 3.615316, -9.373602]], dtype=float32)
time = 27870	action = 0	current_phase = 0	next_phase = 1	reward = 0.737225	array([[ 3.6384397, -9.369238 ]], dtype=float32)
time = 27875	action = 0	current_phase = 0	next_phase = 1	reward = 0.731069	array([[ 3.6082587, -9.358002 ]], dtype=float32)
time = 27880	action = 0	current_phase = 0	next_phase = 1	reward = 0.713620	array([[ 3.6118636, -9.372538 ]], dtype=float32)
time = 27885	action = 0	current_phase = 0	next_phase = 1	reward = 0.442184	array([[ 3.6046176, -9.413015 ]], dtype=float32)
time = 27890	action = 0	current_phase = 0	next_phase = 1	reward = 0.731366	array([[ 3.6693463, -9.391766 ]], dtype=float32)
time = 27895	action = 0	current_phase = 0	next_phase = 1	reward = 1.006855	array([[ 3.5594954, -9.434704 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 5s - loss: 3.9368 - val_loss: 1.8248
Epoch 2/50
 - 5s - loss: 7.4963 - val_loss: 2.2056
Epoch 3/50
 - 5s - loss: 4.5241 - val_loss: 1.5357
Epoch 4/50
 - 5s - loss: 4.5344 - val_loss: 1.8218
Epoch 5/50
 - 5s - loss: 6.8071 - val_loss: 3.9990
Epoch 6/50
 - 4s - loss: 4.0949 - val_loss: 2.7715
Epoch 7/50
 - 5s - loss: 4.1558 - val_loss: 1.8353
Epoch 8/50
 - 5s - loss: 3.5634 - val_loss: 2.0531
Epoch 9/50
 - 4s - loss: 3.6050 - val_loss: 1.9011
Epoch 10/50
 - 6s - loss: 5.1005 - val_loss: 1.4072
Epoch 11/50
 - 5s - loss: 4.4503 - val_loss: 1.9115
Epoch 12/50
 - 5s - loss: 3.2539 - val_loss: 1.8770
Epoch 13/50
 - 5s - loss: 5.2460 - val_loss: 2.3841
Epoch 14/50
 - 4s - loss: 3.1891 - val_loss: 2.3818
Epoch 15/50
 - 5s - loss: 3.9212 - val_loss: 1.8964
Epoch 16/50
 - 5s - loss: 5.0023 - val_loss: 2.2252
Epoch 17/50
 - 4s - loss: 4.2724 - val_loss: 1.9976
Epoch 18/50
 - 4s - loss: 4.0899 - val_loss: 2.6302
Epoch 19/50
 - 5s - loss: 5.0009 - val_loss: 3.1780
Epoch 20/50
 - 4s - loss: 2.8416 - val_loss: 1.6553
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 27900	action = 0	current_phase = 0	next_phase = 1	reward = 0.443809	array([[ 3.6412811, -9.392712 ]], dtype=float32)
time = 27905	action = 0	current_phase = 0	next_phase = 1	reward = 0.999265	array([[ 3.6091137, -9.376693 ]], dtype=float32)
time = 27910	action = 0	current_phase = 0	next_phase = 1	reward = 0.716696	array([[ 3.5773134, -9.391478 ]], dtype=float32)
time = 27915	action = 0	current_phase = 0	next_phase = 1	reward = 0.175164	array([[ 3.6270514, -9.429561 ]], dtype=float32)
time = 27920	action = 0	current_phase = 0	next_phase = 1	reward = 1.299387	array([[ 3.5817719, -9.43541  ]], dtype=float32)
time = 27925	action = 0	current_phase = 0	next_phase = 1	reward = 0.728710	array([[ 3.6294603, -9.355608 ]], dtype=float32)
time = 27930	action = 0	current_phase = 0	next_phase = 1	reward = 0.725110	array([[ 3.6247025, -9.358173 ]], dtype=float32)
time = 27935	action = 0	current_phase = 0	next_phase = 1	reward = 0.717920	array([[ 3.5954342, -9.434287 ]], dtype=float32)
time = 27940	action = 0	current_phase = 0	next_phase = 1	reward = 0.715528	array([[ 3.6155767, -9.410381 ]], dtype=float32)
time = 27945	action = 0	current_phase = 0	next_phase = 1	reward = 0.716332	array([[ 3.5318155, -9.441836 ]], dtype=float32)
time = 27950	action = 0	current_phase = 0	next_phase = 1	reward = 0.164342	array([[ 3.5402842, -9.40687  ]], dtype=float32)
time = 27955	action = 0	current_phase = 0	next_phase = 1	reward = 1.005387	array([[ 3.5860376, -9.413755 ]], dtype=float32)
time = 27960	action = 0	current_phase = 0	next_phase = 1	reward = 0.719424	array([[ 3.6241064, -9.336447 ]], dtype=float32)
time = 27965	action = 0	current_phase = 0	next_phase = 1	reward = 1.000207	array([[ 3.609374, -9.387705]], dtype=float32)
time = 27970	action = 0	current_phase = 0	next_phase = 1	reward = 0.450142	array([[ 3.5845108, -9.347565 ]], dtype=float32)
time = 27975	action = 0	current_phase = 0	next_phase = 1	reward = 1.007833	array([[ 3.518608, -9.466545]], dtype=float32)
time = 27980	action = 0	current_phase = 0	next_phase = 1	reward = 0.719044	array([[ 3.5960636, -9.381699 ]], dtype=float32)
time = 27985	action = 0	current_phase = 0	next_phase = 1	reward = 0.445860	array([[ 3.6056929, -9.363155 ]], dtype=float32)
time = 27990	action = 0	current_phase = 0	next_phase = 1	reward = 0.725301	array([[ 3.5264177, -9.513031 ]], dtype=float32)
time = 27995	action = 0	current_phase = 0	next_phase = 1	reward = 1.003037	array([[ 3.5836248, -9.39823  ]], dtype=float32)
time = 28000	action = 0	current_phase = 0	next_phase = 1	reward = 0.719880	array([[ 3.6009026, -9.417847 ]], dtype=float32)
time = 28005	action = 0	current_phase = 0	next_phase = 1	reward = 0.447346	array([[ 3.5238123, -9.427507 ]], dtype=float32)
time = 28010	action = 0	current_phase = 0	next_phase = 1	reward = 0.448460	array([[ 3.6078405, -9.471209 ]], dtype=float32)
time = 28015	action = 0	current_phase = 0	next_phase = 1	reward = 1.010217	array([[ 3.6003819, -9.414471 ]], dtype=float32)
time = 28020	action = 0	current_phase = 0	next_phase = 1	reward = 1.003401	array([[ 3.6164656, -9.381943 ]], dtype=float32)
time = 28025	action = 0	current_phase = 0	next_phase = 1	reward = 0.724367	array([[ 3.569932, -9.413577]], dtype=float32)
time = 28030	action = 0	current_phase = 0	next_phase = 1	reward = 0.721831	array([[ 3.5856009, -9.38772  ]], dtype=float32)
time = 28035	action = 0	current_phase = 0	next_phase = 1	reward = 0.442138	array([[ 3.607955, -9.423091]], dtype=float32)
time = 28040	action = 0	current_phase = 0	next_phase = 1	reward = 1.013465	array([[ 3.5640545, -9.413771 ]], dtype=float32)
time = 28045	action = 0	current_phase = 0	next_phase = 1	reward = 0.451254	array([[ 3.603218, -9.412777]], dtype=float32)
time = 28050	action = 0	current_phase = 0	next_phase = 1	reward = 1.008006	array([[ 3.6165972, -9.430935 ]], dtype=float32)
time = 28055	action = 0	current_phase = 0	next_phase = 1	reward = 0.719087	array([[ 3.5812426, -9.3514   ]], dtype=float32)
time = 28060	action = 0	current_phase = 0	next_phase = 1	reward = 0.713325	array([[ 3.5781288, -9.434449 ]], dtype=float32)
time = 28065	action = 0	current_phase = 0	next_phase = 1	reward = 0.721313	array([[ 3.6238823, -9.440287 ]], dtype=float32)
time = 28070	action = 0	current_phase = 0	next_phase = 1	reward = 0.717580	array([[ 3.5861902, -9.393488 ]], dtype=float32)
time = 28075	action = 0	current_phase = 0	next_phase = 1	reward = 0.446711	array([[ 3.5958633, -9.432968 ]], dtype=float32)
time = 28080	action = 0	current_phase = 0	next_phase = 1	reward = 0.999390	array([[ 3.6233788, -9.396406 ]], dtype=float32)
time = 28085	action = 0	current_phase = 0	next_phase = 1	reward = 0.717029	array([[ 3.6200876, -9.371653 ]], dtype=float32)
time = 28090	action = 0	current_phase = 0	next_phase = 1	reward = 0.719157	array([[ 3.5934563, -9.330347 ]], dtype=float32)
time = 28095	action = 0	current_phase = 0	next_phase = 1	reward = 0.171178	array([[ 3.577671, -9.38566 ]], dtype=float32)
time = 28100	action = 0	current_phase = 0	next_phase = 1	reward = 1.291010	array([[ 3.5878258, -9.447512 ]], dtype=float32)
time = 28105	action = 0	current_phase = 0	next_phase = 1	reward = 0.722967	array([[ 3.6388226, -9.354812 ]], dtype=float32)
time = 28110	action = 0	current_phase = 0	next_phase = 1	reward = 0.722272	array([[ 3.5635328, -9.438293 ]], dtype=float32)
time = 28115	action = 0	current_phase = 0	next_phase = 1	reward = 0.717676	array([[ 3.5750895, -9.417735 ]], dtype=float32)
time = 28120	action = 0	current_phase = 0	next_phase = 1	reward = 0.440242	array([[ 3.5794945, -9.41852  ]], dtype=float32)
time = 28125	action = 0	current_phase = 0	next_phase = 1	reward = 1.003877	array([[ 3.6101646, -9.347248 ]], dtype=float32)
time = 28130	action = 0	current_phase = 0	next_phase = 1	reward = 0.725053	array([[ 3.5442696, -9.397467 ]], dtype=float32)
time = 28135	action = 0	current_phase = 0	next_phase = 1	reward = 0.440201	array([[ 3.5868511, -9.383931 ]], dtype=float32)
time = 28140	action = 0	current_phase = 0	next_phase = 1	reward = 0.999653	array([[ 3.5736647, -9.477404 ]], dtype=float32)
time = 28145	action = 0	current_phase = 0	next_phase = 1	reward = 0.440552	array([[ 3.583334, -9.45281 ]], dtype=float32)
time = 28150	action = 0	current_phase = 0	next_phase = 1	reward = 0.722028	array([[ 3.6033459, -9.327017 ]], dtype=float32)
time = 28155	action = 0	current_phase = 0	next_phase = 1	reward = 0.999631	array([[ 3.5788908, -9.368038 ]], dtype=float32)
time = 28160	action = 0	current_phase = 0	next_phase = 1	reward = 0.162370	array([[ 3.5968637, -9.343824 ]], dtype=float32)
time = 28165	action = 0	current_phase = 0	next_phase = 1	reward = 1.283396	array([[ 3.55645 , -9.454423]], dtype=float32)
time = 28170	action = 0	current_phase = 0	next_phase = 1	reward = 0.440202	array([[ 3.6080036, -9.341421 ]], dtype=float32)
time = 28175	action = 0	current_phase = 0	next_phase = 1	reward = 0.725844	array([[ 3.594408 , -9.4030695]], dtype=float32)
time = 28180	action = 0	current_phase = 0	next_phase = 1	reward = 1.006535	array([[ 3.6348534, -9.388824 ]], dtype=float32)
time = 28185	action = 0	current_phase = 0	next_phase = 1	reward = 0.442711	array([[ 3.6289062, -9.442915 ]], dtype=float32)
time = 28190	action = 0	current_phase = 0	next_phase = 1	reward = 1.005970	array([[ 3.498083, -9.461786]], dtype=float32)
time = 28195	action = 0	current_phase = 0	next_phase = 1	reward = 0.721754	array([[ 3.6607828, -9.3645525]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 6.1325 - val_loss: 3.4049
Epoch 2/50
 - 4s - loss: 4.9076 - val_loss: 3.4002
Epoch 3/50
 - 4s - loss: 5.3233 - val_loss: 2.0952
Epoch 4/50
 - 4s - loss: 4.0893 - val_loss: 1.5136
Epoch 5/50
 - 4s - loss: 6.0684 - val_loss: 2.6097
Epoch 6/50
 - 4s - loss: 3.8126 - val_loss: 1.6656
Epoch 7/50
 - 4s - loss: 3.8160 - val_loss: 2.6767
Epoch 8/50
 - 4s - loss: 3.9927 - val_loss: 2.9820
Epoch 9/50
 - 4s - loss: 5.3815 - val_loss: 2.7055
Epoch 10/50
 - 4s - loss: 5.1880 - val_loss: 2.3954
Epoch 11/50
 - 4s - loss: 3.4196 - val_loss: 2.5113
Epoch 12/50
 - 4s - loss: 3.5865 - val_loss: 3.3474
Epoch 13/50
 - 4s - loss: 4.5920 - val_loss: 1.6391
Epoch 14/50
 - 4s - loss: 5.1639 - val_loss: 1.9563
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 28200	action = 0	current_phase = 0	next_phase = 1	reward = 0.446251	array([[ 3.6173825, -9.35726  ]], dtype=float32)
time = 28205	action = 0	current_phase = 0	next_phase = 1	reward = 1.003428	array([[ 3.5688863, -9.375967 ]], dtype=float32)
time = 28210	action = 0	current_phase = 0	next_phase = 1	reward = 0.451525	array([[ 3.5751052, -9.354071 ]], dtype=float32)
time = 28215	action = 0	current_phase = 0	next_phase = 1	reward = 1.005934	array([[ 3.566855, -9.317549]], dtype=float32)
time = 28220	action = 0	current_phase = 0	next_phase = 1	reward = 0.448520	array([[ 3.625052, -9.307247]], dtype=float32)
time = 28225	action = 0	current_phase = 0	next_phase = 1	reward = 0.716147	array([[ 3.5804543, -9.359201 ]], dtype=float32)
time = 28230	action = 0	current_phase = 0	next_phase = 1	reward = 0.992986	array([[ 3.567721, -9.375359]], dtype=float32)
time = 28235	action = 0	current_phase = 0	next_phase = 1	reward = 0.722456	array([[ 3.603602, -9.300701]], dtype=float32)
time = 28240	action = 0	current_phase = 0	next_phase = 1	reward = 0.444457	array([[ 3.5745597, -9.319443 ]], dtype=float32)
time = 28245	action = 0	current_phase = 0	next_phase = 1	reward = 1.000278	array([[ 3.6069274, -9.338898 ]], dtype=float32)
time = 28250	action = 0	current_phase = 0	next_phase = 1	reward = 0.725847	array([[ 3.643025, -9.341115]], dtype=float32)
time = 28255	action = 0	current_phase = 0	next_phase = 1	reward = 0.726758	array([[ 3.5981383, -9.349293 ]], dtype=float32)
time = 28260	action = 0	current_phase = 0	next_phase = 1	reward = 0.727348	array([[ 3.5921683, -9.405952 ]], dtype=float32)
time = 28265	action = 0	current_phase = 0	next_phase = 1	reward = 0.721965	array([[ 3.5809808, -9.414548 ]], dtype=float32)
time = 28270	action = 0	current_phase = 0	next_phase = 1	reward = 0.442315	array([[ 3.577273, -9.323004]], dtype=float32)
time = 28275	action = 0	current_phase = 0	next_phase = 1	reward = 0.728132	array([[ 3.578116, -9.404789]], dtype=float32)
time = 28280	action = 0	current_phase = 0	next_phase = 1	reward = 1.000987	array([[ 3.5751119, -9.300875 ]], dtype=float32)
time = 28285	action = 0	current_phase = 0	next_phase = 1	reward = 0.441763	array([[ 3.5859084, -9.313356 ]], dtype=float32)
time = 28290	action = 0	current_phase = 0	next_phase = 1	reward = 0.723016	array([[ 3.5445256, -9.405006 ]], dtype=float32)
time = 28295	action = 0	current_phase = 0	next_phase = 1	reward = 1.000830	array([[ 3.5956302, -9.371296 ]], dtype=float32)
time = 28300	action = 0	current_phase = 0	next_phase = 1	reward = 0.727201	array([[ 3.5875888, -9.351478 ]], dtype=float32)
time = 28305	action = 0	current_phase = 0	next_phase = 1	reward = 0.731020	array([[ 3.5734363, -9.423    ]], dtype=float32)
time = 28310	action = 0	current_phase = 0	next_phase = 1	reward = 0.729083	array([[ 3.5919147, -9.309911 ]], dtype=float32)
time = 28315	action = 0	current_phase = 0	next_phase = 1	reward = 0.443487	array([[ 3.598351, -9.315019]], dtype=float32)
time = 28320	action = 0	current_phase = 0	next_phase = 1	reward = 1.003940	array([[ 3.606032, -9.342372]], dtype=float32)
time = 28325	action = 0	current_phase = 0	next_phase = 1	reward = 0.716919	array([[ 3.5739818, -9.323984 ]], dtype=float32)
time = 28330	action = 0	current_phase = 0	next_phase = 1	reward = 0.713495	array([[ 3.554092, -9.356503]], dtype=float32)
time = 28335	action = 0	current_phase = 0	next_phase = 1	reward = 0.438154	array([[ 3.630444, -9.350238]], dtype=float32)
time = 28340	action = 0	current_phase = 0	next_phase = 1	reward = 1.006905	array([[ 3.5680928, -9.384317 ]], dtype=float32)
time = 28345	action = 0	current_phase = 0	next_phase = 1	reward = 0.453374	array([[ 3.54456, -9.38744]], dtype=float32)
time = 28350	action = 0	current_phase = 0	next_phase = 1	reward = 1.006810	array([[ 3.5737138, -9.375644 ]], dtype=float32)
time = 28355	action = 0	current_phase = 0	next_phase = 1	reward = 0.728313	array([[ 3.568396, -9.387489]], dtype=float32)
time = 28360	action = 0	current_phase = 0	next_phase = 1	reward = 0.721332	array([[ 3.5881782, -9.318574 ]], dtype=float32)
time = 28365	action = 0	current_phase = 0	next_phase = 1	reward = 0.724127	array([[ 3.5929923, -9.289864 ]], dtype=float32)
time = 28370	action = 0	current_phase = 0	next_phase = 1	reward = 0.442977	array([[ 3.608746, -9.393997]], dtype=float32)
time = 28375	action = 0	current_phase = 0	next_phase = 1	reward = 1.001860	array([[ 3.597589, -9.333242]], dtype=float32)
time = 28380	action = 0	current_phase = 0	next_phase = 1	reward = 0.444574	array([[ 3.6355681, -9.342297 ]], dtype=float32)
time = 28385	action = 0	current_phase = 0	next_phase = 1	reward = 0.993478	array([[ 3.609118, -9.363461]], dtype=float32)
time = 28390	action = 0	current_phase = 0	next_phase = 1	reward = 0.437722	array([[ 3.515246 , -9.3832445]], dtype=float32)
time = 28395	action = 0	current_phase = 0	next_phase = 1	reward = 0.450073	array([[ 3.574841, -9.410468]], dtype=float32)
time = 28400	action = 0	current_phase = 0	next_phase = 1	reward = 1.284109	array([[ 3.5482821, -9.417526 ]], dtype=float32)
time = 28405	action = 0	current_phase = 0	next_phase = 1	reward = 0.441060	array([[ 3.6137424, -9.358828 ]], dtype=float32)
time = 28410	action = 0	current_phase = 0	next_phase = 1	reward = 1.009329	array([[ 3.5697742, -9.361771 ]], dtype=float32)
time = 28415	action = 0	current_phase = 0	next_phase = 1	reward = 0.720678	array([[ 3.562348, -9.375428]], dtype=float32)
time = 28420	action = 0	current_phase = 0	next_phase = 1	reward = 0.447583	array([[ 3.593099, -9.353483]], dtype=float32)
time = 28425	action = 0	current_phase = 0	next_phase = 1	reward = 1.004589	array([[ 3.5779672, -9.332293 ]], dtype=float32)
time = 28430	action = 0	current_phase = 0	next_phase = 1	reward = 0.731333	array([[ 3.6188788, -9.334568 ]], dtype=float32)
time = 28435	action = 0	current_phase = 0	next_phase = 1	reward = 0.723005	array([[ 3.5839915, -9.334479 ]], dtype=float32)
time = 28440	action = 0	current_phase = 0	next_phase = 1	reward = 0.443691	array([[ 3.6132932, -9.307637 ]], dtype=float32)
time = 28445	action = 0	current_phase = 0	next_phase = 1	reward = 1.000970	array([[ 3.632831, -9.363304]], dtype=float32)
time = 28450	action = 0	current_phase = 0	next_phase = 1	reward = 0.717743	array([[ 3.6154475, -9.357883 ]], dtype=float32)
time = 28455	action = 0	current_phase = 0	next_phase = 1	reward = 0.724877	array([[ 3.5581336, -9.404659 ]], dtype=float32)
time = 28460	action = 0	current_phase = 0	next_phase = 1	reward = 0.719659	array([[ 3.6153235, -9.348505 ]], dtype=float32)
time = 28465	action = 0	current_phase = 0	next_phase = 1	reward = 0.443638	array([[ 3.5773787, -9.322111 ]], dtype=float32)
time = 28470	action = 0	current_phase = 0	next_phase = 1	reward = 1.003750	array([[ 3.6294894, -9.355194 ]], dtype=float32)
time = 28475	action = 0	current_phase = 0	next_phase = 1	reward = 0.722358	array([[ 3.610558, -9.289909]], dtype=float32)
time = 28480	action = 0	current_phase = 0	next_phase = 1	reward = 0.731102	array([[ 3.5772262, -9.304981 ]], dtype=float32)
time = 28485	action = 0	current_phase = 0	next_phase = 1	reward = 0.715351	array([[ 3.604731, -9.351347]], dtype=float32)
time = 28490	action = 0	current_phase = 0	next_phase = 1	reward = 0.726770	array([[ 3.5705123, -9.381123 ]], dtype=float32)
time = 28495	action = 0	current_phase = 0	next_phase = 1	reward = 0.721378	array([[ 3.594664, -9.300237]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.8441 - val_loss: 2.6970
Epoch 2/50
 - 4s - loss: 4.6197 - val_loss: 2.9369
Epoch 3/50
 - 4s - loss: 5.1137 - val_loss: 2.3987
Epoch 4/50
 - 4s - loss: 2.6310 - val_loss: 3.2056
Epoch 5/50
 - 5s - loss: 3.6505 - val_loss: 3.8363
Epoch 6/50
 - 5s - loss: 3.9081 - val_loss: 1.6835
Epoch 7/50
 - 5s - loss: 4.7814 - val_loss: 2.7546
Epoch 8/50
 - 4s - loss: 5.1307 - val_loss: 2.0349
Epoch 9/50
 - 4s - loss: 3.2778 - val_loss: 1.8101
Epoch 10/50
 - 5s - loss: 5.3721 - val_loss: 2.7841
Epoch 11/50
 - 4s - loss: 5.7249 - val_loss: 2.2820
Epoch 12/50
 - 6s - loss: 4.1702 - val_loss: 3.0315
Epoch 13/50
 - 4s - loss: 3.3010 - val_loss: 2.7413
Epoch 14/50
 - 4s - loss: 4.3847 - val_loss: 2.3528
Epoch 15/50
 - 4s - loss: 3.2359 - val_loss: 1.9236
Epoch 16/50
 - 4s - loss: 3.4691 - val_loss: 2.7727
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 28500	action = 0	current_phase = 0	next_phase = 1	reward = 0.444986	array([[ 3.597362, -9.483189]], dtype=float32)
time = 28505	action = 0	current_phase = 0	next_phase = 1	reward = 1.002996	array([[ 3.64467 , -9.430066]], dtype=float32)
time = 28510	action = 0	current_phase = 0	next_phase = 1	reward = 0.720270	array([[ 3.6203437, -9.309225 ]], dtype=float32)
time = 28515	action = 0	current_phase = 0	next_phase = 1	reward = 0.719445	array([[ 3.625979, -9.364701]], dtype=float32)
time = 28520	action = 0	current_phase = 0	next_phase = 1	reward = 0.726369	array([[ 3.6427426, -9.350988 ]], dtype=float32)
time = 28525	action = 0	current_phase = 0	next_phase = 1	reward = 0.708706	array([[ 3.5745578, -9.410753 ]], dtype=float32)
time = 28530	action = 0	current_phase = 0	next_phase = 1	reward = 0.167389	array([[ 3.585935, -9.294681]], dtype=float32)
time = 28535	action = 0	current_phase = 0	next_phase = 1	reward = 1.287078	array([[ 3.6010346, -9.408091 ]], dtype=float32)
time = 28540	action = 0	current_phase = 0	next_phase = 1	reward = 0.720323	array([[ 3.57834, -9.44776]], dtype=float32)
time = 28545	action = 0	current_phase = 0	next_phase = 1	reward = 0.440836	array([[ 3.6131186, -9.44598  ]], dtype=float32)
time = 28550	action = 0	current_phase = 0	next_phase = 1	reward = 0.997790	array([[ 3.6553378, -9.407339 ]], dtype=float32)
time = 28555	action = 0	current_phase = 0	next_phase = 1	reward = 0.445013	array([[ 3.5791478, -9.350735 ]], dtype=float32)
time = 28560	action = 0	current_phase = 0	next_phase = 1	reward = 1.001376	array([[ 3.4884658, -9.417223 ]], dtype=float32)
time = 28565	action = 0	current_phase = 0	next_phase = 1	reward = 0.440267	array([[ 3.6224418, -9.362274 ]], dtype=float32)
time = 28570	action = 0	current_phase = 0	next_phase = 1	reward = 1.007306	array([[ 3.6023784, -9.5206375]], dtype=float32)
time = 28575	action = 0	current_phase = 0	next_phase = 1	reward = 0.725510	array([[ 3.6065412, -9.480869 ]], dtype=float32)
time = 28580	action = 0	current_phase = 0	next_phase = 1	reward = 0.728323	array([[ 3.5213284, -9.384956 ]], dtype=float32)
time = 28585	action = 0	current_phase = 0	next_phase = 1	reward = 0.451500	array([[ 3.590715, -9.358054]], dtype=float32)
time = 28590	action = 0	current_phase = 0	next_phase = 1	reward = 0.988574	array([[ 3.4581733, -9.544931 ]], dtype=float32)
time = 28595	action = 0	current_phase = 0	next_phase = 1	reward = 0.162496	array([[ 3.5908208, -9.356649 ]], dtype=float32)
time = 28600	action = 0	current_phase = 0	next_phase = 1	reward = 1.286059	array([[ 3.6096778, -9.507389 ]], dtype=float32)
time = 28605	action = 0	current_phase = 0	next_phase = 1	reward = 0.719379	array([[ 3.599152 , -9.3812895]], dtype=float32)
time = 28610	action = 0	current_phase = 0	next_phase = 1	reward = 0.443656	array([[ 3.6020856, -9.386932 ]], dtype=float32)
time = 28615	action = 0	current_phase = 0	next_phase = 1	reward = 1.005730	array([[ 3.5740666, -9.444614 ]], dtype=float32)
time = 28620	action = 0	current_phase = 0	next_phase = 1	reward = 0.718110	array([[ 3.5761647, -9.354702 ]], dtype=float32)
time = 28625	action = 0	current_phase = 0	next_phase = 1	reward = 0.445993	array([[ 3.585546, -9.333466]], dtype=float32)
time = 28630	action = 0	current_phase = 0	next_phase = 1	reward = 1.007631	array([[ 3.5991397, -9.438458 ]], dtype=float32)
time = 28635	action = 0	current_phase = 0	next_phase = 1	reward = 0.443452	array([[ 3.6739402, -9.408928 ]], dtype=float32)
time = 28640	action = 0	current_phase = 0	next_phase = 1	reward = 1.009379	array([[ 3.6042743, -9.313858 ]], dtype=float32)
time = 28645	action = 0	current_phase = 0	next_phase = 1	reward = 0.716923	array([[ 3.5855432, -9.393441 ]], dtype=float32)
time = 28650	action = 0	current_phase = 0	next_phase = 1	reward = 0.718886	array([[ 3.608231, -9.402046]], dtype=float32)
time = 28655	action = 0	current_phase = 0	next_phase = 1	reward = 0.726474	array([[ 3.5909266, -9.330278 ]], dtype=float32)
time = 28660	action = 0	current_phase = 0	next_phase = 1	reward = 0.725995	array([[ 3.59685 , -9.425122]], dtype=float32)
time = 28665	action = 0	current_phase = 0	next_phase = 1	reward = 0.721438	array([[ 3.6654658, -9.450099 ]], dtype=float32)
time = 28670	action = 0	current_phase = 0	next_phase = 1	reward = 0.715868	array([[ 3.5378995, -9.359978 ]], dtype=float32)
time = 28675	action = 0	current_phase = 0	next_phase = 1	reward = 0.435798	array([[ 3.6531615, -9.335082 ]], dtype=float32)
time = 28680	action = 0	current_phase = 0	next_phase = 1	reward = 1.001439	array([[ 3.5416446, -9.563761 ]], dtype=float32)
time = 28685	action = 0	current_phase = 0	next_phase = 1	reward = 0.443936	array([[ 3.597363, -9.408039]], dtype=float32)
time = 28690	action = 0	current_phase = 0	next_phase = 1	reward = 1.009837	array([[ 3.5617986, -9.428997 ]], dtype=float32)
time = 28695	action = 0	current_phase = 0	next_phase = 1	reward = 0.720846	array([[ 3.6081815, -9.291187 ]], dtype=float32)
time = 28700	action = 0	current_phase = 0	next_phase = 1	reward = 0.443457	array([[ 3.6306472, -9.3824005]], dtype=float32)
time = 28705	action = 0	current_phase = 0	next_phase = 1	reward = 1.001353	array([[ 3.632505, -9.401184]], dtype=float32)
time = 28710	action = 0	current_phase = 0	next_phase = 1	reward = 0.718489	array([[ 3.7099433, -9.513561 ]], dtype=float32)
time = 28715	action = 0	current_phase = 0	next_phase = 1	reward = 0.716633	array([[ 3.5789123, -9.3860035]], dtype=float32)
time = 28720	action = 0	current_phase = 0	next_phase = 1	reward = 0.446902	array([[ 3.645493, -9.345046]], dtype=float32)
time = 28725	action = 0	current_phase = 0	next_phase = 1	reward = 1.000071	array([[ 3.5215669, -9.468264 ]], dtype=float32)
time = 28730	action = 0	current_phase = 0	next_phase = 1	reward = 0.447919	array([[ 3.5416398, -9.419511 ]], dtype=float32)
time = 28735	action = 0	current_phase = 0	next_phase = 1	reward = 1.003326	array([[ 3.5794911, -9.53101  ]], dtype=float32)
time = 28740	action = 0	current_phase = 0	next_phase = 1	reward = 0.440624	array([[ 3.5676274, -9.384062 ]], dtype=float32)
time = 28745	action = 0	current_phase = 0	next_phase = 1	reward = 0.725228	array([[ 3.6220107, -9.32621  ]], dtype=float32)
time = 28750	action = 0	current_phase = 0	next_phase = 1	reward = 1.008841	array([[ 3.5460505, -9.520601 ]], dtype=float32)
time = 28755	action = 0	current_phase = 0	next_phase = 1	reward = 0.725927	array([[ 3.577026, -9.457638]], dtype=float32)
time = 28760	action = 0	current_phase = 0	next_phase = 1	reward = 0.444082	array([[ 3.6168504, -9.465466 ]], dtype=float32)
time = 28765	action = 0	current_phase = 0	next_phase = 1	reward = 1.004942	array([[ 3.5593524, -9.428362 ]], dtype=float32)
time = 28770	action = 0	current_phase = 0	next_phase = 1	reward = 0.444557	array([[ 3.6216836, -9.289019 ]], dtype=float32)
time = 28775	action = 0	current_phase = 0	next_phase = 1	reward = 1.005463	array([[ 3.5903525, -9.364274 ]], dtype=float32)
time = 28780	action = 0	current_phase = 0	next_phase = 1	reward = 0.725336	array([[ 3.572291, -9.322376]], dtype=float32)
time = 28785	action = 0	current_phase = 0	next_phase = 1	reward = 0.719757	array([[ 3.629951, -9.464983]], dtype=float32)
time = 28790	action = 0	current_phase = 0	next_phase = 1	reward = 0.722080	array([[ 3.5645394, -9.347273 ]], dtype=float32)
time = 28795	action = 0	current_phase = 0	next_phase = 1	reward = 0.722410	array([[ 3.586615, -9.340282]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.6266 - val_loss: 3.8764
Epoch 2/50
 - 4s - loss: 3.9498 - val_loss: 3.7377
Epoch 3/50
 - 4s - loss: 3.4840 - val_loss: 3.3699
Epoch 4/50
 - 4s - loss: 4.0102 - val_loss: 3.1668
Epoch 5/50
 - 4s - loss: 4.1496 - val_loss: 4.4982
Epoch 6/50
 - 4s - loss: 3.2329 - val_loss: 5.1265
Epoch 7/50
 - 4s - loss: 4.3672 - val_loss: 3.6241
Epoch 8/50
 - 4s - loss: 3.1231 - val_loss: 3.6335
Epoch 9/50
 - 4s - loss: 4.6412 - val_loss: 4.1901
Epoch 10/50
 - 4s - loss: 3.8908 - val_loss: 4.0045
Epoch 11/50
 - 4s - loss: 5.5928 - val_loss: 2.9110
Epoch 12/50
 - 4s - loss: 4.4765 - val_loss: 3.6870
Epoch 13/50
 - 4s - loss: 3.7033 - val_loss: 2.8252
Epoch 14/50
 - 4s - loss: 3.2643 - val_loss: 3.1312
Epoch 15/50
 - 4s - loss: 5.6711 - val_loss: 4.2498
Epoch 16/50
 - 4s - loss: 3.6937 - val_loss: 4.2607
Epoch 17/50
 - 4s - loss: 3.9810 - val_loss: 4.2691
Epoch 18/50
 - 4s - loss: 4.1229 - val_loss: 3.1001
Epoch 19/50
 - 4s - loss: 4.6003 - val_loss: 3.3051
Epoch 20/50
 - 4s - loss: 6.4301 - val_loss: 3.4330
Epoch 21/50
 - 4s - loss: 4.3620 - val_loss: 4.0412
Epoch 22/50
 - 4s - loss: 3.5078 - val_loss: 3.8760
Epoch 23/50
 - 4s - loss: 4.5013 - val_loss: 3.7150
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 28800	action = 0	current_phase = 0	next_phase = 1	reward = 0.718309	array([[ 3.6224828, -9.313991 ]], dtype=float32)
time = 28805	action = 0	current_phase = 0	next_phase = 1	reward = 0.724039	array([[ 3.6438308, -9.30669  ]], dtype=float32)
time = 28810	action = 0	current_phase = 0	next_phase = 1	reward = 0.451926	array([[ 3.6989179, -9.363293 ]], dtype=float32)
time = 28815	action = 0	current_phase = 0	next_phase = 1	reward = 1.007329	array([[ 3.6138663, -9.324863 ]], dtype=float32)
time = 28820	action = 0	current_phase = 0	next_phase = 1	reward = 0.442806	array([[ 3.6326852, -9.32877  ]], dtype=float32)
time = 28825	action = 0	current_phase = 0	next_phase = 1	reward = 1.001214	array([[ 3.6157393, -9.299181 ]], dtype=float32)
time = 28830	action = 0	current_phase = 0	next_phase = 1	reward = 0.437121	array([[ 3.6443095, -9.292028 ]], dtype=float32)
time = 28835	action = 0	current_phase = 0	next_phase = 1	reward = 0.993011	array([[ 3.6571584, -9.348297 ]], dtype=float32)
time = 28840	action = 0	current_phase = 0	next_phase = 1	reward = 0.721561	array([[ 3.6009145, -9.32229  ]], dtype=float32)
time = 28845	action = 0	current_phase = 0	next_phase = 1	reward = 0.446926	array([[ 3.6450725, -9.2684355]], dtype=float32)
time = 28850	action = 0	current_phase = 0	next_phase = 1	reward = 1.012132	array([[ 3.6364408, -9.29221  ]], dtype=float32)
time = 28855	action = 0	current_phase = 0	next_phase = 1	reward = 0.722271	array([[ 3.6340175, -9.284226 ]], dtype=float32)
time = 28860	action = 0	current_phase = 0	next_phase = 1	reward = 0.722609	array([[ 3.6427627, -9.278743 ]], dtype=float32)
time = 28865	action = 0	current_phase = 0	next_phase = 1	reward = 0.715256	array([[ 3.6883512, -9.367788 ]], dtype=float32)
time = 28870	action = 0	current_phase = 0	next_phase = 1	reward = 0.444023	array([[ 3.6573987, -9.345569 ]], dtype=float32)
time = 28875	action = 0	current_phase = 0	next_phase = 1	reward = 1.011701	array([[ 3.6296678, -9.414507 ]], dtype=float32)
time = 28880	action = 0	current_phase = 0	next_phase = 1	reward = 0.729160	array([[ 3.6965823, -9.39363  ]], dtype=float32)
time = 28885	action = 0	current_phase = 0	next_phase = 1	reward = 0.445581	array([[ 3.6328378, -9.328899 ]], dtype=float32)
time = 28890	action = 0	current_phase = 0	next_phase = 1	reward = 0.726598	array([[ 3.639914, -9.426304]], dtype=float32)
time = 28895	action = 0	current_phase = 0	next_phase = 1	reward = 0.997892	array([[ 3.6254535, -9.345377 ]], dtype=float32)
time = 28900	action = 0	current_phase = 0	next_phase = 1	reward = 0.711492	array([[ 3.6264548, -9.283791 ]], dtype=float32)
time = 28905	action = 0	current_phase = 0	next_phase = 1	reward = 0.439011	array([[ 3.63335 , -9.258318]], dtype=float32)
time = 28910	action = 0	current_phase = 0	next_phase = 1	reward = 0.743375	array([[ 3.5660968, -9.431105 ]], dtype=float32)
time = 28915	action = 0	current_phase = 0	next_phase = 1	reward = 1.014944	array([[ 3.6368327, -9.302119 ]], dtype=float32)
time = 28920	action = 0	current_phase = 0	next_phase = 1	reward = 0.721062	array([[ 3.6354795, -9.316374 ]], dtype=float32)
time = 28925	action = 0	current_phase = 0	next_phase = 1	reward = 0.710926	array([[ 3.6422238, -9.3272915]], dtype=float32)
time = 28930	action = 0	current_phase = 0	next_phase = 1	reward = 0.444541	array([[ 3.6608787, -9.342567 ]], dtype=float32)
time = 28935	action = 0	current_phase = 0	next_phase = 1	reward = 1.001277	array([[ 3.6193748, -9.258646 ]], dtype=float32)
time = 28940	action = 0	current_phase = 0	next_phase = 1	reward = 0.444945	array([[ 3.6368937, -9.31402  ]], dtype=float32)
time = 28945	action = 0	current_phase = 0	next_phase = 1	reward = 0.718242	array([[ 3.6303105, -9.286218 ]], dtype=float32)
time = 28950	action = 0	current_phase = 0	next_phase = 1	reward = 0.720073	array([[ 3.6798282, -9.304777 ]], dtype=float32)
time = 28955	action = 0	current_phase = 0	next_phase = 1	reward = 0.461333	array([[ 3.6467814, -9.324926 ]], dtype=float32)
time = 28960	action = 0	current_phase = 0	next_phase = 1	reward = 1.012569	array([[ 3.5535474, -9.342133 ]], dtype=float32)
time = 28965	action = 0	current_phase = 0	next_phase = 1	reward = 1.012276	array([[ 3.6230054, -9.358843 ]], dtype=float32)
time = 28970	action = 0	current_phase = 0	next_phase = 1	reward = 0.723283	array([[ 3.6469378, -9.321165 ]], dtype=float32)
time = 28975	action = 0	current_phase = 0	next_phase = 1	reward = 0.722991	array([[ 3.6143146, -9.353417 ]], dtype=float32)
time = 28980	action = 0	current_phase = 0	next_phase = 1	reward = 0.450340	array([[ 3.6625028, -9.314619 ]], dtype=float32)
time = 28985	action = 0	current_phase = 0	next_phase = 1	reward = 1.015428	array([[ 3.6236339, -9.345734 ]], dtype=float32)
time = 28990	action = 0	current_phase = 0	next_phase = 1	reward = 0.721091	array([[ 3.6277595, -9.359011 ]], dtype=float32)
time = 28995	action = 0	current_phase = 0	next_phase = 1	reward = 0.716737	array([[ 3.6206956, -9.3533535]], dtype=float32)
time = 29000	action = 0	current_phase = 0	next_phase = 1	reward = 0.437653	array([[ 3.6260114, -9.325674 ]], dtype=float32)
time = 29005	action = 0	current_phase = 0	next_phase = 1	reward = 0.998455	array([[ 3.6488776, -9.325954 ]], dtype=float32)
time = 29010	action = 0	current_phase = 0	next_phase = 1	reward = 0.443967	array([[ 3.635388 , -9.3677845]], dtype=float32)
time = 29015	action = 0	current_phase = 0	next_phase = 1	reward = 1.003454	array([[ 3.6287255, -9.306776 ]], dtype=float32)
time = 29020	action = 0	current_phase = 0	next_phase = 1	reward = 0.448376	array([[ 3.6561627, -9.267738 ]], dtype=float32)
time = 29025	action = 0	current_phase = 0	next_phase = 1	reward = 1.009212	array([[ 3.6486735, -9.359132 ]], dtype=float32)
time = 29030	action = 0	current_phase = 0	next_phase = 1	reward = 0.715594	array([[ 3.6341329, -9.369642 ]], dtype=float32)
time = 29035	action = 0	current_phase = 0	next_phase = 1	reward = 0.441659	array([[ 3.6109214, -9.329103 ]], dtype=float32)
time = 29040	action = 0	current_phase = 0	next_phase = 1	reward = 1.003775	array([[ 3.617125, -9.319638]], dtype=float32)
time = 29045	action = 0	current_phase = 0	next_phase = 1	reward = 0.724893	array([[ 3.64928 , -9.323467]], dtype=float32)
time = 29050	action = 0	current_phase = 0	next_phase = 1	reward = 0.441106	array([[ 3.6475158, -9.322409 ]], dtype=float32)
time = 29055	action = 0	current_phase = 0	next_phase = 1	reward = 0.998869	array([[ 3.5957608, -9.41054  ]], dtype=float32)
time = 29060	action = 0	current_phase = 0	next_phase = 1	reward = 0.436077	array([[ 3.653397, -9.276926]], dtype=float32)
time = 29065	action = 0	current_phase = 0	next_phase = 1	reward = 0.443754	array([[ 3.6193833, -9.318323 ]], dtype=float32)
time = 29070	action = 0	current_phase = 0	next_phase = 1	reward = 1.279915	array([[ 3.6113925, -9.307541 ]], dtype=float32)
time = 29075	action = 0	current_phase = 0	next_phase = 1	reward = 0.446698	array([[ 3.6332297, -9.347892 ]], dtype=float32)
time = 29080	action = 0	current_phase = 0	next_phase = 1	reward = 0.448387	array([[ 3.6174932, -9.3212385]], dtype=float32)
time = 29085	action = 0	current_phase = 0	next_phase = 1	reward = 1.286991	array([[ 3.6134715, -9.459591 ]], dtype=float32)
time = 29090	action = 0	current_phase = 0	next_phase = 1	reward = 0.441561	array([[ 3.6135345, -9.334606 ]], dtype=float32)
time = 29095	action = 0	current_phase = 0	next_phase = 1	reward = 1.001527	array([[ 3.6348042, -9.32422  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.9971 - val_loss: 1.3705
Epoch 2/50
 - 4s - loss: 4.8530 - val_loss: 2.1841
Epoch 3/50
 - 4s - loss: 5.4938 - val_loss: 1.6549
Epoch 4/50
 - 4s - loss: 5.0980 - val_loss: 1.2234
Epoch 5/50
 - 4s - loss: 4.5093 - val_loss: 1.3885
Epoch 6/50
 - 4s - loss: 4.2157 - val_loss: 1.4245
Epoch 7/50
 - 4s - loss: 3.7883 - val_loss: 1.8701
Epoch 8/50
 - 4s - loss: 6.4073 - val_loss: 2.4639
Epoch 9/50
 - 4s - loss: 4.0314 - val_loss: 1.2667
Epoch 10/50
 - 4s - loss: 3.9638 - val_loss: 1.4630
Epoch 11/50
 - 4s - loss: 5.1513 - val_loss: 1.2892
Epoch 12/50
 - 4s - loss: 3.5223 - val_loss: 2.5151
Epoch 13/50
 - 4s - loss: 4.4948 - val_loss: 1.3318
Epoch 14/50
 - 4s - loss: 5.5274 - val_loss: 1.5044
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 29100	action = 0	current_phase = 0	next_phase = 1	reward = 0.718429	array([[ 3.570455, -9.267373]], dtype=float32)
time = 29105	action = 0	current_phase = 0	next_phase = 1	reward = 0.716482	array([[ 3.6133647, -9.352822 ]], dtype=float32)
time = 29110	action = 0	current_phase = 0	next_phase = 1	reward = 0.715169	array([[ 3.506267 , -9.3204365]], dtype=float32)
time = 29115	action = 0	current_phase = 0	next_phase = 1	reward = 0.447770	array([[ 3.5670505, -9.320189 ]], dtype=float32)
time = 29120	action = 0	current_phase = 0	next_phase = 1	reward = 1.008149	array([[ 3.5504537, -9.288357 ]], dtype=float32)
time = 29125	action = 0	current_phase = 0	next_phase = 1	reward = 0.443032	array([[ 3.596129, -9.261368]], dtype=float32)
time = 29130	action = 0	current_phase = 0	next_phase = 1	reward = 0.995199	array([[ 3.5608506, -9.352976 ]], dtype=float32)
time = 29135	action = 0	current_phase = 0	next_phase = 1	reward = 0.442004	array([[ 3.603479, -9.297173]], dtype=float32)
time = 29140	action = 0	current_phase = 0	next_phase = 1	reward = 0.720191	array([[ 3.5807328, -9.32021  ]], dtype=float32)
time = 29145	action = 0	current_phase = 0	next_phase = 1	reward = 0.731985	array([[ 3.5966601, -9.304149 ]], dtype=float32)
time = 29150	action = 0	current_phase = 0	next_phase = 1	reward = 1.001575	array([[ 3.6088195, -9.26026  ]], dtype=float32)
time = 29155	action = 0	current_phase = 0	next_phase = 1	reward = 0.439578	array([[ 3.5835319, -9.269537 ]], dtype=float32)
time = 29160	action = 0	current_phase = 0	next_phase = 1	reward = 1.000339	array([[ 3.5528827, -9.323547 ]], dtype=float32)
time = 29165	action = 0	current_phase = 0	next_phase = 1	reward = 0.724950	array([[ 3.5659509, -9.240578 ]], dtype=float32)
time = 29170	action = 0	current_phase = 0	next_phase = 1	reward = 0.448976	array([[ 3.590631, -9.314096]], dtype=float32)
time = 29175	action = 0	current_phase = 0	next_phase = 1	reward = 1.000407	array([[ 3.5387025, -9.427265 ]], dtype=float32)
time = 29180	action = 0	current_phase = 0	next_phase = 1	reward = 0.438243	array([[ 3.5868182, -9.2985935]], dtype=float32)
time = 29185	action = 0	current_phase = 0	next_phase = 1	reward = 1.000388	array([[ 3.574823, -9.229633]], dtype=float32)
time = 29190	action = 0	current_phase = 0	next_phase = 1	reward = 0.446180	array([[ 3.5754867, -9.359312 ]], dtype=float32)
time = 29195	action = 0	current_phase = 0	next_phase = 1	reward = 0.725992	array([[ 3.5673642, -9.36833  ]], dtype=float32)
time = 29200	action = 0	current_phase = 0	next_phase = 1	reward = 0.999983	array([[ 3.5517268, -9.344984 ]], dtype=float32)
time = 29205	action = 0	current_phase = 0	next_phase = 1	reward = 0.713624	array([[ 3.5671115, -9.264387 ]], dtype=float32)
time = 29210	action = 0	current_phase = 0	next_phase = 1	reward = 0.441602	array([[ 3.5783992, -9.310733 ]], dtype=float32)
time = 29215	action = 0	current_phase = 0	next_phase = 1	reward = 0.725242	array([[ 3.5289817, -9.38921  ]], dtype=float32)
time = 29220	action = 0	current_phase = 0	next_phase = 1	reward = 1.017189	array([[ 3.589913, -9.270288]], dtype=float32)
time = 29225	action = 0	current_phase = 0	next_phase = 1	reward = 0.452542	array([[ 3.5903354, -9.313019 ]], dtype=float32)
time = 29230	action = 0	current_phase = 0	next_phase = 1	reward = 1.004896	array([[ 3.537991, -9.435167]], dtype=float32)
time = 29235	action = 0	current_phase = 0	next_phase = 1	reward = 0.716470	array([[ 3.5866838, -9.255287 ]], dtype=float32)
time = 29240	action = 0	current_phase = 0	next_phase = 1	reward = 0.436874	array([[ 3.6108775, -9.2455635]], dtype=float32)
time = 29245	action = 0	current_phase = 0	next_phase = 1	reward = 0.723951	array([[ 3.5599036, -9.343494 ]], dtype=float32)
time = 29250	action = 0	current_phase = 0	next_phase = 1	reward = 0.731348	array([[ 3.540954, -9.318791]], dtype=float32)
time = 29255	action = 0	current_phase = 0	next_phase = 1	reward = 0.727699	array([[ 3.5472255, -9.405537 ]], dtype=float32)
time = 29260	action = 0	current_phase = 0	next_phase = 1	reward = 1.008416	array([[ 3.5655951, -9.368095 ]], dtype=float32)
time = 29265	action = 0	current_phase = 0	next_phase = 1	reward = 0.726209	array([[ 3.5713754, -9.276278 ]], dtype=float32)
time = 29270	action = 0	current_phase = 0	next_phase = 1	reward = 0.728130	array([[ 3.5918546, -9.327735 ]], dtype=float32)
time = 29275	action = 0	current_phase = 0	next_phase = 1	reward = 0.726049	array([[ 3.5823607, -9.337715 ]], dtype=float32)
time = 29280	action = 0	current_phase = 0	next_phase = 1	reward = 0.717060	array([[ 3.5502524, -9.333162 ]], dtype=float32)
time = 29285	action = 0	current_phase = 0	next_phase = 1	reward = 0.717969	array([[ 3.5585256, -9.34613  ]], dtype=float32)
time = 29290	action = 0	current_phase = 0	next_phase = 1	reward = 0.717462	array([[ 3.5967994, -9.256448 ]], dtype=float32)
time = 29295	action = 0	current_phase = 0	next_phase = 1	reward = 0.726179	array([[ 3.6119094, -9.2692995]], dtype=float32)
time = 29300	action = 0	current_phase = 0	next_phase = 1	reward = 0.449785	array([[ 3.5640273, -9.255882 ]], dtype=float32)
time = 29305	action = 0	current_phase = 0	next_phase = 1	reward = 0.729183	array([[ 3.545772, -9.31144 ]], dtype=float32)
time = 29310	action = 0	current_phase = 0	next_phase = 1	reward = 1.000460	array([[ 3.5874639, -9.265232 ]], dtype=float32)
time = 29315	action = 0	current_phase = 0	next_phase = 1	reward = 0.726288	array([[ 3.576095, -9.304192]], dtype=float32)
time = 29320	action = 0	current_phase = 0	next_phase = 1	reward = 0.727955	array([[ 3.5246634, -9.342724 ]], dtype=float32)
time = 29325	action = 0	current_phase = 0	next_phase = 1	reward = 0.444106	array([[ 3.6022553, -9.218702 ]], dtype=float32)
time = 29330	action = 0	current_phase = 0	next_phase = 1	reward = 1.004642	array([[ 3.6009479, -9.284362 ]], dtype=float32)
time = 29335	action = 0	current_phase = 0	next_phase = 1	reward = 0.721389	array([[ 3.6167789, -9.240889 ]], dtype=float32)
time = 29340	action = 0	current_phase = 0	next_phase = 1	reward = 0.434915	array([[ 3.58713 , -9.290024]], dtype=float32)
time = 29345	action = 0	current_phase = 0	next_phase = 1	reward = 0.727040	array([[ 3.5816073, -9.246785 ]], dtype=float32)
time = 29350	action = 0	current_phase = 0	next_phase = 1	reward = 0.998727	array([[ 3.5579581, -9.283198 ]], dtype=float32)
time = 29355	action = 0	current_phase = 0	next_phase = 1	reward = 0.724165	array([[ 3.5174375, -9.329868 ]], dtype=float32)
time = 29360	action = 0	current_phase = 0	next_phase = 1	reward = 0.436257	array([[ 3.5898318, -9.291103 ]], dtype=float32)
time = 29365	action = 0	current_phase = 0	next_phase = 1	reward = 1.006682	array([[ 3.5584693, -9.372194 ]], dtype=float32)
time = 29370	action = 0	current_phase = 0	next_phase = 1	reward = 0.720796	array([[ 3.5609336, -9.275007 ]], dtype=float32)
time = 29375	action = 0	current_phase = 0	next_phase = 1	reward = 0.162926	array([[ 3.566113, -9.306784]], dtype=float32)
time = 29380	action = 0	current_phase = 0	next_phase = 1	reward = 1.283819	array([[ 3.5728908, -9.312195 ]], dtype=float32)
time = 29385	action = 0	current_phase = 0	next_phase = 1	reward = 0.718814	array([[ 3.611421, -9.275314]], dtype=float32)
time = 29390	action = 0	current_phase = 0	next_phase = 1	reward = 0.726752	array([[ 3.540298, -9.250641]], dtype=float32)
time = 29395	action = 0	current_phase = 0	next_phase = 1	reward = 0.443636	array([[ 3.6015353, -9.224837 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.6911 - val_loss: 3.5291
Epoch 2/50
 - 4s - loss: 4.4421 - val_loss: 1.9688
Epoch 3/50
 - 4s - loss: 5.8043 - val_loss: 1.7043
Epoch 4/50
 - 5s - loss: 4.7400 - val_loss: 2.3414
Epoch 5/50
 - 5s - loss: 5.7107 - val_loss: 1.7176
Epoch 6/50
 - 5s - loss: 4.6466 - val_loss: 2.5887
Epoch 7/50
 - 5s - loss: 6.4722 - val_loss: 2.0200
Epoch 8/50
 - 5s - loss: 5.6302 - val_loss: 1.9866
Epoch 9/50
 - 5s - loss: 5.5030 - val_loss: 1.8440
Epoch 10/50
 - 4s - loss: 4.2282 - val_loss: 2.1918
Epoch 11/50
 - 4s - loss: 4.1086 - val_loss: 2.2018
Epoch 12/50
 - 4s - loss: 5.0982 - val_loss: 2.1926
Epoch 13/50
 - 6s - loss: 3.0382 - val_loss: 3.6579
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 29400	action = 0	current_phase = 0	next_phase = 1	reward = 0.722747	array([[ 3.5547433, -9.473168 ]], dtype=float32)
time = 29405	action = 0	current_phase = 0	next_phase = 1	reward = 1.000460	array([[ 3.6000066, -9.275912 ]], dtype=float32)
time = 29410	action = 0	current_phase = 0	next_phase = 1	reward = 0.713442	array([[ 3.5672784, -9.371416 ]], dtype=float32)
time = 29415	action = 0	current_phase = 0	next_phase = 1	reward = 0.714755	array([[ 3.6798959, -9.315113 ]], dtype=float32)
time = 29420	action = 0	current_phase = 0	next_phase = 1	reward = 0.726239	array([[ 3.6405406, -9.2755785]], dtype=float32)
time = 29425	action = 0	current_phase = 0	next_phase = 1	reward = 0.445432	array([[ 3.6221251, -9.28791  ]], dtype=float32)
time = 29430	action = 0	current_phase = 0	next_phase = 1	reward = 0.725097	array([[ 3.5347075, -9.423895 ]], dtype=float32)
time = 29435	action = 0	current_phase = 0	next_phase = 1	reward = 1.006098	array([[ 3.6158843, -9.368962 ]], dtype=float32)
time = 29440	action = 0	current_phase = 0	next_phase = 1	reward = 0.443642	array([[ 3.6436124, -9.250404 ]], dtype=float32)
time = 29445	action = 0	current_phase = 0	next_phase = 1	reward = 1.011124	array([[ 3.5765185, -9.352912 ]], dtype=float32)
time = 29450	action = 0	current_phase = 0	next_phase = 1	reward = 0.721130	array([[ 3.623837, -9.288202]], dtype=float32)
time = 29455	action = 0	current_phase = 0	next_phase = 1	reward = 0.727632	array([[ 3.5455232, -9.419348 ]], dtype=float32)
time = 29460	action = 0	current_phase = 0	next_phase = 1	reward = 0.721270	array([[ 3.6546836, -9.266293 ]], dtype=float32)
time = 29465	action = 0	current_phase = 0	next_phase = 1	reward = 0.725901	array([[ 3.5214696, -9.425001 ]], dtype=float32)
time = 29470	action = 0	current_phase = 0	next_phase = 1	reward = 0.718339	array([[ 3.6323247, -9.34408  ]], dtype=float32)
time = 29475	action = 0	current_phase = 0	next_phase = 1	reward = 0.714018	array([[ 3.580214, -9.359297]], dtype=float32)
time = 29480	action = 0	current_phase = 0	next_phase = 1	reward = 0.436113	array([[ 3.6419778, -9.2964   ]], dtype=float32)
time = 29485	action = 0	current_phase = 0	next_phase = 1	reward = 0.999449	array([[ 3.5420995, -9.451778 ]], dtype=float32)
time = 29490	action = 0	current_phase = 0	next_phase = 1	reward = 0.719556	array([[ 3.557879, -9.314896]], dtype=float32)
time = 29495	action = 0	current_phase = 0	next_phase = 1	reward = 0.718465	array([[ 3.612144, -9.35594 ]], dtype=float32)
time = 29500	action = 0	current_phase = 0	next_phase = 1	reward = 0.721740	array([[ 3.6377568, -9.305205 ]], dtype=float32)
time = 29505	action = 0	current_phase = 0	next_phase = 1	reward = 0.438896	array([[ 3.650494, -9.324803]], dtype=float32)
time = 29510	action = 0	current_phase = 0	next_phase = 1	reward = 0.998545	array([[ 3.6346564, -9.298768 ]], dtype=float32)
time = 29515	action = 0	current_phase = 0	next_phase = 1	reward = 0.725177	array([[ 3.5728955, -9.427446 ]], dtype=float32)
time = 29520	action = 0	current_phase = 0	next_phase = 1	reward = 0.721460	array([[ 3.6162858, -9.348858 ]], dtype=float32)
time = 29525	action = 0	current_phase = 0	next_phase = 1	reward = 0.725218	array([[ 3.5915427, -9.319297 ]], dtype=float32)
time = 29530	action = 0	current_phase = 0	next_phase = 1	reward = 0.455975	array([[ 3.6179833, -9.322361 ]], dtype=float32)
time = 29535	action = 0	current_phase = 0	next_phase = 1	reward = 0.726077	array([[ 3.6000714, -9.428776 ]], dtype=float32)
time = 29540	action = 0	current_phase = 0	next_phase = 1	reward = 1.003337	array([[ 3.6451497, -9.38525  ]], dtype=float32)
time = 29545	action = 0	current_phase = 0	next_phase = 1	reward = 0.436844	array([[ 3.6064258, -9.243643 ]], dtype=float32)
time = 29550	action = 0	current_phase = 0	next_phase = 1	reward = 1.010489	array([[ 3.581924, -9.346402]], dtype=float32)
time = 29555	action = 0	current_phase = 0	next_phase = 1	reward = 0.723077	array([[ 3.6357732, -9.334124 ]], dtype=float32)
time = 29560	action = 0	current_phase = 0	next_phase = 1	reward = 0.442971	array([[ 3.6024795, -9.310123 ]], dtype=float32)
time = 29565	action = 0	current_phase = 0	next_phase = 1	reward = 1.002566	array([[ 3.5999284, -9.29579  ]], dtype=float32)
time = 29570	action = 0	current_phase = 0	next_phase = 1	reward = 0.726979	array([[ 3.6583362, -9.274544 ]], dtype=float32)
time = 29575	action = 0	current_phase = 0	next_phase = 1	reward = 0.720259	array([[ 3.6708684, -9.27318  ]], dtype=float32)
time = 29580	action = 0	current_phase = 0	next_phase = 1	reward = 0.724658	array([[ 3.6265569, -9.392124 ]], dtype=float32)
time = 29585	action = 0	current_phase = 0	next_phase = 1	reward = 0.732674	array([[ 3.6258569, -9.243334 ]], dtype=float32)
time = 29590	action = 0	current_phase = 0	next_phase = 1	reward = 0.728743	array([[ 3.5712466, -9.321301 ]], dtype=float32)
time = 29595	action = 0	current_phase = 0	next_phase = 1	reward = 0.728423	array([[ 3.651527, -9.318614]], dtype=float32)
time = 29600	action = 0	current_phase = 0	next_phase = 1	reward = 0.724643	array([[ 3.624105, -9.282203]], dtype=float32)
time = 29605	action = 0	current_phase = 0	next_phase = 1	reward = 0.723041	array([[ 3.5790238, -9.305517 ]], dtype=float32)
time = 29610	action = 0	current_phase = 0	next_phase = 1	reward = 0.718177	array([[ 3.6406045, -9.232482 ]], dtype=float32)
time = 29615	action = 0	current_phase = 0	next_phase = 1	reward = 0.437480	array([[ 3.638988, -9.270083]], dtype=float32)
time = 29620	action = 0	current_phase = 0	next_phase = 1	reward = 1.003116	array([[ 3.6449065, -9.306484 ]], dtype=float32)
time = 29625	action = 0	current_phase = 0	next_phase = 1	reward = 0.715252	array([[ 3.5754285, -9.355528 ]], dtype=float32)
time = 29630	action = 0	current_phase = 0	next_phase = 1	reward = 0.442193	array([[ 3.4365048, -9.483639 ]], dtype=float32)
time = 29635	action = 0	current_phase = 0	next_phase = 1	reward = 0.451160	array([[ 3.638698, -9.295534]], dtype=float32)
time = 29640	action = 0	current_phase = 0	next_phase = 1	reward = 1.286727	array([[ 3.5192513, -9.381807 ]], dtype=float32)
time = 29645	action = 0	current_phase = 0	next_phase = 1	reward = 0.708731	array([[ 3.6117406, -9.287883 ]], dtype=float32)
time = 29650	action = 0	current_phase = 0	next_phase = 1	reward = 0.716531	array([[ 3.622519, -9.301435]], dtype=float32)
time = 29655	action = 0	current_phase = 0	next_phase = 1	reward = 0.723932	array([[ 3.6188722, -9.254532 ]], dtype=float32)
time = 29660	action = 0	current_phase = 0	next_phase = 1	reward = 0.440688	array([[ 3.6129403, -9.312006 ]], dtype=float32)
time = 29665	action = 0	current_phase = 0	next_phase = 1	reward = 1.010364	array([[ 3.6412616, -9.3016205]], dtype=float32)
time = 29670	action = 0	current_phase = 0	next_phase = 1	reward = 0.710468	array([[ 3.6645684, -9.249489 ]], dtype=float32)
time = 29675	action = 0	current_phase = 0	next_phase = 1	reward = 0.715767	array([[ 3.60074 , -9.351874]], dtype=float32)
time = 29680	action = 0	current_phase = 0	next_phase = 1	reward = 0.164809	array([[ 3.5157638, -9.340948 ]], dtype=float32)
time = 29685	action = 0	current_phase = 0	next_phase = 1	reward = 1.007774	array([[ 3.5967116, -9.357013 ]], dtype=float32)
time = 29690	action = 0	current_phase = 0	next_phase = 1	reward = 1.001152	array([[ 3.6041808, -9.406517 ]], dtype=float32)
time = 29695	action = 0	current_phase = 0	next_phase = 1	reward = 0.719987	array([[ 3.6466584, -9.289099 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.4826 - val_loss: 1.9243
Epoch 2/50
 - 4s - loss: 4.8456 - val_loss: 1.8389
Epoch 3/50
 - 4s - loss: 5.4957 - val_loss: 2.2380
Epoch 4/50
 - 4s - loss: 5.2314 - val_loss: 1.8767
Epoch 5/50
 - 4s - loss: 3.9161 - val_loss: 2.5158
Epoch 6/50
 - 4s - loss: 5.6262 - val_loss: 2.3718
Epoch 7/50
 - 4s - loss: 5.9014 - val_loss: 2.8972
Epoch 8/50
 - 4s - loss: 4.2590 - val_loss: 2.5374
Epoch 9/50
 - 4s - loss: 5.9085 - val_loss: 2.8227
Epoch 10/50
 - 4s - loss: 7.1222 - val_loss: 3.0682
Epoch 11/50
 - 4s - loss: 4.5913 - val_loss: 2.9499
Epoch 12/50
 - 4s - loss: 4.4974 - val_loss: 2.9329
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 29700	action = 0	current_phase = 0	next_phase = 1	reward = 0.713438	array([[ 3.6292667, -9.298599 ]], dtype=float32)
time = 29705	action = 0	current_phase = 0	next_phase = 1	reward = 0.723332	array([[ 3.6713552, -9.316617 ]], dtype=float32)
time = 29710	action = 0	current_phase = 0	next_phase = 1	reward = 0.448924	array([[ 3.6643524, -9.263906 ]], dtype=float32)
time = 29715	action = 0	current_phase = 0	next_phase = 1	reward = 1.010352	array([[ 3.5507221, -9.3440275]], dtype=float32)
time = 29720	action = 0	current_phase = 0	next_phase = 1	reward = 0.445187	array([[ 3.6788626, -9.232166 ]], dtype=float32)
time = 29725	action = 0	current_phase = 0	next_phase = 1	reward = 1.002456	array([[ 3.5833502, -9.401217 ]], dtype=float32)
time = 29730	action = 0	current_phase = 0	next_phase = 1	reward = 0.719594	array([[ 3.6904678, -9.300766 ]], dtype=float32)
time = 29735	action = 0	current_phase = 0	next_phase = 1	reward = 0.717341	array([[ 3.6454153, -9.263296 ]], dtype=float32)
time = 29740	action = 0	current_phase = 0	next_phase = 1	reward = 0.437505	array([[ 3.6542873, -9.292725 ]], dtype=float32)
time = 29745	action = 0	current_phase = 0	next_phase = 1	reward = 1.000509	array([[ 3.6771812, -9.308018 ]], dtype=float32)
time = 29750	action = 0	current_phase = 0	next_phase = 1	reward = 0.716293	array([[ 3.6030025, -9.2623   ]], dtype=float32)
time = 29755	action = 0	current_phase = 0	next_phase = 1	reward = 0.166047	array([[ 3.6389961, -9.202518 ]], dtype=float32)
time = 29760	action = 0	current_phase = 0	next_phase = 1	reward = 0.736609	array([[ 3.617732, -9.35045 ]], dtype=float32)
time = 29765	action = 0	current_phase = 0	next_phase = 1	reward = 1.298377	array([[ 3.6548347, -9.337893 ]], dtype=float32)
time = 29770	action = 0	current_phase = 0	next_phase = 1	reward = 0.723248	array([[ 3.6949892, -9.2826185]], dtype=float32)
time = 29775	action = 0	current_phase = 0	next_phase = 1	reward = 0.440669	array([[ 3.640586, -9.295238]], dtype=float32)
time = 29780	action = 0	current_phase = 0	next_phase = 1	reward = 0.998992	array([[ 3.6097717, -9.318541 ]], dtype=float32)
time = 29785	action = 0	current_phase = 0	next_phase = 1	reward = 0.446598	array([[ 3.6954708, -9.246847 ]], dtype=float32)
time = 29790	action = 0	current_phase = 0	next_phase = 1	reward = 0.723508	array([[ 3.6526709, -9.29599  ]], dtype=float32)
time = 29795	action = 0	current_phase = 0	next_phase = 1	reward = 1.004583	array([[ 3.6216917, -9.257332 ]], dtype=float32)
time = 29800	action = 0	current_phase = 0	next_phase = 1	reward = 0.442323	array([[ 3.659955, -9.23808 ]], dtype=float32)
time = 29805	action = 0	current_phase = 0	next_phase = 1	reward = 0.729810	array([[ 3.621276, -9.384686]], dtype=float32)
time = 29810	action = 0	current_phase = 0	next_phase = 1	reward = 1.005301	array([[ 3.681263, -9.19001 ]], dtype=float32)
time = 29815	action = 0	current_phase = 0	next_phase = 1	reward = 0.721656	array([[ 3.6680536, -9.246187 ]], dtype=float32)
time = 29820	action = 0	current_phase = 0	next_phase = 1	reward = 0.440380	array([[ 3.610098 , -9.2463455]], dtype=float32)
time = 29825	action = 0	current_phase = 0	next_phase = 1	reward = 0.719690	array([[ 3.67842 , -9.252642]], dtype=float32)
time = 29830	action = 0	current_phase = 0	next_phase = 1	reward = 0.996193	array([[ 3.672803, -9.24013 ]], dtype=float32)
time = 29835	action = 0	current_phase = 0	next_phase = 1	reward = 0.436760	array([[ 3.6826572, -9.215683 ]], dtype=float32)
time = 29840	action = 0	current_phase = 0	next_phase = 1	reward = 0.731333	array([[ 3.6181211, -9.372496 ]], dtype=float32)
time = 29845	action = 0	current_phase = 0	next_phase = 1	reward = 1.001298	array([[ 3.5895634, -9.35906  ]], dtype=float32)
time = 29850	action = 0	current_phase = 0	next_phase = 1	reward = 0.717522	array([[ 3.6572008, -9.254101 ]], dtype=float32)
time = 29855	action = 0	current_phase = 0	next_phase = 1	reward = 0.445579	array([[ 3.5906477, -9.263018 ]], dtype=float32)
time = 29860	action = 0	current_phase = 0	next_phase = 1	reward = 0.728875	array([[ 3.6423597, -9.353084 ]], dtype=float32)
time = 29865	action = 0	current_phase = 0	next_phase = 1	reward = 0.999402	array([[ 3.5711937, -9.427338 ]], dtype=float32)
time = 29870	action = 0	current_phase = 0	next_phase = 1	reward = 0.446019	array([[ 3.6624527, -9.294683 ]], dtype=float32)
time = 29875	action = 0	current_phase = 0	next_phase = 1	reward = 1.005868	array([[ 3.6804457, -9.31069  ]], dtype=float32)
time = 29880	action = 0	current_phase = 0	next_phase = 1	reward = 0.727915	array([[ 3.6609879, -9.266035 ]], dtype=float32)
time = 29885	action = 0	current_phase = 0	next_phase = 1	reward = 0.447148	array([[ 3.6642523, -9.186893 ]], dtype=float32)
time = 29890	action = 0	current_phase = 0	next_phase = 1	reward = 0.733013	array([[ 3.6432161, -9.309826 ]], dtype=float32)
time = 29895	action = 0	current_phase = 0	next_phase = 1	reward = 0.999161	array([[ 3.6548195, -9.324865 ]], dtype=float32)
time = 29900	action = 0	current_phase = 0	next_phase = 1	reward = 0.446946	array([[ 3.652895, -9.206538]], dtype=float32)
time = 29905	action = 0	current_phase = 0	next_phase = 1	reward = 0.730209	array([[ 3.6697083, -9.2258625]], dtype=float32)
time = 29910	action = 0	current_phase = 0	next_phase = 1	reward = 1.005510	array([[ 3.6207485, -9.353137 ]], dtype=float32)
time = 29915	action = 0	current_phase = 0	next_phase = 1	reward = 0.722837	array([[ 3.7047138, -9.296292 ]], dtype=float32)
time = 29920	action = 0	current_phase = 0	next_phase = 1	reward = 0.724237	array([[ 3.654292, -9.24353 ]], dtype=float32)
time = 29925	action = 0	current_phase = 0	next_phase = 1	reward = 0.725583	array([[ 3.632244, -9.285519]], dtype=float32)
time = 29930	action = 0	current_phase = 0	next_phase = 1	reward = 0.730560	array([[ 3.6731253, -9.319868 ]], dtype=float32)
time = 29935	action = 0	current_phase = 0	next_phase = 1	reward = 0.726867	array([[ 3.6122074, -9.28023  ]], dtype=float32)
time = 29940	action = 0	current_phase = 0	next_phase = 1	reward = 0.716085	array([[ 3.599474, -9.319538]], dtype=float32)
time = 29945	action = 0	current_phase = 0	next_phase = 1	reward = 0.711572	array([[ 3.6696796, -9.269319 ]], dtype=float32)
time = 29950	action = 0	current_phase = 0	next_phase = 1	reward = 0.439606	array([[ 3.6104097, -9.2859535]], dtype=float32)
time = 29955	action = 0	current_phase = 0	next_phase = 1	reward = 0.448259	array([[ 3.6846113, -9.2302265]], dtype=float32)
time = 29960	action = 0	current_phase = 0	next_phase = 1	reward = 1.290539	array([[ 3.6351337, -9.307747 ]], dtype=float32)
time = 29965	action = 0	current_phase = 0	next_phase = 1	reward = 0.716919	array([[ 3.6035376, -9.252852 ]], dtype=float32)
time = 29970	action = 0	current_phase = 0	next_phase = 1	reward = 0.718496	array([[ 3.6620932, -9.254366 ]], dtype=float32)
time = 29975	action = 0	current_phase = 0	next_phase = 1	reward = 0.443998	array([[ 3.6513662, -9.274695 ]], dtype=float32)
time = 29980	action = 0	current_phase = 0	next_phase = 1	reward = 1.007786	array([[ 3.6634445, -9.293564 ]], dtype=float32)
time = 29985	action = 0	current_phase = 0	next_phase = 1	reward = 0.724291	array([[ 3.682643, -9.254318]], dtype=float32)
time = 29990	action = 0	current_phase = 0	next_phase = 1	reward = 0.725494	array([[ 3.678937, -9.237878]], dtype=float32)
time = 29995	action = 0	current_phase = 0	next_phase = 1	reward = 0.449132	array([[ 3.613285, -9.30661 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 7.8227 - val_loss: 1.9829
Epoch 2/50
 - 4s - loss: 4.6866 - val_loss: 1.9642
Epoch 3/50
 - 4s - loss: 5.9005 - val_loss: 1.9730
Epoch 4/50
 - 4s - loss: 4.1248 - val_loss: 2.8092
Epoch 5/50
 - 4s - loss: 5.6316 - val_loss: 2.1489
Epoch 6/50
 - 4s - loss: 2.9960 - val_loss: 1.6620
Epoch 7/50
 - 4s - loss: 4.4997 - val_loss: 2.0680
Epoch 8/50
 - 4s - loss: 5.2003 - val_loss: 1.7240
Epoch 9/50
 - 4s - loss: 2.8861 - val_loss: 1.6523
Epoch 10/50
 - 4s - loss: 3.7926 - val_loss: 1.5006
Epoch 11/50
 - 4s - loss: 4.5460 - val_loss: 2.1937
Epoch 12/50
 - 4s - loss: 6.1843 - val_loss: 1.6296
Epoch 13/50
 - 4s - loss: 3.9096 - val_loss: 1.8710
Epoch 14/50
 - 4s - loss: 4.5455 - val_loss: 1.6271
Epoch 15/50
 - 4s - loss: 5.9849 - val_loss: 2.1160
Epoch 16/50
 - 4s - loss: 4.0616 - val_loss: 1.8532
Epoch 17/50
 - 4s - loss: 5.3551 - val_loss: 2.3431
Epoch 18/50
 - 5s - loss: 3.6570 - val_loss: 2.6400
Epoch 19/50
 - 5s - loss: 3.8699 - val_loss: 1.9961
Epoch 20/50
 - 4s - loss: 4.9598 - val_loss: 2.7202
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 30000	action = 0	current_phase = 0	next_phase = 1	reward = 1.001864	array([[ 3.6244502, -9.300053 ]], dtype=float32)
time = 30005	action = 0	current_phase = 0	next_phase = 1	reward = 0.719225	array([[ 3.6324306, -9.316625 ]], dtype=float32)
time = 30010	action = 0	current_phase = 0	next_phase = 1	reward = 0.713619	array([[ 3.6361651, -9.248181 ]], dtype=float32)
time = 30015	action = 0	current_phase = 0	next_phase = 1	reward = 0.724352	array([[ 3.5972095, -9.305651 ]], dtype=float32)
time = 30020	action = 0	current_phase = 0	next_phase = 1	reward = 0.719132	array([[ 3.6461806, -9.257246 ]], dtype=float32)
time = 30025	action = 0	current_phase = 0	next_phase = 1	reward = 0.729783	array([[ 3.6314855, -9.242731 ]], dtype=float32)
time = 30030	action = 0	current_phase = 0	next_phase = 1	reward = 0.725098	array([[ 3.6653762, -9.250326 ]], dtype=float32)
time = 30035	action = 0	current_phase = 0	next_phase = 1	reward = 0.447066	array([[ 3.625544, -9.283733]], dtype=float32)
time = 30040	action = 0	current_phase = 0	next_phase = 1	reward = 1.009218	array([[ 3.6635385, -9.248023 ]], dtype=float32)
time = 30045	action = 0	current_phase = 0	next_phase = 1	reward = 0.724119	array([[ 3.6121955, -9.259741 ]], dtype=float32)
time = 30050	action = 0	current_phase = 0	next_phase = 1	reward = 0.722022	array([[ 3.6290402, -9.283771 ]], dtype=float32)
time = 30055	action = 0	current_phase = 0	next_phase = 1	reward = 0.723604	array([[ 3.6207156, -9.24593  ]], dtype=float32)
time = 30060	action = 0	current_phase = 0	next_phase = 1	reward = 0.725777	array([[ 3.6306148, -9.273843 ]], dtype=float32)
time = 30065	action = 0	current_phase = 0	next_phase = 1	reward = 0.723564	array([[ 3.6547399, -9.211748 ]], dtype=float32)
time = 30070	action = 0	current_phase = 0	next_phase = 1	reward = 0.724322	array([[ 3.6533904, -9.258196 ]], dtype=float32)
time = 30075	action = 0	current_phase = 0	next_phase = 1	reward = 0.719897	array([[ 3.6507306, -9.200878 ]], dtype=float32)
time = 30080	action = 0	current_phase = 0	next_phase = 1	reward = 0.715867	array([[ 3.5773396, -9.281797 ]], dtype=float32)
time = 30085	action = 0	current_phase = 0	next_phase = 1	reward = 0.722763	array([[ 3.665792, -9.229782]], dtype=float32)
time = 30090	action = 0	current_phase = 0	next_phase = 1	reward = 0.717007	array([[ 3.6714149, -9.242092 ]], dtype=float32)
time = 30095	action = 0	current_phase = 0	next_phase = 1	reward = 0.441897	array([[ 3.6374192, -9.270937 ]], dtype=float32)
time = 30100	action = 0	current_phase = 0	next_phase = 1	reward = 0.733859	array([[ 3.6329246, -9.2479725]], dtype=float32)
time = 30105	action = 0	current_phase = 0	next_phase = 1	reward = 1.011340	array([[ 3.6362367, -9.323393 ]], dtype=float32)
time = 30110	action = 0	current_phase = 0	next_phase = 1	reward = 0.722659	array([[ 3.628633, -9.238809]], dtype=float32)
time = 30115	action = 0	current_phase = 0	next_phase = 1	reward = 0.722888	array([[ 3.64601 , -9.298662]], dtype=float32)
time = 30120	action = 0	current_phase = 0	next_phase = 1	reward = 0.729292	array([[ 3.623386, -9.269077]], dtype=float32)
time = 30125	action = 0	current_phase = 0	next_phase = 1	reward = 0.442935	array([[ 3.670216, -9.239855]], dtype=float32)
time = 30130	action = 0	current_phase = 0	next_phase = 1	reward = 1.011450	array([[ 3.603867, -9.315842]], dtype=float32)
time = 30135	action = 0	current_phase = 0	next_phase = 1	reward = 0.726141	array([[ 3.6289306, -9.27157  ]], dtype=float32)
time = 30140	action = 0	current_phase = 0	next_phase = 1	reward = 0.723610	array([[ 3.6385827, -9.228967 ]], dtype=float32)
time = 30145	action = 0	current_phase = 0	next_phase = 1	reward = 0.716472	array([[ 3.6352048, -9.243076 ]], dtype=float32)
time = 30150	action = 0	current_phase = 0	next_phase = 1	reward = 0.717051	array([[ 3.6027684, -9.309351 ]], dtype=float32)
time = 30155	action = 0	current_phase = 0	next_phase = 1	reward = 0.438829	array([[ 3.6459556, -9.240351 ]], dtype=float32)
time = 30160	action = 0	current_phase = 0	next_phase = 1	reward = 0.733266	array([[ 3.6630168, -9.25124  ]], dtype=float32)
time = 30165	action = 0	current_phase = 0	next_phase = 1	reward = 1.010006	array([[ 3.5531259, -9.274327 ]], dtype=float32)
time = 30170	action = 0	current_phase = 0	next_phase = 1	reward = 0.445457	array([[ 3.6339984, -9.264335 ]], dtype=float32)
time = 30175	action = 0	current_phase = 0	next_phase = 1	reward = 1.014638	array([[ 3.5612435, -9.358725 ]], dtype=float32)
time = 30180	action = 0	current_phase = 0	next_phase = 1	reward = 0.725140	array([[ 3.5740743, -9.253943 ]], dtype=float32)
time = 30185	action = 0	current_phase = 0	next_phase = 1	reward = 0.726160	array([[ 3.5615344, -9.337718 ]], dtype=float32)
time = 30190	action = 0	current_phase = 0	next_phase = 1	reward = 0.447908	array([[ 3.6014266, -9.25012  ]], dtype=float32)
time = 30195	action = 0	current_phase = 0	next_phase = 1	reward = 0.721586	array([[ 3.6514459, -9.247206 ]], dtype=float32)
time = 30200	action = 0	current_phase = 0	next_phase = 1	reward = 1.000250	array([[ 3.501573, -9.349264]], dtype=float32)
time = 30205	action = 0	current_phase = 0	next_phase = 1	reward = 0.436865	array([[ 3.6557193, -9.218771 ]], dtype=float32)
time = 30210	action = 0	current_phase = 0	next_phase = 1	reward = 0.729573	array([[ 3.6338944, -9.272729 ]], dtype=float32)
time = 30215	action = 0	current_phase = 0	next_phase = 1	reward = 1.011246	array([[ 3.6030412, -9.238838 ]], dtype=float32)
time = 30220	action = 0	current_phase = 0	next_phase = 1	reward = 0.724888	array([[ 3.6263547, -9.239259 ]], dtype=float32)
time = 30225	action = 0	current_phase = 0	next_phase = 1	reward = 0.445593	array([[ 3.6503358, -9.278191 ]], dtype=float32)
time = 30230	action = 0	current_phase = 0	next_phase = 1	reward = 1.001028	array([[ 3.6133657, -9.363736 ]], dtype=float32)
time = 30235	action = 0	current_phase = 0	next_phase = 1	reward = 0.719749	array([[ 3.6112456, -9.28244  ]], dtype=float32)
time = 30240	action = 0	current_phase = 0	next_phase = 1	reward = 0.445268	array([[ 3.6321406, -9.313886 ]], dtype=float32)
time = 30245	action = 0	current_phase = 0	next_phase = 1	reward = 0.728160	array([[ 3.619596, -9.290737]], dtype=float32)
time = 30250	action = 0	current_phase = 0	next_phase = 1	reward = 0.728291	array([[ 3.6153703, -9.322424 ]], dtype=float32)
time = 30255	action = 0	current_phase = 0	next_phase = 1	reward = 1.005241	array([[ 3.6063275, -9.315401 ]], dtype=float32)
time = 30260	action = 0	current_phase = 0	next_phase = 1	reward = 0.720648	array([[ 3.617679, -9.296472]], dtype=float32)
time = 30265	action = 0	current_phase = 0	next_phase = 1	reward = 0.444564	array([[ 3.650597, -9.265422]], dtype=float32)
time = 30270	action = 0	current_phase = 0	next_phase = 1	reward = 1.008966	array([[ 3.5974126, -9.329617 ]], dtype=float32)
time = 30275	action = 0	current_phase = 0	next_phase = 1	reward = 0.715518	array([[ 3.5953774, -9.26292  ]], dtype=float32)
time = 30280	action = 0	current_phase = 0	next_phase = 1	reward = 0.439591	array([[ 3.654964, -9.323608]], dtype=float32)
time = 30285	action = 0	current_phase = 0	next_phase = 1	reward = 0.999994	array([[ 3.6285472, -9.2911415]], dtype=float32)
time = 30290	action = 0	current_phase = 0	next_phase = 1	reward = 0.731254	array([[ 3.5583024, -9.358712 ]], dtype=float32)
time = 30295	action = 0	current_phase = 0	next_phase = 1	reward = 0.733468	array([[ 3.6574464, -9.254677 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.4769 - val_loss: 1.7526
Epoch 2/50
 - 4s - loss: 5.3287 - val_loss: 2.4060
Epoch 3/50
 - 4s - loss: 3.9903 - val_loss: 2.2355
Epoch 4/50
 - 4s - loss: 4.5089 - val_loss: 1.7343
Epoch 5/50
 - 4s - loss: 6.0861 - val_loss: 2.0990
Epoch 6/50
 - 4s - loss: 4.1230 - val_loss: 1.9328
Epoch 7/50
 - 4s - loss: 4.1665 - val_loss: 2.5493
Epoch 8/50
 - 4s - loss: 4.4546 - val_loss: 1.8185
Epoch 9/50
 - 4s - loss: 4.4386 - val_loss: 1.9861
Epoch 10/50
 - 4s - loss: 5.6298 - val_loss: 1.9439
Epoch 11/50
 - 4s - loss: 4.8901 - val_loss: 1.8066
Epoch 12/50
 - 4s - loss: 5.7807 - val_loss: 2.0597
Epoch 13/50
 - 4s - loss: 3.2938 - val_loss: 2.1160
Epoch 14/50
 - 5s - loss: 3.4454 - val_loss: 1.8762
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 30300	action = 0	current_phase = 0	next_phase = 1	reward = 0.725699	array([[ 3.591445, -9.260281]], dtype=float32)
time = 30305	action = 0	current_phase = 0	next_phase = 1	reward = 0.724809	array([[ 3.6039171, -9.299752 ]], dtype=float32)
time = 30310	action = 0	current_phase = 0	next_phase = 1	reward = 0.722279	array([[ 3.612608, -9.225071]], dtype=float32)
time = 30315	action = 0	current_phase = 0	next_phase = 1	reward = 0.719403	array([[ 3.612074, -9.271703]], dtype=float32)
time = 30320	action = 0	current_phase = 0	next_phase = 1	reward = 0.437068	array([[ 3.586028, -9.284372]], dtype=float32)
time = 30325	action = 0	current_phase = 0	next_phase = 1	reward = 1.016977	array([[ 3.6215525, -9.265404 ]], dtype=float32)
time = 30330	action = 0	current_phase = 0	next_phase = 1	reward = 0.440486	array([[ 3.610633, -9.255722]], dtype=float32)
time = 30335	action = 0	current_phase = 0	next_phase = 1	reward = 1.001881	array([[ 3.6124306, -9.2522545]], dtype=float32)
time = 30340	action = 0	current_phase = 0	next_phase = 1	reward = 0.714817	array([[ 3.6258736, -9.249813 ]], dtype=float32)
time = 30345	action = 0	current_phase = 0	next_phase = 1	reward = 0.440865	array([[ 3.6268072, -9.263612 ]], dtype=float32)
time = 30350	action = 0	current_phase = 0	next_phase = 1	reward = 1.008801	array([[ 3.6283398, -9.225628 ]], dtype=float32)
time = 30355	action = 0	current_phase = 0	next_phase = 1	reward = 0.726267	array([[ 3.5630312, -9.28908  ]], dtype=float32)
time = 30360	action = 0	current_phase = 0	next_phase = 1	reward = 0.448664	array([[ 3.6107197, -9.292388 ]], dtype=float32)
time = 30365	action = 0	current_phase = 0	next_phase = 1	reward = 0.727911	array([[ 3.6456242, -9.338814 ]], dtype=float32)
time = 30370	action = 0	current_phase = 0	next_phase = 1	reward = 1.002265	array([[ 3.5891237, -9.305271 ]], dtype=float32)
time = 30375	action = 0	current_phase = 0	next_phase = 1	reward = 0.440476	array([[ 3.6371107, -9.199146 ]], dtype=float32)
time = 30380	action = 0	current_phase = 0	next_phase = 1	reward = 0.998515	array([[ 3.6087809, -9.357071 ]], dtype=float32)
time = 30385	action = 0	current_phase = 0	next_phase = 1	reward = 0.714707	array([[ 3.635045, -9.255365]], dtype=float32)
time = 30390	action = 0	current_phase = 0	next_phase = 1	reward = 0.439290	array([[ 3.6061163, -9.236955 ]], dtype=float32)
time = 30395	action = 0	current_phase = 0	next_phase = 1	reward = 1.004273	array([[ 3.5836773, -9.287772 ]], dtype=float32)
time = 30400	action = 0	current_phase = 0	next_phase = 1	reward = 0.725571	array([[ 3.6271  , -9.282057]], dtype=float32)
time = 30405	action = 0	current_phase = 0	next_phase = 1	reward = 0.443544	array([[ 3.626483, -9.236217]], dtype=float32)
time = 30410	action = 0	current_phase = 0	next_phase = 1	reward = 1.006390	array([[ 3.6117697, -9.240025 ]], dtype=float32)
time = 30415	action = 0	current_phase = 0	next_phase = 1	reward = 0.729040	array([[ 3.621544, -9.238804]], dtype=float32)
time = 30420	action = 0	current_phase = 0	next_phase = 1	reward = 0.724457	array([[ 3.6328335, -9.244274 ]], dtype=float32)
time = 30425	action = 0	current_phase = 0	next_phase = 1	reward = 0.720917	array([[ 3.5962057, -9.255285 ]], dtype=float32)
time = 30430	action = 0	current_phase = 0	next_phase = 1	reward = 0.444815	array([[ 3.6578846, -9.273687 ]], dtype=float32)
time = 30435	action = 0	current_phase = 0	next_phase = 1	reward = 1.000144	array([[ 3.5747766, -9.280512 ]], dtype=float32)
time = 30440	action = 0	current_phase = 0	next_phase = 1	reward = 0.442279	array([[ 3.6387606, -9.248129 ]], dtype=float32)
time = 30445	action = 0	current_phase = 0	next_phase = 1	reward = 1.005149	array([[ 3.621172, -9.227312]], dtype=float32)
time = 30450	action = 0	current_phase = 0	next_phase = 1	reward = 0.721144	array([[ 3.615244, -9.269315]], dtype=float32)
time = 30455	action = 0	current_phase = 0	next_phase = 1	reward = 0.722894	array([[ 3.6262245, -9.239878 ]], dtype=float32)
time = 30460	action = 0	current_phase = 0	next_phase = 1	reward = 0.713686	array([[ 3.6134596, -9.260004 ]], dtype=float32)
time = 30465	action = 0	current_phase = 0	next_phase = 1	reward = 0.725905	array([[ 3.6514778, -9.245775 ]], dtype=float32)
time = 30470	action = 0	current_phase = 0	next_phase = 1	reward = 0.725925	array([[ 3.6235218, -9.257164 ]], dtype=float32)
time = 30475	action = 0	current_phase = 0	next_phase = 1	reward = 0.721438	array([[ 3.6177912, -9.236197 ]], dtype=float32)
time = 30480	action = 0	current_phase = 0	next_phase = 1	reward = 0.166265	array([[ 3.646452, -9.241263]], dtype=float32)
time = 30485	action = 0	current_phase = 0	next_phase = 1	reward = 1.008431	array([[ 3.5804052, -9.261763 ]], dtype=float32)
time = 30490	action = 0	current_phase = 0	next_phase = 1	reward = 0.995287	array([[ 3.601982, -9.273767]], dtype=float32)
time = 30495	action = 0	current_phase = 0	next_phase = 1	reward = 0.722788	array([[ 3.6053543, -9.249498 ]], dtype=float32)
time = 30500	action = 0	current_phase = 0	next_phase = 1	reward = 0.725392	array([[ 3.614627, -9.293293]], dtype=float32)
time = 30505	action = 0	current_phase = 0	next_phase = 1	reward = 0.443485	array([[ 3.5960932, -9.2795   ]], dtype=float32)
time = 30510	action = 0	current_phase = 0	next_phase = 1	reward = 1.002848	array([[ 3.6116438, -9.224929 ]], dtype=float32)
time = 30515	action = 0	current_phase = 0	next_phase = 1	reward = 0.718582	array([[ 3.632635, -9.277301]], dtype=float32)
time = 30520	action = 0	current_phase = 0	next_phase = 1	reward = 0.445765	array([[ 3.6125584, -9.305898 ]], dtype=float32)
time = 30525	action = 0	current_phase = 0	next_phase = 1	reward = 1.000055	array([[ 3.5575018, -9.309759 ]], dtype=float32)
time = 30530	action = 0	current_phase = 0	next_phase = 1	reward = 0.442652	array([[ 3.5976582, -9.226697 ]], dtype=float32)
time = 30535	action = 0	current_phase = 0	next_phase = 1	reward = 1.014158	array([[ 3.5937443, -9.406887 ]], dtype=float32)
time = 30540	action = 0	current_phase = 0	next_phase = 1	reward = 0.728136	array([[ 3.642171, -9.273341]], dtype=float32)
time = 30545	action = 0	current_phase = 0	next_phase = 1	reward = 0.449280	array([[ 3.6050825, -9.24806  ]], dtype=float32)
time = 30550	action = 0	current_phase = 0	next_phase = 1	reward = 0.999524	array([[ 3.6340399, -9.256956 ]], dtype=float32)
time = 30555	action = 0	current_phase = 0	next_phase = 1	reward = 0.720185	array([[ 3.5641003, -9.290739 ]], dtype=float32)
time = 30560	action = 0	current_phase = 0	next_phase = 1	reward = 0.437157	array([[ 3.631792, -9.241562]], dtype=float32)
time = 30565	action = 0	current_phase = 0	next_phase = 1	reward = 0.731948	array([[ 3.4084816, -9.436551 ]], dtype=float32)
time = 30570	action = 0	current_phase = 0	next_phase = 1	reward = 1.005028	array([[ 3.547309, -9.367855]], dtype=float32)
time = 30575	action = 0	current_phase = 0	next_phase = 1	reward = 0.721008	array([[ 3.6148987, -9.260092 ]], dtype=float32)
time = 30580	action = 0	current_phase = 0	next_phase = 1	reward = 0.720333	array([[ 3.616376, -9.20838 ]], dtype=float32)
time = 30585	action = 0	current_phase = 0	next_phase = 1	reward = 0.720846	array([[ 3.592844 , -9.3105545]], dtype=float32)
time = 30590	action = 0	current_phase = 0	next_phase = 1	reward = 0.727976	array([[ 3.6041317, -9.23428  ]], dtype=float32)
time = 30595	action = 0	current_phase = 0	next_phase = 1	reward = 0.720952	array([[ 3.5928898, -9.300642 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 6.7445 - val_loss: 1.7850
Epoch 2/50
 - 4s - loss: 4.0257 - val_loss: 2.3365
Epoch 3/50
 - 4s - loss: 3.5579 - val_loss: 2.0726
Epoch 4/50
 - 4s - loss: 3.9505 - val_loss: 2.1491
Epoch 5/50
 - 4s - loss: 4.2619 - val_loss: 1.7603
Epoch 6/50
 - 4s - loss: 3.5592 - val_loss: 2.7766
Epoch 7/50
 - 4s - loss: 5.4652 - val_loss: 3.3834
Epoch 8/50
 - 4s - loss: 5.7480 - val_loss: 2.9547
Epoch 9/50
 - 4s - loss: 3.6886 - val_loss: 1.6135
Epoch 10/50
 - 4s - loss: 4.5607 - val_loss: 2.5427
Epoch 11/50
 - 4s - loss: 3.5171 - val_loss: 1.8458
Epoch 12/50
 - 4s - loss: 4.8456 - val_loss: 1.7955
Epoch 13/50
 - 4s - loss: 3.5796 - val_loss: 1.7308
Epoch 14/50
 - 4s - loss: 3.7219 - val_loss: 3.0243
Epoch 15/50
 - 4s - loss: 3.5100 - val_loss: 1.9362
Epoch 16/50
 - 4s - loss: 6.8035 - val_loss: 2.4744
Epoch 17/50
 - 4s - loss: 3.9380 - val_loss: 1.6827
Epoch 18/50
 - 4s - loss: 5.7120 - val_loss: 2.0221
Epoch 19/50
 - 4s - loss: 5.2117 - val_loss: 2.3694
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 30600	action = 0	current_phase = 0	next_phase = 1	reward = 0.722467	array([[ 3.591485, -9.328777]], dtype=float32)
time = 30605	action = 0	current_phase = 0	next_phase = 1	reward = 0.720478	array([[ 3.672595, -9.334104]], dtype=float32)
time = 30610	action = 0	current_phase = 0	next_phase = 1	reward = 0.710052	array([[ 3.6918488, -9.280421 ]], dtype=float32)
time = 30615	action = 0	current_phase = 0	next_phase = 1	reward = 0.434641	array([[ 3.6447515, -9.225683 ]], dtype=float32)
time = 30620	action = 0	current_phase = 0	next_phase = 1	reward = 0.724298	array([[ 3.6377745, -9.286186 ]], dtype=float32)
time = 30625	action = 0	current_phase = 0	next_phase = 1	reward = 0.720826	array([[ 3.6437998, -9.269425 ]], dtype=float32)
time = 30630	action = 0	current_phase = 0	next_phase = 1	reward = 0.720441	array([[ 3.6994028, -9.297335 ]], dtype=float32)
time = 30635	action = 0	current_phase = 0	next_phase = 1	reward = 0.996367	array([[ 3.6324682, -9.294891 ]], dtype=float32)
time = 30640	action = 0	current_phase = 0	next_phase = 1	reward = 0.448351	array([[ 3.6574602, -9.247568 ]], dtype=float32)
time = 30645	action = 0	current_phase = 0	next_phase = 1	reward = 1.003568	array([[ 3.70327 , -9.318424]], dtype=float32)
time = 30650	action = 0	current_phase = 0	next_phase = 1	reward = 0.443901	array([[ 3.656084, -9.312326]], dtype=float32)
time = 30655	action = 0	current_phase = 0	next_phase = 1	reward = 0.726416	array([[ 3.6483107, -9.285769 ]], dtype=float32)
time = 30660	action = 0	current_phase = 0	next_phase = 1	reward = 0.726507	array([[ 3.61448 , -9.260578]], dtype=float32)
time = 30665	action = 0	current_phase = 0	next_phase = 1	reward = 1.001245	array([[ 3.6804314, -9.298237 ]], dtype=float32)
time = 30670	action = 0	current_phase = 0	next_phase = 1	reward = 0.724591	array([[ 3.6513252, -9.275196 ]], dtype=float32)
time = 30675	action = 0	current_phase = 0	next_phase = 1	reward = 0.727907	array([[ 3.6796656, -9.3062315]], dtype=float32)
time = 30680	action = 0	current_phase = 0	next_phase = 1	reward = 0.723017	array([[ 3.6102638, -9.305017 ]], dtype=float32)
time = 30685	action = 0	current_phase = 0	next_phase = 1	reward = 0.727568	array([[ 3.64849 , -9.313306]], dtype=float32)
time = 30690	action = 0	current_phase = 0	next_phase = 1	reward = 0.729295	array([[ 3.593216, -9.346235]], dtype=float32)
time = 30695	action = 0	current_phase = 0	next_phase = 1	reward = 0.728562	array([[ 3.6812963, -9.259909 ]], dtype=float32)
time = 30700	action = 0	current_phase = 0	next_phase = 1	reward = 0.709728	array([[ 3.6769848, -9.196907 ]], dtype=float32)
time = 30705	action = 0	current_phase = 0	next_phase = 1	reward = 0.712940	array([[ 3.6910725, -9.261062 ]], dtype=float32)
time = 30710	action = 0	current_phase = 0	next_phase = 1	reward = 0.443292	array([[ 3.6670284, -9.262899 ]], dtype=float32)
time = 30715	action = 0	current_phase = 0	next_phase = 1	reward = 0.735063	array([[ 3.6338568, -9.270737 ]], dtype=float32)
time = 30720	action = 0	current_phase = 0	next_phase = 1	reward = 1.018557	array([[ 3.6801434, -9.245625 ]], dtype=float32)
time = 30725	action = 0	current_phase = 0	next_phase = 1	reward = 0.733361	array([[ 3.6923132, -9.258837 ]], dtype=float32)
time = 30730	action = 0	current_phase = 0	next_phase = 1	reward = 0.725520	array([[ 3.6768513, -9.330778 ]], dtype=float32)
time = 30735	action = 0	current_phase = 0	next_phase = 1	reward = 0.722183	array([[ 3.6520224, -9.266905 ]], dtype=float32)
time = 30740	action = 0	current_phase = 0	next_phase = 1	reward = 0.723099	array([[ 3.6949472, -9.247157 ]], dtype=float32)
time = 30745	action = 0	current_phase = 0	next_phase = 1	reward = 0.721602	array([[ 3.6711597, -9.227026 ]], dtype=float32)
time = 30750	action = 0	current_phase = 0	next_phase = 1	reward = 0.721030	array([[ 3.660634, -9.261644]], dtype=float32)
time = 30755	action = 0	current_phase = 0	next_phase = 1	reward = 0.444003	array([[ 3.6896849, -9.246782 ]], dtype=float32)
time = 30760	action = 0	current_phase = 0	next_phase = 1	reward = 0.727776	array([[ 3.6742773, -9.2324705]], dtype=float32)
time = 30765	action = 0	current_phase = 0	next_phase = 1	reward = 1.006105	array([[ 3.6501675, -9.300903 ]], dtype=float32)
time = 30770	action = 0	current_phase = 0	next_phase = 1	reward = 0.723408	array([[ 3.6663742, -9.297968 ]], dtype=float32)
time = 30775	action = 0	current_phase = 0	next_phase = 1	reward = 0.727544	array([[ 3.557496, -9.303986]], dtype=float32)
time = 30780	action = 0	current_phase = 0	next_phase = 1	reward = 0.446532	array([[ 3.5873861, -9.28458  ]], dtype=float32)
time = 30785	action = 0	current_phase = 0	next_phase = 1	reward = 0.726648	array([[ 3.580038, -9.378447]], dtype=float32)
time = 30790	action = 0	current_phase = 0	next_phase = 1	reward = 1.003512	array([[ 3.6698017, -9.2691   ]], dtype=float32)
time = 30795	action = 0	current_phase = 0	next_phase = 1	reward = 0.717124	array([[ 3.6496658, -9.24601  ]], dtype=float32)
time = 30800	action = 0	current_phase = 0	next_phase = 1	reward = 0.716918	array([[ 3.5868616, -9.261664 ]], dtype=float32)
time = 30805	action = 0	current_phase = 0	next_phase = 1	reward = 0.167643	array([[ 3.6436415, -9.274052 ]], dtype=float32)
time = 30810	action = 0	current_phase = 0	next_phase = 1	reward = 1.288585	array([[ 3.637433, -9.323359]], dtype=float32)
time = 30815	action = 0	current_phase = 0	next_phase = 1	reward = 0.722993	array([[ 3.7006378, -9.220459 ]], dtype=float32)
time = 30820	action = 0	current_phase = 0	next_phase = 1	reward = 0.718779	array([[ 3.6088228, -9.317833 ]], dtype=float32)
time = 30825	action = 0	current_phase = 0	next_phase = 1	reward = 0.444538	array([[ 3.666647, -9.323601]], dtype=float32)
time = 30830	action = 0	current_phase = 0	next_phase = 1	reward = 1.000331	array([[ 3.5107813, -9.449276 ]], dtype=float32)
time = 30835	action = 0	current_phase = 0	next_phase = 1	reward = 0.441055	array([[ 3.6555614, -9.23005  ]], dtype=float32)
time = 30840	action = 0	current_phase = 0	next_phase = 1	reward = 0.448833	array([[ 3.6543722, -9.234082 ]], dtype=float32)
time = 30845	action = 0	current_phase = 0	next_phase = 1	reward = 1.288066	array([[ 3.6438465, -9.291174 ]], dtype=float32)
time = 30850	action = 0	current_phase = 0	next_phase = 1	reward = 0.721746	array([[ 3.659995, -9.250195]], dtype=float32)
time = 30855	action = 0	current_phase = 0	next_phase = 1	reward = 0.448308	array([[ 3.6588087, -9.217737 ]], dtype=float32)
time = 30860	action = 0	current_phase = 0	next_phase = 1	reward = 1.005081	array([[ 3.6481886, -9.315045 ]], dtype=float32)
time = 30865	action = 0	current_phase = 0	next_phase = 1	reward = 0.720423	array([[ 3.6301517, -9.343478 ]], dtype=float32)
time = 30870	action = 0	current_phase = 0	next_phase = 1	reward = 0.722299	array([[ 3.729804, -9.239536]], dtype=float32)
time = 30875	action = 0	current_phase = 0	next_phase = 1	reward = 0.721475	array([[ 3.6365252, -9.25742  ]], dtype=float32)
time = 30880	action = 0	current_phase = 0	next_phase = 1	reward = 0.445646	array([[ 3.653448, -9.278231]], dtype=float32)
time = 30885	action = 0	current_phase = 0	next_phase = 1	reward = 0.724817	array([[ 3.6315613, -9.306765 ]], dtype=float32)
time = 30890	action = 0	current_phase = 0	next_phase = 1	reward = 0.725624	array([[ 3.6754026, -9.220951 ]], dtype=float32)
time = 30895	action = 0	current_phase = 0	next_phase = 1	reward = 0.728870	array([[ 3.6479254, -9.26829  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 6.7602 - val_loss: 2.6383
Epoch 2/50
 - 4s - loss: 4.0508 - val_loss: 3.1730
Epoch 3/50
 - 4s - loss: 5.0897 - val_loss: 2.9142
Epoch 4/50
 - 4s - loss: 7.1276 - val_loss: 3.1720
Epoch 5/50
 - 4s - loss: 4.4053 - val_loss: 3.0315
Epoch 6/50
 - 4s - loss: 3.9832 - val_loss: 1.7505
Epoch 7/50
 - 4s - loss: 4.2150 - val_loss: 2.4820
Epoch 8/50
 - 4s - loss: 4.2376 - val_loss: 2.7564
Epoch 9/50
 - 4s - loss: 4.7406 - val_loss: 2.5537
Epoch 10/50
 - 4s - loss: 5.0863 - val_loss: 2.6366
Epoch 11/50
 - 4s - loss: 5.0083 - val_loss: 5.2607
Epoch 12/50
 - 4s - loss: 4.8067 - val_loss: 1.9086
Epoch 13/50
 - 4s - loss: 3.5957 - val_loss: 1.6582
Epoch 14/50
 - 4s - loss: 4.4786 - val_loss: 2.0123
Epoch 15/50
 - 4s - loss: 3.8076 - val_loss: 1.9805
Epoch 16/50
 - 4s - loss: 7.2598 - val_loss: 2.5098
Epoch 17/50
 - 4s - loss: 4.0349 - val_loss: 3.2303
Epoch 18/50
 - 4s - loss: 5.0238 - val_loss: 3.1343
Epoch 19/50
 - 4s - loss: 6.6328 - val_loss: 3.5715
Epoch 20/50
 - 4s - loss: 6.0722 - val_loss: 4.4457
Epoch 21/50
 - 4s - loss: 4.2096 - val_loss: 2.6550
Epoch 22/50
 - 6s - loss: 6.2737 - val_loss: 4.7690
Epoch 23/50
 - 5s - loss: 3.7241 - val_loss: 2.4361
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 30900	action = 0	current_phase = 0	next_phase = 1	reward = 1.008862	array([[ 3.6305737, -9.252979 ]], dtype=float32)
time = 30905	action = 0	current_phase = 0	next_phase = 1	reward = 0.715342	array([[ 3.6734567, -9.256081 ]], dtype=float32)
time = 30910	action = 0	current_phase = 0	next_phase = 1	reward = 0.440256	array([[ 3.5467334, -9.270449 ]], dtype=float32)
time = 30915	action = 0	current_phase = 0	next_phase = 1	reward = 1.009703	array([[ 3.6255803, -9.274787 ]], dtype=float32)
time = 30920	action = 0	current_phase = 0	next_phase = 1	reward = 0.441703	array([[ 3.6789908, -9.198599 ]], dtype=float32)
time = 30925	action = 0	current_phase = 0	next_phase = 1	reward = 1.009616	array([[ 3.6558309, -9.230977 ]], dtype=float32)
time = 30930	action = 0	current_phase = 0	next_phase = 1	reward = 0.725050	array([[ 3.599257, -9.258144]], dtype=float32)
time = 30935	action = 0	current_phase = 0	next_phase = 1	reward = 0.443377	array([[ 3.6389756, -9.264353 ]], dtype=float32)
time = 30940	action = 0	current_phase = 0	next_phase = 1	reward = 0.996796	array([[ 3.636602, -9.288772]], dtype=float32)
time = 30945	action = 0	current_phase = 0	next_phase = 1	reward = 0.722130	array([[ 3.6229444, -9.239747 ]], dtype=float32)
time = 30950	action = 0	current_phase = 0	next_phase = 1	reward = 0.723463	array([[ 3.590961, -9.247778]], dtype=float32)
time = 30955	action = 0	current_phase = 0	next_phase = 1	reward = 0.450993	array([[ 3.663015, -9.254686]], dtype=float32)
time = 30960	action = 0	current_phase = 0	next_phase = 1	reward = 0.731942	array([[ 3.6386056, -9.277111 ]], dtype=float32)
time = 30965	action = 0	current_phase = 0	next_phase = 1	reward = 1.005692	array([[ 3.5781446, -9.267033 ]], dtype=float32)
time = 30970	action = 0	current_phase = 0	next_phase = 1	reward = 0.718725	array([[ 3.6770892, -9.156334 ]], dtype=float32)
time = 30975	action = 0	current_phase = 0	next_phase = 1	reward = 0.722375	array([[ 3.6710134, -9.251362 ]], dtype=float32)
time = 30980	action = 0	current_phase = 0	next_phase = 1	reward = 0.723037	array([[ 3.6522546, -9.226243 ]], dtype=float32)
time = 30985	action = 0	current_phase = 0	next_phase = 1	reward = 0.721575	array([[ 3.6712813, -9.195397 ]], dtype=float32)
time = 30990	action = 0	current_phase = 0	next_phase = 1	reward = 0.447402	array([[ 3.680448, -9.175968]], dtype=float32)
time = 30995	action = 0	current_phase = 0	next_phase = 1	reward = 1.002567	array([[ 3.6586547, -9.188313 ]], dtype=float32)
time = 31000	action = 0	current_phase = 0	next_phase = 1	reward = 0.720890	array([[ 3.6885114, -9.25209  ]], dtype=float32)
time = 31005	action = 0	current_phase = 0	next_phase = 1	reward = 0.729379	array([[ 3.6727881, -9.23556  ]], dtype=float32)
time = 31010	action = 0	current_phase = 0	next_phase = 1	reward = 0.451470	array([[ 3.636393, -9.249737]], dtype=float32)
time = 31015	action = 0	current_phase = 0	next_phase = 1	reward = 1.005088	array([[ 3.6452117, -9.259512 ]], dtype=float32)
time = 31020	action = 0	current_phase = 0	next_phase = 1	reward = 0.722736	array([[ 3.6739326, -9.256175 ]], dtype=float32)
time = 31025	action = 0	current_phase = 0	next_phase = 1	reward = 0.729316	array([[ 3.6480079, -9.217722 ]], dtype=float32)
time = 31030	action = 0	current_phase = 0	next_phase = 1	reward = 0.732264	array([[ 3.6493049, -9.244379 ]], dtype=float32)
time = 31035	action = 0	current_phase = 0	next_phase = 1	reward = 0.717232	array([[ 3.640306, -9.291899]], dtype=float32)
time = 31040	action = 0	current_phase = 0	next_phase = 1	reward = 0.725315	array([[ 3.6482358, -9.2813225]], dtype=float32)
time = 31045	action = 0	current_phase = 0	next_phase = 1	reward = 0.734457	array([[ 3.6536498, -9.218999 ]], dtype=float32)
time = 31050	action = 0	current_phase = 0	next_phase = 1	reward = 0.724555	array([[ 3.6483254, -9.224358 ]], dtype=float32)
time = 31055	action = 0	current_phase = 0	next_phase = 1	reward = 0.444811	array([[ 3.6937814, -9.26962  ]], dtype=float32)
time = 31060	action = 0	current_phase = 0	next_phase = 1	reward = 0.997604	array([[ 3.629127, -9.415623]], dtype=float32)
time = 31065	action = 0	current_phase = 0	next_phase = 1	reward = 0.717945	array([[ 3.6438975, -9.297206 ]], dtype=float32)
time = 31070	action = 0	current_phase = 0	next_phase = 1	reward = 0.440549	array([[ 3.689364, -9.217027]], dtype=float32)
time = 31075	action = 0	current_phase = 0	next_phase = 1	reward = 1.010520	array([[ 3.6585393, -9.225836 ]], dtype=float32)
time = 31080	action = 0	current_phase = 0	next_phase = 1	reward = 0.724285	array([[ 3.6380115, -9.221613 ]], dtype=float32)
time = 31085	action = 0	current_phase = 0	next_phase = 1	reward = 0.723305	array([[ 3.6421447, -9.195982 ]], dtype=float32)
time = 31090	action = 0	current_phase = 0	next_phase = 1	reward = 0.726829	array([[ 3.666595, -9.214983]], dtype=float32)
time = 31095	action = 0	current_phase = 0	next_phase = 1	reward = 0.721599	array([[ 3.62884 , -9.255211]], dtype=float32)
time = 31100	action = 0	current_phase = 0	next_phase = 1	reward = 0.717297	array([[ 3.6824489, -9.1847725]], dtype=float32)
time = 31105	action = 0	current_phase = 0	next_phase = 1	reward = 0.716209	array([[ 3.660952, -9.195095]], dtype=float32)
time = 31110	action = 0	current_phase = 0	next_phase = 1	reward = 0.445899	array([[ 3.6765943, -9.2247505]], dtype=float32)
time = 31115	action = 0	current_phase = 0	next_phase = 1	reward = 1.001719	array([[ 3.6506839, -9.224695 ]], dtype=float32)
time = 31120	action = 0	current_phase = 0	next_phase = 1	reward = 0.727443	array([[ 3.6717477, -9.214647 ]], dtype=float32)
time = 31125	action = 0	current_phase = 0	next_phase = 1	reward = 0.727433	array([[ 3.6249442, -9.185127 ]], dtype=float32)
time = 31130	action = 0	current_phase = 0	next_phase = 1	reward = 0.448097	array([[ 3.6405473, -9.268177 ]], dtype=float32)
time = 31135	action = 0	current_phase = 0	next_phase = 1	reward = 1.007625	array([[ 3.6284118, -9.302273 ]], dtype=float32)
time = 31140	action = 0	current_phase = 0	next_phase = 1	reward = 0.443546	array([[ 3.6878142, -9.228542 ]], dtype=float32)
time = 31145	action = 0	current_phase = 0	next_phase = 1	reward = 1.006246	array([[ 3.6433215, -9.286809 ]], dtype=float32)
time = 31150	action = 0	current_phase = 0	next_phase = 1	reward = 0.720058	array([[ 3.662746, -9.217861]], dtype=float32)
time = 31155	action = 0	current_phase = 0	next_phase = 1	reward = 0.730711	array([[ 3.6410127, -9.267296 ]], dtype=float32)
time = 31160	action = 0	current_phase = 0	next_phase = 1	reward = 0.722244	array([[ 3.6500754, -9.234114 ]], dtype=float32)
time = 31165	action = 0	current_phase = 0	next_phase = 1	reward = 0.719799	array([[ 3.6632304, -9.212109 ]], dtype=float32)
time = 31170	action = 0	current_phase = 0	next_phase = 1	reward = 0.715788	array([[ 3.6410956, -9.235699 ]], dtype=float32)
time = 31175	action = 0	current_phase = 0	next_phase = 1	reward = 0.434771	array([[ 3.5397048, -9.299944 ]], dtype=float32)
time = 31180	action = 0	current_phase = 0	next_phase = 1	reward = 0.442549	array([[ 3.6099582, -9.291449 ]], dtype=float32)
time = 31185	action = 0	current_phase = 0	next_phase = 1	reward = 1.289591	array([[ 3.6706243, -9.237871 ]], dtype=float32)
time = 31190	action = 0	current_phase = 0	next_phase = 1	reward = 0.720237	array([[ 3.639627, -9.29555 ]], dtype=float32)
time = 31195	action = 0	current_phase = 0	next_phase = 1	reward = 0.722946	array([[ 3.654694, -9.197626]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 7.1563 - val_loss: 1.6329
Epoch 2/50
 - 4s - loss: 5.2084 - val_loss: 2.2270
Epoch 3/50
 - 4s - loss: 7.7214 - val_loss: 1.7909
Epoch 4/50
 - 4s - loss: 5.2368 - val_loss: 2.0227
Epoch 5/50
 - 4s - loss: 5.9392 - val_loss: 1.7127
Epoch 6/50
 - 4s - loss: 3.9624 - val_loss: 1.8790
Epoch 7/50
 - 4s - loss: 4.6654 - val_loss: 2.2099
Epoch 8/50
 - 4s - loss: 6.9888 - val_loss: 2.7321
Epoch 9/50
 - 4s - loss: 4.5387 - val_loss: 2.0499
Epoch 10/50
 - 4s - loss: 5.5311 - val_loss: 2.2063
Epoch 11/50
 - 4s - loss: 4.2507 - val_loss: 2.7850
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 31200	action = 0	current_phase = 0	next_phase = 1	reward = 0.442265	array([[ 3.6848783, -9.255941 ]], dtype=float32)
time = 31205	action = 0	current_phase = 0	next_phase = 1	reward = 0.727988	array([[ 3.6595144, -9.271183 ]], dtype=float32)
time = 31210	action = 0	current_phase = 0	next_phase = 1	reward = 1.006724	array([[ 3.681899, -9.341583]], dtype=float32)
time = 31215	action = 0	current_phase = 0	next_phase = 1	reward = 0.717289	array([[ 3.661996, -9.229214]], dtype=float32)
time = 31220	action = 0	current_phase = 0	next_phase = 1	reward = 0.171391	array([[ 3.691163, -9.265799]], dtype=float32)
time = 31225	action = 0	current_phase = 0	next_phase = 1	reward = 1.282919	array([[ 3.682209, -9.289089]], dtype=float32)
time = 31230	action = 0	current_phase = 0	next_phase = 1	reward = 0.438518	array([[ 3.6316233, -9.338028 ]], dtype=float32)
time = 31235	action = 0	current_phase = 0	next_phase = 1	reward = 0.446143	array([[ 3.688573, -9.245337]], dtype=float32)
time = 31240	action = 0	current_phase = 0	next_phase = 1	reward = 1.281574	array([[ 3.651165, -9.368214]], dtype=float32)
time = 31245	action = 0	current_phase = 0	next_phase = 1	reward = 0.442494	array([[ 3.7282448, -9.234726 ]], dtype=float32)
time = 31250	action = 0	current_phase = 0	next_phase = 1	reward = 0.998686	array([[ 3.6832075, -9.261243 ]], dtype=float32)
time = 31255	action = 0	current_phase = 0	next_phase = 1	reward = 0.727417	array([[ 3.7242203, -9.274136 ]], dtype=float32)
time = 31260	action = 0	current_phase = 0	next_phase = 1	reward = 0.442769	array([[ 3.6773758, -9.192179 ]], dtype=float32)
time = 31265	action = 0	current_phase = 0	next_phase = 1	reward = 0.731657	array([[ 3.652855, -9.278536]], dtype=float32)
time = 31270	action = 0	current_phase = 0	next_phase = 1	reward = 1.015566	array([[ 3.6427202, -9.354145 ]], dtype=float32)
time = 31275	action = 0	current_phase = 0	next_phase = 1	reward = 0.727431	array([[ 3.6900597, -9.205372 ]], dtype=float32)
time = 31280	action = 0	current_phase = 0	next_phase = 1	reward = 0.445210	array([[ 3.6465502, -9.256476 ]], dtype=float32)
time = 31285	action = 0	current_phase = 0	next_phase = 1	reward = 0.730303	array([[ 3.62465 , -9.318014]], dtype=float32)
time = 31290	action = 0	current_phase = 0	next_phase = 1	reward = 1.006013	array([[ 3.6802282, -9.2613125]], dtype=float32)
time = 31295	action = 0	current_phase = 0	next_phase = 1	reward = 0.719127	array([[ 3.7167778, -9.153082 ]], dtype=float32)
time = 31300	action = 0	current_phase = 0	next_phase = 1	reward = 0.723687	array([[ 3.6218872, -9.244263 ]], dtype=float32)
time = 31305	action = 0	current_phase = 0	next_phase = 1	reward = 0.720946	array([[ 3.6524973, -9.232378 ]], dtype=float32)
time = 31310	action = 0	current_phase = 0	next_phase = 1	reward = 0.722880	array([[ 3.6249142, -9.294326 ]], dtype=float32)
time = 31315	action = 0	current_phase = 0	next_phase = 1	reward = 0.451592	array([[ 3.7087135, -9.189318 ]], dtype=float32)
time = 31320	action = 0	current_phase = 0	next_phase = 1	reward = 1.005838	array([[ 3.6127548, -9.395235 ]], dtype=float32)
time = 31325	action = 0	current_phase = 0	next_phase = 1	reward = 0.449993	array([[ 3.6694584, -9.247086 ]], dtype=float32)
time = 31330	action = 0	current_phase = 0	next_phase = 1	reward = 1.002795	array([[ 3.6549149, -9.290106 ]], dtype=float32)
time = 31335	action = 0	current_phase = 0	next_phase = 1	reward = 0.716329	array([[ 3.5734243, -9.266804 ]], dtype=float32)
time = 31340	action = 0	current_phase = 0	next_phase = 1	reward = 0.441454	array([[ 3.6758308, -9.261786 ]], dtype=float32)
time = 31345	action = 0	current_phase = 0	next_phase = 1	reward = 0.729558	array([[ 3.5976772, -9.317691 ]], dtype=float32)
time = 31350	action = 0	current_phase = 0	next_phase = 1	reward = 0.726666	array([[ 3.7448244, -9.2716675]], dtype=float32)
time = 31355	action = 0	current_phase = 0	next_phase = 1	reward = 1.004541	array([[ 3.657218, -9.280644]], dtype=float32)
time = 31360	action = 0	current_phase = 0	next_phase = 1	reward = 0.715619	array([[ 3.5860376, -9.242172 ]], dtype=float32)
time = 31365	action = 0	current_phase = 0	next_phase = 1	reward = 0.715499	array([[ 3.6811342, -9.283925 ]], dtype=float32)
time = 31370	action = 0	current_phase = 0	next_phase = 1	reward = 0.442963	array([[ 3.6524668, -9.246374 ]], dtype=float32)
time = 31375	action = 0	current_phase = 0	next_phase = 1	reward = 1.011736	array([[ 3.6812906, -9.231827 ]], dtype=float32)
time = 31380	action = 0	current_phase = 0	next_phase = 1	reward = 0.442810	array([[ 3.7019663, -9.212509 ]], dtype=float32)
time = 31385	action = 0	current_phase = 0	next_phase = 1	reward = 0.996992	array([[ 3.690918, -9.180787]], dtype=float32)
time = 31390	action = 0	current_phase = 0	next_phase = 1	reward = 0.719711	array([[ 3.7265167, -9.28508  ]], dtype=float32)
time = 31395	action = 0	current_phase = 0	next_phase = 1	reward = 0.720473	array([[ 3.5504322, -9.35948  ]], dtype=float32)
time = 31400	action = 0	current_phase = 0	next_phase = 1	reward = 0.446020	array([[ 3.7065067, -9.260358 ]], dtype=float32)
time = 31405	action = 0	current_phase = 0	next_phase = 1	reward = 1.014133	array([[ 3.697939, -9.250273]], dtype=float32)
time = 31410	action = 0	current_phase = 0	next_phase = 1	reward = 0.717654	array([[ 3.7201633, -9.2603   ]], dtype=float32)
time = 31415	action = 0	current_phase = 0	next_phase = 1	reward = 0.723657	array([[ 3.6821938, -9.240934 ]], dtype=float32)
time = 31420	action = 0	current_phase = 0	next_phase = 1	reward = 0.441861	array([[ 3.641018, -9.257547]], dtype=float32)
time = 31425	action = 0	current_phase = 0	next_phase = 1	reward = 0.727305	array([[ 3.6757326, -9.196642 ]], dtype=float32)
time = 31430	action = 0	current_phase = 0	next_phase = 1	reward = 0.722661	array([[ 3.6449537, -9.2599945]], dtype=float32)
time = 31435	action = 0	current_phase = 0	next_phase = 1	reward = 0.997226	array([[ 3.6513395, -9.28463  ]], dtype=float32)
time = 31440	action = 0	current_phase = 0	next_phase = 1	reward = 0.445026	array([[ 3.7017384, -9.319937 ]], dtype=float32)
time = 31445	action = 0	current_phase = 0	next_phase = 1	reward = 0.735029	array([[ 3.668518, -9.190735]], dtype=float32)
time = 31450	action = 0	current_phase = 0	next_phase = 1	reward = 1.005662	array([[ 3.6684618, -9.277439 ]], dtype=float32)
time = 31455	action = 0	current_phase = 0	next_phase = 1	reward = 0.437990	array([[ 3.675641, -9.262548]], dtype=float32)
time = 31460	action = 0	current_phase = 0	next_phase = 1	reward = 0.724444	array([[ 3.662589, -9.288986]], dtype=float32)
time = 31465	action = 0	current_phase = 0	next_phase = 1	reward = 0.727354	array([[ 3.6969633, -9.297119 ]], dtype=float32)
time = 31470	action = 0	current_phase = 0	next_phase = 1	reward = 1.002751	array([[ 3.7090282, -9.233028 ]], dtype=float32)
time = 31475	action = 0	current_phase = 0	next_phase = 1	reward = 0.722761	array([[ 3.6727858, -9.24544  ]], dtype=float32)
time = 31480	action = 0	current_phase = 0	next_phase = 1	reward = 0.735007	array([[ 3.7097626, -9.177119 ]], dtype=float32)
time = 31485	action = 0	current_phase = 0	next_phase = 1	reward = 0.720453	array([[ 3.676982, -9.292116]], dtype=float32)
time = 31490	action = 0	current_phase = 0	next_phase = 1	reward = 0.441250	array([[ 3.672079, -9.231802]], dtype=float32)
time = 31495	action = 0	current_phase = 0	next_phase = 1	reward = 0.999674	array([[ 3.656291 , -9.2858715]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.2135 - val_loss: 2.6945
Epoch 2/50
 - 4s - loss: 5.8604 - val_loss: 1.8289
Epoch 3/50
 - 4s - loss: 5.1077 - val_loss: 1.7754
Epoch 4/50
 - 4s - loss: 7.3677 - val_loss: 1.7106
Epoch 5/50
 - 4s - loss: 5.1927 - val_loss: 2.9178
Epoch 6/50
 - 6s - loss: 4.4545 - val_loss: 1.9727
Epoch 7/50
 - 4s - loss: 5.8994 - val_loss: 1.6369
Epoch 8/50
 - 4s - loss: 4.4054 - val_loss: 2.3948
Epoch 9/50
 - 4s - loss: 5.3849 - val_loss: 1.6416
Epoch 10/50
 - 4s - loss: 5.2930 - val_loss: 2.1377
Epoch 11/50
 - 4s - loss: 5.6508 - val_loss: 2.4026
Epoch 12/50
 - 4s - loss: 6.9062 - val_loss: 3.7203
Epoch 13/50
 - 4s - loss: 4.5964 - val_loss: 2.3989
Epoch 14/50
 - 4s - loss: 4.7027 - val_loss: 2.3474
Epoch 15/50
 - 4s - loss: 5.5448 - val_loss: 2.1429
Epoch 16/50
 - 4s - loss: 7.2780 - val_loss: 2.3119
Epoch 17/50
 - 4s - loss: 5.1366 - val_loss: 2.3445
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 31500	action = 0	current_phase = 0	next_phase = 1	reward = 0.440554	array([[ 3.6541076, -9.245655 ]], dtype=float32)
time = 31505	action = 0	current_phase = 0	next_phase = 1	reward = 1.004397	array([[ 3.6594605, -9.213372 ]], dtype=float32)
time = 31510	action = 0	current_phase = 0	next_phase = 1	reward = 0.722095	array([[ 3.5666738, -9.243344 ]], dtype=float32)
time = 31515	action = 0	current_phase = 0	next_phase = 1	reward = 0.720901	array([[ 3.6357799, -9.204684 ]], dtype=float32)
time = 31520	action = 0	current_phase = 0	next_phase = 1	reward = 0.450375	array([[ 3.640925, -9.16988 ]], dtype=float32)
time = 31525	action = 0	current_phase = 0	next_phase = 1	reward = 0.721083	array([[ 3.6536078, -9.192148 ]], dtype=float32)
time = 31530	action = 0	current_phase = 0	next_phase = 1	reward = 1.005803	array([[ 3.5968099, -9.24579  ]], dtype=float32)
time = 31535	action = 0	current_phase = 0	next_phase = 1	reward = 0.445098	array([[ 3.6300073, -9.24017  ]], dtype=float32)
time = 31540	action = 0	current_phase = 0	next_phase = 1	reward = 1.003716	array([[ 3.6088347, -9.239397 ]], dtype=float32)
time = 31545	action = 0	current_phase = 0	next_phase = 1	reward = 0.719489	array([[ 3.6335616, -9.232499 ]], dtype=float32)
time = 31550	action = 0	current_phase = 0	next_phase = 1	reward = 0.726457	array([[ 3.664555, -9.221661]], dtype=float32)
time = 31555	action = 0	current_phase = 0	next_phase = 1	reward = 0.727651	array([[ 3.6256814, -9.258346 ]], dtype=float32)
time = 31560	action = 0	current_phase = 0	next_phase = 1	reward = 0.729254	array([[ 3.6462235, -9.217117 ]], dtype=float32)
time = 31565	action = 0	current_phase = 0	next_phase = 1	reward = 0.725044	array([[ 3.6401353, -9.245808 ]], dtype=float32)
time = 31570	action = 0	current_phase = 0	next_phase = 1	reward = 0.723716	array([[ 3.6579785, -9.155844 ]], dtype=float32)
time = 31575	action = 0	current_phase = 0	next_phase = 1	reward = 0.729279	array([[ 3.6521153, -9.261714 ]], dtype=float32)
time = 31580	action = 0	current_phase = 0	next_phase = 1	reward = 0.721131	array([[ 3.6303754, -9.286324 ]], dtype=float32)
time = 31585	action = 0	current_phase = 0	next_phase = 1	reward = 0.725860	array([[ 3.6558595, -9.252112 ]], dtype=float32)
time = 31590	action = 0	current_phase = 0	next_phase = 1	reward = 0.725001	array([[ 3.6632428, -9.196619 ]], dtype=float32)
time = 31595	action = 0	current_phase = 0	next_phase = 1	reward = 0.444070	array([[ 3.6410575, -9.23109  ]], dtype=float32)
time = 31600	action = 0	current_phase = 0	next_phase = 1	reward = 1.002731	array([[ 3.6277204, -9.2382145]], dtype=float32)
time = 31605	action = 0	current_phase = 0	next_phase = 1	reward = 0.716962	array([[ 3.6287198, -9.191399 ]], dtype=float32)
time = 31610	action = 0	current_phase = 0	next_phase = 1	reward = 0.720694	array([[ 3.6750445, -9.209719 ]], dtype=float32)
time = 31615	action = 0	current_phase = 0	next_phase = 1	reward = 0.716068	array([[ 3.6278129, -9.188168 ]], dtype=float32)
time = 31620	action = 0	current_phase = 0	next_phase = 1	reward = 0.450155	array([[ 3.6352725, -9.225962 ]], dtype=float32)
time = 31625	action = 0	current_phase = 0	next_phase = 1	reward = 1.011526	array([[ 3.586681, -9.281569]], dtype=float32)
time = 31630	action = 0	current_phase = 0	next_phase = 1	reward = 0.443744	array([[ 3.6734338, -9.175641 ]], dtype=float32)
time = 31635	action = 0	current_phase = 0	next_phase = 1	reward = 0.996113	array([[ 3.6180453, -9.210343 ]], dtype=float32)
time = 31640	action = 0	current_phase = 0	next_phase = 1	reward = 0.431673	array([[ 3.6451402, -9.235119 ]], dtype=float32)
time = 31645	action = 0	current_phase = 0	next_phase = 1	reward = 0.996920	array([[ 3.6157537, -9.264612 ]], dtype=float32)
time = 31650	action = 0	current_phase = 0	next_phase = 1	reward = 0.720630	array([[ 3.6513028, -9.199795 ]], dtype=float32)
time = 31655	action = 0	current_phase = 0	next_phase = 1	reward = 0.726042	array([[ 3.6547046, -9.18767  ]], dtype=float32)
time = 31660	action = 0	current_phase = 0	next_phase = 1	reward = 0.447599	array([[ 3.5900912, -9.339972 ]], dtype=float32)
time = 31665	action = 0	current_phase = 0	next_phase = 1	reward = 1.003106	array([[ 3.5775828, -9.262409 ]], dtype=float32)
time = 31670	action = 0	current_phase = 0	next_phase = 1	reward = 0.713089	array([[ 3.68251 , -9.172188]], dtype=float32)
time = 31675	action = 0	current_phase = 0	next_phase = 1	reward = 0.706449	array([[ 3.6096053, -9.221211 ]], dtype=float32)
time = 31680	action = 0	current_phase = 0	next_phase = 1	reward = 0.436386	array([[ 3.650844 , -9.2339945]], dtype=float32)
time = 31685	action = 0	current_phase = 0	next_phase = 1	reward = 0.731185	array([[ 3.5938134, -9.280186 ]], dtype=float32)
time = 31690	action = 0	current_phase = 0	next_phase = 1	reward = 0.737694	array([[ 3.6290936, -9.249063 ]], dtype=float32)
time = 31695	action = 0	current_phase = 0	next_phase = 1	reward = 1.006247	array([[ 3.6283164, -9.215605 ]], dtype=float32)
time = 31700	action = 0	current_phase = 0	next_phase = 1	reward = 0.724136	array([[ 3.6692433, -9.190298 ]], dtype=float32)
time = 31705	action = 0	current_phase = 0	next_phase = 1	reward = 0.726242	array([[ 3.6708045, -9.188831 ]], dtype=float32)
time = 31710	action = 0	current_phase = 0	next_phase = 1	reward = 0.726437	array([[ 3.5858226, -9.27874  ]], dtype=float32)
time = 31715	action = 0	current_phase = 0	next_phase = 1	reward = 0.734103	array([[ 3.6350007, -9.180277 ]], dtype=float32)
time = 31720	action = 0	current_phase = 0	next_phase = 1	reward = 0.724784	array([[ 3.6631427, -9.221072 ]], dtype=float32)
time = 31725	action = 0	current_phase = 0	next_phase = 1	reward = 0.718181	array([[ 3.6319613, -9.21677  ]], dtype=float32)
time = 31730	action = 0	current_phase = 0	next_phase = 1	reward = 0.715707	array([[ 3.6292415, -9.2409725]], dtype=float32)
time = 31735	action = 0	current_phase = 0	next_phase = 1	reward = 0.717126	array([[ 3.5957665, -9.29136  ]], dtype=float32)
time = 31740	action = 0	current_phase = 0	next_phase = 1	reward = 0.721476	array([[ 3.5911403, -9.216978 ]], dtype=float32)
time = 31745	action = 0	current_phase = 0	next_phase = 1	reward = 0.447646	array([[ 3.6221595, -9.225281 ]], dtype=float32)
time = 31750	action = 0	current_phase = 0	next_phase = 1	reward = 1.007371	array([[ 3.5841384, -9.263109 ]], dtype=float32)
time = 31755	action = 0	current_phase = 0	next_phase = 1	reward = 0.438290	array([[ 3.6532083, -9.241163 ]], dtype=float32)
time = 31760	action = 0	current_phase = 0	next_phase = 1	reward = 1.005674	array([[ 3.6054072, -9.23299  ]], dtype=float32)
time = 31765	action = 0	current_phase = 0	next_phase = 1	reward = 0.443227	array([[ 3.6332002, -9.23361  ]], dtype=float32)
time = 31770	action = 0	current_phase = 0	next_phase = 1	reward = 0.723284	array([[ 3.6786923, -9.278923 ]], dtype=float32)
time = 31775	action = 0	current_phase = 0	next_phase = 1	reward = 1.000089	array([[ 3.6399236, -9.218338 ]], dtype=float32)
time = 31780	action = 0	current_phase = 0	next_phase = 1	reward = 0.718924	array([[ 3.6400723, -9.206554 ]], dtype=float32)
time = 31785	action = 0	current_phase = 0	next_phase = 1	reward = 0.443747	array([[ 3.6674523, -9.18335  ]], dtype=float32)
time = 31790	action = 0	current_phase = 0	next_phase = 1	reward = 1.005716	array([[ 3.6548514, -9.2505   ]], dtype=float32)
time = 31795	action = 0	current_phase = 0	next_phase = 1	reward = 0.435272	array([[ 3.628655, -9.2549  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.1706 - val_loss: 1.8913
Epoch 2/50
 - 4s - loss: 4.3333 - val_loss: 2.0590
Epoch 3/50
 - 4s - loss: 4.8541 - val_loss: 2.4418
Epoch 4/50
 - 4s - loss: 5.1072 - val_loss: 2.0200
Epoch 5/50
 - 4s - loss: 5.7136 - val_loss: 2.0800
Epoch 6/50
 - 4s - loss: 5.1501 - val_loss: 2.1937
Epoch 7/50
 - 4s - loss: 4.6403 - val_loss: 1.9640
Epoch 8/50
 - 4s - loss: 7.9481 - val_loss: 2.8523
Epoch 9/50
 - 4s - loss: 4.6473 - val_loss: 2.9562
Epoch 10/50
 - 4s - loss: 4.0330 - val_loss: 1.8337
Epoch 11/50
 - 4s - loss: 4.2100 - val_loss: 1.8437
Epoch 12/50
 - 4s - loss: 7.0522 - val_loss: 1.9740
Epoch 13/50
 - 4s - loss: 5.4218 - val_loss: 1.9617
Epoch 14/50
 - 4s - loss: 4.7298 - val_loss: 2.5146
Epoch 15/50
 - 4s - loss: 5.2580 - val_loss: 2.0124
Epoch 16/50
 - 4s - loss: 4.9317 - val_loss: 2.1312
Epoch 17/50
 - 4s - loss: 3.7806 - val_loss: 2.4845
Epoch 18/50
 - 4s - loss: 5.0362 - val_loss: 2.5044
Epoch 19/50
 - 4s - loss: 4.3089 - val_loss: 1.9288
Epoch 20/50
 - 4s - loss: 4.7991 - val_loss: 2.4377
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 31800	action = 0	current_phase = 0	next_phase = 1	reward = 0.732563	array([[ 3.641005, -9.219957]], dtype=float32)
time = 31805	action = 0	current_phase = 0	next_phase = 1	reward = 0.726650	array([[ 3.677754, -9.158572]], dtype=float32)
time = 31810	action = 0	current_phase = 0	next_phase = 1	reward = 1.006272	array([[ 3.684526, -9.274955]], dtype=float32)
time = 31815	action = 0	current_phase = 0	next_phase = 1	reward = 0.724918	array([[ 3.7024589, -9.169036 ]], dtype=float32)
time = 31820	action = 0	current_phase = 0	next_phase = 1	reward = 0.438440	array([[ 3.6733756, -9.233583 ]], dtype=float32)
time = 31825	action = 0	current_phase = 0	next_phase = 1	reward = 0.715717	array([[ 3.691033, -9.250841]], dtype=float32)
time = 31830	action = 0	current_phase = 0	next_phase = 1	reward = 0.729227	array([[ 3.6806483, -9.262983 ]], dtype=float32)
time = 31835	action = 0	current_phase = 0	next_phase = 1	reward = 0.726770	array([[ 3.6490645, -9.235174 ]], dtype=float32)
time = 31840	action = 0	current_phase = 0	next_phase = 1	reward = 1.005543	array([[ 3.663014, -9.256768]], dtype=float32)
time = 31845	action = 0	current_phase = 0	next_phase = 1	reward = 0.727708	array([[ 3.6253362, -9.269625 ]], dtype=float32)
time = 31850	action = 0	current_phase = 0	next_phase = 1	reward = 0.712571	array([[ 3.627684, -9.236311]], dtype=float32)
time = 31855	action = 0	current_phase = 0	next_phase = 1	reward = 0.720659	array([[ 3.6671586, -9.2038145]], dtype=float32)
time = 31860	action = 0	current_phase = 0	next_phase = 1	reward = 0.442018	array([[ 3.6567578, -9.188215 ]], dtype=float32)
time = 31865	action = 0	current_phase = 0	next_phase = 1	reward = 0.730699	array([[ 3.6812062, -9.211002 ]], dtype=float32)
time = 31870	action = 0	current_phase = 0	next_phase = 1	reward = 1.001354	array([[ 3.682222, -9.221413]], dtype=float32)
time = 31875	action = 0	current_phase = 0	next_phase = 1	reward = 0.720091	array([[ 3.6889405, -9.205475 ]], dtype=float32)
time = 31880	action = 0	current_phase = 0	next_phase = 1	reward = 0.444473	array([[ 3.655581, -9.201   ]], dtype=float32)
time = 31885	action = 0	current_phase = 0	next_phase = 1	reward = 1.007276	array([[ 3.609651, -9.346455]], dtype=float32)
time = 31890	action = 0	current_phase = 0	next_phase = 1	reward = 0.439884	array([[ 3.660933, -9.20553 ]], dtype=float32)
time = 31895	action = 0	current_phase = 0	next_phase = 1	reward = 0.728155	array([[ 3.635612, -9.384117]], dtype=float32)
time = 31900	action = 0	current_phase = 0	next_phase = 1	reward = 0.726313	array([[ 3.6749616, -9.162205 ]], dtype=float32)
time = 31905	action = 0	current_phase = 0	next_phase = 1	reward = 1.004454	array([[ 3.6469207, -9.246099 ]], dtype=float32)
time = 31910	action = 0	current_phase = 0	next_phase = 1	reward = 0.720035	array([[ 3.6420493, -9.230814 ]], dtype=float32)
time = 31915	action = 0	current_phase = 0	next_phase = 1	reward = 0.446380	array([[ 3.6373057, -9.234476 ]], dtype=float32)
time = 31920	action = 0	current_phase = 0	next_phase = 1	reward = 0.723826	array([[ 3.6242785, -9.309027 ]], dtype=float32)
time = 31925	action = 0	current_phase = 0	next_phase = 1	reward = 0.728884	array([[ 3.6888156, -9.293812 ]], dtype=float32)
time = 31930	action = 0	current_phase = 0	next_phase = 1	reward = 0.716828	array([[ 3.6802735, -9.156311 ]], dtype=float32)
time = 31935	action = 0	current_phase = 0	next_phase = 1	reward = 1.003419	array([[ 3.6834502, -9.25826  ]], dtype=float32)
time = 31940	action = 0	current_phase = 0	next_phase = 1	reward = 0.437601	array([[ 3.6411538, -9.22909  ]], dtype=float32)
time = 31945	action = 0	current_phase = 0	next_phase = 1	reward = 0.444589	array([[ 3.668118, -9.233462]], dtype=float32)
time = 31950	action = 0	current_phase = 0	next_phase = 1	reward = 1.010164	array([[ 3.6606336, -9.259693 ]], dtype=float32)
time = 31955	action = 0	current_phase = 0	next_phase = 1	reward = 1.003827	array([[ 3.6593852, -9.233145 ]], dtype=float32)
time = 31960	action = 0	current_phase = 0	next_phase = 1	reward = 0.715743	array([[ 3.67775 , -9.155995]], dtype=float32)
time = 31965	action = 0	current_phase = 0	next_phase = 1	reward = 0.452611	array([[ 3.6027064, -9.220114 ]], dtype=float32)
time = 31970	action = 0	current_phase = 0	next_phase = 1	reward = 1.004047	array([[ 3.7164245, -9.256033 ]], dtype=float32)
time = 31975	action = 0	current_phase = 0	next_phase = 1	reward = 0.439286	array([[ 3.7133117, -9.185219 ]], dtype=float32)
time = 31980	action = 0	current_phase = 0	next_phase = 1	reward = 0.730342	array([[ 3.6899295, -9.188243 ]], dtype=float32)
time = 31985	action = 0	current_phase = 0	next_phase = 1	reward = 1.011765	array([[ 3.6658072, -9.198189 ]], dtype=float32)
time = 31990	action = 0	current_phase = 0	next_phase = 1	reward = 0.725099	array([[ 3.6867976, -9.233221 ]], dtype=float32)
time = 31995	action = 0	current_phase = 0	next_phase = 1	reward = 0.717727	array([[ 3.674214, -9.193565]], dtype=float32)
time = 32000	action = 0	current_phase = 0	next_phase = 1	reward = 0.711711	array([[ 3.691071, -9.276786]], dtype=float32)
time = 32005	action = 0	current_phase = 0	next_phase = 1	reward = 0.720311	array([[ 3.7117238, -9.206301 ]], dtype=float32)
time = 32010	action = 0	current_phase = 0	next_phase = 1	reward = 0.736333	array([[ 3.6905255, -9.280424 ]], dtype=float32)
time = 32015	action = 0	current_phase = 0	next_phase = 1	reward = 0.733432	array([[ 3.5643268, -9.38129  ]], dtype=float32)
time = 32020	action = 0	current_phase = 0	next_phase = 1	reward = 0.715943	array([[ 3.677115, -9.290867]], dtype=float32)
time = 32025	action = 0	current_phase = 0	next_phase = 1	reward = 0.725184	array([[ 3.5533233, -9.27969  ]], dtype=float32)
time = 32030	action = 0	current_phase = 0	next_phase = 1	reward = 0.451010	array([[ 3.6993299, -9.224426 ]], dtype=float32)
time = 32035	action = 0	current_phase = 0	next_phase = 1	reward = 1.008917	array([[ 3.6641536, -9.248594 ]], dtype=float32)
time = 32040	action = 0	current_phase = 0	next_phase = 1	reward = 0.722391	array([[ 3.671101, -9.175964]], dtype=float32)
time = 32045	action = 0	current_phase = 0	next_phase = 1	reward = 0.720247	array([[ 3.6628985, -9.264839 ]], dtype=float32)
time = 32050	action = 0	current_phase = 0	next_phase = 1	reward = 0.718748	array([[ 3.6446614, -9.181747 ]], dtype=float32)
time = 32055	action = 0	current_phase = 0	next_phase = 1	reward = 0.452605	array([[ 3.6324677, -9.217333 ]], dtype=float32)
time = 32060	action = 0	current_phase = 0	next_phase = 1	reward = 0.726442	array([[ 3.6573958, -9.192966 ]], dtype=float32)
time = 32065	action = 0	current_phase = 0	next_phase = 1	reward = 0.994786	array([[ 3.6352258, -9.306082 ]], dtype=float32)
time = 32070	action = 0	current_phase = 0	next_phase = 1	reward = 0.719763	array([[ 3.6968284, -9.225292 ]], dtype=float32)
time = 32075	action = 0	current_phase = 0	next_phase = 1	reward = 0.719912	array([[ 3.6911187, -9.2362385]], dtype=float32)
time = 32080	action = 0	current_phase = 0	next_phase = 1	reward = 0.443782	array([[ 3.6789832, -9.245895 ]], dtype=float32)
time = 32085	action = 0	current_phase = 0	next_phase = 1	reward = 1.012641	array([[ 3.6899257, -9.171818 ]], dtype=float32)
time = 32090	action = 0	current_phase = 0	next_phase = 1	reward = 0.722605	array([[ 3.6916375, -9.243336 ]], dtype=float32)
time = 32095	action = 0	current_phase = 0	next_phase = 1	reward = 0.443168	array([[ 3.5960984, -9.248869 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.9525 - val_loss: 2.3237
Epoch 2/50
 - 4s - loss: 5.6648 - val_loss: 2.9932
Epoch 3/50
 - 4s - loss: 6.7760 - val_loss: 3.0042
Epoch 4/50
 - 4s - loss: 5.1797 - val_loss: 2.1839
Epoch 5/50
 - 4s - loss: 3.5958 - val_loss: 2.6138
Epoch 6/50
 - 4s - loss: 5.6894 - val_loss: 4.4686
Epoch 7/50
 - 4s - loss: 6.1295 - val_loss: 3.2299
Epoch 8/50
 - 4s - loss: 6.6615 - val_loss: 2.6733
Epoch 9/50
 - 4s - loss: 3.7101 - val_loss: 2.5265
Epoch 10/50
 - 4s - loss: 8.1133 - val_loss: 2.5305
Epoch 11/50
 - 4s - loss: 3.1961 - val_loss: 2.0054
Epoch 12/50
 - 4s - loss: 4.2249 - val_loss: 2.8090
Epoch 13/50
 - 4s - loss: 4.2270 - val_loss: 2.8165
Epoch 14/50
 - 4s - loss: 4.3914 - val_loss: 2.6998
Epoch 15/50
 - 4s - loss: 4.5353 - val_loss: 2.4467
Epoch 16/50
 - 4s - loss: 5.5492 - val_loss: 2.9323
Epoch 17/50
 - 4s - loss: 5.0671 - val_loss: 2.7864
Epoch 18/50
 - 4s - loss: 3.8922 - val_loss: 2.4272
Epoch 19/50
 - 4s - loss: 4.2734 - val_loss: 4.0930
Epoch 20/50
 - 4s - loss: 6.1831 - val_loss: 3.6923
Epoch 21/50
 - 4s - loss: 3.3250 - val_loss: 3.4888
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 32100	action = 0	current_phase = 0	next_phase = 1	reward = 0.999626	array([[ 3.6324306, -9.267392 ]], dtype=float32)
time = 32105	action = 0	current_phase = 0	next_phase = 1	reward = 0.445544	array([[ 3.5689921, -9.248776 ]], dtype=float32)
time = 32110	action = 0	current_phase = 0	next_phase = 1	reward = 1.004161	array([[ 3.6706681, -9.215832 ]], dtype=float32)
time = 32115	action = 0	current_phase = 0	next_phase = 1	reward = 0.715566	array([[ 3.6068368, -9.187773 ]], dtype=float32)
time = 32120	action = 0	current_phase = 0	next_phase = 1	reward = 0.166666	array([[ 3.6155753, -9.203064 ]], dtype=float32)
time = 32125	action = 0	current_phase = 0	next_phase = 1	reward = 1.293452	array([[ 3.6119885, -9.316593 ]], dtype=float32)
time = 32130	action = 0	current_phase = 0	next_phase = 1	reward = 0.719497	array([[ 3.555386, -9.23657 ]], dtype=float32)
time = 32135	action = 0	current_phase = 0	next_phase = 1	reward = 0.440224	array([[ 3.6368213, -9.242903 ]], dtype=float32)
time = 32140	action = 0	current_phase = 0	next_phase = 1	reward = 0.998139	array([[ 3.3694339, -9.513116 ]], dtype=float32)
time = 32145	action = 0	current_phase = 0	next_phase = 1	reward = 0.443946	array([[ 3.6614232, -9.195848 ]], dtype=float32)
time = 32150	action = 0	current_phase = 0	next_phase = 1	reward = 0.724816	array([[ 3.5841308, -9.328867 ]], dtype=float32)
time = 32155	action = 0	current_phase = 0	next_phase = 1	reward = 0.444523	array([[ 3.4931064, -9.407791 ]], dtype=float32)
time = 32160	action = 0	current_phase = 0	next_phase = 1	reward = 1.007762	array([[ 3.6078877, -9.19779  ]], dtype=float32)
time = 32165	action = 0	current_phase = 0	next_phase = 1	reward = 0.732214	array([[ 3.4408555, -9.389675 ]], dtype=float32)
time = 32170	action = 0	current_phase = 0	next_phase = 1	reward = 1.011906	array([[ 3.631699, -9.202945]], dtype=float32)
time = 32175	action = 0	current_phase = 0	next_phase = 1	reward = 0.728468	array([[ 3.6049266, -9.3042755]], dtype=float32)
time = 32180	action = 0	current_phase = 0	next_phase = 1	reward = 0.721171	array([[ 3.5861201, -9.274136 ]], dtype=float32)
time = 32185	action = 0	current_phase = 0	next_phase = 1	reward = 0.443304	array([[ 3.6178823, -9.23555  ]], dtype=float32)
time = 32190	action = 0	current_phase = 0	next_phase = 1	reward = 1.002533	array([[ 3.6683955, -9.190476 ]], dtype=float32)
time = 32195	action = 0	current_phase = 0	next_phase = 1	reward = 0.722663	array([[ 3.6534266, -9.220577 ]], dtype=float32)
time = 32200	action = 0	current_phase = 0	next_phase = 1	reward = 0.441178	array([[ 3.5332026, -9.239037 ]], dtype=float32)
time = 32205	action = 0	current_phase = 0	next_phase = 1	reward = 1.007853	array([[ 3.6540217, -9.355713 ]], dtype=float32)
time = 32210	action = 0	current_phase = 0	next_phase = 1	reward = 0.728430	array([[ 3.6580796, -9.21092  ]], dtype=float32)
time = 32215	action = 0	current_phase = 0	next_phase = 1	reward = 0.443106	array([[ 3.6546311, -9.327908 ]], dtype=float32)
time = 32220	action = 0	current_phase = 0	next_phase = 1	reward = 1.008544	array([[ 3.6619859, -9.264645 ]], dtype=float32)
time = 32225	action = 0	current_phase = 0	next_phase = 1	reward = 0.721519	array([[ 3.6342578, -9.1736145]], dtype=float32)
time = 32230	action = 0	current_phase = 0	next_phase = 1	reward = 0.717700	array([[ 3.6567569, -9.231664 ]], dtype=float32)
time = 32235	action = 0	current_phase = 0	next_phase = 1	reward = 0.717955	array([[ 3.645453, -9.218046]], dtype=float32)
time = 32240	action = 0	current_phase = 0	next_phase = 1	reward = 0.718545	array([[ 3.673016, -9.22212 ]], dtype=float32)
time = 32245	action = 0	current_phase = 0	next_phase = 1	reward = 0.733081	array([[ 3.6814322, -9.226742 ]], dtype=float32)
time = 32250	action = 0	current_phase = 0	next_phase = 1	reward = 0.718728	array([[ 3.678947, -9.231113]], dtype=float32)
time = 32255	action = 0	current_phase = 0	next_phase = 1	reward = 0.719836	array([[ 3.6276631, -9.201389 ]], dtype=float32)
time = 32260	action = 0	current_phase = 0	next_phase = 1	reward = 0.719810	array([[ 3.593018, -9.246831]], dtype=float32)
time = 32265	action = 0	current_phase = 0	next_phase = 1	reward = 0.731954	array([[ 3.6273236, -9.2628765]], dtype=float32)
time = 32270	action = 0	current_phase = 0	next_phase = 1	reward = 0.723258	array([[ 3.6792903, -9.208274 ]], dtype=float32)
time = 32275	action = 0	current_phase = 0	next_phase = 1	reward = 0.718131	array([[ 3.6050391, -9.168347 ]], dtype=float32)
time = 32280	action = 0	current_phase = 0	next_phase = 1	reward = 0.443783	array([[ 3.6209035, -9.239047 ]], dtype=float32)
time = 32285	action = 0	current_phase = 0	next_phase = 1	reward = 0.724760	array([[ 3.6061482, -9.3166275]], dtype=float32)
time = 32290	action = 0	current_phase = 0	next_phase = 1	reward = 1.001504	array([[ 3.5566926, -9.289291 ]], dtype=float32)
time = 32295	action = 0	current_phase = 0	next_phase = 1	reward = 0.719619	array([[ 3.6597934, -9.224076 ]], dtype=float32)
time = 32300	action = 0	current_phase = 0	next_phase = 1	reward = 0.716834	array([[ 3.6364589, -9.220131 ]], dtype=float32)
time = 32305	action = 0	current_phase = 0	next_phase = 1	reward = 0.438714	array([[ 3.5633893, -9.276963 ]], dtype=float32)
time = 32310	action = 0	current_phase = 0	next_phase = 1	reward = 0.720910	array([[ 3.6250777, -9.186098 ]], dtype=float32)
time = 32315	action = 0	current_phase = 0	next_phase = 1	reward = 0.721488	array([[ 3.669004, -9.19693 ]], dtype=float32)
time = 32320	action = 0	current_phase = 0	next_phase = 1	reward = 1.005566	array([[ 3.618157, -9.301491]], dtype=float32)
time = 32325	action = 0	current_phase = 0	next_phase = 1	reward = 0.441959	array([[ 3.5622993, -9.2180195]], dtype=float32)
time = 32330	action = 0	current_phase = 0	next_phase = 1	reward = 0.737085	array([[ 3.590466, -9.296671]], dtype=float32)
time = 32335	action = 0	current_phase = 0	next_phase = 1	reward = 0.999938	array([[ 3.594215, -9.280986]], dtype=float32)
time = 32340	action = 0	current_phase = 0	next_phase = 1	reward = 0.445166	array([[ 3.6455216, -9.254944 ]], dtype=float32)
time = 32345	action = 0	current_phase = 0	next_phase = 1	reward = 1.000759	array([[ 3.5532088, -9.305609 ]], dtype=float32)
time = 32350	action = 0	current_phase = 0	next_phase = 1	reward = 0.447377	array([[ 3.6147714, -9.231926 ]], dtype=float32)
time = 32355	action = 0	current_phase = 0	next_phase = 1	reward = 1.005196	array([[ 3.7201915, -9.2464285]], dtype=float32)
time = 32360	action = 0	current_phase = 0	next_phase = 1	reward = 0.443274	array([[ 3.5768323, -9.264196 ]], dtype=float32)
time = 32365	action = 0	current_phase = 0	next_phase = 1	reward = 0.452094	array([[ 3.6640983, -9.157166 ]], dtype=float32)
time = 32370	action = 0	current_phase = 0	next_phase = 1	reward = 1.289542	array([[ 3.6326642, -9.330702 ]], dtype=float32)
time = 32375	action = 0	current_phase = 0	next_phase = 1	reward = 0.729619	array([[ 3.6655211, -9.1712055]], dtype=float32)
time = 32380	action = 0	current_phase = 0	next_phase = 1	reward = 0.726620	array([[ 3.627441 , -9.2162895]], dtype=float32)
time = 32385	action = 0	current_phase = 0	next_phase = 1	reward = 0.725220	array([[ 3.6261392, -9.230616 ]], dtype=float32)
time = 32390	action = 0	current_phase = 0	next_phase = 1	reward = 0.714824	array([[ 3.1738324, -9.306722 ]], dtype=float32)
time = 32395	action = 0	current_phase = 0	next_phase = 1	reward = 0.444153	array([[ 3.5688405, -9.225564 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.0595 - val_loss: 2.5108
Epoch 2/50
 - 4s - loss: 6.0897 - val_loss: 2.9659
Epoch 3/50
 - 4s - loss: 3.2200 - val_loss: 2.8452
Epoch 4/50
 - 4s - loss: 4.3676 - val_loss: 2.3442
Epoch 5/50
 - 4s - loss: 3.7871 - val_loss: 2.9554
Epoch 6/50
 - 4s - loss: 6.2421 - val_loss: 2.2409
Epoch 7/50
 - 4s - loss: 4.1056 - val_loss: 2.2305
Epoch 8/50
 - 4s - loss: 3.8185 - val_loss: 2.8162
Epoch 9/50
 - 4s - loss: 3.4667 - val_loss: 3.0130
Epoch 10/50
 - 4s - loss: 2.8703 - val_loss: 2.6705
Epoch 11/50
 - 4s - loss: 4.1302 - val_loss: 2.0804
Epoch 12/50
 - 4s - loss: 4.5716 - val_loss: 2.7771
Epoch 13/50
 - 4s - loss: 3.9690 - val_loss: 2.4660
Epoch 14/50
 - 4s - loss: 3.7475 - val_loss: 2.9936
Epoch 15/50
 - 4s - loss: 4.2451 - val_loss: 2.7659
Epoch 16/50
 - 4s - loss: 3.7700 - val_loss: 2.6163
Epoch 17/50
 - 4s - loss: 5.0489 - val_loss: 3.0673
Epoch 18/50
 - 4s - loss: 5.7723 - val_loss: 3.0916
Epoch 19/50
 - 4s - loss: 6.4865 - val_loss: 2.3706
Epoch 20/50
 - 4s - loss: 5.8594 - val_loss: 2.6442
Epoch 21/50
 - 4s - loss: 3.2577 - val_loss: 3.5235
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 32400	action = 0	current_phase = 0	next_phase = 1	reward = 0.727778	array([[ 3.5900712, -9.271767 ]], dtype=float32)
time = 32405	action = 0	current_phase = 0	next_phase = 1	reward = 1.012472	array([[ 3.589807, -9.267714]], dtype=float32)
time = 32410	action = 0	current_phase = 0	next_phase = 1	reward = 0.723510	array([[ 3.5982366, -9.161209 ]], dtype=float32)
time = 32415	action = 0	current_phase = 0	next_phase = 1	reward = 0.731696	array([[ 3.5985665, -9.24118  ]], dtype=float32)
time = 32420	action = 0	current_phase = 0	next_phase = 1	reward = 0.727580	array([[ 3.6093545, -9.20293  ]], dtype=float32)
time = 32425	action = 0	current_phase = 0	next_phase = 1	reward = 0.722039	array([[ 3.5683045, -9.216551 ]], dtype=float32)
time = 32430	action = 0	current_phase = 0	next_phase = 1	reward = 0.721640	array([[ 3.5996184, -9.227482 ]], dtype=float32)
time = 32435	action = 0	current_phase = 0	next_phase = 1	reward = 0.709033	array([[ 3.595963, -9.236542]], dtype=float32)
time = 32440	action = 0	current_phase = 0	next_phase = 1	reward = 0.156008	array([[ 3.506329, -9.271635]], dtype=float32)
time = 32445	action = 0	current_phase = 0	next_phase = 1	reward = 1.005017	array([[ 3.531344, -9.229522]], dtype=float32)
time = 32450	action = 0	current_phase = 0	next_phase = 1	reward = 0.735985	array([[ 3.7104201, -9.376646 ]], dtype=float32)
time = 32455	action = 0	current_phase = 0	next_phase = 1	reward = 0.729357	array([[ 3.5635886, -9.233893 ]], dtype=float32)
time = 32460	action = 0	current_phase = 0	next_phase = 1	reward = 1.000590	array([[ 3.5369525, -9.2966   ]], dtype=float32)
time = 32465	action = 0	current_phase = 0	next_phase = 1	reward = 0.441674	array([[ 3.6390252, -9.197754 ]], dtype=float32)
time = 32470	action = 0	current_phase = 0	next_phase = 1	reward = 1.002553	array([[ 3.4630027, -9.467688 ]], dtype=float32)
time = 32475	action = 0	current_phase = 0	next_phase = 1	reward = 0.443051	array([[ 3.6364398, -9.246524 ]], dtype=float32)
time = 32480	action = 0	current_phase = 0	next_phase = 1	reward = 1.003338	array([[ 3.4426866, -9.345707 ]], dtype=float32)
time = 32485	action = 0	current_phase = 0	next_phase = 1	reward = 0.719551	array([[ 3.5818572, -9.21653  ]], dtype=float32)
time = 32490	action = 0	current_phase = 0	next_phase = 1	reward = 0.167419	array([[ 3.5662217, -9.274342 ]], dtype=float32)
time = 32495	action = 0	current_phase = 0	next_phase = 1	reward = 1.289598	array([[ 3.5646586, -9.266512 ]], dtype=float32)
time = 32500	action = 0	current_phase = 0	next_phase = 1	reward = 0.723197	array([[ 3.5727477, -9.205128 ]], dtype=float32)
time = 32505	action = 0	current_phase = 0	next_phase = 1	reward = 0.444140	array([[ 3.5936322, -9.227205 ]], dtype=float32)
time = 32510	action = 0	current_phase = 0	next_phase = 1	reward = 0.726515	array([[ 3.6049056, -9.364165 ]], dtype=float32)
time = 32515	action = 0	current_phase = 0	next_phase = 1	reward = 1.005576	array([[ 3.5934443, -9.230453 ]], dtype=float32)
time = 32520	action = 0	current_phase = 0	next_phase = 1	reward = 0.442592	array([[ 3.6511588, -9.217398 ]], dtype=float32)
time = 32525	action = 0	current_phase = 0	next_phase = 1	reward = 1.008309	array([[ 3.5256686, -9.234709 ]], dtype=float32)
time = 32530	action = 0	current_phase = 0	next_phase = 1	reward = 0.716767	array([[ 3.6449437, -9.281564 ]], dtype=float32)
time = 32535	action = 0	current_phase = 0	next_phase = 1	reward = 0.714603	array([[ 3.5196557, -9.22156  ]], dtype=float32)
time = 32540	action = 0	current_phase = 0	next_phase = 1	reward = 0.718832	array([[ 3.5524707, -9.22187  ]], dtype=float32)
time = 32545	action = 0	current_phase = 0	next_phase = 1	reward = 0.449431	array([[ 3.5635161, -9.281113 ]], dtype=float32)
time = 32550	action = 0	current_phase = 0	next_phase = 1	reward = 0.725248	array([[ 3.5984473, -9.277985 ]], dtype=float32)
time = 32555	action = 0	current_phase = 0	next_phase = 1	reward = 1.004860	array([[ 3.5562167, -9.24155  ]], dtype=float32)
time = 32560	action = 0	current_phase = 0	next_phase = 1	reward = 0.438765	array([[ 3.598556, -9.159121]], dtype=float32)
time = 32565	action = 0	current_phase = 0	next_phase = 1	reward = 0.454792	array([[ 3.632958, -9.309757]], dtype=float32)
time = 32570	action = 0	current_phase = 0	next_phase = 1	reward = 1.009783	array([[ 3.5550256, -9.3623705]], dtype=float32)
time = 32575	action = 0	current_phase = 0	next_phase = 1	reward = 0.729128	array([[ 3.5667987, -9.269329 ]], dtype=float32)
time = 32580	action = 0	current_phase = 0	next_phase = 1	reward = 1.007365	array([[ 3.5680013, -9.217789 ]], dtype=float32)
time = 32585	action = 0	current_phase = 0	next_phase = 1	reward = 0.446728	array([[ 3.616261, -9.290001]], dtype=float32)
time = 32590	action = 0	current_phase = 0	next_phase = 1	reward = 1.002549	array([[ 3.609282, -9.280716]], dtype=float32)
time = 32595	action = 0	current_phase = 0	next_phase = 1	reward = 0.719425	array([[ 3.6013894, -9.179731 ]], dtype=float32)
time = 32600	action = 0	current_phase = 0	next_phase = 1	reward = 0.721583	array([[ 3.5907035, -9.255698 ]], dtype=float32)
time = 32605	action = 0	current_phase = 0	next_phase = 1	reward = 0.727047	array([[ 3.5447469, -9.219671 ]], dtype=float32)
time = 32610	action = 0	current_phase = 0	next_phase = 1	reward = 0.443628	array([[ 3.6189446, -9.231211 ]], dtype=float32)
time = 32615	action = 0	current_phase = 0	next_phase = 1	reward = 1.017692	array([[ 3.553082, -9.321844]], dtype=float32)
time = 32620	action = 0	current_phase = 0	next_phase = 1	reward = 0.723796	array([[ 3.6422591, -9.195787 ]], dtype=float32)
time = 32625	action = 0	current_phase = 0	next_phase = 1	reward = 0.721340	array([[ 3.592505, -9.22854 ]], dtype=float32)
time = 32630	action = 0	current_phase = 0	next_phase = 1	reward = 0.720475	array([[ 3.6185327, -9.204896 ]], dtype=float32)
time = 32635	action = 0	current_phase = 0	next_phase = 1	reward = 0.729692	array([[ 3.6162  , -9.164921]], dtype=float32)
time = 32640	action = 0	current_phase = 0	next_phase = 1	reward = 0.726776	array([[ 3.6366343, -9.176361 ]], dtype=float32)
time = 32645	action = 0	current_phase = 0	next_phase = 1	reward = 0.725252	array([[ 3.6256614, -9.222662 ]], dtype=float32)
time = 32650	action = 0	current_phase = 0	next_phase = 1	reward = 0.719324	array([[ 3.6358743, -9.162123 ]], dtype=float32)
time = 32655	action = 0	current_phase = 0	next_phase = 1	reward = 0.440801	array([[ 3.6043038, -9.21818  ]], dtype=float32)
time = 32660	action = 0	current_phase = 0	next_phase = 1	reward = 0.999988	array([[ 3.4934287, -9.288244 ]], dtype=float32)
time = 32665	action = 0	current_phase = 0	next_phase = 1	reward = 0.718931	array([[ 3.5356555, -9.252824 ]], dtype=float32)
time = 32670	action = 0	current_phase = 0	next_phase = 1	reward = 0.443930	array([[ 3.5528178, -9.193768 ]], dtype=float32)
time = 32675	action = 0	current_phase = 0	next_phase = 1	reward = 1.008125	array([[ 3.433209, -9.402577]], dtype=float32)
time = 32680	action = 0	current_phase = 0	next_phase = 1	reward = 0.444845	array([[ 3.4880395, -9.230701 ]], dtype=float32)
time = 32685	action = 0	current_phase = 0	next_phase = 1	reward = 0.726693	array([[ 3.5871491, -9.246212 ]], dtype=float32)
time = 32690	action = 0	current_phase = 0	next_phase = 1	reward = 0.998940	array([[ 3.6027074, -9.290086 ]], dtype=float32)
time = 32695	action = 0	current_phase = 0	next_phase = 1	reward = 0.719059	array([[ 3.5818696, -9.27339  ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 7.6404 - val_loss: 1.7048
Epoch 2/50
 - 4s - loss: 3.8550 - val_loss: 2.2330
Epoch 3/50
 - 4s - loss: 5.8354 - val_loss: 1.8272
Epoch 4/50
 - 4s - loss: 4.5869 - val_loss: 1.5142
Epoch 5/50
 - 4s - loss: 4.8599 - val_loss: 1.6039
Epoch 6/50
 - 4s - loss: 5.6932 - val_loss: 2.5100
Epoch 7/50
 - 4s - loss: 5.9680 - val_loss: 2.7617
Epoch 8/50
 - 4s - loss: 4.3672 - val_loss: 2.2007
Epoch 9/50
 - 4s - loss: 6.2138 - val_loss: 2.0303
Epoch 10/50
 - 4s - loss: 4.1820 - val_loss: 1.8764
Epoch 11/50
 - 4s - loss: 4.1346 - val_loss: 1.6313
Epoch 12/50
 - 4s - loss: 3.5833 - val_loss: 1.8110
Epoch 13/50
 - 4s - loss: 3.8027 - val_loss: 1.8395
Epoch 14/50
 - 4s - loss: 4.7029 - val_loss: 1.9081
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 32700	action = 0	current_phase = 0	next_phase = 1	reward = 0.166067	array([[ 3.6736264, -9.22184  ]], dtype=float32)
time = 32705	action = 0	current_phase = 0	next_phase = 1	reward = 1.287511	array([[ 3.6533504, -9.260145 ]], dtype=float32)
time = 32710	action = 0	current_phase = 0	next_phase = 1	reward = 0.727020	array([[ 3.6707196, -9.166155 ]], dtype=float32)
time = 32715	action = 0	current_phase = 0	next_phase = 1	reward = 0.723386	array([[ 3.6798558, -9.153718 ]], dtype=float32)
time = 32720	action = 0	current_phase = 0	next_phase = 1	reward = 0.728336	array([[ 3.5780644, -9.326843 ]], dtype=float32)
time = 32725	action = 0	current_phase = 0	next_phase = 1	reward = 0.449177	array([[ 3.6717858, -9.17388  ]], dtype=float32)
time = 32730	action = 0	current_phase = 0	next_phase = 1	reward = 1.009720	array([[ 3.6786847, -9.305215 ]], dtype=float32)
time = 32735	action = 0	current_phase = 0	next_phase = 1	reward = 0.716542	array([[ 3.6755843, -9.236176 ]], dtype=float32)
time = 32740	action = 0	current_phase = 0	next_phase = 1	reward = 0.444474	array([[ 3.6805005, -9.251928 ]], dtype=float32)
time = 32745	action = 0	current_phase = 0	next_phase = 1	reward = 0.724665	array([[ 3.6683955, -9.272018 ]], dtype=float32)
time = 32750	action = 0	current_phase = 0	next_phase = 1	reward = 0.727221	array([[ 3.6104684, -9.236498 ]], dtype=float32)
time = 32755	action = 0	current_phase = 0	next_phase = 1	reward = 1.006699	array([[ 3.65863 , -9.232995]], dtype=float32)
time = 32760	action = 0	current_phase = 0	next_phase = 1	reward = 0.722581	array([[ 3.6845784, -9.279663 ]], dtype=float32)
time = 32765	action = 0	current_phase = 0	next_phase = 1	reward = 0.722642	array([[ 3.5968852, -9.306919 ]], dtype=float32)
time = 32770	action = 0	current_phase = 0	next_phase = 1	reward = 0.722362	array([[ 3.6561742, -9.236436 ]], dtype=float32)
time = 32775	action = 0	current_phase = 0	next_phase = 1	reward = 0.717498	array([[ 3.6578355, -9.201471 ]], dtype=float32)
time = 32780	action = 0	current_phase = 0	next_phase = 1	reward = 0.727430	array([[ 3.6199527, -9.2416315]], dtype=float32)
time = 32785	action = 0	current_phase = 0	next_phase = 1	reward = 0.445113	array([[ 3.674481, -9.175823]], dtype=float32)
time = 32790	action = 0	current_phase = 0	next_phase = 1	reward = 1.007833	array([[ 3.6600518, -9.216579 ]], dtype=float32)
time = 32795	action = 0	current_phase = 0	next_phase = 1	reward = 0.715221	array([[ 3.70365 , -9.236263]], dtype=float32)
time = 32800	action = 0	current_phase = 0	next_phase = 1	reward = 0.716897	array([[ 3.66505 , -9.252592]], dtype=float32)
time = 32805	action = 0	current_phase = 0	next_phase = 1	reward = 0.452039	array([[ 3.7012296, -9.186268 ]], dtype=float32)
time = 32810	action = 0	current_phase = 0	next_phase = 1	reward = 1.010161	array([[ 3.690248, -9.273829]], dtype=float32)
time = 32815	action = 0	current_phase = 0	next_phase = 1	reward = 0.731264	array([[ 3.7009645, -9.228004 ]], dtype=float32)
time = 32820	action = 0	current_phase = 0	next_phase = 1	reward = 0.714738	array([[ 3.6707482, -9.203932 ]], dtype=float32)
time = 32825	action = 0	current_phase = 0	next_phase = 1	reward = 0.439980	array([[ 3.671042, -9.263372]], dtype=float32)
time = 32830	action = 0	current_phase = 0	next_phase = 1	reward = 0.997209	array([[ 3.6588492, -9.250499 ]], dtype=float32)
time = 32835	action = 0	current_phase = 0	next_phase = 1	reward = 0.442166	array([[ 3.6956887, -9.165672 ]], dtype=float32)
time = 32840	action = 0	current_phase = 0	next_phase = 1	reward = 1.015970	array([[ 3.699657, -9.273977]], dtype=float32)
time = 32845	action = 0	current_phase = 0	next_phase = 1	reward = 0.725762	array([[ 3.6832538, -9.21855  ]], dtype=float32)
time = 32850	action = 0	current_phase = 0	next_phase = 1	reward = 0.719479	array([[ 3.5974011, -9.2330265]], dtype=float32)
time = 32855	action = 0	current_phase = 0	next_phase = 1	reward = 0.174970	array([[ 3.664146, -9.19504 ]], dtype=float32)
time = 32860	action = 0	current_phase = 0	next_phase = 1	reward = 1.290720	array([[ 3.6113963, -9.360045 ]], dtype=float32)
time = 32865	action = 0	current_phase = 0	next_phase = 1	reward = 0.725003	array([[ 3.648212, -9.207607]], dtype=float32)
time = 32870	action = 0	current_phase = 0	next_phase = 1	reward = 0.717287	array([[ 3.703837, -9.204184]], dtype=float32)
time = 32875	action = 0	current_phase = 0	next_phase = 1	reward = 0.718185	array([[ 3.7049413, -9.254147 ]], dtype=float32)
time = 32880	action = 0	current_phase = 0	next_phase = 1	reward = 0.716966	array([[ 3.7002454, -9.247701 ]], dtype=float32)
time = 32885	action = 0	current_phase = 0	next_phase = 1	reward = 0.721942	array([[ 3.6538186, -9.243116 ]], dtype=float32)
time = 32890	action = 0	current_phase = 0	next_phase = 1	reward = 0.723244	array([[ 3.6505685, -9.213804 ]], dtype=float32)
time = 32895	action = 0	current_phase = 0	next_phase = 1	reward = 0.721141	array([[ 3.7141538, -9.228954 ]], dtype=float32)
time = 32900	action = 0	current_phase = 0	next_phase = 1	reward = 0.720478	array([[ 3.663446, -9.218052]], dtype=float32)
time = 32905	action = 0	current_phase = 0	next_phase = 1	reward = 0.721297	array([[ 3.665604, -9.264615]], dtype=float32)
time = 32910	action = 0	current_phase = 0	next_phase = 1	reward = 0.727753	array([[ 3.6811366, -9.257122 ]], dtype=float32)
time = 32915	action = 0	current_phase = 0	next_phase = 1	reward = 0.722942	array([[ 3.689361 , -9.1954975]], dtype=float32)
time = 32920	action = 0	current_phase = 0	next_phase = 1	reward = 0.729242	array([[ 3.6836057, -9.2198925]], dtype=float32)
time = 32925	action = 0	current_phase = 0	next_phase = 1	reward = 0.715427	array([[ 3.6913724, -9.233479 ]], dtype=float32)
time = 32930	action = 0	current_phase = 0	next_phase = 1	reward = 0.715069	array([[ 3.6784253, -9.216644 ]], dtype=float32)
time = 32935	action = 0	current_phase = 0	next_phase = 1	reward = 0.716444	array([[ 3.7014604, -9.233303 ]], dtype=float32)
time = 32940	action = 0	current_phase = 0	next_phase = 1	reward = 0.441564	array([[ 3.6844077, -9.185738 ]], dtype=float32)
time = 32945	action = 0	current_phase = 0	next_phase = 1	reward = 1.006184	array([[ 3.6691728, -9.282454 ]], dtype=float32)
time = 32950	action = 0	current_phase = 0	next_phase = 1	reward = 0.438294	array([[ 3.6855483, -9.234958 ]], dtype=float32)
time = 32955	action = 0	current_phase = 0	next_phase = 1	reward = 0.736174	array([[ 3.6808858, -9.225561 ]], dtype=float32)
time = 32960	action = 0	current_phase = 0	next_phase = 1	reward = 0.725833	array([[ 3.574143, -9.220303]], dtype=float32)
time = 32965	action = 0	current_phase = 0	next_phase = 1	reward = 1.004694	array([[ 3.6462188, -9.260366 ]], dtype=float32)
time = 32970	action = 0	current_phase = 0	next_phase = 1	reward = 0.454548	array([[ 3.6627154, -9.228954 ]], dtype=float32)
time = 32975	action = 0	current_phase = 0	next_phase = 1	reward = 0.999838	array([[ 3.630507, -9.262257]], dtype=float32)
time = 32980	action = 0	current_phase = 0	next_phase = 1	reward = 0.717111	array([[ 3.6169915, -9.214896 ]], dtype=float32)
time = 32985	action = 0	current_phase = 0	next_phase = 1	reward = 0.444250	array([[ 3.6449313, -9.174797 ]], dtype=float32)
time = 32990	action = 0	current_phase = 0	next_phase = 1	reward = 1.012627	array([[ 3.674333, -9.355867]], dtype=float32)
time = 32995	action = 0	current_phase = 0	next_phase = 1	reward = 0.718788	array([[ 3.6928077, -9.169218 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.1415 - val_loss: 1.7710
Epoch 2/50
 - 4s - loss: 6.5772 - val_loss: 1.5888
Epoch 3/50
 - 4s - loss: 8.0529 - val_loss: 3.9394
Epoch 4/50
 - 4s - loss: 5.6889 - val_loss: 2.2447
Epoch 5/50
 - 4s - loss: 8.2938 - val_loss: 2.5574
Epoch 6/50
 - 4s - loss: 4.2472 - val_loss: 2.0275
Epoch 7/50
 - 4s - loss: 4.9162 - val_loss: 3.1960
Epoch 8/50
 - 4s - loss: 3.9774 - val_loss: 2.0609
Epoch 9/50
 - 4s - loss: 4.5199 - val_loss: 3.7309
Epoch 10/50
 - 4s - loss: 4.3013 - val_loss: 3.1156
Epoch 11/50
 - 4s - loss: 4.4130 - val_loss: 1.8384
Epoch 12/50
 - 4s - loss: 7.2059 - val_loss: 2.9595
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 33000	action = 0	current_phase = 0	next_phase = 1	reward = 0.721299	array([[ 3.5698462, -9.270703 ]], dtype=float32)
time = 33005	action = 0	current_phase = 0	next_phase = 1	reward = 0.714141	array([[ 3.5958767, -9.27528  ]], dtype=float32)
time = 33010	action = 0	current_phase = 0	next_phase = 1	reward = 0.716684	array([[ 3.605587, -9.286234]], dtype=float32)
time = 33015	action = 0	current_phase = 0	next_phase = 1	reward = 0.429855	array([[ 3.6197653, -9.215614 ]], dtype=float32)
time = 33020	action = 0	current_phase = 0	next_phase = 1	reward = 0.720064	array([[ 3.5895433, -9.38178  ]], dtype=float32)
time = 33025	action = 0	current_phase = 0	next_phase = 1	reward = 0.446121	array([[ 3.4986277, -9.33497  ]], dtype=float32)
time = 33030	action = 0	current_phase = 0	next_phase = 1	reward = 0.728709	array([[ 3.2811604, -9.667859 ]], dtype=float32)
time = 33035	action = 0	current_phase = 0	next_phase = 1	reward = 1.283811	array([[ 3.3410902, -9.542816 ]], dtype=float32)
time = 33040	action = 0	current_phase = 0	next_phase = 1	reward = 0.723133	array([[ 3.6145277, -9.272854 ]], dtype=float32)
time = 33045	action = 0	current_phase = 0	next_phase = 1	reward = 0.727078	array([[ 3.6386242, -9.279231 ]], dtype=float32)
time = 33050	action = 0	current_phase = 0	next_phase = 1	reward = 0.726602	array([[ 3.6173372, -9.242964 ]], dtype=float32)
time = 33055	action = 0	current_phase = 0	next_phase = 1	reward = 0.727846	array([[ 3.186798, -9.641548]], dtype=float32)
time = 33060	action = 0	current_phase = 0	next_phase = 1	reward = 0.714273	array([[ 3.6295013, -9.223745 ]], dtype=float32)
time = 33065	action = 0	current_phase = 0	next_phase = 1	reward = 0.716999	array([[ 3.656951, -9.244565]], dtype=float32)
time = 33070	action = 0	current_phase = 0	next_phase = 1	reward = 0.164214	array([[ 3.6505394, -9.32734  ]], dtype=float32)
time = 33075	action = 0	current_phase = 0	next_phase = 1	reward = 1.013647	array([[ 3.4064407, -9.498442 ]], dtype=float32)
time = 33080	action = 0	current_phase = 0	next_phase = 1	reward = 1.008179	array([[ 3.6468792, -9.2350855]], dtype=float32)
time = 33085	action = 0	current_phase = 0	next_phase = 1	reward = 0.722836	array([[ 3.6838741, -9.231303 ]], dtype=float32)
time = 33090	action = 0	current_phase = 0	next_phase = 1	reward = 0.718977	array([[ 3.6226912, -9.2994375]], dtype=float32)
time = 33095	action = 0	current_phase = 0	next_phase = 1	reward = 0.721052	array([[ 3.6118126, -9.295736 ]], dtype=float32)
time = 33100	action = 0	current_phase = 0	next_phase = 1	reward = 0.725789	array([[ 3.6192198, -9.299941 ]], dtype=float32)
time = 33105	action = 0	current_phase = 0	next_phase = 1	reward = 0.719771	array([[ 3.6094913, -9.305065 ]], dtype=float32)
time = 33110	action = 0	current_phase = 0	next_phase = 1	reward = 0.719007	array([[ 3.5186071, -9.394327 ]], dtype=float32)
time = 33115	action = 0	current_phase = 0	next_phase = 1	reward = 0.445273	array([[ 3.4617615, -9.384156 ]], dtype=float32)
time = 33120	action = 0	current_phase = 0	next_phase = 1	reward = 1.012896	array([[ 3.606842, -9.280842]], dtype=float32)
time = 33125	action = 0	current_phase = 0	next_phase = 1	reward = 0.722232	array([[ 3.659134, -9.249817]], dtype=float32)
time = 33130	action = 0	current_phase = 0	next_phase = 1	reward = 0.721303	array([[ 3.6477861, -9.252472 ]], dtype=float32)
time = 33135	action = 0	current_phase = 0	next_phase = 1	reward = 0.720655	array([[ 3.5397224, -9.270771 ]], dtype=float32)
time = 33140	action = 0	current_phase = 0	next_phase = 1	reward = 0.715612	array([[ 3.615221, -9.229147]], dtype=float32)
time = 33145	action = 0	current_phase = 0	next_phase = 1	reward = 0.720479	array([[ 3.6022272, -9.2489805]], dtype=float32)
time = 33150	action = 0	current_phase = 0	next_phase = 1	reward = 0.443446	array([[ 3.5937357, -9.253623 ]], dtype=float32)
time = 33155	action = 0	current_phase = 0	next_phase = 1	reward = 1.007325	array([[ 3.596387, -9.221567]], dtype=float32)
time = 33160	action = 0	current_phase = 0	next_phase = 1	reward = 0.717241	array([[ 3.4443321, -9.349655 ]], dtype=float32)
time = 33165	action = 0	current_phase = 0	next_phase = 1	reward = 0.442318	array([[ 3.5286655, -9.2332535]], dtype=float32)
time = 33170	action = 0	current_phase = 0	next_phase = 1	reward = 0.728852	array([[ 3.6099844, -9.343987 ]], dtype=float32)
time = 33175	action = 0	current_phase = 0	next_phase = 1	reward = 1.011957	array([[ 3.6260433, -9.247481 ]], dtype=float32)
time = 33180	action = 0	current_phase = 0	next_phase = 1	reward = 0.720673	array([[ 3.5994682, -9.285681 ]], dtype=float32)
time = 33185	action = 0	current_phase = 0	next_phase = 1	reward = 0.451133	array([[ 3.582633, -9.272445]], dtype=float32)
time = 33190	action = 0	current_phase = 0	next_phase = 1	reward = 1.017148	array([[ 3.5790634, -9.279345 ]], dtype=float32)
time = 33195	action = 0	current_phase = 0	next_phase = 1	reward = 0.732850	array([[ 3.6004848, -9.205095 ]], dtype=float32)
time = 33200	action = 0	current_phase = 0	next_phase = 1	reward = 0.722947	array([[ 3.6476297, -9.151431 ]], dtype=float32)
time = 33205	action = 0	current_phase = 0	next_phase = 1	reward = 0.717402	array([[ 3.6547184, -9.211488 ]], dtype=float32)
time = 33210	action = 0	current_phase = 0	next_phase = 1	reward = 0.715400	array([[ 3.5970745, -9.202099 ]], dtype=float32)
time = 33215	action = 0	current_phase = 0	next_phase = 1	reward = 0.723407	array([[ 3.6354294, -9.210535 ]], dtype=float32)
time = 33220	action = 0	current_phase = 0	next_phase = 1	reward = 0.445008	array([[ 3.6306229, -9.195879 ]], dtype=float32)
time = 33225	action = 0	current_phase = 0	next_phase = 1	reward = 0.718206	array([[ 3.4296455, -9.353289 ]], dtype=float32)
time = 33230	action = 0	current_phase = 0	next_phase = 1	reward = 1.001387	array([[ 3.4363155, -9.418839 ]], dtype=float32)
time = 33235	action = 0	current_phase = 0	next_phase = 1	reward = 0.719543	array([[ 3.654169, -9.242009]], dtype=float32)
time = 33240	action = 0	current_phase = 0	next_phase = 1	reward = 0.726567	array([[ 3.6203394, -9.26556  ]], dtype=float32)
time = 33245	action = 0	current_phase = 0	next_phase = 1	reward = 0.444487	array([[ 3.6496267, -9.226475 ]], dtype=float32)
time = 33250	action = 0	current_phase = 0	next_phase = 1	reward = 0.736259	array([[ 3.4780197, -9.520611 ]], dtype=float32)
time = 33255	action = 0	current_phase = 0	next_phase = 1	reward = 1.003982	array([[ 3.6346369, -9.255415 ]], dtype=float32)
time = 33260	action = 0	current_phase = 0	next_phase = 1	reward = 0.717812	array([[ 3.6622772, -9.280684 ]], dtype=float32)
time = 33265	action = 0	current_phase = 0	next_phase = 1	reward = 0.715348	array([[ 3.6470327, -9.219524 ]], dtype=float32)
time = 33270	action = 0	current_phase = 0	next_phase = 1	reward = 0.439922	array([[ 3.6256933, -9.235113 ]], dtype=float32)
time = 33275	action = 0	current_phase = 0	next_phase = 1	reward = 1.002098	array([[ 3.6465216, -9.196548 ]], dtype=float32)
time = 33280	action = 0	current_phase = 0	next_phase = 1	reward = 0.724367	array([[ 3.6206903, -9.229881 ]], dtype=float32)
time = 33285	action = 0	current_phase = 0	next_phase = 1	reward = 0.720589	array([[ 3.452548, -9.331677]], dtype=float32)
time = 33290	action = 0	current_phase = 0	next_phase = 1	reward = 0.733630	array([[ 3.6346846, -9.249367 ]], dtype=float32)
time = 33295	action = 0	current_phase = 0	next_phase = 1	reward = 0.721482	array([[ 3.6393719, -9.219152 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 7.7202 - val_loss: 2.5831
Epoch 2/50
 - 4s - loss: 5.9696 - val_loss: 2.3213
Epoch 3/50
 - 4s - loss: 9.1443 - val_loss: 2.5239
Epoch 4/50
 - 4s - loss: 5.6483 - val_loss: 3.0951
Epoch 5/50
 - 4s - loss: 5.7196 - val_loss: 2.0960
Epoch 6/50
 - 4s - loss: 4.2952 - val_loss: 2.7168
Epoch 7/50
 - 4s - loss: 5.9292 - val_loss: 2.3346
Epoch 8/50
 - 4s - loss: 4.1376 - val_loss: 2.1591
Epoch 9/50
 - 4s - loss: 4.5787 - val_loss: 3.1788
Epoch 10/50
 - 4s - loss: 9.3895 - val_loss: 3.1410
Epoch 11/50
 - 4s - loss: 4.5508 - val_loss: 2.8077
Epoch 12/50
 - 4s - loss: 8.7332 - val_loss: 2.7800
Epoch 13/50
 - 4s - loss: 4.6645 - val_loss: 3.2366
Epoch 14/50
 - 4s - loss: 4.7740 - val_loss: 2.2208
Epoch 15/50
 - 4s - loss: 5.4350 - val_loss: 2.1542
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 33300	action = 0	current_phase = 0	next_phase = 1	reward = 0.712393	array([[ 3.6673298, -9.239217 ]], dtype=float32)
time = 33305	action = 0	current_phase = 0	next_phase = 1	reward = 0.720221	array([[ 3.6648111, -9.226179 ]], dtype=float32)
time = 33310	action = 0	current_phase = 0	next_phase = 1	reward = 0.441038	array([[ 3.6686058, -9.195204 ]], dtype=float32)
time = 33315	action = 0	current_phase = 0	next_phase = 1	reward = 0.737789	array([[ 3.6567955, -9.235714 ]], dtype=float32)
time = 33320	action = 0	current_phase = 0	next_phase = 1	reward = 1.001898	array([[ 3.6189823, -9.247934 ]], dtype=float32)
time = 33325	action = 0	current_phase = 0	next_phase = 1	reward = 0.436380	array([[ 3.6537743, -9.248239 ]], dtype=float32)
time = 33330	action = 0	current_phase = 0	next_phase = 1	reward = 0.729889	array([[ 3.6213388, -9.2949   ]], dtype=float32)
time = 33335	action = 0	current_phase = 0	next_phase = 1	reward = 0.728546	array([[ 3.6095324, -9.227585 ]], dtype=float32)
time = 33340	action = 0	current_phase = 0	next_phase = 1	reward = 1.003772	array([[ 3.6145792, -9.196384 ]], dtype=float32)
time = 33345	action = 0	current_phase = 0	next_phase = 1	reward = 0.441343	array([[ 3.6153488, -9.181128 ]], dtype=float32)
time = 33350	action = 0	current_phase = 0	next_phase = 1	reward = 1.003526	array([[ 3.6039095, -9.276622 ]], dtype=float32)
time = 33355	action = 0	current_phase = 0	next_phase = 1	reward = 0.440047	array([[ 3.614849, -9.186554]], dtype=float32)
time = 33360	action = 0	current_phase = 0	next_phase = 1	reward = 0.731001	array([[ 3.6351929, -9.235981 ]], dtype=float32)
time = 33365	action = 0	current_phase = 0	next_phase = 1	reward = 1.006524	array([[ 3.596157, -9.347128]], dtype=float32)
time = 33370	action = 0	current_phase = 0	next_phase = 1	reward = 0.723752	array([[ 3.646864, -9.232479]], dtype=float32)
time = 33375	action = 0	current_phase = 0	next_phase = 1	reward = 0.723098	array([[ 3.6328096, -9.208998 ]], dtype=float32)
time = 33380	action = 0	current_phase = 0	next_phase = 1	reward = 0.441153	array([[ 3.6787348, -9.250149 ]], dtype=float32)
time = 33385	action = 0	current_phase = 0	next_phase = 1	reward = 0.998384	array([[ 3.61314 , -9.202944]], dtype=float32)
time = 33390	action = 0	current_phase = 0	next_phase = 1	reward = 0.709910	array([[ 3.6569853, -9.183367 ]], dtype=float32)
time = 33395	action = 0	current_phase = 0	next_phase = 1	reward = 0.727765	array([[ 3.6236954, -9.2882   ]], dtype=float32)
time = 33400	action = 0	current_phase = 0	next_phase = 1	reward = 0.727721	array([[ 3.6341114, -9.20606  ]], dtype=float32)
time = 33405	action = 0	current_phase = 0	next_phase = 1	reward = 0.723774	array([[ 3.6148958, -9.203894 ]], dtype=float32)
time = 33410	action = 0	current_phase = 0	next_phase = 1	reward = 0.718705	array([[ 3.6383123, -9.225457 ]], dtype=float32)
time = 33415	action = 0	current_phase = 0	next_phase = 1	reward = 0.445037	array([[ 3.6218214, -9.21069  ]], dtype=float32)
time = 33420	action = 0	current_phase = 0	next_phase = 1	reward = 1.012200	array([[ 3.6310835, -9.245683 ]], dtype=float32)
time = 33425	action = 0	current_phase = 0	next_phase = 1	reward = 0.166028	array([[ 3.664916, -9.283709]], dtype=float32)
time = 33430	action = 0	current_phase = 0	next_phase = 1	reward = 1.283363	array([[ 3.6119394, -9.273176 ]], dtype=float32)
time = 33435	action = 0	current_phase = 0	next_phase = 1	reward = 0.719654	array([[ 3.629712, -9.260362]], dtype=float32)
time = 33440	action = 0	current_phase = 0	next_phase = 1	reward = 0.454595	array([[ 3.6055899, -9.252655 ]], dtype=float32)
time = 33445	action = 0	current_phase = 0	next_phase = 1	reward = 0.442194	array([[ 3.6372566, -9.193205 ]], dtype=float32)
time = 33450	action = 0	current_phase = 0	next_phase = 1	reward = 1.008047	array([[ 3.6116962, -9.282507 ]], dtype=float32)
time = 33455	action = 0	current_phase = 0	next_phase = 1	reward = 1.009098	array([[ 3.6375828, -9.147909 ]], dtype=float32)
time = 33460	action = 0	current_phase = 0	next_phase = 1	reward = 0.723873	array([[ 3.6057158, -9.270182 ]], dtype=float32)
time = 33465	action = 0	current_phase = 0	next_phase = 1	reward = 0.727005	array([[ 3.6451645, -9.257371 ]], dtype=float32)
time = 33470	action = 0	current_phase = 0	next_phase = 1	reward = 0.724866	array([[ 3.6434078, -9.213297 ]], dtype=float32)
time = 33475	action = 0	current_phase = 0	next_phase = 1	reward = 0.716796	array([[ 3.654292, -9.186962]], dtype=float32)
time = 33480	action = 0	current_phase = 0	next_phase = 1	reward = 0.729735	array([[ 3.6285152, -9.214233 ]], dtype=float32)
time = 33485	action = 0	current_phase = 0	next_phase = 1	reward = 0.444348	array([[ 3.571186, -9.325294]], dtype=float32)
time = 33490	action = 0	current_phase = 0	next_phase = 1	reward = 0.724351	array([[ 3.6067162, -9.289311 ]], dtype=float32)
time = 33495	action = 0	current_phase = 0	next_phase = 1	reward = 0.996846	array([[ 3.6280184, -9.205518 ]], dtype=float32)
time = 33500	action = 0	current_phase = 0	next_phase = 1	reward = 0.436316	array([[ 3.6524086, -9.207277 ]], dtype=float32)
time = 33505	action = 0	current_phase = 0	next_phase = 1	reward = 1.005790	array([[ 3.5201178, -9.245436 ]], dtype=float32)
time = 33510	action = 0	current_phase = 0	next_phase = 1	reward = 0.721679	array([[ 3.6438465, -9.234582 ]], dtype=float32)
time = 33515	action = 0	current_phase = 0	next_phase = 1	reward = 0.722129	array([[ 3.6663303, -9.237483 ]], dtype=float32)
time = 33520	action = 0	current_phase = 0	next_phase = 1	reward = 0.720282	array([[ 3.611394, -9.2724  ]], dtype=float32)
time = 33525	action = 0	current_phase = 0	next_phase = 1	reward = 0.169686	array([[ 3.6432486, -9.223055 ]], dtype=float32)
time = 33530	action = 0	current_phase = 0	next_phase = 1	reward = 1.297701	array([[ 3.6017485, -9.266531 ]], dtype=float32)
time = 33535	action = 0	current_phase = 0	next_phase = 1	reward = 0.720105	array([[ 3.6239185, -9.2625475]], dtype=float32)
time = 33540	action = 0	current_phase = 0	next_phase = 1	reward = 0.719986	array([[ 3.6115723, -9.260675 ]], dtype=float32)
time = 33545	action = 0	current_phase = 0	next_phase = 1	reward = 0.716132	array([[ 3.6531782, -9.183779 ]], dtype=float32)
time = 33550	action = 0	current_phase = 0	next_phase = 1	reward = 0.444593	array([[ 3.6234732, -9.209682 ]], dtype=float32)
time = 33555	action = 0	current_phase = 0	next_phase = 1	reward = 0.723346	array([[ 3.6393833, -9.255026 ]], dtype=float32)
time = 33560	action = 0	current_phase = 0	next_phase = 1	reward = 1.003721	array([[ 3.5621548, -9.297648 ]], dtype=float32)
time = 33565	action = 0	current_phase = 0	next_phase = 1	reward = 0.715874	array([[ 3.6139545, -9.168923 ]], dtype=float32)
time = 33570	action = 0	current_phase = 0	next_phase = 1	reward = 0.444029	array([[ 3.6646814, -9.27767  ]], dtype=float32)
time = 33575	action = 0	current_phase = 0	next_phase = 1	reward = 0.726241	array([[ 3.6295776, -9.269847 ]], dtype=float32)
time = 33580	action = 0	current_phase = 0	next_phase = 1	reward = 0.997920	array([[ 3.6276722, -9.278334 ]], dtype=float32)
time = 33585	action = 0	current_phase = 0	next_phase = 1	reward = 0.447479	array([[ 3.6435652, -9.197493 ]], dtype=float32)
time = 33590	action = 0	current_phase = 0	next_phase = 1	reward = 1.004468	array([[ 3.5844536, -9.330599 ]], dtype=float32)
time = 33595	action = 0	current_phase = 0	next_phase = 1	reward = 0.160500	array([[ 3.5891075, -9.256558 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 6.1654 - val_loss: 3.1248
Epoch 2/50
 - 4s - loss: 4.4682 - val_loss: 3.0864
Epoch 3/50
 - 4s - loss: 5.0556 - val_loss: 3.3512
Epoch 4/50
 - 4s - loss: 3.7342 - val_loss: 3.0052
Epoch 5/50
 - 4s - loss: 5.3892 - val_loss: 2.9850
Epoch 6/50
 - 4s - loss: 3.9270 - val_loss: 3.2885
Epoch 7/50
 - 4s - loss: 5.4463 - val_loss: 3.0177
Epoch 8/50
 - 4s - loss: 4.7206 - val_loss: 2.7250
Epoch 9/50
 - 4s - loss: 3.3715 - val_loss: 3.0889
Epoch 10/50
 - 4s - loss: 3.8653 - val_loss: 3.1625
Epoch 11/50
 - 4s - loss: 4.1487 - val_loss: 3.0725
Epoch 12/50
 - 4s - loss: 4.1314 - val_loss: 2.5869
Epoch 13/50
 - 4s - loss: 4.7612 - val_loss: 2.5120
Epoch 14/50
 - 4s - loss: 5.4101 - val_loss: 3.2297
Epoch 15/50
 - 4s - loss: 5.5675 - val_loss: 2.6447
Epoch 16/50
 - 4s - loss: 3.9759 - val_loss: 3.7527
Epoch 17/50
 - 4s - loss: 4.8578 - val_loss: 4.1016
Epoch 18/50
 - 4s - loss: 5.2275 - val_loss: 2.3301
Epoch 19/50
 - 4s - loss: 4.7149 - val_loss: 3.1354
Epoch 20/50
 - 4s - loss: 4.0277 - val_loss: 2.6287
Epoch 21/50
 - 4s - loss: 4.7031 - val_loss: 3.0506
Epoch 22/50
 - 4s - loss: 4.3239 - val_loss: 2.8779
Epoch 23/50
 - 4s - loss: 3.9193 - val_loss: 5.2955
Epoch 24/50
 - 4s - loss: 4.4560 - val_loss: 3.3369
Epoch 25/50
 - 4s - loss: 3.4336 - val_loss: 3.1834
Epoch 26/50
 - 4s - loss: 2.4320 - val_loss: 2.5390
Epoch 27/50
 - 4s - loss: 5.3935 - val_loss: 2.7264
Epoch 28/50
 - 4s - loss: 4.0022 - val_loss: 2.5186
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 33600	action = 0	current_phase = 0	next_phase = 1	reward = 1.284108	array([[ 3.580748, -9.273338]], dtype=float32)
time = 33605	action = 0	current_phase = 0	next_phase = 1	reward = 0.447464	array([[ 3.5531487, -9.184502 ]], dtype=float32)
time = 33610	action = 0	current_phase = 0	next_phase = 1	reward = 0.731261	array([[ 3.6310086, -9.219879 ]], dtype=float32)
time = 33615	action = 0	current_phase = 0	next_phase = 1	reward = 1.006887	array([[ 3.617744, -9.177561]], dtype=float32)
time = 33620	action = 0	current_phase = 0	next_phase = 1	reward = 0.728553	array([[ 3.5631948, -9.248217 ]], dtype=float32)
time = 33625	action = 0	current_phase = 0	next_phase = 1	reward = 0.723809	array([[ 3.6639552, -9.2038765]], dtype=float32)
time = 33630	action = 0	current_phase = 0	next_phase = 1	reward = 0.441408	array([[ 3.6583047, -9.16286  ]], dtype=float32)
time = 33635	action = 0	current_phase = 0	next_phase = 1	reward = 0.999064	array([[ 3.6340814, -9.177619 ]], dtype=float32)
time = 33640	action = 0	current_phase = 0	next_phase = 1	reward = 0.436617	array([[ 3.6111684, -9.227543 ]], dtype=float32)
time = 33645	action = 0	current_phase = 0	next_phase = 1	reward = 0.998616	array([[ 3.5626416, -9.210962 ]], dtype=float32)
time = 33650	action = 0	current_phase = 0	next_phase = 1	reward = 0.168574	array([[ 3.5910878, -9.204114 ]], dtype=float32)
time = 33655	action = 0	current_phase = 0	next_phase = 1	reward = 1.295051	array([[ 3.5953612, -9.197469 ]], dtype=float32)
time = 33660	action = 0	current_phase = 0	next_phase = 1	reward = 0.449839	array([[ 3.6772857, -9.121103 ]], dtype=float32)
time = 33665	action = 0	current_phase = 0	next_phase = 1	reward = 1.002042	array([[ 3.6244988, -9.206259 ]], dtype=float32)
time = 33670	action = 0	current_phase = 0	next_phase = 1	reward = 0.711774	array([[ 3.600347, -9.153501]], dtype=float32)
time = 33675	action = 0	current_phase = 0	next_phase = 1	reward = 0.722513	array([[ 3.6393714, -9.1779   ]], dtype=float32)
time = 33680	action = 0	current_phase = 0	next_phase = 1	reward = 0.717972	array([[ 3.6233287, -9.175169 ]], dtype=float32)
time = 33685	action = 0	current_phase = 0	next_phase = 1	reward = 0.728241	array([[ 3.6275506, -9.167669 ]], dtype=float32)
time = 33690	action = 0	current_phase = 0	next_phase = 1	reward = 0.446395	array([[ 3.6285577, -9.182995 ]], dtype=float32)
time = 33695	action = 0	current_phase = 0	next_phase = 1	reward = 0.730763	array([[ 3.664308, -9.190485]], dtype=float32)
time = 33700	action = 0	current_phase = 0	next_phase = 1	reward = 1.004603	array([[ 3.6407123, -9.16424  ]], dtype=float32)
time = 33705	action = 0	current_phase = 0	next_phase = 1	reward = 0.717908	array([[ 3.647287, -9.243076]], dtype=float32)
time = 33710	action = 0	current_phase = 0	next_phase = 1	reward = 0.728989	array([[ 3.6005998, -9.216841 ]], dtype=float32)
time = 33715	action = 0	current_phase = 0	next_phase = 1	reward = 0.725941	array([[ 3.6482682, -9.125809 ]], dtype=float32)
time = 33720	action = 0	current_phase = 0	next_phase = 1	reward = 0.721977	array([[ 3.6281018, -9.193939 ]], dtype=float32)
time = 33725	action = 0	current_phase = 0	next_phase = 1	reward = 0.442305	array([[ 3.6252074, -9.227379 ]], dtype=float32)
time = 33730	action = 0	current_phase = 0	next_phase = 1	reward = 0.999013	array([[ 3.5935502, -9.248472 ]], dtype=float32)
time = 33735	action = 0	current_phase = 0	next_phase = 1	reward = 0.719676	array([[ 3.648172, -9.140266]], dtype=float32)
time = 33740	action = 0	current_phase = 0	next_phase = 1	reward = 0.718657	array([[ 3.6627965, -9.116109 ]], dtype=float32)
time = 33745	action = 0	current_phase = 0	next_phase = 1	reward = 0.716956	array([[ 3.5976977, -9.175822 ]], dtype=float32)
time = 33750	action = 0	current_phase = 0	next_phase = 1	reward = 0.440678	array([[ 3.613275, -9.224886]], dtype=float32)
time = 33755	action = 0	current_phase = 0	next_phase = 1	reward = 1.009973	array([[ 3.5311322, -9.4043045]], dtype=float32)
time = 33760	action = 0	current_phase = 0	next_phase = 1	reward = 0.728224	array([[ 3.613009, -9.19023 ]], dtype=float32)
time = 33765	action = 0	current_phase = 0	next_phase = 1	reward = 0.720294	array([[ 3.6462512, -9.185549 ]], dtype=float32)
time = 33770	action = 0	current_phase = 0	next_phase = 1	reward = 0.724763	array([[ 3.562018, -9.164171]], dtype=float32)
time = 33775	action = 0	current_phase = 0	next_phase = 1	reward = 0.719900	array([[ 3.6188302, -9.237623 ]], dtype=float32)
time = 33780	action = 0	current_phase = 0	next_phase = 1	reward = 0.722490	array([[ 3.6207795, -9.225533 ]], dtype=float32)
time = 33785	action = 0	current_phase = 0	next_phase = 1	reward = 0.717085	array([[ 3.6431632, -9.18297  ]], dtype=float32)
time = 33790	action = 0	current_phase = 0	next_phase = 1	reward = 0.720397	array([[ 3.6330495, -9.212399 ]], dtype=float32)
time = 33795	action = 0	current_phase = 0	next_phase = 1	reward = 0.437378	array([[ 3.6171775, -9.165279 ]], dtype=float32)
time = 33800	action = 0	current_phase = 0	next_phase = 1	reward = 0.728433	array([[ 3.6129127, -9.186933 ]], dtype=float32)
time = 33805	action = 0	current_phase = 0	next_phase = 1	reward = 0.722882	array([[ 3.6742606, -9.128268 ]], dtype=float32)
time = 33810	action = 0	current_phase = 0	next_phase = 1	reward = 0.729156	array([[ 3.6205058, -9.150661 ]], dtype=float32)
time = 33815	action = 0	current_phase = 0	next_phase = 1	reward = 1.003978	array([[ 3.663076, -9.139965]], dtype=float32)
time = 33820	action = 0	current_phase = 0	next_phase = 1	reward = 0.735715	array([[ 3.647017, -9.178221]], dtype=float32)
time = 33825	action = 0	current_phase = 0	next_phase = 1	reward = 0.721955	array([[ 3.6104856, -9.206139 ]], dtype=float32)
time = 33830	action = 0	current_phase = 0	next_phase = 1	reward = 0.720439	array([[ 3.5458179, -9.220499 ]], dtype=float32)
time = 33835	action = 0	current_phase = 0	next_phase = 1	reward = 0.433069	array([[ 3.6417403, -9.112523 ]], dtype=float32)
time = 33840	action = 0	current_phase = 0	next_phase = 1	reward = 0.724049	array([[ 3.644321, -9.299651]], dtype=float32)
time = 33845	action = 0	current_phase = 0	next_phase = 1	reward = 1.005605	array([[ 3.517571, -9.205606]], dtype=float32)
time = 33850	action = 0	current_phase = 0	next_phase = 1	reward = 0.456343	array([[ 3.6203637, -9.24524  ]], dtype=float32)
time = 33855	action = 0	current_phase = 0	next_phase = 1	reward = 1.010368	array([[ 3.606771, -9.250907]], dtype=float32)
time = 33860	action = 0	current_phase = 0	next_phase = 1	reward = 0.722914	array([[ 3.6201758, -9.184473 ]], dtype=float32)
time = 33865	action = 0	current_phase = 0	next_phase = 1	reward = 0.445996	array([[ 3.6418185, -9.123064 ]], dtype=float32)
time = 33870	action = 0	current_phase = 0	next_phase = 1	reward = 1.004837	array([[ 3.6027608, -9.190544 ]], dtype=float32)
time = 33875	action = 0	current_phase = 0	next_phase = 1	reward = 0.444034	array([[ 3.6242414, -9.171185 ]], dtype=float32)
time = 33880	action = 0	current_phase = 0	next_phase = 1	reward = 1.004234	array([[ 3.6117415, -9.218867 ]], dtype=float32)
time = 33885	action = 0	current_phase = 0	next_phase = 1	reward = 0.708557	array([[ 3.4895797, -9.301327 ]], dtype=float32)
time = 33890	action = 0	current_phase = 0	next_phase = 1	reward = 0.722382	array([[ 3.5816731, -9.24962  ]], dtype=float32)
time = 33895	action = 0	current_phase = 0	next_phase = 1	reward = 0.729441	array([[ 3.6028686, -9.217539 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 7.6595 - val_loss: 2.9794
Epoch 2/50
 - 4s - loss: 4.8430 - val_loss: 3.5071
Epoch 3/50
 - 4s - loss: 6.7101 - val_loss: 2.7861
Epoch 4/50
 - 4s - loss: 5.8042 - val_loss: 2.9684
Epoch 5/50
 - 4s - loss: 5.0138 - val_loss: 1.8070
Epoch 6/50
 - 4s - loss: 4.4827 - val_loss: 2.4127
Epoch 7/50
 - 4s - loss: 4.9246 - val_loss: 2.0382
Epoch 8/50
 - 4s - loss: 5.9566 - val_loss: 2.6059
Epoch 9/50
 - 4s - loss: 5.3004 - val_loss: 1.7654
Epoch 10/50
 - 4s - loss: 6.4845 - val_loss: 3.2666
Epoch 11/50
 - 4s - loss: 5.7314 - val_loss: 1.9298
Epoch 12/50
 - 4s - loss: 5.8403 - val_loss: 2.4400
Epoch 13/50
 - 4s - loss: 4.1640 - val_loss: 1.8774
Epoch 14/50
 - 4s - loss: 9.0000 - val_loss: 1.9611
Epoch 15/50
 - 4s - loss: 5.8854 - val_loss: 1.8164
Epoch 16/50
 - 4s - loss: 3.9090 - val_loss: 2.2410
Epoch 17/50
 - 4s - loss: 7.5315 - val_loss: 2.0274
Epoch 18/50
 - 4s - loss: 4.7710 - val_loss: 2.4527
Epoch 19/50
 - 4s - loss: 5.7413 - val_loss: 2.0248
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 33900	action = 0	current_phase = 0	next_phase = 1	reward = 0.721052	array([[ 3.6387124, -9.152384 ]], dtype=float32)
time = 33905	action = 0	current_phase = 0	next_phase = 1	reward = 0.718781	array([[ 3.6702085, -9.152664 ]], dtype=float32)
time = 33910	action = 0	current_phase = 0	next_phase = 1	reward = 0.721737	array([[ 3.6390548, -9.157446 ]], dtype=float32)
time = 33915	action = 0	current_phase = 0	next_phase = 1	reward = 0.439315	array([[ 3.5569692, -9.195236 ]], dtype=float32)
time = 33920	action = 0	current_phase = 0	next_phase = 1	reward = 0.722216	array([[ 3.6192632, -9.150799 ]], dtype=float32)
time = 33925	action = 0	current_phase = 0	next_phase = 1	reward = 0.726411	array([[ 3.6027951, -9.16675  ]], dtype=float32)
time = 33930	action = 0	current_phase = 0	next_phase = 1	reward = 0.726981	array([[ 3.6072602, -9.120539 ]], dtype=float32)
time = 33935	action = 0	current_phase = 0	next_phase = 1	reward = 1.001126	array([[ 3.6379218, -9.1476965]], dtype=float32)
time = 33940	action = 0	current_phase = 0	next_phase = 1	reward = 0.459534	array([[ 3.638289, -9.127912]], dtype=float32)
time = 33945	action = 0	current_phase = 0	next_phase = 1	reward = 0.726844	array([[ 3.6046844, -9.144838 ]], dtype=float32)
time = 33950	action = 0	current_phase = 0	next_phase = 1	reward = 0.996959	array([[ 3.6602054, -9.164621 ]], dtype=float32)
time = 33955	action = 0	current_phase = 0	next_phase = 1	reward = 0.723887	array([[ 3.6680856, -9.122426 ]], dtype=float32)
time = 33960	action = 0	current_phase = 0	next_phase = 1	reward = 0.446984	array([[ 3.6228995, -9.157878 ]], dtype=float32)
time = 33965	action = 0	current_phase = 0	next_phase = 1	reward = 0.733837	array([[ 3.591064, -9.353511]], dtype=float32)
time = 33970	action = 0	current_phase = 0	next_phase = 1	reward = 1.000945	array([[ 3.4748006, -9.269672 ]], dtype=float32)
time = 33975	action = 0	current_phase = 0	next_phase = 1	reward = 0.439125	array([[ 3.642571, -9.153474]], dtype=float32)
time = 33980	action = 0	current_phase = 0	next_phase = 1	reward = 0.997698	array([[ 3.6491208, -9.246237 ]], dtype=float32)
time = 33985	action = 0	current_phase = 0	next_phase = 1	reward = 0.711649	array([[ 3.6403708, -9.17293  ]], dtype=float32)
time = 33990	action = 0	current_phase = 0	next_phase = 1	reward = 0.443277	array([[ 3.6198382, -9.117428 ]], dtype=float32)
time = 33995	action = 0	current_phase = 0	next_phase = 1	reward = 0.451493	array([[ 3.6294475, -9.177254 ]], dtype=float32)
time = 34000	action = 0	current_phase = 0	next_phase = 1	reward = 1.296025	array([[ 3.6048875, -9.276253 ]], dtype=float32)
time = 34005	action = 0	current_phase = 0	next_phase = 1	reward = 0.724599	array([[ 3.571611, -9.138942]], dtype=float32)
time = 34010	action = 0	current_phase = 0	next_phase = 1	reward = 0.439277	array([[ 3.6108613, -9.123442 ]], dtype=float32)
time = 34015	action = 0	current_phase = 0	next_phase = 1	reward = 0.725536	array([[ 3.651277, -9.139587]], dtype=float32)
time = 34020	action = 0	current_phase = 0	next_phase = 1	reward = 1.002398	array([[ 3.6292996, -9.166508 ]], dtype=float32)
time = 34025	action = 0	current_phase = 0	next_phase = 1	reward = 0.721331	array([[ 3.5971322, -9.16996  ]], dtype=float32)
time = 34030	action = 0	current_phase = 0	next_phase = 1	reward = 0.724417	array([[ 3.6228786, -9.1375065]], dtype=float32)
time = 34035	action = 0	current_phase = 0	next_phase = 1	reward = 0.435349	array([[ 3.6129394, -9.168128 ]], dtype=float32)
time = 34040	action = 0	current_phase = 0	next_phase = 1	reward = 1.003452	array([[ 3.5780911, -9.287489 ]], dtype=float32)
time = 34045	action = 0	current_phase = 0	next_phase = 1	reward = 0.725832	array([[ 3.6515117, -9.156717 ]], dtype=float32)
time = 34050	action = 0	current_phase = 0	next_phase = 1	reward = 0.722778	array([[ 3.639957, -9.110823]], dtype=float32)
time = 34055	action = 0	current_phase = 0	next_phase = 1	reward = 0.717059	array([[ 3.6309237, -9.181695 ]], dtype=float32)
time = 34060	action = 0	current_phase = 0	next_phase = 1	reward = 0.722404	array([[ 3.654365, -9.173258]], dtype=float32)
time = 34065	action = 0	current_phase = 0	next_phase = 1	reward = 0.723721	array([[ 3.642548 , -9.1059885]], dtype=float32)
time = 34070	action = 0	current_phase = 0	next_phase = 1	reward = 0.730213	array([[ 3.6679425, -9.2138405]], dtype=float32)
time = 34075	action = 0	current_phase = 0	next_phase = 1	reward = 0.726173	array([[ 3.6338048, -9.197344 ]], dtype=float32)
time = 34080	action = 0	current_phase = 0	next_phase = 1	reward = 0.723929	array([[ 3.6213899, -9.1568165]], dtype=float32)
time = 34085	action = 0	current_phase = 0	next_phase = 1	reward = 0.722025	array([[ 3.6438498, -9.164272 ]], dtype=float32)
time = 34090	action = 0	current_phase = 0	next_phase = 1	reward = 0.443503	array([[ 3.6396651, -9.237558 ]], dtype=float32)
time = 34095	action = 0	current_phase = 0	next_phase = 1	reward = 0.999502	array([[ 3.620626, -9.269929]], dtype=float32)
time = 34100	action = 0	current_phase = 0	next_phase = 1	reward = 0.440671	array([[ 3.6764941, -9.177853 ]], dtype=float32)
time = 34105	action = 0	current_phase = 0	next_phase = 1	reward = 0.729536	array([[ 3.6039786, -9.160252 ]], dtype=float32)
time = 34110	action = 0	current_phase = 0	next_phase = 1	reward = 1.003995	array([[ 3.543634, -9.252984]], dtype=float32)
time = 34115	action = 0	current_phase = 0	next_phase = 1	reward = 0.163029	array([[ 3.5607495, -9.250175 ]], dtype=float32)
time = 34120	action = 0	current_phase = 0	next_phase = 1	reward = 1.286734	array([[ 3.5283551, -9.230674 ]], dtype=float32)
time = 34125	action = 0	current_phase = 0	next_phase = 1	reward = 0.441884	array([[ 3.6240945, -9.154282 ]], dtype=float32)
time = 34130	action = 0	current_phase = 0	next_phase = 1	reward = 0.446558	array([[ 3.655291, -9.106903]], dtype=float32)
time = 34135	action = 0	current_phase = 0	next_phase = 1	reward = 1.003354	array([[ 3.5665069, -9.32893  ]], dtype=float32)
time = 34140	action = 0	current_phase = 0	next_phase = 1	reward = 0.723285	array([[ 3.653831, -9.245413]], dtype=float32)
time = 34145	action = 0	current_phase = 0	next_phase = 1	reward = 1.002220	array([[ 3.5503163, -9.199642 ]], dtype=float32)
time = 34150	action = 0	current_phase = 0	next_phase = 1	reward = 0.446777	array([[ 3.6530976, -9.160862 ]], dtype=float32)
time = 34155	action = 0	current_phase = 0	next_phase = 1	reward = 0.998337	array([[ 3.643209, -9.210312]], dtype=float32)
time = 34160	action = 0	current_phase = 0	next_phase = 1	reward = 0.443707	array([[ 3.6417985, -9.166632 ]], dtype=float32)
time = 34165	action = 0	current_phase = 0	next_phase = 1	reward = 0.723012	array([[ 3.619533, -9.1125  ]], dtype=float32)
time = 34170	action = 0	current_phase = 0	next_phase = 1	reward = 0.726703	array([[ 3.6444392, -9.145483 ]], dtype=float32)
time = 34175	action = 0	current_phase = 0	next_phase = 1	reward = 1.003204	array([[ 3.6065793, -9.198952 ]], dtype=float32)
time = 34180	action = 0	current_phase = 0	next_phase = 1	reward = 0.439212	array([[ 3.5921674, -9.20902  ]], dtype=float32)
time = 34185	action = 0	current_phase = 0	next_phase = 1	reward = 0.719089	array([[ 3.6495738, -9.160582 ]], dtype=float32)
time = 34190	action = 0	current_phase = 0	next_phase = 1	reward = 1.000558	array([[ 3.6507487, -9.131422 ]], dtype=float32)
time = 34195	action = 0	current_phase = 0	next_phase = 1	reward = 0.439157	array([[ 3.6322265, -9.151741 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.8039 - val_loss: 2.2315
Epoch 2/50
 - 4s - loss: 5.1449 - val_loss: 2.1477
Epoch 3/50
 - 4s - loss: 5.4708 - val_loss: 1.6459
Epoch 4/50
 - 4s - loss: 3.8464 - val_loss: 1.5548
Epoch 5/50
 - 4s - loss: 6.9884 - val_loss: 1.8289
Epoch 6/50
 - 4s - loss: 5.1103 - val_loss: 2.1844
Epoch 7/50
 - 4s - loss: 5.1927 - val_loss: 2.0566
Epoch 8/50
 - 4s - loss: 3.8732 - val_loss: 1.7096
Epoch 9/50
 - 4s - loss: 4.2211 - val_loss: 1.7034
Epoch 10/50
 - 4s - loss: 4.8794 - val_loss: 1.7011
Epoch 11/50
 - 4s - loss: 4.9996 - val_loss: 1.8990
Epoch 12/50
 - 4s - loss: 5.5079 - val_loss: 2.7459
Epoch 13/50
 - 5s - loss: 4.8456 - val_loss: 1.6988
Epoch 14/50
 - 4s - loss: 4.8204 - val_loss: 2.4919
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 34200	action = 0	current_phase = 0	next_phase = 1	reward = 1.004997	array([[ 3.6398826, -9.177549 ]], dtype=float32)
time = 34205	action = 0	current_phase = 0	next_phase = 1	reward = 0.722089	array([[ 3.6654735, -9.096506 ]], dtype=float32)
time = 34210	action = 0	current_phase = 0	next_phase = 1	reward = 0.453468	array([[ 3.6459622, -9.086636 ]], dtype=float32)
time = 34215	action = 0	current_phase = 0	next_phase = 1	reward = 0.730721	array([[ 3.6795106, -9.091043 ]], dtype=float32)
time = 34220	action = 0	current_phase = 0	next_phase = 1	reward = 1.003040	array([[ 3.5885825, -9.107723 ]], dtype=float32)
time = 34225	action = 0	current_phase = 0	next_phase = 1	reward = 0.719360	array([[ 3.6615863, -9.077212 ]], dtype=float32)
time = 34230	action = 0	current_phase = 0	next_phase = 1	reward = 0.726108	array([[ 3.675527, -9.109253]], dtype=float32)
time = 34235	action = 0	current_phase = 0	next_phase = 1	reward = 0.440717	array([[ 3.637385, -9.103902]], dtype=float32)
time = 34240	action = 0	current_phase = 0	next_phase = 1	reward = 1.008221	array([[ 3.5954537, -9.200399 ]], dtype=float32)
time = 34245	action = 0	current_phase = 0	next_phase = 1	reward = 0.159051	array([[ 3.6596036, -9.101614 ]], dtype=float32)
time = 34250	action = 0	current_phase = 0	next_phase = 1	reward = 1.281882	array([[ 3.6249728, -9.262276 ]], dtype=float32)
time = 34255	action = 0	current_phase = 0	next_phase = 1	reward = 0.448282	array([[ 3.6386523, -9.133701 ]], dtype=float32)
time = 34260	action = 0	current_phase = 0	next_phase = 1	reward = 0.721282	array([[ 3.638782, -9.098253]], dtype=float32)
time = 34265	action = 0	current_phase = 0	next_phase = 1	reward = 0.723634	array([[ 3.6183038, -9.151179 ]], dtype=float32)
time = 34270	action = 0	current_phase = 0	next_phase = 1	reward = 0.727510	array([[ 3.630672, -9.107767]], dtype=float32)
time = 34275	action = 0	current_phase = 0	next_phase = 1	reward = 1.001690	array([[ 3.6174932, -9.125239 ]], dtype=float32)
time = 34280	action = 0	current_phase = 0	next_phase = 1	reward = 0.438713	array([[ 3.633469, -9.128971]], dtype=float32)
time = 34285	action = 0	current_phase = 0	next_phase = 1	reward = 0.724713	array([[ 3.6136298, -9.073488 ]], dtype=float32)
time = 34290	action = 0	current_phase = 0	next_phase = 1	reward = 0.730683	array([[ 3.6151052, -9.086941 ]], dtype=float32)
time = 34295	action = 0	current_phase = 0	next_phase = 1	reward = 0.716573	array([[ 3.6400752, -9.118776 ]], dtype=float32)
time = 34300	action = 0	current_phase = 0	next_phase = 1	reward = 1.006129	array([[ 3.5910954, -9.180838 ]], dtype=float32)
time = 34305	action = 0	current_phase = 0	next_phase = 1	reward = 0.716220	array([[ 3.6561284, -9.107241 ]], dtype=float32)
time = 34310	action = 0	current_phase = 0	next_phase = 1	reward = 0.718111	array([[ 3.578237, -9.077877]], dtype=float32)
time = 34315	action = 0	current_phase = 0	next_phase = 1	reward = 0.450375	array([[ 3.6440177, -9.102645 ]], dtype=float32)
time = 34320	action = 0	current_phase = 0	next_phase = 1	reward = 1.009174	array([[ 3.6063094, -9.189123 ]], dtype=float32)
time = 34325	action = 0	current_phase = 0	next_phase = 1	reward = 0.447071	array([[ 3.6298718, -9.126253 ]], dtype=float32)
time = 34330	action = 0	current_phase = 0	next_phase = 1	reward = 1.004797	array([[ 3.6311355, -9.128729 ]], dtype=float32)
time = 34335	action = 0	current_phase = 0	next_phase = 1	reward = 0.720632	array([[ 3.6339955, -9.133283 ]], dtype=float32)
time = 34340	action = 0	current_phase = 0	next_phase = 1	reward = 0.718931	array([[ 3.6213193, -9.050661 ]], dtype=float32)
time = 34345	action = 0	current_phase = 0	next_phase = 1	reward = 0.719095	array([[ 3.638968, -9.084946]], dtype=float32)
time = 34350	action = 0	current_phase = 0	next_phase = 1	reward = 0.448151	array([[ 3.6354203, -9.098841 ]], dtype=float32)
time = 34355	action = 0	current_phase = 0	next_phase = 1	reward = 1.007418	array([[ 3.6408467, -9.087997 ]], dtype=float32)
time = 34360	action = 0	current_phase = 0	next_phase = 1	reward = 0.726317	array([[ 3.668655, -9.101647]], dtype=float32)
time = 34365	action = 0	current_phase = 0	next_phase = 1	reward = 0.728713	array([[ 3.6533446, -9.103702 ]], dtype=float32)
time = 34370	action = 0	current_phase = 0	next_phase = 1	reward = 0.717876	array([[ 3.6053967, -9.042102 ]], dtype=float32)
time = 34375	action = 0	current_phase = 0	next_phase = 1	reward = 0.717191	array([[ 3.6196132, -9.108057 ]], dtype=float32)
time = 34380	action = 0	current_phase = 0	next_phase = 1	reward = 0.162868	array([[ 3.6589093, -9.115921 ]], dtype=float32)
time = 34385	action = 0	current_phase = 0	next_phase = 1	reward = 0.733664	array([[ 3.633225, -9.130439]], dtype=float32)
time = 34390	action = 0	current_phase = 0	next_phase = 1	reward = 1.285555	array([[ 3.3784146, -9.300272 ]], dtype=float32)
time = 34395	action = 0	current_phase = 0	next_phase = 1	reward = 0.440641	array([[ 3.6428313, -9.098221 ]], dtype=float32)
time = 34400	action = 0	current_phase = 0	next_phase = 1	reward = 0.454688	array([[ 3.6480947, -9.179497 ]], dtype=float32)
time = 34405	action = 0	current_phase = 0	next_phase = 1	reward = 1.016028	array([[ 3.6145186, -9.207158 ]], dtype=float32)
time = 34410	action = 0	current_phase = 0	next_phase = 1	reward = 1.008970	array([[ 3.6571012, -9.121435 ]], dtype=float32)
time = 34415	action = 0	current_phase = 0	next_phase = 1	reward = 0.723703	array([[ 3.62917 , -9.121385]], dtype=float32)
time = 34420	action = 0	current_phase = 0	next_phase = 1	reward = 0.721259	array([[ 3.6487641, -9.184893 ]], dtype=float32)
time = 34425	action = 0	current_phase = 0	next_phase = 1	reward = 0.717422	array([[ 3.6127286, -9.092375 ]], dtype=float32)
time = 34430	action = 0	current_phase = 0	next_phase = 1	reward = 0.717728	array([[ 3.6137729, -9.054799 ]], dtype=float32)
time = 34435	action = 0	current_phase = 0	next_phase = 1	reward = 0.729150	array([[ 3.6593509, -9.133863 ]], dtype=float32)
time = 34440	action = 0	current_phase = 0	next_phase = 1	reward = 0.444660	array([[ 3.6460671, -9.094663 ]], dtype=float32)
time = 34445	action = 0	current_phase = 0	next_phase = 1	reward = 1.004405	array([[ 3.6343493, -9.091863 ]], dtype=float32)
time = 34450	action = 0	current_phase = 0	next_phase = 1	reward = 0.714904	array([[ 3.6253114, -9.071707 ]], dtype=float32)
time = 34455	action = 0	current_phase = 0	next_phase = 1	reward = 0.442487	array([[ 3.65828 , -9.124134]], dtype=float32)
time = 34460	action = 0	current_phase = 0	next_phase = 1	reward = 1.002236	array([[ 3.6486526, -9.15436  ]], dtype=float32)
time = 34465	action = 0	current_phase = 0	next_phase = 1	reward = 0.713656	array([[ 3.640432, -9.091801]], dtype=float32)
time = 34470	action = 0	current_phase = 0	next_phase = 1	reward = 0.441570	array([[ 3.667296, -9.061052]], dtype=float32)
time = 34475	action = 0	current_phase = 0	next_phase = 1	reward = 1.010013	array([[ 3.5862508, -9.118642 ]], dtype=float32)
time = 34480	action = 0	current_phase = 0	next_phase = 1	reward = 0.443503	array([[ 3.6625285, -9.07935  ]], dtype=float32)
time = 34485	action = 0	current_phase = 0	next_phase = 1	reward = 0.995081	array([[ 3.564074, -9.239095]], dtype=float32)
time = 34490	action = 0	current_phase = 0	next_phase = 1	reward = 0.438091	array([[ 3.6603732, -9.078283 ]], dtype=float32)
time = 34495	action = 0	current_phase = 0	next_phase = 1	reward = 0.729515	array([[ 3.6127057, -9.137609 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 3.1163 - val_loss: 3.5876
Epoch 2/50
 - 5s - loss: 6.7287 - val_loss: 2.9618
Epoch 3/50
 - 5s - loss: 5.3202 - val_loss: 2.9397
Epoch 4/50
 - 5s - loss: 4.8389 - val_loss: 2.6934
Epoch 5/50
 - 5s - loss: 8.1810 - val_loss: 2.5560
Epoch 6/50
 - 6s - loss: 6.6483 - val_loss: 2.2945
Epoch 7/50
 - 5s - loss: 6.6654 - val_loss: 2.7949
Epoch 8/50
 - 5s - loss: 5.4599 - val_loss: 2.0162
Epoch 9/50
 - 6s - loss: 4.6058 - val_loss: 1.9850
Epoch 10/50
 - 4s - loss: 4.8647 - val_loss: 2.3917
Epoch 11/50
 - 6s - loss: 4.6114 - val_loss: 2.2326
Epoch 12/50
 - 4s - loss: 4.8841 - val_loss: 2.4848
Epoch 13/50
 - 4s - loss: 4.6055 - val_loss: 2.9928
Epoch 14/50
 - 5s - loss: 3.9403 - val_loss: 2.4164
Epoch 15/50
 - 4s - loss: 3.2416 - val_loss: 2.8741
Epoch 16/50
 - 5s - loss: 3.5478 - val_loss: 3.3843
Epoch 17/50
 - 5s - loss: 2.7458 - val_loss: 2.5492
Epoch 18/50
 - 4s - loss: 4.4753 - val_loss: 2.6951
Epoch 19/50
 - 4s - loss: 3.1609 - val_loss: 3.1820
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 34500	action = 0	current_phase = 0	next_phase = 1	reward = 0.446430	array([[ 3.614986, -9.147675]], dtype=float32)
time = 34505	action = 0	current_phase = 0	next_phase = 1	reward = 1.285481	array([[ 3.6334147, -9.146343 ]], dtype=float32)
time = 34510	action = 0	current_phase = 0	next_phase = 1	reward = 0.725179	array([[ 3.5992818, -9.049945 ]], dtype=float32)
time = 34515	action = 0	current_phase = 0	next_phase = 1	reward = 0.729611	array([[ 3.6351209, -9.103224 ]], dtype=float32)
time = 34520	action = 0	current_phase = 0	next_phase = 1	reward = 0.447216	array([[ 3.6287665, -9.033456 ]], dtype=float32)
time = 34525	action = 0	current_phase = 0	next_phase = 1	reward = 1.009241	array([[ 3.6023555, -9.045073 ]], dtype=float32)
time = 34530	action = 0	current_phase = 0	next_phase = 1	reward = 0.734134	array([[ 3.6417346, -9.061323 ]], dtype=float32)
time = 34535	action = 0	current_phase = 0	next_phase = 1	reward = 0.728190	array([[ 3.6382842, -9.065791 ]], dtype=float32)
time = 34540	action = 0	current_phase = 0	next_phase = 1	reward = 0.715091	array([[ 3.638188, -9.076176]], dtype=float32)
time = 34545	action = 0	current_phase = 0	next_phase = 1	reward = 0.717508	array([[ 3.6463113, -9.006143 ]], dtype=float32)
time = 34550	action = 0	current_phase = 0	next_phase = 1	reward = 0.444714	array([[ 3.6471448, -9.090813 ]], dtype=float32)
time = 34555	action = 0	current_phase = 0	next_phase = 1	reward = 1.000519	array([[ 3.4332356, -9.313985 ]], dtype=float32)
time = 34560	action = 0	current_phase = 0	next_phase = 1	reward = 0.448880	array([[ 3.6387858, -9.065735 ]], dtype=float32)
time = 34565	action = 0	current_phase = 0	next_phase = 1	reward = 1.003648	array([[ 3.5477967, -9.081809 ]], dtype=float32)
time = 34570	action = 0	current_phase = 0	next_phase = 1	reward = 0.441863	array([[ 3.6651425, -9.068711 ]], dtype=float32)
time = 34575	action = 0	current_phase = 0	next_phase = 1	reward = 0.996855	array([[ 3.5874276, -9.105406 ]], dtype=float32)
time = 34580	action = 0	current_phase = 0	next_phase = 1	reward = 0.436931	array([[ 3.627293, -9.036717]], dtype=float32)
time = 34585	action = 0	current_phase = 0	next_phase = 1	reward = 0.726984	array([[ 3.58293, -9.10395]], dtype=float32)
time = 34590	action = 0	current_phase = 0	next_phase = 1	reward = 0.727973	array([[ 3.6295676, -9.174395 ]], dtype=float32)
time = 34595	action = 0	current_phase = 0	next_phase = 1	reward = 1.006481	array([[ 3.626554, -9.121109]], dtype=float32)
time = 34600	action = 0	current_phase = 0	next_phase = 1	reward = 0.442311	array([[ 3.6267323, -8.999131 ]], dtype=float32)
time = 34605	action = 0	current_phase = 0	next_phase = 1	reward = 0.726570	array([[ 3.6154208, -9.114212 ]], dtype=float32)
time = 34610	action = 0	current_phase = 0	next_phase = 1	reward = 0.725646	array([[ 3.5791125, -9.1170845]], dtype=float32)
time = 34615	action = 0	current_phase = 0	next_phase = 1	reward = 0.722733	array([[ 3.6026082, -9.094457 ]], dtype=float32)
time = 34620	action = 0	current_phase = 0	next_phase = 1	reward = 0.999970	array([[ 3.6330905, -9.069704 ]], dtype=float32)
time = 34625	action = 0	current_phase = 0	next_phase = 1	reward = 0.718770	array([[ 3.5676198, -9.070249 ]], dtype=float32)
time = 34630	action = 0	current_phase = 0	next_phase = 1	reward = 0.158374	array([[ 3.6348147, -9.114141 ]], dtype=float32)
time = 34635	action = 0	current_phase = 0	next_phase = 1	reward = 1.294620	array([[ 3.6010356, -9.171789 ]], dtype=float32)
time = 34640	action = 0	current_phase = 0	next_phase = 1	reward = 0.446707	array([[ 3.650165, -9.08934 ]], dtype=float32)
time = 34645	action = 0	current_phase = 0	next_phase = 1	reward = 1.004425	array([[ 3.6381822, -9.025068 ]], dtype=float32)
time = 34650	action = 0	current_phase = 0	next_phase = 1	reward = 0.724699	array([[ 3.622768, -9.012263]], dtype=float32)
time = 34655	action = 0	current_phase = 0	next_phase = 1	reward = 0.724284	array([[ 3.498407, -9.107461]], dtype=float32)
time = 34660	action = 0	current_phase = 0	next_phase = 1	reward = 0.724046	array([[ 3.623155, -9.021148]], dtype=float32)
time = 34665	action = 0	current_phase = 0	next_phase = 1	reward = 0.445382	array([[ 3.6296172, -9.084394 ]], dtype=float32)
time = 34670	action = 0	current_phase = 0	next_phase = 1	reward = 0.734058	array([[ 3.6448178, -9.222206 ]], dtype=float32)
time = 34675	action = 0	current_phase = 0	next_phase = 1	reward = 1.013456	array([[ 3.615849, -9.035118]], dtype=float32)
time = 34680	action = 0	current_phase = 0	next_phase = 1	reward = 0.722459	array([[ 3.594996 , -9.1421175]], dtype=float32)
time = 34685	action = 0	current_phase = 0	next_phase = 1	reward = 0.717902	array([[ 3.6452565, -9.084484 ]], dtype=float32)
time = 34690	action = 0	current_phase = 0	next_phase = 1	reward = 0.720325	array([[ 3.6481576, -9.050709 ]], dtype=float32)
time = 34695	action = 0	current_phase = 0	next_phase = 1	reward = 0.735669	array([[ 3.6316285, -9.068333 ]], dtype=float32)
time = 34700	action = 0	current_phase = 0	next_phase = 1	reward = 0.720568	array([[ 3.5487819, -9.081895 ]], dtype=float32)
time = 34705	action = 0	current_phase = 0	next_phase = 1	reward = 0.720524	array([[ 3.6479611, -8.985665 ]], dtype=float32)
time = 34710	action = 0	current_phase = 0	next_phase = 1	reward = 0.724885	array([[ 3.6291623, -9.067533 ]], dtype=float32)
time = 34715	action = 0	current_phase = 0	next_phase = 1	reward = 0.729201	array([[ 3.647181, -9.104385]], dtype=float32)
time = 34720	action = 0	current_phase = 0	next_phase = 1	reward = 0.442180	array([[ 3.5778203, -9.035558 ]], dtype=float32)
time = 34725	action = 0	current_phase = 0	next_phase = 1	reward = 0.725616	array([[ 3.6277719, -9.071259 ]], dtype=float32)
time = 34730	action = 0	current_phase = 0	next_phase = 1	reward = 1.004963	array([[ 3.637199, -9.137599]], dtype=float32)
time = 34735	action = 0	current_phase = 0	next_phase = 1	reward = 0.727783	array([[ 3.6654344, -9.045685 ]], dtype=float32)
time = 34740	action = 0	current_phase = 0	next_phase = 1	reward = 0.722521	array([[ 3.633988, -9.059994]], dtype=float32)
time = 34745	action = 0	current_phase = 0	next_phase = 1	reward = 0.719936	array([[ 3.6496358, -9.032354 ]], dtype=float32)
time = 34750	action = 0	current_phase = 0	next_phase = 1	reward = 0.720582	array([[ 3.6536794, -9.041208 ]], dtype=float32)
time = 34755	action = 0	current_phase = 0	next_phase = 1	reward = 0.725144	array([[ 3.6469588, -9.053951 ]], dtype=float32)
time = 34760	action = 0	current_phase = 0	next_phase = 1	reward = 0.443292	array([[ 3.6244063, -9.087374 ]], dtype=float32)
time = 34765	action = 0	current_phase = 0	next_phase = 1	reward = 0.726452	array([[ 3.6103663, -9.204815 ]], dtype=float32)
time = 34770	action = 0	current_phase = 0	next_phase = 1	reward = 1.000852	array([[ 3.6043077, -9.169317 ]], dtype=float32)
time = 34775	action = 0	current_phase = 0	next_phase = 1	reward = 0.711882	array([[ 3.63446 , -9.070343]], dtype=float32)
time = 34780	action = 0	current_phase = 0	next_phase = 1	reward = 0.729182	array([[ 3.6148648, -9.074176 ]], dtype=float32)
time = 34785	action = 0	current_phase = 0	next_phase = 1	reward = 0.720864	array([[ 3.6436725, -9.074606 ]], dtype=float32)
time = 34790	action = 0	current_phase = 0	next_phase = 1	reward = 0.723102	array([[ 3.626801, -9.082804]], dtype=float32)
time = 34795	action = 0	current_phase = 0	next_phase = 1	reward = 0.441115	array([[ 3.645105, -9.035702]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.9646 - val_loss: 2.1357
Epoch 2/50
 - 4s - loss: 4.6955 - val_loss: 2.0725
Epoch 3/50
 - 4s - loss: 5.2125 - val_loss: 1.4925
Epoch 4/50
 - 4s - loss: 3.9586 - val_loss: 2.2129
Epoch 5/50
 - 4s - loss: 3.7420 - val_loss: 1.8103
Epoch 6/50
 - 4s - loss: 5.1613 - val_loss: 2.3000
Epoch 7/50
 - 4s - loss: 6.7688 - val_loss: 1.6347
Epoch 8/50
 - 4s - loss: 5.7835 - val_loss: 1.4033
Epoch 9/50
 - 4s - loss: 5.0529 - val_loss: 1.5900
Epoch 10/50
 - 4s - loss: 4.8587 - val_loss: 1.8538
Epoch 11/50
 - 4s - loss: 4.0367 - val_loss: 2.0150
Epoch 12/50
 - 4s - loss: 5.7736 - val_loss: 3.2008
Epoch 13/50
 - 4s - loss: 5.9741 - val_loss: 1.8249
Epoch 14/50
 - 4s - loss: 3.5753 - val_loss: 1.9493
Epoch 15/50
 - 5s - loss: 5.2072 - val_loss: 2.4966
Epoch 16/50
 - 4s - loss: 4.2826 - val_loss: 1.9655
Epoch 17/50
 - 4s - loss: 3.9600 - val_loss: 2.2328
Epoch 18/50
 - 4s - loss: 4.8769 - val_loss: 1.8079
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 34800	action = 0	current_phase = 0	next_phase = 1	reward = 1.011787	array([[ 3.6439028, -9.073299 ]], dtype=float32)
time = 34805	action = 0	current_phase = 0	next_phase = 1	reward = 0.729519	array([[ 3.6585064, -9.060251 ]], dtype=float32)
time = 34810	action = 0	current_phase = 0	next_phase = 1	reward = 0.714827	array([[ 3.6308327, -9.062711 ]], dtype=float32)
time = 34815	action = 0	current_phase = 0	next_phase = 1	reward = 0.716492	array([[ 3.6355963, -9.093568 ]], dtype=float32)
time = 34820	action = 0	current_phase = 0	next_phase = 1	reward = 0.723245	array([[ 3.6434288, -9.073288 ]], dtype=float32)
time = 34825	action = 0	current_phase = 0	next_phase = 1	reward = 0.724333	array([[ 3.6315508, -9.0860615]], dtype=float32)
time = 34830	action = 0	current_phase = 0	next_phase = 1	reward = 0.439738	array([[ 3.6481514, -9.10222  ]], dtype=float32)
time = 34835	action = 0	current_phase = 0	next_phase = 1	reward = 0.726201	array([[ 3.5626144, -9.133793 ]], dtype=float32)
time = 34840	action = 0	current_phase = 0	next_phase = 1	reward = 0.735520	array([[ 3.5773973, -9.047974 ]], dtype=float32)
time = 34845	action = 0	current_phase = 0	next_phase = 1	reward = 0.725839	array([[ 3.6510725, -9.120329 ]], dtype=float32)
time = 34850	action = 0	current_phase = 0	next_phase = 1	reward = 0.723226	array([[ 3.6105194, -9.130594 ]], dtype=float32)
time = 34855	action = 0	current_phase = 0	next_phase = 1	reward = 0.997465	array([[ 3.6442986, -9.109852 ]], dtype=float32)
time = 34860	action = 0	current_phase = 0	next_phase = 1	reward = 0.718087	array([[ 3.633584, -9.062144]], dtype=float32)
time = 34865	action = 0	current_phase = 0	next_phase = 1	reward = 0.433834	array([[ 3.6171865, -9.090047 ]], dtype=float32)
time = 34870	action = 0	current_phase = 0	next_phase = 1	reward = 0.449660	array([[ 3.642292, -9.069112]], dtype=float32)
time = 34875	action = 0	current_phase = 0	next_phase = 1	reward = 1.012681	array([[ 3.6330767, -9.101396 ]], dtype=float32)
time = 34880	action = 0	current_phase = 0	next_phase = 1	reward = 1.002153	array([[ 3.5367775, -9.141987 ]], dtype=float32)
time = 34885	action = 0	current_phase = 0	next_phase = 1	reward = 0.732996	array([[ 3.6406012, -9.040416 ]], dtype=float32)
time = 34890	action = 0	current_phase = 0	next_phase = 1	reward = 0.721250	array([[ 3.6143389, -9.018305 ]], dtype=float32)
time = 34895	action = 0	current_phase = 0	next_phase = 1	reward = 0.442683	array([[ 3.6410093, -9.181618 ]], dtype=float32)
time = 34900	action = 0	current_phase = 0	next_phase = 1	reward = 1.008527	array([[ 3.6084042, -9.155837 ]], dtype=float32)
time = 34905	action = 0	current_phase = 0	next_phase = 1	reward = 0.442023	array([[ 3.6335258, -9.048847 ]], dtype=float32)
time = 34910	action = 0	current_phase = 0	next_phase = 1	reward = 1.007083	array([[ 3.6193075, -9.081297 ]], dtype=float32)
time = 34915	action = 0	current_phase = 0	next_phase = 1	reward = 0.721704	array([[ 3.6396084, -9.060829 ]], dtype=float32)
time = 34920	action = 0	current_phase = 0	next_phase = 1	reward = 0.727384	array([[ 3.655446, -9.060194]], dtype=float32)
time = 34925	action = 0	current_phase = 0	next_phase = 1	reward = 0.165138	array([[ 3.6297731, -9.039336 ]], dtype=float32)
time = 34930	action = 0	current_phase = 0	next_phase = 1	reward = 1.280109	array([[ 3.6032314, -9.148554 ]], dtype=float32)
time = 34935	action = 0	current_phase = 0	next_phase = 1	reward = 0.728594	array([[ 3.6261435, -9.007837 ]], dtype=float32)
time = 34940	action = 0	current_phase = 0	next_phase = 1	reward = 0.722901	array([[ 3.6279345, -9.110279 ]], dtype=float32)
time = 34945	action = 0	current_phase = 0	next_phase = 1	reward = 0.722502	array([[ 3.5369873, -9.055282 ]], dtype=float32)
time = 34950	action = 0	current_phase = 0	next_phase = 1	reward = 0.723523	array([[ 3.5878859, -9.05884  ]], dtype=float32)
time = 34955	action = 0	current_phase = 0	next_phase = 1	reward = 0.722305	array([[ 3.646862, -9.059227]], dtype=float32)
time = 34960	action = 0	current_phase = 0	next_phase = 1	reward = 0.442230	array([[ 3.6558704, -9.047075 ]], dtype=float32)
time = 34965	action = 0	current_phase = 0	next_phase = 1	reward = 1.000455	array([[ 3.644847, -9.04484 ]], dtype=float32)
time = 34970	action = 0	current_phase = 0	next_phase = 1	reward = 0.719891	array([[ 3.6671772, -9.064463 ]], dtype=float32)
time = 34975	action = 0	current_phase = 0	next_phase = 1	reward = 0.726190	array([[ 3.5603275, -9.107053 ]], dtype=float32)
time = 34980	action = 0	current_phase = 0	next_phase = 1	reward = 0.726422	array([[ 3.6258202, -9.010156 ]], dtype=float32)
time = 34985	action = 0	current_phase = 0	next_phase = 1	reward = 0.448117	array([[ 3.6424932, -9.082081 ]], dtype=float32)
time = 34990	action = 0	current_phase = 0	next_phase = 1	reward = 1.000881	array([[ 3.6336699, -9.208073 ]], dtype=float32)
time = 34995	action = 0	current_phase = 0	next_phase = 1	reward = 0.720028	array([[ 3.6340532, -9.05505  ]], dtype=float32)
time = 35000	action = 0	current_phase = 0	next_phase = 1	reward = 0.451274	array([[ 3.6510105, -9.104296 ]], dtype=float32)
time = 35005	action = 0	current_phase = 0	next_phase = 1	reward = 1.009095	array([[ 3.649129 , -9.0840435]], dtype=float32)
time = 35010	action = 0	current_phase = 0	next_phase = 1	reward = 0.714179	array([[ 3.6063776, -9.058691 ]], dtype=float32)
time = 35015	action = 0	current_phase = 0	next_phase = 1	reward = 0.715376	array([[ 3.5975914, -9.034403 ]], dtype=float32)
time = 35020	action = 0	current_phase = 0	next_phase = 1	reward = 0.437744	array([[ 3.6521797, -9.028866 ]], dtype=float32)
time = 35025	action = 0	current_phase = 0	next_phase = 1	reward = 0.728386	array([[ 3.5422764, -9.267899 ]], dtype=float32)
time = 35030	action = 0	current_phase = 0	next_phase = 1	reward = 0.718752	array([[ 3.654234, -9.172749]], dtype=float32)
time = 35035	action = 0	current_phase = 0	next_phase = 1	reward = 0.730975	array([[ 3.6233912, -9.013933 ]], dtype=float32)
time = 35040	action = 0	current_phase = 0	next_phase = 1	reward = 0.727092	array([[ 3.64752 , -9.070192]], dtype=float32)
time = 35045	action = 0	current_phase = 0	next_phase = 1	reward = 1.002968	array([[ 3.4737186, -9.261536 ]], dtype=float32)
time = 35050	action = 0	current_phase = 0	next_phase = 1	reward = 0.721624	array([[ 3.6506872, -9.021651 ]], dtype=float32)
time = 35055	action = 0	current_phase = 0	next_phase = 1	reward = 0.723494	array([[ 3.6743402, -9.053571 ]], dtype=float32)
time = 35060	action = 0	current_phase = 0	next_phase = 1	reward = 0.717408	array([[ 3.6236372, -9.050538 ]], dtype=float32)
time = 35065	action = 0	current_phase = 0	next_phase = 1	reward = 0.435852	array([[ 3.646988, -9.062984]], dtype=float32)
time = 35070	action = 0	current_phase = 0	next_phase = 1	reward = 1.003325	array([[ 3.633751, -9.078142]], dtype=float32)
time = 35075	action = 0	current_phase = 0	next_phase = 1	reward = 0.435851	array([[ 3.675397, -9.148342]], dtype=float32)
time = 35080	action = 0	current_phase = 0	next_phase = 1	reward = 1.006787	array([[ 3.613412, -9.10438 ]], dtype=float32)
time = 35085	action = 0	current_phase = 0	next_phase = 1	reward = 0.448080	array([[ 3.559002, -9.104206]], dtype=float32)
time = 35090	action = 0	current_phase = 0	next_phase = 1	reward = 0.449188	array([[ 3.5230064, -9.095632 ]], dtype=float32)
time = 35095	action = 0	current_phase = 0	next_phase = 1	reward = 1.014256	array([[ 3.566743, -9.26079 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4.8258 - val_loss: 2.0989
Epoch 2/50
 - 4s - loss: 5.7918 - val_loss: 1.8753
Epoch 3/50
 - 4s - loss: 6.5608 - val_loss: 1.6350
Epoch 4/50
 - 4s - loss: 4.8583 - val_loss: 2.1954
Epoch 5/50
 - 4s - loss: 5.8682 - val_loss: 1.4284
Epoch 6/50
 - 5s - loss: 5.0214 - val_loss: 1.6226
Epoch 7/50
 - 4s - loss: 6.1376 - val_loss: 1.9110
Epoch 8/50
 - 4s - loss: 4.1165 - val_loss: 2.0263
Epoch 9/50
 - 4s - loss: 4.8875 - val_loss: 2.3090
Epoch 10/50
 - 4s - loss: 3.8125 - val_loss: 1.7608
Epoch 11/50
 - 4s - loss: 4.5038 - val_loss: 2.0002
Epoch 12/50
 - 4s - loss: 6.1491 - val_loss: 2.2456
Epoch 13/50
 - 4s - loss: 4.4801 - val_loss: 2.0534
Epoch 14/50
 - 4s - loss: 4.3133 - val_loss: 1.7372
Epoch 15/50
 - 4s - loss: 4.2135 - val_loss: 2.0155
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 35100	action = 0	current_phase = 0	next_phase = 1	reward = 1.002639	array([[ 3.5110178, -9.175215 ]], dtype=float32)
time = 35105	action = 0	current_phase = 0	next_phase = 1	reward = 0.447057	array([[ 3.6175327, -9.095256 ]], dtype=float32)
time = 35110	action = 0	current_phase = 0	next_phase = 1	reward = 1.002434	array([[ 3.6222878, -9.084381 ]], dtype=float32)
time = 35115	action = 0	current_phase = 0	next_phase = 1	reward = 0.442776	array([[ 3.5537596, -9.10857  ]], dtype=float32)
time = 35120	action = 0	current_phase = 0	next_phase = 1	reward = 0.726814	array([[ 3.644372, -9.081412]], dtype=float32)
time = 35125	action = 0	current_phase = 0	next_phase = 1	reward = 1.001955	array([[ 3.6362524, -9.082183 ]], dtype=float32)
time = 35130	action = 0	current_phase = 0	next_phase = 1	reward = 0.720135	array([[ 3.6663265, -9.048008 ]], dtype=float32)
time = 35135	action = 0	current_phase = 0	next_phase = 1	reward = 0.720100	array([[ 3.553403 , -9.0959015]], dtype=float32)
time = 35140	action = 0	current_phase = 0	next_phase = 1	reward = 0.443064	array([[ 3.629777, -9.036058]], dtype=float32)
time = 35145	action = 0	current_phase = 0	next_phase = 1	reward = 1.002005	array([[ 3.6313972, -9.185538 ]], dtype=float32)
time = 35150	action = 0	current_phase = 0	next_phase = 1	reward = 0.723566	array([[ 3.595868, -9.06536 ]], dtype=float32)
time = 35155	action = 0	current_phase = 0	next_phase = 1	reward = 0.723753	array([[ 3.6548166, -9.03673  ]], dtype=float32)
time = 35160	action = 0	current_phase = 0	next_phase = 1	reward = 0.730687	array([[ 3.641531, -9.082833]], dtype=float32)
time = 35165	action = 0	current_phase = 0	next_phase = 1	reward = 0.444723	array([[ 3.6595297, -8.998671 ]], dtype=float32)
time = 35170	action = 0	current_phase = 0	next_phase = 1	reward = 1.004436	array([[ 3.6329098, -9.074556 ]], dtype=float32)
time = 35175	action = 0	current_phase = 0	next_phase = 1	reward = 0.721625	array([[ 3.634037, -9.099388]], dtype=float32)
time = 35180	action = 0	current_phase = 0	next_phase = 1	reward = 0.718498	array([[ 3.6403418, -9.099577 ]], dtype=float32)
time = 35185	action = 0	current_phase = 0	next_phase = 1	reward = 0.717663	array([[ 3.6269426, -9.083993 ]], dtype=float32)
time = 35190	action = 0	current_phase = 0	next_phase = 1	reward = 0.718678	array([[ 3.6489573, -9.078919 ]], dtype=float32)
time = 35195	action = 0	current_phase = 0	next_phase = 1	reward = 0.720478	array([[ 3.6278057, -9.098042 ]], dtype=float32)
time = 35200	action = 0	current_phase = 0	next_phase = 1	reward = 0.723556	array([[ 3.6099586, -9.077339 ]], dtype=float32)
time = 35205	action = 0	current_phase = 0	next_phase = 1	reward = 0.438042	array([[ 3.5725193, -9.094568 ]], dtype=float32)
time = 35210	action = 0	current_phase = 0	next_phase = 1	reward = 0.996876	array([[ 3.569994, -9.104207]], dtype=float32)
time = 35215	action = 0	current_phase = 0	next_phase = 1	reward = 0.441151	array([[ 3.5538445, -9.097244 ]], dtype=float32)
time = 35220	action = 0	current_phase = 0	next_phase = 1	reward = 0.722269	array([[ 3.623848, -9.221758]], dtype=float32)
time = 35225	action = 0	current_phase = 0	next_phase = 1	reward = 1.003846	array([[ 3.6226263, -9.193014 ]], dtype=float32)
time = 35230	action = 0	current_phase = 0	next_phase = 1	reward = 0.728233	array([[ 3.621027, -9.081104]], dtype=float32)
time = 35235	action = 0	current_phase = 0	next_phase = 1	reward = 0.450337	array([[ 3.481742, -9.18529 ]], dtype=float32)
time = 35240	action = 0	current_phase = 0	next_phase = 1	reward = 1.010052	array([[ 3.6290665, -9.170566 ]], dtype=float32)
time = 35245	action = 0	current_phase = 0	next_phase = 1	reward = 0.722210	array([[ 3.6067886, -9.072749 ]], dtype=float32)
time = 35250	action = 0	current_phase = 0	next_phase = 1	reward = 0.715855	array([[ 3.5954065, -9.131369 ]], dtype=float32)
time = 35255	action = 0	current_phase = 0	next_phase = 1	reward = 0.430143	array([[ 3.5883093, -9.108571 ]], dtype=float32)
time = 35260	action = 0	current_phase = 0	next_phase = 1	reward = 1.005787	array([[ 3.6437683, -9.1159935]], dtype=float32)
time = 35265	action = 0	current_phase = 0	next_phase = 1	reward = 0.448301	array([[ 3.5863094, -9.033619 ]], dtype=float32)
time = 35270	action = 0	current_phase = 0	next_phase = 1	reward = 0.725631	array([[ 3.6399288, -9.087269 ]], dtype=float32)
time = 35275	action = 0	current_phase = 0	next_phase = 1	reward = 0.732605	array([[ 3.6209927, -9.114323 ]], dtype=float32)
time = 35280	action = 0	current_phase = 0	next_phase = 1	reward = 1.012622	array([[ 3.664813, -9.060596]], dtype=float32)
time = 35285	action = 0	current_phase = 0	next_phase = 1	reward = 0.450474	array([[ 3.6793156, -9.004258 ]], dtype=float32)
time = 35290	action = 0	current_phase = 0	next_phase = 1	reward = 1.011882	array([[ 3.6485014, -9.08515  ]], dtype=float32)
time = 35295	action = 0	current_phase = 0	next_phase = 1	reward = 0.734016	array([[ 3.6382093, -9.053035 ]], dtype=float32)
time = 35300	action = 0	current_phase = 0	next_phase = 1	reward = 0.727191	array([[ 3.6155748, -9.136058 ]], dtype=float32)
time = 35305	action = 0	current_phase = 0	next_phase = 1	reward = 0.730170	array([[ 3.658924, -9.096973]], dtype=float32)
time = 35310	action = 0	current_phase = 0	next_phase = 1	reward = 0.721838	array([[ 3.6458836, -9.000865 ]], dtype=float32)
time = 35315	action = 0	current_phase = 0	next_phase = 1	reward = 0.724100	array([[ 3.669221, -9.062375]], dtype=float32)
time = 35320	action = 0	current_phase = 0	next_phase = 1	reward = 0.723484	array([[ 3.661974, -9.000022]], dtype=float32)
time = 35325	action = 0	current_phase = 0	next_phase = 1	reward = 0.721928	array([[ 3.6659536, -9.114969 ]], dtype=float32)
time = 35330	action = 0	current_phase = 0	next_phase = 1	reward = 0.724312	array([[ 3.6360922, -9.035055 ]], dtype=float32)
time = 35335	action = 0	current_phase = 0	next_phase = 1	reward = 0.437763	array([[ 3.6417646, -9.100365 ]], dtype=float32)
time = 35340	action = 0	current_phase = 0	next_phase = 1	reward = 1.004186	array([[ 3.6319675, -9.080692 ]], dtype=float32)
time = 35345	action = 0	current_phase = 0	next_phase = 1	reward = 0.445916	array([[ 3.5693178, -9.147951 ]], dtype=float32)
time = 35350	action = 0	current_phase = 0	next_phase = 1	reward = 1.005409	array([[ 3.6722956, -9.10095  ]], dtype=float32)
time = 35355	action = 0	current_phase = 0	next_phase = 1	reward = 0.446848	array([[ 3.6377802, -9.006325 ]], dtype=float32)
time = 35360	action = 0	current_phase = 0	next_phase = 1	reward = 0.720158	array([[ 3.6541471, -9.1135845]], dtype=float32)
time = 35365	action = 0	current_phase = 0	next_phase = 1	reward = 0.726445	array([[ 3.6112776, -9.210198 ]], dtype=float32)
time = 35370	action = 0	current_phase = 0	next_phase = 1	reward = 1.001982	array([[ 3.4682207, -9.250942 ]], dtype=float32)
time = 35375	action = 0	current_phase = 0	next_phase = 1	reward = 0.723830	array([[ 3.6295233, -9.02593  ]], dtype=float32)
time = 35380	action = 0	current_phase = 0	next_phase = 1	reward = 0.442562	array([[ 3.647543, -9.052028]], dtype=float32)
time = 35385	action = 0	current_phase = 0	next_phase = 1	reward = 0.998702	array([[ 3.657587, -9.060561]], dtype=float32)
time = 35390	action = 0	current_phase = 0	next_phase = 1	reward = 0.444808	array([[ 3.6648893, -9.016112 ]], dtype=float32)
time = 35395	action = 0	current_phase = 0	next_phase = 1	reward = 1.009941	array([[ 3.5939035, -9.282871 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 7s - loss: 5.9680 - val_loss: 1.5688
Epoch 2/50
 - 6s - loss: 5.8154 - val_loss: 2.1566
Epoch 3/50
 - 4s - loss: 6.3559 - val_loss: 3.1074
Epoch 4/50
 - 4s - loss: 7.2836 - val_loss: 2.7316
Epoch 5/50
 - 4s - loss: 6.1875 - val_loss: 1.8617
Epoch 6/50
 - 4s - loss: 6.0403 - val_loss: 1.9940
Epoch 7/50
 - 4s - loss: 5.8798 - val_loss: 1.6787
Epoch 8/50
 - 4s - loss: 5.8093 - val_loss: 1.4954
Epoch 9/50
 - 4s - loss: 6.1295 - val_loss: 1.4911
Epoch 10/50
 - 4s - loss: 4.8448 - val_loss: 1.7049
Epoch 11/50
 - 4s - loss: 5.8493 - val_loss: 1.7843
Epoch 12/50
 - 4s - loss: 5.5980 - val_loss: 2.4999
Epoch 13/50
 - 4s - loss: 4.9707 - val_loss: 3.0692
Epoch 14/50
 - 4s - loss: 4.3987 - val_loss: 2.1264
Epoch 15/50
 - 4s - loss: 5.0381 - val_loss: 1.7490
Epoch 16/50
 - 4s - loss: 5.7405 - val_loss: 1.7665
Epoch 17/50
 - 4s - loss: 4.5156 - val_loss: 4.4117
Epoch 18/50
 - 4s - loss: 5.0968 - val_loss: 2.8382
Epoch 19/50
 - 4s - loss: 4.0406 - val_loss: 2.7227
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 35400	action = 0	current_phase = 0	next_phase = 1	reward = 0.721661	array([[ 3.6254578, -9.065563 ]], dtype=float32)
time = 35405	action = 0	current_phase = 0	next_phase = 1	reward = 0.167544	array([[ 3.6386433, -9.16626  ]], dtype=float32)
time = 35410	action = 0	current_phase = 0	next_phase = 1	reward = 1.286600	array([[ 3.6176949, -9.264108 ]], dtype=float32)
time = 35415	action = 0	current_phase = 0	next_phase = 1	reward = 0.714641	array([[ 3.5964003, -9.119053 ]], dtype=float32)
time = 35420	action = 0	current_phase = 0	next_phase = 1	reward = 0.435512	array([[ 3.6339054, -9.167339 ]], dtype=float32)
time = 35425	action = 0	current_phase = 0	next_phase = 1	reward = 0.716548	array([[ 3.5214548, -9.304312 ]], dtype=float32)
time = 35430	action = 0	current_phase = 0	next_phase = 1	reward = 0.997796	array([[ 3.6140518, -9.211532 ]], dtype=float32)
time = 35435	action = 0	current_phase = 0	next_phase = 1	reward = 0.444699	array([[ 3.629817, -9.059917]], dtype=float32)
time = 35440	action = 0	current_phase = 0	next_phase = 1	reward = 0.736423	array([[ 3.6399221, -9.207485 ]], dtype=float32)
time = 35445	action = 0	current_phase = 0	next_phase = 1	reward = 0.726610	array([[ 3.631774, -9.272596]], dtype=float32)
time = 35450	action = 0	current_phase = 0	next_phase = 1	reward = 1.000840	array([[ 3.6652422, -9.186875 ]], dtype=float32)
time = 35455	action = 0	current_phase = 0	next_phase = 1	reward = 0.442225	array([[ 3.6270914, -9.0843315]], dtype=float32)
time = 35460	action = 0	current_phase = 0	next_phase = 1	reward = 1.010470	array([[ 3.639203, -9.128801]], dtype=float32)
time = 35465	action = 0	current_phase = 0	next_phase = 1	reward = 0.448616	array([[ 3.6459417, -9.111307 ]], dtype=float32)
time = 35470	action = 0	current_phase = 0	next_phase = 1	reward = 1.003847	array([[ 3.584056, -9.162331]], dtype=float32)
time = 35475	action = 0	current_phase = 0	next_phase = 1	reward = 0.719994	array([[ 3.6578703, -9.080906 ]], dtype=float32)
time = 35480	action = 0	current_phase = 0	next_phase = 1	reward = 0.723187	array([[ 3.6620188, -9.071084 ]], dtype=float32)
time = 35485	action = 0	current_phase = 0	next_phase = 1	reward = 0.724745	array([[ 3.6384583, -9.163388 ]], dtype=float32)
time = 35490	action = 0	current_phase = 0	next_phase = 1	reward = 0.726325	array([[ 3.6471624, -9.116695 ]], dtype=float32)
time = 35495	action = 0	current_phase = 0	next_phase = 1	reward = 0.721937	array([[ 3.6164093, -9.147213 ]], dtype=float32)
time = 35500	action = 0	current_phase = 0	next_phase = 1	reward = 0.723663	array([[ 3.6527805, -9.158316 ]], dtype=float32)
time = 35505	action = 0	current_phase = 0	next_phase = 1	reward = 0.445809	array([[ 3.6309443, -9.165213 ]], dtype=float32)
time = 35510	action = 0	current_phase = 0	next_phase = 1	reward = 1.005936	array([[ 3.6850758, -9.0922165]], dtype=float32)
time = 35515	action = 0	current_phase = 0	next_phase = 1	reward = 0.442929	array([[ 3.5884838, -9.161858 ]], dtype=float32)
time = 35520	action = 0	current_phase = 0	next_phase = 1	reward = 1.001804	array([[ 3.657155, -9.134125]], dtype=float32)
time = 35525	action = 0	current_phase = 0	next_phase = 1	reward = 0.718663	array([[ 3.6136484, -9.231735 ]], dtype=float32)
time = 35530	action = 0	current_phase = 0	next_phase = 1	reward = 0.444154	array([[ 3.6671505, -9.08637  ]], dtype=float32)
time = 35535	action = 0	current_phase = 0	next_phase = 1	reward = 0.728053	array([[ 3.6489277, -9.242879 ]], dtype=float32)
time = 35540	action = 0	current_phase = 0	next_phase = 1	reward = 1.002684	array([[ 3.5863419, -9.134834 ]], dtype=float32)
time = 35545	action = 0	current_phase = 0	next_phase = 1	reward = 0.441375	array([[ 3.65829 , -9.124215]], dtype=float32)
time = 35550	action = 0	current_phase = 0	next_phase = 1	reward = 0.720477	array([[ 3.6367521, -9.146775 ]], dtype=float32)
time = 35555	action = 0	current_phase = 0	next_phase = 1	reward = 0.726417	array([[ 3.6737642, -9.13278  ]], dtype=float32)
time = 35560	action = 0	current_phase = 0	next_phase = 1	reward = 0.999465	array([[ 3.6498384, -9.093662 ]], dtype=float32)
time = 35565	action = 0	current_phase = 0	next_phase = 1	reward = 0.455601	array([[ 3.6727505, -9.181807 ]], dtype=float32)
time = 35570	action = 0	current_phase = 0	next_phase = 1	reward = 1.002324	array([[ 3.6609087, -9.133518 ]], dtype=float32)
time = 35575	action = 0	current_phase = 0	next_phase = 1	reward = 0.722079	array([[ 3.6511164, -9.159206 ]], dtype=float32)
time = 35580	action = 0	current_phase = 0	next_phase = 1	reward = 0.713514	array([[ 3.6638556, -9.115759 ]], dtype=float32)
time = 35585	action = 0	current_phase = 0	next_phase = 1	reward = 0.437373	array([[ 3.6425886, -9.161727 ]], dtype=float32)
time = 35590	action = 0	current_phase = 0	next_phase = 1	reward = 0.725117	array([[ 3.6352034, -9.148233 ]], dtype=float32)
time = 35595	action = 0	current_phase = 0	next_phase = 1	reward = 0.731253	array([[ 3.6349802, -9.179778 ]], dtype=float32)
time = 35600	action = 0	current_phase = 0	next_phase = 1	reward = 1.002459	array([[ 3.6415339, -9.117319 ]], dtype=float32)
time = 35605	action = 0	current_phase = 0	next_phase = 1	reward = 0.434267	array([[ 3.6117516, -9.104442 ]], dtype=float32)
time = 35610	action = 0	current_phase = 0	next_phase = 1	reward = 0.721848	array([[ 3.6585093, -9.247819 ]], dtype=float32)
time = 35615	action = 0	current_phase = 0	next_phase = 1	reward = 0.730920	array([[ 3.587016, -9.117623]], dtype=float32)
time = 35620	action = 0	current_phase = 0	next_phase = 1	reward = 0.725669	array([[ 3.658101, -9.14063 ]], dtype=float32)
time = 35625	action = 0	current_phase = 0	next_phase = 1	reward = 0.736972	array([[ 3.54988 , -9.311662]], dtype=float32)
time = 35630	action = 0	current_phase = 0	next_phase = 1	reward = 1.005054	array([[ 3.5923395, -9.163205 ]], dtype=float32)
time = 35635	action = 0	current_phase = 0	next_phase = 1	reward = 0.721402	array([[ 3.6588612, -9.150625 ]], dtype=float32)
time = 35640	action = 0	current_phase = 0	next_phase = 1	reward = 0.720534	array([[ 3.658638, -9.119367]], dtype=float32)
time = 35645	action = 0	current_phase = 0	next_phase = 1	reward = 0.719575	array([[ 3.6253567, -9.189381 ]], dtype=float32)
time = 35650	action = 0	current_phase = 0	next_phase = 1	reward = 0.448255	array([[ 3.6586676, -9.154572 ]], dtype=float32)
time = 35655	action = 0	current_phase = 0	next_phase = 1	reward = 1.003441	array([[ 3.6316328, -9.165715 ]], dtype=float32)
time = 35660	action = 0	current_phase = 0	next_phase = 1	reward = 0.718087	array([[ 3.6474829, -9.074837 ]], dtype=float32)
time = 35665	action = 0	current_phase = 0	next_phase = 1	reward = 0.726739	array([[ 3.6477919, -9.149359 ]], dtype=float32)
time = 35670	action = 0	current_phase = 0	next_phase = 1	reward = 0.720968	array([[ 3.6566515, -9.166545 ]], dtype=float32)
time = 35675	action = 0	current_phase = 0	next_phase = 1	reward = 0.443777	array([[ 3.6580162, -9.156364 ]], dtype=float32)
time = 35680	action = 0	current_phase = 0	next_phase = 1	reward = 0.725704	array([[ 3.6254349, -9.138226 ]], dtype=float32)
time = 35685	action = 0	current_phase = 0	next_phase = 1	reward = 1.012137	array([[ 3.641057, -9.144077]], dtype=float32)
time = 35690	action = 0	current_phase = 0	next_phase = 1	reward = 0.726319	array([[ 3.5824099, -9.18349  ]], dtype=float32)
time = 35695	action = 0	current_phase = 0	next_phase = 1	reward = 0.442418	array([[ 3.6870136, -9.126457 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 7.1118 - val_loss: 1.3246
Epoch 2/50
 - 5s - loss: 4.6415 - val_loss: 1.2323
Epoch 3/50
 - 6s - loss: 6.8199 - val_loss: 0.9925
Epoch 4/50
 - 6s - loss: 4.8262 - val_loss: 1.1646
Epoch 5/50
 - 7s - loss: 4.4823 - val_loss: 1.0764
Epoch 6/50
 - 6s - loss: 8.5577 - val_loss: 1.7249
Epoch 7/50
 - 5s - loss: 4.1795 - val_loss: 1.3934
Epoch 8/50
 - 4s - loss: 5.3457 - val_loss: 1.2015
Epoch 9/50
 - 4s - loss: 5.7920 - val_loss: 1.3510
Epoch 10/50
 - 4s - loss: 4.6757 - val_loss: 1.1724
Epoch 11/50
 - 5s - loss: 4.9434 - val_loss: 1.3704
Epoch 12/50
 - 4s - loss: 5.9441 - val_loss: 1.4043
Epoch 13/50
 - 5s - loss: 6.1728 - val_loss: 1.5691
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 35700	action = 0	current_phase = 0	next_phase = 1	reward = 1.004520	array([[ 3.6975107, -9.186436 ]], dtype=float32)
time = 35705	action = 0	current_phase = 0	next_phase = 1	reward = 0.719590	array([[ 3.6440487, -9.082601 ]], dtype=float32)
time = 35710	action = 0	current_phase = 0	next_phase = 1	reward = 0.725175	array([[ 3.704444, -9.175041]], dtype=float32)
time = 35715	action = 0	current_phase = 0	next_phase = 1	reward = 0.450792	array([[ 3.6739492, -9.086923 ]], dtype=float32)
time = 35720	action = 0	current_phase = 0	next_phase = 1	reward = 1.006924	array([[ 3.6194525, -9.068041 ]], dtype=float32)
time = 35725	action = 0	current_phase = 0	next_phase = 1	reward = 0.447702	array([[ 3.6714878, -9.123444 ]], dtype=float32)
time = 35730	action = 0	current_phase = 0	next_phase = 1	reward = 1.000778	array([[ 3.6610403, -9.062711 ]], dtype=float32)
time = 35735	action = 0	current_phase = 0	next_phase = 1	reward = 0.719529	array([[ 3.65176, -9.19847]], dtype=float32)
time = 35740	action = 0	current_phase = 0	next_phase = 1	reward = 0.728745	array([[ 3.6626759, -9.066924 ]], dtype=float32)
time = 35745	action = 0	current_phase = 0	next_phase = 1	reward = 0.450722	array([[ 3.6777763, -9.07757  ]], dtype=float32)
time = 35750	action = 0	current_phase = 0	next_phase = 1	reward = 1.005508	array([[ 3.6777544, -9.092396 ]], dtype=float32)
time = 35755	action = 0	current_phase = 0	next_phase = 1	reward = 0.720452	array([[ 3.6697912, -9.089447 ]], dtype=float32)
time = 35760	action = 0	current_phase = 0	next_phase = 1	reward = 0.711103	array([[ 3.6720839, -9.15168  ]], dtype=float32)
time = 35765	action = 0	current_phase = 0	next_phase = 1	reward = 0.444061	array([[ 3.6697035, -9.106238 ]], dtype=float32)
time = 35770	action = 0	current_phase = 0	next_phase = 1	reward = 1.010465	array([[ 3.6263905, -9.144752 ]], dtype=float32)
time = 35775	action = 0	current_phase = 0	next_phase = 1	reward = 0.725690	array([[ 3.6804676, -9.093477 ]], dtype=float32)
time = 35780	action = 0	current_phase = 0	next_phase = 1	reward = 0.720101	array([[ 3.6712847, -9.037177 ]], dtype=float32)
time = 35785	action = 0	current_phase = 0	next_phase = 1	reward = 0.722485	array([[ 3.6557665, -9.067722 ]], dtype=float32)
time = 35790	action = 0	current_phase = 0	next_phase = 1	reward = 0.440049	array([[ 3.6664648, -9.11992  ]], dtype=float32)
time = 35795	action = 0	current_phase = 0	next_phase = 1	reward = 1.005898	array([[ 3.6813183, -9.2446995]], dtype=float32)
time = 35800	action = 0	current_phase = 0	next_phase = 1	reward = 0.721687	array([[ 3.6709948, -9.0490055]], dtype=float32)
time = 35805	action = 0	current_phase = 0	next_phase = 1	reward = 0.451485	array([[ 3.677187, -9.072557]], dtype=float32)
time = 35810	action = 0	current_phase = 0	next_phase = 1	reward = 0.731166	array([[ 3.670887, -9.286631]], dtype=float32)
time = 35815	action = 0	current_phase = 0	next_phase = 1	reward = 1.004732	array([[ 3.6543322, -9.122429 ]], dtype=float32)
time = 35820	action = 0	current_phase = 0	next_phase = 1	reward = 0.722698	array([[ 3.6737852, -9.079346 ]], dtype=float32)
time = 35825	action = 0	current_phase = 0	next_phase = 1	reward = 0.722808	array([[ 3.6820345, -9.073713 ]], dtype=float32)
time = 35830	action = 0	current_phase = 0	next_phase = 1	reward = 0.724210	array([[ 3.6795464, -9.112191 ]], dtype=float32)
time = 35835	action = 0	current_phase = 0	next_phase = 1	reward = 0.718015	array([[ 3.6764908, -9.071953 ]], dtype=float32)
time = 35840	action = 0	current_phase = 0	next_phase = 1	reward = 0.713043	array([[ 3.6712198, -9.111273 ]], dtype=float32)
time = 35845	action = 0	current_phase = 0	next_phase = 1	reward = 0.445583	array([[ 3.6207771, -9.055204 ]], dtype=float32)
time = 35850	action = 0	current_phase = 0	next_phase = 1	reward = 1.009624	array([[ 3.6524925, -9.114163 ]], dtype=float32)
time = 35855	action = 0	current_phase = 0	next_phase = 1	reward = 0.719323	array([[ 3.6869354, -9.130871 ]], dtype=float32)
time = 35860	action = 0	current_phase = 0	next_phase = 1	reward = 0.715240	array([[ 3.682743, -9.141977]], dtype=float32)
time = 35865	action = 0	current_phase = 0	next_phase = 1	reward = 0.719581	array([[ 3.669238, -9.057587]], dtype=float32)
time = 35870	action = 0	current_phase = 0	next_phase = 1	reward = 0.447456	array([[ 3.6378164, -9.080813 ]], dtype=float32)
time = 35875	action = 0	current_phase = 0	next_phase = 1	reward = 0.731446	array([[ 3.6838093, -9.198618 ]], dtype=float32)
time = 35880	action = 0	current_phase = 0	next_phase = 1	reward = 0.990881	array([[ 3.6486206, -9.264992 ]], dtype=float32)
time = 35885	action = 0	current_phase = 0	next_phase = 1	reward = 0.439856	array([[ 3.675311, -9.118372]], dtype=float32)
time = 35890	action = 0	current_phase = 0	next_phase = 1	reward = 0.725726	array([[ 3.6045885, -9.117357 ]], dtype=float32)
time = 35895	action = 0	current_phase = 0	next_phase = 1	reward = 1.014955	array([[ 3.6714296, -9.210329 ]], dtype=float32)
time = 35900	action = 0	current_phase = 0	next_phase = 1	reward = 0.718258	array([[ 3.6569805, -9.139345 ]], dtype=float32)
time = 35905	action = 0	current_phase = 0	next_phase = 1	reward = 0.431468	array([[ 3.6554756, -9.141627 ]], dtype=float32)
time = 35910	action = 0	current_phase = 0	next_phase = 1	reward = 0.724490	array([[ 3.6925182, -9.136077 ]], dtype=float32)
time = 35915	action = 0	current_phase = 0	next_phase = 1	reward = 0.732643	array([[ 3.6675415, -9.116852 ]], dtype=float32)
time = 35920	action = 0	current_phase = 0	next_phase = 1	reward = 1.000962	array([[ 3.6693058, -9.134493 ]], dtype=float32)
time = 35925	action = 0	current_phase = 0	next_phase = 1	reward = 0.723423	array([[ 3.6845427, -9.114414 ]], dtype=float32)
time = 35930	action = 0	current_phase = 0	next_phase = 1	reward = 0.716815	array([[ 3.6689262, -9.128159 ]], dtype=float32)
time = 35935	action = 0	current_phase = 0	next_phase = 1	reward = 0.451619	array([[ 3.6630507, -9.115767 ]], dtype=float32)
time = 35940	action = 0	current_phase = 0	next_phase = 1	reward = 1.014637	array([[ 3.6853142, -9.100516 ]], dtype=float32)
time = 35945	action = 0	current_phase = 0	next_phase = 1	reward = 0.731372	array([[ 3.670989, -9.126585]], dtype=float32)
time = 35950	action = 0	current_phase = 0	next_phase = 1	reward = 0.713193	array([[ 3.6475258, -9.15758  ]], dtype=float32)
time = 35955	action = 0	current_phase = 0	next_phase = 1	reward = 0.715199	array([[ 3.6823215, -9.167259 ]], dtype=float32)
time = 35960	action = 0	current_phase = 0	next_phase = 1	reward = 0.714214	array([[ 3.665493, -9.091068]], dtype=float32)
time = 35965	action = 0	current_phase = 0	next_phase = 1	reward = 0.443217	array([[ 3.669548, -9.098052]], dtype=float32)
time = 35970	action = 0	current_phase = 0	next_phase = 1	reward = 1.000945	array([[ 3.6730576, -9.100391 ]], dtype=float32)
time = 35975	action = 0	current_phase = 0	next_phase = 1	reward = 0.720655	array([[ 3.5952358, -9.102584 ]], dtype=float32)
time = 35980	action = 0	current_phase = 0	next_phase = 1	reward = 0.164769	array([[ 3.6641722, -9.110832 ]], dtype=float32)
time = 35985	action = 0	current_phase = 0	next_phase = 1	reward = 1.008736	array([[ 3.6627007, -9.147381 ]], dtype=float32)
time = 35990	action = 0	current_phase = 0	next_phase = 1	reward = 1.001185	array([[ 3.6748886, -9.138195 ]], dtype=float32)
time = 35995	action = 0	current_phase = 0	next_phase = 1	reward = 0.722007	array([[ 3.6571407, -9.090429 ]], dtype=float32)
Train on 833 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 5.9088 - val_loss: 2.0741
Epoch 2/50
 - 4s - loss: 6.4177 - val_loss: 1.5757
Epoch 3/50
 - 4s - loss: 8.2090 - val_loss: 2.2976
Epoch 4/50
 - 4s - loss: 4.6682 - val_loss: 2.0659
Epoch 5/50
 - 4s - loss: 4.8982 - val_loss: 1.8076
Epoch 6/50
 - 4s - loss: 5.4070 - val_loss: 1.9130
Epoch 7/50
 - 4s - loss: 4.6674 - val_loss: 1.8740
Epoch 8/50
 - 4s - loss: 5.9284 - val_loss: 2.0010
Epoch 9/50
 - 4s - loss: 4.5399 - val_loss: 1.7745
Epoch 10/50
 - 5s - loss: 5.5495 - val_loss: 1.9197
Epoch 11/50
 - 4s - loss: 5.2412 - val_loss: 2.0113
Epoch 12/50
 - 4s - loss: 6.9558 - val_loss: 3.2832
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 303, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 291, after forget
time = 36000	action = 0	current_phase = 0	next_phase = 1	reward = 0.232330	array([[ 3.6543026, -9.106301 ]], dtype=float32)
time = 36005	action = 0	current_phase = 0	next_phase = 1	reward = -0.334898	array([[ 3.613926, -8.974766]], dtype=float32)
time = 36010	action = 0	current_phase = 0	next_phase = 1	reward = 0.371604	array([[ 3.488945, -9.128372]], dtype=float32)
time = 36015	action = 0	current_phase = 0	next_phase = 1	reward = 1.072027	array([[ 3.5647488, -9.014938 ]], dtype=float32)
time = 36020	action = 0	current_phase = 0	next_phase = 1	reward = 0.122605	array([[ 3.6180744, -9.006094 ]], dtype=float32)
time = 36025	action = 0	current_phase = 0	next_phase = 1	reward = -0.947825	array([[ 3.6052046, -9.020226 ]], dtype=float32)
time = 36030	action = 0	current_phase = 0	next_phase = 1	reward = -2.176157	array([[ 3.5465336, -8.9894   ]], dtype=float32)
time = 36035	action = 0	current_phase = 0	next_phase = 1	reward = -3.470436	array([[ 3.5630188, -8.995928 ]], dtype=float32)
time = 36040	action = 0	current_phase = 0	next_phase = 1	reward = -4.776192	array([[ 3.6161718, -9.067245 ]], dtype=float32)
time = 36045	action = 0	current_phase = 0	next_phase = 1	reward = -6.263578	array([[ 3.6143837, -9.025122 ]], dtype=float32)
time = 36050	action = 0	current_phase = 0	next_phase = 1	reward = -7.784212	array([[ 3.2306318, -9.511499 ]], dtype=float32)
time = 36055	action = 0	current_phase = 0	next_phase = 1	reward = -9.173356	array([[ 3.5005894, -9.223948 ]], dtype=float32)
time = 36060	action = 0	current_phase = 0	next_phase = 1	reward = -10.897442	array([[ 3.4835854, -9.325963 ]], dtype=float32)
time = 36065	action = 0	current_phase = 0	next_phase = 1	reward = -12.766752	array([[ 2.8437643, -9.866655 ]], dtype=float32)
time = 36070	action = 0	current_phase = 0	next_phase = 1	reward = -14.665242	array([[ -5.727395, -15.184057]], dtype=float32)
time = 36075	action = 0	current_phase = 0	next_phase = 1	reward = -16.663305	array([[  0.91041756, -11.439052  ]], dtype=float32)
time = 36080	action = 0	current_phase = 0	next_phase = 1	reward = -18.690769	array([[ -6.9490204, -15.888279 ]], dtype=float32)
time = 36085	action = 0	current_phase = 0	next_phase = 1	reward = -20.597007	array([[ -2.7941928, -15.044888 ]], dtype=float32)
time = 36090	action = 0	current_phase = 0	next_phase = 1	reward = -22.998665	array([[ -4.857642, -15.306486]], dtype=float32)
time = 36095	action = 0	current_phase = 0	next_phase = 1	reward = -25.288976	array([[ -1.5573354, -14.369783 ]], dtype=float32)
time = 36100	action = 0	current_phase = 0	next_phase = 1	reward = -27.450493	array([[ -2.95619 , -15.851149]], dtype=float32)
time = 36105	action = 0	current_phase = 0	next_phase = 1	reward = -29.900215	array([[ -5.4558134, -16.896347 ]], dtype=float32)
time = 36110	action = 1	current_phase = 0	next_phase = 1	reward = -43.324547	array([[-12.979986, -12.28262 ]], dtype=float32)
time = 36118	action = 1	current_phase = 1	next_phase = 0	reward = -32.197622	array([[-55.777225 ,  -2.5256202]], dtype=float32)
time = 36126	action = 0	current_phase = 0	next_phase = 1	reward = -16.039223	array([[ -3.5120306, -17.15106  ]], dtype=float32)
time = 36131	action = 1	current_phase = 0	next_phase = 1	reward = -18.502071	array([[-14.379267, -11.065668]], dtype=float32)
time = 36139	action = 1	current_phase = 1	next_phase = 0	reward = -17.057672	array([[-48.19175 ,  -3.462966]], dtype=float32)
time = 36147	action = 0	current_phase = 0	next_phase = 1	reward = -13.245911	array([[-10.075429, -13.376497]], dtype=float32)
time = 36152	action = 0	current_phase = 0	next_phase = 1	reward = -16.926299	array([[ -4.0478244, -16.344835 ]], dtype=float32)
time = 36157	action = 0	current_phase = 0	next_phase = 1	reward = -20.135212	array([[ -2.8749943, -18.070648 ]], dtype=float32)
time = 36162	action = 0	current_phase = 0	next_phase = 1	reward = -21.927934	array([[ -3.1495676, -18.827177 ]], dtype=float32)
time = 36167	action = 0	current_phase = 0	next_phase = 1	reward = -25.789165	array([[-10.8302765, -13.811272 ]], dtype=float32)
time = 36172	action = 0	current_phase = 0	next_phase = 1	reward = -30.905300	array([[ -6.695902, -13.990328]], dtype=float32)
time = 36177	action = 0	current_phase = 0	next_phase = 1	reward = -37.093985	array([[ -2.5129042, -19.761967 ]], dtype=float32)
time = 36182	action = 0	current_phase = 0	next_phase = 1	reward = -42.215262	array([[ -1.8506055, -21.152271 ]], dtype=float32)
time = 36187	action = 0	current_phase = 0	next_phase = 1	reward = -46.030258	array([[ -1.1013894, -22.669895 ]], dtype=float32)
time = 36192	action = 0	current_phase = 0	next_phase = 1	reward = -49.683872	array([[ -1.7243361, -21.474594 ]], dtype=float32)
time = 36197	action = 0	current_phase = 0	next_phase = 1	reward = -53.415010	array([[ -1.5911021, -21.657818 ]], dtype=float32)
time = 36202	action = 0	current_phase = 0	next_phase = 1	reward = -57.340134	array([[ -2.1536536, -20.051311 ]], dtype=float32)
time = 36207	action = 0	current_phase = 0	next_phase = 1	reward = -61.410349	array([[ -5.5298276, -17.3106   ]], dtype=float32)
time = 36212	action = 0	current_phase = 0	next_phase = 1	reward = -65.257359	array([[ -3.029655, -19.613281]], dtype=float32)
time = 36217	action = 0	current_phase = 0	next_phase = 1	reward = -69.548127	array([[ -3.4847722, -17.564919 ]], dtype=float32)
time = 36222	action = 0	current_phase = 0	next_phase = 1	reward = -73.932276	array([[ -2.367413, -19.237913]], dtype=float32)
time = 36227	action = 0	current_phase = 0	next_phase = 1	reward = -78.211518	array([[ -2.199685, -20.512535]], dtype=float32)
time = 36232	action = 0	current_phase = 0	next_phase = 1	reward = -82.569699	array([[ -1.0480256, -20.007828 ]], dtype=float32)
time = 36237	action = 0	current_phase = 0	next_phase = 1	reward = -87.171583	array([[ -0.10595989, -26.04961   ]], dtype=float32)
time = 36242	action = 0	current_phase = 0	next_phase = 1	reward = -91.603171	array([[ -0.36841726, -25.210733  ]], dtype=float32)
time = 36247	action = 0	current_phase = 0	next_phase = 1	reward = -96.428554	array([[ -1.3839045, -25.728102 ]], dtype=float32)
time = 36252	action = 0	current_phase = 0	next_phase = 1	reward = -101.190876	array([[ -0.15282393, -24.915844  ]], dtype=float32)
time = 36257	action = 0	current_phase = 0	next_phase = 1	reward = -106.155170	array([[  0.3530388, -26.154516 ]], dtype=float32)
time = 36262	action = 0	current_phase = 0	next_phase = 1	reward = -111.154981	array([[  0.41904163, -24.567535  ]], dtype=float32)
time = 36267	action = 0	current_phase = 0	next_phase = 1	reward = -116.196692	array([[  0.7447128, -26.329287 ]], dtype=float32)
time = 36272	action = 0	current_phase = 0	next_phase = 1	reward = -121.324455	array([[  0.6102514, -27.40362  ]], dtype=float32)
time = 36277	action = 0	current_phase = 0	next_phase = 1	reward = -126.382408	array([[  0.31844425, -27.819904  ]], dtype=float32)
time = 36282	action = 0	current_phase = 0	next_phase = 1	reward = -131.887713	array([[  1.5421591, -26.10485  ]], dtype=float32)
time = 36287	action = 0	current_phase = 0	next_phase = 1	reward = -137.279872	array([[  0.45094776, -29.130043  ]], dtype=float32)
time = 36292	action = 0	current_phase = 0	next_phase = 1	reward = -142.819906	array([[  1.7643108, -25.594816 ]], dtype=float32)
time = 36297	action = 0	current_phase = 0	next_phase = 1	reward = -148.390248	array([[  1.6222696, -25.070791 ]], dtype=float32)
Train on 835 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 18.6644 - val_loss: 38.0644
Epoch 2/50
 - 4s - loss: 14.5308 - val_loss: 33.5996
Epoch 3/50
 - 4s - loss: 16.5284 - val_loss: 26.8236
Epoch 4/50
 - 4s - loss: 13.1206 - val_loss: 25.8879
Epoch 5/50
 - 4s - loss: 10.1660 - val_loss: 26.1358
Epoch 6/50
 - 4s - loss: 16.6426 - val_loss: 26.9899
Epoch 7/50
 - 4s - loss: 13.4019 - val_loss: 26.3075
Epoch 8/50
 - 4s - loss: 10.8633 - val_loss: 27.4249
Epoch 9/50
 - 4s - loss: 12.4137 - val_loss: 27.7253
Epoch 10/50
 - 4s - loss: 11.1433 - val_loss: 27.5304
Epoch 11/50
 - 4s - loss: 8.9626 - val_loss: 28.1073
Epoch 12/50
 - 4s - loss: 11.6725 - val_loss: 27.0675
Epoch 13/50
 - 4s - loss: 12.1682 - val_loss: 27.1726
Epoch 14/50
 - 4s - loss: 10.7265 - val_loss: 28.3544
length of memory (state 0, action 0): 1054, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 305, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 293, after forget
time = 36302	action = 0	current_phase = 0	next_phase = 1	reward = -154.052808	array([[-29.523457, -56.974823]], dtype=float32)
time = 36307	action = 0	current_phase = 0	next_phase = 1	reward = -159.852793	array([[-29.565205, -56.735855]], dtype=float32)
time = 36312	action = 0	current_phase = 0	next_phase = 1	reward = -165.852818	array([[-29.465923, -57.307587]], dtype=float32)
time = 36317	action = 0	current_phase = 0	next_phase = 1	reward = -171.844888	array([[-29.576996, -56.6692  ]], dtype=float32)
time = 36322	action = 0	current_phase = 0	next_phase = 1	reward = -177.823811	array([[-29.59013, -56.5945 ]], dtype=float32)
time = 36327	action = 0	current_phase = 0	next_phase = 1	reward = -184.044712	array([[-29.60176 , -56.528538]], dtype=float32)
time = 36332	action = 0	current_phase = 0	next_phase = 1	reward = -190.308016	array([[-29.653194, -56.238537]], dtype=float32)
time = 36337	action = 0	current_phase = 0	next_phase = 1	reward = -196.667230	array([[-29.703197, -55.959457]], dtype=float32)
time = 36342	action = 0	current_phase = 0	next_phase = 1	reward = -203.218850	array([[-29.729465, -55.813976]], dtype=float32)
time = 36347	action = 0	current_phase = 0	next_phase = 1	reward = -209.714644	array([[-29.75813 , -55.656155]], dtype=float32)
time = 36352	action = 0	current_phase = 0	next_phase = 1	reward = -216.401128	array([[-29.763542, -55.626465]], dtype=float32)
time = 36357	action = 0	current_phase = 0	next_phase = 1	reward = -223.183436	array([[-29.759838, -55.646767]], dtype=float32)
time = 36362	action = 0	current_phase = 0	next_phase = 1	reward = -229.960221	array([[-29.767353, -55.605556]], dtype=float32)
time = 36367	action = 0	current_phase = 0	next_phase = 1	reward = -236.145833	array([[-29.771263, -55.584156]], dtype=float32)
time = 36372	action = 0	current_phase = 0	next_phase = 1	reward = -241.937500	array([[-29.772614, -55.57677 ]], dtype=float32)
time = 36377	action = 0	current_phase = 0	next_phase = 1	reward = -247.729167	array([[-29.773472, -55.57209 ]], dtype=float32)
time = 36382	action = 0	current_phase = 0	next_phase = 1	reward = -253.520833	array([[-29.774014, -55.56912 ]], dtype=float32)
time = 36387	action = 0	current_phase = 0	next_phase = 1	reward = -259.312500	array([[-29.774357, -55.567238]], dtype=float32)
time = 36392	action = 0	current_phase = 0	next_phase = 1	reward = -265.104167	array([[-29.774574, -55.566048]], dtype=float32)
time = 36397	action = 0	current_phase = 0	next_phase = 1	reward = -270.895833	array([[-29.774712, -55.56529 ]], dtype=float32)
time = 36402	action = 0	current_phase = 0	next_phase = 1	reward = -276.687500	array([[-29.774803, -55.564816]], dtype=float32)
time = 36407	action = 0	current_phase = 0	next_phase = 1	reward = -282.479167	array([[-29.774853, -55.564507]], dtype=float32)
time = 36412	action = 0	current_phase = 0	next_phase = 1	reward = -288.270833	array([[-29.77489, -55.56432]], dtype=float32)
time = 36417	action = 0	current_phase = 0	next_phase = 1	reward = -294.062500	array([[-29.77491 , -55.564213]], dtype=float32)
time = 36422	action = 0	current_phase = 0	next_phase = 1	reward = -299.854167	array([[-29.774925, -55.56415 ]], dtype=float32)
time = 36427	action = 0	current_phase = 0	next_phase = 1	reward = -305.645833	array([[-29.774925, -55.56416 ]], dtype=float32)
time = 36432	action = 0	current_phase = 0	next_phase = 1	reward = -311.437500	array([[-29.774921, -55.56426 ]], dtype=float32)
time = 36437	action = 0	current_phase = 0	next_phase = 1	reward = -317.229167	array([[-29.774902, -55.564537]], dtype=float32)
time = 36442	action = 0	current_phase = 0	next_phase = 1	reward = -323.020833	array([[-29.774853, -55.565224]], dtype=float32)
time = 36447	action = 0	current_phase = 0	next_phase = 1	reward = -328.812500	array([[-29.77472, -55.56687]], dtype=float32)
time = 36452	action = 0	current_phase = 0	next_phase = 1	reward = -334.604167	array([[-29.77441 , -55.570755]], dtype=float32)
time = 36457	action = 0	current_phase = 0	next_phase = 1	reward = -340.395833	array([[-29.773682, -55.579887]], dtype=float32)
time = 36462	action = 0	current_phase = 0	next_phase = 1	reward = -346.187500	array([[-29.771957, -55.60134 ]], dtype=float32)
time = 36467	action = 0	current_phase = 0	next_phase = 1	reward = -351.979167	array([[-29.767887, -55.651608]], dtype=float32)
time = 36472	action = 0	current_phase = 0	next_phase = 1	reward = -357.770833	array([[-29.758167, -55.769028]], dtype=float32)
time = 36477	action = 0	current_phase = 0	next_phase = 1	reward = -363.562500	array([[-29.734531, -56.040867]], dtype=float32)
time = 36482	action = 0	current_phase = 0	next_phase = 1	reward = -369.354167	array([[-29.675201, -56.65684 ]], dtype=float32)
time = 36487	action = 0	current_phase = 0	next_phase = 1	reward = -375.145833	array([[-29.521088, -57.97894 ]], dtype=float32)
time = 36492	action = 0	current_phase = 0	next_phase = 1	reward = -380.937500	array([[-29.131638, -60.469395]], dtype=float32)
time = 36497	action = 0	current_phase = 0	next_phase = 1	reward = -386.729167	array([[-28.324379, -64.08643 ]], dtype=float32)
time = 36502	action = 0	current_phase = 0	next_phase = 1	reward = -392.520833	array([[-27.175251, -67.69883 ]], dtype=float32)
time = 36507	action = 0	current_phase = 0	next_phase = 1	reward = -398.312500	array([[-26.101185, -70.215065]], dtype=float32)
time = 36512	action = 0	current_phase = 0	next_phase = 1	reward = -404.104167	array([[-25.398106, -71.588776]], dtype=float32)
time = 36517	action = 0	current_phase = 0	next_phase = 1	reward = -409.895833	array([[-25.031418, -72.24546 ]], dtype=float32)
time = 36522	action = 0	current_phase = 0	next_phase = 1	reward = -415.687500	array([[-24.860146, -72.54125 ]], dtype=float32)
time = 36527	action = 0	current_phase = 0	next_phase = 1	reward = -421.479167	array([[-24.782845, -72.67364 ]], dtype=float32)
time = 36532	action = 0	current_phase = 0	next_phase = 1	reward = -427.270833	array([[-24.746216, -72.737946]], dtype=float32)
time = 36537	action = 0	current_phase = 0	next_phase = 1	reward = -433.062500	array([[-24.724167, -72.7802  ]], dtype=float32)
time = 36542	action = 0	current_phase = 0	next_phase = 1	reward = -438.854167	array([[-24.702164, -72.82744 ]], dtype=float32)
time = 36547	action = 0	current_phase = 0	next_phase = 1	reward = -444.645833	array([[-24.667873, -72.90524 ]], dtype=float32)
time = 36552	action = 0	current_phase = 0	next_phase = 1	reward = -450.437500	array([[-24.604084, -73.05169 ]], dtype=float32)
time = 36557	action = 0	current_phase = 0	next_phase = 1	reward = -456.229167	array([[-24.480091, -73.33493 ]], dtype=float32)
time = 36562	action = 0	current_phase = 0	next_phase = 1	reward = -462.020833	array([[-24.238014, -73.87942 ]], dtype=float32)
time = 36567	action = 0	current_phase = 0	next_phase = 1	reward = -467.812500	array([[-23.77045, -74.90005]], dtype=float32)
time = 36572	action = 0	current_phase = 0	next_phase = 1	reward = -473.604167	array([[-22.893963, -76.71825 ]], dtype=float32)
time = 36577	action = 0	current_phase = 0	next_phase = 1	reward = -479.395833	array([[-21.366247, -79.66328 ]], dtype=float32)
time = 36582	action = 0	current_phase = 0	next_phase = 1	reward = -485.187500	array([[-19.089252, -83.72493 ]], dtype=float32)
time = 36587	action = 0	current_phase = 0	next_phase = 1	reward = -490.979167	array([[-16.394619, -88.23889 ]], dtype=float32)
time = 36592	action = 0	current_phase = 0	next_phase = 1	reward = -496.770833	array([[-13.738363, -92.34943 ]], dtype=float32)
time = 36597	action = 0	current_phase = 0	next_phase = 1	reward = -502.562500	array([[-11.533816, -95.501236]], dtype=float32)
Train on 835 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 500.3487 - val_loss: 862.8727
Epoch 2/50
 - 4s - loss: 494.9197 - val_loss: 857.7727
Epoch 3/50
 - 4s - loss: 492.9034 - val_loss: 854.4786
Epoch 4/50
 - 4s - loss: 488.2388 - val_loss: 849.3007
Epoch 5/50
 - 4s - loss: 484.8891 - val_loss: 844.4079
Epoch 6/50
 - 4s - loss: 483.7908 - val_loss: 844.8712
Epoch 7/50
 - 4s - loss: 480.9691 - val_loss: 836.8035
Epoch 8/50
 - 4s - loss: 478.4397 - val_loss: 833.4794
Epoch 9/50
 - 4s - loss: 475.2480 - val_loss: 830.5321
Epoch 10/50
 - 4s - loss: 473.6915 - val_loss: 826.7862
Epoch 11/50
 - 4s - loss: 472.4260 - val_loss: 823.5594
Epoch 12/50
 - 4s - loss: 470.6946 - val_loss: 816.3640
Epoch 13/50
 - 4s - loss: 467.0922 - val_loss: 814.8585
Epoch 14/50
 - 4s - loss: 465.9662 - val_loss: 807.9813
Epoch 15/50
 - 4s - loss: 467.7644 - val_loss: 807.5850
Epoch 16/50
 - 4s - loss: 462.1793 - val_loss: 803.5243
Epoch 17/50
 - 4s - loss: 457.8543 - val_loss: 799.7215
Epoch 18/50
 - 4s - loss: 458.2248 - val_loss: 797.0344
Epoch 19/50
 - 4s - loss: 454.8144 - val_loss: 792.5413
Epoch 20/50
 - 4s - loss: 453.7038 - val_loss: 790.2275
Epoch 21/50
 - 4s - loss: 457.0129 - val_loss: 787.7933
Epoch 22/50
 - 4s - loss: 451.1345 - val_loss: 785.9558
Epoch 23/50
 - 4s - loss: 454.1439 - val_loss: 782.3596
Epoch 24/50
 - 4s - loss: 447.8001 - val_loss: 781.1025
Epoch 25/50
 - 4s - loss: 447.4576 - val_loss: 778.8377
Epoch 26/50
 - 4s - loss: 445.6657 - val_loss: 775.6602
Epoch 27/50
 - 4s - loss: 444.6700 - val_loss: 775.7822
Epoch 28/50
 - 4s - loss: 444.7876 - val_loss: 772.0715
Epoch 29/50
 - 4s - loss: 444.1008 - val_loss: 770.0391
Epoch 30/50
 - 4s - loss: 444.6322 - val_loss: 768.6157
Epoch 31/50
 - 4s - loss: 439.3987 - val_loss: 767.1109
Epoch 32/50
 - 4s - loss: 438.4313 - val_loss: 765.0223
Epoch 33/50
 - 4s - loss: 438.9146 - val_loss: 763.0614
Epoch 34/50
 - 5s - loss: 435.8285 - val_loss: 761.9656
Epoch 35/50
 - 4s - loss: 436.4844 - val_loss: 761.1763
Epoch 36/50
 - 4s - loss: 434.8347 - val_loss: 760.5765
Epoch 37/50
 - 5s - loss: 434.0402 - val_loss: 755.5496
Epoch 38/50
 - 4s - loss: 434.3925 - val_loss: 755.2368
Epoch 39/50
 - 5s - loss: 432.2979 - val_loss: 753.9323
Epoch 40/50
 - 5s - loss: 432.5342 - val_loss: 751.2484
Epoch 41/50
 - 4s - loss: 430.9888 - val_loss: 749.1921
Epoch 42/50
 - 4s - loss: 430.1625 - val_loss: 747.4114
Epoch 43/50
 - 4s - loss: 428.2504 - val_loss: 744.9776
Epoch 44/50
 - 4s - loss: 427.8068 - val_loss: 744.3996
Epoch 45/50
 - 4s - loss: 427.0429 - val_loss: 743.6539
Epoch 46/50
 - 4s - loss: 425.9000 - val_loss: 741.8828
Epoch 47/50
 - 4s - loss: 426.5978 - val_loss: 738.9763
Epoch 48/50
 - 4s - loss: 423.1095 - val_loss: 737.4564
Epoch 49/50
 - 5s - loss: 421.3146 - val_loss: 738.0591
Epoch 50/50
 - 4s - loss: 419.6197 - val_loss: 735.2220
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 305, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 293, after forget
time = 36602	action = 0	current_phase = 0	next_phase = 1	reward = -508.354167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36607	action = 0	current_phase = 0	next_phase = 1	reward = -514.145833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36612	action = 0	current_phase = 0	next_phase = 1	reward = -519.937500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36617	action = 0	current_phase = 0	next_phase = 1	reward = -525.729167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36622	action = 0	current_phase = 0	next_phase = 1	reward = -531.520833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36627	action = 0	current_phase = 0	next_phase = 1	reward = -537.312500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36632	action = 0	current_phase = 0	next_phase = 1	reward = -543.104167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36637	action = 0	current_phase = 0	next_phase = 1	reward = -548.895833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36642	action = 0	current_phase = 0	next_phase = 1	reward = -554.687500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36647	action = 0	current_phase = 0	next_phase = 1	reward = -560.479167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36652	action = 0	current_phase = 0	next_phase = 1	reward = -566.270833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36657	action = 0	current_phase = 0	next_phase = 1	reward = -572.062500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36662	action = 0	current_phase = 0	next_phase = 1	reward = -577.854167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36667	action = 0	current_phase = 0	next_phase = 1	reward = -583.645833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36672	action = 0	current_phase = 0	next_phase = 1	reward = -589.437500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36677	action = 0	current_phase = 0	next_phase = 1	reward = -595.229167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36682	action = 0	current_phase = 0	next_phase = 1	reward = -601.020833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36687	action = 0	current_phase = 0	next_phase = 1	reward = -606.812500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36692	action = 0	current_phase = 0	next_phase = 1	reward = -612.604167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36697	action = 0	current_phase = 0	next_phase = 1	reward = -618.395833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36702	action = 0	current_phase = 0	next_phase = 1	reward = -624.187500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36707	action = 0	current_phase = 0	next_phase = 1	reward = -629.979167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36712	action = 0	current_phase = 0	next_phase = 1	reward = -635.770833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36717	action = 0	current_phase = 0	next_phase = 1	reward = -641.562500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36722	action = 0	current_phase = 0	next_phase = 1	reward = -647.354167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36727	action = 0	current_phase = 0	next_phase = 1	reward = -653.145833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36732	action = 0	current_phase = 0	next_phase = 1	reward = -658.937500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36737	action = 0	current_phase = 0	next_phase = 1	reward = -664.729167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36742	action = 0	current_phase = 0	next_phase = 1	reward = -670.520833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36747	action = 0	current_phase = 0	next_phase = 1	reward = -676.312500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36752	action = 0	current_phase = 0	next_phase = 1	reward = -682.104167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36757	action = 0	current_phase = 0	next_phase = 1	reward = -687.895833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36762	action = 0	current_phase = 0	next_phase = 1	reward = -693.687500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36767	action = 0	current_phase = 0	next_phase = 1	reward = -699.479167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36772	action = 0	current_phase = 0	next_phase = 1	reward = -705.270833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36777	action = 0	current_phase = 0	next_phase = 1	reward = -711.062500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36782	action = 0	current_phase = 0	next_phase = 1	reward = -716.854167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36787	action = 0	current_phase = 0	next_phase = 1	reward = -722.645833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36792	action = 0	current_phase = 0	next_phase = 1	reward = -728.437500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36797	action = 0	current_phase = 0	next_phase = 1	reward = -734.229167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36802	action = 0	current_phase = 0	next_phase = 1	reward = -740.020833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36807	action = 0	current_phase = 0	next_phase = 1	reward = -745.812500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36812	action = 0	current_phase = 0	next_phase = 1	reward = -751.604167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36817	action = 0	current_phase = 0	next_phase = 1	reward = -757.395833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36822	action = 0	current_phase = 0	next_phase = 1	reward = -763.187500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36827	action = 0	current_phase = 0	next_phase = 1	reward = -768.979167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36832	action = 0	current_phase = 0	next_phase = 1	reward = -774.770833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36837	action = 0	current_phase = 0	next_phase = 1	reward = -780.562500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36842	action = 0	current_phase = 0	next_phase = 1	reward = -786.354167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36847	action = 0	current_phase = 0	next_phase = 1	reward = -792.145833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36852	action = 0	current_phase = 0	next_phase = 1	reward = -797.937500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36857	action = 0	current_phase = 0	next_phase = 1	reward = -803.729167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36862	action = 0	current_phase = 0	next_phase = 1	reward = -809.520833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36867	action = 0	current_phase = 0	next_phase = 1	reward = -815.312500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36872	action = 0	current_phase = 0	next_phase = 1	reward = -821.104167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36877	action = 0	current_phase = 0	next_phase = 1	reward = -826.895833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36882	action = 0	current_phase = 0	next_phase = 1	reward = -832.687500	array([[-54.025146, -73.847435]], dtype=float32)
time = 36887	action = 0	current_phase = 0	next_phase = 1	reward = -838.479167	array([[-54.025146, -73.847435]], dtype=float32)
time = 36892	action = 0	current_phase = 0	next_phase = 1	reward = -844.270833	array([[-54.025146, -73.847435]], dtype=float32)
time = 36897	action = 0	current_phase = 0	next_phase = 1	reward = -850.062500	array([[-54.025146, -73.847435]], dtype=float32)
Train on 835 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 2964.5819 - val_loss: 5074.7641
Epoch 2/50
 - 4s - loss: 2959.0105 - val_loss: 5067.4271
Epoch 3/50
 - 4s - loss: 2948.2679 - val_loss: 5058.4893
Epoch 4/50
 - 4s - loss: 2942.8103 - val_loss: 5050.6047
Epoch 5/50
 - 5s - loss: 2939.2754 - val_loss: 5044.7073
Epoch 6/50
 - 4s - loss: 2935.3954 - val_loss: 5037.5469
Epoch 7/50
 - 4s - loss: 2931.2655 - val_loss: 5033.0343
Epoch 8/50
 - 4s - loss: 2927.1932 - val_loss: 5026.8945
Epoch 9/50
 - 5s - loss: 2925.4579 - val_loss: 5019.7782
Epoch 10/50
 - 4s - loss: 2921.2305 - val_loss: 5015.0908
Epoch 11/50
 - 5s - loss: 2915.0536 - val_loss: 5010.1014
Epoch 12/50
 - 4s - loss: 2912.1999 - val_loss: 5003.2276
Epoch 13/50
 - 4s - loss: 2909.9967 - val_loss: 5000.3172
Epoch 14/50
 - 4s - loss: 2905.4362 - val_loss: 4993.9139
Epoch 15/50
 - 4s - loss: 2901.8932 - val_loss: 4989.0053
Epoch 16/50
 - 5s - loss: 2901.1709 - val_loss: 4984.6878
Epoch 17/50
 - 5s - loss: 2897.8856 - val_loss: 4979.3416
Epoch 18/50
 - 5s - loss: 2892.3318 - val_loss: 4974.1324
Epoch 19/50
 - 4s - loss: 2889.3525 - val_loss: 4969.5949
Epoch 20/50
 - 5s - loss: 2889.0330 - val_loss: 4964.6732
Epoch 21/50
 - 4s - loss: 2884.3789 - val_loss: 4959.7365
Epoch 22/50
 - 4s - loss: 2879.9889 - val_loss: 4956.2023
Epoch 23/50
 - 4s - loss: 2878.0804 - val_loss: 4951.0063
Epoch 24/50
 - 4s - loss: 2873.6546 - val_loss: 4946.4243
Epoch 25/50
 - 4s - loss: 2872.5512 - val_loss: 4940.5120
Epoch 26/50
 - 4s - loss: 2874.5602 - val_loss: 4935.7565
Epoch 27/50
 - 4s - loss: 2864.3929 - val_loss: 4931.3752
Epoch 28/50
 - 4s - loss: 2860.4071 - val_loss: 4927.0699
Epoch 29/50
 - 4s - loss: 2858.5036 - val_loss: 4922.1631
Epoch 30/50
 - 4s - loss: 2855.2437 - val_loss: 4917.0117
Epoch 31/50
 - 5s - loss: 2851.3598 - val_loss: 4913.6132
Epoch 32/50
 - 4s - loss: 2850.0875 - val_loss: 4908.5773
Epoch 33/50
 - 4s - loss: 2846.0601 - val_loss: 4903.2477
Epoch 34/50
 - 4s - loss: 2844.6411 - val_loss: 4900.7251
Epoch 35/50
 - 4s - loss: 2839.3920 - val_loss: 4896.0324
Epoch 36/50
 - 4s - loss: 2835.8856 - val_loss: 4889.1483
Epoch 37/50
 - 4s - loss: 2835.3692 - val_loss: 4885.3780
Epoch 38/50
 - 4s - loss: 2830.4906 - val_loss: 4879.5636
Epoch 39/50
 - 4s - loss: 2830.5960 - val_loss: 4874.9623
Epoch 40/50
 - 4s - loss: 2827.0669 - val_loss: 4871.1942
Epoch 41/50
 - 4s - loss: 2821.2969 - val_loss: 4865.3263
Epoch 42/50
 - 4s - loss: 2819.8578 - val_loss: 4865.5529
Epoch 43/50
 - 4s - loss: 2816.7603 - val_loss: 4857.2762
Epoch 44/50
 - 4s - loss: 2811.3082 - val_loss: 4851.2795
Epoch 45/50
 - 4s - loss: 2809.0197 - val_loss: 4846.4873
Epoch 46/50
 - 4s - loss: 2806.3977 - val_loss: 4841.8644
Epoch 47/50
 - 4s - loss: 2801.3022 - val_loss: 4837.2996
Epoch 48/50
 - 4s - loss: 2799.5672 - val_loss: 4832.1285
Epoch 49/50
 - 4s - loss: 2797.7225 - val_loss: 4827.1988
Epoch 50/50
 - 5s - loss: 2795.4611 - val_loss: 4821.2490
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 305, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 293, after forget
time = 36902	action = 0	current_phase = 0	next_phase = 1	reward = -855.854167	array([[-69.63658, -75.01879]], dtype=float32)
time = 36907	action = 0	current_phase = 0	next_phase = 1	reward = -861.645833	array([[-69.63658, -75.01885]], dtype=float32)
time = 36912	action = 0	current_phase = 0	next_phase = 1	reward = -867.437500	array([[-69.63658, -75.01892]], dtype=float32)
time = 36917	action = 0	current_phase = 0	next_phase = 1	reward = -873.229167	array([[-69.63659, -75.019  ]], dtype=float32)
time = 36922	action = 0	current_phase = 0	next_phase = 1	reward = -879.020833	array([[-69.63659, -75.01908]], dtype=float32)
time = 36927	action = 0	current_phase = 0	next_phase = 1	reward = -884.812500	array([[-69.6366  , -75.019165]], dtype=float32)
time = 36932	action = 0	current_phase = 0	next_phase = 1	reward = -890.604167	array([[-69.6366  , -75.019264]], dtype=float32)
time = 36937	action = 0	current_phase = 0	next_phase = 1	reward = -896.395833	array([[-69.63661, -75.01937]], dtype=float32)
time = 36942	action = 0	current_phase = 0	next_phase = 1	reward = -902.187500	array([[-69.63661 , -75.019485]], dtype=float32)
time = 36947	action = 0	current_phase = 0	next_phase = 1	reward = -907.979167	array([[-69.63663, -75.01962]], dtype=float32)
time = 36952	action = 0	current_phase = 0	next_phase = 1	reward = -913.770833	array([[-69.63663, -75.01977]], dtype=float32)
time = 36957	action = 0	current_phase = 0	next_phase = 1	reward = -919.562500	array([[-69.636635, -75.01992 ]], dtype=float32)
time = 36962	action = 0	current_phase = 0	next_phase = 1	reward = -925.354167	array([[-69.63664, -75.02008]], dtype=float32)
time = 36967	action = 0	current_phase = 0	next_phase = 1	reward = -931.145833	array([[-69.63666, -75.02027]], dtype=float32)
time = 36972	action = 0	current_phase = 0	next_phase = 1	reward = -936.937500	array([[-69.636665, -75.02048 ]], dtype=float32)
time = 36977	action = 0	current_phase = 0	next_phase = 1	reward = -942.729167	array([[-69.63667, -75.0207 ]], dtype=float32)
time = 36982	action = 0	current_phase = 0	next_phase = 1	reward = -948.520833	array([[-69.63669, -75.02094]], dtype=float32)
time = 36987	action = 0	current_phase = 0	next_phase = 1	reward = -954.312500	array([[-69.636696, -75.02121 ]], dtype=float32)
time = 36992	action = 0	current_phase = 0	next_phase = 1	reward = -960.104167	array([[-69.63672, -75.0215 ]], dtype=float32)
time = 36997	action = 0	current_phase = 0	next_phase = 1	reward = -965.895833	array([[-69.636734, -75.02182 ]], dtype=float32)
time = 37002	action = 0	current_phase = 0	next_phase = 1	reward = -971.687500	array([[-69.63676, -75.02218]], dtype=float32)
time = 37007	action = 0	current_phase = 0	next_phase = 1	reward = -977.479167	array([[-69.63678, -75.02255]], dtype=float32)
time = 37012	action = 0	current_phase = 0	next_phase = 1	reward = -983.270833	array([[-69.636795, -75.02297 ]], dtype=float32)
time = 37017	action = 0	current_phase = 0	next_phase = 1	reward = -989.062500	array([[-69.63682, -75.02343]], dtype=float32)
time = 37022	action = 0	current_phase = 0	next_phase = 1	reward = -994.854167	array([[-69.63685 , -75.023926]], dtype=float32)
time = 37027	action = 0	current_phase = 0	next_phase = 1	reward = -1000.645833	array([[-69.63689, -75.02447]], dtype=float32)
time = 37032	action = 0	current_phase = 0	next_phase = 1	reward = -1006.437500	array([[-69.63692 , -75.025085]], dtype=float32)
time = 37037	action = 0	current_phase = 0	next_phase = 1	reward = -1012.229167	array([[-69.63695, -75.02574]], dtype=float32)
time = 37042	action = 0	current_phase = 0	next_phase = 1	reward = -1018.020833	array([[-69.63698, -75.02646]], dtype=float32)
time = 37047	action = 0	current_phase = 0	next_phase = 1	reward = -1023.812500	array([[-69.637024, -75.027245]], dtype=float32)
time = 37052	action = 0	current_phase = 0	next_phase = 1	reward = -1029.604167	array([[-69.63707, -75.02811]], dtype=float32)
time = 37057	action = 0	current_phase = 0	next_phase = 1	reward = -1035.395833	array([[-69.637115, -75.02905 ]], dtype=float32)
time = 37062	action = 0	current_phase = 0	next_phase = 1	reward = -1041.187500	array([[-69.63718, -75.03008]], dtype=float32)
time = 37067	action = 0	current_phase = 0	next_phase = 1	reward = -1046.979167	array([[-69.63724 , -75.031204]], dtype=float32)
time = 37072	action = 0	current_phase = 0	next_phase = 1	reward = -1052.770833	array([[-69.637314, -75.03244 ]], dtype=float32)
time = 37077	action = 0	current_phase = 0	next_phase = 1	reward = -1058.562500	array([[-69.637375, -75.0338  ]], dtype=float32)
time = 37082	action = 0	current_phase = 0	next_phase = 1	reward = -1064.354167	array([[-69.63745, -75.03528]], dtype=float32)
time = 37087	action = 0	current_phase = 0	next_phase = 1	reward = -1070.145833	array([[-69.63754, -75.03689]], dtype=float32)
time = 37092	action = 0	current_phase = 0	next_phase = 1	reward = -1075.937500	array([[-69.637634, -75.03866 ]], dtype=float32)
time = 37097	action = 0	current_phase = 0	next_phase = 1	reward = -1081.729167	array([[-69.63774, -75.04059]], dtype=float32)
time = 37102	action = 0	current_phase = 0	next_phase = 1	reward = -1087.520833	array([[-69.63785, -75.04271]], dtype=float32)
time = 37107	action = 0	current_phase = 0	next_phase = 1	reward = -1093.312500	array([[-69.63797, -75.04503]], dtype=float32)
time = 37112	action = 0	current_phase = 0	next_phase = 1	reward = -1099.104167	array([[-69.63811 , -75.047554]], dtype=float32)
time = 37117	action = 0	current_phase = 0	next_phase = 1	reward = -1104.895833	array([[-69.63826 , -75.050316]], dtype=float32)
time = 37122	action = 0	current_phase = 0	next_phase = 1	reward = -1110.687500	array([[-69.63841, -75.05334]], dtype=float32)
time = 37127	action = 0	current_phase = 0	next_phase = 1	reward = -1116.479167	array([[-69.63858, -75.05663]], dtype=float32)
time = 37132	action = 0	current_phase = 0	next_phase = 1	reward = -1122.270833	array([[-69.63878, -75.06024]], dtype=float32)
time = 37137	action = 0	current_phase = 0	next_phase = 1	reward = -1128.062500	array([[-69.63899, -75.06418]], dtype=float32)
time = 37142	action = 0	current_phase = 0	next_phase = 1	reward = -1133.854167	array([[-69.63921, -75.06848]], dtype=float32)
time = 37147	action = 0	current_phase = 0	next_phase = 1	reward = -1139.645833	array([[-69.639465, -75.07317 ]], dtype=float32)
time = 37152	action = 0	current_phase = 0	next_phase = 1	reward = -1145.437500	array([[-69.639725, -75.0783  ]], dtype=float32)
time = 37157	action = 0	current_phase = 0	next_phase = 1	reward = -1151.229167	array([[-69.64003, -75.08389]], dtype=float32)
time = 37162	action = 0	current_phase = 0	next_phase = 1	reward = -1157.020833	array([[-69.64034, -75.08999]], dtype=float32)
time = 37167	action = 0	current_phase = 0	next_phase = 1	reward = -1162.812500	array([[-69.6407 , -75.09664]], dtype=float32)
time = 37172	action = 0	current_phase = 0	next_phase = 1	reward = -1168.604167	array([[-69.64107, -75.1039 ]], dtype=float32)
time = 37177	action = 0	current_phase = 0	next_phase = 1	reward = -1174.395833	array([[-69.64148, -75.1118 ]], dtype=float32)
time = 37182	action = 0	current_phase = 0	next_phase = 1	reward = -1180.187500	array([[-69.64194, -75.12041]], dtype=float32)
time = 37187	action = 0	current_phase = 0	next_phase = 1	reward = -1185.979167	array([[-69.64241, -75.12978]], dtype=float32)
time = 37192	action = 0	current_phase = 0	next_phase = 1	reward = -1191.770833	array([[-69.642944, -75.13997 ]], dtype=float32)
time = 37197	action = 0	current_phase = 0	next_phase = 1	reward = -1197.562500	array([[-69.64351, -75.15106]], dtype=float32)
Train on 835 samples, validate on 358 samples
Epoch 1/50
 - 4s - loss: 4581.5754 - val_loss: 10943.4263
Epoch 2/50
 - 4s - loss: 4577.5002 - val_loss: 10932.9543
Epoch 3/50
 - 4s - loss: 4571.4754 - val_loss: 10923.0230
Epoch 4/50
 - 5s - loss: 4564.7441 - val_loss: 10913.6768
Epoch 5/50
 - 5s - loss: 4557.9413 - val_loss: 10902.7030
Epoch 6/50
 - 4s - loss: 4552.6825 - val_loss: 10893.0408
Epoch 7/50
 - 5s - loss: 4548.1089 - val_loss: 10883.2609
Epoch 8/50
 - 5s - loss: 4543.9642 - val_loss: 10873.4531
Epoch 9/50
 - 5s - loss: 4536.2723 - val_loss: 10863.6727
Epoch 10/50
 - 6s - loss: 4534.5724 - val_loss: 10854.6186
Epoch 11/50
 - 5s - loss: 4526.9333 - val_loss: 10844.9892
Epoch 12/50
 - 4s - loss: 4519.1807 - val_loss: 10835.6695
Epoch 13/50
 - 4s - loss: 4515.4260 - val_loss: 10827.4964
Epoch 14/50
 - 6s - loss: 4512.2104 - val_loss: 10819.2011
Epoch 15/50
 - 6s - loss: 4506.3565 - val_loss: 10806.9710
Epoch 16/50
 - 5s - loss: 4502.0563 - val_loss: 10797.2788
Epoch 17/50
 - 4s - loss: 4494.9512 - val_loss: 10788.7290
Epoch 18/50
 - 5s - loss: 4492.8149 - val_loss: 10779.9446
Epoch 19/50
 - 4s - loss: 4485.1700 - val_loss: 10771.7692
Epoch 20/50
 - 4s - loss: 4483.2684 - val_loss: 10761.3345
Epoch 21/50
 - 4s - loss: 4475.0357 - val_loss: 10751.9219
Epoch 22/50
 - 4s - loss: 4470.3885 - val_loss: 10742.7054
Epoch 23/50
 - 4s - loss: 4466.3454 - val_loss: 10733.4576
Epoch 24/50
 - 4s - loss: 4460.1159 - val_loss: 10725.4515
Epoch 25/50
 - 4s - loss: 4456.7920 - val_loss: 10715.3339
Epoch 26/50
 - 4s - loss: 4451.4226 - val_loss: 10706.9407
Epoch 27/50
 - 4s - loss: 4447.6270 - val_loss: 10698.7530
Epoch 28/50
 - 4s - loss: 4441.2602 - val_loss: 10688.4989
Epoch 29/50
 - 4s - loss: 4437.0842 - val_loss: 10679.0496
Epoch 30/50
 - 4s - loss: 4432.3169 - val_loss: 10670.6328
Epoch 31/50
 - 4s - loss: 4426.3063 - val_loss: 10662.0451
Epoch 32/50
 - 4s - loss: 4423.0489 - val_loss: 10652.8007
Epoch 33/50
 - 4s - loss: 4416.7216 - val_loss: 10643.1686
Epoch 34/50
 - 4s - loss: 4414.5647 - val_loss: 10634.7429
Epoch 35/50
 - 4s - loss: 4407.4483 - val_loss: 10625.0230
Epoch 36/50
 - 4s - loss: 4405.9546 - val_loss: 10615.6274
Epoch 37/50
 - 4s - loss: 4396.6006 - val_loss: 10607.2917
Epoch 38/50
 - 4s - loss: 4392.1813 - val_loss: 10598.5329
Epoch 39/50
 - 4s - loss: 4389.8838 - val_loss: 10592.9588
Epoch 40/50
 - 4s - loss: 4382.0707 - val_loss: 10579.7954
Epoch 41/50
 - 4s - loss: 4378.6429 - val_loss: 10571.8816
Epoch 42/50
 - 4s - loss: 4373.4663 - val_loss: 10561.7337
Epoch 43/50
 - 4s - loss: 4369.1968 - val_loss: 10553.3786
Epoch 44/50
 - 4s - loss: 4363.6459 - val_loss: 10544.3499
Epoch 45/50
 - 4s - loss: 4360.1356 - val_loss: 10534.2409
Epoch 46/50
 - 4s - loss: 4354.7606 - val_loss: 10525.3581
Epoch 47/50
 - 4s - loss: 4351.6387 - val_loss: 10517.5600
Epoch 48/50
 - 5s - loss: 4345.9850 - val_loss: 10508.2793
Epoch 49/50
 - 4s - loss: 4340.6490 - val_loss: 10500.8971
Epoch 50/50
 - 4s - loss: 4334.6128 - val_loss: 10489.2705
length of memory (state 0, action 0): 1060, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 305, after forget
length of memory (state 1, action 0): 490, after forget
length of memory (state 1, action 1): 293, after forget
time = 37202	action = 1	current_phase = 0	next_phase = 1	reward = -1839.578806	array([[-86.01853, -75.33607]], dtype=float32)
time = 37210	action = 0	current_phase = 1	next_phase = 0	reward = -1046.438435	array([[-75.72116 , -98.598465]], dtype=float32)
time = 37215	action = 0	current_phase = 1	next_phase = 0	reward = -965.194199	array([[-75.72116 , -98.598465]], dtype=float32)
time = 37220	action = 0	current_phase = 1	next_phase = 0	reward = -890.390490	array([[-75.72116 , -98.598465]], dtype=float32)
time = 37225	action = 0	current_phase = 1	next_phase = 0	reward = -803.385418	array([[-75.72116 , -98.598465]], dtype=float32)
time = 37230	action = 0	current_phase = 1	next_phase = 0	reward = -741.887226	array([[-75.72116 , -98.598465]], dtype=float32)
time = 37235	action = 0	current_phase = 1	next_phase = 0	reward = -670.391081	array([[-75.72116 , -98.598465]], dtype=float32)
time = 37240	action = 0	current_phase = 1	next_phase = 0	reward = -567.092613	array([[-75.72116 , -98.598465]], dtype=float32)
time = 37245	action = 0	current_phase = 1	next_phase = 0	reward = -256.694387	array([[-75.72116 , -98.598465]], dtype=float32)
time = 37250	action = 0	current_phase = 1	next_phase = 0	reward = -152.083301	array([[-75.72116 , -98.598465]], dtype=float32)
time = 37255	action = 0	current_phase = 1	next_phase = 0	reward = -54.540732	array([[-76.10476, -98.66392]], dtype=float32)
time = 37260	action = 0	current_phase = 1	next_phase = 0	reward = 21.938715	array([[-47.43701, -97.10497]], dtype=float32)
time = 37265	action = 1	current_phase = 1	next_phase = 0	reward = -10.104001	array([[-41.586445, -32.998978]], dtype=float32)
time = 37273	action = 0	current_phase = 0	next_phase = 1	reward = -10.128068	array([[ -7.1599646, -36.19038  ]], dtype=float32)
time = 37278	action = 0	current_phase = 0	next_phase = 1	reward = -11.984952	array([[-10.101712, -37.995655]], dtype=float32)
time = 37283	action = 0	current_phase = 0	next_phase = 1	reward = -14.939533	array([[ -9.300526, -38.304832]], dtype=float32)
time = 37288	action = 0	current_phase = 0	next_phase = 1	reward = -18.109332	array([[ -8.912744, -36.829884]], dtype=float32)
time = 37293	action = 0	current_phase = 0	next_phase = 1	reward = -21.515711	array([[-12.06039 , -40.502094]], dtype=float32)
time = 37298	action = 0	current_phase = 0	next_phase = 1	reward = -25.939760	array([[-25.763483, -45.766964]], dtype=float32)
time = 37303	action = 0	current_phase = 0	next_phase = 1	reward = -32.156429	array([[-30.744785, -46.139656]], dtype=float32)
time = 37308	action = 0	current_phase = 0	next_phase = 1	reward = -38.226035	array([[-32.966057, -46.584145]], dtype=float32)
time = 37313	action = 0	current_phase = 0	next_phase = 1	reward = -44.426477	array([[-34.143036, -48.99893 ]], dtype=float32)
time = 37318	action = 0	current_phase = 0	next_phase = 1	reward = -52.013441	array([[-41.725445, -48.331802]], dtype=float32)
time = 37323	action = 0	current_phase = 0	next_phase = 1	reward = -59.060971	array([[-45.55698 , -51.077602]], dtype=float32)
time = 37328	action = 0	current_phase = 0	next_phase = 1	reward = -66.017539	array([[-53.6195  , -54.057266]], dtype=float32)
time = 37333	action = 0	current_phase = 0	next_phase = 1	reward = -72.444081	array([[-56.141365, -57.12991 ]], dtype=float32)
time = 37338	action = 1	current_phase = 0	next_phase = 1	reward = -97.462727	array([[-57.740185, -55.245514]], dtype=float32)
time = 37346	action = 1	current_phase = 1	next_phase = 0	reward = -118.852908	array([[-95.12335, -27.66448]], dtype=float32)
time = 37354	action = 1	current_phase = 0	next_phase = 1	reward = -96.129275	array([[-58.16362, -55.12694]], dtype=float32)
time = 37362	action = 1	current_phase = 1	next_phase = 0	reward = -118.795106	array([[-97.42913, -29.97431]], dtype=float32)
time = 37370	action = 0	current_phase = 0	next_phase = 1	reward = -76.240901	array([[-42.048676, -53.49627 ]], dtype=float32)
time = 37375	action = 0	current_phase = 0	next_phase = 1	reward = -77.634734	array([[-48.668385, -57.123695]], dtype=float32)
time = 37380	action = 0	current_phase = 0	next_phase = 1	reward = -77.860964	array([[-44.95687, -55.7039 ]], dtype=float32)
time = 37385	action = 0	current_phase = 0	next_phase = 1	reward = -77.735106	array([[-45.330414, -57.372307]], dtype=float32)
time = 37390	action = 0	current_phase = 0	next_phase = 1	reward = -77.941804	array([[-47.5783  , -57.352158]], dtype=float32)
time = 37395	action = 0	current_phase = 0	next_phase = 1	reward = -77.698439	array([[-47.136196, -56.25016 ]], dtype=float32)
time = 37400	action = 0	current_phase = 0	next_phase = 1	reward = -77.692608	array([[-47.88492 , -57.094666]], dtype=float32)
time = 37405	action = 0	current_phase = 0	next_phase = 1	reward = -78.615993	array([[-47.99396 , -57.933456]], dtype=float32)
time = 37410	action = 0	current_phase = 0	next_phase = 1	reward = -77.958393	array([[-50.214417, -58.372044]], dtype=float32)
time = 37415	action = 0	current_phase = 0	next_phase = 1	reward = -78.720240	array([[-49.018677, -57.744476]], dtype=float32)
time = 37420	action = 0	current_phase = 0	next_phase = 1	reward = -79.301516	array([[-50.86652, -58.70952]], dtype=float32)
time = 37425	action = 0	current_phase = 0	next_phase = 1	reward = -82.608403	array([[-51.960606, -60.69872 ]], dtype=float32)
time = 37430	action = 0	current_phase = 0	next_phase = 1	reward = -90.770116	array([[-62.888935, -72.64917 ]], dtype=float32)
time = 37435	action = 0	current_phase = 0	next_phase = 1	reward = -98.701286	array([[-72.594666, -79.898445]], dtype=float32)
time = 37440	action = 0	current_phase = 0	next_phase = 1	reward = -106.244731	array([[-73.70026, -82.33064]], dtype=float32)
time = 37445	action = 0	current_phase = 0	next_phase = 1	reward = -113.380111	array([[-72.70058, -83.38495]], dtype=float32)
time = 37450	action = 0	current_phase = 0	next_phase = 1	reward = -120.205771	array([[-72.25607, -83.23641]], dtype=float32)
time = 37455	action = 0	current_phase = 0	next_phase = 1	reward = -128.208302	array([[-73.23694, -82.16035]], dtype=float32)
time = 37460	action = 0	current_phase = 0	next_phase = 1	reward = -135.189857	array([[-78.49567, -79.33519]], dtype=float32)
time = 37465	action = 1	current_phase = 0	next_phase = 1	reward = -190.557190	array([[-84.425644, -76.23995 ]], dtype=float32)
time = 37473	action = 1	current_phase = 1	next_phase = 0	reward = -209.577201	array([[-106.71066 ,  -90.023285]], dtype=float32)
time = 37481	action = 1	current_phase = 0	next_phase = 1	reward = -163.012950	array([[-85.19427, -75.81566]], dtype=float32)
time = 37489	action = 1	current_phase = 1	next_phase = 0	reward = -179.816443	array([[-107.02816 ,  -85.847824]], dtype=float32)
time = 37497	action = 1	current_phase = 0	next_phase = 1	reward = -137.665645	array([[-79.02391 , -78.965996]], dtype=float32)
Train on 838 samples, validate on 360 samples
Epoch 1/50
 - 5s - loss: 13047.8279 - val_loss: 6275.2590
Epoch 2/50
 - 5s - loss: 13015.8397 - val_loss: 6262.2330
Epoch 3/50
 - 5s - loss: 13005.2913 - val_loss: 6245.9901
Epoch 4/50
 - 5s - loss: 12989.4633 - val_loss: 6231.6397
Epoch 5/50
 - 5s - loss: 12977.0618 - val_loss: 6216.8000
Epoch 6/50
 - 5s - loss: 12965.7793 - val_loss: 6202.8748
Epoch 7/50
 - 5s - loss: 12956.0403 - val_loss: 6189.2227
Epoch 8/50
 - 6s - loss: 12944.7725 - val_loss: 6176.1158
Epoch 9/50
 - 5s - loss: 12930.1563 - val_loss: 6159.2295
Epoch 10/50
 - 5s - loss: 12914.7224 - val_loss: 6145.2940
Epoch 11/50
 - 5s - loss: 12905.9604 - val_loss: 6132.6224
Epoch 12/50
 - 4s - loss: 12890.7314 - val_loss: 6117.9846
Epoch 13/50
 - 5s - loss: 12878.3810 - val_loss: 6105.1001
Epoch 14/50
 - 6s - loss: 12867.0546 - val_loss: 6091.0710
Epoch 15/50
 - 6s - loss: 12855.4110 - val_loss: 6075.1397
Epoch 16/50
 - 5s - loss: 12845.2895 - val_loss: 6063.8339
Epoch 17/50
 - 5s - loss: 12830.7105 - val_loss: 6048.3395
Epoch 18/50
 - 5s - loss: 12819.2411 - val_loss: 6035.0081
Epoch 19/50
 - 5s - loss: 12807.0261 - val_loss: 6019.6776
Epoch 20/50
 - 5s - loss: 12799.6204 - val_loss: 6005.9314
Epoch 21/50
 - 5s - loss: 12782.2808 - val_loss: 5994.1269
Epoch 22/50
 - 5s - loss: 12777.4365 - val_loss: 5981.7893
Epoch 23/50
 - 5s - loss: 12760.5960 - val_loss: 5969.6738
Epoch 24/50
 - 5s - loss: 12748.1634 - val_loss: 5954.1387
Epoch 25/50
 - 4s - loss: 12738.5994 - val_loss: 5950.4882
Epoch 26/50
 - 5s - loss: 12729.0164 - val_loss: 5931.5250
Epoch 27/50
 - 5s - loss: 12716.6487 - val_loss: 5932.7438
Epoch 28/50
 - 4s - loss: 12701.2711 - val_loss: 5920.5253
Epoch 29/50
 - 5s - loss: 12690.8186 - val_loss: 5891.3760
Epoch 30/50
 - 4s - loss: 12677.3124 - val_loss: 5878.9472
Epoch 31/50
 - 4s - loss: 12665.8466 - val_loss: 5879.3078
Epoch 32/50
 - 5s - loss: 12653.3884 - val_loss: 5854.6581
Epoch 33/50
 - 4s - loss: 12644.1995 - val_loss: 5889.9454
Epoch 34/50
 - 5s - loss: 12633.2704 - val_loss: 5843.1901
Epoch 35/50
 - 4s - loss: 12620.5824 - val_loss: 5816.1540
Epoch 36/50
 - 5s - loss: 12608.7688 - val_loss: 5805.9020
Epoch 37/50
 - 5s - loss: 12599.4472 - val_loss: 5793.0917
Epoch 38/50
 - 4s - loss: 12588.2558 - val_loss: 5786.0285
Epoch 39/50
 - 4s - loss: 12576.0032 - val_loss: 5778.0989
Epoch 40/50
 - 5s - loss: 12568.4793 - val_loss: 5762.4316
Epoch 41/50
 - 4s - loss: 12552.6090 - val_loss: 5751.3877
Epoch 42/50
 - 5s - loss: 12542.2025 - val_loss: 5735.7631
Epoch 43/50
 - 5s - loss: 12554.9134 - val_loss: 5731.3310
Epoch 44/50
 - 4s - loss: 12520.8777 - val_loss: 5717.4705
Epoch 45/50
 - 4s - loss: 12509.8752 - val_loss: 5706.2254
Epoch 46/50
 - 5s - loss: 12522.5269 - val_loss: 5695.8495
Epoch 47/50
 - 5s - loss: 12485.6319 - val_loss: 5690.2015
Epoch 48/50
 - 5s - loss: 12476.1493 - val_loss: 5679.0667
Epoch 49/50
 - 5s - loss: 12464.7466 - val_loss: 5673.3234
Epoch 50/50
 - 5s - loss: 12453.7532 - val_loss: 5660.6726
length of memory (state 0, action 0): 1032, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 311, after forget
length of memory (state 1, action 0): 501, after forget
length of memory (state 1, action 1): 298, after forget
time = 37505	action = 0	current_phase = 1	next_phase = 0	reward = -53.051994	array([[ -99.64478 , -114.795235]], dtype=float32)
time = 37510	action = 0	current_phase = 1	next_phase = 0	reward = -18.112431	array([[ -63.257988, -104.51322 ]], dtype=float32)
time = 37515	action = 0	current_phase = 1	next_phase = 0	reward = -7.972141	array([[-64.33705 , -94.962776]], dtype=float32)
time = 37520	action = 0	current_phase = 1	next_phase = 0	reward = 17.920883	array([[-47.396923, -94.6978  ]], dtype=float32)
time = 37525	action = 1	current_phase = 1	next_phase = 0	reward = -26.898054	array([[-57.74891 , -29.759306]], dtype=float32)
time = 37533	action = 0	current_phase = 0	next_phase = 1	reward = -15.865847	array([[-10.079685, -40.116203]], dtype=float32)
time = 37538	action = 0	current_phase = 0	next_phase = 1	reward = -17.790881	array([[ -3.5848608, -36.943398 ]], dtype=float32)
time = 37543	action = 0	current_phase = 0	next_phase = 1	reward = -20.379297	array([[ -5.271893, -38.17401 ]], dtype=float32)
time = 37548	action = 0	current_phase = 0	next_phase = 1	reward = -25.041076	array([[-15.478823, -44.809784]], dtype=float32)
time = 37553	action = 0	current_phase = 0	next_phase = 1	reward = -29.418350	array([[-20.246979, -47.287872]], dtype=float32)
time = 37558	action = 0	current_phase = 0	next_phase = 1	reward = -35.935801	array([[-21.131609, -47.822334]], dtype=float32)
time = 37563	action = 0	current_phase = 0	next_phase = 1	reward = -41.376953	array([[-22.36042 , -50.720917]], dtype=float32)
time = 37568	action = 0	current_phase = 0	next_phase = 1	reward = -47.577603	array([[-22.146091, -56.257767]], dtype=float32)
time = 37573	action = 0	current_phase = 0	next_phase = 1	reward = -53.349903	array([[-27.049738, -51.067413]], dtype=float32)
time = 37578	action = 0	current_phase = 0	next_phase = 1	reward = -60.607844	array([[-23.660084, -49.62702 ]], dtype=float32)
time = 37583	action = 0	current_phase = 0	next_phase = 1	reward = -68.122360	array([[-50.92083, -91.52225]], dtype=float32)
time = 37588	action = 0	current_phase = 0	next_phase = 1	reward = -74.493210	array([[ -52.5355  , -101.940254]], dtype=float32)
time = 37593	action = 0	current_phase = 0	next_phase = 1	reward = -82.110050	array([[ -51.38002 , -103.496765]], dtype=float32)
time = 37598	action = 0	current_phase = 0	next_phase = 1	reward = -90.494246	array([[ -48.885452, -105.48177 ]], dtype=float32)
time = 37603	action = 0	current_phase = 0	next_phase = 1	reward = -98.600540	array([[ -56.50354, -107.11551]], dtype=float32)
time = 37608	action = 0	current_phase = 0	next_phase = 1	reward = -106.810957	array([[ -63.32335, -103.65905]], dtype=float32)
time = 37613	action = 0	current_phase = 0	next_phase = 1	reward = -115.122557	array([[ -66.345726, -101.86529 ]], dtype=float32)
time = 37618	action = 0	current_phase = 0	next_phase = 1	reward = -124.448615	array([[-78.15446, -93.55443]], dtype=float32)
time = 37623	action = 0	current_phase = 0	next_phase = 1	reward = -132.923053	array([[-82.738106, -89.86892 ]], dtype=float32)
time = 37628	action = 1	current_phase = 0	next_phase = 1	reward = -186.756979	array([[-95.090965, -82.382416]], dtype=float32)
time = 37636	action = 0	current_phase = 1	next_phase = 0	reward = -96.546351	array([[ -95.17777, -119.77245]], dtype=float32)
time = 37641	action = 0	current_phase = 1	next_phase = 0	reward = -76.343912	array([[ -92.138535, -120.02678 ]], dtype=float32)
time = 37646	action = 0	current_phase = 1	next_phase = 0	reward = -88.773939	array([[ -99.45878, -118.83529]], dtype=float32)
time = 37651	action = 0	current_phase = 1	next_phase = 0	reward = -87.091171	array([[-103.09272, -118.32649]], dtype=float32)
time = 37656	action = 0	current_phase = 1	next_phase = 0	reward = -64.294317	array([[ -95.244774, -119.73163 ]], dtype=float32)
time = 37661	action = 0	current_phase = 1	next_phase = 0	reward = -64.839602	array([[-105.800575, -116.18599 ]], dtype=float32)
time = 37666	action = 0	current_phase = 1	next_phase = 0	reward = -60.129233	array([[-110.19767 , -115.369675]], dtype=float32)
time = 37671	action = 0	current_phase = 1	next_phase = 0	reward = -55.651219	array([[ -85.51265, -113.39838]], dtype=float32)
time = 37676	action = 0	current_phase = 1	next_phase = 0	reward = -41.355472	array([[ -68.15907 , -104.759926]], dtype=float32)
time = 37681	action = 0	current_phase = 1	next_phase = 0	reward = -24.402125	array([[-67.35847, -92.32365]], dtype=float32)
time = 37686	action = 0	current_phase = 1	next_phase = 0	reward = -10.749872	array([[-56.372066, -99.06237 ]], dtype=float32)
time = 37691	action = 1	current_phase = 1	next_phase = 0	reward = -30.351555	array([[-41.75611 , -27.549822]], dtype=float32)
time = 37699	action = 0	current_phase = 0	next_phase = 1	reward = -14.241062	array([[-12.991237, -39.197083]], dtype=float32)
time = 37704	action = 0	current_phase = 0	next_phase = 1	reward = -15.557368	array([[ -4.155901, -34.014954]], dtype=float32)
time = 37709	action = 0	current_phase = 0	next_phase = 1	reward = -18.192505	array([[ -5.792307, -38.172073]], dtype=float32)
time = 37714	action = 0	current_phase = 0	next_phase = 1	reward = -21.176706	array([[ -3.7994814, -35.022217 ]], dtype=float32)
time = 37719	action = 0	current_phase = 0	next_phase = 1	reward = -25.610666	array([[-12.099812, -42.6976  ]], dtype=float32)
time = 37724	action = 0	current_phase = 0	next_phase = 1	reward = -30.291429	array([[-28.296026, -50.230675]], dtype=float32)
time = 37729	action = 0	current_phase = 0	next_phase = 1	reward = -35.804371	array([[-22.75446 , -48.425407]], dtype=float32)
time = 37734	action = 0	current_phase = 0	next_phase = 1	reward = -42.543704	array([[-22.767353, -49.983543]], dtype=float32)
time = 37739	action = 0	current_phase = 0	next_phase = 1	reward = -49.501257	array([[-29.976862, -57.107834]], dtype=float32)
time = 37744	action = 0	current_phase = 0	next_phase = 1	reward = -56.788248	array([[-30.917015, -65.29614 ]], dtype=float32)
time = 37749	action = 0	current_phase = 0	next_phase = 1	reward = -63.646700	array([[-49.762314, -98.428894]], dtype=float32)
time = 37754	action = 0	current_phase = 0	next_phase = 1	reward = -70.983575	array([[-55.41593, -97.56199]], dtype=float32)
time = 37759	action = 0	current_phase = 0	next_phase = 1	reward = -77.788826	array([[ -52.96808, -102.58441]], dtype=float32)
time = 37764	action = 0	current_phase = 0	next_phase = 1	reward = -86.211257	array([[ -53.12401, -102.44451]], dtype=float32)
time = 37769	action = 0	current_phase = 0	next_phase = 1	reward = -94.279910	array([[-56.737816, -99.95848 ]], dtype=float32)
time = 37774	action = 0	current_phase = 0	next_phase = 1	reward = -102.498686	array([[-67.969604, -95.45952 ]], dtype=float32)
time = 37779	action = 0	current_phase = 0	next_phase = 1	reward = -111.517653	array([[-73.49971, -95.36313]], dtype=float32)
time = 37784	action = 0	current_phase = 0	next_phase = 1	reward = -121.173946	array([[-81.439514, -91.57284 ]], dtype=float32)
time = 37789	action = 0	current_phase = 0	next_phase = 1	reward = -129.700783	array([[-86.91559 , -88.130356]], dtype=float32)
time = 37794	action = 1	current_phase = 0	next_phase = 1	reward = -202.412413	array([[-99.09553 , -80.783295]], dtype=float32)
time = 37802	action = 0	current_phase = 1	next_phase = 0	reward = -108.396602	array([[ -93.73406, -119.8766 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 5s - loss: 14574.1704 - val_loss: 7351.9698
Epoch 2/50
 - 5s - loss: 14548.8752 - val_loss: 7331.6436
Epoch 3/50
 - 4s - loss: 14526.3229 - val_loss: 7320.5749
Epoch 4/50
 - 5s - loss: 14500.8494 - val_loss: 7306.4192
Epoch 5/50
 - 4s - loss: 14488.7675 - val_loss: 7297.6771
Epoch 6/50
 - 5s - loss: 14471.2633 - val_loss: 7284.6477
Epoch 7/50
 - 5s - loss: 14460.5099 - val_loss: 7277.8580
Epoch 8/50
 - 5s - loss: 14439.7501 - val_loss: 7266.7441
Epoch 9/50
 - 5s - loss: 14425.5693 - val_loss: 7257.8482
Epoch 10/50
 - 5s - loss: 14408.5660 - val_loss: 7244.0797
Epoch 11/50
 - 5s - loss: 14392.6533 - val_loss: 7233.8946
Epoch 12/50
 - 5s - loss: 14375.8398 - val_loss: 7231.7122
Epoch 13/50
 - 5s - loss: 14361.3664 - val_loss: 7220.2123
Epoch 14/50
 - 5s - loss: 14347.5348 - val_loss: 7211.2316
Epoch 15/50
 - 5s - loss: 14339.1958 - val_loss: 7202.2780
Epoch 16/50
 - 5s - loss: 14320.1636 - val_loss: 7195.7027
Epoch 17/50
 - 5s - loss: 14315.0348 - val_loss: 7182.9833
Epoch 18/50
 - 5s - loss: 14297.5064 - val_loss: 7178.0535
Epoch 19/50
 - 5s - loss: 14286.0646 - val_loss: 7173.0136
Epoch 20/50
 - 5s - loss: 14274.0788 - val_loss: 7156.1586
Epoch 21/50
 - 5s - loss: 14270.4731 - val_loss: 7146.4705
Epoch 22/50
 - 5s - loss: 14241.3353 - val_loss: 7139.0363
Epoch 23/50
 - 5s - loss: 14230.1186 - val_loss: 7143.2539
Epoch 24/50
 - 5s - loss: 14221.3347 - val_loss: 7127.5809
Epoch 25/50
 - 5s - loss: 14210.1668 - val_loss: 7123.1901
Epoch 26/50
 - 5s - loss: 14200.2846 - val_loss: 7107.7346
Epoch 27/50
 - 5s - loss: 14182.9993 - val_loss: 7103.3432
Epoch 28/50
 - 5s - loss: 14171.7887 - val_loss: 7096.0601
Epoch 29/50
 - 5s - loss: 14160.3065 - val_loss: 7087.8080
Epoch 30/50
 - 5s - loss: 14144.2256 - val_loss: 7077.8695
Epoch 31/50
 - 5s - loss: 14132.4454 - val_loss: 7080.1018
Epoch 32/50
 - 5s - loss: 14122.9200 - val_loss: 7059.6569
Epoch 33/50
 - 5s - loss: 14106.5384 - val_loss: 7049.0000
Epoch 34/50
 - 5s - loss: 14096.3896 - val_loss: 7049.6955
Epoch 35/50
 - 5s - loss: 14085.5878 - val_loss: 7032.3134
Epoch 36/50
 - 5s - loss: 14076.8046 - val_loss: 7033.9193
Epoch 37/50
 - 5s - loss: 14060.3760 - val_loss: 7019.5037
Epoch 38/50
 - 5s - loss: 14046.8978 - val_loss: 7014.2005
Epoch 39/50
 - 6s - loss: 14040.3020 - val_loss: 7010.7088
Epoch 40/50
 - 6s - loss: 14031.0068 - val_loss: 7009.8812
Epoch 41/50
 - 5s - loss: 14019.2667 - val_loss: 6999.0420
Epoch 42/50
 - 5s - loss: 14008.2787 - val_loss: 6979.4890
Epoch 43/50
 - 5s - loss: 13991.2597 - val_loss: 6971.3356
Epoch 44/50
 - 4s - loss: 13984.3546 - val_loss: 6963.9480
Epoch 45/50
 - 5s - loss: 13970.1512 - val_loss: 6969.3072
Epoch 46/50
 - 4s - loss: 13960.1091 - val_loss: 6951.9919
Epoch 47/50
 - 5s - loss: 13948.6694 - val_loss: 6946.7795
Epoch 48/50
 - 5s - loss: 13935.4666 - val_loss: 6942.0803
Epoch 49/50
 - 4s - loss: 13926.6888 - val_loss: 6934.1313
Epoch 50/50
 - 5s - loss: 13911.4314 - val_loss: 6922.5502
length of memory (state 0, action 0): 1038, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 313, after forget
length of memory (state 1, action 0): 517, after forget
length of memory (state 1, action 1): 300, after forget
time = 37807	action = 1	current_phase = 1	next_phase = 0	reward = -196.646539	array([[-147.43463, -117.99065]], dtype=float32)
time = 37815	action = 0	current_phase = 0	next_phase = 1	reward = -117.781973	array([[ -92.914406, -107.94425 ]], dtype=float32)
time = 37820	action = 0	current_phase = 0	next_phase = 1	reward = -115.196655	array([[ -96.479546, -105.08917 ]], dtype=float32)
time = 37825	action = 0	current_phase = 0	next_phase = 1	reward = -114.971332	array([[ -92.92046 , -107.934906]], dtype=float32)
time = 37830	action = 0	current_phase = 0	next_phase = 1	reward = -115.595927	array([[-100.75369, -101.53754]], dtype=float32)
time = 37835	action = 0	current_phase = 0	next_phase = 1	reward = -118.715781	array([[ -97.98556, -103.83299]], dtype=float32)
time = 37840	action = 0	current_phase = 0	next_phase = 1	reward = -119.460916	array([[ -94.82678 , -106.395035]], dtype=float32)
time = 37845	action = 0	current_phase = 0	next_phase = 1	reward = -120.836147	array([[ -90.912155, -109.47448 ]], dtype=float32)
time = 37850	action = 0	current_phase = 0	next_phase = 1	reward = -120.376897	array([[ -90.51886 , -109.762985]], dtype=float32)
time = 37855	action = 0	current_phase = 0	next_phase = 1	reward = -120.908588	array([[ -91.05887, -109.35993]], dtype=float32)
time = 37860	action = 0	current_phase = 0	next_phase = 1	reward = -122.087800	array([[ -90.59498 , -109.699425]], dtype=float32)
time = 37865	action = 0	current_phase = 0	next_phase = 1	reward = -123.035294	array([[ -89.55089, -110.43581]], dtype=float32)
time = 37870	action = 0	current_phase = 0	next_phase = 1	reward = -123.974461	array([[ -88.650826, -111.053925]], dtype=float32)
time = 37875	action = 0	current_phase = 0	next_phase = 1	reward = -124.396163	array([[ -86.80671, -112.32411]], dtype=float32)
time = 37880	action = 0	current_phase = 0	next_phase = 1	reward = -126.848770	array([[ -85.98861 , -112.873116]], dtype=float32)
time = 37885	action = 0	current_phase = 0	next_phase = 1	reward = -133.522367	array([[ -81.8446 , -115.65011]], dtype=float32)
time = 37890	action = 0	current_phase = 0	next_phase = 1	reward = -142.125352	array([[ -84.70801, -113.72973]], dtype=float32)
time = 37895	action = 0	current_phase = 0	next_phase = 1	reward = -150.046125	array([[ -85.71975, -113.05621]], dtype=float32)
time = 37900	action = 0	current_phase = 0	next_phase = 1	reward = -156.484953	array([[ -88.20734, -111.39523]], dtype=float32)
time = 37905	action = 0	current_phase = 0	next_phase = 1	reward = -162.491660	array([[ -89.12068, -110.77908]], dtype=float32)
time = 37910	action = 0	current_phase = 0	next_phase = 1	reward = -168.450000	array([[ -89.52853, -110.50002]], dtype=float32)
time = 37915	action = 0	current_phase = 0	next_phase = 1	reward = -174.408333	array([[ -90.28121, -109.98259]], dtype=float32)
time = 37920	action = 0	current_phase = 0	next_phase = 1	reward = -180.366667	array([[ -93.69963, -107.65431]], dtype=float32)
time = 37925	action = 1	current_phase = 0	next_phase = 1	reward = -270.321234	array([[-105.70622,  -99.39947]], dtype=float32)
time = 37933	action = 1	current_phase = 1	next_phase = 0	reward = -277.631765	array([[-144.45082 , -120.482834]], dtype=float32)
time = 37941	action = 0	current_phase = 0	next_phase = 1	reward = -169.764667	array([[ -98.82715, -104.08261]], dtype=float32)
time = 37946	action = 1	current_phase = 0	next_phase = 1	reward = -247.607724	array([[-107.7626 ,  -98.06676]], dtype=float32)
time = 37954	action = 1	current_phase = 1	next_phase = 0	reward = -253.786621	array([[-139.84761, -122.8402 ]], dtype=float32)
time = 37962	action = 0	current_phase = 0	next_phase = 1	reward = -154.266638	array([[ -84.50904 , -113.614136]], dtype=float32)
time = 37967	action = 0	current_phase = 0	next_phase = 1	reward = -154.507738	array([[ -95.42656, -106.93515]], dtype=float32)
time = 37972	action = 0	current_phase = 0	next_phase = 1	reward = -154.832239	array([[ -67.130844, -125.84955 ]], dtype=float32)
time = 37977	action = 0	current_phase = 0	next_phase = 1	reward = -153.531162	array([[ -72.83037, -121.76621]], dtype=float32)
time = 37982	action = 0	current_phase = 0	next_phase = 1	reward = -149.523577	array([[ -79.22767 , -117.296265]], dtype=float32)
time = 37987	action = 0	current_phase = 0	next_phase = 1	reward = -145.117933	array([[ -69.255356, -124.2645  ]], dtype=float32)
time = 37992	action = 0	current_phase = 0	next_phase = 1	reward = -144.016683	array([[ -66.3858  , -126.289055]], dtype=float32)
time = 37997	action = 0	current_phase = 0	next_phase = 1	reward = -142.862526	array([[ -65.25697, -127.27695]], dtype=float32)
time = 38002	action = 0	current_phase = 0	next_phase = 1	reward = -140.960831	array([[ -63.387405, -129.1593  ]], dtype=float32)
time = 38007	action = 0	current_phase = 0	next_phase = 1	reward = -138.653364	array([[ -63.76267, -128.75433]], dtype=float32)
time = 38012	action = 0	current_phase = 0	next_phase = 1	reward = -138.404846	array([[ -63.86631, -128.7509 ]], dtype=float32)
time = 38017	action = 0	current_phase = 0	next_phase = 1	reward = -139.506357	array([[ -64.03641, -128.62376]], dtype=float32)
time = 38022	action = 0	current_phase = 0	next_phase = 1	reward = -140.401746	array([[ -65.62868, -127.16645]], dtype=float32)
time = 38027	action = 0	current_phase = 0	next_phase = 1	reward = -141.220449	array([[ -65.75814, -127.06578]], dtype=float32)
time = 38032	action = 0	current_phase = 0	next_phase = 1	reward = -143.954129	array([[ -66.0509 , -126.79256]], dtype=float32)
time = 38037	action = 0	current_phase = 0	next_phase = 1	reward = -150.118570	array([[ -66.14026, -126.70165]], dtype=float32)
time = 38042	action = 0	current_phase = 0	next_phase = 1	reward = -157.731651	array([[ -67.49471, -125.2269 ]], dtype=float32)
time = 38047	action = 0	current_phase = 0	next_phase = 1	reward = -165.828108	array([[ -71.9653 , -121.37724]], dtype=float32)
time = 38052	action = 0	current_phase = 0	next_phase = 1	reward = -173.261545	array([[ -73.545044, -120.21891 ]], dtype=float32)
time = 38057	action = 0	current_phase = 0	next_phase = 1	reward = -179.370816	array([[ -73.99621 , -119.895676]], dtype=float32)
time = 38062	action = 0	current_phase = 0	next_phase = 1	reward = -185.183331	array([[ -74.06027, -119.8481 ]], dtype=float32)
time = 38067	action = 0	current_phase = 0	next_phase = 1	reward = -190.995833	array([[ -74.16995, -119.74147]], dtype=float32)
time = 38072	action = 0	current_phase = 0	next_phase = 1	reward = -196.808333	array([[ -75.59357, -118.3166 ]], dtype=float32)
time = 38077	action = 0	current_phase = 0	next_phase = 1	reward = -202.620833	array([[ -84.019615, -109.59112 ]], dtype=float32)
time = 38082	action = 0	current_phase = 0	next_phase = 1	reward = -208.433333	array([[ -88.7541 , -104.54216]], dtype=float32)
time = 38087	action = 0	current_phase = 0	next_phase = 1	reward = -214.245833	array([[ -89.20039 , -104.065796]], dtype=float32)
time = 38092	action = 0	current_phase = 0	next_phase = 1	reward = -220.058333	array([[ -89.23741, -104.02826]], dtype=float32)
time = 38097	action = 0	current_phase = 0	next_phase = 1	reward = -225.870833	array([[ -89.24861, -104.01883]], dtype=float32)
time = 38102	action = 0	current_phase = 0	next_phase = 1	reward = -231.683333	array([[ -89.25994, -104.00976]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 5s - loss: 9722.0425 - val_loss: 19039.3368
Epoch 2/50
 - 6s - loss: 9692.8929 - val_loss: 19033.1522
Epoch 3/50
 - 6s - loss: 9679.5004 - val_loss: 19005.0792
Epoch 4/50
 - 5s - loss: 9663.6531 - val_loss: 18991.8811
Epoch 5/50
 - 5s - loss: 9654.4539 - val_loss: 18971.6013
Epoch 6/50
 - 5s - loss: 9643.4805 - val_loss: 18964.5204
Epoch 7/50
 - 5s - loss: 9625.3993 - val_loss: 18941.4994
Epoch 8/50
 - 6s - loss: 9616.8216 - val_loss: 18922.4892
Epoch 9/50
 - 6s - loss: 9604.9090 - val_loss: 18903.4519
Epoch 10/50
 - 6s - loss: 9594.9018 - val_loss: 18890.0703
Epoch 11/50
 - 6s - loss: 9584.6482 - val_loss: 18872.7824
Epoch 12/50
 - 5s - loss: 9575.7151 - val_loss: 18839.9907
Epoch 13/50
 - 5s - loss: 9563.7050 - val_loss: 18837.8402
Epoch 14/50
 - 5s - loss: 9552.3469 - val_loss: 18798.2195
Epoch 15/50
 - 5s - loss: 9544.8860 - val_loss: 18809.7705
Epoch 16/50
 - 5s - loss: 9540.1855 - val_loss: 18793.9993
Epoch 17/50
 - 5s - loss: 9525.9137 - val_loss: 18754.6633
Epoch 18/50
 - 5s - loss: 9515.0323 - val_loss: 18753.8029
Epoch 19/50
 - 5s - loss: 9505.1603 - val_loss: 18747.2926
Epoch 20/50
 - 5s - loss: 9498.9644 - val_loss: 18736.8887
Epoch 21/50
 - 5s - loss: 9482.6146 - val_loss: 18720.2469
Epoch 22/50
 - 4s - loss: 9475.5809 - val_loss: 18705.4829
Epoch 23/50
 - 5s - loss: 9465.2251 - val_loss: 18687.9605
Epoch 24/50
 - 5s - loss: 9453.6664 - val_loss: 18658.0695
Epoch 25/50
 - 5s - loss: 9448.2515 - val_loss: 18652.5917
Epoch 26/50
 - 5s - loss: 9433.9829 - val_loss: 18626.6801
Epoch 27/50
 - 5s - loss: 9429.5888 - val_loss: 18611.1150
Epoch 28/50
 - 6s - loss: 9415.5580 - val_loss: 18611.9173
Epoch 29/50
 - 5s - loss: 9402.9009 - val_loss: 18593.0478
Epoch 30/50
 - 5s - loss: 9396.4452 - val_loss: 18576.4912
Epoch 31/50
 - 5s - loss: 9390.9625 - val_loss: 18549.5583
Epoch 32/50
 - 5s - loss: 9378.6075 - val_loss: 18541.2297
Epoch 33/50
 - 5s - loss: 9367.1489 - val_loss: 18526.5141
Epoch 34/50
 - 5s - loss: 9360.4652 - val_loss: 18527.7990
Epoch 35/50
 - 5s - loss: 9345.1786 - val_loss: 18496.3151
Epoch 36/50
 - 5s - loss: 9335.6079 - val_loss: 18478.1303
Epoch 37/50
 - 5s - loss: 9333.3941 - val_loss: 18462.3515
Epoch 38/50
 - 5s - loss: 9322.7671 - val_loss: 18460.0514
Epoch 39/50
 - 6s - loss: 9310.5659 - val_loss: 18440.2207
Epoch 40/50
 - 6s - loss: 9300.2701 - val_loss: 18427.9195
Epoch 41/50
 - 5s - loss: 9290.1082 - val_loss: 18428.0251
Epoch 42/50
 - 5s - loss: 9285.0088 - val_loss: 18398.6668
Epoch 43/50
 - 5s - loss: 9272.6726 - val_loss: 18387.7409
Epoch 44/50
 - 6s - loss: 9262.6420 - val_loss: 18366.8478
Epoch 45/50
 - 6s - loss: 9251.8923 - val_loss: 18363.4218
Epoch 46/50
 - 5s - loss: 9252.0850 - val_loss: 18342.5734
Epoch 47/50
 - 5s - loss: 9237.9436 - val_loss: 18322.7330
Epoch 48/50
 - 5s - loss: 9224.2524 - val_loss: 18310.7075
Epoch 49/50
 - 5s - loss: 9214.1002 - val_loss: 18296.6272
Epoch 50/50
 - 4s - loss: 9205.4473 - val_loss: 18279.9797
length of memory (state 0, action 0): 1052, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 315, after forget
length of memory (state 1, action 0): 517, after forget
length of memory (state 1, action 1): 303, after forget
time = 38107	action = 1	current_phase = 0	next_phase = 1	reward = -353.678821	array([[-141.0038 ,  -90.10335]], dtype=float32)
time = 38115	action = 1	current_phase = 1	next_phase = 0	reward = -351.434488	array([[-164.83856, -101.28179]], dtype=float32)
time = 38123	action = 1	current_phase = 0	next_phase = 1	reward = -317.491151	array([[-140.8856 ,  -90.43992]], dtype=float32)
time = 38131	action = 1	current_phase = 1	next_phase = 0	reward = -308.359158	array([[-164.83931, -101.28013]], dtype=float32)
time = 38139	action = 1	current_phase = 0	next_phase = 1	reward = -264.274721	array([[-141.02556,  -90.02867]], dtype=float32)
time = 38147	action = 1	current_phase = 1	next_phase = 0	reward = -152.139028	array([[-132.3285 ,  -96.57447]], dtype=float32)
time = 38155	action = 1	current_phase = 0	next_phase = 1	reward = -61.574195	array([[-127.59858 ,  -97.293144]], dtype=float32)
time = 38163	action = 0	current_phase = 1	next_phase = 0	reward = -20.058830	array([[ -57.714592, -110.073395]], dtype=float32)
time = 38168	action = 0	current_phase = 1	next_phase = 0	reward = 1.310853	array([[-62.71505, -87.61501]], dtype=float32)
time = 38173	action = 0	current_phase = 1	next_phase = 0	reward = -1.531922	array([[-53.14337 , -79.742256]], dtype=float32)
time = 38178	action = 1	current_phase = 1	next_phase = 0	reward = -34.470709	array([[-58.360443, -52.71723 ]], dtype=float32)
time = 38186	action = 1	current_phase = 0	next_phase = 1	reward = -15.260933	array([[-41.260666, -34.81673 ]], dtype=float32)
time = 38194	action = 1	current_phase = 1	next_phase = 0	reward = -31.044064	array([[-69.6738  , -43.599487]], dtype=float32)
time = 38202	action = 1	current_phase = 0	next_phase = 1	reward = -5.569086	array([[-41.440132, -30.437508]], dtype=float32)
time = 38210	action = 1	current_phase = 1	next_phase = 0	reward = -21.923249	array([[-53.68882, -43.12028]], dtype=float32)
time = 38218	action = 0	current_phase = 0	next_phase = 1	reward = -15.227534	array([[-34.800262, -36.81447 ]], dtype=float32)
time = 38223	action = 1	current_phase = 0	next_phase = 1	reward = -8.054375	array([[-40.0265  , -35.465073]], dtype=float32)
time = 38231	action = 1	current_phase = 1	next_phase = 0	reward = -28.752854	array([[-55.023895, -45.127045]], dtype=float32)
time = 38239	action = 1	current_phase = 0	next_phase = 1	reward = -7.871715	array([[-42.757008, -28.419662]], dtype=float32)
time = 38247	action = 1	current_phase = 1	next_phase = 0	reward = -28.290580	array([[-52.414722, -44.397408]], dtype=float32)
time = 38255	action = 1	current_phase = 0	next_phase = 1	reward = -10.064490	array([[-52.460907, -37.007843]], dtype=float32)
time = 38263	action = 1	current_phase = 1	next_phase = 0	reward = -27.439873	array([[-49.64431, -41.69537]], dtype=float32)
time = 38271	action = 0	current_phase = 0	next_phase = 1	reward = -18.252471	array([[-35.427948, -47.55886 ]], dtype=float32)
time = 38276	action = 1	current_phase = 0	next_phase = 1	reward = -17.897345	array([[-52.581055, -39.784454]], dtype=float32)
time = 38284	action = 1	current_phase = 1	next_phase = 0	reward = -29.594342	array([[-63.55549, -46.00924]], dtype=float32)
time = 38292	action = 1	current_phase = 0	next_phase = 1	reward = -12.150761	array([[-44.956573, -32.561363]], dtype=float32)
time = 38300	action = 1	current_phase = 1	next_phase = 0	reward = -32.033120	array([[-72.86551, -72.68367]], dtype=float32)
time = 38308	action = 1	current_phase = 0	next_phase = 1	reward = -23.274252	array([[-46.64746, -33.43538]], dtype=float32)
time = 38316	action = 1	current_phase = 1	next_phase = 0	reward = -30.976839	array([[-58.232018, -44.79951 ]], dtype=float32)
time = 38324	action = 1	current_phase = 0	next_phase = 1	reward = -10.071299	array([[-46.66892 , -35.933517]], dtype=float32)
time = 38332	action = 1	current_phase = 1	next_phase = 0	reward = -19.079515	array([[-58.00841 , -48.718937]], dtype=float32)
time = 38340	action = 1	current_phase = 0	next_phase = 1	reward = -7.044619	array([[-39.233543, -37.00367 ]], dtype=float32)
time = 38348	action = 1	current_phase = 1	next_phase = 0	reward = -23.510230	array([[-51.178635, -44.640057]], dtype=float32)
time = 38356	action = 1	current_phase = 0	next_phase = 1	reward = -5.186096	array([[-47.51032 , -31.655146]], dtype=float32)
time = 38364	action = 1	current_phase = 1	next_phase = 0	reward = -18.463819	array([[-52.944065, -43.965958]], dtype=float32)
time = 38372	action = 0	current_phase = 0	next_phase = 1	reward = -12.441468	array([[-42.54961 , -46.188423]], dtype=float32)
time = 38377	action = 1	current_phase = 0	next_phase = 1	reward = -4.905087	array([[-39.016087, -33.41986 ]], dtype=float32)
time = 38385	action = 1	current_phase = 1	next_phase = 0	reward = -23.271751	array([[-58.07045 , -42.477802]], dtype=float32)
time = 38393	action = 1	current_phase = 0	next_phase = 1	reward = -10.136948	array([[-45.501972, -39.621315]], dtype=float32)
time = 38401	action = 1	current_phase = 1	next_phase = 0	reward = -24.746800	array([[-53.082726, -46.125587]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 7s - loss: 13465.4298 - val_loss: 12749.4016
Epoch 2/50
 - 6s - loss: 13457.1546 - val_loss: 12737.4144
Epoch 3/50
 - 6s - loss: 13438.0548 - val_loss: 12726.6485
Epoch 4/50
 - 6s - loss: 13422.4792 - val_loss: 12714.0933
Epoch 5/50
 - 5s - loss: 13413.2699 - val_loss: 12699.5484
Epoch 6/50
 - 6s - loss: 13400.6814 - val_loss: 12690.2163
Epoch 7/50
 - 5s - loss: 13389.5109 - val_loss: 12678.6924
Epoch 8/50
 - 5s - loss: 13372.7646 - val_loss: 12665.5783
Epoch 9/50
 - 5s - loss: 13365.1547 - val_loss: 12653.5216
Epoch 10/50
 - 4s - loss: 13351.7840 - val_loss: 12638.2712
Epoch 11/50
 - 5s - loss: 13337.9027 - val_loss: 12632.8697
Epoch 12/50
 - 5s - loss: 13321.9946 - val_loss: 12619.4967
Epoch 13/50
 - 6s - loss: 13314.3680 - val_loss: 12606.0726
Epoch 14/50
 - 6s - loss: 13308.1481 - val_loss: 12594.7058
Epoch 15/50
 - 5s - loss: 13291.1260 - val_loss: 12565.2864
Epoch 16/50
 - 7s - loss: 13275.4771 - val_loss: 12562.7310
Epoch 17/50
 - 5s - loss: 13267.0979 - val_loss: 12555.1076
Epoch 18/50
 - 5s - loss: 13248.3167 - val_loss: 12529.6938
Epoch 19/50
 - 6s - loss: 13243.4969 - val_loss: 12517.7010
Epoch 20/50
 - 5s - loss: 13226.2572 - val_loss: 12512.9735
Epoch 21/50
 - 3004s - loss: 13216.4116 - val_loss: 12499.5641
Epoch 22/50
 - 4s - loss: 13205.4882 - val_loss: 12488.9778
Epoch 23/50
 - 4s - loss: 13196.0911 - val_loss: 12483.3935
Epoch 24/50
 - 4s - loss: 13178.5931 - val_loss: 12471.0410
Epoch 25/50
 - 4s - loss: 13166.8746 - val_loss: 12463.9622
Epoch 26/50
 - 4s - loss: 13146.2721 - val_loss: 12446.1831
Epoch 27/50
 - 4s - loss: 13150.9968 - val_loss: 12434.9804
Epoch 28/50
 - 4s - loss: 13132.2375 - val_loss: 12423.4950
Epoch 29/50
^[[A^[[A - 8s - loss: 13119.6853 - val_loss: 12406.8600
Epoch 30/50
 - 4s - loss: 13109.1882 - val_loss: 12401.7237
Epoch 31/50
 - 4s - loss: 13094.6097 - val_loss: 12388.3488
Epoch 32/50
 - 5s - loss: 13092.6724 - val_loss: 12372.3819
Epoch 33/50
 - 5s - loss: 13067.8112 - val_loss: 12368.4159
Epoch 34/50
 - 4s - loss: 13061.1602 - val_loss: 12358.0597
Epoch 35/50
 - 5s - loss: 13033.9499 - val_loss: 12339.4406
Epoch 36/50
 - 4s - loss: 13033.2961 - val_loss: 12335.0496
Epoch 37/50
 - 4s - loss: 13026.6607 - val_loss: 12320.2764
Epoch 38/50
 - 4s - loss: 13010.3090 - val_loss: 12308.8912
Epoch 39/50
 - 4s - loss: 12990.4891 - val_loss: 12295.1256
Epoch 40/50
 - 4s - loss: 12989.8969 - val_loss: 12287.7577
Epoch 41/50
 - 4s - loss: 12992.2919 - val_loss: 12279.5885
Epoch 42/50
 - 4s - loss: 12971.4361 - val_loss: 12267.3061
Epoch 43/50
 - 4s - loss: 12959.1730 - val_loss: 12254.0824
Epoch 44/50
 - 4s - loss: 12934.9818 - val_loss: 12245.9599
Epoch 45/50
 - 5s - loss: 12935.9037 - val_loss: 12231.6608
Epoch 46/50
 - 4s - loss: 12920.2169 - val_loss: 12220.6185
Epoch 47/50
 - 4s - loss: 12896.7115 - val_loss: 12204.8871
Epoch 48/50
 - 4s - loss: 12902.8524 - val_loss: 12198.8412
Epoch 49/50
 - 4s - loss: 12885.3533 - val_loss: 12184.4751
Epoch 50/50
 - 4s - loss: 12871.2854 - val_loss: 12172.7105
length of memory (state 0, action 0): 1003, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 332, after forget
length of memory (state 1, action 0): 520, after forget
length of memory (state 1, action 1): 320, after forget
time = 38409	action = 1	current_phase = 0	next_phase = 1	reward = -3.772144	array([[-45.495213, -37.28117 ]], dtype=float32)
time = 38417	action = 1	current_phase = 1	next_phase = 0	reward = -21.696119	array([[-53.367863, -45.963577]], dtype=float32)
time = 38425	action = 0	current_phase = 0	next_phase = 1	reward = -15.015973	array([[-18.260246, -67.17856 ]], dtype=float32)
time = 38430	action = 1	current_phase = 0	next_phase = 1	reward = -11.758530	array([[-44.15157 , -35.568382]], dtype=float32)
time = 38438	action = 1	current_phase = 1	next_phase = 0	reward = -25.541547	array([[-53.562656, -45.88714 ]], dtype=float32)
time = 38446	action = 0	current_phase = 0	next_phase = 1	reward = -18.802789	array([[-38.41169, -42.45039]], dtype=float32)
time = 38451	action = 1	current_phase = 0	next_phase = 1	reward = -17.082235	array([[-45.153004, -35.497574]], dtype=float32)
time = 38459	action = 1	current_phase = 1	next_phase = 0	reward = -33.997930	array([[-61.085266, -48.32072 ]], dtype=float32)
time = 38467	action = 1	current_phase = 0	next_phase = 1	reward = -12.268396	array([[-45.466213, -34.41428 ]], dtype=float32)
time = 38475	action = 1	current_phase = 1	next_phase = 0	reward = -31.352262	array([[-57.32973, -46.29696]], dtype=float32)
time = 38483	action = 0	current_phase = 0	next_phase = 1	reward = -20.302811	array([[-29.42653 , -52.365566]], dtype=float32)
time = 38488	action = 1	current_phase = 0	next_phase = 1	reward = -13.710517	array([[-45.330467, -34.476433]], dtype=float32)
time = 38496	action = 1	current_phase = 1	next_phase = 0	reward = -30.707499	array([[-53.131126, -45.58768 ]], dtype=float32)
time = 38504	action = 1	current_phase = 0	next_phase = 1	reward = -13.210738	array([[-42.530083, -37.202454]], dtype=float32)
time = 38512	action = 1	current_phase = 1	next_phase = 0	reward = -28.148706	array([[-52.670567, -45.730186]], dtype=float32)
time = 38520	action = 1	current_phase = 0	next_phase = 1	reward = -14.739613	array([[-45.113174, -34.764477]], dtype=float32)
time = 38528	action = 1	current_phase = 1	next_phase = 0	reward = -25.434520	array([[-52.331234, -45.61879 ]], dtype=float32)
time = 38536	action = 1	current_phase = 0	next_phase = 1	reward = 3.139843	array([[-44.04593 , -35.648983]], dtype=float32)
time = 38544	action = 1	current_phase = 1	next_phase = 0	reward = -19.726440	array([[-55.410297, -45.780334]], dtype=float32)
time = 38552	action = 1	current_phase = 0	next_phase = 1	reward = 4.602107	array([[-42.046303, -38.17154 ]], dtype=float32)
time = 38560	action = 1	current_phase = 1	next_phase = 0	reward = -20.099499	array([[-72.07006 , -53.452023]], dtype=float32)
time = 38568	action = 1	current_phase = 0	next_phase = 1	reward = 0.663498	array([[-45.87033, -38.05386]], dtype=float32)
time = 38576	action = 1	current_phase = 1	next_phase = 0	reward = -17.852475	array([[-55.94599 , -46.954327]], dtype=float32)
time = 38584	action = 0	current_phase = 0	next_phase = 1	reward = -12.434535	array([[-31.39146, -51.37934]], dtype=float32)
time = 38589	action = 0	current_phase = 0	next_phase = 1	reward = -16.206724	array([[-38.03659 , -45.701183]], dtype=float32)
time = 38594	action = 1	current_phase = 0	next_phase = 1	reward = -17.044047	array([[-42.407906, -37.987255]], dtype=float32)
time = 38602	action = 1	current_phase = 1	next_phase = 0	reward = -34.864351	array([[-61.951996, -47.18772 ]], dtype=float32)
time = 38610	action = 1	current_phase = 0	next_phase = 1	reward = -18.319835	array([[-44.222366, -35.576267]], dtype=float32)
time = 38618	action = 1	current_phase = 1	next_phase = 0	reward = -34.516071	array([[-53.333813, -45.78177 ]], dtype=float32)
time = 38626	action = 0	current_phase = 0	next_phase = 1	reward = -23.767222	array([[-33.65055 , -48.052002]], dtype=float32)
time = 38631	action = 1	current_phase = 0	next_phase = 1	reward = -22.911535	array([[-44.165237, -35.779266]], dtype=float32)
time = 38639	action = 1	current_phase = 1	next_phase = 0	reward = -39.162643	array([[-54.49263 , -45.780197]], dtype=float32)
time = 38647	action = 1	current_phase = 0	next_phase = 1	reward = -23.682680	array([[-45.05239, -34.93807]], dtype=float32)
time = 38655	action = 1	current_phase = 1	next_phase = 0	reward = -37.428549	array([[-52.357426, -45.69865 ]], dtype=float32)
time = 38663	action = 1	current_phase = 0	next_phase = 1	reward = -13.927109	array([[-43.637764, -36.10058 ]], dtype=float32)
time = 38671	action = 1	current_phase = 1	next_phase = 0	reward = -32.457004	array([[-52.311153, -45.64102 ]], dtype=float32)
time = 38679	action = 0	current_phase = 0	next_phase = 1	reward = -17.839648	array([[-37.478775, -43.613255]], dtype=float32)
time = 38684	action = 1	current_phase = 0	next_phase = 1	reward = -12.971680	array([[-42.96159 , -36.974087]], dtype=float32)
time = 38692	action = 1	current_phase = 1	next_phase = 0	reward = -26.183559	array([[-52.5363 , -45.65466]], dtype=float32)
time = 38700	action = 0	current_phase = 0	next_phase = 1	reward = -17.092072	array([[-41.82042, -42.29878]], dtype=float32)
time = 38705	action = 1	current_phase = 0	next_phase = 1	reward = -10.323165	array([[-52.258   , -44.892773]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 10198.6151 - val_loss: 14277.3492
Epoch 2/50
 - 4s - loss: 10195.0495 - val_loss: 14271.3015
Epoch 3/50
 - 4s - loss: 10176.9730 - val_loss: 14269.5875
Epoch 4/50
 - 4s - loss: 10168.1144 - val_loss: 14263.6966
Epoch 5/50
 - 4s - loss: 10161.5953 - val_loss: 14249.1746
Epoch 6/50
 - 4s - loss: 10150.1461 - val_loss: 14237.1948
Epoch 7/50
 - 4s - loss: 10139.9216 - val_loss: 14232.4650
Epoch 8/50
 - 4s - loss: 10133.0046 - val_loss: 14217.5362
Epoch 9/50
 - 4s - loss: 10119.0557 - val_loss: 14222.1407
Epoch 10/50
 - 4s - loss: 10112.6654 - val_loss: 14214.3073
Epoch 11/50
 - 4s - loss: 10105.0801 - val_loss: 14196.9507
Epoch 12/50
 - 4s - loss: 10096.9398 - val_loss: 14202.9064
Epoch 13/50
 - 4s - loss: 10085.4776 - val_loss: 14182.0956
Epoch 14/50
 - 4s - loss: 10072.4940 - val_loss: 14168.6808
Epoch 15/50
 - 4s - loss: 10071.3626 - val_loss: 14160.6011
Epoch 16/50
 - 4s - loss: 10051.5959 - val_loss: 14160.6581
Epoch 17/50
 - 4s - loss: 10039.9834 - val_loss: 14151.1449
Epoch 18/50
 - 4s - loss: 10034.3574 - val_loss: 14145.0706
Epoch 19/50
 - 4s - loss: 10022.5726 - val_loss: 14142.4139
Epoch 20/50
 - 4s - loss: 10016.7729 - val_loss: 14120.0936
Epoch 21/50
 - 4s - loss: 10004.0293 - val_loss: 14121.9707
Epoch 22/50
 - 4s - loss: 9991.1501 - val_loss: 14105.5214
Epoch 23/50
 - 4s - loss: 9984.9012 - val_loss: 14109.0319
Epoch 24/50
 - 4s - loss: 9975.5152 - val_loss: 14106.0944
Epoch 25/50
 - 4s - loss: 9967.5737 - val_loss: 14088.3189
Epoch 26/50
 - 4s - loss: 9957.8268 - val_loss: 14073.4502
Epoch 27/50
 - 4s - loss: 9947.9171 - val_loss: 14073.7688
Epoch 28/50
 - 4s - loss: 9946.6625 - val_loss: 14064.9229
Epoch 29/50
 - 4s - loss: 9927.2087 - val_loss: 14061.8816
Epoch 30/50
 - 4s - loss: 9918.3397 - val_loss: 14049.8729
Epoch 31/50
 - 4s - loss: 9913.6064 - val_loss: 14048.6943
Epoch 32/50
 - 4s - loss: 9916.1770 - val_loss: 14036.8020
Epoch 33/50
 - 4s - loss: 9893.5884 - val_loss: 14023.4010
Epoch 34/50
 - 4s - loss: 9889.8995 - val_loss: 14011.9039
Epoch 35/50
 - 4s - loss: 9883.0375 - val_loss: 13998.6112
Epoch 36/50
 - 4s - loss: 9874.5458 - val_loss: 13998.7936
Epoch 37/50
 - 4s - loss: 9862.2032 - val_loss: 13990.4449
Epoch 38/50
 - 4s - loss: 9847.0680 - val_loss: 13982.5035
Epoch 39/50
 - 4s - loss: 9847.7675 - val_loss: 13970.0700
Epoch 40/50
 - 4s - loss: 9842.9974 - val_loss: 13965.2505
Epoch 41/50
 - 4s - loss: 9823.4835 - val_loss: 13953.4603
Epoch 42/50
 - 4s - loss: 9813.2281 - val_loss: 13948.4035
Epoch 43/50
 - 4s - loss: 9805.3477 - val_loss: 13917.4850
Epoch 44/50
 - 4s - loss: 9802.6798 - val_loss: 13932.6925
Epoch 45/50
 - 4s - loss: 9786.2652 - val_loss: 13921.4113
Epoch 46/50
 - 4s - loss: 9776.0818 - val_loss: 13917.5178
Epoch 47/50
 - 4s - loss: 9771.4923 - val_loss: 13914.9181
Epoch 48/50
 - 4s - loss: 9768.7929 - val_loss: 13899.2897
Epoch 49/50
 - 4s - loss: 9757.3220 - val_loss: 13884.3805
Epoch 50/50
 - 4s - loss: 9741.4466 - val_loss: 13880.3669
length of memory (state 0, action 0): 1008, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 349, after forget
length of memory (state 1, action 0): 520, after forget
length of memory (state 1, action 1): 336, after forget
time = 38713	action = 1	current_phase = 1	next_phase = 0	reward = -28.982611	array([[-57.720673, -44.959846]], dtype=float32)
time = 38721	action = 0	current_phase = 0	next_phase = 1	reward = -20.969861	array([[-40.272434, -46.883003]], dtype=float32)
time = 38726	action = 1	current_phase = 0	next_phase = 1	reward = -21.133399	array([[-44.111023, -42.041935]], dtype=float32)
time = 38734	action = 1	current_phase = 1	next_phase = 0	reward = -38.905939	array([[-66.80643, -45.59954]], dtype=float32)
time = 38742	action = 0	current_phase = 0	next_phase = 1	reward = -27.850991	array([[-38.989143, -54.073715]], dtype=float32)
time = 38747	action = 0	current_phase = 0	next_phase = 1	reward = -31.024538	array([[-40.255062, -54.103294]], dtype=float32)
time = 38752	action = 1	current_phase = 0	next_phase = 1	reward = -35.953826	array([[-49.943344, -48.50359 ]], dtype=float32)
time = 38760	action = 0	current_phase = 1	next_phase = 0	reward = -6.008454	array([[ -58.29966, -102.90447]], dtype=float32)
time = 38765	action = 1	current_phase = 1	next_phase = 0	reward = -48.249687	array([[-53.96955 , -46.558224]], dtype=float32)
time = 38773	action = 1	current_phase = 0	next_phase = 1	reward = -32.503884	array([[-70.35345 , -62.523663]], dtype=float32)
time = 38781	action = 1	current_phase = 1	next_phase = 0	reward = -47.399083	array([[-52.531822, -50.25886 ]], dtype=float32)
time = 38789	action = 1	current_phase = 0	next_phase = 1	reward = -27.405400	array([[-72.856094, -53.494453]], dtype=float32)
time = 38797	action = 0	current_phase = 1	next_phase = 0	reward = -4.279018	array([[-51.834465, -55.734493]], dtype=float32)
time = 38802	action = 0	current_phase = 1	next_phase = 0	reward = 3.176826	array([[-41.098152, -81.99218 ]], dtype=float32)
time = 38807	action = 1	current_phase = 1	next_phase = 0	reward = -27.072010	array([[-46.79148 , -31.415058]], dtype=float32)
time = 38815	action = 1	current_phase = 0	next_phase = 1	reward = -7.235276	array([[-43.00478 , -41.066875]], dtype=float32)
time = 38823	action = 1	current_phase = 1	next_phase = 0	reward = -19.650186	array([[-48.962997, -41.075844]], dtype=float32)
time = 38831	action = 1	current_phase = 0	next_phase = 1	reward = -5.787781	array([[-42.839584, -40.446465]], dtype=float32)
time = 38839	action = 1	current_phase = 1	next_phase = 0	reward = -17.327351	array([[-53.102097, -42.62851 ]], dtype=float32)
time = 38847	action = 0	current_phase = 0	next_phase = 1	reward = -13.509491	array([[-32.9788  , -43.102325]], dtype=float32)
time = 38852	action = 0	current_phase = 0	next_phase = 1	reward = -16.681664	array([[-39.141815, -47.11705 ]], dtype=float32)
time = 38857	action = 0	current_phase = 0	next_phase = 1	reward = -21.490970	array([[-39.42467, -49.55839]], dtype=float32)
time = 38862	action = 0	current_phase = 0	next_phase = 1	reward = -26.518099	array([[-41.3759 , -45.98426]], dtype=float32)
time = 38867	action = 1	current_phase = 0	next_phase = 1	reward = -36.108380	array([[-52.191704, -48.944477]], dtype=float32)
time = 38875	action = 1	current_phase = 1	next_phase = 0	reward = -52.664610	array([[-89.973495, -53.189102]], dtype=float32)
time = 38883	action = 0	current_phase = 0	next_phase = 1	reward = -36.404076	array([[-88.791016, -89.48312 ]], dtype=float32)
time = 38888	action = 0	current_phase = 0	next_phase = 1	reward = -40.956714	array([[-83.079956, -87.97413 ]], dtype=float32)
time = 38893	action = 0	current_phase = 0	next_phase = 1	reward = -46.328763	array([[ -87.82851, -107.80014]], dtype=float32)
time = 38898	action = 0	current_phase = 0	next_phase = 1	reward = -51.862887	array([[-103.01524, -103.15565]], dtype=float32)
time = 38903	action = 0	current_phase = 0	next_phase = 1	reward = -57.975534	array([[ -74.89806, -134.487  ]], dtype=float32)
time = 38908	action = 1	current_phase = 0	next_phase = 1	reward = -82.601473	array([[-115.30948, -115.17218]], dtype=float32)
time = 38916	action = 0	current_phase = 1	next_phase = 0	reward = -42.961433	array([[ -90.28371, -130.57878]], dtype=float32)
time = 38921	action = 0	current_phase = 1	next_phase = 0	reward = -37.438539	array([[ -90.004036, -127.50361 ]], dtype=float32)
time = 38926	action = 0	current_phase = 1	next_phase = 0	reward = -38.713973	array([[ -87.48707 , -123.754875]], dtype=float32)
time = 38931	action = 0	current_phase = 1	next_phase = 0	reward = -43.549729	array([[ -88.755974, -124.65932 ]], dtype=float32)
time = 38936	action = 0	current_phase = 1	next_phase = 0	reward = -37.682974	array([[ -65.2798  , -111.902885]], dtype=float32)
time = 38941	action = 0	current_phase = 1	next_phase = 0	reward = -45.509449	array([[ -58.493454, -108.635284]], dtype=float32)
time = 38946	action = 0	current_phase = 1	next_phase = 0	reward = -43.488744	array([[ -56.772873, -107.38058 ]], dtype=float32)
time = 38951	action = 0	current_phase = 1	next_phase = 0	reward = -33.508616	array([[ -59.213837, -108.62732 ]], dtype=float32)
time = 38956	action = 0	current_phase = 1	next_phase = 0	reward = -21.881036	array([[ -57.808327, -106.833694]], dtype=float32)
time = 38961	action = 1	current_phase = 1	next_phase = 0	reward = -38.892083	array([[-52.816597, -46.849716]], dtype=float32)
time = 38969	action = 1	current_phase = 0	next_phase = 1	reward = -20.705792	array([[-34.407806, -28.550766]], dtype=float32)
time = 38977	action = 1	current_phase = 1	next_phase = 0	reward = -19.686762	array([[-47.541603, -30.421066]], dtype=float32)
time = 38985	action = 1	current_phase = 0	next_phase = 1	reward = -14.208224	array([[-26.65039 , -26.632479]], dtype=float32)
time = 38993	action = 1	current_phase = 1	next_phase = 0	reward = -29.904145	array([[-46.948814, -31.311024]], dtype=float32)
time = 39001	action = 1	current_phase = 0	next_phase = 1	reward = -21.531054	array([[-28.27732 , -26.028952]], dtype=float32)
time = 39009	action = 1	current_phase = 1	next_phase = 0	reward = -34.439140	array([[-55.603523, -45.860416]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 10523.5009 - val_loss: 22307.1178
Epoch 2/50
 - 4s - loss: 10510.1846 - val_loss: 22263.9026
Epoch 3/50
 - 4s - loss: 10490.9394 - val_loss: 22250.3503
Epoch 4/50
 - 4s - loss: 10483.8703 - val_loss: 22222.8164
Epoch 5/50
 - 4s - loss: 10471.4602 - val_loss: 22201.4236
Epoch 6/50
 - 4s - loss: 10459.0461 - val_loss: 22191.6869
Epoch 7/50
 - 4s - loss: 10445.3108 - val_loss: 22172.7504
Epoch 8/50
 - 4s - loss: 10434.6899 - val_loss: 22163.4614
Epoch 9/50
 - 4s - loss: 10424.9625 - val_loss: 22150.1257
Epoch 10/50
 - 4s - loss: 10416.9693 - val_loss: 22134.4236
Epoch 11/50
 - 4s - loss: 10404.8289 - val_loss: 22116.1465
Epoch 12/50
 - 4s - loss: 10399.2143 - val_loss: 22099.4053
Epoch 13/50
 - 4s - loss: 10385.4657 - val_loss: 22075.9614
Epoch 14/50
 - 4s - loss: 10373.0751 - val_loss: 22064.1435
Epoch 15/50
 - 4s - loss: 10365.9945 - val_loss: 22054.2802
Epoch 16/50
 - 4s - loss: 10358.6019 - val_loss: 22025.2176
Epoch 17/50
 - 4s - loss: 10342.7093 - val_loss: 22004.4985
Epoch 18/50
 - 4s - loss: 10330.1331 - val_loss: 22003.3699
Epoch 19/50
 - 4s - loss: 10327.6008 - val_loss: 21971.4470
Epoch 20/50
 - 4s - loss: 10314.6379 - val_loss: 21961.2145
Epoch 21/50
 - 4s - loss: 10313.0500 - val_loss: 21954.6045
Epoch 22/50
 - 4s - loss: 10297.0848 - val_loss: 21934.4561
Epoch 23/50
 - 4s - loss: 10289.5035 - val_loss: 21916.0873
Epoch 24/50
 - 4s - loss: 10280.7715 - val_loss: 21905.6898
Epoch 25/50
 - 4s - loss: 10272.9193 - val_loss: 21886.7351
Epoch 26/50
 - 4s - loss: 10261.6603 - val_loss: 21864.5510
Epoch 27/50
 - 4s - loss: 10244.2558 - val_loss: 21848.8394
Epoch 28/50
 - 4s - loss: 10235.7256 - val_loss: 21838.1961
Epoch 29/50
 - 4s - loss: 10227.0230 - val_loss: 21819.8209
Epoch 30/50
 - 4s - loss: 10220.6783 - val_loss: 21806.1763
Epoch 31/50
 - 4s - loss: 10206.8752 - val_loss: 21787.5274
Epoch 32/50
 - 4s - loss: 10205.5300 - val_loss: 21778.5403
Epoch 33/50
 - 4s - loss: 10201.2422 - val_loss: 21774.8430
Epoch 34/50
 - 4s - loss: 10184.0485 - val_loss: 21753.0302
Epoch 35/50
 - 4s - loss: 10171.7609 - val_loss: 21733.5660
Epoch 36/50
 - 6s - loss: 10165.0138 - val_loss: 21725.1538
Epoch 37/50
 - 4s - loss: 10159.1652 - val_loss: 21696.5629
Epoch 38/50
 - 4s - loss: 10148.9433 - val_loss: 21684.2803
Epoch 39/50
 - 4s - loss: 10136.5471 - val_loss: 21666.3757
Epoch 40/50
 - 4s - loss: 10123.9328 - val_loss: 21656.0562
Epoch 41/50
 - 4s - loss: 10121.6506 - val_loss: 21657.3192
Epoch 42/50
 - 4s - loss: 10106.8851 - val_loss: 21624.9949
Epoch 43/50
 - 4s - loss: 10098.6356 - val_loss: 21603.6280
Epoch 44/50
 - 4s - loss: 10092.8828 - val_loss: 21588.3289
Epoch 45/50
 - 4s - loss: 10082.9645 - val_loss: 21575.0957
Epoch 46/50
 - 4s - loss: 10073.1878 - val_loss: 21566.0369
Epoch 47/50
 - 4s - loss: 10061.5471 - val_loss: 21550.2825
Epoch 48/50
 - 4s - loss: 10050.5862 - val_loss: 21531.4422
Epoch 49/50
 - 4s - loss: 10046.5883 - val_loss: 21510.1561
Epoch 50/50
 - 4s - loss: 10029.5309 - val_loss: 21513.6076
length of memory (state 0, action 0): 1012, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 360, after forget
length of memory (state 1, action 0): 532, after forget
length of memory (state 1, action 1): 348, after forget
time = 39017	action = 1	current_phase = 0	next_phase = 1	reward = -24.021981	array([[-43.2763  , -39.475086]], dtype=float32)
time = 39025	action = 1	current_phase = 1	next_phase = 0	reward = -38.958455	array([[-55.463852, -48.051815]], dtype=float32)
time = 39033	action = 1	current_phase = 0	next_phase = 1	reward = -29.284437	array([[-43.13722, -39.52731]], dtype=float32)
time = 39041	action = 1	current_phase = 1	next_phase = 0	reward = -45.237590	array([[-61.587135, -51.00325 ]], dtype=float32)
time = 39049	action = 0	current_phase = 0	next_phase = 1	reward = -31.011216	array([[-57.163345, -73.57838 ]], dtype=float32)
time = 39054	action = 1	current_phase = 0	next_phase = 1	reward = -41.990303	array([[-75.10051 , -65.578094]], dtype=float32)
time = 39062	action = 1	current_phase = 1	next_phase = 0	reward = -57.261005	array([[-87.45113, -59.97395]], dtype=float32)
time = 39070	action = 0	current_phase = 0	next_phase = 1	reward = -38.085800	array([[-58.250248, -99.56662 ]], dtype=float32)
time = 39075	action = 1	current_phase = 0	next_phase = 1	reward = -49.294600	array([[-116.297134,  -97.68547 ]], dtype=float32)
time = 39083	action = 1	current_phase = 1	next_phase = 0	reward = -61.236234	array([[-76.16618, -63.88459]], dtype=float32)
time = 39091	action = 0	current_phase = 0	next_phase = 1	reward = -39.421486	array([[ -75.92687, -111.7226 ]], dtype=float32)
time = 39096	action = 1	current_phase = 0	next_phase = 1	reward = -49.441879	array([[-103.012924,  -88.07838 ]], dtype=float32)
time = 39104	action = 1	current_phase = 1	next_phase = 0	reward = -61.577514	array([[-58.8385 , -55.07045]], dtype=float32)
time = 39112	action = 0	current_phase = 0	next_phase = 1	reward = -41.104045	array([[-58.90076 , -92.548965]], dtype=float32)
time = 39117	action = 1	current_phase = 0	next_phase = 1	reward = -57.222318	array([[-100.12276,  -90.73212]], dtype=float32)
time = 39125	action = 0	current_phase = 1	next_phase = 0	reward = -22.537456	array([[ -60.488483, -107.88262 ]], dtype=float32)
time = 39130	action = 0	current_phase = 1	next_phase = 0	reward = -10.023991	array([[-56.262394, -78.44491 ]], dtype=float32)
time = 39135	action = 1	current_phase = 1	next_phase = 0	reward = -46.647707	array([[-55.83908 , -52.334698]], dtype=float32)
time = 39143	action = 1	current_phase = 0	next_phase = 1	reward = -34.167174	array([[-46.61405 , -44.092754]], dtype=float32)
time = 39151	action = 1	current_phase = 1	next_phase = 0	reward = -39.483592	array([[-55.379627, -48.174488]], dtype=float32)
time = 39159	action = 1	current_phase = 0	next_phase = 1	reward = -20.798420	array([[-42.88298 , -39.382626]], dtype=float32)
time = 39167	action = 1	current_phase = 1	next_phase = 0	reward = -24.829558	array([[-46.057507, -32.4143  ]], dtype=float32)
time = 39175	action = 1	current_phase = 0	next_phase = 1	reward = -17.923295	array([[-40.755867, -38.323868]], dtype=float32)
time = 39183	action = 1	current_phase = 1	next_phase = 0	reward = -26.936222	array([[-52.220554, -42.891045]], dtype=float32)
time = 39191	action = 0	current_phase = 0	next_phase = 1	reward = -20.078428	array([[-31.634022, -47.6622  ]], dtype=float32)
time = 39196	action = 1	current_phase = 0	next_phase = 1	reward = -26.692363	array([[-42.844578, -39.466614]], dtype=float32)
time = 39204	action = 1	current_phase = 1	next_phase = 0	reward = -38.727364	array([[-56.299946, -48.559387]], dtype=float32)
time = 39212	action = 1	current_phase = 0	next_phase = 1	reward = -35.592374	array([[-42.949043, -39.357826]], dtype=float32)
time = 39220	action = 1	current_phase = 1	next_phase = 0	reward = -46.163345	array([[-57.045105, -48.98855 ]], dtype=float32)
time = 39228	action = 1	current_phase = 0	next_phase = 1	reward = -36.152388	array([[-41.996628, -40.29179 ]], dtype=float32)
time = 39236	action = 1	current_phase = 1	next_phase = 0	reward = -49.993902	array([[-58.727676, -49.472717]], dtype=float32)
time = 39244	action = 0	current_phase = 0	next_phase = 1	reward = -34.307906	array([[-26.908638, -53.623688]], dtype=float32)
time = 39249	action = 1	current_phase = 0	next_phase = 1	reward = -39.671200	array([[-45.96527 , -42.984596]], dtype=float32)
time = 39257	action = 1	current_phase = 1	next_phase = 0	reward = -50.958174	array([[-78.44277 , -59.374336]], dtype=float32)
time = 39265	action = 0	current_phase = 0	next_phase = 1	reward = -33.669684	array([[-37.41909 , -47.169594]], dtype=float32)
time = 39270	action = 1	current_phase = 0	next_phase = 1	reward = -41.250472	array([[-64.67253, -55.71873]], dtype=float32)
time = 39278	action = 1	current_phase = 1	next_phase = 0	reward = -49.881761	array([[-75.30208 , -61.552578]], dtype=float32)
time = 39286	action = 0	current_phase = 0	next_phase = 1	reward = -30.891805	array([[-28.026169, -61.872932]], dtype=float32)
time = 39291	action = 0	current_phase = 0	next_phase = 1	reward = -32.419790	array([[-41.669083, -61.15699 ]], dtype=float32)
time = 39296	action = 1	current_phase = 0	next_phase = 1	reward = -43.318823	array([[-65.56938 , -51.463413]], dtype=float32)
time = 39304	action = 1	current_phase = 1	next_phase = 0	reward = -37.862520	array([[-56.641586, -54.957973]], dtype=float32)
time = 39312	action = 1	current_phase = 0	next_phase = 1	reward = -25.278821	array([[-44.179985, -39.751244]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 13761.1332 - val_loss: 10216.9806
Epoch 2/50
 - 4s - loss: 13746.9623 - val_loss: 10202.9624
Epoch 3/50
 - 4s - loss: 13717.8348 - val_loss: 10195.7476
Epoch 4/50
 - 4s - loss: 13702.0245 - val_loss: 10183.0092
Epoch 5/50
 - 4s - loss: 13699.8710 - val_loss: 10173.3994
Epoch 6/50
 - 4s - loss: 13682.0730 - val_loss: 10154.1560
Epoch 7/50
 - 4s - loss: 13666.4533 - val_loss: 10147.5318
Epoch 8/50
 - 5s - loss: 13646.4920 - val_loss: 10141.4400
Epoch 9/50
 - 5s - loss: 13631.0686 - val_loss: 10125.7681
Epoch 10/50
 - 4s - loss: 13636.9316 - val_loss: 10137.1767
Epoch 11/50
 - 4s - loss: 13615.9437 - val_loss: 10119.0763
Epoch 12/50
 - 4s - loss: 13597.4441 - val_loss: 10097.4220
Epoch 13/50
 - 5s - loss: 13590.6653 - val_loss: 10091.1268
Epoch 14/50
 - 4s - loss: 13579.7347 - val_loss: 10075.6646
Epoch 15/50
 - 4s - loss: 13566.2541 - val_loss: 10070.4698
Epoch 16/50
 - 4s - loss: 13546.0961 - val_loss: 10050.2689
Epoch 17/50
 - 4s - loss: 13550.9412 - val_loss: 10044.8736
Epoch 18/50
 - 4s - loss: 13529.6024 - val_loss: 10030.0780
Epoch 19/50
 - 4s - loss: 13520.8680 - val_loss: 10024.5613
Epoch 20/50
 - 4s - loss: 13495.2820 - val_loss: 10014.3287
Epoch 21/50
 - 4s - loss: 13490.9233 - val_loss: 10007.9158
Epoch 22/50
 - 4s - loss: 13476.1298 - val_loss: 9992.1073
Epoch 23/50
 - 4s - loss: 13466.3539 - val_loss: 9981.3669
Epoch 24/50
 - 5s - loss: 13459.8925 - val_loss: 9972.0662
Epoch 25/50
 - 4s - loss: 13449.1370 - val_loss: 9965.0915
Epoch 26/50
 - 4s - loss: 13431.5942 - val_loss: 9952.1426
Epoch 27/50
 - 4s - loss: 13412.4053 - val_loss: 9944.3801
Epoch 28/50
 - 4s - loss: 13408.9643 - val_loss: 9929.3246
Epoch 29/50
 - 4s - loss: 13391.1091 - val_loss: 9915.1271
Epoch 30/50
 - 5s - loss: 13374.8798 - val_loss: 9903.4220
Epoch 31/50
 - 4s - loss: 13369.5289 - val_loss: 9889.3872
Epoch 32/50
 - 4s - loss: 13360.6964 - val_loss: 9888.4545
Epoch 33/50
 - 5s - loss: 13339.2049 - val_loss: 9877.9697
Epoch 34/50
 - 4s - loss: 13333.7817 - val_loss: 9867.3153
Epoch 35/50
 - 4s - loss: 13314.8614 - val_loss: 9863.7479
Epoch 36/50
 - 4s - loss: 13304.9522 - val_loss: 9853.0900
Epoch 37/50
 - 4s - loss: 13295.1434 - val_loss: 9840.3027
Epoch 38/50
 - 4s - loss: 13283.5548 - val_loss: 9825.2046
Epoch 39/50
 - 4s - loss: 13272.7196 - val_loss: 9820.1919
Epoch 40/50
 - 4s - loss: 13258.3815 - val_loss: 9804.0767
Epoch 41/50
 - 4s - loss: 13241.2028 - val_loss: 9790.8029
Epoch 42/50
 - 4s - loss: 13233.0457 - val_loss: 9782.7918
Epoch 43/50
 - 4s - loss: 13224.4443 - val_loss: 9775.6599
Epoch 44/50
 - 4s - loss: 13214.7799 - val_loss: 9761.7965
Epoch 45/50
 - 4s - loss: 13207.0211 - val_loss: 9751.4329
Epoch 46/50
 - 4s - loss: 13190.5824 - val_loss: 9746.2900
Epoch 47/50
 - 4s - loss: 13179.8394 - val_loss: 9732.4612
Epoch 48/50
 - 4s - loss: 13169.5321 - val_loss: 9718.9250
Epoch 49/50
 - 4s - loss: 13149.2678 - val_loss: 9704.6248
Epoch 50/50
 - 4s - loss: 13140.5360 - val_loss: 9701.0243
length of memory (state 0, action 0): 1009, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 376, after forget
length of memory (state 1, action 0): 534, after forget
length of memory (state 1, action 1): 363, after forget
time = 39320	action = 0	current_phase = 1	next_phase = 0	reward = -0.104300	array([[-53.17028 , -63.011333]], dtype=float32)
time = 39325	action = 0	current_phase = 1	next_phase = 0	reward = 2.931502	array([[-53.21318 , -61.798702]], dtype=float32)
time = 39330	action = 0	current_phase = 1	next_phase = 0	reward = 5.643581	array([[-54.065758, -60.74244 ]], dtype=float32)
time = 39335	action = 0	current_phase = 1	next_phase = 0	reward = 7.462397	array([[-50.685356, -58.41704 ]], dtype=float32)
time = 39340	action = 0	current_phase = 1	next_phase = 0	reward = 1.754875	array([[-51.52397, -58.81057]], dtype=float32)
time = 39345	action = 0	current_phase = 1	next_phase = 0	reward = 6.635582	array([[-39.633617, -50.96916 ]], dtype=float32)
time = 39350	action = 0	current_phase = 1	next_phase = 0	reward = 0.438020	array([[-51.8062 , -58.50888]], dtype=float32)
time = 39355	action = 0	current_phase = 1	next_phase = 0	reward = 14.218459	array([[-52.55755 , -59.132294]], dtype=float32)
time = 39360	action = 1	current_phase = 1	next_phase = 0	reward = -10.088668	array([[-42.27124 , -41.716076]], dtype=float32)
time = 39368	action = 0	current_phase = 0	next_phase = 1	reward = -9.677971	array([[-11.8637085, -27.401148 ]], dtype=float32)
time = 39373	action = 0	current_phase = 0	next_phase = 1	reward = -12.610364	array([[-37.383694, -39.036568]], dtype=float32)
time = 39378	action = 0	current_phase = 0	next_phase = 1	reward = -16.793378	array([[-44.64629, -46.19768]], dtype=float32)
time = 39383	action = 0	current_phase = 0	next_phase = 1	reward = -21.258533	array([[-46.574455, -47.5431  ]], dtype=float32)
time = 39388	action = 0	current_phase = 0	next_phase = 1	reward = -24.858133	array([[-47.864326, -48.80439 ]], dtype=float32)
time = 39393	action = 1	current_phase = 0	next_phase = 1	reward = -34.380775	array([[-71.81412, -61.21106]], dtype=float32)
time = 39401	action = 0	current_phase = 1	next_phase = 0	reward = -19.802006	array([[ -61.942863, -111.53332 ]], dtype=float32)
time = 39406	action = 0	current_phase = 1	next_phase = 0	reward = -7.353098	array([[ -63.117477, -114.47969 ]], dtype=float32)
time = 39411	action = 0	current_phase = 1	next_phase = 0	reward = -13.848942	array([[-54.397446, -61.396954]], dtype=float32)
time = 39416	action = 0	current_phase = 1	next_phase = 0	reward = -13.884389	array([[-54.385246, -64.67983 ]], dtype=float32)
time = 39421	action = 0	current_phase = 1	next_phase = 0	reward = -11.181797	array([[-53.795784, -64.76784 ]], dtype=float32)
time = 39426	action = 0	current_phase = 1	next_phase = 0	reward = -9.071346	array([[-52.90766, -69.48817]], dtype=float32)
time = 39431	action = 0	current_phase = 1	next_phase = 0	reward = -6.625720	array([[-54.273354, -60.565224]], dtype=float32)
time = 39436	action = 0	current_phase = 1	next_phase = 0	reward = -9.223846	array([[-54.111282, -60.33567 ]], dtype=float32)
time = 39441	action = 0	current_phase = 1	next_phase = 0	reward = -5.618471	array([[-56.041245, -61.50517 ]], dtype=float32)
time = 39446	action = 0	current_phase = 1	next_phase = 0	reward = 5.891340	array([[-40.585106, -46.80664 ]], dtype=float32)
time = 39451	action = 0	current_phase = 1	next_phase = 0	reward = 5.651349	array([[-39.416954, -43.453236]], dtype=float32)
time = 39456	action = 1	current_phase = 1	next_phase = 0	reward = -16.977504	array([[-43.64373 , -41.492504]], dtype=float32)
time = 39464	action = 1	current_phase = 0	next_phase = 1	reward = -5.714470	array([[-35.53626, -34.51456]], dtype=float32)
time = 39472	action = 1	current_phase = 1	next_phase = 0	reward = -12.171616	array([[-42.224556, -41.56254 ]], dtype=float32)
time = 39480	action = 1	current_phase = 0	next_phase = 1	reward = -4.643721	array([[-35.121372, -34.48006 ]], dtype=float32)
time = 39488	action = 1	current_phase = 1	next_phase = 0	reward = -12.196861	array([[-42.156494, -41.570595]], dtype=float32)
time = 39496	action = 0	current_phase = 0	next_phase = 1	reward = -9.536211	array([[-43.672745, -45.359375]], dtype=float32)
time = 39501	action = 0	current_phase = 0	next_phase = 1	reward = -13.821728	array([[-43.224274, -45.376812]], dtype=float32)
time = 39506	action = 0	current_phase = 0	next_phase = 1	reward = -17.923867	array([[-45.791027, -47.265297]], dtype=float32)
time = 39511	action = 0	current_phase = 0	next_phase = 1	reward = -22.472039	array([[-47.085567, -48.127285]], dtype=float32)
time = 39516	action = 0	current_phase = 0	next_phase = 1	reward = -28.566899	array([[-49.2016  , -49.267986]], dtype=float32)
time = 39521	action = 1	current_phase = 0	next_phase = 1	reward = -41.990287	array([[-71.494156, -60.018524]], dtype=float32)
time = 39529	action = 0	current_phase = 1	next_phase = 0	reward = -21.494669	array([[ -62.681618, -113.05731 ]], dtype=float32)
time = 39534	action = 0	current_phase = 1	next_phase = 0	reward = -17.787974	array([[-56.296326, -73.88193 ]], dtype=float32)
time = 39539	action = 0	current_phase = 1	next_phase = 0	reward = -20.954908	array([[ -59.744133, -104.42751 ]], dtype=float32)
time = 39544	action = 0	current_phase = 1	next_phase = 0	reward = -20.333761	array([[-52.894653, -67.427284]], dtype=float32)
time = 39549	action = 0	current_phase = 1	next_phase = 0	reward = -19.253311	array([[-53.755424, -66.17282 ]], dtype=float32)
time = 39554	action = 0	current_phase = 1	next_phase = 0	reward = -21.684707	array([[-53.946724, -61.938416]], dtype=float32)
time = 39559	action = 0	current_phase = 1	next_phase = 0	reward = -19.082963	array([[-53.137672, -75.84798 ]], dtype=float32)
time = 39564	action = 0	current_phase = 1	next_phase = 0	reward = -16.665570	array([[-53.08132, -75.08613]], dtype=float32)
time = 39569	action = 0	current_phase = 1	next_phase = 0	reward = -9.716431	array([[-56.97325 , -62.081318]], dtype=float32)
time = 39574	action = 1	current_phase = 1	next_phase = 0	reward = -29.505386	array([[-43.51056 , -41.540237]], dtype=float32)
time = 39582	action = 0	current_phase = 0	next_phase = 1	reward = -21.460625	array([[-44.51387 , -46.046883]], dtype=float32)
time = 39587	action = 0	current_phase = 0	next_phase = 1	reward = -20.602843	array([[-43.792595, -45.26777 ]], dtype=float32)
time = 39592	action = 0	current_phase = 0	next_phase = 1	reward = -19.107951	array([[-45.405083, -46.623104]], dtype=float32)
time = 39597	action = 0	current_phase = 0	next_phase = 1	reward = -22.737412	array([[-41.916176, -42.29395 ]], dtype=float32)
time = 39602	action = 0	current_phase = 0	next_phase = 1	reward = -27.628391	array([[-47.931923, -48.626667]], dtype=float32)
time = 39607	action = 1	current_phase = 0	next_phase = 1	reward = -41.209286	array([[-64.44281 , -56.211952]], dtype=float32)
time = 39615	action = 0	current_phase = 1	next_phase = 0	reward = -23.564176	array([[ -61.695473, -108.41667 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 9851.6696 - val_loss: 19691.7854
Epoch 2/50
 - 4s - loss: 9839.8284 - val_loss: 19676.0180
Epoch 3/50
 - 4s - loss: 9822.4770 - val_loss: 19665.8584
Epoch 4/50
 - 4s - loss: 9815.3078 - val_loss: 19635.6098
Epoch 5/50
 - 4s - loss: 9799.9597 - val_loss: 19623.5873
Epoch 6/50
 - 4s - loss: 9793.0510 - val_loss: 19604.0413
Epoch 7/50
 - 4s - loss: 9789.8487 - val_loss: 19586.3436
Epoch 8/50
 - 4s - loss: 9768.4398 - val_loss: 19568.2048
Epoch 9/50
 - 4s - loss: 9758.0463 - val_loss: 19555.6230
Epoch 10/50
 - 4s - loss: 9750.8912 - val_loss: 19533.2402
Epoch 11/50
 - 4s - loss: 9732.5832 - val_loss: 19514.1683
Epoch 12/50
 - 7s - loss: 9715.1794 - val_loss: 19494.0225
Epoch 13/50
 - 4s - loss: 9708.8704 - val_loss: 19483.9179
Epoch 14/50
 - 4s - loss: 9698.0252 - val_loss: 19467.3849
Epoch 15/50
 - 5s - loss: 9696.7821 - val_loss: 19445.7212
Epoch 16/50
 - 5s - loss: 9677.4572 - val_loss: 19440.5355
Epoch 17/50
 - 5s - loss: 9679.4873 - val_loss: 19413.1021
Epoch 18/50
 - 6s - loss: 9647.2157 - val_loss: 19404.1266
Epoch 19/50
 - 4s - loss: 9651.3313 - val_loss: 19389.5714
Epoch 20/50
 - 4s - loss: 9639.2867 - val_loss: 19374.6298
Epoch 21/50
 - 4s - loss: 9623.2464 - val_loss: 19354.2557
Epoch 22/50
 - 4s - loss: 9615.4410 - val_loss: 19336.6186
Epoch 23/50
 - 4s - loss: 9624.6570 - val_loss: 19312.5654
Epoch 24/50
 - 4s - loss: 9604.1617 - val_loss: 19302.6798
Epoch 25/50
 - 5s - loss: 9585.1749 - val_loss: 19279.0755
Epoch 26/50
 - 4s - loss: 9573.3441 - val_loss: 19275.7851
Epoch 27/50
 - 4s - loss: 9571.8531 - val_loss: 19244.6062
Epoch 28/50
 - 4s - loss: 9557.0338 - val_loss: 19233.4646
Epoch 29/50
 - 4s - loss: 9543.8292 - val_loss: 19214.3745
Epoch 30/50
 - 4s - loss: 9536.8553 - val_loss: 19200.4072
Epoch 31/50
 - 4s - loss: 9518.6301 - val_loss: 19190.4119
Epoch 32/50
 - 4s - loss: 9515.2620 - val_loss: 19168.2702
Epoch 33/50
 - 4s - loss: 9498.4246 - val_loss: 19153.4785
Epoch 34/50
 - 4s - loss: 9504.6887 - val_loss: 19152.5486
Epoch 35/50
 - 4s - loss: 9483.2734 - val_loss: 19130.8681
Epoch 36/50
 - 6s - loss: 9472.0831 - val_loss: 19112.2876
Epoch 37/50
 - 5s - loss: 9455.3168 - val_loss: 19101.4108
Epoch 38/50
 - 4s - loss: 9450.6524 - val_loss: 19076.6353
Epoch 39/50
 - 4s - loss: 9438.3087 - val_loss: 19063.6193
Epoch 40/50
 - 6s - loss: 9422.3583 - val_loss: 19043.4180
Epoch 41/50
 - 4s - loss: 9415.9045 - val_loss: 19031.0657
Epoch 42/50
 - 4s - loss: 9399.5683 - val_loss: 19010.9644
Epoch 43/50
 - 4s - loss: 9404.1393 - val_loss: 18994.9070
Epoch 44/50
 - 4s - loss: 9391.9472 - val_loss: 18977.1131
Epoch 45/50
 - 4s - loss: 9378.1587 - val_loss: 18959.7276
Epoch 46/50
 - 4s - loss: 9363.7614 - val_loss: 18945.3657
Epoch 47/50
 - 4s - loss: 9350.8835 - val_loss: 18931.4256
Epoch 48/50
 - 4s - loss: 9352.5640 - val_loss: 18919.5584
Epoch 49/50
 - 4s - loss: 9325.9490 - val_loss: 18898.6577
Epoch 50/50
 - 4s - loss: 9327.1162 - val_loss: 18900.5706
length of memory (state 0, action 0): 1015, before forget
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 563, after forget
length of memory (state 1, action 1): 368, after forget
time = 39620	action = 0	current_phase = 1	next_phase = 0	reward = -14.772036	array([[-51.758926, -71.32585 ]], dtype=float32)
time = 39625	action = 0	current_phase = 1	next_phase = 0	reward = -19.523975	array([[-52.55275 , -64.334015]], dtype=float32)
time = 39630	action = 0	current_phase = 1	next_phase = 0	reward = -18.360599	array([[-51.69098, -67.35011]], dtype=float32)
time = 39635	action = 0	current_phase = 1	next_phase = 0	reward = -16.816560	array([[-51.553825, -67.6929  ]], dtype=float32)
time = 39640	action = 0	current_phase = 1	next_phase = 0	reward = -12.858987	array([[-52.942673, -62.908447]], dtype=float32)
time = 39645	action = 0	current_phase = 1	next_phase = 0	reward = -11.551209	array([[-52.68151, -62.84102]], dtype=float32)
time = 39650	action = 0	current_phase = 1	next_phase = 0	reward = -10.263017	array([[-52.818604, -62.38934 ]], dtype=float32)
time = 39655	action = 0	current_phase = 1	next_phase = 0	reward = -7.262607	array([[-52.4094 , -62.41856]], dtype=float32)
time = 39660	action = 0	current_phase = 1	next_phase = 0	reward = -2.406461	array([[-44.74025, -55.66684]], dtype=float32)
time = 39665	action = 0	current_phase = 1	next_phase = 0	reward = 1.387148	array([[-40.361908, -43.006824]], dtype=float32)
time = 39670	action = 0	current_phase = 1	next_phase = 0	reward = 2.228373	array([[-41.12835 , -42.906166]], dtype=float32)
time = 39675	action = 0	current_phase = 1	next_phase = 0	reward = -0.537920	array([[-40.924183, -42.93225 ]], dtype=float32)
time = 39680	action = 0	current_phase = 1	next_phase = 0	reward = 2.092139	array([[-39.57347 , -43.104637]], dtype=float32)
time = 39685	action = 0	current_phase = 1	next_phase = 0	reward = 2.359602	array([[-35.157333, -43.05026 ]], dtype=float32)
time = 39690	action = 0	current_phase = 1	next_phase = 0	reward = 7.390293	array([[-30.844664, -42.9486  ]], dtype=float32)
time = 39695	action = 0	current_phase = 1	next_phase = 0	reward = 7.065593	array([[-34.160187, -43.002666]], dtype=float32)
time = 39700	action = 0	current_phase = 1	next_phase = 0	reward = 5.488305	array([[-38.010647, -43.045204]], dtype=float32)
time = 39705	action = 0	current_phase = 1	next_phase = 0	reward = 3.950060	array([[-17.075478, -40.85699 ]], dtype=float32)
time = 39710	action = 0	current_phase = 1	next_phase = 0	reward = 4.789460	array([[-22.25653 , -44.098934]], dtype=float32)
time = 39715	action = 0	current_phase = 1	next_phase = 0	reward = 5.664869	array([[-39.944496, -42.955914]], dtype=float32)
time = 39720	action = 0	current_phase = 1	next_phase = 0	reward = 6.189050	array([[-29.187384, -43.533203]], dtype=float32)
time = 39725	action = 0	current_phase = 1	next_phase = 0	reward = 8.028878	array([[-36.758347, -43.117462]], dtype=float32)
time = 39730	action = 0	current_phase = 1	next_phase = 0	reward = 5.657060	array([[-36.311794, -43.317356]], dtype=float32)
time = 39735	action = 0	current_phase = 1	next_phase = 0	reward = 6.461567	array([[-31.736534, -43.669296]], dtype=float32)
time = 39740	action = 0	current_phase = 1	next_phase = 0	reward = 5.120895	array([[-23.674625, -44.077003]], dtype=float32)
time = 39745	action = 0	current_phase = 1	next_phase = 0	reward = 5.001951	array([[-18.832632, -43.249046]], dtype=float32)
time = 39750	action = 0	current_phase = 1	next_phase = 0	reward = 4.451434	array([[-21.765823, -43.871716]], dtype=float32)
time = 39755	action = 0	current_phase = 1	next_phase = 0	reward = 3.537407	array([[-22.58421 , -40.763477]], dtype=float32)
time = 39760	action = 0	current_phase = 1	next_phase = 0	reward = 4.308246	array([[-22.908567, -43.923374]], dtype=float32)
time = 39765	action = 0	current_phase = 1	next_phase = 0	reward = 3.169738	array([[-22.777655, -43.830265]], dtype=float32)
time = 39770	action = 0	current_phase = 1	next_phase = 0	reward = 4.153034	array([[-23.01519 , -43.891712]], dtype=float32)
time = 39775	action = 0	current_phase = 1	next_phase = 0	reward = 3.281435	array([[-22.861568, -43.860493]], dtype=float32)
time = 39780	action = 0	current_phase = 1	next_phase = 0	reward = 3.242840	array([[-23.263142, -43.95298 ]], dtype=float32)
time = 39785	action = 0	current_phase = 1	next_phase = 0	reward = 3.473114	array([[-23.081083, -43.936478]], dtype=float32)
time = 39790	action = 0	current_phase = 1	next_phase = 0	reward = 2.817986	array([[-23.323256, -43.886852]], dtype=float32)
time = 39795	action = 0	current_phase = 1	next_phase = 0	reward = 3.050056	array([[-23.23663 , -43.944958]], dtype=float32)
time = 39800	action = 0	current_phase = 1	next_phase = 0	reward = 2.768188	array([[-24.772434, -43.224495]], dtype=float32)
time = 39805	action = 0	current_phase = 1	next_phase = 0	reward = 2.438228	array([[-23.208942, -43.92956 ]], dtype=float32)
time = 39810	action = 0	current_phase = 1	next_phase = 0	reward = 2.986290	array([[-20.991343, -43.89146 ]], dtype=float32)
time = 39815	action = 0	current_phase = 1	next_phase = 0	reward = 2.395792	array([[-21.440365, -44.155514]], dtype=float32)
time = 39820	action = 0	current_phase = 1	next_phase = 0	reward = 2.410211	array([[-22.486315, -43.83691 ]], dtype=float32)
time = 39825	action = 0	current_phase = 1	next_phase = 0	reward = 2.955891	array([[-20.42923, -44.13311]], dtype=float32)
time = 39830	action = 0	current_phase = 1	next_phase = 0	reward = 1.844991	array([[-24.729881, -43.13261 ]], dtype=float32)
time = 39835	action = 0	current_phase = 1	next_phase = 0	reward = 2.955640	array([[-23.660477, -43.65196 ]], dtype=float32)
time = 39840	action = 0	current_phase = 1	next_phase = 0	reward = 1.851165	array([[-23.217539, -43.92952 ]], dtype=float32)
time = 39845	action = 0	current_phase = 1	next_phase = 0	reward = 2.956609	array([[-17.65681 , -44.730526]], dtype=float32)
time = 39850	action = 0	current_phase = 1	next_phase = 0	reward = 1.845604	array([[-23.358555, -43.790554]], dtype=float32)
time = 39855	action = 0	current_phase = 1	next_phase = 0	reward = 2.954933	array([[-23.244633, -43.609974]], dtype=float32)
time = 39860	action = 0	current_phase = 1	next_phase = 0	reward = 1.846301	array([[-18.50317 , -44.476254]], dtype=float32)
time = 39865	action = 0	current_phase = 1	next_phase = 0	reward = 2.682692	array([[-23.968369, -43.308178]], dtype=float32)
time = 39870	action = 0	current_phase = 1	next_phase = 0	reward = 2.121404	array([[-23.320679, -43.939053]], dtype=float32)
time = 39875	action = 0	current_phase = 1	next_phase = 0	reward = 2.678395	array([[-23.197227, -43.895992]], dtype=float32)
time = 39880	action = 0	current_phase = 1	next_phase = 0	reward = 2.130327	array([[-21.456375, -43.779743]], dtype=float32)
time = 39885	action = 0	current_phase = 1	next_phase = 0	reward = 2.960573	array([[-23.395502, -43.90798 ]], dtype=float32)
time = 39890	action = 0	current_phase = 1	next_phase = 0	reward = 1.846348	array([[-23.68508 , -43.837864]], dtype=float32)
time = 39895	action = 0	current_phase = 1	next_phase = 0	reward = 2.957503	array([[-21.762793, -44.14549 ]], dtype=float32)
time = 39900	action = 0	current_phase = 1	next_phase = 0	reward = 1.852430	array([[-25.528149, -43.3423  ]], dtype=float32)
time = 39905	action = 0	current_phase = 1	next_phase = 0	reward = 2.967399	array([[-23.182024, -43.92001 ]], dtype=float32)
time = 39910	action = 0	current_phase = 1	next_phase = 0	reward = 1.837005	array([[-24.597975, -42.87933 ]], dtype=float32)
time = 39915	action = 0	current_phase = 1	next_phase = 0	reward = 2.677751	array([[-24.041058, -42.521828]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 11420.0322 - val_loss: 12113.3205
Epoch 2/50
 - 4s - loss: 11411.3728 - val_loss: 12084.5151
Epoch 3/50
 - 4s - loss: 11398.7463 - val_loss: 12073.1721
Epoch 4/50
 - 4s - loss: 11385.0265 - val_loss: 12066.8185
Epoch 5/50
 - 4s - loss: 11361.2827 - val_loss: 12048.1313
Epoch 6/50
 - 4s - loss: 11357.3906 - val_loss: 12040.1893
Epoch 7/50
 - 4s - loss: 11354.0548 - val_loss: 12029.3008
Epoch 8/50
 - 5s - loss: 11332.9152 - val_loss: 12013.7830
Epoch 9/50
 - 4s - loss: 11327.9253 - val_loss: 12012.4501
Epoch 10/50
 - 4s - loss: 11315.9194 - val_loss: 11991.2640
Epoch 11/50
 - 4s - loss: 11303.2479 - val_loss: 11988.3865
Epoch 12/50
 - 4s - loss: 11294.2505 - val_loss: 11968.2763
Epoch 13/50
 - 4s - loss: 11284.8583 - val_loss: 11949.5743
Epoch 14/50
 - 4s - loss: 11274.3591 - val_loss: 11947.4012
Epoch 15/50
 - 4s - loss: 11250.3661 - val_loss: 11925.0346
Epoch 16/50
 - 4s - loss: 11252.9004 - val_loss: 11916.0473
Epoch 17/50
 - 4s - loss: 11240.8279 - val_loss: 11910.7425
Epoch 18/50
 - 4s - loss: 11237.1496 - val_loss: 11900.2810
Epoch 19/50
 - 4s - loss: 11219.6739 - val_loss: 11876.5003
Epoch 20/50
 - 4s - loss: 11206.5013 - val_loss: 11865.9511
Epoch 21/50
 - 4s - loss: 11196.4411 - val_loss: 11859.9007
Epoch 22/50
 - 4s - loss: 11188.3568 - val_loss: 11877.3163
Epoch 23/50
 - 4s - loss: 11178.6551 - val_loss: 11837.9991
Epoch 24/50
 - 4s - loss: 11168.5281 - val_loss: 11828.1023
Epoch 25/50
 - 4s - loss: 11152.6900 - val_loss: 11825.9316
Epoch 26/50
 - 4s - loss: 11144.0084 - val_loss: 11802.7138
Epoch 27/50
 - 4s - loss: 11135.2531 - val_loss: 11795.8000
Epoch 28/50
 - 4s - loss: 11127.8903 - val_loss: 11782.9068
Epoch 29/50
 - 4s - loss: 11115.7983 - val_loss: 11768.6761
Epoch 30/50
 - 4s - loss: 11101.4852 - val_loss: 11754.9848
Epoch 31/50
 - 4s - loss: 11096.8828 - val_loss: 11750.8531
Epoch 32/50
 - 4s - loss: 11089.2499 - val_loss: 11757.8821
Epoch 33/50
 - 4s - loss: 11079.7353 - val_loss: 11722.3822
Epoch 34/50
 - 4s - loss: 11060.7485 - val_loss: 11708.9725
Epoch 35/50
 - 4s - loss: 11058.2944 - val_loss: 11699.5985
Epoch 36/50
 - 4s - loss: 11041.1171 - val_loss: 11705.3567
Epoch 37/50
 - 4s - loss: 11047.5752 - val_loss: 11689.8575
Epoch 38/50
 - 4s - loss: 11030.9253 - val_loss: 11670.5579
Epoch 39/50
 - 4s - loss: 11018.1634 - val_loss: 11658.7234
Epoch 40/50
 - 4s - loss: 11011.2250 - val_loss: 11641.7096
Epoch 41/50
 - 4s - loss: 10998.5370 - val_loss: 11630.5524
Epoch 42/50
 - 4s - loss: 10984.8829 - val_loss: 11621.9110
Epoch 43/50
 - 4s - loss: 10977.7736 - val_loss: 11612.1422
Epoch 44/50
 - 4s - loss: 10972.1396 - val_loss: 11603.3550
Epoch 45/50
 - 4s - loss: 10958.1595 - val_loss: 11587.6066
Epoch 46/50
 - 4s - loss: 10951.3613 - val_loss: 11580.3249
Epoch 47/50
 - 4s - loss: 10938.7507 - val_loss: 11565.4150
Epoch 48/50
 - 4s - loss: 10933.1651 - val_loss: 11569.3708
Epoch 49/50
 - 4s - loss: 10919.3571 - val_loss: 11544.0585
Epoch 50/50
 - 4s - loss: 10908.4940 - val_loss: 11532.5176
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 623, after forget
length of memory (state 1, action 1): 368, after forget
time = 39920	action = 0	current_phase = 1	next_phase = 0	reward = 2.120355	array([[-12.209678, -42.53125 ]], dtype=float32)
time = 39925	action = 0	current_phase = 1	next_phase = 0	reward = 2.675094	array([[-17.526627, -43.95587 ]], dtype=float32)
time = 39930	action = 0	current_phase = 1	next_phase = 0	reward = 2.122611	array([[-13.90286 , -43.369617]], dtype=float32)
time = 39935	action = 0	current_phase = 1	next_phase = 0	reward = 2.959344	array([[-18.247032, -44.02563 ]], dtype=float32)
time = 39940	action = 0	current_phase = 1	next_phase = 0	reward = 2.113690	array([[-17.827587, -43.932915]], dtype=float32)
time = 39945	action = 0	current_phase = 1	next_phase = 0	reward = 2.676164	array([[-19.026894, -44.04654 ]], dtype=float32)
time = 39950	action = 0	current_phase = 1	next_phase = 0	reward = 1.836961	array([[-14.424232, -43.417038]], dtype=float32)
time = 39955	action = 0	current_phase = 1	next_phase = 0	reward = 2.681215	array([[-18.807953, -44.047043]], dtype=float32)
time = 39960	action = 0	current_phase = 1	next_phase = 0	reward = 2.120730	array([[-13.334913, -43.048748]], dtype=float32)
time = 39965	action = 0	current_phase = 1	next_phase = 0	reward = 2.404102	array([[-18.966488, -44.03992 ]], dtype=float32)
time = 39970	action = 0	current_phase = 1	next_phase = 0	reward = 2.407043	array([[-15.371855, -43.60742 ]], dtype=float32)
time = 39975	action = 0	current_phase = 1	next_phase = 0	reward = 2.963678	array([[-17.49274 , -43.944546]], dtype=float32)
time = 39980	action = 0	current_phase = 1	next_phase = 0	reward = 1.849462	array([[-14.834802, -43.57494 ]], dtype=float32)
time = 39985	action = 0	current_phase = 1	next_phase = 0	reward = 2.955559	array([[-18.094017, -44.006073]], dtype=float32)
time = 39990	action = 0	current_phase = 1	next_phase = 0	reward = 2.121948	array([[-15.456959, -43.658775]], dtype=float32)
time = 39995	action = 0	current_phase = 1	next_phase = 0	reward = 2.671843	array([[-18.544308, -44.03363 ]], dtype=float32)
time = 40000	action = 0	current_phase = 1	next_phase = 0	reward = 1.850479	array([[-17.598192, -43.947792]], dtype=float32)
time = 40005	action = 0	current_phase = 1	next_phase = 0	reward = 2.953905	array([[-19.11439 , -44.071198]], dtype=float32)
time = 40010	action = 0	current_phase = 1	next_phase = 0	reward = 1.842060	array([[-12.368882, -42.59609 ]], dtype=float32)
time = 40015	action = 0	current_phase = 1	next_phase = 0	reward = 2.962118	array([[-19.313555, -44.083885]], dtype=float32)
time = 40020	action = 0	current_phase = 1	next_phase = 0	reward = 2.113542	array([[-18.13416, -43.9367 ]], dtype=float32)
time = 40025	action = 0	current_phase = 1	next_phase = 0	reward = 2.402093	array([[-19.165913, -44.07792 ]], dtype=float32)
time = 40030	action = 0	current_phase = 1	next_phase = 0	reward = 2.125733	array([[-17.14437, -43.90185]], dtype=float32)
time = 40035	action = 0	current_phase = 1	next_phase = 0	reward = 2.402450	array([[-19.00952, -44.0636 ]], dtype=float32)
time = 40040	action = 0	current_phase = 1	next_phase = 0	reward = 2.413992	array([[-16.906546, -43.95137 ]], dtype=float32)
time = 40045	action = 0	current_phase = 1	next_phase = 0	reward = 2.966993	array([[-18.874224, -44.05111 ]], dtype=float32)
time = 40050	action = 0	current_phase = 1	next_phase = 0	reward = 1.839393	array([[-17.318804, -43.91361 ]], dtype=float32)
time = 40055	action = 0	current_phase = 1	next_phase = 0	reward = 2.953043	array([[-17.461487, -43.94259 ]], dtype=float32)
time = 40060	action = 0	current_phase = 1	next_phase = 0	reward = 1.843568	array([[-15.314997, -43.670876]], dtype=float32)
time = 40065	action = 0	current_phase = 1	next_phase = 0	reward = 2.684022	array([[-17.581902, -43.95841 ]], dtype=float32)
time = 40070	action = 0	current_phase = 1	next_phase = 0	reward = 2.401694	array([[-17.772186, -43.960224]], dtype=float32)
time = 40075	action = 0	current_phase = 1	next_phase = 0	reward = 2.681462	array([[-18.61639, -44.03232]], dtype=float32)
time = 40080	action = 0	current_phase = 1	next_phase = 0	reward = 1.837306	array([[-16.191622, -43.791958]], dtype=float32)
time = 40085	action = 0	current_phase = 1	next_phase = 0	reward = 2.949921	array([[-17.937828, -43.93863 ]], dtype=float32)
time = 40090	action = 0	current_phase = 1	next_phase = 0	reward = 1.835885	array([[-13.251286, -43.1066  ]], dtype=float32)
time = 40095	action = 0	current_phase = 1	next_phase = 0	reward = 1.844697	array([[-18.88536, -43.99831]], dtype=float32)
time = 40100	action = 0	current_phase = 1	next_phase = 0	reward = 2.980277	array([[-16.164862, -43.8525  ]], dtype=float32)
time = 40105	action = 0	current_phase = 1	next_phase = 0	reward = 2.962202	array([[-18.859116, -44.04989 ]], dtype=float32)
time = 40110	action = 0	current_phase = 1	next_phase = 0	reward = 1.833011	array([[-18.638252, -44.009323]], dtype=float32)
time = 40115	action = 0	current_phase = 1	next_phase = 0	reward = 2.963130	array([[-18.37777, -43.98004]], dtype=float32)
time = 40120	action = 0	current_phase = 1	next_phase = 0	reward = 1.853930	array([[-17.094671, -43.945534]], dtype=float32)
time = 40125	action = 0	current_phase = 1	next_phase = 0	reward = 2.969045	array([[-19.067892, -44.065308]], dtype=float32)
time = 40130	action = 0	current_phase = 1	next_phase = 0	reward = 1.839807	array([[-16.64326, -43.83258]], dtype=float32)
time = 40135	action = 0	current_phase = 1	next_phase = 0	reward = 2.685398	array([[-19.080324, -44.06344 ]], dtype=float32)
time = 40140	action = 0	current_phase = 1	next_phase = 0	reward = 2.399569	array([[-16.655094, -43.83773 ]], dtype=float32)
time = 40145	action = 0	current_phase = 1	next_phase = 0	reward = 2.676134	array([[-18.987017, -44.071205]], dtype=float32)
time = 40150	action = 0	current_phase = 1	next_phase = 0	reward = 1.858551	array([[-18.516365, -44.054176]], dtype=float32)
time = 40155	action = 0	current_phase = 1	next_phase = 0	reward = 2.956418	array([[-19.10767, -44.06525]], dtype=float32)
time = 40160	action = 0	current_phase = 1	next_phase = 0	reward = 1.850795	array([[-12.119789, -42.520367]], dtype=float32)
time = 40165	action = 0	current_phase = 1	next_phase = 0	reward = 2.957819	array([[-19.008057, -44.060066]], dtype=float32)
time = 40170	action = 0	current_phase = 1	next_phase = 0	reward = 1.842011	array([[-15.1316 , -43.58802]], dtype=float32)
time = 40175	action = 0	current_phase = 1	next_phase = 0	reward = 2.682637	array([[-19.288982, -44.069107]], dtype=float32)
time = 40180	action = 0	current_phase = 1	next_phase = 0	reward = 2.123825	array([[-12.838914, -42.91667 ]], dtype=float32)
time = 40185	action = 0	current_phase = 1	next_phase = 0	reward = 2.958350	array([[-19.213188, -44.07415 ]], dtype=float32)
time = 40190	action = 0	current_phase = 1	next_phase = 0	reward = 1.838732	array([[-12.492055, -42.736336]], dtype=float32)
time = 40195	action = 0	current_phase = 1	next_phase = 0	reward = 2.952299	array([[-18.918434, -44.064613]], dtype=float32)
time = 40200	action = 0	current_phase = 1	next_phase = 0	reward = 1.855062	array([[-17.852022, -43.867607]], dtype=float32)
time = 40205	action = 0	current_phase = 1	next_phase = 0	reward = 2.679016	array([[-18.465694, -44.02939 ]], dtype=float32)
time = 40210	action = 0	current_phase = 1	next_phase = 0	reward = 2.124238	array([[-17.400494, -44.034798]], dtype=float32)
time = 40215	action = 0	current_phase = 1	next_phase = 0	reward = 2.677636	array([[-18.93158, -44.05869]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 9525.9297 - val_loss: 9186.2566
Epoch 2/50
 - 4s - loss: 9521.6504 - val_loss: 9186.1263
Epoch 3/50
 - 4s - loss: 9505.1155 - val_loss: 9164.5153
Epoch 4/50
 - 4s - loss: 9495.5923 - val_loss: 9154.4063
Epoch 5/50
 - 4s - loss: 9485.6639 - val_loss: 9143.0612
Epoch 6/50
 - 4s - loss: 9476.1668 - val_loss: 9130.7336
Epoch 7/50
 - 4s - loss: 9461.6415 - val_loss: 9123.9802
Epoch 8/50
 - 4s - loss: 9460.7750 - val_loss: 9120.6699
Epoch 9/50
 - 4s - loss: 9438.5009 - val_loss: 9102.6344
Epoch 10/50
 - 4s - loss: 9429.0776 - val_loss: 9094.5482
Epoch 11/50
 - 4s - loss: 9428.4878 - val_loss: 9078.2680
Epoch 12/50
 - 4s - loss: 9414.9558 - val_loss: 9069.6110
Epoch 13/50
 - 4s - loss: 9414.5831 - val_loss: 9067.0013
Epoch 14/50
 - 4s - loss: 9397.3256 - val_loss: 9050.1992
Epoch 15/50
 - 4s - loss: 9387.8620 - val_loss: 9037.2558
Epoch 16/50
 - 4s - loss: 9381.2353 - val_loss: 9034.5955
Epoch 17/50
 - 4s - loss: 9372.7697 - val_loss: 9011.6006
Epoch 18/50
 - 4s - loss: 9354.9901 - val_loss: 9008.0318
Epoch 19/50
 - 4s - loss: 9351.3729 - val_loss: 8997.0045
Epoch 20/50
 - 4s - loss: 9345.6338 - val_loss: 8987.4924
Epoch 21/50
 - 4s - loss: 9331.1795 - val_loss: 8985.4881
Epoch 22/50
 - 4s - loss: 9318.5419 - val_loss: 8969.9689
Epoch 23/50
 - 4s - loss: 9313.6325 - val_loss: 8953.2412
Epoch 24/50
 - 4s - loss: 9305.4154 - val_loss: 8947.0922
Epoch 25/50
 - 4s - loss: 9299.3153 - val_loss: 8939.9585
Epoch 26/50
 - 4s - loss: 9287.0694 - val_loss: 8926.5859
Epoch 27/50
 - 4s - loss: 9273.0102 - val_loss: 8928.4099
Epoch 28/50
 - 4s - loss: 9264.0428 - val_loss: 8905.4468
Epoch 29/50
 - 4s - loss: 9256.5772 - val_loss: 8898.2162
Epoch 30/50
 - 4s - loss: 9243.0815 - val_loss: 8892.8278
Epoch 31/50
 - 4s - loss: 9240.7411 - val_loss: 8877.3089
Epoch 32/50
 - 4s - loss: 9227.3236 - val_loss: 8863.3630
Epoch 33/50
 - 4s - loss: 9217.4049 - val_loss: 8850.0857
Epoch 34/50
 - 4s - loss: 9210.0424 - val_loss: 8852.0765
Epoch 35/50
 - 4s - loss: 9199.3204 - val_loss: 8855.3679
Epoch 36/50
 - 4s - loss: 9188.3540 - val_loss: 8827.8603
Epoch 37/50
 - 4s - loss: 9180.5121 - val_loss: 8821.1164
Epoch 38/50
 - 4s - loss: 9174.4789 - val_loss: 8820.9210
Epoch 39/50
 - 4s - loss: 9165.5616 - val_loss: 8798.7728
Epoch 40/50
 - 4s - loss: 9156.1685 - val_loss: 8796.3435
Epoch 41/50
 - 4s - loss: 9148.0124 - val_loss: 8782.5862
Epoch 42/50
 - 4s - loss: 9142.9833 - val_loss: 8776.0457
Epoch 43/50
 - 4s - loss: 9128.9138 - val_loss: 8761.1754
Epoch 44/50
 - 4s - loss: 9115.8649 - val_loss: 8745.1622
Epoch 45/50
 - 4s - loss: 9119.5213 - val_loss: 8735.2311
Epoch 46/50
 - 4s - loss: 9104.6541 - val_loss: 8731.2344
Epoch 47/50
 - 4s - loss: 9089.0730 - val_loss: 8727.4045
Epoch 48/50
 - 4s - loss: 9080.9234 - val_loss: 8713.5570
Epoch 49/50
 - 4s - loss: 9078.9557 - val_loss: 8703.5645
Epoch 50/50
 - 4s - loss: 9069.5340 - val_loss: 8694.7222
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 683, after forget
length of memory (state 1, action 1): 368, after forget
time = 40220	action = 0	current_phase = 1	next_phase = 0	reward = 2.124121	array([[-16.882502, -43.209957]], dtype=float32)
time = 40225	action = 0	current_phase = 1	next_phase = 0	reward = 2.670181	array([[-18.660192, -43.43549 ]], dtype=float32)
time = 40230	action = 0	current_phase = 1	next_phase = 0	reward = 2.127816	array([[-16.28957 , -43.200237]], dtype=float32)
time = 40235	action = 0	current_phase = 1	next_phase = 0	reward = 2.950995	array([[-19.965843, -43.514484]], dtype=float32)
time = 40240	action = 0	current_phase = 1	next_phase = 0	reward = 1.847087	array([[-15.063921, -42.959705]], dtype=float32)
time = 40245	action = 0	current_phase = 1	next_phase = 0	reward = 2.961481	array([[-17.424171, -43.245674]], dtype=float32)
time = 40250	action = 0	current_phase = 1	next_phase = 0	reward = 1.844354	array([[-14.690515, -42.998188]], dtype=float32)
time = 40255	action = 0	current_phase = 1	next_phase = 0	reward = 2.672573	array([[-19.935741, -43.486736]], dtype=float32)
time = 40260	action = 0	current_phase = 1	next_phase = 0	reward = 2.129142	array([[-16.391323, -43.14478 ]], dtype=float32)
time = 40265	action = 0	current_phase = 1	next_phase = 0	reward = 2.679500	array([[-19.303938, -43.504204]], dtype=float32)
time = 40270	action = 0	current_phase = 1	next_phase = 0	reward = 2.141327	array([[-18.631996, -43.395584]], dtype=float32)
time = 40275	action = 0	current_phase = 1	next_phase = 0	reward = 2.958046	array([[-19.194317, -43.446728]], dtype=float32)
time = 40280	action = 0	current_phase = 1	next_phase = 0	reward = 1.838992	array([[-15.812709, -43.13456 ]], dtype=float32)
time = 40285	action = 0	current_phase = 1	next_phase = 0	reward = 2.953043	array([[-19.972528, -43.533623]], dtype=float32)
time = 40290	action = 0	current_phase = 1	next_phase = 0	reward = 1.846911	array([[-15.70759, -43.21894]], dtype=float32)
time = 40295	action = 0	current_phase = 1	next_phase = 0	reward = 2.678434	array([[-19.897354, -43.486668]], dtype=float32)
time = 40300	action = 0	current_phase = 1	next_phase = 0	reward = 2.126087	array([[-15.295362, -42.893368]], dtype=float32)
time = 40305	action = 0	current_phase = 1	next_phase = 0	reward = 2.956588	array([[-19.229816, -43.43798 ]], dtype=float32)
time = 40310	action = 0	current_phase = 1	next_phase = 0	reward = 1.850907	array([[-18.965652, -43.43986 ]], dtype=float32)
time = 40315	action = 0	current_phase = 1	next_phase = 0	reward = 2.680359	array([[-19.60506 , -43.483234]], dtype=float32)
time = 40320	action = 0	current_phase = 1	next_phase = 0	reward = 2.129538	array([[-13.768505, -43.01992 ]], dtype=float32)
time = 40325	action = 0	current_phase = 1	next_phase = 0	reward = 2.947502	array([[-20.121475, -43.504707]], dtype=float32)
time = 40330	action = 0	current_phase = 1	next_phase = 0	reward = 1.841284	array([[-16.049826, -43.158993]], dtype=float32)
time = 40335	action = 0	current_phase = 1	next_phase = 0	reward = 2.403161	array([[-17.446451, -43.354504]], dtype=float32)
time = 40340	action = 0	current_phase = 1	next_phase = 0	reward = 2.418023	array([[-15.801146, -43.459045]], dtype=float32)
time = 40345	action = 0	current_phase = 1	next_phase = 0	reward = 2.955047	array([[-19.811108, -43.508217]], dtype=float32)
time = 40350	action = 0	current_phase = 1	next_phase = 0	reward = 1.835917	array([[-13.096998, -42.151127]], dtype=float32)
time = 40355	action = 0	current_phase = 1	next_phase = 0	reward = 2.691024	array([[-19.947975, -43.49734 ]], dtype=float32)
time = 40360	action = 0	current_phase = 1	next_phase = 0	reward = 2.403286	array([[-14.194678, -43.063477]], dtype=float32)
time = 40365	action = 0	current_phase = 1	next_phase = 0	reward = 2.121659	array([[-19.12284, -43.42451]], dtype=float32)
time = 40370	action = 0	current_phase = 1	next_phase = 0	reward = 2.414483	array([[-14.384508, -42.73591 ]], dtype=float32)
time = 40375	action = 0	current_phase = 1	next_phase = 0	reward = 2.962593	array([[-17.505701, -43.349743]], dtype=float32)
time = 40380	action = 0	current_phase = 1	next_phase = 0	reward = 1.836640	array([[-12.941125, -42.156307]], dtype=float32)
time = 40385	action = 0	current_phase = 1	next_phase = 0	reward = 2.951925	array([[-17.876242, -43.366222]], dtype=float32)
time = 40390	action = 0	current_phase = 1	next_phase = 0	reward = 1.842821	array([[-17.49276, -43.34548]], dtype=float32)
time = 40395	action = 0	current_phase = 1	next_phase = 0	reward = 2.969798	array([[-19.931324, -43.483845]], dtype=float32)
time = 40400	action = 0	current_phase = 1	next_phase = 0	reward = 1.849495	array([[-12.053759, -42.47591 ]], dtype=float32)
time = 40405	action = 0	current_phase = 1	next_phase = 0	reward = 2.955430	array([[-20.031376, -43.501495]], dtype=float32)
time = 40410	action = 0	current_phase = 1	next_phase = 0	reward = 1.844675	array([[-16.46127, -43.14657]], dtype=float32)
time = 40415	action = 0	current_phase = 1	next_phase = 0	reward = 2.954115	array([[-20.000011, -43.486504]], dtype=float32)
time = 40420	action = 0	current_phase = 1	next_phase = 0	reward = 1.836445	array([[-19.253656, -43.44387 ]], dtype=float32)
time = 40425	action = 0	current_phase = 1	next_phase = 0	reward = 2.962185	array([[-19.881712, -43.483765]], dtype=float32)
time = 40430	action = 0	current_phase = 1	next_phase = 0	reward = 1.841837	array([[-19.11639, -43.46095]], dtype=float32)
time = 40435	action = 0	current_phase = 1	next_phase = 0	reward = 2.671774	array([[-19.630386, -43.458893]], dtype=float32)
time = 40440	action = 0	current_phase = 1	next_phase = 0	reward = 2.133144	array([[-13.921346, -43.172115]], dtype=float32)
time = 40445	action = 0	current_phase = 1	next_phase = 0	reward = 2.952170	array([[-16.014217, -43.524464]], dtype=float32)
time = 40450	action = 0	current_phase = 1	next_phase = 0	reward = 1.846527	array([[-17.256802, -43.259457]], dtype=float32)
time = 40455	action = 0	current_phase = 1	next_phase = 0	reward = 2.688884	array([[-19.861242, -43.48003 ]], dtype=float32)
time = 40460	action = 0	current_phase = 1	next_phase = 0	reward = 2.126074	array([[-17.22063 , -43.268066]], dtype=float32)
time = 40465	action = 0	current_phase = 1	next_phase = 0	reward = 2.959119	array([[-19.517778, -43.46817 ]], dtype=float32)
time = 40470	action = 0	current_phase = 1	next_phase = 0	reward = 1.844709	array([[-13.578751, -42.82427 ]], dtype=float32)
time = 40475	action = 0	current_phase = 1	next_phase = 0	reward = 2.957099	array([[-19.976566, -43.504642]], dtype=float32)
time = 40480	action = 0	current_phase = 1	next_phase = 0	reward = 1.841471	array([[-14.244012, -43.02883 ]], dtype=float32)
time = 40485	action = 0	current_phase = 1	next_phase = 0	reward = 2.945420	array([[-18.696981, -43.504147]], dtype=float32)
time = 40490	action = 0	current_phase = 1	next_phase = 0	reward = 1.838846	array([[-14.132435, -42.857014]], dtype=float32)
time = 40495	action = 0	current_phase = 1	next_phase = 0	reward = 2.681202	array([[-19.873995, -43.481712]], dtype=float32)
time = 40500	action = 0	current_phase = 1	next_phase = 0	reward = 2.142639	array([[-16.843775, -43.26198 ]], dtype=float32)
time = 40505	action = 0	current_phase = 1	next_phase = 0	reward = 2.674605	array([[-19.332878, -43.443928]], dtype=float32)
time = 40510	action = 0	current_phase = 1	next_phase = 0	reward = 2.117926	array([[-13.694106, -43.26238 ]], dtype=float32)
time = 40515	action = 0	current_phase = 1	next_phase = 0	reward = 2.679611	array([[-18.91616 , -43.496456]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 8821.5238 - val_loss: 14540.9922
Epoch 2/50
 - 4s - loss: 8807.3664 - val_loss: 14530.7672
Epoch 3/50
 - 4s - loss: 8800.4698 - val_loss: 14519.6427
Epoch 4/50
 - 4s - loss: 8787.7255 - val_loss: 14502.7744
Epoch 5/50
 - 4s - loss: 8772.6575 - val_loss: 14500.5261
Epoch 6/50
 - 4s - loss: 8764.6979 - val_loss: 14485.6639
Epoch 7/50
 - 4s - loss: 8749.1608 - val_loss: 14470.2504
Epoch 8/50
 - 4s - loss: 8743.2431 - val_loss: 14460.7795
Epoch 9/50
 - 4s - loss: 8729.3926 - val_loss: 14452.3795
Epoch 10/50
 - 4s - loss: 8715.0098 - val_loss: 14438.1631
Epoch 11/50
 - 4s - loss: 8703.1796 - val_loss: 14426.0860
Epoch 12/50
 - 4s - loss: 8698.3834 - val_loss: 14420.0546
Epoch 13/50
 - 4s - loss: 8686.8589 - val_loss: 14413.4370
Epoch 14/50
 - 4s - loss: 8683.4924 - val_loss: 14394.9707
Epoch 15/50
 - 4s - loss: 8665.2035 - val_loss: 14385.6336
Epoch 16/50
 - 4s - loss: 8651.9658 - val_loss: 14374.7639
Epoch 17/50
 - 4s - loss: 8645.7273 - val_loss: 14361.9752
Epoch 18/50
 - 4s - loss: 8627.5541 - val_loss: 14353.6094
Epoch 19/50
 - 4s - loss: 8623.8539 - val_loss: 14343.0805
Epoch 20/50
 - 4s - loss: 8606.1183 - val_loss: 14334.3999
Epoch 21/50
 - 4s - loss: 8591.9408 - val_loss: 14321.9742
Epoch 22/50
 - 4s - loss: 8596.3892 - val_loss: 14315.3366
Epoch 23/50
 - 4s - loss: 8569.9032 - val_loss: 14305.9742
Epoch 24/50
 - 4s - loss: 8565.4831 - val_loss: 14292.3316
Epoch 25/50
 - 4s - loss: 8552.1174 - val_loss: 14293.9613
Epoch 26/50
 - 4s - loss: 8545.6810 - val_loss: 14270.6892
Epoch 27/50
 - 4s - loss: 8528.2161 - val_loss: 14272.0513
Epoch 28/50
 - 4s - loss: 8518.0690 - val_loss: 14266.4516
Epoch 29/50
 - 4s - loss: 8511.7615 - val_loss: 14244.0222
Epoch 30/50
 - 4s - loss: 8501.5613 - val_loss: 14235.0040
Epoch 31/50
 - 4s - loss: 8496.5219 - val_loss: 14226.1192
Epoch 32/50
 - 4s - loss: 8474.3765 - val_loss: 14219.5994
Epoch 33/50
 - 4s - loss: 8465.1564 - val_loss: 14210.2916
Epoch 34/50
 - 4s - loss: 8456.7019 - val_loss: 14191.0868
Epoch 35/50
 - 4s - loss: 8457.3404 - val_loss: 14190.4347
Epoch 36/50
 - 4s - loss: 8425.1814 - val_loss: 14170.4500
Epoch 37/50
 - 4s - loss: 8428.1656 - val_loss: 14156.3121
Epoch 38/50
 - 4s - loss: 8419.6112 - val_loss: 14154.8582
Epoch 39/50
 - 4s - loss: 8411.6982 - val_loss: 14137.1709
Epoch 40/50
 - 4s - loss: 8395.9439 - val_loss: 14129.5517
Epoch 41/50
 - 4s - loss: 8388.5600 - val_loss: 14121.3757
Epoch 42/50
 - 4s - loss: 8371.8359 - val_loss: 14106.7032
Epoch 43/50
 - 4s - loss: 8362.1803 - val_loss: 14106.7231
Epoch 44/50
 - 4s - loss: 8359.7403 - val_loss: 14087.1558
Epoch 45/50
 - 4s - loss: 8342.1698 - val_loss: 14087.2152
Epoch 46/50
 - 4s - loss: 8337.3385 - val_loss: 14076.0835
Epoch 47/50
 - 4s - loss: 8320.5119 - val_loss: 14071.6815
Epoch 48/50
 - 4s - loss: 8318.5760 - val_loss: 14060.3255
Epoch 49/50
 - 4s - loss: 8301.1602 - val_loss: 14038.4727
Epoch 50/50
 - 4s - loss: 8295.1424 - val_loss: 14025.3902
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 743, after forget
length of memory (state 1, action 1): 368, after forget
time = 40520	action = 0	current_phase = 1	next_phase = 0	reward = 2.128610	array([[-18.158445, -42.994106]], dtype=float32)
time = 40525	action = 0	current_phase = 1	next_phase = 0	reward = 2.682620	array([[-20.054623, -43.046833]], dtype=float32)
time = 40530	action = 0	current_phase = 1	next_phase = 0	reward = 2.402313	array([[-16.840836, -42.824352]], dtype=float32)
time = 40535	action = 0	current_phase = 1	next_phase = 0	reward = 2.674245	array([[-20.013996, -43.020126]], dtype=float32)
time = 40540	action = 0	current_phase = 1	next_phase = 0	reward = 1.841332	array([[-14.621506, -42.524612]], dtype=float32)
time = 40545	action = 0	current_phase = 1	next_phase = 0	reward = 2.683758	array([[-19.88322 , -43.019592]], dtype=float32)
time = 40550	action = 0	current_phase = 1	next_phase = 0	reward = 2.129850	array([[-14.606823, -42.535656]], dtype=float32)
time = 40555	action = 0	current_phase = 1	next_phase = 0	reward = 2.955779	array([[-19.866613, -43.024803]], dtype=float32)
time = 40560	action = 0	current_phase = 1	next_phase = 0	reward = 1.833920	array([[-16.118511, -42.75503 ]], dtype=float32)
time = 40565	action = 0	current_phase = 1	next_phase = 0	reward = 2.393065	array([[-19.923716, -43.06891 ]], dtype=float32)
time = 40570	action = 0	current_phase = 1	next_phase = 0	reward = 2.407073	array([[-19.764574, -43.170498]], dtype=float32)
time = 40575	action = 0	current_phase = 1	next_phase = 0	reward = 2.681587	array([[-19.87919, -43.03347]], dtype=float32)
time = 40580	action = 0	current_phase = 1	next_phase = 0	reward = 2.413147	array([[-17.406502, -42.963337]], dtype=float32)
time = 40585	action = 0	current_phase = 1	next_phase = 0	reward = 2.402283	array([[-19.571714, -43.057964]], dtype=float32)
time = 40590	action = 0	current_phase = 1	next_phase = 0	reward = 2.129981	array([[-18.149906, -42.984623]], dtype=float32)
time = 40595	action = 0	current_phase = 1	next_phase = 0	reward = 2.965065	array([[-19.73195 , -43.022953]], dtype=float32)
time = 40600	action = 0	current_phase = 1	next_phase = 0	reward = 1.845548	array([[-17.905146, -42.938835]], dtype=float32)
time = 40605	action = 0	current_phase = 1	next_phase = 0	reward = 2.962336	array([[-19.19994 , -43.018955]], dtype=float32)
time = 40610	action = 0	current_phase = 1	next_phase = 0	reward = 1.839376	array([[-19.23468 , -42.998703]], dtype=float32)
time = 40615	action = 0	current_phase = 1	next_phase = 0	reward = 2.952828	array([[-16.57055, -42.75473]], dtype=float32)
time = 40620	action = 0	current_phase = 1	next_phase = 0	reward = 1.846015	array([[-17.320103, -42.884903]], dtype=float32)
time = 40625	action = 0	current_phase = 1	next_phase = 0	reward = 2.673554	array([[-20.084343, -43.09106 ]], dtype=float32)
time = 40630	action = 0	current_phase = 1	next_phase = 0	reward = 2.129342	array([[-15.100279, -42.5565  ]], dtype=float32)
time = 40635	action = 0	current_phase = 1	next_phase = 0	reward = 2.966691	array([[-19.658102, -43.026215]], dtype=float32)
time = 40640	action = 0	current_phase = 1	next_phase = 0	reward = 1.841979	array([[-17.563114, -42.890827]], dtype=float32)
time = 40645	action = 0	current_phase = 1	next_phase = 0	reward = 2.955975	array([[-19.554863, -43.03013 ]], dtype=float32)
time = 40650	action = 0	current_phase = 1	next_phase = 0	reward = 1.844863	array([[-16.570696, -42.83482 ]], dtype=float32)
time = 40655	action = 0	current_phase = 1	next_phase = 0	reward = 2.958572	array([[-19.64051 , -43.090847]], dtype=float32)
time = 40660	action = 0	current_phase = 1	next_phase = 0	reward = 1.841571	array([[-15.417147, -42.701115]], dtype=float32)
time = 40665	action = 0	current_phase = 1	next_phase = 0	reward = 2.961320	array([[-20.081432, -43.09401 ]], dtype=float32)
time = 40670	action = 0	current_phase = 1	next_phase = 0	reward = 1.841869	array([[-18.408339, -42.931717]], dtype=float32)
time = 40675	action = 0	current_phase = 1	next_phase = 0	reward = 2.960057	array([[-19.679682, -43.00438 ]], dtype=float32)
time = 40680	action = 0	current_phase = 1	next_phase = 0	reward = 1.837917	array([[-18.932344, -43.082367]], dtype=float32)
time = 40685	action = 0	current_phase = 1	next_phase = 0	reward = 2.960517	array([[-19.998087, -43.102066]], dtype=float32)
time = 40690	action = 0	current_phase = 1	next_phase = 0	reward = 1.846880	array([[-17.078915, -42.846878]], dtype=float32)
time = 40695	action = 0	current_phase = 1	next_phase = 0	reward = 2.956076	array([[-19.666395, -43.00862 ]], dtype=float32)
time = 40700	action = 0	current_phase = 1	next_phase = 0	reward = 1.839408	array([[-14.950891, -42.552345]], dtype=float32)
time = 40705	action = 0	current_phase = 1	next_phase = 0	reward = 2.961157	array([[-19.06183 , -43.150837]], dtype=float32)
time = 40710	action = 0	current_phase = 1	next_phase = 0	reward = 1.850916	array([[-12.996501, -42.728634]], dtype=float32)
time = 40715	action = 0	current_phase = 1	next_phase = 0	reward = 2.678588	array([[-19.051357, -42.997288]], dtype=float32)
time = 40720	action = 0	current_phase = 1	next_phase = 0	reward = 2.123599	array([[-18.12611, -43.1008 ]], dtype=float32)
time = 40725	action = 0	current_phase = 1	next_phase = 0	reward = 2.955988	array([[-19.445347, -42.989395]], dtype=float32)
time = 40730	action = 0	current_phase = 1	next_phase = 0	reward = 1.843839	array([[-18.74844 , -42.985893]], dtype=float32)
time = 40735	action = 0	current_phase = 1	next_phase = 0	reward = 2.680618	array([[-19.389503, -43.026573]], dtype=float32)
time = 40740	action = 0	current_phase = 1	next_phase = 0	reward = 2.124424	array([[-16.723291, -42.86335 ]], dtype=float32)
time = 40745	action = 0	current_phase = 1	next_phase = 0	reward = 2.674799	array([[-20.020199, -43.05683 ]], dtype=float32)
time = 40750	action = 0	current_phase = 1	next_phase = 0	reward = 2.134522	array([[-16.834639, -42.882084]], dtype=float32)
time = 40755	action = 0	current_phase = 1	next_phase = 0	reward = 2.969366	array([[-19.43095 , -43.024456]], dtype=float32)
time = 40760	action = 0	current_phase = 1	next_phase = 0	reward = 1.841000	array([[-17.515055, -42.91965 ]], dtype=float32)
time = 40765	action = 0	current_phase = 1	next_phase = 0	reward = 2.956282	array([[-19.644123, -43.026264]], dtype=float32)
time = 40770	action = 0	current_phase = 1	next_phase = 0	reward = 1.848789	array([[-18.163609, -43.008232]], dtype=float32)
time = 40775	action = 0	current_phase = 1	next_phase = 0	reward = 2.675789	array([[-19.577658, -43.047928]], dtype=float32)
time = 40780	action = 0	current_phase = 1	next_phase = 0	reward = 2.125891	array([[-14.139527, -42.883987]], dtype=float32)
time = 40785	action = 0	current_phase = 1	next_phase = 0	reward = 2.680871	array([[-19.57814 , -43.033833]], dtype=float32)
time = 40790	action = 0	current_phase = 1	next_phase = 0	reward = 2.131041	array([[-16.416817, -42.837406]], dtype=float32)
time = 40795	action = 0	current_phase = 1	next_phase = 0	reward = 2.960644	array([[-19.686539, -43.044197]], dtype=float32)
time = 40800	action = 0	current_phase = 1	next_phase = 0	reward = 1.845615	array([[-16.699974, -42.79025 ]], dtype=float32)
time = 40805	action = 0	current_phase = 1	next_phase = 0	reward = 2.955045	array([[-18.874569, -43.010433]], dtype=float32)
time = 40810	action = 0	current_phase = 1	next_phase = 0	reward = 1.838275	array([[-13.260351, -42.065575]], dtype=float32)
time = 40815	action = 0	current_phase = 1	next_phase = 0	reward = 2.955634	array([[-19.792347, -43.046932]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 8725.7904 - val_loss: 10002.7891
Epoch 2/50
 - 4s - loss: 8703.5550 - val_loss: 10026.5841
Epoch 3/50
 - 4s - loss: 8702.4265 - val_loss: 10018.4916
Epoch 4/50
 - 4s - loss: 8677.4839 - val_loss: 10011.9749
Epoch 5/50
 - 4s - loss: 8673.1916 - val_loss: 9999.8499
Epoch 6/50
 - 4s - loss: 8663.9574 - val_loss: 9986.9706
Epoch 7/50
 - 4s - loss: 8646.1691 - val_loss: 9993.9856
Epoch 8/50
 - 4s - loss: 8638.5352 - val_loss: 9973.4233
Epoch 9/50
 - 4s - loss: 8628.2367 - val_loss: 9964.6851
Epoch 10/50
 - 4s - loss: 8611.3239 - val_loss: 9949.6384
Epoch 11/50
 - 4s - loss: 8609.5662 - val_loss: 9934.8229
Epoch 12/50
 - 4s - loss: 8590.0762 - val_loss: 9924.7796
Epoch 13/50
 - 4s - loss: 8586.7386 - val_loss: 9865.9439
Epoch 14/50
 - 4s - loss: 8563.8733 - val_loss: 9904.5533
Epoch 15/50
 - 4s - loss: 8552.5758 - val_loss: 9901.8724
Epoch 16/50
 - 4s - loss: 8531.4749 - val_loss: 9879.4770
Epoch 17/50
 - 4s - loss: 8538.4977 - val_loss: 9864.9730
Epoch 18/50
 - 4s - loss: 8525.0506 - val_loss: 9860.3484
Epoch 19/50
 - 4s - loss: 8508.4546 - val_loss: 9846.6755
Epoch 20/50
 - 4s - loss: 8504.0567 - val_loss: 9830.3504
Epoch 21/50
 - 4s - loss: 8497.4324 - val_loss: 9820.9899
Epoch 22/50
 - 4s - loss: 8474.1776 - val_loss: 9808.2010
Epoch 23/50
 - 4s - loss: 8478.9923 - val_loss: 9790.7170
Epoch 24/50
 - 4s - loss: 8464.7700 - val_loss: 9789.0244
Epoch 25/50
 - 4s - loss: 8456.1246 - val_loss: 9769.0213
Epoch 26/50
 - 4s - loss: 8436.9442 - val_loss: 9768.2297
Epoch 27/50
 - 4s - loss: 8419.8115 - val_loss: 9755.2049
Epoch 28/50
 - 4s - loss: 8416.2676 - val_loss: 9730.2714
Epoch 29/50
 - 4s - loss: 8408.3382 - val_loss: 9725.1973
Epoch 30/50
 - 4s - loss: 8388.5528 - val_loss: 9714.9185
Epoch 31/50
 - 6s - loss: 8375.8616 - val_loss: 9702.4764
Epoch 32/50
 - 4s - loss: 8370.1888 - val_loss: 9695.5783
Epoch 33/50
 - 4s - loss: 8369.1015 - val_loss: 9687.2081
Epoch 34/50
 - 5s - loss: 8350.2887 - val_loss: 9658.8001
Epoch 35/50
 - 6s - loss: 8331.2406 - val_loss: 9667.1881
Epoch 36/50
 - 4s - loss: 8334.0287 - val_loss: 9671.5508
Epoch 37/50
 - 4s - loss: 8328.7623 - val_loss: 9644.5414
Epoch 38/50
 - 4s - loss: 8305.0845 - val_loss: 9635.0127
Epoch 39/50
 - 4s - loss: 8290.4675 - val_loss: 9638.4680
Epoch 40/50
 - 4s - loss: 8290.4542 - val_loss: 9635.4286
Epoch 41/50
 - 4s - loss: 8278.8611 - val_loss: 9619.3462
Epoch 42/50
 - 4s - loss: 8253.3703 - val_loss: 9604.4722
Epoch 43/50
 - 4s - loss: 8241.6340 - val_loss: 9602.2872
Epoch 44/50
 - 4s - loss: 8229.2942 - val_loss: 9623.1363
Epoch 45/50
 - 4s - loss: 8227.2938 - val_loss: 9590.2355
Epoch 46/50
 - 4s - loss: 8219.9379 - val_loss: 9578.6178
Epoch 47/50
 - 4s - loss: 8213.0035 - val_loss: 9573.6245
Epoch 48/50
 - 4s - loss: 8208.0372 - val_loss: 9556.8517
Epoch 49/50
 - 4s - loss: 8193.3019 - val_loss: 9570.3576
Epoch 50/50
 - 4s - loss: 8183.1282 - val_loss: 9539.9293
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 803, after forget
length of memory (state 1, action 1): 368, after forget
time = 40820	action = 0	current_phase = 1	next_phase = 0	reward = 1.850917	array([[-12.641636, -43.37415 ]], dtype=float32)
time = 40825	action = 0	current_phase = 1	next_phase = 0	reward = 2.952490	array([[-12.490737, -43.226208]], dtype=float32)
time = 40830	action = 0	current_phase = 1	next_phase = 0	reward = 1.837042	array([[-11.8610935, -42.50177  ]], dtype=float32)
time = 40835	action = 0	current_phase = 1	next_phase = 0	reward = 2.406161	array([[-12.789846, -43.43215 ]], dtype=float32)
time = 40840	action = 0	current_phase = 1	next_phase = 0	reward = 2.409245	array([[-12.448204, -43.20827 ]], dtype=float32)
time = 40845	action = 0	current_phase = 1	next_phase = 0	reward = 2.962385	array([[-12.726524, -43.399845]], dtype=float32)
time = 40850	action = 0	current_phase = 1	next_phase = 0	reward = 2.115327	array([[-12.493345, -43.24226 ]], dtype=float32)
time = 40855	action = 0	current_phase = 1	next_phase = 0	reward = 2.666534	array([[-12.70655, -43.38746]], dtype=float32)
time = 40860	action = 0	current_phase = 1	next_phase = 0	reward = 1.853056	array([[-12.577785, -43.30608 ]], dtype=float32)
time = 40865	action = 0	current_phase = 1	next_phase = 0	reward = 2.962842	array([[-12.774997, -43.42831 ]], dtype=float32)
time = 40870	action = 0	current_phase = 1	next_phase = 0	reward = 1.842072	array([[-12.53017, -43.27359]], dtype=float32)
time = 40875	action = 0	current_phase = 1	next_phase = 0	reward = 2.683198	array([[-12.493827, -43.241688]], dtype=float32)
time = 40880	action = 0	current_phase = 1	next_phase = 0	reward = 2.132141	array([[-12.093544, -42.85502 ]], dtype=float32)
time = 40885	action = 0	current_phase = 1	next_phase = 0	reward = 2.676173	array([[-12.641316, -43.36681 ]], dtype=float32)
time = 40890	action = 0	current_phase = 1	next_phase = 0	reward = 2.123985	array([[-12.2569065, -43.078667 ]], dtype=float32)
time = 40895	action = 0	current_phase = 1	next_phase = 0	reward = 2.966446	array([[-12.668557, -43.35615 ]], dtype=float32)
time = 40900	action = 0	current_phase = 1	next_phase = 0	reward = 1.838317	array([[-12.610991, -43.32146 ]], dtype=float32)
time = 40905	action = 0	current_phase = 1	next_phase = 0	reward = 2.953279	array([[-12.641988, -43.340504]], dtype=float32)
time = 40910	action = 0	current_phase = 1	next_phase = 0	reward = 1.846584	array([[-12.759282, -43.417984]], dtype=float32)
time = 40915	action = 0	current_phase = 1	next_phase = 0	reward = 2.964847	array([[-12.792455, -43.431355]], dtype=float32)
time = 40920	action = 0	current_phase = 1	next_phase = 0	reward = 1.875853	array([[-12.099924, -42.85634 ]], dtype=float32)
time = 40925	action = 0	current_phase = 1	next_phase = 0	reward = 2.721502	array([[-12.797598, -43.43451 ]], dtype=float32)
time = 40930	action = 0	current_phase = 1	next_phase = 0	reward = 2.158088	array([[-12.265883, -43.0424  ]], dtype=float32)
time = 40935	action = 0	current_phase = 1	next_phase = 0	reward = 2.972911	array([[-12.790483, -43.44165 ]], dtype=float32)
time = 40940	action = 0	current_phase = 1	next_phase = 0	reward = 1.000160	array([[-12.806122, -43.49587 ]], dtype=float32)
time = 40945	action = 0	current_phase = 1	next_phase = 0	reward = 2.126745	array([[-12.761133, -43.412144]], dtype=float32)
time = 40950	action = 0	current_phase = 1	next_phase = 0	reward = 1.286611	array([[-12.639413, -43.362484]], dtype=float32)
time = 40955	action = 0	current_phase = 1	next_phase = 0	reward = 1.831807	array([[-12.80801 , -43.444225]], dtype=float32)
time = 40960	action = 0	current_phase = 1	next_phase = 0	reward = 1.004876	array([[-12.804821, -43.44543 ]], dtype=float32)
time = 40965	action = 0	current_phase = 1	next_phase = 0	reward = 2.112694	array([[-12.774222, -43.42799 ]], dtype=float32)
time = 40970	action = 0	current_phase = 1	next_phase = 0	reward = 1.273708	array([[-12.761497, -43.42233 ]], dtype=float32)
time = 40975	action = 0	current_phase = 1	next_phase = 0	reward = 1.847332	array([[-12.694729, -43.413788]], dtype=float32)
time = 40980	action = 0	current_phase = 1	next_phase = 0	reward = 1.291136	array([[-12.5128975, -43.26081  ]], dtype=float32)
time = 40985	action = 0	current_phase = 1	next_phase = 0	reward = 1.568905	array([[-12.766622, -43.42028 ]], dtype=float32)
time = 40990	action = 0	current_phase = 1	next_phase = 0	reward = 1.582472	array([[-12.67019 , -43.391247]], dtype=float32)
time = 40995	action = 0	current_phase = 1	next_phase = 0	reward = 1.571428	array([[-12.7500515, -43.41564  ]], dtype=float32)
time = 41000	action = 0	current_phase = 1	next_phase = 0	reward = 1.603286	array([[-12.788405, -43.44486 ]], dtype=float32)
time = 41005	action = 0	current_phase = 1	next_phase = 0	reward = 1.882884	array([[-12.466242, -43.23098 ]], dtype=float32)
time = 41010	action = 0	current_phase = 1	next_phase = 0	reward = 1.289860	array([[-12.825375, -43.479183]], dtype=float32)
time = 41015	action = 0	current_phase = 1	next_phase = 0	reward = 0.718328	array([[-12.598593, -43.285896]], dtype=float32)
time = 41020	action = 0	current_phase = 1	next_phase = 0	reward = 0.714107	array([[-12.812031, -43.459908]], dtype=float32)
time = 41025	action = 0	current_phase = 1	next_phase = 0	reward = 0.710580	array([[-12.778079, -43.43335 ]], dtype=float32)
time = 41030	action = 0	current_phase = 1	next_phase = 0	reward = 0.161859	array([[-12.583093, -43.288567]], dtype=float32)
time = 41035	action = 0	current_phase = 1	next_phase = 0	reward = 1.293122	array([[-12.802197, -43.417145]], dtype=float32)
time = 41040	action = 0	current_phase = 1	next_phase = 0	reward = 0.718866	array([[-12.723687, -43.4194  ]], dtype=float32)
time = 41045	action = 0	current_phase = 1	next_phase = 0	reward = 0.440211	array([[-12.754094, -43.419224]], dtype=float32)
time = 41050	action = 0	current_phase = 1	next_phase = 0	reward = 1.001811	array([[-12.52616 , -43.263966]], dtype=float32)
time = 41055	action = 0	current_phase = 1	next_phase = 0	reward = 0.716027	array([[-12.75936, -43.3847 ]], dtype=float32)
time = 41060	action = 0	current_phase = 1	next_phase = 0	reward = 0.448048	array([[-12.695501, -43.371674]], dtype=float32)
time = 41065	action = 0	current_phase = 1	next_phase = 0	reward = 1.001485	array([[-12.587736, -43.32327 ]], dtype=float32)
time = 41070	action = 0	current_phase = 1	next_phase = 0	reward = 0.715654	array([[-12.784555, -43.39785 ]], dtype=float32)
time = 41075	action = 0	current_phase = 1	next_phase = 0	reward = 0.722204	array([[-12.791727, -43.443043]], dtype=float32)
time = 41080	action = 0	current_phase = 1	next_phase = 0	reward = 0.729044	array([[-12.625367, -43.295   ]], dtype=float32)
time = 41085	action = 0	current_phase = 1	next_phase = 0	reward = 0.716676	array([[-12.829225, -43.488007]], dtype=float32)
time = 41090	action = 0	current_phase = 1	next_phase = 0	reward = 0.722934	array([[-12.75342, -43.37665]], dtype=float32)
time = 41095	action = 0	current_phase = 1	next_phase = 0	reward = 0.714225	array([[-12.72523, -43.40292]], dtype=float32)
time = 41100	action = 0	current_phase = 1	next_phase = 0	reward = 0.721706	array([[-12.760807, -43.438374]], dtype=float32)
time = 41105	action = 0	current_phase = 1	next_phase = 0	reward = 0.440084	array([[-12.6761465, -43.344822 ]], dtype=float32)
time = 41110	action = 0	current_phase = 1	next_phase = 0	reward = 1.005172	array([[-12.787726, -43.38982 ]], dtype=float32)
time = 41115	action = 0	current_phase = 1	next_phase = 0	reward = 0.729061	array([[-12.801362, -43.438717]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 9249.0663 - val_loss: 10593.6881
Epoch 2/50
 - 4s - loss: 9233.9102 - val_loss: 10588.1632
Epoch 3/50
 - 4s - loss: 9219.0762 - val_loss: 10579.4973
Epoch 4/50
 - 4s - loss: 9208.9349 - val_loss: 10572.8708
Epoch 5/50
 - 4s - loss: 9198.6364 - val_loss: 10566.0044
Epoch 6/50
 - 4s - loss: 9188.7569 - val_loss: 10556.0415
Epoch 7/50
 - 4s - loss: 9169.2332 - val_loss: 10548.2706
Epoch 8/50
 - 4s - loss: 9159.0267 - val_loss: 10540.2990
Epoch 9/50
 - 4s - loss: 9143.8797 - val_loss: 10534.4210
Epoch 10/50
 - 4s - loss: 9144.4745 - val_loss: 10527.3624
Epoch 11/50
 - 4s - loss: 9124.5045 - val_loss: 10524.2438
Epoch 12/50
 - 4s - loss: 9108.6940 - val_loss: 10516.4971
Epoch 13/50
 - 4s - loss: 9097.1216 - val_loss: 10509.8128
Epoch 14/50
 - 4s - loss: 9090.8635 - val_loss: 10499.5400
Epoch 15/50
 - 4s - loss: 9069.2618 - val_loss: 10487.0088
Epoch 16/50
 - 4s - loss: 9059.7313 - val_loss: 10475.5516
Epoch 17/50
 - 4s - loss: 9050.6251 - val_loss: 10467.9588
Epoch 18/50
 - 4s - loss: 9036.2857 - val_loss: 10460.0025
Epoch 19/50
 - 4s - loss: 9024.6193 - val_loss: 10457.1494
Epoch 20/50
 - 4s - loss: 9009.0376 - val_loss: 10452.7636
Epoch 21/50
 - 4s - loss: 8995.1548 - val_loss: 10439.8931
Epoch 22/50
 - 4s - loss: 9000.0430 - val_loss: 10432.6759
Epoch 23/50
 - 4s - loss: 8974.7512 - val_loss: 10422.8491
Epoch 24/50
 - 4s - loss: 8962.6545 - val_loss: 10415.5504
Epoch 25/50
 - 4s - loss: 8959.2381 - val_loss: 10404.9388
Epoch 26/50
 - 4s - loss: 8940.8582 - val_loss: 10400.5172
Epoch 27/50
 - 4s - loss: 8930.6124 - val_loss: 10390.8898
Epoch 28/50
 - 4s - loss: 8917.6089 - val_loss: 10383.7059
Epoch 29/50
 - 4s - loss: 8904.2496 - val_loss: 10378.5355
Epoch 30/50
 - 4s - loss: 8894.4798 - val_loss: 10380.2699
Epoch 31/50
 - 4s - loss: 8879.1387 - val_loss: 10365.4031
Epoch 32/50
 - 4s - loss: 8871.5403 - val_loss: 10361.5455
Epoch 33/50
 - 4s - loss: 8859.3758 - val_loss: 10352.7752
Epoch 34/50
 - 4s - loss: 8842.8029 - val_loss: 10342.7054
Epoch 35/50
 - 4s - loss: 8830.7631 - val_loss: 10335.9281
Epoch 36/50
 - 4s - loss: 8825.2839 - val_loss: 10324.8565
Epoch 37/50
 - 4s - loss: 8811.1191 - val_loss: 10318.0659
Epoch 38/50
 - 4s - loss: 8799.4904 - val_loss: 10314.9979
Epoch 39/50
 - 4s - loss: 8800.9116 - val_loss: 10317.0318
Epoch 40/50
 - 4s - loss: 8781.2724 - val_loss: 10296.5958
Epoch 41/50
 - 4s - loss: 8768.1740 - val_loss: 10296.5644
Epoch 42/50
 - 4s - loss: 8750.8305 - val_loss: 10284.7219
Epoch 43/50
 - 4s - loss: 8748.5685 - val_loss: 10281.5669
Epoch 44/50
 - 4s - loss: 8731.4642 - val_loss: 10269.3532
Epoch 45/50
 - 4s - loss: 8723.2924 - val_loss: 10259.4429
Epoch 46/50
 - 4s - loss: 8706.2272 - val_loss: 10254.5805
Epoch 47/50
 - 4s - loss: 8704.0366 - val_loss: 10248.3536
Epoch 48/50
 - 4s - loss: 8684.1550 - val_loss: 10245.1323
Epoch 49/50
 - 4s - loss: 8678.1967 - val_loss: 10231.4699
Epoch 50/50
 - 4s - loss: 8677.7620 - val_loss: 10226.2539
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 863, after forget
length of memory (state 1, action 1): 368, after forget
time = 41120	action = 0	current_phase = 1	next_phase = 0	reward = 0.721646	array([[-12.2954855, -43.470543 ]], dtype=float32)
time = 41125	action = 0	current_phase = 1	next_phase = 0	reward = 0.722346	array([[-12.302617, -43.55894 ]], dtype=float32)
time = 41130	action = 0	current_phase = 1	next_phase = 0	reward = 0.719308	array([[-12.227253, -43.579845]], dtype=float32)
time = 41135	action = 0	current_phase = 1	next_phase = 0	reward = 0.718372	array([[-12.421742, -43.57004 ]], dtype=float32)
time = 41140	action = 0	current_phase = 1	next_phase = 0	reward = 0.720506	array([[-12.377224, -43.578667]], dtype=float32)
time = 41145	action = 0	current_phase = 1	next_phase = 0	reward = 0.720895	array([[-12.243799, -43.53608 ]], dtype=float32)
time = 41150	action = 0	current_phase = 1	next_phase = 0	reward = 0.716498	array([[-12.299982, -43.386562]], dtype=float32)
time = 41155	action = 0	current_phase = 1	next_phase = 0	reward = 0.709657	array([[-12.371988, -43.58355 ]], dtype=float32)
time = 41160	action = 0	current_phase = 1	next_phase = 0	reward = 0.724661	array([[-12.236525, -43.542953]], dtype=float32)
time = 41165	action = 0	current_phase = 1	next_phase = 0	reward = 0.720906	array([[-12.3584385, -43.62019  ]], dtype=float32)
time = 41170	action = 0	current_phase = 1	next_phase = 0	reward = 0.721653	array([[-12.294434, -43.6     ]], dtype=float32)
time = 41175	action = 0	current_phase = 1	next_phase = 0	reward = 0.727943	array([[-12.365898, -43.620094]], dtype=float32)
time = 41180	action = 0	current_phase = 1	next_phase = 0	reward = 0.723550	array([[-12.11983 , -43.350677]], dtype=float32)
time = 41185	action = 0	current_phase = 1	next_phase = 0	reward = 0.720773	array([[-12.304916, -43.56552 ]], dtype=float32)
time = 41190	action = 0	current_phase = 1	next_phase = 0	reward = 0.715683	array([[-12.237485, -43.327293]], dtype=float32)
time = 41195	action = 0	current_phase = 1	next_phase = 0	reward = 0.438566	array([[-12.07686 , -43.255722]], dtype=float32)
time = 41200	action = 0	current_phase = 1	next_phase = 0	reward = 1.000752	array([[-12.370727, -43.280987]], dtype=float32)
time = 41205	action = 0	current_phase = 1	next_phase = 0	reward = 0.717182	array([[-12.352111, -43.599373]], dtype=float32)
time = 41210	action = 0	current_phase = 1	next_phase = 0	reward = 0.717049	array([[-12.372934, -43.61413 ]], dtype=float32)
time = 41215	action = 0	current_phase = 1	next_phase = 0	reward = 0.439064	array([[-12.3735  , -43.632576]], dtype=float32)
time = 41220	action = 0	current_phase = 1	next_phase = 0	reward = 0.999865	array([[-12.40092 , -43.435787]], dtype=float32)
time = 41225	action = 0	current_phase = 1	next_phase = 0	reward = 0.446233	array([[-12.362943, -43.273365]], dtype=float32)
time = 41230	action = 0	current_phase = 1	next_phase = 0	reward = 0.730829	array([[-12.315449, -43.52893 ]], dtype=float32)
time = 41235	action = 0	current_phase = 1	next_phase = 0	reward = 1.011919	array([[-12.232206, -43.46721 ]], dtype=float32)
time = 41240	action = 0	current_phase = 1	next_phase = 0	reward = 0.728062	array([[-12.093372, -43.421593]], dtype=float32)
time = 41245	action = 0	current_phase = 1	next_phase = 0	reward = 0.718993	array([[-12.387429, -43.653385]], dtype=float32)
time = 41250	action = 0	current_phase = 1	next_phase = 0	reward = 0.719258	array([[-12.18836 , -43.440098]], dtype=float32)
time = 41255	action = 0	current_phase = 1	next_phase = 0	reward = 0.717477	array([[-12.315736, -43.551685]], dtype=float32)
time = 41260	action = 0	current_phase = 1	next_phase = 0	reward = 0.439254	array([[-12.120798, -43.427055]], dtype=float32)
time = 41265	action = 0	current_phase = 1	next_phase = 0	reward = 0.991985	array([[-12.251975, -43.228363]], dtype=float32)
time = 41270	action = 0	current_phase = 1	next_phase = 0	reward = 0.438508	array([[-12.277642, -43.5006  ]], dtype=float32)
time = 41275	action = 0	current_phase = 1	next_phase = 0	reward = 1.010203	array([[-12.293906, -43.579227]], dtype=float32)
time = 41280	action = 0	current_phase = 1	next_phase = 0	reward = 0.726739	array([[-12.293736, -43.58962 ]], dtype=float32)
time = 41285	action = 0	current_phase = 1	next_phase = 0	reward = 0.446565	array([[-12.360111, -43.62042 ]], dtype=float32)
time = 41290	action = 0	current_phase = 1	next_phase = 0	reward = 1.000412	array([[-12.2519655, -43.5501   ]], dtype=float32)
time = 41295	action = 0	current_phase = 1	next_phase = 0	reward = 0.440111	array([[-12.427168, -43.213184]], dtype=float32)
time = 41300	action = 0	current_phase = 1	next_phase = 0	reward = 1.000325	array([[-12.40584, -43.64985]], dtype=float32)
time = 41305	action = 0	current_phase = 1	next_phase = 0	reward = 0.438321	array([[-12.304616, -43.613377]], dtype=float32)
time = 41310	action = 0	current_phase = 1	next_phase = 0	reward = 0.721411	array([[-12.2844515, -43.549263 ]], dtype=float32)
time = 41315	action = 0	current_phase = 1	next_phase = 0	reward = 0.720485	array([[-12.305038, -43.50946 ]], dtype=float32)
time = 41320	action = 0	current_phase = 1	next_phase = 0	reward = 1.005125	array([[-12.320867, -43.506523]], dtype=float32)
time = 41325	action = 0	current_phase = 1	next_phase = 0	reward = 0.729142	array([[-12.314476, -43.585495]], dtype=float32)
time = 41330	action = 0	current_phase = 1	next_phase = 0	reward = 0.726704	array([[-12.245508, -43.543903]], dtype=float32)
time = 41335	action = 0	current_phase = 1	next_phase = 0	reward = 0.720450	array([[-12.325069, -43.590057]], dtype=float32)
time = 41340	action = 0	current_phase = 1	next_phase = 0	reward = 0.721617	array([[-12.3724 , -43.61167]], dtype=float32)
time = 41345	action = 0	current_phase = 1	next_phase = 0	reward = 0.716951	array([[-12.257302, -43.53577 ]], dtype=float32)
time = 41350	action = 0	current_phase = 1	next_phase = 0	reward = 0.444141	array([[-12.145299, -43.55187 ]], dtype=float32)
time = 41355	action = 0	current_phase = 1	next_phase = 0	reward = 0.727473	array([[-12.274546, -43.306393]], dtype=float32)
time = 41360	action = 0	current_phase = 1	next_phase = 0	reward = 1.005691	array([[-12.151991, -43.31023 ]], dtype=float32)
time = 41365	action = 0	current_phase = 1	next_phase = 0	reward = 0.713595	array([[-12.317083, -43.528404]], dtype=float32)
time = 41370	action = 0	current_phase = 1	next_phase = 0	reward = 0.715541	array([[-12.36198, -43.32237]], dtype=float32)
time = 41375	action = 0	current_phase = 1	next_phase = 0	reward = 0.714809	array([[-12.420937, -43.601105]], dtype=float32)
time = 41380	action = 0	current_phase = 1	next_phase = 0	reward = 0.709055	array([[-12.330965, -43.61932 ]], dtype=float32)
time = 41385	action = 0	current_phase = 1	next_phase = 0	reward = 0.437628	array([[-12.314597, -43.547356]], dtype=float32)
time = 41390	action = 0	current_phase = 1	next_phase = 0	reward = 1.010474	array([[-12.123733, -43.24041 ]], dtype=float32)
time = 41395	action = 0	current_phase = 1	next_phase = 0	reward = 0.447518	array([[-12.424295, -43.64335 ]], dtype=float32)
time = 41400	action = 0	current_phase = 1	next_phase = 0	reward = 1.004729	array([[-12.419817, -43.045082]], dtype=float32)
time = 41405	action = 0	current_phase = 1	next_phase = 0	reward = 0.721117	array([[-12.3334 , -43.61947]], dtype=float32)
time = 41410	action = 0	current_phase = 1	next_phase = 0	reward = 0.718362	array([[-12.28105, -43.58442]], dtype=float32)
time = 41415	action = 0	current_phase = 1	next_phase = 0	reward = 0.722879	array([[-12.282226, -43.5897  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 8989.5079 - val_loss: 11278.5090
Epoch 2/50
 - 4s - loss: 8984.4177 - val_loss: 11270.5239
Epoch 3/50
 - 4s - loss: 8971.3293 - val_loss: 11256.4321
Epoch 4/50
 - 4s - loss: 8964.9783 - val_loss: 11238.9911
Epoch 5/50
 - 4s - loss: 8963.1638 - val_loss: 11224.6217
Epoch 6/50
 - 4s - loss: 8945.3135 - val_loss: 11221.6722
Epoch 7/50
 - 4s - loss: 8929.9663 - val_loss: 11199.6155
Epoch 8/50
 - 4s - loss: 8923.4668 - val_loss: 11189.0942
Epoch 9/50
 - 4s - loss: 8928.7547 - val_loss: 11173.4449
Epoch 10/50
 - 4s - loss: 8903.9024 - val_loss: 11158.2955
Epoch 11/50
 - 4s - loss: 8910.2574 - val_loss: 11146.4581
Epoch 12/50
 - 4s - loss: 8889.8053 - val_loss: 11133.7690
Epoch 13/50
 - 4s - loss: 8881.8394 - val_loss: 11122.5333
Epoch 14/50
 - 4s - loss: 8873.8088 - val_loss: 11108.5354
Epoch 15/50
 - 4s - loss: 8867.4354 - val_loss: 11094.9331
Epoch 16/50
 - 4s - loss: 8855.2670 - val_loss: 11079.0750
Epoch 17/50
 - 4s - loss: 8865.2080 - val_loss: 11063.7593
Epoch 18/50
 - 4s - loss: 8844.2964 - val_loss: 11060.0812
Epoch 19/50
 - 4s - loss: 8824.3728 - val_loss: 11040.2677
Epoch 20/50
 - 4s - loss: 8820.3311 - val_loss: 11031.1259
Epoch 21/50
 - 4s - loss: 8821.1517 - val_loss: 11013.3785
Epoch 22/50
 - 4s - loss: 8810.7821 - val_loss: 11009.3918
Epoch 23/50
 - 4s - loss: 8794.4346 - val_loss: 10994.5059
Epoch 24/50
 - 4s - loss: 8795.8539 - val_loss: 10979.1002
Epoch 25/50
 - 4s - loss: 8780.2010 - val_loss: 10968.9282
Epoch 26/50
 - 4s - loss: 8777.0176 - val_loss: 10955.8269
Epoch 27/50
 - 4s - loss: 8766.6835 - val_loss: 10940.0694
Epoch 28/50
 - 4s - loss: 8753.0387 - val_loss: 10941.6547
Epoch 29/50
 - 4s - loss: 8747.2159 - val_loss: 10913.0292
Epoch 30/50
 - 4s - loss: 8746.2773 - val_loss: 10897.8164
Epoch 31/50
 - 4s - loss: 8733.7519 - val_loss: 10888.5382
Epoch 32/50
 - 4s - loss: 8724.5955 - val_loss: 10876.2992
Epoch 33/50
 - 4s - loss: 8720.0075 - val_loss: 10867.6959
Epoch 34/50
 - 4s - loss: 8707.8515 - val_loss: 10848.7824
Epoch 35/50
 - 4s - loss: 8700.7820 - val_loss: 10834.0337
Epoch 36/50
 - 4s - loss: 8690.5555 - val_loss: 10825.4578
Epoch 37/50
 - 4s - loss: 8687.9518 - val_loss: 10813.2928
Epoch 38/50
 - 4s - loss: 8675.8711 - val_loss: 10799.0077
Epoch 39/50
 - 4s - loss: 8672.8448 - val_loss: 10789.1831
Epoch 40/50
 - 4s - loss: 8660.6752 - val_loss: 10782.1451
Epoch 41/50
 - 4s - loss: 8656.2739 - val_loss: 10758.9017
Epoch 42/50
 - 4s - loss: 8642.7676 - val_loss: 10753.8946
Epoch 43/50
 - 4s - loss: 8648.2716 - val_loss: 10743.3502
Epoch 44/50
 - 4s - loss: 8630.1986 - val_loss: 10736.8617
Epoch 45/50
 - 4s - loss: 8616.5985 - val_loss: 10707.6918
Epoch 46/50
 - 4s - loss: 8617.1288 - val_loss: 10704.2419
Epoch 47/50
 - 4s - loss: 8604.8089 - val_loss: 10687.9252
Epoch 48/50
 - 4s - loss: 8601.0918 - val_loss: 10679.8016
Epoch 49/50
 - 4s - loss: 8592.2044 - val_loss: 10660.4166
Epoch 50/50
 - 4s - loss: 8592.5669 - val_loss: 10646.7767
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 923, after forget
length of memory (state 1, action 1): 368, after forget
time = 41420	action = 0	current_phase = 1	next_phase = 0	reward = 0.723640	array([[-13.075981, -44.000576]], dtype=float32)
time = 41425	action = 0	current_phase = 1	next_phase = 0	reward = 0.723831	array([[-12.553863, -43.727314]], dtype=float32)
time = 41430	action = 0	current_phase = 1	next_phase = 0	reward = 0.721331	array([[-12.620786, -43.372704]], dtype=float32)
time = 41435	action = 0	current_phase = 1	next_phase = 0	reward = 0.441692	array([[-12.862099, -43.308678]], dtype=float32)
time = 41440	action = 0	current_phase = 1	next_phase = 0	reward = 1.010967	array([[-12.637641, -43.858185]], dtype=float32)
time = 41445	action = 0	current_phase = 1	next_phase = 0	reward = 0.446207	array([[-12.736861, -43.339806]], dtype=float32)
time = 41450	action = 0	current_phase = 1	next_phase = 0	reward = 1.007139	array([[-12.545136, -43.728676]], dtype=float32)
time = 41455	action = 0	current_phase = 1	next_phase = 0	reward = 0.718979	array([[-12.623774, -43.646366]], dtype=float32)
time = 41460	action = 0	current_phase = 1	next_phase = 0	reward = 0.715635	array([[-12.550137, -43.779293]], dtype=float32)
time = 41465	action = 0	current_phase = 1	next_phase = 0	reward = 0.725099	array([[-12.488123, -43.755043]], dtype=float32)
time = 41470	action = 0	current_phase = 1	next_phase = 0	reward = 0.445744	array([[-12.618656, -43.666275]], dtype=float32)
time = 41475	action = 0	current_phase = 1	next_phase = 0	reward = 0.730485	array([[-12.581818, -43.76915 ]], dtype=float32)
time = 41480	action = 0	current_phase = 1	next_phase = 0	reward = 1.005636	array([[-12.584518, -43.658993]], dtype=float32)
time = 41485	action = 0	current_phase = 1	next_phase = 0	reward = 0.711983	array([[-12.643622, -43.79425 ]], dtype=float32)
time = 41490	action = 0	current_phase = 1	next_phase = 0	reward = 0.718173	array([[-12.549898, -43.865795]], dtype=float32)
time = 41495	action = 0	current_phase = 1	next_phase = 0	reward = 0.733436	array([[-12.564308, -43.655083]], dtype=float32)
time = 41500	action = 0	current_phase = 1	next_phase = 0	reward = 0.717805	array([[-12.66227 , -43.727783]], dtype=float32)
time = 41505	action = 0	current_phase = 1	next_phase = 0	reward = 0.709004	array([[-12.762815, -43.749767]], dtype=float32)
time = 41510	action = 0	current_phase = 1	next_phase = 0	reward = 0.717389	array([[-12.667133, -43.529682]], dtype=float32)
time = 41515	action = 0	current_phase = 1	next_phase = 0	reward = 0.722342	array([[-12.667658, -43.54569 ]], dtype=float32)
time = 41520	action = 0	current_phase = 1	next_phase = 0	reward = 0.728798	array([[-12.585115, -43.832695]], dtype=float32)
time = 41525	action = 0	current_phase = 1	next_phase = 0	reward = 0.720418	array([[-12.776546, -43.39488 ]], dtype=float32)
time = 41530	action = 0	current_phase = 1	next_phase = 0	reward = 0.705170	array([[-12.663867, -43.726784]], dtype=float32)
time = 41535	action = 0	current_phase = 1	next_phase = 0	reward = 0.442641	array([[-12.696568, -43.908733]], dtype=float32)
time = 41540	action = 0	current_phase = 1	next_phase = 0	reward = 1.003634	array([[-12.676904, -43.542023]], dtype=float32)
time = 41545	action = 0	current_phase = 1	next_phase = 0	reward = 0.710899	array([[-12.751432, -43.25282 ]], dtype=float32)
time = 41550	action = 0	current_phase = 1	next_phase = 0	reward = 0.436566	array([[-12.740948, -43.369003]], dtype=float32)
time = 41555	action = 0	current_phase = 1	next_phase = 0	reward = 0.996502	array([[-12.632158, -43.73086 ]], dtype=float32)
time = 41560	action = 0	current_phase = 1	next_phase = 0	reward = 0.433149	array([[-12.602405, -43.746384]], dtype=float32)
time = 41565	action = 0	current_phase = 1	next_phase = 0	reward = 0.723504	array([[-12.618554, -43.773087]], dtype=float32)
time = 41570	action = 0	current_phase = 1	next_phase = 0	reward = 1.004134	array([[-12.6854725, -43.548347 ]], dtype=float32)
time = 41575	action = 0	current_phase = 1	next_phase = 0	reward = 0.718234	array([[-12.730883, -43.76979 ]], dtype=float32)
time = 41580	action = 0	current_phase = 1	next_phase = 0	reward = 0.446565	array([[-12.809855, -43.968803]], dtype=float32)
time = 41585	action = 0	current_phase = 1	next_phase = 0	reward = 1.007763	array([[-12.832949, -43.738445]], dtype=float32)
time = 41590	action = 0	current_phase = 1	next_phase = 0	reward = 0.719592	array([[-12.918952, -43.882076]], dtype=float32)
time = 41595	action = 0	current_phase = 1	next_phase = 0	reward = 0.718009	array([[-12.679488, -43.683743]], dtype=float32)
time = 41600	action = 0	current_phase = 1	next_phase = 0	reward = 0.715816	array([[-12.665927, -43.76987 ]], dtype=float32)
time = 41605	action = 0	current_phase = 1	next_phase = 0	reward = 0.442207	array([[-12.653739, -43.611782]], dtype=float32)
time = 41610	action = 0	current_phase = 1	next_phase = 0	reward = 1.014107	array([[-12.639954, -43.851074]], dtype=float32)
time = 41615	action = 0	current_phase = 1	next_phase = 0	reward = 0.725696	array([[-12.654471, -43.590973]], dtype=float32)
time = 41620	action = 0	current_phase = 1	next_phase = 0	reward = 0.721426	array([[-12.613448, -43.7915  ]], dtype=float32)
time = 41625	action = 0	current_phase = 1	next_phase = 0	reward = 0.731902	array([[-12.655397, -43.56307 ]], dtype=float32)
time = 41630	action = 0	current_phase = 1	next_phase = 0	reward = 0.724436	array([[-12.589361, -43.465023]], dtype=float32)
time = 41635	action = 0	current_phase = 1	next_phase = 0	reward = 0.723635	array([[-12.453057, -43.577133]], dtype=float32)
time = 41640	action = 0	current_phase = 1	next_phase = 0	reward = 0.720838	array([[-12.6102495, -43.770897 ]], dtype=float32)
time = 41645	action = 0	current_phase = 1	next_phase = 0	reward = 0.720434	array([[-12.610492, -43.854668]], dtype=float32)
time = 41650	action = 0	current_phase = 1	next_phase = 0	reward = 0.726992	array([[-12.578963, -43.87112 ]], dtype=float32)
time = 41655	action = 0	current_phase = 1	next_phase = 0	reward = 0.447454	array([[-12.95746 , -44.029205]], dtype=float32)
time = 41660	action = 0	current_phase = 1	next_phase = 0	reward = 1.002936	array([[-12.6647835, -43.894394 ]], dtype=float32)
time = 41665	action = 0	current_phase = 1	next_phase = 0	reward = 0.714331	array([[-12.798746, -43.318027]], dtype=float32)
time = 41670	action = 0	current_phase = 1	next_phase = 0	reward = 0.725944	array([[-12.69997, -43.61439]], dtype=float32)
time = 41675	action = 0	current_phase = 1	next_phase = 0	reward = 0.726689	array([[-12.496048, -43.82053 ]], dtype=float32)
time = 41680	action = 0	current_phase = 1	next_phase = 0	reward = 0.714835	array([[-12.756712, -43.885757]], dtype=float32)
time = 41685	action = 0	current_phase = 1	next_phase = 0	reward = 0.717721	array([[-12.728905, -43.67878 ]], dtype=float32)
time = 41690	action = 0	current_phase = 1	next_phase = 0	reward = 0.714343	array([[-12.684692, -43.82207 ]], dtype=float32)
time = 41695	action = 0	current_phase = 1	next_phase = 0	reward = 0.714232	array([[-12.565748, -43.82006 ]], dtype=float32)
time = 41700	action = 0	current_phase = 1	next_phase = 0	reward = 0.433641	array([[-12.718388, -43.37565 ]], dtype=float32)
time = 41705	action = 0	current_phase = 1	next_phase = 0	reward = 1.001667	array([[-12.573932, -43.763   ]], dtype=float32)
time = 41710	action = 0	current_phase = 1	next_phase = 0	reward = 0.721943	array([[-12.575613, -43.713367]], dtype=float32)
time = 41715	action = 0	current_phase = 1	next_phase = 0	reward = 0.444724	array([[-12.47252, -43.64004]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 9290.5262 - val_loss: 7632.1033
Epoch 2/50
 - 4s - loss: 9274.1978 - val_loss: 7626.3067
Epoch 3/50
 - 4s - loss: 9262.8077 - val_loss: 7625.5526
Epoch 4/50
 - 4s - loss: 9253.3807 - val_loss: 7610.1764
Epoch 5/50
 - 4s - loss: 9231.9702 - val_loss: 7608.8288
Epoch 6/50
 - 4s - loss: 9224.8845 - val_loss: 7604.0591
Epoch 7/50
 - 4s - loss: 9205.8980 - val_loss: 7608.6999
Epoch 8/50
 - 4s - loss: 9192.2855 - val_loss: 7583.5986
Epoch 9/50
 - 4s - loss: 9184.5031 - val_loss: 7561.4390
Epoch 10/50
 - 4s - loss: 9177.2334 - val_loss: 7577.4866
Epoch 11/50
 - 4s - loss: 9164.4415 - val_loss: 7540.8867
Epoch 12/50
 - 4s - loss: 9153.0930 - val_loss: 7533.4447
Epoch 13/50
 - 4s - loss: 9138.1750 - val_loss: 7526.0186
Epoch 14/50
 - 4s - loss: 9124.7073 - val_loss: 7547.8551
Epoch 15/50
 - 4s - loss: 9116.6034 - val_loss: 7567.0862
Epoch 16/50
 - 4s - loss: 9106.5547 - val_loss: 7567.4359
Epoch 17/50
 - 4s - loss: 9088.1526 - val_loss: 7560.2251
Epoch 18/50
 - 4s - loss: 9081.3449 - val_loss: 7554.2960
Epoch 19/50
 - 4s - loss: 9072.7178 - val_loss: 7543.4318
Epoch 20/50
 - 4s - loss: 9058.6544 - val_loss: 7529.5652
Epoch 21/50
 - 4s - loss: 9046.1504 - val_loss: 7522.1280
Epoch 22/50
 - 4s - loss: 9037.9905 - val_loss: 7506.9036
Epoch 23/50
 - 4s - loss: 9031.6526 - val_loss: 7509.4880
Epoch 24/50
 - 4s - loss: 9011.6789 - val_loss: 7498.2890
Epoch 25/50
 - 4s - loss: 9000.2257 - val_loss: 7493.9946
Epoch 26/50
 - 4s - loss: 8993.4271 - val_loss: 7479.7443
Epoch 27/50
 - 4s - loss: 8981.9392 - val_loss: 7468.1075
Epoch 28/50
 - 4s - loss: 8971.2535 - val_loss: 7460.0335
Epoch 29/50
 - 4s - loss: 8958.3777 - val_loss: 7449.5022
Epoch 30/50
 - 4s - loss: 8953.0361 - val_loss: 7442.5032
Epoch 31/50
 - 4s - loss: 8939.0528 - val_loss: 7441.1289
Epoch 32/50
 - 4s - loss: 8931.8416 - val_loss: 7431.0268
Epoch 33/50
 - 4s - loss: 8924.4126 - val_loss: 7423.1230
Epoch 34/50
 - 4s - loss: 8907.8720 - val_loss: 7407.7106
Epoch 35/50
 - 4s - loss: 8898.5770 - val_loss: 7362.3181
Epoch 36/50
 - 4s - loss: 8882.1199 - val_loss: 7361.8983
Epoch 37/50
 - 4s - loss: 8874.9517 - val_loss: 7387.7374
Epoch 38/50
 - 4s - loss: 8859.8508 - val_loss: 7383.0706
Epoch 39/50
 - 4s - loss: 8851.6560 - val_loss: 7363.5616
Epoch 40/50
 - 4s - loss: 8836.3758 - val_loss: 7362.8426
Epoch 41/50
 - 4s - loss: 8824.6839 - val_loss: 7349.3169
Epoch 42/50
 - 4s - loss: 8816.7435 - val_loss: 7344.7496
Epoch 43/50
 - 4s - loss: 8806.6211 - val_loss: 7332.7433
Epoch 44/50
 - 4s - loss: 8801.3458 - val_loss: 7323.4483
Epoch 45/50
 - 4s - loss: 8789.2268 - val_loss: 7322.6133
Epoch 46/50
 - 4s - loss: 8769.2743 - val_loss: 7312.7168
Epoch 47/50
 - 4s - loss: 8765.9260 - val_loss: 7299.6819
Epoch 48/50
 - 4s - loss: 8750.7940 - val_loss: 7294.1431
Epoch 49/50
 - 4s - loss: 8738.4365 - val_loss: 7281.1045
Epoch 50/50
 - 4s - loss: 8727.5957 - val_loss: 7277.9114
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 983, after forget
length of memory (state 1, action 1): 368, after forget
time = 41720	action = 0	current_phase = 1	next_phase = 0	reward = 1.006804	array([[-12.926212, -44.94074 ]], dtype=float32)
time = 41725	action = 0	current_phase = 1	next_phase = 0	reward = 0.725116	array([[-12.911707, -43.59669 ]], dtype=float32)
time = 41730	action = 0	current_phase = 1	next_phase = 0	reward = 0.724580	array([[-13.24201, -42.64968]], dtype=float32)
time = 41735	action = 0	current_phase = 1	next_phase = 0	reward = 0.730555	array([[-14.23214 , -44.797047]], dtype=float32)
time = 41740	action = 0	current_phase = 1	next_phase = 0	reward = 0.715670	array([[-13.921057, -42.621426]], dtype=float32)
time = 41745	action = 0	current_phase = 1	next_phase = 0	reward = 0.712088	array([[-13.555411, -43.713795]], dtype=float32)
time = 41750	action = 0	current_phase = 1	next_phase = 0	reward = 0.726918	array([[-13.295042, -44.896557]], dtype=float32)
time = 41755	action = 0	current_phase = 1	next_phase = 0	reward = 0.721436	array([[-12.904646, -44.578712]], dtype=float32)
time = 41760	action = 0	current_phase = 1	next_phase = 0	reward = 0.729224	array([[-12.899675, -43.72476 ]], dtype=float32)
time = 41765	action = 0	current_phase = 1	next_phase = 0	reward = 0.725543	array([[-14.136736, -42.793186]], dtype=float32)
time = 41770	action = 0	current_phase = 1	next_phase = 0	reward = 0.718970	array([[-13.12561 , -42.973133]], dtype=float32)
time = 41775	action = 0	current_phase = 1	next_phase = 0	reward = 0.719621	array([[-13.068386, -43.15331 ]], dtype=float32)
time = 41780	action = 0	current_phase = 1	next_phase = 0	reward = 0.719948	array([[-12.948435, -44.331566]], dtype=float32)
time = 41785	action = 0	current_phase = 1	next_phase = 0	reward = 0.727238	array([[-12.995978, -43.30135 ]], dtype=float32)
time = 41790	action = 0	current_phase = 1	next_phase = 0	reward = 0.720652	array([[-13.678324, -44.223045]], dtype=float32)
time = 41795	action = 0	current_phase = 1	next_phase = 0	reward = 0.717861	array([[-12.774036, -44.180107]], dtype=float32)
time = 41800	action = 0	current_phase = 1	next_phase = 0	reward = 0.714740	array([[-13.146066, -44.307533]], dtype=float32)
time = 41805	action = 0	current_phase = 1	next_phase = 0	reward = 0.716609	array([[-13.079408, -43.362278]], dtype=float32)
time = 41810	action = 0	current_phase = 1	next_phase = 0	reward = 0.439406	array([[-12.596667, -44.156727]], dtype=float32)
time = 41815	action = 0	current_phase = 1	next_phase = 0	reward = 1.000022	array([[-14.16857 , -44.905453]], dtype=float32)
time = 41820	action = 0	current_phase = 1	next_phase = 0	reward = 0.438649	array([[-12.682679, -44.39036 ]], dtype=float32)
time = 41825	action = 0	current_phase = 1	next_phase = 0	reward = 1.000249	array([[-12.930843, -43.45811 ]], dtype=float32)
time = 41830	action = 0	current_phase = 1	next_phase = 0	reward = 0.447438	array([[-12.990436, -44.985207]], dtype=float32)
time = 41835	action = 0	current_phase = 1	next_phase = 0	reward = 1.005646	array([[-13.577494, -44.50625 ]], dtype=float32)
time = 41840	action = 0	current_phase = 1	next_phase = 0	reward = 0.725889	array([[-12.855504, -44.01102 ]], dtype=float32)
time = 41845	action = 0	current_phase = 1	next_phase = 0	reward = 0.723519	array([[-13.00353, -44.47388]], dtype=float32)
time = 41850	action = 0	current_phase = 1	next_phase = 0	reward = 0.720860	array([[-12.695375, -43.852474]], dtype=float32)
time = 41855	action = 0	current_phase = 1	next_phase = 0	reward = 0.445601	array([[-13.186555, -43.054173]], dtype=float32)
time = 41860	action = 0	current_phase = 1	next_phase = 0	reward = 1.003046	array([[-15.067758, -43.257275]], dtype=float32)
time = 41865	action = 0	current_phase = 1	next_phase = 0	reward = 0.716433	array([[-13.141576, -43.51107 ]], dtype=float32)
time = 41870	action = 0	current_phase = 1	next_phase = 0	reward = 0.439690	array([[-13.395218, -42.909645]], dtype=float32)
time = 41875	action = 0	current_phase = 1	next_phase = 0	reward = 1.003384	array([[-13.241516, -42.42127 ]], dtype=float32)
time = 41880	action = 0	current_phase = 1	next_phase = 0	reward = 0.452863	array([[-13.125147, -44.042248]], dtype=float32)
time = 41885	action = 0	current_phase = 1	next_phase = 0	reward = 0.725490	array([[-13.044188, -44.163734]], dtype=float32)
time = 41890	action = 0	current_phase = 1	next_phase = 0	reward = 1.000530	array([[-13.021873, -43.869755]], dtype=float32)
time = 41895	action = 0	current_phase = 1	next_phase = 0	reward = 0.716602	array([[-13.60163 , -43.999897]], dtype=float32)
time = 41900	action = 0	current_phase = 1	next_phase = 0	reward = 0.717800	array([[-12.563851, -44.282196]], dtype=float32)
time = 41905	action = 0	current_phase = 1	next_phase = 0	reward = 0.717034	array([[-13.729673, -43.3296  ]], dtype=float32)
time = 41910	action = 0	current_phase = 1	next_phase = 0	reward = 0.444337	array([[-12.7790575, -44.335865 ]], dtype=float32)
time = 41915	action = 0	current_phase = 1	next_phase = 0	reward = 1.006402	array([[-13.192312, -42.63242 ]], dtype=float32)
time = 41920	action = 0	current_phase = 1	next_phase = 0	reward = 0.442899	array([[-13.6124735, -43.748634 ]], dtype=float32)
time = 41925	action = 0	current_phase = 1	next_phase = 0	reward = 0.994196	array([[-13.506815, -43.601124]], dtype=float32)
time = 41930	action = 0	current_phase = 1	next_phase = 0	reward = 0.718952	array([[-12.9258995, -42.936752 ]], dtype=float32)
time = 41935	action = 0	current_phase = 1	next_phase = 0	reward = 0.718607	array([[-13.298662, -42.83447 ]], dtype=float32)
time = 41940	action = 0	current_phase = 1	next_phase = 0	reward = 0.721776	array([[-12.922546, -44.55779 ]], dtype=float32)
time = 41945	action = 0	current_phase = 1	next_phase = 0	reward = 0.724493	array([[-12.971329, -43.86935 ]], dtype=float32)
time = 41950	action = 0	current_phase = 1	next_phase = 0	reward = 0.721910	array([[-12.751696, -44.208813]], dtype=float32)
time = 41955	action = 0	current_phase = 1	next_phase = 0	reward = 0.720922	array([[-12.801079, -44.663708]], dtype=float32)
time = 41960	action = 0	current_phase = 1	next_phase = 0	reward = 0.721946	array([[-13.279832, -42.67923 ]], dtype=float32)
time = 41965	action = 0	current_phase = 1	next_phase = 0	reward = 0.718761	array([[-12.889362, -43.89891 ]], dtype=float32)
time = 41970	action = 0	current_phase = 1	next_phase = 0	reward = 0.721387	array([[-12.861094, -43.05413 ]], dtype=float32)
time = 41975	action = 0	current_phase = 1	next_phase = 0	reward = 0.722727	array([[-14.708968, -43.89834 ]], dtype=float32)
time = 41980	action = 0	current_phase = 1	next_phase = 0	reward = 0.719646	array([[-15.385405, -43.167618]], dtype=float32)
time = 41985	action = 0	current_phase = 1	next_phase = 0	reward = 0.721725	array([[-13.476614, -44.00731 ]], dtype=float32)
time = 41990	action = 0	current_phase = 1	next_phase = 0	reward = 0.714789	array([[-13.138166, -43.57757 ]], dtype=float32)
time = 41995	action = 0	current_phase = 1	next_phase = 0	reward = 0.724042	array([[-14.187679, -42.670937]], dtype=float32)
time = 42000	action = 0	current_phase = 1	next_phase = 0	reward = 0.441794	array([[-13.330347, -42.252197]], dtype=float32)
time = 42005	action = 0	current_phase = 1	next_phase = 0	reward = 0.996004	array([[-14.63449, -42.74911]], dtype=float32)
time = 42010	action = 0	current_phase = 1	next_phase = 0	reward = 0.730245	array([[-14.035568, -43.241234]], dtype=float32)
time = 42015	action = 0	current_phase = 1	next_phase = 0	reward = 0.722074	array([[-13.318299, -44.276955]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 7577.8116 - val_loss: 8290.7606
Epoch 2/50
 - 4s - loss: 7573.5733 - val_loss: 8286.2327
Epoch 3/50
 - 4s - loss: 7558.2629 - val_loss: 8270.6682
Epoch 4/50
 - 4s - loss: 7546.4011 - val_loss: 8258.0999
Epoch 5/50
 - 4s - loss: 7552.7101 - val_loss: 8248.1956
Epoch 6/50
 - 4s - loss: 7533.3137 - val_loss: 8234.4771
Epoch 7/50
 - 4s - loss: 7528.0878 - val_loss: 8225.2478
Epoch 8/50
 - 4s - loss: 7517.8623 - val_loss: 8198.0268
Epoch 9/50
 - 4s - loss: 7502.8452 - val_loss: 8202.9015
Epoch 10/50
 - 4s - loss: 7495.7847 - val_loss: 8183.7233
Epoch 11/50
 - 4s - loss: 7491.9189 - val_loss: 8170.3010
Epoch 12/50
 - 4s - loss: 7498.2726 - val_loss: 8157.4998
Epoch 13/50
 - 4s - loss: 7472.7495 - val_loss: 8146.9119
Epoch 14/50
 - 4s - loss: 7474.3696 - val_loss: 8131.5181
Epoch 15/50
 - 4s - loss: 7470.5157 - val_loss: 8122.0203
Epoch 16/50
 - 4s - loss: 7453.1370 - val_loss: 8107.9122
Epoch 17/50
 - 4s - loss: 7445.6480 - val_loss: 8100.2850
Epoch 18/50
 - 4s - loss: 7439.7533 - val_loss: 8094.2726
Epoch 19/50
 - 4s - loss: 7432.5800 - val_loss: 8079.9051
Epoch 20/50
 - 4s - loss: 7427.6243 - val_loss: 8069.8655
Epoch 21/50
 - 4s - loss: 7428.3914 - val_loss: 8055.8664
Epoch 22/50
 - 4s - loss: 7413.3398 - val_loss: 8048.0474
Epoch 23/50
 - 4s - loss: 7407.4784 - val_loss: 8033.3096
Epoch 24/50
 - 4s - loss: 7395.2097 - val_loss: 8022.9071
Epoch 25/50
 - 4s - loss: 7398.6228 - val_loss: 8012.3044
Epoch 26/50
 - 4s - loss: 7385.3074 - val_loss: 8002.5571
Epoch 27/50
 - 4s - loss: 7377.0493 - val_loss: 7995.0451
Epoch 28/50
 - 4s - loss: 7379.2677 - val_loss: 7980.9530
Epoch 29/50
 - 4s - loss: 7367.1808 - val_loss: 7968.9775
Epoch 30/50
 - 4s - loss: 7357.9905 - val_loss: 7971.4937
Epoch 31/50
 - 4s - loss: 7354.3825 - val_loss: 7950.9487
Epoch 32/50
 - 4s - loss: 7349.5995 - val_loss: 7937.7963
Epoch 33/50
 - 4s - loss: 7338.9396 - val_loss: 7928.3846
Epoch 34/50
 - 4s - loss: 7340.8610 - val_loss: 7931.9347
Epoch 35/50
 - 4s - loss: 7330.8946 - val_loss: 7909.2491
Epoch 36/50
 - 4s - loss: 7318.2293 - val_loss: 7895.9484
Epoch 37/50
 - 4s - loss: 7354.3950 - val_loss: 7905.7425
Epoch 38/50
 - 4s - loss: 7307.5555 - val_loss: 7884.8119
Epoch 39/50
 - 4s - loss: 7302.5236 - val_loss: 7873.3127
Epoch 40/50
 - 4s - loss: 7298.7732 - val_loss: 7858.1511
Epoch 41/50
 - 4s - loss: 7284.1744 - val_loss: 7844.1082
Epoch 42/50
 - 4s - loss: 7280.4770 - val_loss: 7831.2516
Epoch 43/50
 - 4s - loss: 7273.6355 - val_loss: 7829.4086
Epoch 44/50
 - 4s - loss: 7270.4444 - val_loss: 7814.6042
Epoch 45/50
 - 4s - loss: 7265.8314 - val_loss: 7812.0154
Epoch 46/50
 - 4s - loss: 7270.5170 - val_loss: 7793.1358
Epoch 47/50
 - 4s - loss: 7252.7323 - val_loss: 7790.2985
Epoch 48/50
 - 4s - loss: 7243.7425 - val_loss: 7769.8258
Epoch 49/50
 - 4s - loss: 7244.5839 - val_loss: 7781.9055
Epoch 50/50
 - 4s - loss: 7230.8893 - val_loss: 7757.7276
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1043, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 42020	action = 0	current_phase = 1	next_phase = 0	reward = 0.445751	array([[-14.658465, -43.170044]], dtype=float32)
time = 42025	action = 0	current_phase = 1	next_phase = 0	reward = 0.721391	array([[-14.191068, -45.59781 ]], dtype=float32)
time = 42030	action = 0	current_phase = 1	next_phase = 0	reward = 1.008513	array([[-13.454691, -44.38764 ]], dtype=float32)
time = 42035	action = 0	current_phase = 1	next_phase = 0	reward = 0.434757	array([[-13.0349455, -44.794174 ]], dtype=float32)
time = 42040	action = 0	current_phase = 1	next_phase = 0	reward = 0.998929	array([[-12.94817 , -43.392265]], dtype=float32)
time = 42045	action = 0	current_phase = 1	next_phase = 0	reward = 0.713928	array([[-13.95934 , -44.224915]], dtype=float32)
time = 42050	action = 0	current_phase = 1	next_phase = 0	reward = 0.719182	array([[-14.5988  , -43.623543]], dtype=float32)
time = 42055	action = 0	current_phase = 1	next_phase = 0	reward = 0.723072	array([[-14.151658, -44.64727 ]], dtype=float32)
time = 42060	action = 0	current_phase = 1	next_phase = 0	reward = 0.724314	array([[-13.935288, -44.25467 ]], dtype=float32)
time = 42065	action = 0	current_phase = 1	next_phase = 0	reward = 0.723495	array([[-13.717129, -43.371765]], dtype=float32)
time = 42070	action = 0	current_phase = 1	next_phase = 0	reward = 0.721329	array([[-12.859132, -43.625755]], dtype=float32)
time = 42075	action = 0	current_phase = 1	next_phase = 0	reward = 0.718200	array([[-12.917414, -43.101334]], dtype=float32)
time = 42080	action = 0	current_phase = 1	next_phase = 0	reward = 0.723633	array([[-13.233967, -44.044632]], dtype=float32)
time = 42085	action = 0	current_phase = 1	next_phase = 0	reward = 0.718413	array([[-13.558636, -43.798058]], dtype=float32)
time = 42090	action = 0	current_phase = 1	next_phase = 0	reward = 0.716472	array([[-13.120501, -44.343613]], dtype=float32)
time = 42095	action = 0	current_phase = 1	next_phase = 0	reward = 0.717670	array([[-13.40295 , -43.840836]], dtype=float32)
time = 42100	action = 0	current_phase = 1	next_phase = 0	reward = 0.717331	array([[-12.949332, -44.431816]], dtype=float32)
time = 42105	action = 0	current_phase = 1	next_phase = 0	reward = 0.728223	array([[-12.436001, -44.232384]], dtype=float32)
time = 42110	action = 0	current_phase = 1	next_phase = 0	reward = 0.722838	array([[-14.842635, -44.02443 ]], dtype=float32)
time = 42115	action = 0	current_phase = 1	next_phase = 0	reward = 0.720370	array([[-13.201037, -44.834213]], dtype=float32)
time = 42120	action = 0	current_phase = 1	next_phase = 0	reward = 0.713468	array([[-13.879486, -43.7576  ]], dtype=float32)
time = 42125	action = 0	current_phase = 1	next_phase = 0	reward = 0.443639	array([[-13.609381, -44.49579 ]], dtype=float32)
time = 42130	action = 0	current_phase = 1	next_phase = 0	reward = 1.006416	array([[-13.822393, -45.075462]], dtype=float32)
time = 42135	action = 0	current_phase = 1	next_phase = 0	reward = 0.445396	array([[-15.581039, -44.632034]], dtype=float32)
time = 42140	action = 0	current_phase = 1	next_phase = 0	reward = 1.009261	array([[-14.201003, -44.108192]], dtype=float32)
time = 42145	action = 0	current_phase = 1	next_phase = 0	reward = 0.724732	array([[-15.291091, -44.06292 ]], dtype=float32)
time = 42150	action = 0	current_phase = 1	next_phase = 0	reward = 0.718077	array([[-13.786934, -43.964317]], dtype=float32)
time = 42155	action = 0	current_phase = 1	next_phase = 0	reward = 0.723810	array([[-14.706228, -43.465607]], dtype=float32)
time = 42160	action = 0	current_phase = 1	next_phase = 0	reward = 0.713273	array([[-14.06363 , -43.492264]], dtype=float32)
time = 42165	action = 0	current_phase = 1	next_phase = 0	reward = 0.711206	array([[-13.105437, -43.28431 ]], dtype=float32)
time = 42170	action = 0	current_phase = 1	next_phase = 0	reward = 0.710586	array([[-13.979538, -44.679558]], dtype=float32)
time = 42175	action = 0	current_phase = 1	next_phase = 0	reward = 0.717108	array([[-13.251002, -43.61039 ]], dtype=float32)
time = 42180	action = 0	current_phase = 1	next_phase = 0	reward = 0.718335	array([[-14.029546, -43.95369 ]], dtype=float32)
time = 42185	action = 0	current_phase = 1	next_phase = 0	reward = 0.448660	array([[-13.004358, -44.699158]], dtype=float32)
time = 42190	action = 0	current_phase = 1	next_phase = 0	reward = 1.011177	array([[-13.963225, -44.80002 ]], dtype=float32)
time = 42195	action = 0	current_phase = 1	next_phase = 0	reward = 0.449217	array([[-13.39435, -44.43508]], dtype=float32)
time = 42200	action = 0	current_phase = 1	next_phase = 0	reward = 1.004315	array([[-14.657414, -43.84217 ]], dtype=float32)
time = 42205	action = 0	current_phase = 1	next_phase = 0	reward = 0.717281	array([[-13.768364, -43.157593]], dtype=float32)
time = 42210	action = 0	current_phase = 1	next_phase = 0	reward = 0.716502	array([[-13.461489, -45.036217]], dtype=float32)
time = 42215	action = 0	current_phase = 1	next_phase = 0	reward = 0.443228	array([[-13.26399, -43.83693]], dtype=float32)
time = 42220	action = 0	current_phase = 1	next_phase = 0	reward = 0.999087	array([[-13.250302, -44.338745]], dtype=float32)
time = 42225	action = 0	current_phase = 1	next_phase = 0	reward = 0.438342	array([[-13.059204, -45.111168]], dtype=float32)
time = 42230	action = 0	current_phase = 1	next_phase = 0	reward = 1.002532	array([[-14.012991, -43.351738]], dtype=float32)
time = 42235	action = 0	current_phase = 1	next_phase = 0	reward = 0.444332	array([[-13.229884, -43.180885]], dtype=float32)
time = 42240	action = 0	current_phase = 1	next_phase = 0	reward = 1.009442	array([[-14.845797, -44.53692 ]], dtype=float32)
time = 42245	action = 0	current_phase = 1	next_phase = 0	reward = 0.727115	array([[-13.50467, -44.46427]], dtype=float32)
time = 42250	action = 0	current_phase = 1	next_phase = 0	reward = 0.723797	array([[-12.613937, -44.087944]], dtype=float32)
time = 42255	action = 0	current_phase = 1	next_phase = 0	reward = 0.723702	array([[-13.605947, -44.237633]], dtype=float32)
time = 42260	action = 0	current_phase = 1	next_phase = 0	reward = 0.725693	array([[-15.012531, -44.078552]], dtype=float32)
time = 42265	action = 0	current_phase = 1	next_phase = 0	reward = 0.720767	array([[-13.63323 , -43.495667]], dtype=float32)
time = 42270	action = 0	current_phase = 1	next_phase = 0	reward = 0.725098	array([[-13.393308, -45.031006]], dtype=float32)
time = 42275	action = 0	current_phase = 1	next_phase = 0	reward = 0.721969	array([[-13.497001, -43.857254]], dtype=float32)
time = 42280	action = 0	current_phase = 1	next_phase = 0	reward = 0.719467	array([[-13.035236, -43.062904]], dtype=float32)
time = 42285	action = 0	current_phase = 1	next_phase = 0	reward = 0.442068	array([[-13.602533, -43.50094 ]], dtype=float32)
time = 42290	action = 0	current_phase = 1	next_phase = 0	reward = 1.001812	array([[-13.293773, -44.262703]], dtype=float32)
time = 42295	action = 0	current_phase = 1	next_phase = 0	reward = 0.438215	array([[-13.157863, -43.303314]], dtype=float32)
time = 42300	action = 0	current_phase = 1	next_phase = 0	reward = 0.996913	array([[-13.63505 , -43.393906]], dtype=float32)
time = 42305	action = 0	current_phase = 1	next_phase = 0	reward = 0.705760	array([[-13.83584 , -44.493195]], dtype=float32)
time = 42310	action = 0	current_phase = 1	next_phase = 0	reward = 0.723349	array([[-14.441069, -45.225815]], dtype=float32)
time = 42315	action = 0	current_phase = 1	next_phase = 0	reward = 0.719145	array([[-15.57052 , -43.753654]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 6358.8479 - val_loss: 12287.4249
Epoch 2/50
 - 4s - loss: 6347.3849 - val_loss: 12275.0830
Epoch 3/50
 - 4s - loss: 6337.8326 - val_loss: 12263.2207
Epoch 4/50
 - 4s - loss: 6313.6624 - val_loss: 12253.2003
Epoch 5/50
 - 4s - loss: 6309.2815 - val_loss: 12248.2073
Epoch 6/50
 - 4s - loss: 6302.6714 - val_loss: 12255.2102
Epoch 7/50
 - 4s - loss: 6286.7590 - val_loss: 12235.8832
Epoch 8/50
 - 4s - loss: 6284.1317 - val_loss: 12211.2303
Epoch 9/50
 - 4s - loss: 6270.8054 - val_loss: 12197.2018
Epoch 10/50
 - 4s - loss: 6260.6108 - val_loss: 12188.0428
Epoch 11/50
 - 4s - loss: 6264.2022 - val_loss: 12170.4580
Epoch 12/50
 - 4s - loss: 6244.9687 - val_loss: 12177.4174
Epoch 13/50
 - 4s - loss: 6244.2612 - val_loss: 12157.4905
Epoch 14/50
 - 4s - loss: 6227.5005 - val_loss: 12152.6540
Epoch 15/50
 - 4s - loss: 6214.3943 - val_loss: 12141.8235
Epoch 16/50
 - 4s - loss: 6207.7878 - val_loss: 12123.5646
Epoch 17/50
 - 4s - loss: 6203.4697 - val_loss: 12109.9331
Epoch 18/50
 - 4s - loss: 6196.5238 - val_loss: 12122.8700
Epoch 19/50
 - 4s - loss: 6192.8619 - val_loss: 12112.0262
Epoch 20/50
 - 4s - loss: 6177.1704 - val_loss: 12096.3449
Epoch 21/50
 - 4s - loss: 6176.7161 - val_loss: 12091.5015
Epoch 22/50
 - 4s - loss: 6155.2174 - val_loss: 12063.7748
Epoch 23/50
 - 4s - loss: 6151.3700 - val_loss: 12062.7906
Epoch 24/50
 - 4s - loss: 6148.1448 - val_loss: 12039.1887
Epoch 25/50
 - 4s - loss: 6132.6313 - val_loss: 12036.0014
Epoch 26/50
 - 4s - loss: 6132.3982 - val_loss: 12032.7402
Epoch 27/50
 - 4s - loss: 6121.9675 - val_loss: 12015.7562
Epoch 28/50
 - 4s - loss: 6125.1187 - val_loss: 12001.8965
Epoch 29/50
 - 4s - loss: 6101.3453 - val_loss: 11992.5110
Epoch 30/50
 - 4s - loss: 6091.5458 - val_loss: 11983.8421
Epoch 31/50
 - 4s - loss: 6095.9226 - val_loss: 11989.6070
Epoch 32/50
 - 4s - loss: 6080.4102 - val_loss: 11978.3047
Epoch 33/50
 - 4s - loss: 6079.2931 - val_loss: 11970.5776
Epoch 34/50
 - 4s - loss: 6070.2998 - val_loss: 11959.4166
Epoch 35/50
 - 4s - loss: 6058.3973 - val_loss: 11944.0602
Epoch 36/50
 - 4s - loss: 6049.7172 - val_loss: 11937.1455
Epoch 37/50
 - 4s - loss: 6045.3503 - val_loss: 11923.1248
Epoch 38/50
 - 4s - loss: 6031.9614 - val_loss: 11905.6593
Epoch 39/50
 - 4s - loss: 6028.4387 - val_loss: 11901.4741
Epoch 40/50
 - 4s - loss: 6022.5111 - val_loss: 11895.6123
Epoch 41/50
 - 4s - loss: 6008.4363 - val_loss: 11882.0985
Epoch 42/50
 - 4s - loss: 5998.5227 - val_loss: 11880.1344
Epoch 43/50
 - 4s - loss: 5996.6527 - val_loss: 11880.4472
Epoch 44/50
 - 4s - loss: 5985.0371 - val_loss: 11865.4652
Epoch 45/50
 - 4s - loss: 5977.0320 - val_loss: 11859.9815
Epoch 46/50
 - 4s - loss: 5969.7532 - val_loss: 11850.5956
Epoch 47/50
 - 4s - loss: 5964.8048 - val_loss: 11842.2703
Epoch 48/50
 - 4s - loss: 5956.9725 - val_loss: 11835.6294
Epoch 49/50
 - 4s - loss: 5946.4028 - val_loss: 11814.7138
Epoch 50/50
 - 4s - loss: 5946.5920 - val_loss: 11803.3574
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 42320	action = 0	current_phase = 1	next_phase = 0	reward = 0.719667	array([[-11.0762825, -44.53016  ]], dtype=float32)
time = 42325	action = 0	current_phase = 1	next_phase = 0	reward = 0.721511	array([[-11.065395, -44.54984 ]], dtype=float32)
time = 42330	action = 0	current_phase = 1	next_phase = 0	reward = 0.723028	array([[-11.143977, -43.69453 ]], dtype=float32)
time = 42335	action = 0	current_phase = 1	next_phase = 0	reward = 0.723946	array([[-10.85709, -43.4535 ]], dtype=float32)
time = 42340	action = 0	current_phase = 1	next_phase = 0	reward = 0.724667	array([[-10.964381, -44.612446]], dtype=float32)
time = 42345	action = 0	current_phase = 1	next_phase = 0	reward = 0.721532	array([[-10.969157, -44.971375]], dtype=float32)
time = 42350	action = 0	current_phase = 1	next_phase = 0	reward = 0.717094	array([[-11.066641, -44.06851 ]], dtype=float32)
time = 42355	action = 0	current_phase = 1	next_phase = 0	reward = 0.716910	array([[-10.966629, -44.146057]], dtype=float32)
time = 42360	action = 0	current_phase = 1	next_phase = 0	reward = 0.720263	array([[-11.176149, -43.518272]], dtype=float32)
time = 42365	action = 0	current_phase = 1	next_phase = 0	reward = 0.728869	array([[-11.086831, -44.361767]], dtype=float32)
time = 42370	action = 0	current_phase = 1	next_phase = 0	reward = 0.723741	array([[-10.967689, -44.65014 ]], dtype=float32)
time = 42375	action = 0	current_phase = 1	next_phase = 0	reward = 0.717192	array([[-11.059397, -45.129963]], dtype=float32)
time = 42380	action = 0	current_phase = 1	next_phase = 0	reward = 0.712334	array([[-10.910839, -43.647354]], dtype=float32)
time = 42385	action = 0	current_phase = 1	next_phase = 0	reward = 0.715030	array([[-11.04838, -43.87729]], dtype=float32)
time = 42390	action = 0	current_phase = 1	next_phase = 0	reward = 0.718588	array([[-10.881151, -44.53613 ]], dtype=float32)
time = 42395	action = 0	current_phase = 1	next_phase = 0	reward = 0.451002	array([[-10.939922, -44.517376]], dtype=float32)
time = 42400	action = 0	current_phase = 1	next_phase = 0	reward = 1.010243	array([[-10.857359, -44.5974  ]], dtype=float32)
time = 42405	action = 0	current_phase = 1	next_phase = 0	reward = 0.724592	array([[-10.9819565, -44.552135 ]], dtype=float32)
time = 42410	action = 0	current_phase = 1	next_phase = 0	reward = 0.726359	array([[-10.941959, -44.079144]], dtype=float32)
time = 42415	action = 0	current_phase = 1	next_phase = 0	reward = 0.731708	array([[-10.933749, -44.198296]], dtype=float32)
time = 42420	action = 0	current_phase = 1	next_phase = 0	reward = 0.717503	array([[-11.025216, -44.65541 ]], dtype=float32)
time = 42425	action = 0	current_phase = 1	next_phase = 0	reward = 0.717261	array([[-10.985632, -44.573685]], dtype=float32)
time = 42430	action = 0	current_phase = 1	next_phase = 0	reward = 0.713943	array([[-10.925375, -44.44541 ]], dtype=float32)
time = 42435	action = 0	current_phase = 1	next_phase = 0	reward = 0.720998	array([[-10.987705, -44.389305]], dtype=float32)
time = 42440	action = 0	current_phase = 1	next_phase = 0	reward = 0.718141	array([[-10.825734, -44.06607 ]], dtype=float32)
time = 42445	action = 0	current_phase = 1	next_phase = 0	reward = 0.718526	array([[-11.04692 , -44.235634]], dtype=float32)
time = 42450	action = 0	current_phase = 1	next_phase = 0	reward = 0.716489	array([[-10.995957, -44.540707]], dtype=float32)
time = 42455	action = 0	current_phase = 1	next_phase = 0	reward = 0.438537	array([[-10.889109, -44.003002]], dtype=float32)
time = 42460	action = 0	current_phase = 1	next_phase = 0	reward = 0.998213	array([[-11.05369, -44.918  ]], dtype=float32)
time = 42465	action = 0	current_phase = 1	next_phase = 0	reward = 0.720232	array([[-11.127026, -44.58286 ]], dtype=float32)
time = 42470	action = 0	current_phase = 1	next_phase = 0	reward = 0.723190	array([[-11.03759, -43.5582 ]], dtype=float32)
time = 42475	action = 0	current_phase = 1	next_phase = 0	reward = 0.714047	array([[-11.032918, -44.621994]], dtype=float32)
time = 42480	action = 0	current_phase = 1	next_phase = 0	reward = 0.720630	array([[-11.028119, -45.013863]], dtype=float32)
time = 42485	action = 0	current_phase = 1	next_phase = 0	reward = 0.717535	array([[-11.148109, -44.085182]], dtype=float32)
time = 42490	action = 0	current_phase = 1	next_phase = 0	reward = 0.728537	array([[-10.943857, -44.549496]], dtype=float32)
time = 42495	action = 0	current_phase = 1	next_phase = 0	reward = 0.447510	array([[-10.965131, -45.037384]], dtype=float32)
time = 42500	action = 0	current_phase = 1	next_phase = 0	reward = 1.007349	array([[-10.982776, -45.185013]], dtype=float32)
time = 42505	action = 0	current_phase = 1	next_phase = 0	reward = 0.723334	array([[-11.036396, -44.626842]], dtype=float32)
time = 42510	action = 0	current_phase = 1	next_phase = 0	reward = 0.719499	array([[-11.024534, -43.866127]], dtype=float32)
time = 42515	action = 0	current_phase = 1	next_phase = 0	reward = 0.723382	array([[-10.697202, -43.132294]], dtype=float32)
time = 42520	action = 0	current_phase = 1	next_phase = 0	reward = 0.718714	array([[-10.96531, -44.64179]], dtype=float32)
time = 42525	action = 0	current_phase = 1	next_phase = 0	reward = 0.724737	array([[-10.990103, -44.27252 ]], dtype=float32)
time = 42530	action = 0	current_phase = 1	next_phase = 0	reward = 0.713321	array([[-10.949293, -44.9677  ]], dtype=float32)
time = 42535	action = 0	current_phase = 1	next_phase = 0	reward = 0.439000	array([[-10.895862, -43.76447 ]], dtype=float32)
time = 42540	action = 0	current_phase = 1	next_phase = 0	reward = 0.725971	array([[-11.018541, -43.98093 ]], dtype=float32)
time = 42545	action = 0	current_phase = 1	next_phase = 0	reward = 1.001394	array([[-11.057956, -44.331482]], dtype=float32)
time = 42550	action = 0	current_phase = 1	next_phase = 0	reward = 0.716453	array([[-11.122706, -43.80891 ]], dtype=float32)
time = 42555	action = 0	current_phase = 1	next_phase = 0	reward = 0.713570	array([[-10.838053, -43.25113 ]], dtype=float32)
time = 42560	action = 0	current_phase = 1	next_phase = 0	reward = 0.437441	array([[-11.049154, -44.570595]], dtype=float32)
time = 42565	action = 0	current_phase = 1	next_phase = 0	reward = 0.728064	array([[-10.939058, -44.000328]], dtype=float32)
time = 42570	action = 0	current_phase = 1	next_phase = 0	reward = 1.011395	array([[-11.04653 , -44.629154]], dtype=float32)
time = 42575	action = 0	current_phase = 1	next_phase = 0	reward = 0.435766	array([[-11.021268, -44.7572  ]], dtype=float32)
time = 42580	action = 0	current_phase = 1	next_phase = 0	reward = 1.005459	array([[-10.975611, -45.117428]], dtype=float32)
time = 42585	action = 0	current_phase = 1	next_phase = 0	reward = 0.718937	array([[-11.022057, -45.006084]], dtype=float32)
time = 42590	action = 0	current_phase = 1	next_phase = 0	reward = 0.441787	array([[-11.02339, -44.82579]], dtype=float32)
time = 42595	action = 0	current_phase = 1	next_phase = 0	reward = 1.003346	array([[-10.996709, -45.175053]], dtype=float32)
time = 42600	action = 0	current_phase = 1	next_phase = 0	reward = 0.720148	array([[-10.96624 , -43.348953]], dtype=float32)
time = 42605	action = 0	current_phase = 1	next_phase = 0	reward = 0.712416	array([[-11.059223, -44.336533]], dtype=float32)
time = 42610	action = 0	current_phase = 1	next_phase = 0	reward = 0.723063	array([[-10.862387, -43.422443]], dtype=float32)
time = 42615	action = 0	current_phase = 1	next_phase = 0	reward = 0.725162	array([[-11.037211, -44.012062]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 7185.0684 - val_loss: 10509.5307
Epoch 2/50
 - 4s - loss: 7181.8722 - val_loss: 10526.3114
Epoch 3/50
 - 4s - loss: 7169.8990 - val_loss: 10503.1659
Epoch 4/50
 - 4s - loss: 7157.8824 - val_loss: 10499.8502
Epoch 5/50
 - 4s - loss: 7156.3075 - val_loss: 10495.5479
Epoch 6/50
 - 4s - loss: 7140.0725 - val_loss: 10496.2142
Epoch 7/50
 - 4s - loss: 7129.9502 - val_loss: 10490.7686
Epoch 8/50
 - 4s - loss: 7123.3785 - val_loss: 10490.0331
Epoch 9/50
 - 4s - loss: 7119.7438 - val_loss: 10476.9170
Epoch 10/50
 - 4s - loss: 7100.4020 - val_loss: 10476.6312
Epoch 11/50
 - 4s - loss: 7106.8590 - val_loss: 10462.6939
Epoch 12/50
 - 4s - loss: 7082.8252 - val_loss: 10461.0274
Epoch 13/50
 - 4s - loss: 7074.4686 - val_loss: 10459.6942
Epoch 14/50
 - 4s - loss: 7072.8577 - val_loss: 10453.1466
Epoch 15/50
 - 4s - loss: 7061.5401 - val_loss: 10448.6478
Epoch 16/50
 - 4s - loss: 7058.5881 - val_loss: 10443.1653
Epoch 17/50
 - 4s - loss: 7048.5063 - val_loss: 10435.8603
Epoch 18/50
 - 4s - loss: 7037.9778 - val_loss: 10435.7783
Epoch 19/50
 - 4s - loss: 7031.6416 - val_loss: 10422.8704
Epoch 20/50
 - 4s - loss: 7022.3373 - val_loss: 10420.1702
Epoch 21/50
 - 4s - loss: 7015.6097 - val_loss: 10414.9351
Epoch 22/50
 - 4s - loss: 7014.7777 - val_loss: 10403.4659
Epoch 23/50
 - 4s - loss: 7002.9897 - val_loss: 10402.8942
Epoch 24/50
 - 4s - loss: 6996.0711 - val_loss: 10404.5712
Epoch 25/50
 - 4s - loss: 6980.7973 - val_loss: 10397.4308
Epoch 26/50
 - 4s - loss: 6977.5936 - val_loss: 10395.6123
Epoch 27/50
 - 4s - loss: 6968.9153 - val_loss: 10396.4183
Epoch 28/50
 - 4s - loss: 6955.9387 - val_loss: 10383.6442
Epoch 29/50
 - 4s - loss: 6950.0878 - val_loss: 10372.3494
Epoch 30/50
 - 4s - loss: 6937.9114 - val_loss: 10376.2505
Epoch 31/50
 - 4s - loss: 6931.6354 - val_loss: 10377.8801
Epoch 32/50
 - 4s - loss: 6925.3077 - val_loss: 10369.8485
Epoch 33/50
 - 4s - loss: 6915.1819 - val_loss: 10358.1147
Epoch 34/50
 - 4s - loss: 6915.3415 - val_loss: 10373.7777
Epoch 35/50
 - 4s - loss: 6903.2284 - val_loss: 10371.2961
Epoch 36/50
 - 4s - loss: 6890.7010 - val_loss: 10344.7943
Epoch 37/50
 - 4s - loss: 6886.7730 - val_loss: 10349.5274
Epoch 38/50
 - 4s - loss: 6876.6896 - val_loss: 10353.0842
Epoch 39/50
 - 4s - loss: 6870.5838 - val_loss: 10336.9930
Epoch 40/50
 - 4s - loss: 6858.6676 - val_loss: 10336.4194
Epoch 41/50
 - 4s - loss: 6856.1254 - val_loss: 10332.9327
Epoch 42/50
 - 4s - loss: 6848.9879 - val_loss: 10315.4473
Epoch 43/50
 - 4s - loss: 6839.6457 - val_loss: 10318.8645
Epoch 44/50
 - 4s - loss: 6830.4582 - val_loss: 10320.0759
Epoch 45/50
 - 4s - loss: 6822.0645 - val_loss: 10306.3520
Epoch 46/50
 - 4s - loss: 6815.2149 - val_loss: 10300.9487
Epoch 47/50
 - 4s - loss: 6808.0519 - val_loss: 10304.7266
Epoch 48/50
 - 4s - loss: 6799.0625 - val_loss: 10306.7330
Epoch 49/50
 - 4s - loss: 6794.3628 - val_loss: 10298.6994
Epoch 50/50
 - 4s - loss: 6784.1921 - val_loss: 10282.9811
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 42620	action = 0	current_phase = 1	next_phase = 0	reward = 0.720362	array([[-10.175119, -44.730515]], dtype=float32)
time = 42625	action = 0	current_phase = 1	next_phase = 0	reward = 0.729914	array([[-10.198387, -45.057472]], dtype=float32)
time = 42630	action = 0	current_phase = 1	next_phase = 0	reward = 0.724687	array([[-10.207014, -44.20169 ]], dtype=float32)
time = 42635	action = 0	current_phase = 1	next_phase = 0	reward = 0.721997	array([[-10.211993, -44.512077]], dtype=float32)
time = 42640	action = 0	current_phase = 1	next_phase = 0	reward = 0.714030	array([[-10.14291 , -44.198063]], dtype=float32)
time = 42645	action = 0	current_phase = 1	next_phase = 0	reward = 0.725823	array([[-10.250562, -44.85666 ]], dtype=float32)
time = 42650	action = 0	current_phase = 1	next_phase = 0	reward = 0.722179	array([[-10.224355, -44.75634 ]], dtype=float32)
time = 42655	action = 0	current_phase = 1	next_phase = 0	reward = 0.723103	array([[-10.183701, -44.82444 ]], dtype=float32)
time = 42660	action = 0	current_phase = 1	next_phase = 0	reward = 0.720239	array([[-10.184633, -44.690975]], dtype=float32)
time = 42665	action = 0	current_phase = 1	next_phase = 0	reward = 0.715180	array([[-10.228437, -44.720116]], dtype=float32)
time = 42670	action = 0	current_phase = 1	next_phase = 0	reward = 0.728200	array([[-10.123252, -44.6015  ]], dtype=float32)
time = 42675	action = 0	current_phase = 1	next_phase = 0	reward = 0.726885	array([[-10.162746, -43.96405 ]], dtype=float32)
time = 42680	action = 0	current_phase = 1	next_phase = 0	reward = 0.724466	array([[-10.191376, -44.662884]], dtype=float32)
time = 42685	action = 0	current_phase = 1	next_phase = 0	reward = 0.444611	array([[-10.209812, -45.08814 ]], dtype=float32)
time = 42690	action = 0	current_phase = 1	next_phase = 0	reward = 1.010795	array([[-10.224323, -44.496532]], dtype=float32)
time = 42695	action = 0	current_phase = 1	next_phase = 0	reward = 0.724536	array([[-10.125816, -44.66367 ]], dtype=float32)
time = 42700	action = 0	current_phase = 1	next_phase = 0	reward = 0.720932	array([[-10.192429, -44.9349  ]], dtype=float32)
time = 42705	action = 0	current_phase = 1	next_phase = 0	reward = 0.716264	array([[-10.157311, -44.586243]], dtype=float32)
time = 42710	action = 0	current_phase = 1	next_phase = 0	reward = 0.431933	array([[-10.092171, -44.039295]], dtype=float32)
time = 42715	action = 0	current_phase = 1	next_phase = 0	reward = 0.999817	array([[-10.054239, -44.06679 ]], dtype=float32)
time = 42720	action = 0	current_phase = 1	next_phase = 0	reward = 0.440824	array([[-10.167607, -44.5765  ]], dtype=float32)
time = 42725	action = 0	current_phase = 1	next_phase = 0	reward = 0.733484	array([[-10.195167, -44.8951  ]], dtype=float32)
time = 42730	action = 0	current_phase = 1	next_phase = 0	reward = 1.003884	array([[-10.174284, -44.966225]], dtype=float32)
time = 42735	action = 0	current_phase = 1	next_phase = 0	reward = 0.720011	array([[-10.171047, -44.738205]], dtype=float32)
time = 42740	action = 0	current_phase = 1	next_phase = 0	reward = 0.726264	array([[-10.191781, -44.395477]], dtype=float32)
time = 42745	action = 0	current_phase = 1	next_phase = 0	reward = 0.441800	array([[-10.168647, -44.407467]], dtype=float32)
time = 42750	action = 0	current_phase = 1	next_phase = 0	reward = 1.000063	array([[-10.229427, -44.906452]], dtype=float32)
time = 42755	action = 0	current_phase = 1	next_phase = 0	reward = 0.715677	array([[-10.154945, -44.1605  ]], dtype=float32)
time = 42760	action = 0	current_phase = 1	next_phase = 0	reward = 0.717272	array([[-10.099886, -43.92572 ]], dtype=float32)
time = 42765	action = 0	current_phase = 1	next_phase = 0	reward = 0.442954	array([[-10.111434, -43.786514]], dtype=float32)
time = 42770	action = 0	current_phase = 1	next_phase = 0	reward = 0.996906	array([[-10.147732, -44.344223]], dtype=float32)
time = 42775	action = 0	current_phase = 1	next_phase = 0	reward = 0.711081	array([[-10.2014675, -44.78248  ]], dtype=float32)
time = 42780	action = 0	current_phase = 1	next_phase = 0	reward = 0.714574	array([[-10.199318, -44.553814]], dtype=float32)
time = 42785	action = 0	current_phase = 1	next_phase = 0	reward = 0.443607	array([[-10.147523, -44.545162]], dtype=float32)
time = 42790	action = 0	current_phase = 1	next_phase = 0	reward = 0.727698	array([[-10.214657, -44.50629 ]], dtype=float32)
time = 42795	action = 0	current_phase = 1	next_phase = 0	reward = 1.011675	array([[-10.240141, -45.0821  ]], dtype=float32)
time = 42800	action = 0	current_phase = 1	next_phase = 0	reward = 0.719634	array([[-10.203843, -43.975456]], dtype=float32)
time = 42805	action = 0	current_phase = 1	next_phase = 0	reward = 0.714021	array([[-10.103291, -43.677555]], dtype=float32)
time = 42810	action = 0	current_phase = 1	next_phase = 0	reward = 0.709277	array([[-10.216263, -44.439613]], dtype=float32)
time = 42815	action = 0	current_phase = 1	next_phase = 0	reward = 0.725340	array([[-10.187611, -44.371014]], dtype=float32)
time = 42820	action = 0	current_phase = 1	next_phase = 0	reward = 0.716978	array([[-10.158214, -44.587353]], dtype=float32)
time = 42825	action = 0	current_phase = 1	next_phase = 0	reward = 0.438646	array([[-10.22847, -44.9879 ]], dtype=float32)
time = 42830	action = 0	current_phase = 1	next_phase = 0	reward = 0.998348	array([[-10.142076, -44.34017 ]], dtype=float32)
time = 42835	action = 0	current_phase = 1	next_phase = 0	reward = 0.713598	array([[-10.221352, -44.438053]], dtype=float32)
time = 42840	action = 0	current_phase = 1	next_phase = 0	reward = 0.439877	array([[-10.189647, -44.348255]], dtype=float32)
time = 42845	action = 0	current_phase = 1	next_phase = 0	reward = 0.999663	array([[-10.207073, -43.13986 ]], dtype=float32)
time = 42850	action = 0	current_phase = 1	next_phase = 0	reward = 0.440704	array([[-10.203314, -45.196598]], dtype=float32)
time = 42855	action = 0	current_phase = 1	next_phase = 0	reward = 1.000516	array([[-10.148435, -44.683533]], dtype=float32)
time = 42860	action = 0	current_phase = 1	next_phase = 0	reward = 0.721710	array([[-10.182062, -43.748104]], dtype=float32)
time = 42865	action = 0	current_phase = 1	next_phase = 0	reward = 0.729103	array([[-10.201317, -44.407528]], dtype=float32)
time = 42870	action = 0	current_phase = 1	next_phase = 0	reward = 0.716557	array([[-10.235231, -45.03082 ]], dtype=float32)
time = 42875	action = 0	current_phase = 1	next_phase = 0	reward = 0.724617	array([[-10.193562, -44.906742]], dtype=float32)
time = 42880	action = 0	current_phase = 1	next_phase = 0	reward = 0.442520	array([[-10.179881, -43.950153]], dtype=float32)
time = 42885	action = 0	current_phase = 1	next_phase = 0	reward = 1.004616	array([[-10.17149 , -44.746784]], dtype=float32)
time = 42890	action = 0	current_phase = 1	next_phase = 0	reward = 0.452572	array([[-10.216217, -44.697353]], dtype=float32)
time = 42895	action = 0	current_phase = 1	next_phase = 0	reward = 1.009082	array([[-10.180021, -44.46461 ]], dtype=float32)
time = 42900	action = 0	current_phase = 1	next_phase = 0	reward = 0.722784	array([[-10.211407, -44.11812 ]], dtype=float32)
time = 42905	action = 0	current_phase = 1	next_phase = 0	reward = 0.714621	array([[-10.182093, -44.318615]], dtype=float32)
time = 42910	action = 0	current_phase = 1	next_phase = 0	reward = 0.724309	array([[-10.191383, -44.74371 ]], dtype=float32)
time = 42915	action = 0	current_phase = 1	next_phase = 0	reward = 0.725062	array([[-10.14517 , -44.509155]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 6425.0947 - val_loss: 6277.2583
Epoch 2/50
 - 4s - loss: 6430.6260 - val_loss: 6265.2639
Epoch 3/50
 - 4s - loss: 6421.7137 - val_loss: 6253.3091
Epoch 4/50
 - 4s - loss: 6402.0258 - val_loss: 6236.8289
Epoch 5/50
 - 4s - loss: 6401.0901 - val_loss: 6258.1719
Epoch 6/50
 - 4s - loss: 6385.4964 - val_loss: 6240.1169
Epoch 7/50
 - 4s - loss: 6374.1759 - val_loss: 6218.3087
Epoch 8/50
 - 4s - loss: 6367.9941 - val_loss: 6219.8593
Epoch 9/50
 - 4s - loss: 6363.9040 - val_loss: 6213.2020
Epoch 10/50
 - 4s - loss: 6355.6590 - val_loss: 6207.6627
Epoch 11/50
 - 4s - loss: 6352.1304 - val_loss: 6218.0838
Epoch 12/50
 - 4s - loss: 6343.8384 - val_loss: 6208.8818
Epoch 13/50
 - 4s - loss: 6338.2944 - val_loss: 6185.9269
Epoch 14/50
 - 4s - loss: 6328.4730 - val_loss: 6185.5091
Epoch 15/50
 - 4s - loss: 6311.1506 - val_loss: 6184.0606
Epoch 16/50
 - 4s - loss: 6306.7408 - val_loss: 6176.8129
Epoch 17/50
 - 4s - loss: 6292.4972 - val_loss: 6159.0250
Epoch 18/50
 - 4s - loss: 6292.1755 - val_loss: 6151.9155
Epoch 19/50
 - 4s - loss: 6286.6739 - val_loss: 6146.8047
Epoch 20/50
 - 4s - loss: 6292.4898 - val_loss: 6146.4622
Epoch 21/50
 - 4s - loss: 6270.2054 - val_loss: 6154.4639
Epoch 22/50
 - 4s - loss: 6269.2543 - val_loss: 6135.8373
Epoch 23/50
 - 4s - loss: 6257.7214 - val_loss: 6134.2131
Epoch 24/50
 - 4s - loss: 6249.4425 - val_loss: 6123.1595
Epoch 25/50
 - 4s - loss: 6241.3893 - val_loss: 6106.6438
Epoch 26/50
 - 4s - loss: 6227.9044 - val_loss: 6114.1964
Epoch 27/50
 - 4s - loss: 6233.7220 - val_loss: 6108.0058
Epoch 28/50
 - 4s - loss: 6219.6871 - val_loss: 6103.8704
Epoch 29/50
 - 4s - loss: 6210.1032 - val_loss: 6085.9305
Epoch 30/50
 - 4s - loss: 6216.2216 - val_loss: 6095.0968
Epoch 31/50
 - 4s - loss: 6211.7571 - val_loss: 6076.5250
Epoch 32/50
 - 4s - loss: 6189.1319 - val_loss: 6074.2241
Epoch 33/50
 - 4s - loss: 6180.5510 - val_loss: 6061.3243
Epoch 34/50
 - 4s - loss: 6173.8798 - val_loss: 6063.1188
Epoch 35/50
 - 4s - loss: 6170.1815 - val_loss: 6053.1246
Epoch 36/50
 - 4s - loss: 6162.8933 - val_loss: 6059.5143
Epoch 37/50
 - 4s - loss: 6160.0536 - val_loss: 6051.0896
Epoch 38/50
 - 4s - loss: 6148.3057 - val_loss: 6038.3935
Epoch 39/50
 - 4s - loss: 6138.6917 - val_loss: 6025.3461
Epoch 40/50
 - 4s - loss: 6137.3010 - val_loss: 6032.5051
Epoch 41/50
 - 4s - loss: 6135.0064 - val_loss: 6013.3504
Epoch 42/50
 - 4s - loss: 6117.9002 - val_loss: 6006.0637
Epoch 43/50
 - 4s - loss: 6114.7059 - val_loss: 6012.2231
Epoch 44/50
 - 4s - loss: 6111.1406 - val_loss: 6012.9091
Epoch 45/50
 - 4s - loss: 6096.5703 - val_loss: 5992.7046
Epoch 46/50
 - 4s - loss: 6095.5843 - val_loss: 5987.1020
Epoch 47/50
 - 4s - loss: 6093.0333 - val_loss: 5989.8146
Epoch 48/50
 - 4s - loss: 6072.7445 - val_loss: 5976.7666
Epoch 49/50
 - 4s - loss: 6065.7707 - val_loss: 5973.5755
Epoch 50/50
 - 4s - loss: 6072.2584 - val_loss: 5961.5816
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 42920	action = 0	current_phase = 1	next_phase = 0	reward = 0.718178	array([[ -9.727026, -44.274185]], dtype=float32)
time = 42925	action = 0	current_phase = 1	next_phase = 0	reward = 0.442071	array([[ -9.685654, -44.134422]], dtype=float32)
time = 42930	action = 0	current_phase = 1	next_phase = 0	reward = 1.000331	array([[ -9.589271, -43.396194]], dtype=float32)
time = 42935	action = 0	current_phase = 1	next_phase = 0	reward = 0.716204	array([[ -9.672955, -44.110615]], dtype=float32)
time = 42940	action = 0	current_phase = 1	next_phase = 0	reward = 0.436255	array([[ -9.729894, -44.08075 ]], dtype=float32)
time = 42945	action = 0	current_phase = 1	next_phase = 0	reward = 1.003203	array([[ -9.769007, -44.57883 ]], dtype=float32)
time = 42950	action = 0	current_phase = 1	next_phase = 0	reward = 0.715107	array([[ -9.733831, -44.342556]], dtype=float32)
time = 42955	action = 0	current_phase = 1	next_phase = 0	reward = 0.717655	array([[ -9.700852, -44.251385]], dtype=float32)
time = 42960	action = 0	current_phase = 1	next_phase = 0	reward = 0.723463	array([[ -9.709103, -44.131424]], dtype=float32)
time = 42965	action = 0	current_phase = 1	next_phase = 0	reward = 0.730170	array([[ -9.700784, -44.06269 ]], dtype=float32)
time = 42970	action = 0	current_phase = 1	next_phase = 0	reward = 0.442998	array([[ -9.749472, -44.54919 ]], dtype=float32)
time = 42975	action = 0	current_phase = 1	next_phase = 0	reward = 0.997957	array([[ -9.743265, -44.680984]], dtype=float32)
time = 42980	action = 0	current_phase = 1	next_phase = 0	reward = 0.719948	array([[ -9.769455, -44.454533]], dtype=float32)
time = 42985	action = 0	current_phase = 1	next_phase = 0	reward = 0.716210	array([[ -9.753438, -44.626328]], dtype=float32)
time = 42990	action = 0	current_phase = 1	next_phase = 0	reward = 0.439603	array([[ -9.741808, -44.462154]], dtype=float32)
time = 42995	action = 0	current_phase = 1	next_phase = 0	reward = 0.727146	array([[ -9.754789, -44.265766]], dtype=float32)
time = 43000	action = 0	current_phase = 1	next_phase = 0	reward = 1.006558	array([[ -9.731539, -44.539074]], dtype=float32)
time = 43005	action = 0	current_phase = 1	next_phase = 0	reward = 0.729327	array([[ -9.756721, -44.533466]], dtype=float32)
time = 43010	action = 0	current_phase = 1	next_phase = 0	reward = 0.725043	array([[ -9.731042, -44.078785]], dtype=float32)
time = 43015	action = 0	current_phase = 1	next_phase = 0	reward = 0.434331	array([[ -9.665523, -43.986366]], dtype=float32)
time = 43020	action = 0	current_phase = 1	next_phase = 0	reward = 1.000210	array([[ -9.750175, -44.550426]], dtype=float32)
time = 43025	action = 0	current_phase = 1	next_phase = 0	reward = 0.716914	array([[ -9.729232, -44.49831 ]], dtype=float32)
time = 43030	action = 0	current_phase = 1	next_phase = 0	reward = 0.724338	array([[ -9.734492, -44.53687 ]], dtype=float32)
time = 43035	action = 0	current_phase = 1	next_phase = 0	reward = 0.443173	array([[ -9.69181 , -43.872124]], dtype=float32)
time = 43040	action = 0	current_phase = 1	next_phase = 0	reward = 1.002262	array([[ -9.740279, -44.46424 ]], dtype=float32)
time = 43045	action = 0	current_phase = 1	next_phase = 0	reward = 0.714584	array([[ -9.752875, -44.270725]], dtype=float32)
time = 43050	action = 0	current_phase = 1	next_phase = 0	reward = 0.716944	array([[ -9.712528, -44.30621 ]], dtype=float32)
time = 43055	action = 0	current_phase = 1	next_phase = 0	reward = 0.166139	array([[ -9.737063, -44.610912]], dtype=float32)
time = 43060	action = 0	current_phase = 1	next_phase = 0	reward = 1.015017	array([[ -9.752467, -44.719173]], dtype=float32)
time = 43065	action = 0	current_phase = 1	next_phase = 0	reward = 1.007781	array([[ -9.745827, -44.490482]], dtype=float32)
time = 43070	action = 0	current_phase = 1	next_phase = 0	reward = 0.714931	array([[ -9.723285, -44.32285 ]], dtype=float32)
time = 43075	action = 0	current_phase = 1	next_phase = 0	reward = 0.442845	array([[ -9.692106, -44.03445 ]], dtype=float32)
time = 43080	action = 0	current_phase = 1	next_phase = 0	reward = 1.004921	array([[ -9.708043, -44.314457]], dtype=float32)
time = 43085	action = 0	current_phase = 1	next_phase = 0	reward = 0.440540	array([[ -9.724187, -44.270172]], dtype=float32)
time = 43090	action = 0	current_phase = 1	next_phase = 0	reward = 1.006000	array([[ -9.707967, -44.401875]], dtype=float32)
time = 43095	action = 0	current_phase = 1	next_phase = 0	reward = 0.717178	array([[ -9.711987, -44.461678]], dtype=float32)
time = 43100	action = 0	current_phase = 1	next_phase = 0	reward = 0.718025	array([[ -9.732837, -44.415882]], dtype=float32)
time = 43105	action = 0	current_phase = 1	next_phase = 0	reward = 0.434461	array([[ -9.699567, -44.01388 ]], dtype=float32)
time = 43110	action = 0	current_phase = 1	next_phase = 0	reward = 1.001464	array([[ -9.750475, -44.465675]], dtype=float32)
time = 43115	action = 0	current_phase = 1	next_phase = 0	reward = 0.722375	array([[ -9.784202, -44.711727]], dtype=float32)
time = 43120	action = 0	current_phase = 1	next_phase = 0	reward = 0.447219	array([[ -9.721949, -44.18106 ]], dtype=float32)
time = 43125	action = 0	current_phase = 1	next_phase = 0	reward = 1.006062	array([[ -9.741003, -44.597908]], dtype=float32)
time = 43130	action = 0	current_phase = 1	next_phase = 0	reward = 0.704768	array([[ -9.711376, -44.492165]], dtype=float32)
time = 43135	action = 0	current_phase = 1	next_phase = 0	reward = 0.715729	array([[ -9.734939, -44.53953 ]], dtype=float32)
time = 43140	action = 0	current_phase = 1	next_phase = 0	reward = 0.442891	array([[ -9.760027, -44.452168]], dtype=float32)
time = 43145	action = 0	current_phase = 1	next_phase = 0	reward = 0.730767	array([[ -9.749122, -44.5915  ]], dtype=float32)
time = 43150	action = 0	current_phase = 1	next_phase = 0	reward = 0.728937	array([[ -9.800659, -44.130768]], dtype=float32)
time = 43155	action = 0	current_phase = 1	next_phase = 0	reward = 1.005670	array([[ -9.738594, -44.5105  ]], dtype=float32)
time = 43160	action = 0	current_phase = 1	next_phase = 0	reward = 0.722331	array([[ -9.697125, -44.427452]], dtype=float32)
time = 43165	action = 0	current_phase = 1	next_phase = 0	reward = 0.724108	array([[ -9.751237, -44.401287]], dtype=float32)
time = 43170	action = 0	current_phase = 1	next_phase = 0	reward = 0.723752	array([[ -9.732175, -44.31019 ]], dtype=float32)
time = 43175	action = 0	current_phase = 1	next_phase = 0	reward = 0.722063	array([[ -9.733853, -44.489525]], dtype=float32)
time = 43180	action = 0	current_phase = 1	next_phase = 0	reward = 0.720049	array([[ -9.825994, -44.880222]], dtype=float32)
time = 43185	action = 0	current_phase = 1	next_phase = 0	reward = 0.714819	array([[ -9.743625, -44.48409 ]], dtype=float32)
time = 43190	action = 0	current_phase = 1	next_phase = 0	reward = 0.707213	array([[ -9.745364, -44.651905]], dtype=float32)
time = 43195	action = 0	current_phase = 1	next_phase = 0	reward = 0.441319	array([[ -9.660788, -43.992622]], dtype=float32)
time = 43200	action = 0	current_phase = 1	next_phase = 0	reward = 0.722965	array([[ -9.675352, -44.244053]], dtype=float32)
time = 43205	action = 0	current_phase = 1	next_phase = 0	reward = 0.726702	array([[ -9.756225, -44.73292 ]], dtype=float32)
time = 43210	action = 0	current_phase = 1	next_phase = 0	reward = 1.006134	array([[ -9.816782, -44.44527 ]], dtype=float32)
time = 43215	action = 0	current_phase = 1	next_phase = 0	reward = 0.722477	array([[ -9.732366, -44.590702]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 5435.6519 - val_loss: 8986.7814
Epoch 2/50
 - 4s - loss: 5441.7595 - val_loss: 8984.8266
Epoch 3/50
 - 4s - loss: 5422.9324 - val_loss: 8967.5653
Epoch 4/50
 - 4s - loss: 5419.0783 - val_loss: 8957.2185
Epoch 5/50
 - 4s - loss: 5418.4894 - val_loss: 8948.8416
Epoch 6/50
 - 4s - loss: 5405.3183 - val_loss: 8931.7159
Epoch 7/50
 - 4s - loss: 5399.9141 - val_loss: 8935.0437
Epoch 8/50
 - 4s - loss: 5401.6209 - val_loss: 8918.7673
Epoch 9/50
 - 4s - loss: 5394.0195 - val_loss: 8905.2325
Epoch 10/50
 - 4s - loss: 5388.4750 - val_loss: 8898.7656
Epoch 11/50
 - 4s - loss: 5385.5984 - val_loss: 8881.8137
Epoch 12/50
 - 4s - loss: 5378.4913 - val_loss: 8867.1023
Epoch 13/50
 - 4s - loss: 5376.9008 - val_loss: 8881.4930
Epoch 14/50
 - 4s - loss: 5367.5327 - val_loss: 8859.4180
Epoch 15/50
 - 4s - loss: 5369.6778 - val_loss: 8845.8428
Epoch 16/50
 - 4s - loss: 5358.9546 - val_loss: 8833.3987
Epoch 17/50
 - 4s - loss: 5355.0766 - val_loss: 8846.7666
Epoch 18/50
 - 4s - loss: 5353.9798 - val_loss: 8838.6554
Epoch 19/50
 - 4s - loss: 5345.6878 - val_loss: 8808.8570
Epoch 20/50
 - 4s - loss: 5337.7127 - val_loss: 8794.9717
Epoch 21/50
 - 4s - loss: 5339.7438 - val_loss: 8782.1157
Epoch 22/50
 - 4s - loss: 5345.8541 - val_loss: 8789.1966
Epoch 23/50
 - 4s - loss: 5335.8947 - val_loss: 8765.5508
Epoch 24/50
 - 4s - loss: 5326.3135 - val_loss: 8762.9675
Epoch 25/50
 - 4s - loss: 5324.4135 - val_loss: 8749.8659
Epoch 26/50
 - 4s - loss: 5317.3739 - val_loss: 8735.8413
Epoch 27/50
 - 4s - loss: 5315.9073 - val_loss: 8747.1205
Epoch 28/50
 - 4s - loss: 5301.6887 - val_loss: 8735.0969
Epoch 29/50
 - 4s - loss: 5307.1985 - val_loss: 8723.1819
Epoch 30/50
 - 4s - loss: 5297.1062 - val_loss: 8721.4178
Epoch 31/50
 - 4s - loss: 5294.2582 - val_loss: 8701.6821
Epoch 32/50
 - 4s - loss: 5290.6304 - val_loss: 8682.2416
Epoch 33/50
 - 4s - loss: 5286.5269 - val_loss: 8674.5936
Epoch 34/50
 - 4s - loss: 5288.3711 - val_loss: 8683.2299
Epoch 35/50
 - 4s - loss: 5275.4061 - val_loss: 8651.0869
Epoch 36/50
 - 4s - loss: 5283.3100 - val_loss: 8642.7603
Epoch 37/50
 - 4s - loss: 5264.4980 - val_loss: 8644.2714
Epoch 38/50
 - 4s - loss: 5262.3992 - val_loss: 8640.6395
Epoch 39/50
 - 4s - loss: 5260.0373 - val_loss: 8616.6283
Epoch 40/50
 - 4s - loss: 5251.4962 - val_loss: 8638.3789
Epoch 41/50
 - 4s - loss: 5285.4449 - val_loss: 8597.5814
Epoch 42/50
 - 4s - loss: 5245.3973 - val_loss: 8597.8278
Epoch 43/50
 - 4s - loss: 5253.6047 - val_loss: 8579.1375
Epoch 44/50
 - 4s - loss: 5244.3418 - val_loss: 8570.8592
Epoch 45/50
 - 4s - loss: 5235.0470 - val_loss: 8555.3318
Epoch 46/50
 - 4s - loss: 5228.0077 - val_loss: 8553.0855
Epoch 47/50
 - 4s - loss: 5223.7203 - val_loss: 8549.7434
Epoch 48/50
 - 4s - loss: 5224.9098 - val_loss: 8508.6428
Epoch 49/50
 - 4s - loss: 5220.9269 - val_loss: 8526.5243
Epoch 50/50
 - 4s - loss: 5215.1728 - val_loss: 8505.7069
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 43220	action = 0	current_phase = 1	next_phase = 0	reward = 0.722341	array([[ -9.562082, -44.06562 ]], dtype=float32)
time = 43225	action = 0	current_phase = 1	next_phase = 0	reward = 0.718670	array([[ -9.626902, -44.45127 ]], dtype=float32)
time = 43230	action = 0	current_phase = 1	next_phase = 0	reward = 0.719852	array([[ -9.584408, -44.134636]], dtype=float32)
time = 43235	action = 0	current_phase = 1	next_phase = 0	reward = 0.448587	array([[ -9.515396, -43.685402]], dtype=float32)
time = 43240	action = 0	current_phase = 1	next_phase = 0	reward = 1.004734	array([[ -9.537986, -43.933792]], dtype=float32)
time = 43245	action = 0	current_phase = 1	next_phase = 0	reward = 0.721417	array([[ -9.538404, -43.98169 ]], dtype=float32)
time = 43250	action = 0	current_phase = 1	next_phase = 0	reward = 0.712413	array([[ -9.598584, -44.323814]], dtype=float32)
time = 43255	action = 0	current_phase = 1	next_phase = 0	reward = 0.713814	array([[ -9.545189, -44.00831 ]], dtype=float32)
time = 43260	action = 0	current_phase = 1	next_phase = 0	reward = 0.715801	array([[ -9.570199, -44.14795 ]], dtype=float32)
time = 43265	action = 0	current_phase = 1	next_phase = 0	reward = 0.163022	array([[ -9.601712, -44.19895 ]], dtype=float32)
time = 43270	action = 0	current_phase = 1	next_phase = 0	reward = 1.283916	array([[ -9.585798, -44.145805]], dtype=float32)
time = 43275	action = 0	current_phase = 1	next_phase = 0	reward = 0.447275	array([[ -9.5497055, -44.101204 ]], dtype=float32)
time = 43280	action = 0	current_phase = 1	next_phase = 0	reward = 0.997099	array([[ -9.576054, -44.037277]], dtype=float32)
time = 43285	action = 0	current_phase = 1	next_phase = 0	reward = 0.450802	array([[ -9.600652, -44.377   ]], dtype=float32)
time = 43290	action = 0	current_phase = 1	next_phase = 0	reward = 1.004439	array([[ -9.611555, -44.25566 ]], dtype=float32)
time = 43295	action = 0	current_phase = 1	next_phase = 0	reward = 0.718863	array([[ -9.6147785, -44.373444 ]], dtype=float32)
time = 43300	action = 0	current_phase = 1	next_phase = 0	reward = 0.714232	array([[ -9.507595, -43.69667 ]], dtype=float32)
time = 43305	action = 0	current_phase = 1	next_phase = 0	reward = 0.436235	array([[ -9.578557, -44.24504 ]], dtype=float32)
time = 43310	action = 0	current_phase = 1	next_phase = 0	reward = 0.732627	array([[ -9.537324, -44.006645]], dtype=float32)
time = 43315	action = 0	current_phase = 1	next_phase = 0	reward = 1.008925	array([[ -9.576107, -44.177177]], dtype=float32)
time = 43320	action = 0	current_phase = 1	next_phase = 0	reward = 0.723783	array([[ -9.536016, -43.985275]], dtype=float32)
time = 43325	action = 0	current_phase = 1	next_phase = 0	reward = 0.443627	array([[ -9.574677, -44.146057]], dtype=float32)
time = 43330	action = 0	current_phase = 1	next_phase = 0	reward = 1.000221	array([[ -9.55806 , -44.152298]], dtype=float32)
time = 43335	action = 0	current_phase = 1	next_phase = 0	reward = 0.437447	array([[ -9.527893, -43.892   ]], dtype=float32)
time = 43340	action = 0	current_phase = 1	next_phase = 0	reward = 1.002489	array([[ -9.581407, -44.142456]], dtype=float32)
time = 43345	action = 0	current_phase = 1	next_phase = 0	reward = 0.708518	array([[ -9.612667, -44.14891 ]], dtype=float32)
time = 43350	action = 0	current_phase = 1	next_phase = 0	reward = 0.717942	array([[ -9.585467, -43.98298 ]], dtype=float32)
time = 43355	action = 0	current_phase = 1	next_phase = 0	reward = 0.721469	array([[ -9.602221, -44.278137]], dtype=float32)
time = 43360	action = 0	current_phase = 1	next_phase = 0	reward = 0.444881	array([[ -9.608991, -44.235535]], dtype=float32)
time = 43365	action = 0	current_phase = 1	next_phase = 0	reward = 0.724790	array([[ -9.600345, -44.32435 ]], dtype=float32)
time = 43370	action = 0	current_phase = 1	next_phase = 0	reward = 1.003196	array([[ -9.582118, -44.24537 ]], dtype=float32)
time = 43375	action = 0	current_phase = 1	next_phase = 0	reward = 0.440456	array([[ -9.57682 , -44.153206]], dtype=float32)
time = 43380	action = 0	current_phase = 1	next_phase = 0	reward = 0.990514	array([[ -9.553586, -44.06636 ]], dtype=float32)
time = 43385	action = 0	current_phase = 1	next_phase = 0	reward = 0.439161	array([[ -9.602258, -44.169838]], dtype=float32)
time = 43390	action = 0	current_phase = 1	next_phase = 0	reward = 0.451025	array([[ -9.596186, -44.254402]], dtype=float32)
time = 43395	action = 0	current_phase = 1	next_phase = 0	reward = 1.292115	array([[ -9.585035, -44.24521 ]], dtype=float32)
time = 43400	action = 0	current_phase = 1	next_phase = 0	reward = 0.720619	array([[ -9.577107, -44.154884]], dtype=float32)
time = 43405	action = 0	current_phase = 1	next_phase = 0	reward = 0.437416	array([[ -9.588265, -44.23906 ]], dtype=float32)
time = 43410	action = 0	current_phase = 1	next_phase = 0	reward = 0.728766	array([[ -9.603355, -44.208977]], dtype=float32)
time = 43415	action = 0	current_phase = 1	next_phase = 0	reward = 1.005728	array([[ -9.601086, -44.27552 ]], dtype=float32)
time = 43420	action = 0	current_phase = 1	next_phase = 0	reward = 0.446632	array([[ -9.603714, -44.306137]], dtype=float32)
time = 43425	action = 0	current_phase = 1	next_phase = 0	reward = 0.997393	array([[ -9.555848, -44.016922]], dtype=float32)
time = 43430	action = 0	current_phase = 1	next_phase = 0	reward = 0.716734	array([[ -9.585536, -44.254684]], dtype=float32)
time = 43435	action = 0	current_phase = 1	next_phase = 0	reward = 0.712592	array([[ -9.53133 , -43.844887]], dtype=float32)
time = 43440	action = 0	current_phase = 1	next_phase = 0	reward = 0.718044	array([[ -9.608936, -44.28932 ]], dtype=float32)
time = 43445	action = 0	current_phase = 1	next_phase = 0	reward = 0.714287	array([[ -9.556498, -43.994316]], dtype=float32)
time = 43450	action = 0	current_phase = 1	next_phase = 0	reward = 0.714801	array([[ -9.580633, -44.1904  ]], dtype=float32)
time = 43455	action = 0	current_phase = 1	next_phase = 0	reward = 0.447795	array([[ -9.537292, -43.953514]], dtype=float32)
time = 43460	action = 0	current_phase = 1	next_phase = 0	reward = 0.719812	array([[ -9.588391, -44.2538  ]], dtype=float32)
time = 43465	action = 0	current_phase = 1	next_phase = 0	reward = 0.453857	array([[ -9.599813, -44.28409 ]], dtype=float32)
time = 43470	action = 0	current_phase = 1	next_phase = 0	reward = 1.288878	array([[ -9.613399, -44.350563]], dtype=float32)
time = 43475	action = 0	current_phase = 1	next_phase = 0	reward = 0.717535	array([[ -9.621145, -44.3432  ]], dtype=float32)
time = 43480	action = 0	current_phase = 1	next_phase = 0	reward = 0.718051	array([[ -9.556923, -43.998444]], dtype=float32)
time = 43485	action = 0	current_phase = 1	next_phase = 0	reward = 0.718601	array([[ -9.602247, -44.14409 ]], dtype=float32)
time = 43490	action = 0	current_phase = 1	next_phase = 0	reward = 0.717322	array([[ -9.707788, -44.719055]], dtype=float32)
time = 43495	action = 0	current_phase = 1	next_phase = 0	reward = 0.720364	array([[ -9.494689, -43.67778 ]], dtype=float32)
time = 43500	action = 0	current_phase = 1	next_phase = 0	reward = 0.721889	array([[ -9.580292, -44.130386]], dtype=float32)
time = 43505	action = 0	current_phase = 1	next_phase = 0	reward = 0.718329	array([[ -9.608977, -44.311043]], dtype=float32)
time = 43510	action = 0	current_phase = 1	next_phase = 0	reward = 0.714208	array([[ -9.529757, -43.88185 ]], dtype=float32)
time = 43515	action = 0	current_phase = 1	next_phase = 0	reward = 0.715232	array([[ -9.623012, -44.11451 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 6077.4052 - val_loss: 12032.5368
Epoch 2/50
 - 4s - loss: 6072.3278 - val_loss: 12006.4211
Epoch 3/50
 - 4s - loss: 6068.7601 - val_loss: 11986.1359
Epoch 4/50
 - 4s - loss: 6063.0349 - val_loss: 11980.4002
Epoch 5/50
 - 4s - loss: 6063.6899 - val_loss: 11966.3195
Epoch 6/50
 - 4s - loss: 6048.8137 - val_loss: 11970.1183
Epoch 7/50
 - 4s - loss: 6039.8959 - val_loss: 11974.2383
Epoch 8/50
 - 4s - loss: 6032.7587 - val_loss: 11951.3042
Epoch 9/50
 - 4s - loss: 6019.8297 - val_loss: 11947.1110
Epoch 10/50
 - 4s - loss: 6029.7029 - val_loss: 11926.2335
Epoch 11/50
 - 4s - loss: 6011.8733 - val_loss: 11918.3445
Epoch 12/50
 - 4s - loss: 6004.3122 - val_loss: 11911.1653
Epoch 13/50
 - 4s - loss: 5991.2060 - val_loss: 11913.3837
Epoch 14/50
 - 4s - loss: 5991.8727 - val_loss: 11894.8790
Epoch 15/50
 - 4s - loss: 5977.2369 - val_loss: 11892.4457
Epoch 16/50
 - 4s - loss: 5976.9445 - val_loss: 11882.9063
Epoch 17/50
 - 4s - loss: 5969.1738 - val_loss: 11872.6946
Epoch 18/50
 - 4s - loss: 5963.7806 - val_loss: 11853.9994
Epoch 19/50
 - 4s - loss: 5963.6719 - val_loss: 11843.3020
Epoch 20/50
 - 4s - loss: 5950.4287 - val_loss: 11836.1469
Epoch 21/50
 - 4s - loss: 5945.1276 - val_loss: 11818.9688
Epoch 22/50
 - 4s - loss: 5934.9192 - val_loss: 11814.5154
Epoch 23/50
 - 4s - loss: 5933.1437 - val_loss: 11810.4297
Epoch 24/50
 - 4s - loss: 5931.1112 - val_loss: 11798.1129
Epoch 25/50
 - 4s - loss: 5915.8175 - val_loss: 11806.6708
Epoch 26/50
 - 4s - loss: 5907.9586 - val_loss: 11792.1155
Epoch 27/50
 - 4s - loss: 5918.3699 - val_loss: 11782.8845
Epoch 28/50
 - 4s - loss: 5895.1950 - val_loss: 11772.2375
Epoch 29/50
 - 4s - loss: 5894.4790 - val_loss: 11760.9063
Epoch 30/50
 - 4s - loss: 5893.3998 - val_loss: 11753.9279
Epoch 31/50
 - 4s - loss: 5877.8043 - val_loss: 11748.2756
Epoch 32/50
 - 4s - loss: 5876.1244 - val_loss: 11742.3669
Epoch 33/50
 - 4s - loss: 5867.7270 - val_loss: 11729.3782
Epoch 34/50
 - 4s - loss: 5857.6485 - val_loss: 11725.0335
Epoch 35/50
 - 4s - loss: 5854.2556 - val_loss: 11710.8852
Epoch 36/50
 - 4s - loss: 5858.1624 - val_loss: 11710.1651
Epoch 37/50
 - 4s - loss: 5843.8570 - val_loss: 11694.7977
Epoch 38/50
 - 4s - loss: 5833.5914 - val_loss: 11681.7326
Epoch 39/50
 - 4s - loss: 5832.5668 - val_loss: 11682.1594
Epoch 40/50
 - 4s - loss: 5832.3324 - val_loss: 11672.3480
Epoch 41/50
 - 4s - loss: 5822.5219 - val_loss: 11666.2074
Epoch 42/50
 - 4s - loss: 5809.6140 - val_loss: 11651.9348
Epoch 43/50
 - 4s - loss: 5805.0841 - val_loss: 11662.2347
Epoch 44/50
 - 4s - loss: 5795.9639 - val_loss: 11695.9027
Epoch 45/50
 - 4s - loss: 5792.3747 - val_loss: 11633.8514
Epoch 46/50
 - 4s - loss: 5794.6903 - val_loss: 11626.8336
Epoch 47/50
 - 4s - loss: 5784.0799 - val_loss: 11621.0296
Epoch 48/50
 - 4s - loss: 5776.1470 - val_loss: 11612.8031
Epoch 49/50
 - 4s - loss: 5777.5459 - val_loss: 11598.8747
Epoch 50/50
 - 4s - loss: 5762.6929 - val_loss: 11575.9513
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 43520	action = 0	current_phase = 1	next_phase = 0	reward = 0.726465	array([[ -9.660136, -43.84161 ]], dtype=float32)
time = 43525	action = 0	current_phase = 1	next_phase = 0	reward = 0.729017	array([[ -9.697601, -43.99658 ]], dtype=float32)
time = 43530	action = 0	current_phase = 1	next_phase = 0	reward = 0.731289	array([[ -9.691826, -44.017033]], dtype=float32)
time = 43535	action = 0	current_phase = 1	next_phase = 0	reward = 0.725296	array([[ -9.6688595, -43.808018 ]], dtype=float32)
time = 43540	action = 0	current_phase = 1	next_phase = 0	reward = 0.720831	array([[ -9.6862135, -44.001846 ]], dtype=float32)
time = 43545	action = 0	current_phase = 1	next_phase = 0	reward = 0.714365	array([[ -9.65953 , -43.823387]], dtype=float32)
time = 43550	action = 0	current_phase = 1	next_phase = 0	reward = 0.435277	array([[ -9.687695, -43.94011 ]], dtype=float32)
time = 43555	action = 0	current_phase = 1	next_phase = 0	reward = 1.015688	array([[ -9.656161, -43.89636 ]], dtype=float32)
time = 43560	action = 0	current_phase = 1	next_phase = 0	reward = 0.438455	array([[ -9.659775, -43.882664]], dtype=float32)
time = 43565	action = 0	current_phase = 1	next_phase = 0	reward = 1.005447	array([[ -9.68647, -44.02141]], dtype=float32)
time = 43570	action = 0	current_phase = 1	next_phase = 0	reward = 0.727545	array([[ -9.6933365, -43.81389  ]], dtype=float32)
time = 43575	action = 0	current_phase = 1	next_phase = 0	reward = 0.716019	array([[ -9.665277, -43.898987]], dtype=float32)
time = 43580	action = 0	current_phase = 1	next_phase = 0	reward = 0.448619	array([[ -9.703232, -44.056282]], dtype=float32)
time = 43585	action = 0	current_phase = 1	next_phase = 0	reward = 1.006844	array([[ -9.660513, -43.889565]], dtype=float32)
time = 43590	action = 0	current_phase = 1	next_phase = 0	reward = 0.716741	array([[ -9.672098, -43.94121 ]], dtype=float32)
time = 43595	action = 0	current_phase = 1	next_phase = 0	reward = 0.446413	array([[ -9.661694, -43.85645 ]], dtype=float32)
time = 43600	action = 0	current_phase = 1	next_phase = 0	reward = 0.999709	array([[ -9.642727, -43.790558]], dtype=float32)
time = 43605	action = 0	current_phase = 1	next_phase = 0	reward = 0.716149	array([[ -9.670708, -43.692825]], dtype=float32)
time = 43610	action = 0	current_phase = 1	next_phase = 0	reward = 0.715552	array([[ -9.673888, -43.91114 ]], dtype=float32)
time = 43615	action = 0	current_phase = 1	next_phase = 0	reward = 0.713048	array([[ -9.691066, -44.006763]], dtype=float32)
time = 43620	action = 0	current_phase = 1	next_phase = 0	reward = 0.722788	array([[ -9.642712, -43.743168]], dtype=float32)
time = 43625	action = 0	current_phase = 1	next_phase = 0	reward = 0.446812	array([[ -9.67116, -43.91373]], dtype=float32)
time = 43630	action = 0	current_phase = 1	next_phase = 0	reward = 0.729742	array([[ -9.657749, -43.88822 ]], dtype=float32)
time = 43635	action = 0	current_phase = 1	next_phase = 0	reward = 1.000731	array([[ -9.660196, -43.813007]], dtype=float32)
time = 43640	action = 0	current_phase = 1	next_phase = 0	reward = 0.430029	array([[ -9.698247, -44.02481 ]], dtype=float32)
time = 43645	action = 0	current_phase = 1	next_phase = 0	reward = 0.995693	array([[ -9.70243, -43.86365]], dtype=float32)
time = 43650	action = 0	current_phase = 1	next_phase = 0	reward = 0.713884	array([[ -9.686557, -44.047825]], dtype=float32)
time = 43655	action = 0	current_phase = 1	next_phase = 0	reward = 0.163503	array([[ -9.6659 , -43.83143]], dtype=float32)
time = 43660	action = 0	current_phase = 1	next_phase = 0	reward = 1.005140	array([[ -9.690802, -44.065304]], dtype=float32)
time = 43665	action = 0	current_phase = 1	next_phase = 0	reward = 1.005912	array([[ -9.651094, -43.799206]], dtype=float32)
time = 43670	action = 0	current_phase = 1	next_phase = 0	reward = 0.729278	array([[ -9.659107, -43.87069 ]], dtype=float32)
time = 43675	action = 0	current_phase = 1	next_phase = 0	reward = 0.723304	array([[ -9.607925, -43.571526]], dtype=float32)
time = 43680	action = 0	current_phase = 1	next_phase = 0	reward = 0.717686	array([[ -9.669408, -43.926292]], dtype=float32)
time = 43685	action = 0	current_phase = 1	next_phase = 0	reward = 0.731594	array([[ -9.675052, -43.995598]], dtype=float32)
time = 43690	action = 0	current_phase = 1	next_phase = 0	reward = 0.729516	array([[ -9.668997, -43.895424]], dtype=float32)
time = 43695	action = 0	current_phase = 1	next_phase = 0	reward = 0.723572	array([[ -9.677465, -43.9487  ]], dtype=float32)
time = 43700	action = 0	current_phase = 1	next_phase = 0	reward = 0.719500	array([[ -9.652538, -43.80364 ]], dtype=float32)
time = 43705	action = 0	current_phase = 1	next_phase = 0	reward = 0.714395	array([[ -9.654326, -43.8357  ]], dtype=float32)
time = 43710	action = 0	current_phase = 1	next_phase = 0	reward = 0.708627	array([[ -9.602913, -43.531696]], dtype=float32)
time = 43715	action = 0	current_phase = 1	next_phase = 0	reward = 0.722810	array([[ -9.726308, -43.949734]], dtype=float32)
time = 43720	action = 0	current_phase = 1	next_phase = 0	reward = 0.446931	array([[ -9.686722, -43.977077]], dtype=float32)
time = 43725	action = 0	current_phase = 1	next_phase = 0	reward = 1.014267	array([[ -9.679282, -43.948586]], dtype=float32)
time = 43730	action = 0	current_phase = 1	next_phase = 0	reward = 0.726948	array([[ -9.675932, -43.991932]], dtype=float32)
time = 43735	action = 0	current_phase = 1	next_phase = 0	reward = 0.447805	array([[ -9.68441, -43.91543]], dtype=float32)
time = 43740	action = 0	current_phase = 1	next_phase = 0	reward = 0.992850	array([[ -9.647333, -43.766483]], dtype=float32)
time = 43745	action = 0	current_phase = 1	next_phase = 0	reward = 0.723350	array([[ -9.686673, -43.966232]], dtype=float32)
time = 43750	action = 0	current_phase = 1	next_phase = 0	reward = 0.721590	array([[ -9.673775, -43.90741 ]], dtype=float32)
time = 43755	action = 0	current_phase = 1	next_phase = 0	reward = 0.714033	array([[ -9.687299, -43.94059 ]], dtype=float32)
time = 43760	action = 0	current_phase = 1	next_phase = 0	reward = 0.723622	array([[ -9.671923, -43.954018]], dtype=float32)
time = 43765	action = 0	current_phase = 1	next_phase = 0	reward = 0.725454	array([[ -9.670236, -43.91057 ]], dtype=float32)
time = 43770	action = 0	current_phase = 1	next_phase = 0	reward = 0.446549	array([[ -9.684255, -43.882946]], dtype=float32)
time = 43775	action = 0	current_phase = 1	next_phase = 0	reward = 1.009051	array([[ -9.62218 , -43.694054]], dtype=float32)
time = 43780	action = 0	current_phase = 1	next_phase = 0	reward = 0.727171	array([[ -9.661174, -43.911777]], dtype=float32)
time = 43785	action = 0	current_phase = 1	next_phase = 0	reward = 0.725488	array([[ -9.709738, -44.082634]], dtype=float32)
time = 43790	action = 0	current_phase = 1	next_phase = 0	reward = 0.718081	array([[ -9.672715, -43.93118 ]], dtype=float32)
time = 43795	action = 0	current_phase = 1	next_phase = 0	reward = 0.713833	array([[ -9.68815, -44.02893]], dtype=float32)
time = 43800	action = 0	current_phase = 1	next_phase = 0	reward = 0.711826	array([[ -9.685915, -43.97799 ]], dtype=float32)
time = 43805	action = 0	current_phase = 1	next_phase = 0	reward = 0.442214	array([[ -9.670246, -43.958954]], dtype=float32)
time = 43810	action = 0	current_phase = 1	next_phase = 0	reward = 0.732358	array([[ -9.649771, -43.86852 ]], dtype=float32)
time = 43815	action = 0	current_phase = 1	next_phase = 0	reward = 1.003220	array([[ -9.650355, -43.862545]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 5220.5490 - val_loss: 10217.5495
Epoch 2/50
 - 4s - loss: 5203.8476 - val_loss: 10206.1228
Epoch 3/50
 - 4s - loss: 5193.4424 - val_loss: 10192.8842
Epoch 4/50
 - 4s - loss: 5181.2501 - val_loss: 10186.8778
Epoch 5/50
 - 4s - loss: 5173.6246 - val_loss: 10181.4097
Epoch 6/50
 - 4s - loss: 5159.6814 - val_loss: 10172.7402
Epoch 7/50
 - 4s - loss: 5148.5909 - val_loss: 10159.0087
Epoch 8/50
 - 4s - loss: 5151.9222 - val_loss: 10154.9679
Epoch 9/50
 - 4s - loss: 5141.3829 - val_loss: 10149.3469
Epoch 10/50
 - 4s - loss: 5128.8134 - val_loss: 10147.4845
Epoch 11/50
 - 4s - loss: 5138.2967 - val_loss: 10139.8479
Epoch 12/50
 - 4s - loss: 5115.3823 - val_loss: 10122.8353
Epoch 13/50
 - 4s - loss: 5107.2770 - val_loss: 10128.8654
Epoch 14/50
 - 4s - loss: 5110.4396 - val_loss: 10113.4041
Epoch 15/50
 - 4s - loss: 5096.6886 - val_loss: 10099.8914
Epoch 16/50
 - 4s - loss: 5089.1381 - val_loss: 10095.7002
Epoch 17/50
 - 4s - loss: 5072.0898 - val_loss: 10101.5167
Epoch 18/50
 - 4s - loss: 5072.5869 - val_loss: 10087.3576
Epoch 19/50
 - 4s - loss: 5059.9809 - val_loss: 10076.2526
Epoch 20/50
 - 4s - loss: 5064.1683 - val_loss: 10064.1898
Epoch 21/50
 - 4s - loss: 5055.1975 - val_loss: 10059.3958
Epoch 22/50
 - 4s - loss: 5038.2113 - val_loss: 10055.8848
Epoch 23/50
 - 4s - loss: 5044.7518 - val_loss: 10048.6651
Epoch 24/50
 - 4s - loss: 5032.4912 - val_loss: 10050.4016
Epoch 25/50
 - 4s - loss: 5030.2244 - val_loss: 10030.7011
Epoch 26/50
 - 4s - loss: 5009.7806 - val_loss: 10031.0909
Epoch 27/50
 - 4s - loss: 5007.3697 - val_loss: 10016.7316
Epoch 28/50
 - 4s - loss: 5003.6357 - val_loss: 10013.0583
Epoch 29/50
 - 4s - loss: 4996.7015 - val_loss: 10008.4922
Epoch 30/50
 - 4s - loss: 4984.5083 - val_loss: 9997.7296
Epoch 31/50
 - 4s - loss: 4982.4363 - val_loss: 9995.5347
Epoch 32/50
 - 4s - loss: 4965.3668 - val_loss: 9986.1923
Epoch 33/50
 - 4s - loss: 4969.0083 - val_loss: 9978.5032
Epoch 34/50
 - 4s - loss: 4962.6111 - val_loss: 9980.7608
Epoch 35/50
 - 4s - loss: 4959.0958 - val_loss: 9960.8807
Epoch 36/50
 - 4s - loss: 4941.6075 - val_loss: 9963.1102
Epoch 37/50
 - 4s - loss: 4938.1162 - val_loss: 9946.2640
Epoch 38/50
 - 4s - loss: 4929.1541 - val_loss: 9941.4852
Epoch 39/50
 - 4s - loss: 4926.8968 - val_loss: 9932.8770
Epoch 40/50
 - 4s - loss: 4921.2048 - val_loss: 9926.7096
Epoch 41/50
 - 4s - loss: 4917.0324 - val_loss: 9918.7948
Epoch 42/50
 - 4s - loss: 4904.0163 - val_loss: 9905.0751
Epoch 43/50
 - 4s - loss: 4894.3661 - val_loss: 9908.8772
Epoch 44/50
 - 4s - loss: 4888.2064 - val_loss: 9892.9869
Epoch 45/50
 - 4s - loss: 4881.4621 - val_loss: 9891.6631
Epoch 46/50
 - 4s - loss: 4883.6291 - val_loss: 9881.9850
Epoch 47/50
 - 4s - loss: 4870.7904 - val_loss: 9884.6626
Epoch 48/50
 - 4s - loss: 4857.2329 - val_loss: 9890.3350
Epoch 49/50
 - 4s - loss: 4854.6547 - val_loss: 9864.0888
Epoch 50/50
 - 4s - loss: 4848.4465 - val_loss: 9869.8959
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 43820	action = 0	current_phase = 1	next_phase = 0	reward = 0.715116	array([[ -7.9926567, -43.493435 ]], dtype=float32)
time = 43825	action = 0	current_phase = 1	next_phase = 0	reward = 0.440623	array([[ -7.998306, -43.54684 ]], dtype=float32)
time = 43830	action = 0	current_phase = 1	next_phase = 0	reward = 1.007119	array([[ -7.9860873, -43.434715 ]], dtype=float32)
time = 43835	action = 0	current_phase = 1	next_phase = 0	reward = 0.720847	array([[ -7.9510474, -43.229855 ]], dtype=float32)
time = 43840	action = 0	current_phase = 1	next_phase = 0	reward = 0.726360	array([[ -7.9695077, -43.33973  ]], dtype=float32)
time = 43845	action = 0	current_phase = 1	next_phase = 0	reward = 0.713735	array([[ -7.9446244, -43.149906 ]], dtype=float32)
time = 43850	action = 0	current_phase = 1	next_phase = 0	reward = 0.441408	array([[ -8.00123 , -43.547302]], dtype=float32)
time = 43855	action = 0	current_phase = 1	next_phase = 0	reward = 0.996879	array([[ -7.9806657, -43.411293 ]], dtype=float32)
time = 43860	action = 0	current_phase = 1	next_phase = 0	reward = 0.721625	array([[ -7.970071, -43.164394]], dtype=float32)
time = 43865	action = 0	current_phase = 1	next_phase = 0	reward = 0.717351	array([[ -7.966261, -43.28409 ]], dtype=float32)
time = 43870	action = 0	current_phase = 1	next_phase = 0	reward = 0.728414	array([[ -7.996876, -43.488087]], dtype=float32)
time = 43875	action = 0	current_phase = 1	next_phase = 0	reward = 0.443893	array([[ -7.9740725, -43.362225 ]], dtype=float32)
time = 43880	action = 0	current_phase = 1	next_phase = 0	reward = 0.996615	array([[ -7.9980054, -43.52458  ]], dtype=float32)
time = 43885	action = 0	current_phase = 1	next_phase = 0	reward = 0.716301	array([[ -8.015013, -43.618027]], dtype=float32)
time = 43890	action = 0	current_phase = 1	next_phase = 0	reward = 0.442737	array([[ -7.9970045, -43.51616  ]], dtype=float32)
time = 43895	action = 0	current_phase = 1	next_phase = 0	reward = 1.009008	array([[ -7.993664, -43.469734]], dtype=float32)
time = 43900	action = 0	current_phase = 1	next_phase = 0	reward = 0.724358	array([[ -7.9405994, -43.14441  ]], dtype=float32)
time = 43905	action = 0	current_phase = 1	next_phase = 0	reward = 0.720568	array([[ -7.996781, -43.53237 ]], dtype=float32)
time = 43910	action = 0	current_phase = 1	next_phase = 0	reward = 0.722180	array([[ -7.9798927, -43.350452 ]], dtype=float32)
time = 43915	action = 0	current_phase = 1	next_phase = 0	reward = 0.724595	array([[ -7.990315, -43.50604 ]], dtype=float32)
time = 43920	action = 0	current_phase = 1	next_phase = 0	reward = 0.446445	array([[ -7.980127, -43.38468 ]], dtype=float32)
time = 43925	action = 0	current_phase = 1	next_phase = 0	reward = 1.001888	array([[ -7.9876723, -43.43139  ]], dtype=float32)
time = 43930	action = 0	current_phase = 1	next_phase = 0	reward = 0.726654	array([[ -7.9394274, -43.08953  ]], dtype=float32)
time = 43935	action = 0	current_phase = 1	next_phase = 0	reward = 0.724004	array([[ -8.000317, -43.493095]], dtype=float32)
time = 43940	action = 0	current_phase = 1	next_phase = 0	reward = 0.729851	array([[ -7.9970436, -43.49785  ]], dtype=float32)
time = 43945	action = 0	current_phase = 1	next_phase = 0	reward = 0.718072	array([[ -7.9976816, -43.4876   ]], dtype=float32)
time = 43950	action = 0	current_phase = 1	next_phase = 0	reward = 0.433945	array([[ -7.983708, -43.420765]], dtype=float32)
time = 43955	action = 0	current_phase = 1	next_phase = 0	reward = 0.995578	array([[ -7.9878855, -43.44598  ]], dtype=float32)
time = 43960	action = 0	current_phase = 1	next_phase = 0	reward = 0.442419	array([[ -7.9634027, -43.297527 ]], dtype=float32)
time = 43965	action = 0	current_phase = 1	next_phase = 0	reward = 1.005666	array([[ -7.9666142, -43.25933  ]], dtype=float32)
time = 43970	action = 0	current_phase = 1	next_phase = 0	reward = 0.713708	array([[ -7.998376, -43.49816 ]], dtype=float32)
time = 43975	action = 0	current_phase = 1	next_phase = 0	reward = 0.715300	array([[ -7.9614587, -43.257248 ]], dtype=float32)
time = 43980	action = 0	current_phase = 1	next_phase = 0	reward = 0.438534	array([[ -8.006313, -43.53909 ]], dtype=float32)
time = 43985	action = 0	current_phase = 1	next_phase = 0	reward = 0.729521	array([[ -7.9924273, -43.433258 ]], dtype=float32)
time = 43990	action = 0	current_phase = 1	next_phase = 0	reward = 1.000767	array([[ -7.9845967, -43.396538 ]], dtype=float32)
time = 43995	action = 0	current_phase = 1	next_phase = 0	reward = 0.713270	array([[ -7.9713707, -43.331146 ]], dtype=float32)
time = 44000	action = 0	current_phase = 1	next_phase = 0	reward = 0.710902	array([[ -7.96864, -43.33495]], dtype=float32)
time = 44005	action = 0	current_phase = 1	next_phase = 0	reward = 0.438534	array([[ -7.986696, -43.435112]], dtype=float32)
time = 44010	action = 0	current_phase = 1	next_phase = 0	reward = 0.996393	array([[ -7.9689026, -43.299973 ]], dtype=float32)
time = 44015	action = 0	current_phase = 1	next_phase = 0	reward = 0.448243	array([[ -8.004921, -43.552776]], dtype=float32)
time = 44020	action = 0	current_phase = 1	next_phase = 0	reward = 1.008731	array([[ -7.9788036, -43.34705  ]], dtype=float32)
time = 44025	action = 0	current_phase = 1	next_phase = 0	reward = 0.444492	array([[ -7.98487 , -43.412174]], dtype=float32)
time = 44030	action = 0	current_phase = 1	next_phase = 0	reward = 1.003497	array([[ -7.9650035, -43.304764 ]], dtype=float32)
time = 44035	action = 0	current_phase = 1	next_phase = 0	reward = 0.711791	array([[ -7.996434, -43.493336]], dtype=float32)
time = 44040	action = 0	current_phase = 1	next_phase = 0	reward = 0.723892	array([[ -8.017736, -43.55451 ]], dtype=float32)
time = 44045	action = 0	current_phase = 1	next_phase = 0	reward = 0.727841	array([[ -7.981602, -43.442394]], dtype=float32)
time = 44050	action = 0	current_phase = 1	next_phase = 0	reward = 0.721480	array([[ -7.986522, -43.448227]], dtype=float32)
time = 44055	action = 0	current_phase = 1	next_phase = 0	reward = 0.719885	array([[ -8.00858 , -43.576797]], dtype=float32)
time = 44060	action = 0	current_phase = 1	next_phase = 0	reward = 0.721678	array([[ -7.978905, -43.39089 ]], dtype=float32)
time = 44065	action = 0	current_phase = 1	next_phase = 0	reward = 0.717123	array([[ -7.971238, -43.30983 ]], dtype=float32)
time = 44070	action = 0	current_phase = 1	next_phase = 0	reward = 0.717615	array([[ -7.961874, -43.290596]], dtype=float32)
time = 44075	action = 0	current_phase = 1	next_phase = 0	reward = 0.716124	array([[ -8.005378, -43.517265]], dtype=float32)
time = 44080	action = 0	current_phase = 1	next_phase = 0	reward = 0.443831	array([[ -7.999673, -43.51427 ]], dtype=float32)
time = 44085	action = 0	current_phase = 1	next_phase = 0	reward = 1.010611	array([[ -8.016489, -43.622704]], dtype=float32)
time = 44090	action = 0	current_phase = 1	next_phase = 0	reward = 0.722851	array([[ -7.9638333, -43.259857 ]], dtype=float32)
time = 44095	action = 0	current_phase = 1	next_phase = 0	reward = 0.720562	array([[ -7.9866543, -43.429813 ]], dtype=float32)
time = 44100	action = 0	current_phase = 1	next_phase = 0	reward = 0.435175	array([[ -7.993164, -43.462097]], dtype=float32)
time = 44105	action = 0	current_phase = 1	next_phase = 0	reward = 1.005601	array([[ -7.976211, -43.343594]], dtype=float32)
time = 44110	action = 0	current_phase = 1	next_phase = 0	reward = 0.445026	array([[ -7.99144, -43.48553]], dtype=float32)
time = 44115	action = 0	current_phase = 1	next_phase = 0	reward = 0.997791	array([[ -7.9407525, -43.16176  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 4284.0559 - val_loss: 6990.6508
Epoch 2/50
 - 4s - loss: 4273.4760 - val_loss: 6994.2753
Epoch 3/50
 - 4s - loss: 4266.2447 - val_loss: 6984.4310
Epoch 4/50
 - 4s - loss: 4253.8801 - val_loss: 6987.0917
Epoch 5/50
 - 4s - loss: 4251.5903 - val_loss: 6978.9380
Epoch 6/50
 - 4s - loss: 4237.4873 - val_loss: 6973.5016
Epoch 7/50
 - 4s - loss: 4228.6399 - val_loss: 6967.3930
Epoch 8/50
 - 4s - loss: 4235.5616 - val_loss: 6967.3636
Epoch 9/50
 - 4s - loss: 4216.6007 - val_loss: 6971.3670
Epoch 10/50
 - 4s - loss: 4212.9352 - val_loss: 6957.6257
Epoch 11/50
 - 4s - loss: 4200.8456 - val_loss: 6953.8164
Epoch 12/50
 - 4s - loss: 4198.2645 - val_loss: 6954.5585
Epoch 13/50
 - 4s - loss: 4188.1735 - val_loss: 6946.7259
Epoch 14/50
 - 4s - loss: 4177.6526 - val_loss: 6948.8825
Epoch 15/50
 - 4s - loss: 4177.6074 - val_loss: 6955.5980
Epoch 16/50
 - 4s - loss: 4180.0696 - val_loss: 6944.1698
Epoch 17/50
 - 4s - loss: 4173.2001 - val_loss: 6933.8739
Epoch 18/50
 - 4s - loss: 4160.2935 - val_loss: 6931.6955
Epoch 19/50
 - 4s - loss: 4157.8863 - val_loss: 6928.7800
Epoch 20/50
 - 4s - loss: 4149.4112 - val_loss: 6929.8532
Epoch 21/50
 - 4s - loss: 4140.6733 - val_loss: 6923.4222
Epoch 22/50
 - 4s - loss: 4134.6445 - val_loss: 6924.9900
Epoch 23/50
 - 4s - loss: 4128.6091 - val_loss: 6917.2627
Epoch 24/50
 - 4s - loss: 4123.1777 - val_loss: 6912.3296
Epoch 25/50
 - 4s - loss: 4118.2836 - val_loss: 6919.5453
Epoch 26/50
 - 4s - loss: 4109.8060 - val_loss: 6905.7295
Epoch 27/50
 - 4s - loss: 4109.5175 - val_loss: 6902.6202
Epoch 28/50
 - 4s - loss: 4097.4399 - val_loss: 6899.1579
Epoch 29/50
 - 4s - loss: 4098.4763 - val_loss: 6898.0427
Epoch 30/50
 - 4s - loss: 4092.8101 - val_loss: 6892.4058
Epoch 31/50
 - 4s - loss: 4078.8228 - val_loss: 6889.1418
Epoch 32/50
 - 4s - loss: 4070.6631 - val_loss: 6887.8009
Epoch 33/50
 - 4s - loss: 4078.0100 - val_loss: 6884.0028
Epoch 34/50
 - 4s - loss: 4068.1122 - val_loss: 6882.5502
Epoch 35/50
 - 4s - loss: 4058.5864 - val_loss: 6880.6122
Epoch 36/50
 - 4s - loss: 4050.7643 - val_loss: 6868.8933
Epoch 37/50
 - 4s - loss: 4049.4777 - val_loss: 6867.9677
Epoch 38/50
 - 4s - loss: 4031.9958 - val_loss: 6870.3930
Epoch 39/50
 - 4s - loss: 4034.9119 - val_loss: 6861.6221
Epoch 40/50
 - 4s - loss: 4024.6316 - val_loss: 6865.4091
Epoch 41/50
 - 4s - loss: 4021.4014 - val_loss: 6873.6642
Epoch 42/50
 - 4s - loss: 4022.2855 - val_loss: 6858.4717
Epoch 43/50
 - 4s - loss: 4011.4940 - val_loss: 6855.8734
Epoch 44/50
 - 4s - loss: 4001.6776 - val_loss: 6859.5581
Epoch 45/50
 - 4s - loss: 3996.5642 - val_loss: 6846.0485
Epoch 46/50
 - 4s - loss: 3994.6016 - val_loss: 6845.1018
Epoch 47/50
 - 4s - loss: 3995.0308 - val_loss: 6846.1723
Epoch 48/50
 - 4s - loss: 3977.9172 - val_loss: 6842.5640
Epoch 49/50
 - 4s - loss: 3976.7994 - val_loss: 6838.8073
Epoch 50/50
 - 4s - loss: 3968.1688 - val_loss: 6834.1773
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 44120	action = 0	current_phase = 1	next_phase = 0	reward = 0.720068	array([[ -6.9001093, -43.566483 ]], dtype=float32)
time = 44125	action = 0	current_phase = 1	next_phase = 0	reward = 0.717007	array([[ -6.914809, -43.665855]], dtype=float32)
time = 44130	action = 0	current_phase = 1	next_phase = 0	reward = 0.710739	array([[ -6.8797803, -43.40524  ]], dtype=float32)
time = 44135	action = 0	current_phase = 1	next_phase = 0	reward = 0.717919	array([[ -6.873786, -43.37199 ]], dtype=float32)
time = 44140	action = 0	current_phase = 1	next_phase = 0	reward = 0.444140	array([[ -6.8657227, -43.295734 ]], dtype=float32)
time = 44145	action = 0	current_phase = 1	next_phase = 0	reward = 1.004438	array([[ -6.860809, -43.274887]], dtype=float32)
time = 44150	action = 0	current_phase = 1	next_phase = 0	reward = 0.708727	array([[ -6.845087, -43.156544]], dtype=float32)
time = 44155	action = 0	current_phase = 1	next_phase = 0	reward = 0.716854	array([[ -6.8845677, -43.444782 ]], dtype=float32)
time = 44160	action = 0	current_phase = 1	next_phase = 0	reward = 0.714726	array([[ -6.882084, -43.42516 ]], dtype=float32)
time = 44165	action = 0	current_phase = 1	next_phase = 0	reward = 0.712145	array([[ -6.9158254, -43.67537  ]], dtype=float32)
time = 44170	action = 0	current_phase = 1	next_phase = 0	reward = 0.720593	array([[ -6.847437, -43.15669 ]], dtype=float32)
time = 44175	action = 0	current_phase = 1	next_phase = 0	reward = 0.445386	array([[ -6.8816586, -43.429058 ]], dtype=float32)
time = 44180	action = 0	current_phase = 1	next_phase = 0	reward = 1.002120	array([[ -6.887628, -43.464653]], dtype=float32)
time = 44185	action = 0	current_phase = 1	next_phase = 0	reward = 0.167336	array([[ -6.873475, -43.353592]], dtype=float32)
time = 44190	action = 0	current_phase = 1	next_phase = 0	reward = 1.280664	array([[ -6.8348165, -43.072414 ]], dtype=float32)
time = 44195	action = 0	current_phase = 1	next_phase = 0	reward = 0.442959	array([[ -6.8847346, -43.424927 ]], dtype=float32)
time = 44200	action = 0	current_phase = 1	next_phase = 0	reward = 1.013659	array([[ -6.846092, -43.174423]], dtype=float32)
time = 44205	action = 0	current_phase = 1	next_phase = 0	reward = 0.723125	array([[ -6.918699, -43.675724]], dtype=float32)
time = 44210	action = 0	current_phase = 1	next_phase = 0	reward = 0.444987	array([[ -6.9074664, -43.611355 ]], dtype=float32)
time = 44215	action = 0	current_phase = 1	next_phase = 0	reward = 1.008312	array([[ -6.88181 , -43.422825]], dtype=float32)
time = 44220	action = 0	current_phase = 1	next_phase = 0	reward = 0.447466	array([[ -6.889174, -43.481056]], dtype=float32)
time = 44225	action = 0	current_phase = 1	next_phase = 0	reward = 1.005877	array([[ -6.8374724, -43.108448 ]], dtype=float32)
time = 44230	action = 0	current_phase = 1	next_phase = 0	reward = 0.714645	array([[ -6.884286, -43.44388 ]], dtype=float32)
time = 44235	action = 0	current_phase = 1	next_phase = 0	reward = 0.718279	array([[ -6.8991075, -43.552994 ]], dtype=float32)
time = 44240	action = 0	current_phase = 1	next_phase = 0	reward = 0.717232	array([[ -6.887799, -43.480797]], dtype=float32)
time = 44245	action = 0	current_phase = 1	next_phase = 0	reward = 0.445622	array([[ -6.901514, -43.577675]], dtype=float32)
time = 44250	action = 0	current_phase = 1	next_phase = 0	reward = 1.005431	array([[ -6.872069, -43.34127 ]], dtype=float32)
time = 44255	action = 0	current_phase = 1	next_phase = 0	reward = 0.722502	array([[ -6.9186535, -43.65569  ]], dtype=float32)
time = 44260	action = 0	current_phase = 1	next_phase = 0	reward = 0.720045	array([[ -6.8942113, -43.52476  ]], dtype=float32)
time = 44265	action = 0	current_phase = 1	next_phase = 0	reward = 0.710218	array([[ -6.907604, -43.61686 ]], dtype=float32)
time = 44270	action = 0	current_phase = 1	next_phase = 0	reward = 0.717675	array([[ -6.8566566, -43.240738 ]], dtype=float32)
time = 44275	action = 0	current_phase = 1	next_phase = 0	reward = 0.717099	array([[ -6.8361135, -43.08976  ]], dtype=float32)
time = 44280	action = 0	current_phase = 1	next_phase = 0	reward = 0.442386	array([[ -6.858748, -43.252712]], dtype=float32)
time = 44285	action = 0	current_phase = 1	next_phase = 0	reward = 0.722569	array([[ -6.8617363, -43.293198 ]], dtype=float32)
time = 44290	action = 0	current_phase = 1	next_phase = 0	reward = 0.996463	array([[ -6.8758593, -43.38139  ]], dtype=float32)
time = 44295	action = 0	current_phase = 1	next_phase = 0	reward = 0.721475	array([[ -6.8508916, -43.192062 ]], dtype=float32)
time = 44300	action = 0	current_phase = 1	next_phase = 0	reward = 0.445244	array([[ -6.834201, -43.034615]], dtype=float32)
time = 44305	action = 0	current_phase = 1	next_phase = 0	reward = 0.723593	array([[ -6.892818, -43.49745 ]], dtype=float32)
time = 44310	action = 0	current_phase = 1	next_phase = 0	reward = 1.009864	array([[ -6.876174, -43.38742 ]], dtype=float32)
time = 44315	action = 0	current_phase = 1	next_phase = 0	reward = 0.728487	array([[ -6.8921456, -43.48562  ]], dtype=float32)
time = 44320	action = 0	current_phase = 1	next_phase = 0	reward = 0.721211	array([[ -6.891463, -43.50192 ]], dtype=float32)
time = 44325	action = 0	current_phase = 1	next_phase = 0	reward = 0.709530	array([[ -6.8958254, -43.532486 ]], dtype=float32)
time = 44330	action = 0	current_phase = 1	next_phase = 0	reward = 0.721400	array([[ -6.890644, -43.48953 ]], dtype=float32)
time = 44335	action = 0	current_phase = 1	next_phase = 0	reward = 0.723670	array([[ -6.8598585, -43.275757 ]], dtype=float32)
time = 44340	action = 0	current_phase = 1	next_phase = 0	reward = 0.722100	array([[ -6.872485, -43.347786]], dtype=float32)
time = 44345	action = 0	current_phase = 1	next_phase = 0	reward = 0.722576	array([[ -6.9063907, -43.60587  ]], dtype=float32)
time = 44350	action = 0	current_phase = 1	next_phase = 0	reward = 0.720263	array([[ -6.882876, -43.434414]], dtype=float32)
time = 44355	action = 0	current_phase = 1	next_phase = 0	reward = 0.713814	array([[ -6.8822813, -43.431545 ]], dtype=float32)
time = 44360	action = 0	current_phase = 1	next_phase = 0	reward = 0.714097	array([[ -6.864464, -43.27912 ]], dtype=float32)
time = 44365	action = 0	current_phase = 1	next_phase = 0	reward = 0.717418	array([[ -6.8863606, -43.449497 ]], dtype=float32)
time = 44370	action = 0	current_phase = 1	next_phase = 0	reward = 0.441970	array([[ -6.9056044, -43.565777 ]], dtype=float32)
time = 44375	action = 0	current_phase = 1	next_phase = 0	reward = 1.011959	array([[ -6.8709464, -43.35759  ]], dtype=float32)
time = 44380	action = 0	current_phase = 1	next_phase = 0	reward = 0.443707	array([[ -6.9118743, -43.64971  ]], dtype=float32)
time = 44385	action = 0	current_phase = 1	next_phase = 0	reward = 1.007503	array([[ -6.9108906, -43.639862 ]], dtype=float32)
time = 44390	action = 0	current_phase = 1	next_phase = 0	reward = 0.719276	array([[ -6.870639, -43.35252 ]], dtype=float32)
time = 44395	action = 0	current_phase = 1	next_phase = 0	reward = 0.714743	array([[ -6.8938684, -43.512672 ]], dtype=float32)
time = 44400	action = 0	current_phase = 1	next_phase = 0	reward = 0.714253	array([[ -6.8636684, -43.284992 ]], dtype=float32)
time = 44405	action = 0	current_phase = 1	next_phase = 0	reward = 0.715067	array([[ -6.9292502, -43.760574 ]], dtype=float32)
time = 44410	action = 0	current_phase = 1	next_phase = 0	reward = 0.728144	array([[ -6.903647, -43.580532]], dtype=float32)
time = 44415	action = 0	current_phase = 1	next_phase = 0	reward = 0.442537	array([[ -6.9162436, -43.679283 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3843.3044 - val_loss: 8758.0953
Epoch 2/50
 - 4s - loss: 3829.8617 - val_loss: 8759.2168
Epoch 3/50
 - 4s - loss: 3828.6622 - val_loss: 8751.6179
Epoch 4/50
 - 4s - loss: 3812.2393 - val_loss: 8753.4909
Epoch 5/50
 - 4s - loss: 3812.7698 - val_loss: 8746.9072
Epoch 6/50
 - 4s - loss: 3801.7209 - val_loss: 8741.6463
Epoch 7/50
 - 4s - loss: 3796.4724 - val_loss: 8728.0005
Epoch 8/50
 - 4s - loss: 3803.2039 - val_loss: 8725.9719
Epoch 9/50
 - 4s - loss: 3779.9032 - val_loss: 8729.9226
Epoch 10/50
 - 4s - loss: 3773.9389 - val_loss: 8737.1526
Epoch 11/50
 - 4s - loss: 3770.2673 - val_loss: 8726.0279
Epoch 12/50
 - 4s - loss: 3778.5322 - val_loss: 8706.0448
Epoch 13/50
 - 4s - loss: 3760.2409 - val_loss: 8702.4494
Epoch 14/50
 - 4s - loss: 3752.5734 - val_loss: 8715.7621
Epoch 15/50
 - 4s - loss: 3750.1218 - val_loss: 8709.7022
Epoch 16/50
 - 4s - loss: 3740.8483 - val_loss: 8691.9609
Epoch 17/50
 - 4s - loss: 3735.6225 - val_loss: 8695.5289
Epoch 18/50
 - 4s - loss: 3731.8569 - val_loss: 8690.8451
Epoch 19/50
 - 4s - loss: 3720.7949 - val_loss: 8677.3182
Epoch 20/50
 - 4s - loss: 3712.2986 - val_loss: 8673.6547
Epoch 21/50
 - 4s - loss: 3713.7940 - val_loss: 8680.2016
Epoch 22/50
 - 4s - loss: 3704.8339 - val_loss: 8683.6876
Epoch 23/50
 - 4s - loss: 3700.8747 - val_loss: 8667.6062
Epoch 24/50
 - 4s - loss: 3693.5976 - val_loss: 8665.6262
Epoch 25/50
 - 4s - loss: 3692.7746 - val_loss: 8659.2764
Epoch 26/50
 - 4s - loss: 3684.7782 - val_loss: 8655.2630
Epoch 27/50
 - 4s - loss: 3673.8566 - val_loss: 8650.7150
Epoch 28/50
 - 4s - loss: 3673.1528 - val_loss: 8650.1127
Epoch 29/50
 - 4s - loss: 3664.1760 - val_loss: 8640.3135
Epoch 30/50
 - 4s - loss: 3655.6144 - val_loss: 8634.5346
Epoch 31/50
 - 4s - loss: 3652.3533 - val_loss: 8641.8806
Epoch 32/50
 - 4s - loss: 3657.5037 - val_loss: 8647.6648
Epoch 33/50
 - 4s - loss: 3643.2709 - val_loss: 8636.6872
Epoch 34/50
 - 4s - loss: 3633.7792 - val_loss: 8620.8738
Epoch 35/50
 - 4s - loss: 3631.8310 - val_loss: 8619.4112
Epoch 36/50
 - 4s - loss: 3623.5406 - val_loss: 8611.6127
Epoch 37/50
 - 4s - loss: 3619.1724 - val_loss: 8618.8696
Epoch 38/50
 - 4s - loss: 3618.0206 - val_loss: 8610.3572
Epoch 39/50
 - 4s - loss: 3609.6927 - val_loss: 8605.8141
Epoch 40/50
 - 4s - loss: 3598.8662 - val_loss: 8609.1601
Epoch 41/50
 - 4s - loss: 3598.2656 - val_loss: 8608.5506
Epoch 42/50
 - 4s - loss: 3602.9754 - val_loss: 8595.4731
Epoch 43/50
 - 4s - loss: 3588.0783 - val_loss: 8593.8945
Epoch 44/50
 - 4s - loss: 3579.8487 - val_loss: 8586.7139
Epoch 45/50
 - 4s - loss: 3573.6955 - val_loss: 8589.2798
Epoch 46/50
 - 4s - loss: 3565.6613 - val_loss: 8590.4597
Epoch 47/50
 - 4s - loss: 3565.0585 - val_loss: 8574.8385
Epoch 48/50
 - 4s - loss: 3558.9051 - val_loss: 8593.2795
Epoch 49/50
 - 4s - loss: 3561.0810 - val_loss: 8570.7900
Epoch 50/50
 - 4s - loss: 3543.6866 - val_loss: 8574.0448
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 44420	action = 0	current_phase = 1	next_phase = 0	reward = 1.010942	array([[ -6.659361, -43.054256]], dtype=float32)
time = 44425	action = 0	current_phase = 1	next_phase = 0	reward = 0.723465	array([[ -6.687387, -43.257454]], dtype=float32)
time = 44430	action = 0	current_phase = 1	next_phase = 0	reward = 0.721230	array([[ -6.6671743, -43.06544  ]], dtype=float32)
time = 44435	action = 0	current_phase = 1	next_phase = 0	reward = 0.433606	array([[ -6.668398, -43.086426]], dtype=float32)
time = 44440	action = 0	current_phase = 1	next_phase = 0	reward = 1.001971	array([[ -6.648764, -42.978844]], dtype=float32)
time = 44445	action = 0	current_phase = 1	next_phase = 0	reward = 0.436717	array([[ -6.687749, -43.246193]], dtype=float32)
time = 44450	action = 0	current_phase = 1	next_phase = 0	reward = 0.724408	array([[ -6.6459117, -42.99687  ]], dtype=float32)
time = 44455	action = 0	current_phase = 1	next_phase = 0	reward = 0.734308	array([[ -6.6666408, -43.106335 ]], dtype=float32)
time = 44460	action = 0	current_phase = 1	next_phase = 0	reward = 1.013335	array([[ -6.6627955, -43.09601  ]], dtype=float32)
time = 44465	action = 0	current_phase = 1	next_phase = 0	reward = 0.715320	array([[ -6.6769743, -43.192413 ]], dtype=float32)
time = 44470	action = 0	current_phase = 1	next_phase = 0	reward = 0.715447	array([[ -6.6730647, -43.168602 ]], dtype=float32)
time = 44475	action = 0	current_phase = 1	next_phase = 0	reward = 0.719028	array([[ -6.7001066, -43.322063 ]], dtype=float32)
time = 44480	action = 0	current_phase = 1	next_phase = 0	reward = 0.712287	array([[ -6.671251, -43.137047]], dtype=float32)
time = 44485	action = 0	current_phase = 1	next_phase = 0	reward = 0.715531	array([[ -6.643064, -42.95123 ]], dtype=float32)
time = 44490	action = 0	current_phase = 1	next_phase = 0	reward = 0.166633	array([[ -6.6690497, -43.135216 ]], dtype=float32)
time = 44495	action = 0	current_phase = 1	next_phase = 0	reward = 1.012236	array([[ -6.6627097, -43.086575 ]], dtype=float32)
time = 44500	action = 0	current_phase = 1	next_phase = 0	reward = 0.724770	array([[ -6.675874, -43.145466]], dtype=float32)
time = 44505	action = 0	current_phase = 1	next_phase = 0	reward = 0.717463	array([[ -6.675075, -43.170048]], dtype=float32)
time = 44510	action = 0	current_phase = 1	next_phase = 0	reward = 1.002282	array([[ -6.6847653, -43.24371  ]], dtype=float32)
time = 44515	action = 0	current_phase = 1	next_phase = 0	reward = 0.728003	array([[ -6.666149, -43.110683]], dtype=float32)
time = 44520	action = 0	current_phase = 1	next_phase = 0	reward = 0.724775	array([[ -6.6351857, -42.868877 ]], dtype=float32)
time = 44525	action = 0	current_phase = 1	next_phase = 0	reward = 0.444500	array([[ -6.670562, -43.126266]], dtype=float32)
time = 44530	action = 0	current_phase = 1	next_phase = 0	reward = 1.004430	array([[ -6.6850696, -43.22289  ]], dtype=float32)
time = 44535	action = 0	current_phase = 1	next_phase = 0	reward = 0.720415	array([[ -6.6631446, -43.09917  ]], dtype=float32)
time = 44540	action = 0	current_phase = 1	next_phase = 0	reward = 0.720525	array([[ -6.683339, -43.223785]], dtype=float32)
time = 44545	action = 0	current_phase = 1	next_phase = 0	reward = 0.718453	array([[ -6.644346, -42.967186]], dtype=float32)
time = 44550	action = 0	current_phase = 1	next_phase = 0	reward = 0.715647	array([[ -6.670707, -43.152573]], dtype=float32)
time = 44555	action = 0	current_phase = 1	next_phase = 0	reward = 0.711533	array([[ -6.664821, -43.12002 ]], dtype=float32)
time = 44560	action = 0	current_phase = 1	next_phase = 0	reward = 0.714629	array([[ -6.6818576, -43.21167  ]], dtype=float32)
time = 44565	action = 0	current_phase = 1	next_phase = 0	reward = 0.725718	array([[ -6.669106, -43.12008 ]], dtype=float32)
time = 44570	action = 0	current_phase = 1	next_phase = 0	reward = 0.448685	array([[ -6.668363, -43.105854]], dtype=float32)
time = 44575	action = 0	current_phase = 1	next_phase = 0	reward = 1.012840	array([[ -6.6604347, -43.075405 ]], dtype=float32)
time = 44580	action = 0	current_phase = 1	next_phase = 0	reward = 0.724754	array([[ -6.6538787, -43.079056 ]], dtype=float32)
time = 44585	action = 0	current_phase = 1	next_phase = 0	reward = 0.715562	array([[ -6.669344, -43.127075]], dtype=float32)
time = 44590	action = 0	current_phase = 1	next_phase = 0	reward = 0.717683	array([[ -6.6744165, -43.136383 ]], dtype=float32)
time = 44595	action = 0	current_phase = 1	next_phase = 0	reward = 0.715636	array([[ -6.6675506, -43.103184 ]], dtype=float32)
time = 44600	action = 0	current_phase = 1	next_phase = 0	reward = 0.714631	array([[ -6.6626024, -43.094837 ]], dtype=float32)
time = 44605	action = 0	current_phase = 1	next_phase = 0	reward = 0.437907	array([[ -6.646899, -42.99498 ]], dtype=float32)
time = 44610	action = 0	current_phase = 1	next_phase = 0	reward = 0.998298	array([[ -6.6701684, -43.12549  ]], dtype=float32)
time = 44615	action = 0	current_phase = 1	next_phase = 0	reward = 0.725139	array([[ -6.664976, -43.08198 ]], dtype=float32)
time = 44620	action = 0	current_phase = 1	next_phase = 0	reward = 0.724292	array([[ -6.6689563, -43.140293 ]], dtype=float32)
time = 44625	action = 0	current_phase = 1	next_phase = 0	reward = 0.722932	array([[ -6.6772485, -43.182594 ]], dtype=float32)
time = 44630	action = 0	current_phase = 1	next_phase = 0	reward = 0.714325	array([[ -6.6755557, -43.18417  ]], dtype=float32)
time = 44635	action = 0	current_phase = 1	next_phase = 0	reward = 0.162048	array([[ -6.671459, -43.131752]], dtype=float32)
time = 44640	action = 0	current_phase = 1	next_phase = 0	reward = 1.286972	array([[ -6.679311, -43.094837]], dtype=float32)
time = 44645	action = 0	current_phase = 1	next_phase = 0	reward = 0.713965	array([[ -6.662046, -43.088238]], dtype=float32)
time = 44650	action = 0	current_phase = 1	next_phase = 0	reward = 0.722023	array([[ -6.6587634, -43.068836 ]], dtype=float32)
time = 44655	action = 0	current_phase = 1	next_phase = 0	reward = 0.442176	array([[ -6.647248, -42.984325]], dtype=float32)
time = 44660	action = 0	current_phase = 1	next_phase = 0	reward = 1.010303	array([[ -6.6732273, -43.128063 ]], dtype=float32)
time = 44665	action = 0	current_phase = 1	next_phase = 0	reward = 0.718627	array([[ -6.675931, -43.166878]], dtype=float32)
time = 44670	action = 0	current_phase = 1	next_phase = 0	reward = 0.714928	array([[ -6.6725683, -43.162266 ]], dtype=float32)
time = 44675	action = 0	current_phase = 1	next_phase = 0	reward = 0.724838	array([[ -6.669925, -43.126705]], dtype=float32)
time = 44680	action = 0	current_phase = 1	next_phase = 0	reward = 0.723702	array([[ -6.6532974, -43.00789  ]], dtype=float32)
time = 44685	action = 0	current_phase = 1	next_phase = 0	reward = 0.723387	array([[ -6.673293, -43.148376]], dtype=float32)
time = 44690	action = 0	current_phase = 1	next_phase = 0	reward = 0.717872	array([[ -6.6497574, -42.995876 ]], dtype=float32)
time = 44695	action = 0	current_phase = 1	next_phase = 0	reward = 0.440748	array([[ -6.6424513, -42.950176 ]], dtype=float32)
time = 44700	action = 0	current_phase = 1	next_phase = 0	reward = 0.722118	array([[ -6.6658173, -43.10093  ]], dtype=float32)
time = 44705	action = 0	current_phase = 1	next_phase = 0	reward = 0.997314	array([[ -6.6519012, -42.983074 ]], dtype=float32)
time = 44710	action = 0	current_phase = 1	next_phase = 0	reward = 0.725656	array([[ -6.658155, -43.04559 ]], dtype=float32)
time = 44715	action = 0	current_phase = 1	next_phase = 0	reward = 0.727802	array([[ -6.662916, -43.07943 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 4992.8135 - val_loss: 3377.6027
Epoch 2/50
 - 4s - loss: 4980.6385 - val_loss: 3381.0893
Epoch 3/50
 - 4s - loss: 4967.0489 - val_loss: 3361.0470
Epoch 4/50
 - 4s - loss: 4957.3256 - val_loss: 3379.8889
Epoch 5/50
 - 4s - loss: 4958.3158 - val_loss: 3353.4968
Epoch 6/50
 - 4s - loss: 4938.1391 - val_loss: 3350.6289
Epoch 7/50
 - 4s - loss: 4941.5710 - val_loss: 3338.5323
Epoch 8/50
 - 4s - loss: 4929.7749 - val_loss: 3341.6516
Epoch 9/50
 - 4s - loss: 4917.2430 - val_loss: 3328.6822
Epoch 10/50
 - 4s - loss: 4912.0430 - val_loss: 3351.4463
Epoch 11/50
 - 4s - loss: 4906.9884 - val_loss: 3326.1809
Epoch 12/50
 - 4s - loss: 4900.8884 - val_loss: 3332.7352
Epoch 13/50
 - 4s - loss: 4900.4260 - val_loss: 3320.4888
Epoch 14/50
 - 4s - loss: 4885.8116 - val_loss: 3303.9228
Epoch 15/50
 - 4s - loss: 4877.7212 - val_loss: 3300.6839
Epoch 16/50
 - 4s - loss: 4881.0214 - val_loss: 3300.6324
Epoch 17/50
 - 4s - loss: 4866.6851 - val_loss: 3294.5818
Epoch 18/50
 - 4s - loss: 4859.6915 - val_loss: 3280.6480
Epoch 19/50
 - 4s - loss: 4855.1634 - val_loss: 3296.2312
Epoch 20/50
 - 4s - loss: 4846.8143 - val_loss: 3292.3848
Epoch 21/50
 - 4s - loss: 4842.8063 - val_loss: 3269.6545
Epoch 22/50
 - 4s - loss: 4833.7766 - val_loss: 3280.1489
Epoch 23/50
 - 4s - loss: 4832.0214 - val_loss: 3264.2185
Epoch 24/50
 - 4s - loss: 4817.2884 - val_loss: 3261.0304
Epoch 25/50
 - 4s - loss: 4817.0943 - val_loss: 3245.7363
Epoch 26/50
 - 4s - loss: 4808.4224 - val_loss: 3238.5588
Epoch 27/50
 - 4s - loss: 4798.3042 - val_loss: 3240.0748
Epoch 28/50
 - 4s - loss: 4789.1021 - val_loss: 3246.8947
Epoch 29/50
 - 4s - loss: 4785.6087 - val_loss: 3227.3902
Epoch 30/50
 - 4s - loss: 4787.9863 - val_loss: 3253.6122
Epoch 31/50
 - 4s - loss: 4777.3105 - val_loss: 3256.3803
Epoch 32/50
 - 4s - loss: 4773.7601 - val_loss: 3230.6714
Epoch 33/50
 - 4s - loss: 4761.4857 - val_loss: 3213.1987
Epoch 34/50
 - 4s - loss: 4753.2067 - val_loss: 3215.7786
Epoch 35/50
 - 4s - loss: 4749.8125 - val_loss: 3204.7869
Epoch 36/50
 - 4s - loss: 4737.0824 - val_loss: 3208.2775
Epoch 37/50
 - 4s - loss: 4730.3117 - val_loss: 3198.3566
Epoch 38/50
 - 4s - loss: 4736.7952 - val_loss: 3200.5258
Epoch 39/50
 - 4s - loss: 4716.7959 - val_loss: 3202.8305
Epoch 40/50
 - 4s - loss: 4713.4033 - val_loss: 3207.2243
Epoch 41/50
 - 4s - loss: 4707.5422 - val_loss: 3208.7504
Epoch 42/50
 - 4s - loss: 4702.6262 - val_loss: 3176.4497
Epoch 43/50
 - 4s - loss: 4700.2352 - val_loss: 3181.1562
Epoch 44/50
 - 4s - loss: 4685.2633 - val_loss: 3182.7371
Epoch 45/50
 - 4s - loss: 4677.2473 - val_loss: 3158.8146
Epoch 46/50
 - 4s - loss: 4681.2734 - val_loss: 3164.0541
Epoch 47/50
 - 4s - loss: 4666.2226 - val_loss: 3147.8210
Epoch 48/50
 - 4s - loss: 4659.0308 - val_loss: 3145.3405
Epoch 49/50
 - 4s - loss: 4650.3201 - val_loss: 3154.1302
Epoch 50/50
 - 4s - loss: 4656.6120 - val_loss: 3123.5614
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 44720	action = 0	current_phase = 1	next_phase = 0	reward = 0.721961	array([[ -6.6334023, -43.400974 ]], dtype=float32)
time = 44725	action = 0	current_phase = 1	next_phase = 0	reward = 0.720665	array([[ -6.6338024, -43.42172  ]], dtype=float32)
time = 44730	action = 0	current_phase = 1	next_phase = 0	reward = 0.721646	array([[ -6.635555, -43.356056]], dtype=float32)
time = 44735	action = 0	current_phase = 1	next_phase = 0	reward = 0.718751	array([[ -6.5708637, -42.99012  ]], dtype=float32)
time = 44740	action = 0	current_phase = 1	next_phase = 0	reward = 0.726813	array([[ -6.5850983, -43.043224 ]], dtype=float32)
time = 44745	action = 0	current_phase = 1	next_phase = 0	reward = 0.719737	array([[ -6.62424 , -43.363194]], dtype=float32)
time = 44750	action = 0	current_phase = 1	next_phase = 0	reward = 0.720671	array([[ -6.6259127, -43.321243 ]], dtype=float32)
time = 44755	action = 0	current_phase = 1	next_phase = 0	reward = 0.721965	array([[ -6.6074724, -43.240196 ]], dtype=float32)
time = 44760	action = 0	current_phase = 1	next_phase = 0	reward = 0.720121	array([[ -6.6127295, -43.26999  ]], dtype=float32)
time = 44765	action = 0	current_phase = 1	next_phase = 0	reward = 0.721064	array([[ -6.624508, -43.353363]], dtype=float32)
time = 44770	action = 0	current_phase = 1	next_phase = 0	reward = 0.718479	array([[ -6.6059804, -43.239212 ]], dtype=float32)
time = 44775	action = 0	current_phase = 1	next_phase = 0	reward = 0.443052	array([[ -6.623222, -43.290512]], dtype=float32)
time = 44780	action = 0	current_phase = 1	next_phase = 0	reward = 1.003245	array([[ -6.615999, -43.294647]], dtype=float32)
time = 44785	action = 0	current_phase = 1	next_phase = 0	reward = 0.718012	array([[ -6.699124, -43.46515 ]], dtype=float32)
time = 44790	action = 0	current_phase = 1	next_phase = 0	reward = 0.716947	array([[ -6.604  , -43.22782]], dtype=float32)
time = 44795	action = 0	current_phase = 1	next_phase = 0	reward = 0.439070	array([[ -6.601773, -43.16281 ]], dtype=float32)
time = 44800	action = 0	current_phase = 1	next_phase = 0	reward = 0.995316	array([[ -6.6091456, -43.227623 ]], dtype=float32)
time = 44805	action = 0	current_phase = 1	next_phase = 0	reward = 0.434411	array([[ -6.5733166, -43.007816 ]], dtype=float32)
time = 44810	action = 0	current_phase = 1	next_phase = 0	reward = 1.005524	array([[ -6.605586, -43.23277 ]], dtype=float32)
time = 44815	action = 0	current_phase = 1	next_phase = 0	reward = 0.719817	array([[ -6.615656, -43.280514]], dtype=float32)
time = 44820	action = 0	current_phase = 1	next_phase = 0	reward = 0.448618	array([[ -6.6184745, -43.296932 ]], dtype=float32)
time = 44825	action = 0	current_phase = 1	next_phase = 0	reward = 1.010748	array([[ -6.6250024, -43.36077  ]], dtype=float32)
time = 44830	action = 0	current_phase = 1	next_phase = 0	reward = 0.720676	array([[ -6.594035, -43.09739 ]], dtype=float32)
time = 44835	action = 0	current_phase = 1	next_phase = 0	reward = 0.444942	array([[ -6.6289763, -43.33829  ]], dtype=float32)
time = 44840	action = 0	current_phase = 1	next_phase = 0	reward = 0.726486	array([[ -6.6224666, -43.079144 ]], dtype=float32)
time = 44845	action = 0	current_phase = 1	next_phase = 0	reward = 1.003053	array([[ -6.596487, -43.178795]], dtype=float32)
time = 44850	action = 0	current_phase = 1	next_phase = 0	reward = 0.711112	array([[ -6.647473, -43.29186 ]], dtype=float32)
time = 44855	action = 0	current_phase = 1	next_phase = 0	reward = 0.441364	array([[ -6.6113887, -43.247456 ]], dtype=float32)
time = 44860	action = 0	current_phase = 1	next_phase = 0	reward = 1.006345	array([[ -6.611712, -43.213474]], dtype=float32)
time = 44865	action = 0	current_phase = 1	next_phase = 0	reward = 0.723654	array([[ -6.609283, -43.26094 ]], dtype=float32)
time = 44870	action = 0	current_phase = 1	next_phase = 0	reward = 0.725734	array([[ -6.6034784, -43.212227 ]], dtype=float32)
time = 44875	action = 0	current_phase = 1	next_phase = 0	reward = 0.439560	array([[ -6.6443844, -43.156265 ]], dtype=float32)
time = 44880	action = 0	current_phase = 1	next_phase = 0	reward = 0.992290	array([[ -6.558056, -42.902626]], dtype=float32)
time = 44885	action = 0	current_phase = 1	next_phase = 0	reward = 0.720826	array([[ -6.6014395, -43.197533 ]], dtype=float32)
time = 44890	action = 0	current_phase = 1	next_phase = 0	reward = 0.719535	array([[ -6.61629 , -43.253822]], dtype=float32)
time = 44895	action = 0	current_phase = 1	next_phase = 0	reward = 0.724453	array([[ -6.5859385, -43.098103 ]], dtype=float32)
time = 44900	action = 0	current_phase = 1	next_phase = 0	reward = 0.722046	array([[ -6.628167, -43.375336]], dtype=float32)
time = 44905	action = 0	current_phase = 1	next_phase = 0	reward = 0.720929	array([[ -6.6632934, -43.22607  ]], dtype=float32)
time = 44910	action = 0	current_phase = 1	next_phase = 0	reward = 0.721325	array([[ -6.6060057, -43.22302  ]], dtype=float32)
time = 44915	action = 0	current_phase = 1	next_phase = 0	reward = 0.723628	array([[ -6.6122003, -43.2783   ]], dtype=float32)
time = 44920	action = 0	current_phase = 1	next_phase = 0	reward = 0.724610	array([[ -6.5981636, -43.110004 ]], dtype=float32)
time = 44925	action = 0	current_phase = 1	next_phase = 0	reward = 0.717202	array([[ -6.602149, -43.196766]], dtype=float32)
time = 44930	action = 0	current_phase = 1	next_phase = 0	reward = 0.723281	array([[ -6.6158485, -43.300858 ]], dtype=float32)
time = 44935	action = 0	current_phase = 1	next_phase = 0	reward = 0.718141	array([[ -6.626984, -43.303276]], dtype=float32)
time = 44940	action = 0	current_phase = 1	next_phase = 0	reward = 0.718368	array([[ -6.6104803, -43.267086 ]], dtype=float32)
time = 44945	action = 0	current_phase = 1	next_phase = 0	reward = 0.716676	array([[ -6.613915, -43.269367]], dtype=float32)
time = 44950	action = 0	current_phase = 1	next_phase = 0	reward = 0.440980	array([[ -6.609265, -43.229256]], dtype=float32)
time = 44955	action = 0	current_phase = 1	next_phase = 0	reward = 0.725626	array([[ -6.6111417, -43.200886 ]], dtype=float32)
time = 44960	action = 0	current_phase = 1	next_phase = 0	reward = 0.994926	array([[ -6.578938, -43.033817]], dtype=float32)
time = 44965	action = 0	current_phase = 1	next_phase = 0	reward = 0.721891	array([[ -6.608612, -43.242283]], dtype=float32)
time = 44970	action = 0	current_phase = 1	next_phase = 0	reward = 0.727240	array([[ -6.5847654, -43.089405 ]], dtype=float32)
time = 44975	action = 0	current_phase = 1	next_phase = 0	reward = 0.728707	array([[ -6.5937214, -43.12376  ]], dtype=float32)
time = 44980	action = 0	current_phase = 1	next_phase = 0	reward = 0.720590	array([[ -6.611651, -43.225014]], dtype=float32)
time = 44985	action = 0	current_phase = 1	next_phase = 0	reward = 0.714227	array([[ -6.6433673, -43.38981  ]], dtype=float32)
time = 44990	action = 0	current_phase = 1	next_phase = 0	reward = 0.712783	array([[ -6.6084075, -43.18907  ]], dtype=float32)
time = 44995	action = 0	current_phase = 1	next_phase = 0	reward = 0.440500	array([[ -6.6005154, -43.181053 ]], dtype=float32)
time = 45000	action = 0	current_phase = 1	next_phase = 0	reward = 1.002288	array([[ -6.6002693, -43.197853 ]], dtype=float32)
time = 45005	action = 0	current_phase = 1	next_phase = 0	reward = 0.722038	array([[ -6.591631, -43.111984]], dtype=float32)
time = 45010	action = 0	current_phase = 1	next_phase = 0	reward = 0.437971	array([[ -6.625034, -43.3467  ]], dtype=float32)
time = 45015	action = 0	current_phase = 1	next_phase = 0	reward = 0.998500	array([[ -6.60204 , -43.196053]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 7202.7698 - val_loss: 2517.3116
Epoch 2/50
 - 4s - loss: 7188.6808 - val_loss: 2523.8988
Epoch 3/50
 - 4s - loss: 7169.2115 - val_loss: 2512.2523
Epoch 4/50
 - 4s - loss: 7153.9512 - val_loss: 2521.3102
Epoch 5/50
 - 4s - loss: 7149.5545 - val_loss: 2502.9609
Epoch 6/50
 - 4s - loss: 7137.4208 - val_loss: 2522.9747
Epoch 7/50
 - 4s - loss: 7129.7930 - val_loss: 2505.6490
Epoch 8/50
 - 4s - loss: 7135.7488 - val_loss: 2500.3778
Epoch 9/50
 - 4s - loss: 7114.3623 - val_loss: 2498.7529
Epoch 10/50
 - 4s - loss: 7107.0740 - val_loss: 2493.6721
Epoch 11/50
 - 4s - loss: 7101.8571 - val_loss: 2491.2197
Epoch 12/50
 - 4s - loss: 7091.3019 - val_loss: 2491.7668
Epoch 13/50
 - 4s - loss: 7092.5665 - val_loss: 2487.3676
Epoch 14/50
 - 4s - loss: 7088.9866 - val_loss: 2484.6273
Epoch 15/50
 - 4s - loss: 7079.0769 - val_loss: 2483.6402
Epoch 16/50
 - 4s - loss: 7063.9213 - val_loss: 2472.1530
Epoch 17/50
 - 4s - loss: 7056.4076 - val_loss: 2503.0214
Epoch 18/50
 - 4s - loss: 7052.7504 - val_loss: 2472.9219
Epoch 19/50
 - 4s - loss: 7047.8639 - val_loss: 2463.3193
Epoch 20/50
 - 4s - loss: 7043.9077 - val_loss: 2453.3898
Epoch 21/50
 - 4s - loss: 7032.5181 - val_loss: 2468.3163
Epoch 22/50
 - 4s - loss: 7028.2115 - val_loss: 2453.4308
Epoch 23/50
 - 4s - loss: 7014.9707 - val_loss: 2454.0409
Epoch 24/50
 - 4s - loss: 7017.6220 - val_loss: 2442.6311
Epoch 25/50
 - 4s - loss: 7000.5798 - val_loss: 2441.9425
Epoch 26/50
 - 4s - loss: 6991.1429 - val_loss: 2454.0231
Epoch 27/50
 - 4s - loss: 6990.6488 - val_loss: 2437.8077
Epoch 28/50
 - 4s - loss: 6976.1293 - val_loss: 2427.0628
Epoch 29/50
 - 4s - loss: 6968.9405 - val_loss: 2422.2096
Epoch 30/50
 - 4s - loss: 6960.4972 - val_loss: 2426.5173
Epoch 31/50
 - 4s - loss: 6962.4875 - val_loss: 2432.5147
Epoch 32/50
 - 4s - loss: 6950.8527 - val_loss: 2430.0936
Epoch 33/50
 - 4s - loss: 6955.7864 - val_loss: 2417.0959
Epoch 34/50
 - 4s - loss: 6937.7120 - val_loss: 2407.6285
Epoch 35/50
 - 4s - loss: 6933.8536 - val_loss: 2435.2509
Epoch 36/50
 - 4s - loss: 6926.2266 - val_loss: 2398.3398
Epoch 37/50
 - 4s - loss: 6915.0788 - val_loss: 2406.8629
Epoch 38/50
 - 4s - loss: 6903.0652 - val_loss: 2390.7531
Epoch 39/50
 - 4s - loss: 6906.6609 - val_loss: 2398.1041
Epoch 40/50
 - 4s - loss: 6899.4734 - val_loss: 2391.9142
Epoch 41/50
 - 4s - loss: 6882.9968 - val_loss: 2396.2890
Epoch 42/50
 - 4s - loss: 6885.2193 - val_loss: 2376.0214
Epoch 43/50
 - 4s - loss: 6873.1108 - val_loss: 2385.4958
Epoch 44/50
 - 4s - loss: 6865.2050 - val_loss: 2372.8465
Epoch 45/50
 - 4s - loss: 6862.5859 - val_loss: 2367.1699
Epoch 46/50
 - 4s - loss: 6861.4281 - val_loss: 2361.4906
Epoch 47/50
 - 4s - loss: 6852.3245 - val_loss: 2391.1863
Epoch 48/50
 - 4s - loss: 6863.6202 - val_loss: 2354.2822
Epoch 49/50
 - 4s - loss: 6834.8552 - val_loss: 2356.3996
Epoch 50/50
 - 4s - loss: 6833.3449 - val_loss: 2350.1906
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 45020	action = 0	current_phase = 1	next_phase = 0	reward = 0.715134	array([[ -6.626116, -43.144924]], dtype=float32)
time = 45025	action = 0	current_phase = 1	next_phase = 0	reward = 0.721062	array([[ -6.632433, -43.135242]], dtype=float32)
time = 45030	action = 0	current_phase = 1	next_phase = 0	reward = 0.714182	array([[ -6.6118197, -43.054977 ]], dtype=float32)
time = 45035	action = 0	current_phase = 1	next_phase = 0	reward = 0.718127	array([[ -6.636196, -43.203896]], dtype=float32)
time = 45040	action = 0	current_phase = 1	next_phase = 0	reward = 0.721758	array([[ -6.5958 , -42.95829]], dtype=float32)
time = 45045	action = 0	current_phase = 1	next_phase = 0	reward = 0.713711	array([[ -6.637052, -43.20058 ]], dtype=float32)
time = 45050	action = 0	current_phase = 1	next_phase = 0	reward = 0.710813	array([[ -6.6465054, -43.257122 ]], dtype=float32)
time = 45055	action = 0	current_phase = 1	next_phase = 0	reward = 0.443563	array([[ -6.62203 , -43.127182]], dtype=float32)
time = 45060	action = 0	current_phase = 1	next_phase = 0	reward = 1.001042	array([[ -6.605071, -43.017075]], dtype=float32)
time = 45065	action = 0	current_phase = 1	next_phase = 0	reward = 0.726763	array([[ -6.61524 , -43.079575]], dtype=float32)
time = 45070	action = 0	current_phase = 1	next_phase = 0	reward = 0.727134	array([[ -6.6425414, -43.203003 ]], dtype=float32)
time = 45075	action = 0	current_phase = 1	next_phase = 0	reward = 0.723417	array([[ -6.5969577, -42.97101  ]], dtype=float32)
time = 45080	action = 0	current_phase = 1	next_phase = 0	reward = 0.724153	array([[ -6.6099167, -43.0341   ]], dtype=float32)
time = 45085	action = 0	current_phase = 1	next_phase = 0	reward = 0.722431	array([[ -6.642584, -43.24103 ]], dtype=float32)
time = 45090	action = 0	current_phase = 1	next_phase = 0	reward = 0.442663	array([[ -6.6509953, -43.121037 ]], dtype=float32)
time = 45095	action = 0	current_phase = 1	next_phase = 0	reward = 1.004547	array([[ -6.6110234, -43.054695 ]], dtype=float32)
time = 45100	action = 0	current_phase = 1	next_phase = 0	reward = 0.446607	array([[ -6.6305275, -43.156284 ]], dtype=float32)
time = 45105	action = 0	current_phase = 1	next_phase = 0	reward = 1.000311	array([[ -6.6155376, -43.04136  ]], dtype=float32)
time = 45110	action = 0	current_phase = 1	next_phase = 0	reward = 0.713638	array([[ -6.635213, -43.20701 ]], dtype=float32)
time = 45115	action = 0	current_phase = 1	next_phase = 0	reward = 0.712352	array([[ -6.6208267, -43.104908 ]], dtype=float32)
time = 45120	action = 0	current_phase = 1	next_phase = 0	reward = 0.728045	array([[ -6.607606, -43.030025]], dtype=float32)
time = 45125	action = 0	current_phase = 1	next_phase = 0	reward = 0.730248	array([[ -6.627987, -43.163303]], dtype=float32)
time = 45130	action = 0	current_phase = 1	next_phase = 0	reward = 0.720369	array([[ -6.64934, -43.25677]], dtype=float32)
time = 45135	action = 0	current_phase = 1	next_phase = 0	reward = 0.716156	array([[ -6.6173606, -43.098698 ]], dtype=float32)
time = 45140	action = 0	current_phase = 1	next_phase = 0	reward = 0.715344	array([[ -6.648974, -43.26319 ]], dtype=float32)
time = 45145	action = 0	current_phase = 1	next_phase = 0	reward = 0.709710	array([[ -6.5415998, -42.61733  ]], dtype=float32)
time = 45150	action = 0	current_phase = 1	next_phase = 0	reward = 0.447201	array([[ -6.6134696, -43.063572 ]], dtype=float32)
time = 45155	action = 0	current_phase = 1	next_phase = 0	reward = 0.730563	array([[ -6.6213784, -43.111538 ]], dtype=float32)
time = 45160	action = 0	current_phase = 1	next_phase = 0	reward = 1.013736	array([[ -6.6275826, -43.157436 ]], dtype=float32)
time = 45165	action = 0	current_phase = 1	next_phase = 0	reward = 0.717892	array([[ -6.6302466, -43.15701  ]], dtype=float32)
time = 45170	action = 0	current_phase = 1	next_phase = 0	reward = 0.724772	array([[ -6.641201, -43.202484]], dtype=float32)
time = 45175	action = 0	current_phase = 1	next_phase = 0	reward = 0.719782	array([[ -6.6091375, -43.03295  ]], dtype=float32)
time = 45180	action = 0	current_phase = 1	next_phase = 0	reward = 0.715451	array([[ -6.629557, -43.14791 ]], dtype=float32)
time = 45185	action = 0	current_phase = 1	next_phase = 0	reward = 0.723825	array([[ -6.621821, -43.126377]], dtype=float32)
time = 45190	action = 0	current_phase = 1	next_phase = 0	reward = 0.719478	array([[ -6.650263, -43.214092]], dtype=float32)
time = 45195	action = 0	current_phase = 1	next_phase = 0	reward = 0.718856	array([[ -6.6401753, -43.115738 ]], dtype=float32)
time = 45200	action = 0	current_phase = 1	next_phase = 0	reward = 0.720067	array([[ -6.6409464, -43.21442  ]], dtype=float32)
time = 45205	action = 0	current_phase = 1	next_phase = 0	reward = 0.728459	array([[ -6.6502013, -43.299213 ]], dtype=float32)
time = 45210	action = 0	current_phase = 1	next_phase = 0	reward = 0.723693	array([[ -6.630462, -43.155457]], dtype=float32)
time = 45215	action = 0	current_phase = 1	next_phase = 0	reward = 0.721616	array([[ -6.6408653, -43.232586 ]], dtype=float32)
time = 45220	action = 0	current_phase = 1	next_phase = 0	reward = 0.444976	array([[ -6.6356764, -43.182255 ]], dtype=float32)
time = 45225	action = 0	current_phase = 1	next_phase = 0	reward = 1.001478	array([[ -6.628676, -43.138805]], dtype=float32)
time = 45230	action = 0	current_phase = 1	next_phase = 0	reward = 0.711823	array([[ -6.5732665, -42.817238 ]], dtype=float32)
time = 45235	action = 0	current_phase = 1	next_phase = 0	reward = 0.717984	array([[ -6.650662, -43.294952]], dtype=float32)
time = 45240	action = 0	current_phase = 1	next_phase = 0	reward = 0.721288	array([[ -6.640112, -43.232048]], dtype=float32)
time = 45245	action = 0	current_phase = 1	next_phase = 0	reward = 0.720888	array([[ -6.629844, -43.16772 ]], dtype=float32)
time = 45250	action = 0	current_phase = 1	next_phase = 0	reward = 0.715877	array([[ -6.6508875, -43.295532 ]], dtype=float32)
time = 45255	action = 0	current_phase = 1	next_phase = 0	reward = 0.718636	array([[ -6.622281, -43.085106]], dtype=float32)
time = 45260	action = 0	current_phase = 1	next_phase = 0	reward = 0.446401	array([[ -6.605425, -43.00736 ]], dtype=float32)
time = 45265	action = 0	current_phase = 1	next_phase = 0	reward = 1.003680	array([[ -6.6342597, -43.175415 ]], dtype=float32)
time = 45270	action = 0	current_phase = 1	next_phase = 0	reward = 0.719424	array([[ -6.620659, -43.08857 ]], dtype=float32)
time = 45275	action = 0	current_phase = 1	next_phase = 0	reward = 0.719766	array([[ -6.6370854, -43.20083  ]], dtype=float32)
time = 45280	action = 0	current_phase = 1	next_phase = 0	reward = 0.716969	array([[ -6.6189837, -43.043903 ]], dtype=float32)
time = 45285	action = 0	current_phase = 1	next_phase = 0	reward = 0.438944	array([[ -6.6407447, -43.184284 ]], dtype=float32)
time = 45290	action = 0	current_phase = 1	next_phase = 0	reward = 0.998752	array([[ -6.6362104, -43.192944 ]], dtype=float32)
time = 45295	action = 0	current_phase = 1	next_phase = 0	reward = 0.715126	array([[ -6.5735984, -42.80935  ]], dtype=float32)
time = 45300	action = 0	current_phase = 1	next_phase = 0	reward = 0.715266	array([[ -6.6221566, -43.11888  ]], dtype=float32)
time = 45305	action = 0	current_phase = 1	next_phase = 0	reward = 0.725417	array([[ -6.634851, -43.17115 ]], dtype=float32)
time = 45310	action = 0	current_phase = 1	next_phase = 0	reward = 0.721951	array([[ -6.6438446, -43.252014 ]], dtype=float32)
time = 45315	action = 0	current_phase = 1	next_phase = 0	reward = 0.715137	array([[ -6.630355, -43.15506 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3429.4559 - val_loss: 3656.1629
Epoch 2/50
 - 4s - loss: 3419.6048 - val_loss: 3645.2841
Epoch 3/50
 - 4s - loss: 3409.7082 - val_loss: 3641.9188
Epoch 4/50
 - 4s - loss: 3400.2430 - val_loss: 3632.7438
Epoch 5/50
 - 4s - loss: 3399.8044 - val_loss: 3627.7193
Epoch 6/50
 - 4s - loss: 3390.5048 - val_loss: 3642.7052
Epoch 7/50
 - 4s - loss: 3396.1725 - val_loss: 3630.0905
Epoch 8/50
 - 4s - loss: 3385.3718 - val_loss: 3631.5603
Epoch 9/50
 - 4s - loss: 3371.0547 - val_loss: 3615.6801
Epoch 10/50
 - 4s - loss: 3374.9822 - val_loss: 3611.2414
Epoch 11/50
 - 4s - loss: 3360.7493 - val_loss: 3607.7400
Epoch 12/50
 - 4s - loss: 3353.7840 - val_loss: 3612.1109
Epoch 13/50
 - 4s - loss: 3353.1658 - val_loss: 3595.7157
Epoch 14/50
 - 4s - loss: 3353.9658 - val_loss: 3619.4475
Epoch 15/50
 - 4s - loss: 3344.4823 - val_loss: 3587.5417
Epoch 16/50
 - 4s - loss: 3341.9612 - val_loss: 3584.2628
Epoch 17/50
 - 4s - loss: 3338.8305 - val_loss: 3594.6140
Epoch 18/50
 - 4s - loss: 3335.3101 - val_loss: 3578.9847
Epoch 19/50
 - 4s - loss: 3331.2004 - val_loss: 3577.0383
Epoch 20/50
 - 4s - loss: 3321.3701 - val_loss: 3568.4090
Epoch 21/50
 - 4s - loss: 3323.1710 - val_loss: 3578.6292
Epoch 22/50
 - 4s - loss: 3321.1681 - val_loss: 3601.2669
Epoch 23/50
 - 4s - loss: 3302.2881 - val_loss: 3557.3804
Epoch 24/50
 - 4s - loss: 3300.4034 - val_loss: 3545.9348
Epoch 25/50
 - 4s - loss: 3288.2005 - val_loss: 3546.1620
Epoch 26/50
 - 4s - loss: 3289.0574 - val_loss: 3537.2117
Epoch 27/50
 - 4s - loss: 3282.1509 - val_loss: 3547.0981
Epoch 28/50
 - 4s - loss: 3276.0966 - val_loss: 3527.9087
Epoch 29/50
 - 4s - loss: 3276.8228 - val_loss: 3527.5145
Epoch 30/50
 - 4s - loss: 3269.2601 - val_loss: 3521.0195
Epoch 31/50
 - 4s - loss: 3260.8560 - val_loss: 3521.0526
Epoch 32/50
 - 4s - loss: 3258.1425 - val_loss: 3518.3763
Epoch 33/50
 - 4s - loss: 3252.0015 - val_loss: 3508.7206
Epoch 34/50
 - 4s - loss: 3248.6207 - val_loss: 3520.1761
Epoch 35/50
 - 4s - loss: 3240.3743 - val_loss: 3521.6387
Epoch 36/50
 - 4s - loss: 3243.5523 - val_loss: 3503.3373
Epoch 37/50
 - 4s - loss: 3252.1770 - val_loss: 3506.5978
Epoch 38/50
 - 4s - loss: 3229.1425 - val_loss: 3492.3612
Epoch 39/50
 - 4s - loss: 3225.0326 - val_loss: 3488.3343
Epoch 40/50
 - 4s - loss: 3222.1294 - val_loss: 3484.0513
Epoch 41/50
 - 4s - loss: 3219.6429 - val_loss: 3480.9191
Epoch 42/50
 - 4s - loss: 3211.2003 - val_loss: 3483.4089
Epoch 43/50
 - 4s - loss: 3215.3596 - val_loss: 3472.8459
Epoch 44/50
 - 4s - loss: 3201.8178 - val_loss: 3470.0614
Epoch 45/50
 - 4s - loss: 3200.0703 - val_loss: 3464.4788
Epoch 46/50
 - 4s - loss: 3193.0814 - val_loss: 3455.5079
Epoch 47/50
 - 4s - loss: 3190.4836 - val_loss: 3461.4666
Epoch 48/50
 - 4s - loss: 3181.1376 - val_loss: 3459.9556
Epoch 49/50
 - 4s - loss: 3186.4992 - val_loss: 3445.9234
Epoch 50/50
 - 4s - loss: 3176.0149 - val_loss: 3444.5728
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 45320	action = 0	current_phase = 1	next_phase = 0	reward = 0.716037	array([[ -4.6373672, -43.066696 ]], dtype=float32)
time = 45325	action = 0	current_phase = 1	next_phase = 0	reward = 0.167677	array([[ -4.6483555, -43.20907  ]], dtype=float32)
time = 45330	action = 0	current_phase = 1	next_phase = 0	reward = 1.299112	array([[ -4.6205015, -42.9651   ]], dtype=float32)
time = 45335	action = 0	current_phase = 1	next_phase = 0	reward = 0.721380	array([[ -4.6316376, -43.056553 ]], dtype=float32)
time = 45340	action = 0	current_phase = 1	next_phase = 0	reward = 0.720838	array([[ -4.6557846, -43.18553  ]], dtype=float32)
time = 45345	action = 0	current_phase = 1	next_phase = 0	reward = 0.721181	array([[ -4.629835, -43.028152]], dtype=float32)
time = 45350	action = 0	current_phase = 1	next_phase = 0	reward = 0.714330	array([[ -4.6554203, -43.16329  ]], dtype=float32)
time = 45355	action = 0	current_phase = 1	next_phase = 0	reward = 0.725050	array([[ -4.6776733, -43.12623  ]], dtype=float32)
time = 45360	action = 0	current_phase = 1	next_phase = 0	reward = 0.719292	array([[ -4.6413956, -43.102962 ]], dtype=float32)
time = 45365	action = 0	current_phase = 1	next_phase = 0	reward = 0.442163	array([[ -4.636924, -43.052883]], dtype=float32)
time = 45370	action = 0	current_phase = 1	next_phase = 0	reward = 1.005154	array([[ -4.6341133, -43.066597 ]], dtype=float32)
time = 45375	action = 0	current_phase = 1	next_phase = 0	reward = 0.717882	array([[ -4.6506042, -43.149567 ]], dtype=float32)
time = 45380	action = 0	current_phase = 1	next_phase = 0	reward = 0.713393	array([[ -4.634919, -43.083923]], dtype=float32)
time = 45385	action = 0	current_phase = 1	next_phase = 0	reward = 0.725179	array([[ -4.643278, -43.12963 ]], dtype=float32)
time = 45390	action = 0	current_phase = 1	next_phase = 0	reward = 0.724530	array([[ -4.615185, -42.94553 ]], dtype=float32)
time = 45395	action = 0	current_phase = 1	next_phase = 0	reward = 0.722094	array([[ -4.635413, -43.066505]], dtype=float32)
time = 45400	action = 0	current_phase = 1	next_phase = 0	reward = 0.720406	array([[ -4.6266146, -43.060944 ]], dtype=float32)
time = 45405	action = 0	current_phase = 1	next_phase = 0	reward = 0.709762	array([[ -4.6287203, -43.02375  ]], dtype=float32)
time = 45410	action = 0	current_phase = 1	next_phase = 0	reward = 0.716018	array([[ -4.6290617, -43.04323  ]], dtype=float32)
time = 45415	action = 0	current_phase = 1	next_phase = 0	reward = 0.726018	array([[ -4.6002417, -42.869305 ]], dtype=float32)
time = 45420	action = 0	current_phase = 1	next_phase = 0	reward = 0.725586	array([[ -4.6315165, -43.05811  ]], dtype=float32)
time = 45425	action = 0	current_phase = 1	next_phase = 0	reward = 0.723929	array([[ -4.648489, -43.167755]], dtype=float32)
time = 45430	action = 0	current_phase = 1	next_phase = 0	reward = 0.719050	array([[ -4.6476955, -43.111732 ]], dtype=float32)
time = 45435	action = 0	current_phase = 1	next_phase = 0	reward = 0.441760	array([[ -4.6133413, -42.894936 ]], dtype=float32)
time = 45440	action = 0	current_phase = 1	next_phase = 0	reward = 1.007180	array([[ -4.611849, -42.929718]], dtype=float32)
time = 45445	action = 0	current_phase = 1	next_phase = 0	reward = 0.433496	array([[ -4.6257887, -43.00006  ]], dtype=float32)
time = 45450	action = 0	current_phase = 1	next_phase = 0	reward = 0.994426	array([[ -4.622837, -42.995705]], dtype=float32)
time = 45455	action = 0	current_phase = 1	next_phase = 0	reward = 0.725045	array([[ -4.6601553, -43.207436 ]], dtype=float32)
time = 45460	action = 0	current_phase = 1	next_phase = 0	reward = 0.717647	array([[ -4.6229706, -42.99977  ]], dtype=float32)
time = 45465	action = 0	current_phase = 1	next_phase = 0	reward = 0.722570	array([[ -4.657448, -43.195694]], dtype=float32)
time = 45470	action = 0	current_phase = 1	next_phase = 0	reward = 0.716271	array([[ -4.630327, -43.031822]], dtype=float32)
time = 45475	action = 0	current_phase = 1	next_phase = 0	reward = 0.719627	array([[ -4.6091003, -42.892914 ]], dtype=float32)
time = 45480	action = 0	current_phase = 1	next_phase = 0	reward = 0.447381	array([[ -4.6193447, -42.980515 ]], dtype=float32)
time = 45485	action = 0	current_phase = 1	next_phase = 0	reward = 1.001459	array([[ -4.6282635, -43.013535 ]], dtype=float32)
time = 45490	action = 0	current_phase = 1	next_phase = 0	reward = 0.444046	array([[ -4.6488047, -43.152855 ]], dtype=float32)
time = 45495	action = 0	current_phase = 1	next_phase = 0	reward = 1.001658	array([[ -4.6068945, -42.86721  ]], dtype=float32)
time = 45500	action = 0	current_phase = 1	next_phase = 0	reward = 0.733914	array([[ -4.604471, -42.86921 ]], dtype=float32)
time = 45505	action = 0	current_phase = 1	next_phase = 0	reward = 0.724282	array([[ -4.6111784, -42.9256   ]], dtype=float32)
time = 45510	action = 0	current_phase = 1	next_phase = 0	reward = 0.717658	array([[ -4.658304, -43.19314 ]], dtype=float32)
time = 45515	action = 0	current_phase = 1	next_phase = 0	reward = 0.714887	array([[ -4.6432323, -43.108788 ]], dtype=float32)
time = 45520	action = 0	current_phase = 1	next_phase = 0	reward = 0.717845	array([[ -4.649967, -43.14366 ]], dtype=float32)
time = 45525	action = 0	current_phase = 1	next_phase = 0	reward = 0.711402	array([[ -4.661188, -43.009853]], dtype=float32)
time = 45530	action = 0	current_phase = 1	next_phase = 0	reward = 0.450545	array([[ -4.635021, -43.055763]], dtype=float32)
time = 45535	action = 0	current_phase = 1	next_phase = 0	reward = 1.006177	array([[ -4.65856 , -43.193756]], dtype=float32)
time = 45540	action = 0	current_phase = 1	next_phase = 0	reward = 0.446625	array([[ -4.6549854, -43.13482  ]], dtype=float32)
time = 45545	action = 0	current_phase = 1	next_phase = 0	reward = 1.003396	array([[ -4.647587, -43.130203]], dtype=float32)
time = 45550	action = 0	current_phase = 1	next_phase = 0	reward = 0.717612	array([[ -4.644844, -43.1115  ]], dtype=float32)
time = 45555	action = 0	current_phase = 1	next_phase = 0	reward = 0.718896	array([[ -4.62416 , -43.010418]], dtype=float32)
time = 45560	action = 0	current_phase = 1	next_phase = 0	reward = 0.440460	array([[ -4.599497, -42.84326 ]], dtype=float32)
time = 45565	action = 0	current_phase = 1	next_phase = 0	reward = 1.000458	array([[ -4.6124077, -42.915123 ]], dtype=float32)
time = 45570	action = 0	current_phase = 1	next_phase = 0	reward = 0.713062	array([[ -4.6374187, -43.073433 ]], dtype=float32)
time = 45575	action = 0	current_phase = 1	next_phase = 0	reward = 0.440846	array([[ -4.6323433, -43.044273 ]], dtype=float32)
time = 45580	action = 0	current_phase = 1	next_phase = 0	reward = 0.727974	array([[ -4.6290836, -43.027283 ]], dtype=float32)
time = 45585	action = 0	current_phase = 1	next_phase = 0	reward = 0.742760	array([[ -4.5788403, -42.69626  ]], dtype=float32)
time = 45590	action = 0	current_phase = 1	next_phase = 0	reward = 1.007201	array([[ -4.629712, -43.060204]], dtype=float32)
time = 45595	action = 0	current_phase = 1	next_phase = 0	reward = 0.716401	array([[ -4.657736, -43.18897 ]], dtype=float32)
time = 45600	action = 0	current_phase = 1	next_phase = 0	reward = 0.720391	array([[ -4.5565653, -42.549824 ]], dtype=float32)
time = 45605	action = 0	current_phase = 1	next_phase = 0	reward = 0.447891	array([[ -4.6332636, -43.04332  ]], dtype=float32)
time = 45610	action = 0	current_phase = 1	next_phase = 0	reward = 1.003824	array([[ -4.617449, -42.933975]], dtype=float32)
time = 45615	action = 0	current_phase = 1	next_phase = 0	reward = 0.718966	array([[ -4.6123476, -42.92415  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3399.2589 - val_loss: 7438.3195
Epoch 2/50
 - 4s - loss: 3403.5313 - val_loss: 7422.7207
Epoch 3/50
 - 4s - loss: 3380.9374 - val_loss: 7454.8510
Epoch 4/50
 - 4s - loss: 3379.1951 - val_loss: 7428.8025
Epoch 5/50
 - 4s - loss: 3377.3659 - val_loss: 7427.4105
Epoch 6/50
 - 4s - loss: 3368.4096 - val_loss: 7426.6865
Epoch 7/50
 - 4s - loss: 3377.6980 - val_loss: 7423.7455
Epoch 8/50
 - 4s - loss: 3360.1401 - val_loss: 7400.1823
Epoch 9/50
 - 4s - loss: 3351.0920 - val_loss: 7407.9744
Epoch 10/50
 - 4s - loss: 3340.4448 - val_loss: 7411.0504
Epoch 11/50
 - 4s - loss: 3349.8609 - val_loss: 7410.3808
Epoch 12/50
 - 4s - loss: 3354.8428 - val_loss: 7392.3085
Epoch 13/50
 - 4s - loss: 3331.4174 - val_loss: 7421.5074
Epoch 14/50
 - 4s - loss: 3326.2795 - val_loss: 7394.0372
Epoch 15/50
 - 4s - loss: 3328.7522 - val_loss: 7414.3240
Epoch 16/50
 - 4s - loss: 3324.7026 - val_loss: 7389.8793
Epoch 17/50
 - 4s - loss: 3316.5382 - val_loss: 7376.0610
Epoch 18/50
 - 4s - loss: 3324.0599 - val_loss: 7373.6723
Epoch 19/50
 - 4s - loss: 3305.3139 - val_loss: 7370.4068
Epoch 20/50
 - 4s - loss: 3300.5580 - val_loss: 7366.1904
Epoch 21/50
 - 4s - loss: 3287.0006 - val_loss: 7376.3763
Epoch 22/50
 - 4s - loss: 3292.4406 - val_loss: 7371.2233
Epoch 23/50
 - 4s - loss: 3289.0093 - val_loss: 7359.1168
Epoch 24/50
 - 4s - loss: 3286.6502 - val_loss: 7350.4914
Epoch 25/50
 - 4s - loss: 3282.7067 - val_loss: 7335.6553
Epoch 26/50
 - 4s - loss: 3272.0722 - val_loss: 7341.7281
Epoch 27/50
 - 4s - loss: 3267.5531 - val_loss: 7363.9072
Epoch 28/50
 - 4s - loss: 3261.0787 - val_loss: 7337.5715
Epoch 29/50
 - 4s - loss: 3267.3886 - val_loss: 7320.6796
Epoch 30/50
 - 4s - loss: 3257.3000 - val_loss: 7340.4386
Epoch 31/50
 - 4s - loss: 3251.7661 - val_loss: 7330.9321
Epoch 32/50
 - 4s - loss: 3251.7585 - val_loss: 7314.6652
Epoch 33/50
 - 4s - loss: 3240.4924 - val_loss: 7315.8844
Epoch 34/50
 - 4s - loss: 3238.3843 - val_loss: 7309.6715
Epoch 35/50
 - 4s - loss: 3229.5794 - val_loss: 7300.1404
Epoch 36/50
 - 4s - loss: 3230.3186 - val_loss: 7307.5102
Epoch 37/50
 - 4s - loss: 3226.6981 - val_loss: 7311.2335
Epoch 38/50
 - 4s - loss: 3222.2312 - val_loss: 7295.0761
Epoch 39/50
 - 4s - loss: 3216.7186 - val_loss: 7302.4209
Epoch 40/50
 - 4s - loss: 3211.3684 - val_loss: 7308.1734
Epoch 41/50
 - 4s - loss: 3206.9544 - val_loss: 7302.1481
Epoch 42/50
 - 4s - loss: 3217.4214 - val_loss: 7299.3175
Epoch 43/50
 - 4s - loss: 3198.9433 - val_loss: 7316.5592
Epoch 44/50
 - 4s - loss: 3199.7023 - val_loss: 7307.9537
Epoch 45/50
 - 4s - loss: 3189.2025 - val_loss: 7281.0880
Epoch 46/50
 - 4s - loss: 3188.5381 - val_loss: 7297.7079
Epoch 47/50
 - 4s - loss: 3183.5570 - val_loss: 7270.4973
Epoch 48/50
 - 4s - loss: 3184.0015 - val_loss: 7267.6516
Epoch 49/50
 - 4s - loss: 3175.7889 - val_loss: 7291.1774
Epoch 50/50
 - 4s - loss: 3166.1004 - val_loss: 7269.5788
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 45620	action = 0	current_phase = 1	next_phase = 0	reward = 0.708456	array([[ -4.427532, -42.94581 ]], dtype=float32)
time = 45625	action = 0	current_phase = 1	next_phase = 0	reward = 0.434096	array([[ -4.4550285, -43.04397  ]], dtype=float32)
time = 45630	action = 0	current_phase = 1	next_phase = 0	reward = 0.719439	array([[ -4.4143734, -42.87034  ]], dtype=float32)
time = 45635	action = 0	current_phase = 1	next_phase = 0	reward = 1.000457	array([[ -4.4162035, -42.882786 ]], dtype=float32)
time = 45640	action = 0	current_phase = 1	next_phase = 0	reward = 0.728713	array([[ -4.4423246, -43.00019  ]], dtype=float32)
time = 45645	action = 0	current_phase = 1	next_phase = 0	reward = 0.731438	array([[ -4.434581, -42.96718 ]], dtype=float32)
time = 45650	action = 0	current_phase = 1	next_phase = 0	reward = 0.720057	array([[ -4.4281206, -42.934914 ]], dtype=float32)
time = 45655	action = 0	current_phase = 1	next_phase = 0	reward = 0.723980	array([[ -4.5184984, -43.14814  ]], dtype=float32)
time = 45660	action = 0	current_phase = 1	next_phase = 0	reward = 0.725430	array([[ -4.436185, -42.961998]], dtype=float32)
time = 45665	action = 0	current_phase = 1	next_phase = 0	reward = 0.725244	array([[ -4.3989296, -42.81742  ]], dtype=float32)
time = 45670	action = 0	current_phase = 1	next_phase = 0	reward = 0.716589	array([[ -4.406515, -42.83249 ]], dtype=float32)
time = 45675	action = 0	current_phase = 1	next_phase = 0	reward = 0.716441	array([[ -4.4326553, -42.955902 ]], dtype=float32)
time = 45680	action = 0	current_phase = 1	next_phase = 0	reward = 0.712921	array([[ -4.441556, -43.00244 ]], dtype=float32)
time = 45685	action = 0	current_phase = 1	next_phase = 0	reward = 0.444704	array([[ -4.4375105, -42.983482 ]], dtype=float32)
time = 45690	action = 0	current_phase = 1	next_phase = 0	reward = 1.001064	array([[ -4.3916616, -42.753532 ]], dtype=float32)
time = 45695	action = 0	current_phase = 1	next_phase = 0	reward = 0.717291	array([[ -4.4645033, -42.948627 ]], dtype=float32)
time = 45700	action = 0	current_phase = 1	next_phase = 0	reward = 0.721336	array([[ -4.4314795, -42.963684 ]], dtype=float32)
time = 45705	action = 0	current_phase = 1	next_phase = 0	reward = 0.733184	array([[ -4.4043484, -42.84364  ]], dtype=float32)
time = 45710	action = 0	current_phase = 1	next_phase = 0	reward = 0.714643	array([[ -4.4205112, -42.91519  ]], dtype=float32)
time = 45715	action = 0	current_phase = 1	next_phase = 0	reward = 0.725790	array([[ -4.416813, -42.898537]], dtype=float32)
time = 45720	action = 0	current_phase = 1	next_phase = 0	reward = 0.721543	array([[ -4.434352, -42.97545 ]], dtype=float32)
time = 45725	action = 0	current_phase = 1	next_phase = 0	reward = 0.719485	array([[ -4.4504957, -43.032005 ]], dtype=float32)
time = 45730	action = 0	current_phase = 1	next_phase = 0	reward = 0.718776	array([[ -4.4352274, -42.969067 ]], dtype=float32)
time = 45735	action = 0	current_phase = 1	next_phase = 0	reward = 0.722322	array([[ -4.4395514, -42.982765 ]], dtype=float32)
time = 45740	action = 0	current_phase = 1	next_phase = 0	reward = 0.711393	array([[ -4.3903704, -42.768883 ]], dtype=float32)
time = 45745	action = 0	current_phase = 1	next_phase = 0	reward = 0.440144	array([[ -4.4310303, -42.966423 ]], dtype=float32)
time = 45750	action = 0	current_phase = 1	next_phase = 0	reward = 1.002098	array([[ -4.44357 , -43.013386]], dtype=float32)
time = 45755	action = 0	current_phase = 1	next_phase = 0	reward = 0.718383	array([[ -4.4587564, -43.07263  ]], dtype=float32)
time = 45760	action = 0	current_phase = 1	next_phase = 0	reward = 0.717536	array([[ -4.4281597, -42.93373  ]], dtype=float32)
time = 45765	action = 0	current_phase = 1	next_phase = 0	reward = 0.718800	array([[ -4.4481754, -43.030502 ]], dtype=float32)
time = 45770	action = 0	current_phase = 1	next_phase = 0	reward = 0.442728	array([[ -4.4235363, -42.915253 ]], dtype=float32)
time = 45775	action = 0	current_phase = 1	next_phase = 0	reward = 1.010895	array([[ -4.4177923, -42.896828 ]], dtype=float32)
time = 45780	action = 0	current_phase = 1	next_phase = 0	reward = 0.724623	array([[ -4.4716616, -43.12345  ]], dtype=float32)
time = 45785	action = 0	current_phase = 1	next_phase = 0	reward = 0.451178	array([[ -4.429578, -42.943825]], dtype=float32)
time = 45790	action = 0	current_phase = 1	next_phase = 0	reward = 1.004281	array([[ -4.4020195, -42.829544 ]], dtype=float32)
time = 45795	action = 0	current_phase = 1	next_phase = 0	reward = 0.717885	array([[ -4.430093, -42.913956]], dtype=float32)
time = 45800	action = 0	current_phase = 1	next_phase = 0	reward = 0.721383	array([[ -4.391268, -42.784733]], dtype=float32)
time = 45805	action = 0	current_phase = 1	next_phase = 0	reward = 0.723504	array([[ -4.4795704, -43.073517 ]], dtype=float32)
time = 45810	action = 0	current_phase = 1	next_phase = 0	reward = 0.720514	array([[ -4.4604807, -43.076374 ]], dtype=float32)
time = 45815	action = 0	current_phase = 1	next_phase = 0	reward = 0.718666	array([[ -4.4533443, -43.041046 ]], dtype=float32)
time = 45820	action = 0	current_phase = 1	next_phase = 0	reward = 0.714234	array([[ -4.4144554, -42.871323 ]], dtype=float32)
time = 45825	action = 0	current_phase = 1	next_phase = 0	reward = 0.725326	array([[ -4.4391594, -42.98353  ]], dtype=float32)
time = 45830	action = 0	current_phase = 1	next_phase = 0	reward = 0.719860	array([[ -4.4239655, -42.943024 ]], dtype=float32)
time = 45835	action = 0	current_phase = 1	next_phase = 0	reward = 0.440930	array([[ -4.4526434, -43.049835 ]], dtype=float32)
time = 45840	action = 0	current_phase = 1	next_phase = 0	reward = 1.001212	array([[ -4.443084, -43.007195]], dtype=float32)
time = 45845	action = 0	current_phase = 1	next_phase = 0	reward = 0.723180	array([[ -4.4394035, -43.01351  ]], dtype=float32)
time = 45850	action = 0	current_phase = 1	next_phase = 0	reward = 0.715988	array([[ -4.4092073, -42.849766 ]], dtype=float32)
time = 45855	action = 0	current_phase = 1	next_phase = 0	reward = 0.445554	array([[ -4.415431, -42.881172]], dtype=float32)
time = 45860	action = 0	current_phase = 1	next_phase = 0	reward = 1.005535	array([[ -4.418042, -42.897736]], dtype=float32)
time = 45865	action = 0	current_phase = 1	next_phase = 0	reward = 0.724100	array([[ -4.4462996, -43.010162 ]], dtype=float32)
time = 45870	action = 0	current_phase = 1	next_phase = 0	reward = 0.729727	array([[ -4.4515285, -43.030495 ]], dtype=float32)
time = 45875	action = 0	current_phase = 1	next_phase = 0	reward = 0.723093	array([[ -4.408431, -42.832886]], dtype=float32)
time = 45880	action = 0	current_phase = 1	next_phase = 0	reward = 0.718014	array([[ -4.3961525, -42.80597  ]], dtype=float32)
time = 45885	action = 0	current_phase = 1	next_phase = 0	reward = 0.716079	array([[ -4.3810368, -42.74189  ]], dtype=float32)
time = 45890	action = 0	current_phase = 1	next_phase = 0	reward = 0.720671	array([[ -4.463771, -43.091286]], dtype=float32)
time = 45895	action = 0	current_phase = 1	next_phase = 0	reward = 0.729328	array([[ -4.4330072, -42.954494 ]], dtype=float32)
time = 45900	action = 0	current_phase = 1	next_phase = 0	reward = 0.444631	array([[ -4.434881, -42.972088]], dtype=float32)
time = 45905	action = 0	current_phase = 1	next_phase = 0	reward = 0.998608	array([[ -4.4171867, -42.891624 ]], dtype=float32)
time = 45910	action = 0	current_phase = 1	next_phase = 0	reward = 0.715099	array([[ -4.4442987, -43.011734 ]], dtype=float32)
time = 45915	action = 0	current_phase = 1	next_phase = 0	reward = 0.706912	array([[ -4.423053, -42.9218  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3005.3249 - val_loss: 4641.7390
Epoch 2/50
 - 4s - loss: 2991.2029 - val_loss: 4638.8262
Epoch 3/50
 - 4s - loss: 2988.8855 - val_loss: 4634.7613
Epoch 4/50
 - 4s - loss: 2980.6881 - val_loss: 4626.9748
Epoch 5/50
 - 4s - loss: 2975.8868 - val_loss: 4614.0504
Epoch 6/50
 - 4s - loss: 2971.5591 - val_loss: 4600.4571
Epoch 7/50
 - 4s - loss: 2977.0747 - val_loss: 4606.3005
Epoch 8/50
 - 4s - loss: 2963.4874 - val_loss: 4585.7088
Epoch 9/50
 - 4s - loss: 2952.2569 - val_loss: 4587.5621
Epoch 10/50
 - 4s - loss: 2957.1120 - val_loss: 4598.7334
Epoch 11/50
 - 4s - loss: 2943.8132 - val_loss: 4567.9390
Epoch 12/50
 - 4s - loss: 2941.7534 - val_loss: 4586.8649
Epoch 13/50
 - 4s - loss: 2931.0728 - val_loss: 4562.4240
Epoch 14/50
 - 4s - loss: 2940.2559 - val_loss: 4543.6457
Epoch 15/50
 - 4s - loss: 2927.0219 - val_loss: 4544.3751
Epoch 16/50
 - 4s - loss: 2922.3828 - val_loss: 4530.1300
Epoch 17/50
 - 4s - loss: 2914.8210 - val_loss: 4537.7648
Epoch 18/50
 - 3s - loss: 2927.5332 - val_loss: 4533.5688
Epoch 19/50
 - 4s - loss: 2909.1722 - val_loss: 4527.8471
Epoch 20/50
 - 4s - loss: 2905.5956 - val_loss: 4513.2777
Epoch 21/50
 - 4s - loss: 2897.5829 - val_loss: 4502.3587
Epoch 22/50
 - 4s - loss: 2893.4187 - val_loss: 4509.7785
Epoch 23/50
 - 4s - loss: 2897.0723 - val_loss: 4498.8747
Epoch 24/50
 - 4s - loss: 2883.7441 - val_loss: 4476.9945
Epoch 25/50
 - 4s - loss: 2886.2324 - val_loss: 4480.8824
Epoch 26/50
 - 4s - loss: 2871.5742 - val_loss: 4473.5785
Epoch 27/50
 - 4s - loss: 2881.1536 - val_loss: 4471.1351
Epoch 28/50
 - 4s - loss: 2856.6323 - val_loss: 4479.3046
Epoch 29/50
 - 4s - loss: 2863.3070 - val_loss: 4477.2894
Epoch 30/50
 - 4s - loss: 2849.3263 - val_loss: 4445.1620
Epoch 31/50
 - 4s - loss: 2846.0081 - val_loss: 4446.5122
Epoch 32/50
 - 4s - loss: 2850.0081 - val_loss: 4458.5005
Epoch 33/50
 - 4s - loss: 2844.3524 - val_loss: 4442.7983
Epoch 34/50
 - 4s - loss: 2845.2181 - val_loss: 4429.6556
Epoch 35/50
 - 4s - loss: 2839.3944 - val_loss: 4414.0089
Epoch 36/50
 - 4s - loss: 2830.7371 - val_loss: 4402.4171
Epoch 37/50
 - 4s - loss: 2822.4922 - val_loss: 4427.9855
Epoch 38/50
 - 4s - loss: 2820.5562 - val_loss: 4418.0846
Epoch 39/50
 - 4s - loss: 2813.9503 - val_loss: 4394.4722
Epoch 40/50
 - 4s - loss: 2805.8886 - val_loss: 4400.3890
Epoch 41/50
 - 4s - loss: 2807.9002 - val_loss: 4403.1609
Epoch 42/50
 - 4s - loss: 2797.8064 - val_loss: 4381.9333
Epoch 43/50
 - 4s - loss: 2799.2675 - val_loss: 4380.1789
Epoch 44/50
 - 4s - loss: 2795.4501 - val_loss: 4373.2236
Epoch 45/50
 - 4s - loss: 2783.3977 - val_loss: 4363.7701
Epoch 46/50
 - 4s - loss: 2795.0859 - val_loss: 4354.2908
Epoch 47/50
 - 4s - loss: 2779.4446 - val_loss: 4344.1270
Epoch 48/50
 - 4s - loss: 2779.7852 - val_loss: 4346.6266
Epoch 49/50
 - 4s - loss: 2771.1409 - val_loss: 4334.6346
Epoch 50/50
 - 4s - loss: 2762.1209 - val_loss: 4331.2487
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 45920	action = 0	current_phase = 1	next_phase = 0	reward = 0.726569	array([[ -4.5754843, -43.04218  ]], dtype=float32)
time = 45925	action = 0	current_phase = 1	next_phase = 0	reward = 0.447650	array([[ -4.549343, -42.927475]], dtype=float32)
time = 45930	action = 0	current_phase = 1	next_phase = 0	reward = 0.729839	array([[ -4.508815, -42.73064 ]], dtype=float32)
time = 45935	action = 0	current_phase = 1	next_phase = 0	reward = 1.006427	array([[ -4.5067415, -42.769585 ]], dtype=float32)
time = 45940	action = 0	current_phase = 1	next_phase = 0	reward = 0.713269	array([[ -4.5212164, -42.812004 ]], dtype=float32)
time = 45945	action = 0	current_phase = 1	next_phase = 0	reward = 0.437970	array([[ -4.56077 , -42.972862]], dtype=float32)
time = 45950	action = 0	current_phase = 1	next_phase = 0	reward = 0.988772	array([[ -4.5004616, -42.738827 ]], dtype=float32)
time = 45955	action = 0	current_phase = 1	next_phase = 0	reward = 0.718868	array([[ -4.5435286, -42.90709  ]], dtype=float32)
time = 45960	action = 0	current_phase = 1	next_phase = 0	reward = 0.448369	array([[ -4.574128, -43.023117]], dtype=float32)
time = 45965	action = 0	current_phase = 1	next_phase = 0	reward = 1.007162	array([[ -4.5095882, -42.76232  ]], dtype=float32)
time = 45970	action = 0	current_phase = 1	next_phase = 0	reward = 0.725210	array([[ -4.555501, -42.960102]], dtype=float32)
time = 45975	action = 0	current_phase = 1	next_phase = 0	reward = 0.726124	array([[ -4.4593287, -42.54997  ]], dtype=float32)
time = 45980	action = 0	current_phase = 1	next_phase = 0	reward = 0.715940	array([[ -4.572546, -43.017685]], dtype=float32)
time = 45985	action = 0	current_phase = 1	next_phase = 0	reward = 0.440540	array([[ -4.514352, -42.791397]], dtype=float32)
time = 45990	action = 0	current_phase = 1	next_phase = 0	reward = 0.997425	array([[ -4.5584383, -42.960762 ]], dtype=float32)
time = 45995	action = 0	current_phase = 1	next_phase = 0	reward = 0.722030	array([[ -4.526417, -42.852425]], dtype=float32)
time = 46000	action = 0	current_phase = 1	next_phase = 0	reward = 0.722296	array([[ -4.5617676, -42.975853 ]], dtype=float32)
time = 46005	action = 0	current_phase = 1	next_phase = 0	reward = 0.722056	array([[ -4.5461826, -42.912754 ]], dtype=float32)
time = 46010	action = 0	current_phase = 1	next_phase = 0	reward = 0.723796	array([[ -4.5716915, -43.023502 ]], dtype=float32)
time = 46015	action = 0	current_phase = 1	next_phase = 0	reward = 0.721990	array([[ -4.516945, -42.79959 ]], dtype=float32)
time = 46020	action = 0	current_phase = 1	next_phase = 0	reward = 0.723109	array([[ -4.4597254, -42.554688 ]], dtype=float32)
time = 46025	action = 0	current_phase = 1	next_phase = 0	reward = 0.723857	array([[ -4.5007563, -42.734226 ]], dtype=float32)
time = 46030	action = 0	current_phase = 1	next_phase = 0	reward = 0.723422	array([[ -4.551675, -42.934326]], dtype=float32)
time = 46035	action = 0	current_phase = 1	next_phase = 0	reward = 0.716397	array([[ -4.5346727, -42.871765 ]], dtype=float32)
time = 46040	action = 0	current_phase = 1	next_phase = 0	reward = 0.723479	array([[ -4.5698996, -43.014496 ]], dtype=float32)
time = 46045	action = 0	current_phase = 1	next_phase = 0	reward = 0.727147	array([[ -4.5542355, -42.94866  ]], dtype=float32)
time = 46050	action = 0	current_phase = 1	next_phase = 0	reward = 0.723045	array([[ -4.53479, -42.87346]], dtype=float32)
time = 46055	action = 0	current_phase = 1	next_phase = 0	reward = 0.442881	array([[ -4.500944, -42.73336 ]], dtype=float32)
time = 46060	action = 0	current_phase = 1	next_phase = 0	reward = 0.999052	array([[ -4.5890636, -43.08264  ]], dtype=float32)
time = 46065	action = 0	current_phase = 1	next_phase = 0	reward = 0.713099	array([[ -4.521248, -42.817814]], dtype=float32)
time = 46070	action = 0	current_phase = 1	next_phase = 0	reward = 0.442088	array([[ -4.5560904, -42.95823  ]], dtype=float32)
time = 46075	action = 0	current_phase = 1	next_phase = 0	reward = 0.721816	array([[ -4.461176, -42.556965]], dtype=float32)
time = 46080	action = 0	current_phase = 1	next_phase = 0	reward = 0.993943	array([[ -4.5984974, -43.120506 ]], dtype=float32)
time = 46085	action = 0	current_phase = 1	next_phase = 0	reward = 0.716292	array([[ -4.4358616, -42.45843  ]], dtype=float32)
time = 46090	action = 0	current_phase = 1	next_phase = 0	reward = 0.439903	array([[ -4.4967203, -42.712364 ]], dtype=float32)
time = 46095	action = 0	current_phase = 1	next_phase = 0	reward = 1.001495	array([[ -4.5358515, -42.875175 ]], dtype=float32)
time = 46100	action = 0	current_phase = 1	next_phase = 0	reward = 0.440402	array([[ -4.545643, -42.909424]], dtype=float32)
time = 46105	action = 0	current_phase = 1	next_phase = 0	reward = 1.007000	array([[ -4.537236, -42.882423]], dtype=float32)
time = 46110	action = 0	current_phase = 1	next_phase = 0	reward = 0.165476	array([[ -4.6049185, -43.141014 ]], dtype=float32)
time = 46115	action = 0	current_phase = 1	next_phase = 0	reward = 1.289937	array([[ -4.5391464, -42.887707 ]], dtype=float32)
time = 46120	action = 0	current_phase = 1	next_phase = 0	reward = 0.713421	array([[ -4.5362234, -42.869522 ]], dtype=float32)
time = 46125	action = 0	current_phase = 1	next_phase = 0	reward = 0.434520	array([[ -4.5279884, -42.842136 ]], dtype=float32)
time = 46130	action = 0	current_phase = 1	next_phase = 0	reward = 1.001568	array([[ -4.5309734, -42.85658  ]], dtype=float32)
time = 46135	action = 0	current_phase = 1	next_phase = 0	reward = 0.454447	array([[ -4.540271, -42.898727]], dtype=float32)
time = 46140	action = 0	current_phase = 1	next_phase = 0	reward = 1.009982	array([[ -4.5172358, -42.805897 ]], dtype=float32)
time = 46145	action = 0	current_phase = 1	next_phase = 0	reward = 0.724588	array([[ -4.551653, -42.93129 ]], dtype=float32)
time = 46150	action = 0	current_phase = 1	next_phase = 0	reward = 0.717272	array([[ -4.5363474, -42.87523  ]], dtype=float32)
time = 46155	action = 0	current_phase = 1	next_phase = 0	reward = 0.720297	array([[ -4.5263824, -42.83416  ]], dtype=float32)
time = 46160	action = 0	current_phase = 1	next_phase = 0	reward = 0.723884	array([[ -4.4650736, -42.56475  ]], dtype=float32)
time = 46165	action = 0	current_phase = 1	next_phase = 0	reward = 0.712610	array([[ -4.5438766, -42.91592  ]], dtype=float32)
time = 46170	action = 0	current_phase = 1	next_phase = 0	reward = 0.725522	array([[ -4.560049, -42.973392]], dtype=float32)
time = 46175	action = 0	current_phase = 1	next_phase = 0	reward = 0.444588	array([[ -4.559373, -42.96743 ]], dtype=float32)
time = 46180	action = 0	current_phase = 1	next_phase = 0	reward = 1.003029	array([[ -4.527754, -42.846474]], dtype=float32)
time = 46185	action = 0	current_phase = 1	next_phase = 0	reward = 0.435877	array([[ -4.5674877, -43.008575 ]], dtype=float32)
time = 46190	action = 0	current_phase = 1	next_phase = 0	reward = 0.997610	array([[ -4.567971, -43.014484]], dtype=float32)
time = 46195	action = 0	current_phase = 1	next_phase = 0	reward = 0.715697	array([[ -4.577688, -43.032764]], dtype=float32)
time = 46200	action = 0	current_phase = 1	next_phase = 0	reward = 0.722626	array([[ -4.4966326, -42.708767 ]], dtype=float32)
time = 46205	action = 0	current_phase = 1	next_phase = 0	reward = 0.439597	array([[ -4.48872 , -42.704124]], dtype=float32)
time = 46210	action = 0	current_phase = 1	next_phase = 0	reward = 0.998800	array([[ -4.53557, -42.86979]], dtype=float32)
time = 46215	action = 0	current_phase = 1	next_phase = 0	reward = 0.435591	array([[ -4.5498695, -42.924183 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 5386.6267 - val_loss: 1318.7432
Epoch 2/50
 - 4s - loss: 5366.6800 - val_loss: 1315.6202
Epoch 3/50
 - 4s - loss: 5375.9488 - val_loss: 1322.7869
Epoch 4/50
 - 4s - loss: 5352.3279 - val_loss: 1328.6863
Epoch 5/50
 - 4s - loss: 5358.1761 - val_loss: 1313.1406
Epoch 6/50
 - 4s - loss: 5342.3142 - val_loss: 1295.1943
Epoch 7/50
 - 4s - loss: 5331.4311 - val_loss: 1299.2533
Epoch 8/50
 - 4s - loss: 5345.5842 - val_loss: 1300.7391
Epoch 9/50
 - 4s - loss: 5317.9232 - val_loss: 1293.6396
Epoch 10/50
 - 4s - loss: 5319.2334 - val_loss: 1293.3687
Epoch 11/50
 - 4s - loss: 5315.8079 - val_loss: 1291.7054
Epoch 12/50
 - 4s - loss: 5304.7090 - val_loss: 1291.6556
Epoch 13/50
 - 4s - loss: 5297.9919 - val_loss: 1299.8564
Epoch 14/50
 - 4s - loss: 5291.5925 - val_loss: 1284.5590
Epoch 15/50
 - 4s - loss: 5303.5980 - val_loss: 1292.5546
Epoch 16/50
 - 4s - loss: 5296.6192 - val_loss: 1292.0316
Epoch 17/50
 - 4s - loss: 5285.4738 - val_loss: 1281.8420
Epoch 18/50
 - 4s - loss: 5279.8407 - val_loss: 1278.2621
Epoch 19/50
 - 4s - loss: 5278.2203 - val_loss: 1273.9218
Epoch 20/50
 - 4s - loss: 5265.7411 - val_loss: 1267.7191
Epoch 21/50
 - 4s - loss: 5256.1770 - val_loss: 1276.0654
Epoch 22/50
 - 4s - loss: 5253.0699 - val_loss: 1277.5037
Epoch 23/50
 - 4s - loss: 5253.4641 - val_loss: 1262.8411
Epoch 24/50
 - 4s - loss: 5240.5165 - val_loss: 1260.2893
Epoch 25/50
 - 4s - loss: 5236.1990 - val_loss: 1263.7443
Epoch 26/50
 - 4s - loss: 5236.5873 - val_loss: 1251.8421
Epoch 27/50
 - 4s - loss: 5226.9746 - val_loss: 1254.9912
Epoch 28/50
 - 4s - loss: 5225.5791 - val_loss: 1262.3711
Epoch 29/50
 - 4s - loss: 5232.2748 - val_loss: 1247.7198
Epoch 30/50
 - 4s - loss: 5218.4959 - val_loss: 1254.1629
Epoch 31/50
 - 4s - loss: 5201.1280 - val_loss: 1240.0313
Epoch 32/50
 - 4s - loss: 5202.4006 - val_loss: 1250.2922
Epoch 33/50
 - 4s - loss: 5201.6763 - val_loss: 1237.3064
Epoch 34/50
 - 4s - loss: 5199.2557 - val_loss: 1238.8645
Epoch 35/50
 - 4s - loss: 5187.3626 - val_loss: 1231.7163
Epoch 36/50
 - 4s - loss: 5180.5427 - val_loss: 1244.4447
Epoch 37/50
 - 4s - loss: 5183.4961 - val_loss: 1227.3793
Epoch 38/50
 - 4s - loss: 5166.9872 - val_loss: 1228.5745
Epoch 39/50
 - 4s - loss: 5169.3347 - val_loss: 1235.6076
Epoch 40/50
 - 4s - loss: 5173.4717 - val_loss: 1228.9802
Epoch 41/50
 - 4s - loss: 5159.3930 - val_loss: 1220.3384
Epoch 42/50
 - 4s - loss: 5150.2002 - val_loss: 1225.9481
Epoch 43/50
 - 4s - loss: 5163.4766 - val_loss: 1215.2312
Epoch 44/50
 - 4s - loss: 5143.3512 - val_loss: 1211.7513
Epoch 45/50
 - 4s - loss: 5130.5157 - val_loss: 1207.3849
Epoch 46/50
 - 4s - loss: 5132.9494 - val_loss: 1209.3757
Epoch 47/50
 - 4s - loss: 5129.7049 - val_loss: 1215.9805
Epoch 48/50
 - 4s - loss: 5118.7195 - val_loss: 1214.0152
Epoch 49/50
 - 4s - loss: 5116.3098 - val_loss: 1199.0024
Epoch 50/50
 - 4s - loss: 5109.4733 - val_loss: 1211.6635
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 46220	action = 0	current_phase = 1	next_phase = 0	reward = 1.003083	array([[ -4.5988235, -42.85666  ]], dtype=float32)
time = 46225	action = 0	current_phase = 1	next_phase = 0	reward = 0.721109	array([[ -4.6307487, -42.944733 ]], dtype=float32)
time = 46230	action = 0	current_phase = 1	next_phase = 0	reward = 0.718978	array([[ -4.595375, -42.851128]], dtype=float32)
time = 46235	action = 0	current_phase = 1	next_phase = 0	reward = 0.440802	array([[ -4.5906343, -42.840702 ]], dtype=float32)
time = 46240	action = 0	current_phase = 1	next_phase = 0	reward = 0.999870	array([[ -4.6044397, -42.869377 ]], dtype=float32)
time = 46245	action = 0	current_phase = 1	next_phase = 0	reward = 0.723337	array([[ -4.5508986, -42.723133 ]], dtype=float32)
time = 46250	action = 0	current_phase = 1	next_phase = 0	reward = 0.733032	array([[ -4.53259 , -42.711205]], dtype=float32)
time = 46255	action = 0	current_phase = 1	next_phase = 0	reward = 0.717062	array([[ -4.60989 , -42.890984]], dtype=float32)
time = 46260	action = 0	current_phase = 1	next_phase = 0	reward = 0.722604	array([[ -4.6190634, -42.911148 ]], dtype=float32)
time = 46265	action = 0	current_phase = 1	next_phase = 0	reward = 0.725898	array([[ -4.608857, -42.878937]], dtype=float32)
time = 46270	action = 0	current_phase = 1	next_phase = 0	reward = 0.725821	array([[ -4.6282454, -42.94565  ]], dtype=float32)
time = 46275	action = 0	current_phase = 1	next_phase = 0	reward = 0.718008	array([[ -4.557249, -42.73076 ]], dtype=float32)
time = 46280	action = 0	current_phase = 1	next_phase = 0	reward = 0.703924	array([[ -4.6109705, -42.88592  ]], dtype=float32)
time = 46285	action = 0	current_phase = 1	next_phase = 0	reward = 0.435413	array([[ -4.6274233, -42.932964 ]], dtype=float32)
time = 46290	action = 0	current_phase = 1	next_phase = 0	reward = 0.728134	array([[ -4.585989, -42.82093 ]], dtype=float32)
time = 46295	action = 0	current_phase = 1	next_phase = 0	reward = 1.001854	array([[ -4.6035233, -42.87101  ]], dtype=float32)
time = 46300	action = 0	current_phase = 1	next_phase = 0	reward = 0.718428	array([[ -4.583516, -42.81256 ]], dtype=float32)
time = 46305	action = 0	current_phase = 1	next_phase = 0	reward = 0.440287	array([[ -4.572157, -42.768944]], dtype=float32)
time = 46310	action = 0	current_phase = 1	next_phase = 0	reward = 1.006462	array([[ -4.5567446, -42.725056 ]], dtype=float32)
time = 46315	action = 0	current_phase = 1	next_phase = 0	reward = 0.719705	array([[ -4.6142654, -42.90142  ]], dtype=float32)
time = 46320	action = 0	current_phase = 1	next_phase = 0	reward = 0.717930	array([[ -4.6258945, -42.933235 ]], dtype=float32)
time = 46325	action = 0	current_phase = 1	next_phase = 0	reward = 0.721399	array([[ -4.615184, -42.90712 ]], dtype=float32)
time = 46330	action = 0	current_phase = 1	next_phase = 0	reward = 0.725905	array([[ -4.6152115, -42.904472 ]], dtype=float32)
time = 46335	action = 0	current_phase = 1	next_phase = 0	reward = 0.709942	array([[ -4.598242, -42.857582]], dtype=float32)
time = 46340	action = 0	current_phase = 1	next_phase = 0	reward = 0.720647	array([[ -4.617136, -42.899284]], dtype=float32)
time = 46345	action = 0	current_phase = 1	next_phase = 0	reward = 0.720835	array([[ -4.5906544, -42.83659  ]], dtype=float32)
time = 46350	action = 0	current_phase = 1	next_phase = 0	reward = 0.446028	array([[ -4.5820045, -42.80777  ]], dtype=float32)
time = 46355	action = 0	current_phase = 1	next_phase = 0	reward = 1.003987	array([[ -4.5989075, -42.859516 ]], dtype=float32)
time = 46360	action = 0	current_phase = 1	next_phase = 0	reward = 0.711841	array([[ -4.601598, -42.862415]], dtype=float32)
time = 46365	action = 0	current_phase = 1	next_phase = 0	reward = 0.450005	array([[ -4.580634, -42.797455]], dtype=float32)
time = 46370	action = 0	current_phase = 1	next_phase = 0	reward = 1.003788	array([[ -4.6296635, -42.94076  ]], dtype=float32)
time = 46375	action = 0	current_phase = 1	next_phase = 0	reward = 0.722585	array([[ -4.579232, -42.793625]], dtype=float32)
time = 46380	action = 0	current_phase = 1	next_phase = 0	reward = 0.718805	array([[ -4.592415, -42.85529 ]], dtype=float32)
time = 46385	action = 0	current_phase = 1	next_phase = 0	reward = 0.719969	array([[ -4.6053104, -42.871628 ]], dtype=float32)
time = 46390	action = 0	current_phase = 1	next_phase = 0	reward = 0.442156	array([[ -4.609514, -42.88392 ]], dtype=float32)
time = 46395	action = 0	current_phase = 1	next_phase = 0	reward = 1.002846	array([[ -4.605359, -42.888   ]], dtype=float32)
time = 46400	action = 0	current_phase = 1	next_phase = 0	reward = 0.720374	array([[ -4.596609, -42.850166]], dtype=float32)
time = 46405	action = 0	current_phase = 1	next_phase = 0	reward = 0.717645	array([[ -4.6307755, -42.946106 ]], dtype=float32)
time = 46410	action = 0	current_phase = 1	next_phase = 0	reward = 0.718508	array([[ -4.5993624, -42.854637 ]], dtype=float32)
time = 46415	action = 0	current_phase = 1	next_phase = 0	reward = 0.721351	array([[ -4.607705, -42.896076]], dtype=float32)
time = 46420	action = 0	current_phase = 1	next_phase = 0	reward = 0.727782	array([[ -4.613306, -42.89341 ]], dtype=float32)
time = 46425	action = 0	current_phase = 1	next_phase = 0	reward = 0.721904	array([[ -4.5915947, -42.85056  ]], dtype=float32)
time = 46430	action = 0	current_phase = 1	next_phase = 0	reward = 0.719373	array([[ -4.5821323, -42.799595 ]], dtype=float32)
time = 46435	action = 0	current_phase = 1	next_phase = 0	reward = 0.723299	array([[ -4.565612, -42.75135 ]], dtype=float32)
time = 46440	action = 0	current_phase = 1	next_phase = 0	reward = 0.720683	array([[ -4.593299, -42.829617]], dtype=float32)
time = 46445	action = 0	current_phase = 1	next_phase = 0	reward = 0.718380	array([[ -4.6108  , -42.893753]], dtype=float32)
time = 46450	action = 0	current_phase = 1	next_phase = 0	reward = 0.723311	array([[ -4.6085453, -42.877136 ]], dtype=float32)
time = 46455	action = 0	current_phase = 1	next_phase = 0	reward = 0.719665	array([[ -4.604007, -42.87723 ]], dtype=float32)
time = 46460	action = 0	current_phase = 1	next_phase = 0	reward = 0.715637	array([[ -4.5969324, -42.85087  ]], dtype=float32)
time = 46465	action = 0	current_phase = 1	next_phase = 0	reward = 0.715826	array([[ -4.5505104, -42.71009  ]], dtype=float32)
time = 46470	action = 0	current_phase = 1	next_phase = 0	reward = 0.725174	array([[ -4.587266, -42.827454]], dtype=float32)
time = 46475	action = 0	current_phase = 1	next_phase = 0	reward = 0.727932	array([[ -4.5875473, -42.815857 ]], dtype=float32)
time = 46480	action = 0	current_phase = 1	next_phase = 0	reward = 0.720739	array([[ -4.5448914, -42.6919   ]], dtype=float32)
time = 46485	action = 0	current_phase = 1	next_phase = 0	reward = 0.718467	array([[ -4.6048393, -42.861656 ]], dtype=float32)
time = 46490	action = 0	current_phase = 1	next_phase = 0	reward = 0.718988	array([[ -4.5922403, -42.8323   ]], dtype=float32)
time = 46495	action = 0	current_phase = 1	next_phase = 0	reward = 0.442779	array([[ -4.619007, -42.933792]], dtype=float32)
time = 46500	action = 0	current_phase = 1	next_phase = 0	reward = 0.995135	array([[ -4.586714, -42.80722 ]], dtype=float32)
time = 46505	action = 0	current_phase = 1	next_phase = 0	reward = 0.718171	array([[ -4.630704, -42.934982]], dtype=float32)
time = 46510	action = 0	current_phase = 1	next_phase = 0	reward = 0.711705	array([[ -4.600892, -42.85814 ]], dtype=float32)
time = 46515	action = 0	current_phase = 1	next_phase = 0	reward = 0.442247	array([[ -4.6329136, -42.960735 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 4439.9326 - val_loss: 2088.4309
Epoch 2/50
 - 4s - loss: 4432.2825 - val_loss: 2077.3072
Epoch 3/50
 - 4s - loss: 4450.4453 - val_loss: 2071.1255
Epoch 4/50
 - 4s - loss: 4423.6032 - val_loss: 2064.1235
Epoch 5/50
 - 4s - loss: 4430.8695 - val_loss: 2078.7506
Epoch 6/50
 - 4s - loss: 4432.0644 - val_loss: 2076.4510
Epoch 7/50
 - 4s - loss: 4408.7366 - val_loss: 2083.8789
Epoch 8/50
 - 4s - loss: 4410.7190 - val_loss: 2093.0271
Epoch 9/50
 - 4s - loss: 4403.2576 - val_loss: 2066.8679
Epoch 10/50
 - 4s - loss: 4405.1404 - val_loss: 2054.4913
Epoch 11/50
 - 4s - loss: 4411.8345 - val_loss: 2071.9190
Epoch 12/50
 - 4s - loss: 4392.1785 - val_loss: 2067.3018
Epoch 13/50
 - 4s - loss: 4395.9040 - val_loss: 2057.5317
Epoch 14/50
 - 4s - loss: 4384.5566 - val_loss: 2057.9499
Epoch 15/50
 - 4s - loss: 4400.0385 - val_loss: 2054.8041
Epoch 16/50
 - 4s - loss: 4376.8206 - val_loss: 2051.6117
Epoch 17/50
 - 4s - loss: 4373.6672 - val_loss: 2047.3801
Epoch 18/50
 - 4s - loss: 4380.8515 - val_loss: 2057.4450
Epoch 19/50
 - 4s - loss: 4366.5373 - val_loss: 2040.0851
Epoch 20/50
 - 4s - loss: 4364.3975 - val_loss: 2037.0653
Epoch 21/50
 - 4s - loss: 4380.3793 - val_loss: 2041.3012
Epoch 22/50
 - 4s - loss: 4356.7021 - val_loss: 2042.4266
Epoch 23/50
 - 4s - loss: 4358.4632 - val_loss: 2050.0505
Epoch 24/50
 - 4s - loss: 4357.8468 - val_loss: 2046.9833
Epoch 25/50
 - 4s - loss: 4351.2397 - val_loss: 2040.9103
Epoch 26/50
 - 4s - loss: 4344.8684 - val_loss: 2027.5085
Epoch 27/50
 - 4s - loss: 4355.3763 - val_loss: 2033.5611
Epoch 28/50
 - 4s - loss: 4338.1137 - val_loss: 2036.6901
Epoch 29/50
 - 4s - loss: 4332.7207 - val_loss: 2025.2459
Epoch 30/50
 - 4s - loss: 4324.9273 - val_loss: 2017.3008
Epoch 31/50
 - 4s - loss: 4338.1667 - val_loss: 2019.1617
Epoch 32/50
 - 4s - loss: 4326.6861 - val_loss: 2028.4488
Epoch 33/50
 - 4s - loss: 4322.3273 - val_loss: 2019.8230
Epoch 34/50
 - 4s - loss: 4315.9752 - val_loss: 2001.9682
Epoch 35/50
 - 4s - loss: 4309.1365 - val_loss: 2000.6794
Epoch 36/50
 - 4s - loss: 4313.6886 - val_loss: 2009.7691
Epoch 37/50
 - 4s - loss: 4311.2876 - val_loss: 2002.8431
Epoch 38/50
 - 4s - loss: 4306.0930 - val_loss: 2001.1367
Epoch 39/50
 - 4s - loss: 4311.2205 - val_loss: 1990.5102
Epoch 40/50
 - 4s - loss: 4310.4110 - val_loss: 2009.0493
Epoch 41/50
 - 4s - loss: 4290.8449 - val_loss: 2002.6706
Epoch 42/50
 - 4s - loss: 4293.3642 - val_loss: 1992.1993
Epoch 43/50
 - 4s - loss: 4292.9633 - val_loss: 1992.6340
Epoch 44/50
 - 4s - loss: 4286.1935 - val_loss: 2005.9419
Epoch 45/50
 - 4s - loss: 4282.0156 - val_loss: 2002.8100
Epoch 46/50
 - 4s - loss: 4278.0280 - val_loss: 1992.1482
Epoch 47/50
 - 4s - loss: 4275.4079 - val_loss: 1998.4670
Epoch 48/50
 - 4s - loss: 4276.2414 - val_loss: 1969.7934
Epoch 49/50
 - 4s - loss: 4285.0291 - val_loss: 1968.4152
Epoch 50/50
 - 4s - loss: 4274.3935 - val_loss: 1974.4488
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 46520	action = 0	current_phase = 1	next_phase = 0	reward = 1.007567	array([[ -4.646676, -42.97031 ]], dtype=float32)
time = 46525	action = 0	current_phase = 1	next_phase = 0	reward = 0.728220	array([[ -4.6586056, -43.01116  ]], dtype=float32)
time = 46530	action = 0	current_phase = 1	next_phase = 0	reward = 0.725221	array([[ -4.6473255, -42.967773 ]], dtype=float32)
time = 46535	action = 0	current_phase = 1	next_phase = 0	reward = 0.718179	array([[ -4.6521387, -42.98532  ]], dtype=float32)
time = 46540	action = 0	current_phase = 1	next_phase = 0	reward = 0.723466	array([[ -4.652712, -42.98145 ]], dtype=float32)
time = 46545	action = 0	current_phase = 1	next_phase = 0	reward = 0.720826	array([[ -4.6413145, -42.960087 ]], dtype=float32)
time = 46550	action = 0	current_phase = 1	next_phase = 0	reward = 0.714071	array([[ -4.6390533, -42.95881  ]], dtype=float32)
time = 46555	action = 0	current_phase = 1	next_phase = 0	reward = 0.707810	array([[ -4.6679068, -43.050293 ]], dtype=float32)
time = 46560	action = 0	current_phase = 1	next_phase = 0	reward = 0.722324	array([[ -4.6335764, -42.93707  ]], dtype=float32)
time = 46565	action = 0	current_phase = 1	next_phase = 0	reward = 0.723822	array([[ -4.6543636, -42.989548 ]], dtype=float32)
time = 46570	action = 0	current_phase = 1	next_phase = 0	reward = 0.721263	array([[ -4.6384335, -42.95459  ]], dtype=float32)
time = 46575	action = 0	current_phase = 1	next_phase = 0	reward = 0.726929	array([[ -4.6303368, -42.927933 ]], dtype=float32)
time = 46580	action = 0	current_phase = 1	next_phase = 0	reward = 0.720464	array([[ -4.649127, -42.98429 ]], dtype=float32)
time = 46585	action = 0	current_phase = 1	next_phase = 0	reward = 0.726211	array([[ -4.65625 , -42.993958]], dtype=float32)
time = 46590	action = 0	current_phase = 1	next_phase = 0	reward = 0.722419	array([[ -4.6553392, -42.99392  ]], dtype=float32)
time = 46595	action = 0	current_phase = 1	next_phase = 0	reward = 0.442415	array([[ -4.6367493, -42.93937  ]], dtype=float32)
time = 46600	action = 0	current_phase = 1	next_phase = 0	reward = 1.007483	array([[ -4.6387053, -42.94845  ]], dtype=float32)
time = 46605	action = 0	current_phase = 1	next_phase = 0	reward = 0.723397	array([[ -4.645547, -42.96924 ]], dtype=float32)
time = 46610	action = 0	current_phase = 1	next_phase = 0	reward = 0.722086	array([[ -4.6473026, -42.975502 ]], dtype=float32)
time = 46615	action = 0	current_phase = 1	next_phase = 0	reward = 0.722379	array([[ -4.631049, -42.92961 ]], dtype=float32)
time = 46620	action = 0	current_phase = 1	next_phase = 0	reward = 0.726325	array([[ -4.6668415, -43.030663 ]], dtype=float32)
time = 46625	action = 0	current_phase = 1	next_phase = 0	reward = 0.432720	array([[ -4.6338797, -42.94929  ]], dtype=float32)
time = 46630	action = 0	current_phase = 1	next_phase = 0	reward = 0.997217	array([[ -4.660596, -43.01966 ]], dtype=float32)
time = 46635	action = 0	current_phase = 1	next_phase = 0	reward = 0.437071	array([[ -4.654831, -42.994316]], dtype=float32)
time = 46640	action = 0	current_phase = 1	next_phase = 0	reward = 0.731213	array([[ -4.635803, -42.938057]], dtype=float32)
time = 46645	action = 0	current_phase = 1	next_phase = 0	reward = 0.997748	array([[ -4.654893, -43.003326]], dtype=float32)
time = 46650	action = 0	current_phase = 1	next_phase = 0	reward = 0.719893	array([[ -4.634178, -42.924618]], dtype=float32)
time = 46655	action = 0	current_phase = 1	next_phase = 0	reward = 0.718017	array([[ -4.6551228, -42.99773  ]], dtype=float32)
time = 46660	action = 0	current_phase = 1	next_phase = 0	reward = 0.723850	array([[ -4.6485043, -42.980495 ]], dtype=float32)
time = 46665	action = 0	current_phase = 1	next_phase = 0	reward = 0.718568	array([[ -4.667754, -43.0371  ]], dtype=float32)
time = 46670	action = 0	current_phase = 1	next_phase = 0	reward = 0.441042	array([[ -4.6269484, -42.905807 ]], dtype=float32)
time = 46675	action = 0	current_phase = 1	next_phase = 0	reward = 1.009313	array([[ -4.657029, -43.008995]], dtype=float32)
time = 46680	action = 0	current_phase = 1	next_phase = 0	reward = 0.717930	array([[ -4.6363745, -42.934654 ]], dtype=float32)
time = 46685	action = 0	current_phase = 1	next_phase = 0	reward = 0.445165	array([[ -4.65357 , -42.987328]], dtype=float32)
time = 46690	action = 0	current_phase = 1	next_phase = 0	reward = 0.731015	array([[ -4.6487627, -42.97416  ]], dtype=float32)
time = 46695	action = 0	current_phase = 1	next_phase = 0	reward = 1.008660	array([[ -4.652047, -42.98436 ]], dtype=float32)
time = 46700	action = 0	current_phase = 1	next_phase = 0	reward = 0.725570	array([[ -4.632038, -42.924446]], dtype=float32)
time = 46705	action = 0	current_phase = 1	next_phase = 0	reward = 0.723736	array([[ -4.652693, -42.98391 ]], dtype=float32)
time = 46710	action = 0	current_phase = 1	next_phase = 0	reward = 0.721384	array([[ -4.651514, -42.984215]], dtype=float32)
time = 46715	action = 0	current_phase = 1	next_phase = 0	reward = 0.720424	array([[ -4.6589003, -43.003822 ]], dtype=float32)
time = 46720	action = 0	current_phase = 1	next_phase = 0	reward = 0.719054	array([[ -4.6392403, -42.953415 ]], dtype=float32)
time = 46725	action = 0	current_phase = 1	next_phase = 0	reward = 0.441359	array([[ -4.631628, -42.92475 ]], dtype=float32)
time = 46730	action = 0	current_phase = 1	next_phase = 0	reward = 1.000058	array([[ -4.6558075, -43.001976 ]], dtype=float32)
time = 46735	action = 0	current_phase = 1	next_phase = 0	reward = 0.445149	array([[ -4.6434402, -42.958366 ]], dtype=float32)
time = 46740	action = 0	current_phase = 1	next_phase = 0	reward = 1.003983	array([[ -4.648988, -42.988388]], dtype=float32)
time = 46745	action = 0	current_phase = 1	next_phase = 0	reward = 0.722689	array([[ -4.6374254, -42.94554  ]], dtype=float32)
time = 46750	action = 0	current_phase = 1	next_phase = 0	reward = 0.720422	array([[ -4.6593523, -43.006012 ]], dtype=float32)
time = 46755	action = 0	current_phase = 1	next_phase = 0	reward = 0.716363	array([[ -4.629921, -42.90629 ]], dtype=float32)
time = 46760	action = 0	current_phase = 1	next_phase = 0	reward = 0.719384	array([[ -4.6608114, -43.014904 ]], dtype=float32)
time = 46765	action = 0	current_phase = 1	next_phase = 0	reward = 0.442030	array([[ -4.5808945, -42.742172 ]], dtype=float32)
time = 46770	action = 0	current_phase = 1	next_phase = 0	reward = 1.005885	array([[ -4.6640882, -43.025734 ]], dtype=float32)
time = 46775	action = 0	current_phase = 1	next_phase = 0	reward = 0.726700	array([[ -4.653825, -42.99174 ]], dtype=float32)
time = 46780	action = 0	current_phase = 1	next_phase = 0	reward = 0.723117	array([[ -4.6350965, -42.934834 ]], dtype=float32)
time = 46785	action = 0	current_phase = 1	next_phase = 0	reward = 0.455208	array([[ -4.6359262, -42.96849  ]], dtype=float32)
time = 46790	action = 0	current_phase = 1	next_phase = 0	reward = 1.005486	array([[ -4.6540594, -42.990913 ]], dtype=float32)
time = 46795	action = 0	current_phase = 1	next_phase = 0	reward = 0.716375	array([[ -4.652606, -42.99066 ]], dtype=float32)
time = 46800	action = 0	current_phase = 1	next_phase = 0	reward = 0.713000	array([[ -4.5797663, -42.748013 ]], dtype=float32)
time = 46805	action = 0	current_phase = 1	next_phase = 0	reward = 0.723151	array([[ -4.6440325, -42.972733 ]], dtype=float32)
time = 46810	action = 0	current_phase = 1	next_phase = 0	reward = 0.450471	array([[ -4.6255417, -42.91587  ]], dtype=float32)
time = 46815	action = 0	current_phase = 1	next_phase = 0	reward = 1.002899	array([[ -4.6361256, -42.94007  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 5410.7901 - val_loss: 621.3487
Epoch 2/50
 - 4s - loss: 5408.8214 - val_loss: 611.5257
Epoch 3/50
 - 4s - loss: 5393.1297 - val_loss: 622.8049
Epoch 4/50
 - 4s - loss: 5385.1810 - val_loss: 616.9729
Epoch 5/50
 - 4s - loss: 5380.2330 - val_loss: 611.6461
Epoch 6/50
 - 4s - loss: 5370.1028 - val_loss: 604.4878
Epoch 7/50
 - 4s - loss: 5373.0990 - val_loss: 610.7371
Epoch 8/50
 - 4s - loss: 5371.4260 - val_loss: 604.4830
Epoch 9/50
 - 4s - loss: 5361.8495 - val_loss: 605.8229
Epoch 10/50
 - 4s - loss: 5352.3149 - val_loss: 619.3418
Epoch 11/50
 - 4s - loss: 5356.6625 - val_loss: 606.1085
Epoch 12/50
 - 4s - loss: 5346.8007 - val_loss: 606.1186
Epoch 13/50
 - 4s - loss: 5333.5084 - val_loss: 618.9220
Epoch 14/50
 - 4s - loss: 5336.6577 - val_loss: 604.1654
Epoch 15/50
 - 4s - loss: 5326.5105 - val_loss: 602.7022
Epoch 16/50
 - 4s - loss: 5328.0592 - val_loss: 606.4121
Epoch 17/50
 - 4s - loss: 5316.1848 - val_loss: 600.9800
Epoch 18/50
 - 4s - loss: 5307.4746 - val_loss: 601.0638
Epoch 19/50
 - 4s - loss: 5307.4776 - val_loss: 598.3425
Epoch 20/50
 - 4s - loss: 5299.3015 - val_loss: 598.0934
Epoch 21/50
 - 4s - loss: 5292.2781 - val_loss: 596.0461
Epoch 22/50
 - 4s - loss: 5291.0665 - val_loss: 592.6399
Epoch 23/50
 - 4s - loss: 5282.2434 - val_loss: 596.0978
Epoch 24/50
 - 4s - loss: 5282.5281 - val_loss: 588.2803
Epoch 25/50
 - 4s - loss: 5272.5310 - val_loss: 594.6703
Epoch 26/50
 - 4s - loss: 5259.1695 - val_loss: 589.5394
Epoch 27/50
 - 4s - loss: 5267.8531 - val_loss: 593.1512
Epoch 28/50
 - 4s - loss: 5259.6538 - val_loss: 594.1998
Epoch 29/50
 - 4s - loss: 5250.4204 - val_loss: 594.2314
Epoch 30/50
 - 4s - loss: 5250.1850 - val_loss: 587.2335
Epoch 31/50
 - 4s - loss: 5239.2772 - val_loss: 589.7992
Epoch 32/50
 - 4s - loss: 5231.9816 - val_loss: 588.6632
Epoch 33/50
 - 4s - loss: 5231.9354 - val_loss: 593.8774
Epoch 34/50
 - 4s - loss: 5231.1380 - val_loss: 591.9318
Epoch 35/50
 - 4s - loss: 5225.1650 - val_loss: 581.5639
Epoch 36/50
 - 4s - loss: 5220.4165 - val_loss: 591.7430
Epoch 37/50
 - 4s - loss: 5209.8485 - val_loss: 589.9626
Epoch 38/50
 - 4s - loss: 5215.6954 - val_loss: 581.4626
Epoch 39/50
 - 4s - loss: 5201.4867 - val_loss: 599.3907
Epoch 40/50
 - 4s - loss: 5205.6186 - val_loss: 583.1925
Epoch 41/50
 - 4s - loss: 5188.9420 - val_loss: 595.3878
Epoch 42/50
 - 4s - loss: 5192.4453 - val_loss: 578.9920
Epoch 43/50
 - 4s - loss: 5185.2561 - val_loss: 586.9231
Epoch 44/50
 - 4s - loss: 5187.4113 - val_loss: 578.4253
Epoch 45/50
 - 4s - loss: 5170.3042 - val_loss: 586.5166
Epoch 46/50
 - 4s - loss: 5167.1987 - val_loss: 585.2645
Epoch 47/50
 - 4s - loss: 5161.9940 - val_loss: 581.0912
Epoch 48/50
 - 4s - loss: 5152.4105 - val_loss: 581.7257
Epoch 49/50
 - 4s - loss: 5149.0267 - val_loss: 580.2341
Epoch 50/50
 - 4s - loss: 5149.7474 - val_loss: 581.1982
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 46820	action = 0	current_phase = 1	next_phase = 0	reward = 0.722760	array([[ -3.2152328, -42.681656 ]], dtype=float32)
time = 46825	action = 0	current_phase = 1	next_phase = 0	reward = 0.723666	array([[ -3.2776127, -42.943615 ]], dtype=float32)
time = 46830	action = 0	current_phase = 1	next_phase = 0	reward = 0.723409	array([[ -3.253312, -42.8351  ]], dtype=float32)
time = 46835	action = 0	current_phase = 1	next_phase = 0	reward = 0.725117	array([[ -3.2623644, -42.887955 ]], dtype=float32)
time = 46840	action = 0	current_phase = 1	next_phase = 0	reward = 0.445717	array([[ -3.252633, -42.84308 ]], dtype=float32)
time = 46845	action = 0	current_phase = 1	next_phase = 0	reward = 1.004326	array([[ -3.2738762, -42.925545 ]], dtype=float32)
time = 46850	action = 0	current_phase = 1	next_phase = 0	reward = 0.713156	array([[ -3.2650547, -42.87928  ]], dtype=float32)
time = 46855	action = 0	current_phase = 1	next_phase = 0	reward = 0.440024	array([[ -3.2625055, -42.891457 ]], dtype=float32)
time = 46860	action = 0	current_phase = 1	next_phase = 0	reward = 0.726459	array([[ -3.2619343, -42.88982  ]], dtype=float32)
time = 46865	action = 0	current_phase = 1	next_phase = 0	reward = 1.003103	array([[ -3.247817, -42.825012]], dtype=float32)
time = 46870	action = 0	current_phase = 1	next_phase = 0	reward = 0.719101	array([[ -3.2622337, -42.87867  ]], dtype=float32)
time = 46875	action = 0	current_phase = 1	next_phase = 0	reward = 0.442877	array([[ -3.2739315, -42.921852 ]], dtype=float32)
time = 46880	action = 0	current_phase = 1	next_phase = 0	reward = 0.997068	array([[ -3.2601395, -42.871975 ]], dtype=float32)
time = 46885	action = 0	current_phase = 1	next_phase = 0	reward = 0.712094	array([[ -3.2405138, -42.755726 ]], dtype=float32)
time = 46890	action = 0	current_phase = 1	next_phase = 0	reward = 0.161290	array([[ -3.2425194, -42.801453 ]], dtype=float32)
time = 46895	action = 0	current_phase = 1	next_phase = 0	reward = 1.291304	array([[ -3.2628317, -42.882713 ]], dtype=float32)
time = 46900	action = 0	current_phase = 1	next_phase = 0	reward = 0.723672	array([[ -3.2522058, -42.842224 ]], dtype=float32)
time = 46905	action = 0	current_phase = 1	next_phase = 0	reward = 0.443126	array([[ -3.277275, -42.943367]], dtype=float32)
time = 46910	action = 0	current_phase = 1	next_phase = 0	reward = 1.006170	array([[ -3.2803764, -42.95041  ]], dtype=float32)
time = 46915	action = 0	current_phase = 1	next_phase = 0	reward = 0.723575	array([[ -3.2583027, -42.869354 ]], dtype=float32)
time = 46920	action = 0	current_phase = 1	next_phase = 0	reward = 0.722814	array([[ -3.2694607, -42.91193  ]], dtype=float32)
time = 46925	action = 0	current_phase = 1	next_phase = 0	reward = 0.716381	array([[ -3.2821875, -42.958504 ]], dtype=float32)
time = 46930	action = 0	current_phase = 1	next_phase = 0	reward = 0.719807	array([[ -3.228756, -42.768005]], dtype=float32)
time = 46935	action = 0	current_phase = 1	next_phase = 0	reward = 0.439678	array([[ -3.2522087, -42.83828  ]], dtype=float32)
time = 46940	action = 0	current_phase = 1	next_phase = 0	reward = 0.992661	array([[ -3.2756643, -42.929054 ]], dtype=float32)
time = 46945	action = 0	current_phase = 1	next_phase = 0	reward = 0.712439	array([[ -3.2538805, -42.848587 ]], dtype=float32)
time = 46950	action = 0	current_phase = 1	next_phase = 0	reward = 0.160321	array([[ -3.2537699, -42.851234 ]], dtype=float32)
time = 46955	action = 0	current_phase = 1	next_phase = 0	reward = 1.290523	array([[ -3.274314, -42.928413]], dtype=float32)
time = 46960	action = 0	current_phase = 1	next_phase = 0	reward = 0.714057	array([[ -3.2560759, -42.855087 ]], dtype=float32)
time = 46965	action = 0	current_phase = 1	next_phase = 0	reward = 0.444748	array([[ -3.2318506, -42.74738  ]], dtype=float32)
time = 46970	action = 0	current_phase = 1	next_phase = 0	reward = 0.999098	array([[ -3.2759361, -42.928307 ]], dtype=float32)
time = 46975	action = 0	current_phase = 1	next_phase = 0	reward = 0.436473	array([[ -3.271222, -42.91423 ]], dtype=float32)
time = 46980	action = 0	current_phase = 1	next_phase = 0	reward = 0.726128	array([[ -3.2516088, -42.837082 ]], dtype=float32)
time = 46985	action = 0	current_phase = 1	next_phase = 0	reward = 1.008555	array([[ -3.2805471, -42.958282 ]], dtype=float32)
time = 46990	action = 0	current_phase = 1	next_phase = 0	reward = 0.714016	array([[ -3.2123108, -42.672203 ]], dtype=float32)
time = 46995	action = 0	current_phase = 1	next_phase = 0	reward = 0.717938	array([[ -3.2839556, -42.973602 ]], dtype=float32)
time = 47000	action = 0	current_phase = 1	next_phase = 0	reward = 0.719129	array([[ -3.228714, -42.73645 ]], dtype=float32)
time = 47005	action = 0	current_phase = 1	next_phase = 0	reward = 0.721585	array([[ -3.256402, -42.856297]], dtype=float32)
time = 47010	action = 0	current_phase = 1	next_phase = 0	reward = 0.715935	array([[ -3.2605486, -42.876755 ]], dtype=float32)
time = 47015	action = 0	current_phase = 1	next_phase = 0	reward = 0.719014	array([[ -3.2756367, -42.935165 ]], dtype=float32)
time = 47020	action = 0	current_phase = 1	next_phase = 0	reward = 0.720608	array([[ -3.2624207, -42.882126 ]], dtype=float32)
time = 47025	action = 0	current_phase = 1	next_phase = 0	reward = 0.722850	array([[ -3.2525377, -42.85484  ]], dtype=float32)
time = 47030	action = 0	current_phase = 1	next_phase = 0	reward = 0.727039	array([[ -3.2506018, -42.846695 ]], dtype=float32)
time = 47035	action = 0	current_phase = 1	next_phase = 0	reward = 0.446816	array([[ -3.2682133, -42.9116   ]], dtype=float32)
time = 47040	action = 0	current_phase = 1	next_phase = 0	reward = 0.999576	array([[ -3.2447596, -42.81362  ]], dtype=float32)
time = 47045	action = 0	current_phase = 1	next_phase = 0	reward = 0.720587	array([[ -3.2504025, -42.846115 ]], dtype=float32)
time = 47050	action = 0	current_phase = 1	next_phase = 0	reward = 0.719335	array([[ -3.244422, -42.81163 ]], dtype=float32)
time = 47055	action = 0	current_phase = 1	next_phase = 0	reward = 0.722258	array([[ -3.2693558, -42.889122 ]], dtype=float32)
time = 47060	action = 0	current_phase = 1	next_phase = 0	reward = 0.717631	array([[ -3.2582598, -42.87278  ]], dtype=float32)
time = 47065	action = 0	current_phase = 1	next_phase = 0	reward = 0.710636	array([[ -3.2875595, -42.983826 ]], dtype=float32)
time = 47070	action = 0	current_phase = 1	next_phase = 0	reward = 0.722608	array([[ -3.2563734, -42.859673 ]], dtype=float32)
time = 47075	action = 0	current_phase = 1	next_phase = 0	reward = 0.440654	array([[ -3.2879906, -42.960236 ]], dtype=float32)
time = 47080	action = 0	current_phase = 1	next_phase = 0	reward = 0.723879	array([[ -3.2712898, -42.90892  ]], dtype=float32)
time = 47085	action = 0	current_phase = 1	next_phase = 0	reward = 1.004476	array([[ -3.2654686, -42.89466  ]], dtype=float32)
time = 47090	action = 0	current_phase = 1	next_phase = 0	reward = 0.712085	array([[ -3.2436352, -42.826977 ]], dtype=float32)
time = 47095	action = 0	current_phase = 1	next_phase = 0	reward = 0.161981	array([[ -3.2604084, -42.883575 ]], dtype=float32)
time = 47100	action = 0	current_phase = 1	next_phase = 0	reward = 1.285810	array([[ -3.2783527, -42.941025 ]], dtype=float32)
time = 47105	action = 0	current_phase = 1	next_phase = 0	reward = 0.722721	array([[ -3.2681828, -42.90028  ]], dtype=float32)
time = 47110	action = 0	current_phase = 1	next_phase = 0	reward = 0.721528	array([[ -3.263463, -42.88502 ]], dtype=float32)
time = 47115	action = 0	current_phase = 1	next_phase = 0	reward = 0.709865	array([[ -3.26342 , -42.883286]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2412.2306 - val_loss: 6962.9568
Epoch 2/50
 - 4s - loss: 2401.3123 - val_loss: 6957.4119
Epoch 3/50
 - 4s - loss: 2400.7113 - val_loss: 6961.5078
Epoch 4/50
 - 4s - loss: 2393.8120 - val_loss: 6962.2178
Epoch 5/50
 - 4s - loss: 2391.6117 - val_loss: 6970.3972
Epoch 6/50
 - 4s - loss: 2383.4881 - val_loss: 6972.4930
Epoch 7/50
 - 4s - loss: 2390.9390 - val_loss: 6951.7813
Epoch 8/50
 - 4s - loss: 2384.5000 - val_loss: 6945.8107
Epoch 9/50
 - 4s - loss: 2375.6873 - val_loss: 6945.0747
Epoch 10/50
 - 4s - loss: 2371.7834 - val_loss: 6945.5845
Epoch 11/50
 - 4s - loss: 2373.6740 - val_loss: 6948.5210
Epoch 12/50
 - 4s - loss: 2368.9633 - val_loss: 6954.0349
Epoch 13/50
 - 4s - loss: 2367.1099 - val_loss: 6939.9093
Epoch 14/50
 - 4s - loss: 2374.1020 - val_loss: 6940.8938
Epoch 15/50
 - 4s - loss: 2357.4522 - val_loss: 6926.1010
Epoch 16/50
 - 4s - loss: 2358.5114 - val_loss: 6922.1985
Epoch 17/50
 - 4s - loss: 2359.6812 - val_loss: 6937.4580
Epoch 18/50
 - 4s - loss: 2363.6653 - val_loss: 6927.3800
Epoch 19/50
 - 4s - loss: 2357.3327 - val_loss: 6916.1889
Epoch 20/50
 - 4s - loss: 2346.4452 - val_loss: 6917.0507
Epoch 21/50
 - 4s - loss: 2343.9281 - val_loss: 6912.5167
Epoch 22/50
 - 4s - loss: 2338.5197 - val_loss: 6934.4388
Epoch 23/50
 - 4s - loss: 2334.9460 - val_loss: 6908.5026
Epoch 24/50
 - 4s - loss: 2333.1357 - val_loss: 6922.7413
Epoch 25/50
 - 4s - loss: 2328.4309 - val_loss: 6907.8619
Epoch 26/50
 - 4s - loss: 2325.8442 - val_loss: 6898.1805
Epoch 27/50
 - 4s - loss: 2321.9189 - val_loss: 6905.5272
Epoch 28/50
 - 4s - loss: 2316.5485 - val_loss: 6893.3291
Epoch 29/50
 - 4s - loss: 2307.2000 - val_loss: 6909.3188
Epoch 30/50
 - 4s - loss: 2313.6300 - val_loss: 6880.5756
Epoch 31/50
 - 3s - loss: 2303.9308 - val_loss: 6881.9952
Epoch 32/50
 - 4s - loss: 2304.7150 - val_loss: 6870.0620
Epoch 33/50
 - 4s - loss: 2309.1152 - val_loss: 6873.8393
Epoch 34/50
 - 4s - loss: 2296.7079 - val_loss: 6869.4250
Epoch 35/50
 - 4s - loss: 2290.1027 - val_loss: 6871.8263
Epoch 36/50
 - 4s - loss: 2290.8747 - val_loss: 6859.9230
Epoch 37/50
 - 4s - loss: 2288.5465 - val_loss: 6866.8172
Epoch 38/50
 - 4s - loss: 2286.3759 - val_loss: 6860.6560
Epoch 39/50
 - 4s - loss: 2280.0720 - val_loss: 6857.0929
Epoch 40/50
 - 4s - loss: 2277.5145 - val_loss: 6858.5642
Epoch 41/50
 - 4s - loss: 2276.8215 - val_loss: 6849.3783
Epoch 42/50
 - 4s - loss: 2278.1266 - val_loss: 6853.2384
Epoch 43/50
 - 4s - loss: 2267.2745 - val_loss: 6885.9916
Epoch 44/50
 - 4s - loss: 2275.5424 - val_loss: 6842.0534
Epoch 45/50
 - 4s - loss: 2265.3978 - val_loss: 6840.8652
Epoch 46/50
 - 4s - loss: 2258.3456 - val_loss: 6849.3695
Epoch 47/50
 - 4s - loss: 2262.5477 - val_loss: 6842.4753
Epoch 48/50
 - 4s - loss: 2254.6836 - val_loss: 6841.7725
Epoch 49/50
 - 4s - loss: 2262.3337 - val_loss: 6834.4585
Epoch 50/50
 - 4s - loss: 2247.7418 - val_loss: 6832.1356
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 47120	action = 0	current_phase = 1	next_phase = 0	reward = 0.726604	array([[ -3.068799, -42.85302 ]], dtype=float32)
time = 47125	action = 0	current_phase = 1	next_phase = 0	reward = 0.727195	array([[ -3.0652723, -42.84913  ]], dtype=float32)
time = 47130	action = 0	current_phase = 1	next_phase = 0	reward = 0.729648	array([[ -3.065442, -42.840385]], dtype=float32)
time = 47135	action = 0	current_phase = 1	next_phase = 0	reward = 0.732110	array([[ -3.0750017, -42.874187 ]], dtype=float32)
time = 47140	action = 0	current_phase = 1	next_phase = 0	reward = 0.708400	array([[ -3.0748825, -42.876114 ]], dtype=float32)
time = 47145	action = 0	current_phase = 1	next_phase = 0	reward = 0.439089	array([[ -3.033557, -42.745934]], dtype=float32)
time = 47150	action = 0	current_phase = 1	next_phase = 0	reward = 0.997539	array([[ -3.0733566, -42.868828 ]], dtype=float32)
time = 47155	action = 0	current_phase = 1	next_phase = 0	reward = 0.715757	array([[ -3.043106, -42.776413]], dtype=float32)
time = 47160	action = 0	current_phase = 1	next_phase = 0	reward = 0.434501	array([[ -3.0670748, -42.850273 ]], dtype=float32)
time = 47165	action = 0	current_phase = 1	next_phase = 0	reward = 0.999379	array([[ -3.064166, -42.841393]], dtype=float32)
time = 47170	action = 0	current_phase = 1	next_phase = 0	reward = 0.724255	array([[ -3.073018, -42.87105 ]], dtype=float32)
time = 47175	action = 0	current_phase = 1	next_phase = 0	reward = 0.717439	array([[ -3.0622168, -42.838997 ]], dtype=float32)
time = 47180	action = 0	current_phase = 1	next_phase = 0	reward = 0.727135	array([[ -3.0677366, -42.852592 ]], dtype=float32)
time = 47185	action = 0	current_phase = 1	next_phase = 0	reward = 0.723185	array([[ -3.0669012, -42.851105 ]], dtype=float32)
time = 47190	action = 0	current_phase = 1	next_phase = 0	reward = 0.726833	array([[ -3.0507717, -42.80443  ]], dtype=float32)
time = 47195	action = 0	current_phase = 1	next_phase = 0	reward = 0.726546	array([[ -3.0850153, -42.90454  ]], dtype=float32)
time = 47200	action = 0	current_phase = 1	next_phase = 0	reward = 0.722495	array([[ -3.0508966, -42.804268 ]], dtype=float32)
time = 47205	action = 0	current_phase = 1	next_phase = 0	reward = 0.720754	array([[ -3.047779, -42.805084]], dtype=float32)
time = 47210	action = 0	current_phase = 1	next_phase = 0	reward = 0.718845	array([[ -3.0291958, -42.73346  ]], dtype=float32)
time = 47215	action = 0	current_phase = 1	next_phase = 0	reward = 0.722142	array([[ -3.0864162, -42.9083   ]], dtype=float32)
time = 47220	action = 0	current_phase = 1	next_phase = 0	reward = 0.433638	array([[ -3.0284443, -42.72966  ]], dtype=float32)
time = 47225	action = 0	current_phase = 1	next_phase = 0	reward = 1.000183	array([[ -3.0472097, -42.788315 ]], dtype=float32)
time = 47230	action = 0	current_phase = 1	next_phase = 0	reward = 0.443373	array([[ -3.0776072, -42.881714 ]], dtype=float32)
time = 47235	action = 0	current_phase = 1	next_phase = 0	reward = 1.004157	array([[ -3.0732698, -42.866432 ]], dtype=float32)
time = 47240	action = 0	current_phase = 1	next_phase = 0	reward = 0.721106	array([[ -3.0603704, -42.83085  ]], dtype=float32)
time = 47245	action = 0	current_phase = 1	next_phase = 0	reward = 0.721779	array([[ -3.0449982, -42.783936 ]], dtype=float32)
time = 47250	action = 0	current_phase = 1	next_phase = 0	reward = 0.725038	array([[ -3.04704, -42.78756]], dtype=float32)
time = 47255	action = 0	current_phase = 1	next_phase = 0	reward = 0.729536	array([[ -3.08008 , -42.890846]], dtype=float32)
time = 47260	action = 0	current_phase = 1	next_phase = 0	reward = 0.718111	array([[ -3.075304, -42.87625 ]], dtype=float32)
time = 47265	action = 0	current_phase = 1	next_phase = 0	reward = 0.718723	array([[ -3.0524635, -42.808006 ]], dtype=float32)
time = 47270	action = 0	current_phase = 1	next_phase = 0	reward = 0.718126	array([[ -3.05476 , -42.812576]], dtype=float32)
time = 47275	action = 0	current_phase = 1	next_phase = 0	reward = 0.716308	array([[ -3.0503864, -42.799545 ]], dtype=float32)
time = 47280	action = 0	current_phase = 1	next_phase = 0	reward = 0.448940	array([[ -3.0550394, -42.818077 ]], dtype=float32)
time = 47285	action = 0	current_phase = 1	next_phase = 0	reward = 1.004236	array([[ -3.0530539, -42.807316 ]], dtype=float32)
time = 47290	action = 0	current_phase = 1	next_phase = 0	reward = 0.446153	array([[ -3.0447502, -42.785553 ]], dtype=float32)
time = 47295	action = 0	current_phase = 1	next_phase = 0	reward = 1.010053	array([[ -3.0685387, -42.858093 ]], dtype=float32)
time = 47300	action = 0	current_phase = 1	next_phase = 0	reward = 0.720750	array([[ -3.0491934, -42.79583  ]], dtype=float32)
time = 47305	action = 0	current_phase = 1	next_phase = 0	reward = 0.708006	array([[ -3.0538425, -42.81002  ]], dtype=float32)
time = 47310	action = 0	current_phase = 1	next_phase = 0	reward = 0.438816	array([[ -3.0649366, -42.851807 ]], dtype=float32)
time = 47315	action = 0	current_phase = 1	next_phase = 0	reward = 1.008335	array([[ -3.0294104, -42.73259  ]], dtype=float32)
time = 47320	action = 0	current_phase = 1	next_phase = 0	reward = 0.717171	array([[ -3.0543938, -42.811813 ]], dtype=float32)
time = 47325	action = 0	current_phase = 1	next_phase = 0	reward = 0.727254	array([[ -3.0610933, -42.83418  ]], dtype=float32)
time = 47330	action = 0	current_phase = 1	next_phase = 0	reward = 0.723845	array([[ -3.0756702, -42.877396 ]], dtype=float32)
time = 47335	action = 0	current_phase = 1	next_phase = 0	reward = 0.716094	array([[ -3.0359068, -42.756687 ]], dtype=float32)
time = 47340	action = 0	current_phase = 1	next_phase = 0	reward = 0.721822	array([[ -3.0619993, -42.83689  ]], dtype=float32)
time = 47345	action = 0	current_phase = 1	next_phase = 0	reward = 0.451199	array([[ -3.0830612, -42.90016  ]], dtype=float32)
time = 47350	action = 0	current_phase = 1	next_phase = 0	reward = 1.002983	array([[ -3.0492134, -42.79552  ]], dtype=float32)
time = 47355	action = 0	current_phase = 1	next_phase = 0	reward = 0.721568	array([[ -3.0596132, -42.827026 ]], dtype=float32)
time = 47360	action = 0	current_phase = 1	next_phase = 0	reward = 0.721554	array([[ -3.054387, -42.81194 ]], dtype=float32)
time = 47365	action = 0	current_phase = 1	next_phase = 0	reward = 0.723784	array([[ -3.0737524, -42.87278  ]], dtype=float32)
time = 47370	action = 0	current_phase = 1	next_phase = 0	reward = 0.731618	array([[ -3.0554485, -42.816536 ]], dtype=float32)
time = 47375	action = 0	current_phase = 1	next_phase = 0	reward = 0.718672	array([[ -3.0598946, -42.83031  ]], dtype=float32)
time = 47380	action = 0	current_phase = 1	next_phase = 0	reward = 0.725228	array([[ -3.0665236, -42.849274 ]], dtype=float32)
time = 47385	action = 0	current_phase = 1	next_phase = 0	reward = 0.719285	array([[ -3.063508, -42.840813]], dtype=float32)
time = 47390	action = 0	current_phase = 1	next_phase = 0	reward = 0.718695	array([[ -3.0444336, -42.777718 ]], dtype=float32)
time = 47395	action = 0	current_phase = 1	next_phase = 0	reward = 0.721807	array([[ -3.0610142, -42.83431  ]], dtype=float32)
time = 47400	action = 0	current_phase = 1	next_phase = 0	reward = 0.716508	array([[ -3.0673313, -42.854233 ]], dtype=float32)
time = 47405	action = 0	current_phase = 1	next_phase = 0	reward = 0.721417	array([[ -3.0585842, -42.826096 ]], dtype=float32)
time = 47410	action = 0	current_phase = 1	next_phase = 0	reward = 0.721045	array([[ -3.0884628, -42.90108  ]], dtype=float32)
time = 47415	action = 0	current_phase = 1	next_phase = 0	reward = 0.716781	array([[ -3.02876 , -42.729187]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3036.5161 - val_loss: 6703.4070
Epoch 2/50
 - 4s - loss: 3020.8373 - val_loss: 6710.2171
Epoch 3/50
 - 4s - loss: 3018.6486 - val_loss: 6709.2690
Epoch 4/50
 - 4s - loss: 3023.0913 - val_loss: 6702.2361
Epoch 5/50
 - 4s - loss: 3008.5259 - val_loss: 6714.5024
Epoch 6/50
 - 4s - loss: 3006.8873 - val_loss: 6687.1335
Epoch 7/50
 - 4s - loss: 3005.9149 - val_loss: 6680.9045
Epoch 8/50
 - 4s - loss: 3007.6426 - val_loss: 6695.5085
Epoch 9/50
 - 4s - loss: 2991.7742 - val_loss: 6676.4767
Epoch 10/50
 - 4s - loss: 2990.3197 - val_loss: 6673.6729
Epoch 11/50
 - 4s - loss: 2969.1371 - val_loss: 6665.7839
Epoch 12/50
 - 4s - loss: 2972.4763 - val_loss: 6660.4332
Epoch 13/50
 - 4s - loss: 2958.8106 - val_loss: 6661.9078
Epoch 14/50
 - 4s - loss: 2951.4821 - val_loss: 6653.5644
Epoch 15/50
 - 4s - loss: 2951.4410 - val_loss: 6649.8244
Epoch 16/50
 - 4s - loss: 2946.8892 - val_loss: 6649.6846
Epoch 17/50
 - 4s - loss: 2946.0158 - val_loss: 6659.2694
Epoch 18/50
 - 4s - loss: 2942.5558 - val_loss: 6656.7217
Epoch 19/50
 - 4s - loss: 2948.6307 - val_loss: 6641.2646
Epoch 20/50
 - 4s - loss: 2918.0500 - val_loss: 6637.9125
Epoch 21/50
 - 4s - loss: 2917.6458 - val_loss: 6633.4830
Epoch 22/50
 - 4s - loss: 2916.1443 - val_loss: 6634.0868
Epoch 23/50
 - 4s - loss: 2904.5291 - val_loss: 6626.6963
Epoch 24/50
 - 4s - loss: 2912.9626 - val_loss: 6633.3842
Epoch 25/50
 - 4s - loss: 2900.2516 - val_loss: 6623.3605
Epoch 26/50
 - 4s - loss: 2894.8076 - val_loss: 6626.1345
Epoch 27/50
 - 4s - loss: 2914.2295 - val_loss: 6620.7370
Epoch 28/50
 - 4s - loss: 2874.1013 - val_loss: 6625.5294
Epoch 29/50
 - 4s - loss: 2872.1847 - val_loss: 6624.7344
Epoch 30/50
 - 4s - loss: 2867.2327 - val_loss: 6617.5207
Epoch 31/50
 - 4s - loss: 2874.0711 - val_loss: 6604.7552
Epoch 32/50
 - 4s - loss: 2864.8767 - val_loss: 6600.4775
Epoch 33/50
 - 4s - loss: 2857.7903 - val_loss: 6603.6563
Epoch 34/50
 - 4s - loss: 2853.4563 - val_loss: 6614.5336
Epoch 35/50
 - 4s - loss: 2844.1042 - val_loss: 6594.8623
Epoch 36/50
 - 4s - loss: 2843.3486 - val_loss: 6579.3888
Epoch 37/50
 - 4s - loss: 2834.1021 - val_loss: 6599.5885
Epoch 38/50
 - 4s - loss: 2833.4577 - val_loss: 6577.3148
Epoch 39/50
 - 4s - loss: 2825.5762 - val_loss: 6593.5971
Epoch 40/50
 - 4s - loss: 2822.6565 - val_loss: 6572.1769
Epoch 41/50
 - 4s - loss: 2813.8745 - val_loss: 6589.6080
Epoch 42/50
 - 4s - loss: 2819.8218 - val_loss: 6563.1651
Epoch 43/50
 - 4s - loss: 2817.7030 - val_loss: 6598.2674
Epoch 44/50
 - 4s - loss: 2815.1856 - val_loss: 6553.3989
Epoch 45/50
 - 4s - loss: 2794.4621 - val_loss: 6559.5388
Epoch 46/50
 - 4s - loss: 2801.6346 - val_loss: 6559.0929
Epoch 47/50
 - 4s - loss: 2790.3236 - val_loss: 6551.7904
Epoch 48/50
 - 4s - loss: 2776.6191 - val_loss: 6549.7146
Epoch 49/50
 - 4s - loss: 2782.1222 - val_loss: 6548.6333
Epoch 50/50
 - 4s - loss: 2770.2771 - val_loss: 6538.0574
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 47420	action = 0	current_phase = 1	next_phase = 0	reward = 0.719926	array([[ -3.0739355, -42.834995 ]], dtype=float32)
time = 47425	action = 0	current_phase = 1	next_phase = 0	reward = 0.724678	array([[ -3.032076, -42.763393]], dtype=float32)
time = 47430	action = 0	current_phase = 1	next_phase = 0	reward = 0.723077	array([[ -3.0645828, -42.8182   ]], dtype=float32)
time = 47435	action = 0	current_phase = 1	next_phase = 0	reward = 0.709730	array([[ -3.050477, -42.789272]], dtype=float32)
time = 47440	action = 0	current_phase = 1	next_phase = 0	reward = 0.714527	array([[ -3.0601387, -42.811493 ]], dtype=float32)
time = 47445	action = 0	current_phase = 1	next_phase = 0	reward = 0.718097	array([[ -3.0407581, -42.774628 ]], dtype=float32)
time = 47450	action = 0	current_phase = 1	next_phase = 0	reward = 0.732963	array([[ -3.048771, -42.790916]], dtype=float32)
time = 47455	action = 0	current_phase = 1	next_phase = 0	reward = 0.727254	array([[ -3.0713673, -42.82832  ]], dtype=float32)
time = 47460	action = 0	current_phase = 1	next_phase = 0	reward = 0.726114	array([[ -3.0764523, -42.831394 ]], dtype=float32)
time = 47465	action = 0	current_phase = 1	next_phase = 0	reward = 0.727335	array([[ -3.0820522, -42.84778  ]], dtype=float32)
time = 47470	action = 0	current_phase = 1	next_phase = 0	reward = 0.713133	array([[ -3.0589085, -42.81076  ]], dtype=float32)
time = 47475	action = 0	current_phase = 1	next_phase = 0	reward = 0.718400	array([[ -3.0559568, -42.801304 ]], dtype=float32)
time = 47480	action = 0	current_phase = 1	next_phase = 0	reward = 0.715869	array([[ -3.0407667, -42.775814 ]], dtype=float32)
time = 47485	action = 0	current_phase = 1	next_phase = 0	reward = 0.714215	array([[ -3.07366, -42.82884]], dtype=float32)
time = 47490	action = 0	current_phase = 1	next_phase = 0	reward = 0.722690	array([[ -3.0651731, -42.81824  ]], dtype=float32)
time = 47495	action = 0	current_phase = 1	next_phase = 0	reward = 0.724170	array([[ -3.0553627, -42.802345 ]], dtype=float32)
time = 47500	action = 0	current_phase = 1	next_phase = 0	reward = 0.727656	array([[ -3.0816183, -42.846043 ]], dtype=float32)
time = 47505	action = 0	current_phase = 1	next_phase = 0	reward = 0.727720	array([[ -3.050848, -42.794563]], dtype=float32)
time = 47510	action = 0	current_phase = 1	next_phase = 0	reward = 0.722695	array([[ -3.0624266, -42.813618 ]], dtype=float32)
time = 47515	action = 0	current_phase = 1	next_phase = 0	reward = 0.722770	array([[ -3.0520716, -42.79378  ]], dtype=float32)
time = 47520	action = 0	current_phase = 1	next_phase = 0	reward = 0.724180	array([[ -3.0031881, -42.7097   ]], dtype=float32)
time = 47525	action = 0	current_phase = 1	next_phase = 0	reward = 0.706709	array([[ -3.026555, -42.749767]], dtype=float32)
time = 47530	action = 0	current_phase = 1	next_phase = 0	reward = 0.714735	array([[ -3.044734, -42.781723]], dtype=float32)
time = 47535	action = 0	current_phase = 1	next_phase = 0	reward = 0.716713	array([[ -3.0374804, -42.77015  ]], dtype=float32)
time = 47540	action = 0	current_phase = 1	next_phase = 0	reward = 0.453439	array([[ -3.03693 , -42.767723]], dtype=float32)
time = 47545	action = 0	current_phase = 1	next_phase = 0	reward = 1.005464	array([[ -3.056594, -42.7963  ]], dtype=float32)
time = 47550	action = 0	current_phase = 1	next_phase = 0	reward = 0.716207	array([[ -3.0679398, -42.822968 ]], dtype=float32)
time = 47555	action = 0	current_phase = 1	next_phase = 0	reward = 0.717041	array([[ -3.0658598, -42.81062  ]], dtype=float32)
time = 47560	action = 0	current_phase = 1	next_phase = 0	reward = 0.723439	array([[ -3.0113592, -42.720924 ]], dtype=float32)
time = 47565	action = 0	current_phase = 1	next_phase = 0	reward = 0.719302	array([[ -3.0474977, -42.789448 ]], dtype=float32)
time = 47570	action = 0	current_phase = 1	next_phase = 0	reward = 0.717053	array([[ -3.0500135, -42.79355  ]], dtype=float32)
time = 47575	action = 0	current_phase = 1	next_phase = 0	reward = 0.711577	array([[ -3.0805378, -42.842937 ]], dtype=float32)
time = 47580	action = 0	current_phase = 1	next_phase = 0	reward = 0.439794	array([[ -3.0709658, -42.82702  ]], dtype=float32)
time = 47585	action = 0	current_phase = 1	next_phase = 0	reward = 0.725949	array([[ -3.0649548, -42.817078 ]], dtype=float32)
time = 47590	action = 0	current_phase = 1	next_phase = 0	reward = 1.002486	array([[ -3.0854216, -42.852634 ]], dtype=float32)
time = 47595	action = 0	current_phase = 1	next_phase = 0	reward = 0.716754	array([[ -3.0591707, -42.805126 ]], dtype=float32)
time = 47600	action = 0	current_phase = 1	next_phase = 0	reward = 0.439566	array([[ -3.0783377, -42.84083  ]], dtype=float32)
time = 47605	action = 0	current_phase = 1	next_phase = 0	reward = 1.002234	array([[ -3.0018349, -42.701565 ]], dtype=float32)
time = 47610	action = 0	current_phase = 1	next_phase = 0	reward = 0.719683	array([[ -3.0580673, -42.806168 ]], dtype=float32)
time = 47615	action = 0	current_phase = 1	next_phase = 0	reward = 0.718691	array([[ -3.068102, -42.82172 ]], dtype=float32)
time = 47620	action = 0	current_phase = 1	next_phase = 0	reward = 0.442894	array([[ -3.060731, -42.81211 ]], dtype=float32)
time = 47625	action = 0	current_phase = 1	next_phase = 0	reward = 1.003342	array([[ -3.063096, -42.81329 ]], dtype=float32)
time = 47630	action = 0	current_phase = 1	next_phase = 0	reward = 0.727678	array([[ -3.0594978, -42.808456 ]], dtype=float32)
time = 47635	action = 0	current_phase = 1	next_phase = 0	reward = 0.442488	array([[ -3.050538, -42.78873 ]], dtype=float32)
time = 47640	action = 0	current_phase = 1	next_phase = 0	reward = 0.996394	array([[ -3.0621967, -42.80506  ]], dtype=float32)
time = 47645	action = 0	current_phase = 1	next_phase = 0	reward = 0.728676	array([[ -3.0746098, -42.832756 ]], dtype=float32)
time = 47650	action = 0	current_phase = 1	next_phase = 0	reward = 0.720052	array([[ -3.0853434, -42.851368 ]], dtype=float32)
time = 47655	action = 0	current_phase = 1	next_phase = 0	reward = 0.720154	array([[ -3.0129213, -42.72282  ]], dtype=float32)
time = 47660	action = 0	current_phase = 1	next_phase = 0	reward = 0.726159	array([[ -3.0748549, -42.833977 ]], dtype=float32)
time = 47665	action = 0	current_phase = 1	next_phase = 0	reward = 0.439595	array([[ -3.0550737, -42.79823  ]], dtype=float32)
time = 47670	action = 0	current_phase = 1	next_phase = 0	reward = 0.995778	array([[ -3.0470915, -42.78427  ]], dtype=float32)
time = 47675	action = 0	current_phase = 1	next_phase = 0	reward = 0.713603	array([[ -3.043848, -42.779594]], dtype=float32)
time = 47680	action = 0	current_phase = 1	next_phase = 0	reward = 0.441718	array([[ -3.0468845, -42.788948 ]], dtype=float32)
time = 47685	action = 0	current_phase = 1	next_phase = 0	reward = 1.003761	array([[ -3.0449924, -42.78054  ]], dtype=float32)
time = 47690	action = 0	current_phase = 1	next_phase = 0	reward = 0.459819	array([[ -3.0750294, -42.834446 ]], dtype=float32)
time = 47695	action = 0	current_phase = 1	next_phase = 0	reward = 1.007183	array([[ -3.0467434, -42.78737  ]], dtype=float32)
time = 47700	action = 0	current_phase = 1	next_phase = 0	reward = 0.720879	array([[ -3.081318, -42.844143]], dtype=float32)
time = 47705	action = 0	current_phase = 1	next_phase = 0	reward = 0.723330	array([[ -3.05941 , -42.806957]], dtype=float32)
time = 47710	action = 0	current_phase = 1	next_phase = 0	reward = 0.722703	array([[ -3.085743, -42.849865]], dtype=float32)
time = 47715	action = 0	current_phase = 1	next_phase = 0	reward = 0.724518	array([[ -3.0688725, -42.825497 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 1732.5971 - val_loss: 2578.6370
Epoch 2/50
 - 4s - loss: 1702.3517 - val_loss: 2607.6317
Epoch 3/50
 - 4s - loss: 1722.9903 - val_loss: 2573.1291
Epoch 4/50
 - 4s - loss: 1702.0563 - val_loss: 2556.3825
Epoch 5/50
 - 4s - loss: 1702.5136 - val_loss: 2545.7377
Epoch 6/50
 - 4s - loss: 1709.1619 - val_loss: 2578.9464
Epoch 7/50
 - 4s - loss: 1691.2880 - val_loss: 2546.8564
Epoch 8/50
 - 4s - loss: 1703.2434 - val_loss: 2545.0896
Epoch 9/50
 - 4s - loss: 1717.5457 - val_loss: 2553.1396
Epoch 10/50
 - 4s - loss: 1686.6977 - val_loss: 2556.3954
Epoch 11/50
 - 4s - loss: 1691.3512 - val_loss: 2541.1619
Epoch 12/50
 - 4s - loss: 1693.6227 - val_loss: 2552.9115
Epoch 13/50
 - 4s - loss: 1691.9526 - val_loss: 2532.6441
Epoch 14/50
 - 4s - loss: 1670.5177 - val_loss: 2514.9318
Epoch 15/50
 - 4s - loss: 1668.9118 - val_loss: 2528.6181
Epoch 16/50
 - 4s - loss: 1671.7360 - val_loss: 2524.2955
Epoch 17/50
 - 4s - loss: 1673.4953 - val_loss: 2519.3371
Epoch 18/50
 - 4s - loss: 1669.5706 - val_loss: 2503.1117
Epoch 19/50
 - 4s - loss: 1680.6922 - val_loss: 2526.2426
Epoch 20/50
 - 4s - loss: 1657.9632 - val_loss: 2535.6056
Epoch 21/50
 - 4s - loss: 1660.0069 - val_loss: 2520.3831
Epoch 22/50
 - 4s - loss: 1672.5743 - val_loss: 2529.7609
Epoch 23/50
 - 4s - loss: 1654.2297 - val_loss: 2511.0504
Epoch 24/50
 - 4s - loss: 1672.3053 - val_loss: 2530.4274
Epoch 25/50
 - 4s - loss: 1667.2276 - val_loss: 2510.5847
Epoch 26/50
 - 4s - loss: 1645.8068 - val_loss: 2498.6621
Epoch 27/50
 - 4s - loss: 1645.1794 - val_loss: 2537.3568
Epoch 28/50
 - 4s - loss: 1641.5690 - val_loss: 2491.9070
Epoch 29/50
 - 4s - loss: 1641.1481 - val_loss: 2509.5641
Epoch 30/50
 - 4s - loss: 1650.7596 - val_loss: 2504.6931
Epoch 31/50
 - 4s - loss: 1644.3005 - val_loss: 2489.2441
Epoch 32/50
 - 4s - loss: 1641.9272 - val_loss: 2482.7828
Epoch 33/50
 - 4s - loss: 1637.9244 - val_loss: 2474.0960
Epoch 34/50
 - 4s - loss: 1636.5182 - val_loss: 2464.4475
Epoch 35/50
 - 4s - loss: 1625.4070 - val_loss: 2460.0232
Epoch 36/50
 - 4s - loss: 1635.4181 - val_loss: 2462.0082
Epoch 37/50
 - 4s - loss: 1616.0950 - val_loss: 2465.9901
Epoch 38/50
 - 4s - loss: 1626.4797 - val_loss: 2474.3390
Epoch 39/50
 - 4s - loss: 1630.8753 - val_loss: 2472.6587
Epoch 40/50
 - 4s - loss: 1635.7820 - val_loss: 2443.1573
Epoch 41/50
 - 4s - loss: 1613.0639 - val_loss: 2439.3630
Epoch 42/50
 - 4s - loss: 1616.6601 - val_loss: 2478.2913
Epoch 43/50
 - 4s - loss: 1613.8115 - val_loss: 2435.1007
Epoch 44/50
 - 4s - loss: 1604.7273 - val_loss: 2456.5070
Epoch 45/50
 - 4s - loss: 1606.1767 - val_loss: 2430.4812
Epoch 46/50
 - 4s - loss: 1612.9265 - val_loss: 2440.7163
Epoch 47/50
 - 4s - loss: 1603.2467 - val_loss: 2435.0515
Epoch 48/50
 - 4s - loss: 1594.1570 - val_loss: 2431.2942
Epoch 49/50
 - 4s - loss: 1594.7182 - val_loss: 2437.3966
Epoch 50/50
 - 4s - loss: 1602.6610 - val_loss: 2422.7772
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 47720	action = 0	current_phase = 1	next_phase = 0	reward = 0.715745	array([[ -2.9865446, -42.840164 ]], dtype=float32)
time = 47725	action = 0	current_phase = 1	next_phase = 0	reward = 0.719696	array([[ -2.9856195, -42.84072  ]], dtype=float32)
time = 47730	action = 0	current_phase = 1	next_phase = 0	reward = 0.716823	array([[ -2.9915342, -42.844707 ]], dtype=float32)
time = 47735	action = 0	current_phase = 1	next_phase = 0	reward = 0.710068	array([[ -2.9836988, -42.839676 ]], dtype=float32)
time = 47740	action = 0	current_phase = 1	next_phase = 0	reward = 0.730979	array([[ -2.9845486, -42.840485 ]], dtype=float32)
time = 47745	action = 0	current_phase = 1	next_phase = 0	reward = 0.724706	array([[ -2.9966269, -42.849327 ]], dtype=float32)
time = 47750	action = 0	current_phase = 1	next_phase = 0	reward = 0.442170	array([[ -2.9568806, -42.81144  ]], dtype=float32)
time = 47755	action = 0	current_phase = 1	next_phase = 0	reward = 0.995852	array([[ -2.9758453, -42.833824 ]], dtype=float32)
time = 47760	action = 0	current_phase = 1	next_phase = 0	reward = 0.708693	array([[ -2.9853792, -42.842728 ]], dtype=float32)
time = 47765	action = 0	current_phase = 1	next_phase = 0	reward = 0.713707	array([[ -2.9677172, -42.820587 ]], dtype=float32)
time = 47770	action = 0	current_phase = 1	next_phase = 0	reward = 0.440386	array([[ -2.9893484, -42.843994 ]], dtype=float32)
time = 47775	action = 0	current_phase = 1	next_phase = 0	reward = 0.729669	array([[ -2.9771843, -42.831593 ]], dtype=float32)
time = 47780	action = 0	current_phase = 1	next_phase = 0	reward = 1.003658	array([[ -2.9885416, -42.85135  ]], dtype=float32)
time = 47785	action = 0	current_phase = 1	next_phase = 0	reward = 0.726399	array([[ -2.9886312, -42.842842 ]], dtype=float32)
time = 47790	action = 0	current_phase = 1	next_phase = 0	reward = 0.722927	array([[ -2.9844246, -42.8404   ]], dtype=float32)
time = 47795	action = 0	current_phase = 1	next_phase = 0	reward = 0.717804	array([[ -2.9920502, -42.846024 ]], dtype=float32)
time = 47800	action = 0	current_phase = 1	next_phase = 0	reward = 0.430539	array([[ -2.952958, -42.804832]], dtype=float32)
time = 47805	action = 0	current_phase = 1	next_phase = 0	reward = 0.995421	array([[ -2.9764671, -42.82927  ]], dtype=float32)
time = 47810	action = 0	current_phase = 1	next_phase = 0	reward = 0.713732	array([[ -2.9643364, -42.81971  ]], dtype=float32)
time = 47815	action = 0	current_phase = 1	next_phase = 0	reward = 0.447365	array([[ -2.985899, -42.84026 ]], dtype=float32)
time = 47820	action = 0	current_phase = 1	next_phase = 0	reward = 1.006545	array([[ -2.9785423, -42.834145 ]], dtype=float32)
time = 47825	action = 0	current_phase = 1	next_phase = 0	reward = 0.719111	array([[ -2.9736156, -42.826546 ]], dtype=float32)
time = 47830	action = 0	current_phase = 1	next_phase = 0	reward = 0.717749	array([[ -2.9750519, -42.832123 ]], dtype=float32)
time = 47835	action = 0	current_phase = 1	next_phase = 0	reward = 0.449881	array([[ -2.9900427, -42.843903 ]], dtype=float32)
time = 47840	action = 0	current_phase = 1	next_phase = 0	reward = 0.999535	array([[ -3.0063229, -42.852158 ]], dtype=float32)
time = 47845	action = 0	current_phase = 1	next_phase = 0	reward = 0.711873	array([[ -2.9916945, -42.835968 ]], dtype=float32)
time = 47850	action = 0	current_phase = 1	next_phase = 0	reward = 0.717523	array([[ -2.9859676, -42.850964 ]], dtype=float32)
time = 47855	action = 0	current_phase = 1	next_phase = 0	reward = 0.718312	array([[ -2.9847527, -42.83795  ]], dtype=float32)
time = 47860	action = 0	current_phase = 1	next_phase = 0	reward = 0.721164	array([[ -2.97019, -42.82674]], dtype=float32)
time = 47865	action = 0	current_phase = 1	next_phase = 0	reward = 0.718346	array([[ -2.989149, -42.85077 ]], dtype=float32)
time = 47870	action = 0	current_phase = 1	next_phase = 0	reward = 0.714096	array([[ -2.9536753, -42.805176 ]], dtype=float32)
time = 47875	action = 0	current_phase = 1	next_phase = 0	reward = 0.715626	array([[ -2.992033, -42.855476]], dtype=float32)
time = 47880	action = 0	current_phase = 1	next_phase = 0	reward = 0.440554	array([[ -2.9653072, -42.81864  ]], dtype=float32)
time = 47885	action = 0	current_phase = 1	next_phase = 0	reward = 0.999023	array([[ -2.9431362, -42.793358 ]], dtype=float32)
time = 47890	action = 0	current_phase = 1	next_phase = 0	reward = 0.720312	array([[ -2.9796019, -42.833694 ]], dtype=float32)
time = 47895	action = 0	current_phase = 1	next_phase = 0	reward = 0.439151	array([[ -2.9533672, -42.8107   ]], dtype=float32)
time = 47900	action = 0	current_phase = 1	next_phase = 0	reward = 1.005292	array([[ -2.982788, -42.83957 ]], dtype=float32)
time = 47905	action = 0	current_phase = 1	next_phase = 0	reward = 0.439783	array([[ -3.0004883, -42.856064 ]], dtype=float32)
time = 47910	action = 0	current_phase = 1	next_phase = 0	reward = 0.724920	array([[ -2.9761858, -42.832138 ]], dtype=float32)
time = 47915	action = 0	current_phase = 1	next_phase = 0	reward = 1.002062	array([[ -2.9786854, -42.831688 ]], dtype=float32)
time = 47920	action = 0	current_phase = 1	next_phase = 0	reward = 0.720443	array([[ -2.990758, -42.850975]], dtype=float32)
time = 47925	action = 0	current_phase = 1	next_phase = 0	reward = 0.440150	array([[ -2.987031, -42.841125]], dtype=float32)
time = 47930	action = 0	current_phase = 1	next_phase = 0	reward = 1.007317	array([[ -2.9812307, -42.834785 ]], dtype=float32)
time = 47935	action = 0	current_phase = 1	next_phase = 0	reward = 0.723709	array([[ -2.9731512, -42.82738  ]], dtype=float32)
time = 47940	action = 0	current_phase = 1	next_phase = 0	reward = 0.717391	array([[ -2.9911098, -42.845894 ]], dtype=float32)
time = 47945	action = 0	current_phase = 1	next_phase = 0	reward = 0.715876	array([[ -3.0125227, -42.84368  ]], dtype=float32)
time = 47950	action = 0	current_phase = 1	next_phase = 0	reward = 0.433474	array([[ -2.991376, -42.844833]], dtype=float32)
time = 47955	action = 0	current_phase = 1	next_phase = 0	reward = 1.008877	array([[ -2.9884148, -42.843315 ]], dtype=float32)
time = 47960	action = 0	current_phase = 1	next_phase = 0	reward = 0.719790	array([[ -2.994278, -42.860718]], dtype=float32)
time = 47965	action = 0	current_phase = 1	next_phase = 0	reward = 0.724225	array([[ -2.9961443, -42.84761  ]], dtype=float32)
time = 47970	action = 0	current_phase = 1	next_phase = 0	reward = 0.722003	array([[ -2.9761267, -42.832695 ]], dtype=float32)
time = 47975	action = 0	current_phase = 1	next_phase = 0	reward = 0.722665	array([[ -2.9826412, -42.83728  ]], dtype=float32)
time = 47980	action = 0	current_phase = 1	next_phase = 0	reward = 0.725613	array([[ -2.9892788, -42.842545 ]], dtype=float32)
time = 47985	action = 0	current_phase = 1	next_phase = 0	reward = 0.720668	array([[ -2.9974127, -42.850586 ]], dtype=float32)
time = 47990	action = 0	current_phase = 1	next_phase = 0	reward = 0.724591	array([[ -2.9887428, -42.844337 ]], dtype=float32)
time = 47995	action = 0	current_phase = 1	next_phase = 0	reward = 0.719029	array([[ -2.9896412, -42.845387 ]], dtype=float32)
time = 48000	action = 0	current_phase = 1	next_phase = 0	reward = 0.717972	array([[ -3.0000648, -42.843483 ]], dtype=float32)
time = 48005	action = 0	current_phase = 1	next_phase = 0	reward = 0.716304	array([[ -2.9672194, -42.814026 ]], dtype=float32)
time = 48010	action = 0	current_phase = 1	next_phase = 0	reward = 0.439601	array([[ -2.9758387, -42.832386 ]], dtype=float32)
time = 48015	action = 0	current_phase = 1	next_phase = 0	reward = 0.725180	array([[ -2.9802322, -42.83314  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3919.7208 - val_loss: 1153.5773
Epoch 2/50
 - 4s - loss: 3912.8554 - val_loss: 1149.5426
Epoch 3/50
 - 4s - loss: 3917.8676 - val_loss: 1158.5555
Epoch 4/50
 - 4s - loss: 3901.2198 - val_loss: 1148.9802
Epoch 5/50
 - 4s - loss: 3907.0785 - val_loss: 1150.4109
Epoch 6/50
 - 4s - loss: 3907.0324 - val_loss: 1179.4287
Epoch 7/50
 - 4s - loss: 3902.9772 - val_loss: 1176.4353
Epoch 8/50
 - 4s - loss: 3903.3201 - val_loss: 1172.3783
Epoch 9/50
 - 4s - loss: 3919.0976 - val_loss: 1168.2579
Epoch 10/50
 - 4s - loss: 3891.6235 - val_loss: 1151.2164
Epoch 11/50
 - 4s - loss: 3897.8674 - val_loss: 1164.6216
Epoch 12/50
 - 4s - loss: 3880.1728 - val_loss: 1191.8467
Epoch 13/50
 - 4s - loss: 3885.2333 - val_loss: 1225.6833
Epoch 14/50
 - 4s - loss: 3875.0155 - val_loss: 1151.4907
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 48020	action = 0	current_phase = 1	next_phase = 0	reward = 1.002725	array([[ -3.107028, -42.892727]], dtype=float32)
time = 48025	action = 0	current_phase = 1	next_phase = 0	reward = 0.717072	array([[ -3.1108236, -42.892143 ]], dtype=float32)
time = 48030	action = 0	current_phase = 1	next_phase = 0	reward = 0.445918	array([[ -3.117094, -42.895985]], dtype=float32)
time = 48035	action = 0	current_phase = 1	next_phase = 0	reward = 0.728532	array([[ -3.1789055, -42.890778 ]], dtype=float32)
time = 48040	action = 0	current_phase = 1	next_phase = 0	reward = 1.006385	array([[ -3.123231, -42.902122]], dtype=float32)
time = 48045	action = 0	current_phase = 1	next_phase = 0	reward = 0.723344	array([[ -3.127058, -42.90323 ]], dtype=float32)
time = 48050	action = 0	current_phase = 1	next_phase = 0	reward = 0.722865	array([[ -3.1083183, -42.897778 ]], dtype=float32)
time = 48055	action = 0	current_phase = 1	next_phase = 0	reward = 0.721690	array([[ -3.1040087, -42.891876 ]], dtype=float32)
time = 48060	action = 0	current_phase = 1	next_phase = 0	reward = 0.446039	array([[ -3.1159773, -42.898895 ]], dtype=float32)
time = 48065	action = 0	current_phase = 1	next_phase = 0	reward = 0.734359	array([[ -3.1077356, -42.893116 ]], dtype=float32)
time = 48070	action = 0	current_phase = 1	next_phase = 0	reward = 1.013844	array([[ -3.1191654, -42.900726 ]], dtype=float32)
time = 48075	action = 0	current_phase = 1	next_phase = 0	reward = 0.728532	array([[ -3.1244364, -42.904503 ]], dtype=float32)
time = 48080	action = 0	current_phase = 1	next_phase = 0	reward = 0.723293	array([[ -3.1306133, -42.90104  ]], dtype=float32)
time = 48085	action = 0	current_phase = 1	next_phase = 0	reward = 0.717216	array([[ -3.1132755, -42.89852  ]], dtype=float32)
time = 48090	action = 0	current_phase = 1	next_phase = 0	reward = 0.719389	array([[ -3.1105623, -42.88788  ]], dtype=float32)
time = 48095	action = 0	current_phase = 1	next_phase = 0	reward = 0.439406	array([[ -3.1116943, -42.89594  ]], dtype=float32)
time = 48100	action = 0	current_phase = 1	next_phase = 0	reward = 1.010391	array([[ -3.11862 , -42.901375]], dtype=float32)
time = 48105	action = 0	current_phase = 1	next_phase = 0	reward = 0.719028	array([[ -3.0965834, -42.888023 ]], dtype=float32)
time = 48110	action = 0	current_phase = 1	next_phase = 0	reward = 0.717309	array([[ -3.1107197, -42.89058  ]], dtype=float32)
time = 48115	action = 0	current_phase = 1	next_phase = 0	reward = 0.723121	array([[ -3.113202, -42.89704 ]], dtype=float32)
time = 48120	action = 0	current_phase = 1	next_phase = 0	reward = 0.715594	array([[ -3.0884 , -42.88337]], dtype=float32)
time = 48125	action = 0	current_phase = 1	next_phase = 0	reward = 0.437614	array([[ -3.1119528, -42.898632 ]], dtype=float32)
time = 48130	action = 0	current_phase = 1	next_phase = 0	reward = 0.998833	array([[ -3.0863352, -42.882874 ]], dtype=float32)
time = 48135	action = 0	current_phase = 1	next_phase = 0	reward = 0.442892	array([[ -3.11131, -42.89595]], dtype=float32)
time = 48140	action = 0	current_phase = 1	next_phase = 0	reward = 1.002814	array([[ -3.114643, -42.901596]], dtype=float32)
time = 48145	action = 0	current_phase = 1	next_phase = 0	reward = 0.723103	array([[ -3.1086397, -42.895584 ]], dtype=float32)
time = 48150	action = 0	current_phase = 1	next_phase = 0	reward = 0.722474	array([[ -3.1232367, -42.91053  ]], dtype=float32)
time = 48155	action = 0	current_phase = 1	next_phase = 0	reward = 0.717775	array([[ -3.1086512, -42.89205  ]], dtype=float32)
time = 48160	action = 0	current_phase = 1	next_phase = 0	reward = 0.711785	array([[ -3.104951, -42.89426 ]], dtype=float32)
time = 48165	action = 0	current_phase = 1	next_phase = 0	reward = 0.438140	array([[ -3.1332188, -42.923073 ]], dtype=float32)
time = 48170	action = 0	current_phase = 1	next_phase = 0	reward = 1.001904	array([[ -3.0973673, -42.88646  ]], dtype=float32)
time = 48175	action = 0	current_phase = 1	next_phase = 0	reward = 0.726092	array([[ -3.1009693, -42.895966 ]], dtype=float32)
time = 48180	action = 0	current_phase = 1	next_phase = 0	reward = 0.440258	array([[ -3.1079397, -42.89031  ]], dtype=float32)
time = 48185	action = 0	current_phase = 1	next_phase = 0	reward = 0.722723	array([[ -3.1267805, -42.90557  ]], dtype=float32)
time = 48190	action = 0	current_phase = 1	next_phase = 0	reward = 0.993155	array([[ -3.12422, -42.89774]], dtype=float32)
time = 48195	action = 0	current_phase = 1	next_phase = 0	reward = 0.442273	array([[ -3.1160994, -42.898018 ]], dtype=float32)
time = 48200	action = 0	current_phase = 1	next_phase = 0	reward = 0.730580	array([[ -3.1101198, -42.89492  ]], dtype=float32)
time = 48205	action = 0	current_phase = 1	next_phase = 0	reward = 0.997428	array([[ -3.2147799, -42.88289  ]], dtype=float32)
time = 48210	action = 0	current_phase = 1	next_phase = 0	reward = 0.722858	array([[ -3.116704, -42.904198]], dtype=float32)
time = 48215	action = 0	current_phase = 1	next_phase = 0	reward = 0.725784	array([[ -3.1201649, -42.901993 ]], dtype=float32)
time = 48220	action = 0	current_phase = 1	next_phase = 0	reward = 0.717159	array([[ -3.110262, -42.896492]], dtype=float32)
time = 48225	action = 0	current_phase = 1	next_phase = 0	reward = 0.718747	array([[ -3.12012, -42.90235]], dtype=float32)
time = 48230	action = 0	current_phase = 1	next_phase = 0	reward = 0.450840	array([[ -3.0811949, -42.875626 ]], dtype=float32)
time = 48235	action = 0	current_phase = 1	next_phase = 0	reward = 1.008599	array([[ -3.1227722, -42.888386 ]], dtype=float32)
time = 48240	action = 0	current_phase = 1	next_phase = 0	reward = 0.725444	array([[ -3.1231413, -42.902878 ]], dtype=float32)
time = 48245	action = 0	current_phase = 1	next_phase = 0	reward = 0.720942	array([[ -3.1105213, -42.895214 ]], dtype=float32)
time = 48250	action = 0	current_phase = 1	next_phase = 0	reward = 0.721408	array([[ -3.1163216, -42.89493  ]], dtype=float32)
time = 48255	action = 0	current_phase = 1	next_phase = 0	reward = 0.720672	array([[ -3.1151218, -42.882294 ]], dtype=float32)
time = 48260	action = 0	current_phase = 1	next_phase = 0	reward = 0.720476	array([[ -3.1113434, -42.896683 ]], dtype=float32)
time = 48265	action = 0	current_phase = 1	next_phase = 0	reward = 0.721856	array([[ -3.1194458, -42.90122  ]], dtype=float32)
time = 48270	action = 0	current_phase = 1	next_phase = 0	reward = 0.723452	array([[ -3.1264925, -42.90667  ]], dtype=float32)
time = 48275	action = 0	current_phase = 1	next_phase = 0	reward = 0.721867	array([[ -3.110239, -42.896465]], dtype=float32)
time = 48280	action = 0	current_phase = 1	next_phase = 0	reward = 0.729855	array([[ -3.116067, -42.898964]], dtype=float32)
time = 48285	action = 0	current_phase = 1	next_phase = 0	reward = 0.716148	array([[ -3.0870705, -42.880417 ]], dtype=float32)
time = 48290	action = 0	current_phase = 1	next_phase = 0	reward = 0.712302	array([[ -3.1124353, -42.8798   ]], dtype=float32)
time = 48295	action = 0	current_phase = 1	next_phase = 0	reward = 0.720076	array([[ -3.078967, -42.876217]], dtype=float32)
time = 48300	action = 0	current_phase = 1	next_phase = 0	reward = 0.434600	array([[ -3.130745, -42.881668]], dtype=float32)
time = 48305	action = 0	current_phase = 1	next_phase = 0	reward = 1.004223	array([[ -3.1056147, -42.895397 ]], dtype=float32)
time = 48310	action = 0	current_phase = 1	next_phase = 0	reward = 0.437255	array([[ -3.1468754, -42.90654  ]], dtype=float32)
time = 48315	action = 0	current_phase = 1	next_phase = 0	reward = 1.005928	array([[ -3.0930796, -42.8847   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2456.6198 - val_loss: 7329.8485
Epoch 2/50
 - 4s - loss: 2452.3246 - val_loss: 7341.6588
Epoch 3/50
 - 4s - loss: 2438.6385 - val_loss: 7313.0220
Epoch 4/50
 - 4s - loss: 2445.9298 - val_loss: 7318.0862
Epoch 5/50
 - 4s - loss: 2431.7467 - val_loss: 7315.2923
Epoch 6/50
 - 4s - loss: 2437.4371 - val_loss: 7299.0754
Epoch 7/50
 - 4s - loss: 2417.0258 - val_loss: 7320.7253
Epoch 8/50
 - 4s - loss: 2427.0804 - val_loss: 7346.6952
Epoch 9/50
 - 4s - loss: 2411.7090 - val_loss: 7302.9731
Epoch 10/50
 - 4s - loss: 2406.4123 - val_loss: 7276.3824
Epoch 11/50
 - 4s - loss: 2395.9380 - val_loss: 7263.8618
Epoch 12/50
 - 4s - loss: 2397.3994 - val_loss: 7271.6768
Epoch 13/50
 - 4s - loss: 2388.1194 - val_loss: 7277.0536
Epoch 14/50
 - 4s - loss: 2387.9474 - val_loss: 7282.3955
Epoch 15/50
 - 4s - loss: 2379.8472 - val_loss: 7254.3609
Epoch 16/50
 - 4s - loss: 2378.2923 - val_loss: 7235.1837
Epoch 17/50
 - 4s - loss: 2374.7025 - val_loss: 7253.8859
Epoch 18/50
 - 4s - loss: 2359.4287 - val_loss: 7235.4036
Epoch 19/50
 - 4s - loss: 2362.8865 - val_loss: 7216.4763
Epoch 20/50
 - 4s - loss: 2355.5459 - val_loss: 7210.7217
Epoch 21/50
 - 4s - loss: 2349.9271 - val_loss: 7209.7028
Epoch 22/50
 - 4s - loss: 2350.6272 - val_loss: 7209.3574
Epoch 23/50
 - 4s - loss: 2353.4497 - val_loss: 7208.4679
Epoch 24/50
 - 4s - loss: 2358.8931 - val_loss: 7216.9520
Epoch 25/50
 - 4s - loss: 2343.7279 - val_loss: 7196.0204
Epoch 26/50
 - 4s - loss: 2352.7171 - val_loss: 7177.9311
Epoch 27/50
 - 4s - loss: 2338.6938 - val_loss: 7177.6364
Epoch 28/50
 - 4s - loss: 2331.4384 - val_loss: 7176.7202
Epoch 29/50
 - 4s - loss: 2319.5301 - val_loss: 7186.8832
Epoch 30/50
 - 4s - loss: 2322.3794 - val_loss: 7200.9521
Epoch 31/50
 - 4s - loss: 2321.3574 - val_loss: 7183.7080
Epoch 32/50
 - 4s - loss: 2307.2653 - val_loss: 7167.0384
Epoch 33/50
 - 4s - loss: 2301.3276 - val_loss: 7145.7201
Epoch 34/50
 - 4s - loss: 2304.6886 - val_loss: 7151.8806
Epoch 35/50
 - 4s - loss: 2288.2131 - val_loss: 7141.9022
Epoch 36/50
 - 4s - loss: 2294.1333 - val_loss: 7158.4687
Epoch 37/50
 - 4s - loss: 2291.3010 - val_loss: 7136.5401
Epoch 38/50
 - 4s - loss: 2287.4383 - val_loss: 7136.4341
Epoch 39/50
 - 4s - loss: 2270.8147 - val_loss: 7128.1404
Epoch 40/50
 - 4s - loss: 2277.3390 - val_loss: 7120.1188
Epoch 41/50
 - 4s - loss: 2266.8825 - val_loss: 7116.1085
Epoch 42/50
 - 4s - loss: 2265.9430 - val_loss: 7107.5663
Epoch 43/50
 - 4s - loss: 2250.3332 - val_loss: 7147.6546
Epoch 44/50
 - 4s - loss: 2257.1533 - val_loss: 7113.2444
Epoch 45/50
 - 4s - loss: 2249.4736 - val_loss: 7107.3295
Epoch 46/50
 - 4s - loss: 2250.7813 - val_loss: 7091.4653
Epoch 47/50
 - 4s - loss: 2258.5229 - val_loss: 7101.8598
Epoch 48/50
 - 4s - loss: 2240.5956 - val_loss: 7100.3534
Epoch 49/50
 - 4s - loss: 2234.6737 - val_loss: 7090.8587
Epoch 50/50
 - 4s - loss: 2227.4157 - val_loss: 7084.1131
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 48320	action = 0	current_phase = 1	next_phase = 0	reward = 0.727824	array([[ -1.9365311, -42.85513  ]], dtype=float32)
time = 48325	action = 0	current_phase = 1	next_phase = 0	reward = 0.444026	array([[ -1.9794912, -42.88275  ]], dtype=float32)
time = 48330	action = 0	current_phase = 1	next_phase = 0	reward = 1.003141	array([[ -1.9724627, -42.871315 ]], dtype=float32)
time = 48335	action = 0	current_phase = 1	next_phase = 0	reward = 0.727368	array([[ -1.9663572, -42.87085  ]], dtype=float32)
time = 48340	action = 0	current_phase = 1	next_phase = 0	reward = 0.715235	array([[ -1.9594975, -42.877075 ]], dtype=float32)
time = 48345	action = 0	current_phase = 1	next_phase = 0	reward = 0.712205	array([[ -1.9944773, -42.88349  ]], dtype=float32)
time = 48350	action = 0	current_phase = 1	next_phase = 0	reward = 0.439369	array([[ -1.9794149, -42.87622  ]], dtype=float32)
time = 48355	action = 0	current_phase = 1	next_phase = 0	reward = 0.722483	array([[ -1.9662485, -42.866043 ]], dtype=float32)
time = 48360	action = 0	current_phase = 1	next_phase = 0	reward = 1.003098	array([[ -1.9277096, -42.84946  ]], dtype=float32)
time = 48365	action = 0	current_phase = 1	next_phase = 0	reward = 0.720326	array([[ -1.9085817, -42.833633 ]], dtype=float32)
time = 48370	action = 0	current_phase = 1	next_phase = 0	reward = 0.449791	array([[ -1.9543705, -42.85956  ]], dtype=float32)
time = 48375	action = 0	current_phase = 1	next_phase = 0	reward = 0.997086	array([[ -1.9868402, -42.895767 ]], dtype=float32)
time = 48380	action = 0	current_phase = 1	next_phase = 0	reward = 0.716029	array([[ -1.9915466, -42.890144 ]], dtype=float32)
time = 48385	action = 0	current_phase = 1	next_phase = 0	reward = 0.439760	array([[ -1.9791174, -42.878494 ]], dtype=float32)
time = 48390	action = 0	current_phase = 1	next_phase = 0	reward = 1.005513	array([[ -1.9659328, -42.868675 ]], dtype=float32)
time = 48395	action = 0	current_phase = 1	next_phase = 0	reward = 0.728641	array([[ -1.9727602, -42.870068 ]], dtype=float32)
time = 48400	action = 0	current_phase = 1	next_phase = 0	reward = 0.724477	array([[ -1.9848185, -42.883408 ]], dtype=float32)
time = 48405	action = 0	current_phase = 1	next_phase = 0	reward = 0.721506	array([[ -1.9823942, -42.88459  ]], dtype=float32)
time = 48410	action = 0	current_phase = 1	next_phase = 0	reward = 0.720928	array([[ -1.964014, -42.87313 ]], dtype=float32)
time = 48415	action = 0	current_phase = 1	next_phase = 0	reward = 0.723736	array([[ -1.9790192, -42.896767 ]], dtype=float32)
time = 48420	action = 0	current_phase = 1	next_phase = 0	reward = 0.724879	array([[ -1.9688787, -42.871975 ]], dtype=float32)
time = 48425	action = 0	current_phase = 1	next_phase = 0	reward = 0.722552	array([[ -1.9776363, -42.877037 ]], dtype=float32)
time = 48430	action = 0	current_phase = 1	next_phase = 0	reward = 0.720094	array([[ -1.9908581, -42.891445 ]], dtype=float32)
time = 48435	action = 0	current_phase = 1	next_phase = 0	reward = 0.716572	array([[ -1.9612932, -42.878777 ]], dtype=float32)
time = 48440	action = 0	current_phase = 1	next_phase = 0	reward = 0.441461	array([[ -1.9584255, -42.863983 ]], dtype=float32)
time = 48445	action = 0	current_phase = 1	next_phase = 0	reward = 1.003158	array([[ -1.9873304, -42.881905 ]], dtype=float32)
time = 48450	action = 0	current_phase = 1	next_phase = 0	reward = 0.719330	array([[ -1.9894199, -42.89215  ]], dtype=float32)
time = 48455	action = 0	current_phase = 1	next_phase = 0	reward = 0.718404	array([[ -1.9833593, -42.88379  ]], dtype=float32)
time = 48460	action = 0	current_phase = 1	next_phase = 0	reward = 0.718409	array([[ -1.9705544, -42.872223 ]], dtype=float32)
time = 48465	action = 0	current_phase = 1	next_phase = 0	reward = 0.709756	array([[ -1.9873953, -42.884155 ]], dtype=float32)
time = 48470	action = 0	current_phase = 1	next_phase = 0	reward = 0.434235	array([[ -1.9856291, -42.89396  ]], dtype=float32)
time = 48475	action = 0	current_phase = 1	next_phase = 0	reward = 0.729042	array([[ -1.9774313, -42.88465  ]], dtype=float32)
time = 48480	action = 0	current_phase = 1	next_phase = 0	reward = 0.723579	array([[ -1.9767351, -42.874603 ]], dtype=float32)
time = 48485	action = 0	current_phase = 1	next_phase = 0	reward = 0.998046	array([[ -1.9956532, -42.88629  ]], dtype=float32)
time = 48490	action = 0	current_phase = 1	next_phase = 0	reward = 0.711746	array([[ -1.9703617, -42.879677 ]], dtype=float32)
time = 48495	action = 0	current_phase = 1	next_phase = 0	reward = 0.439142	array([[ -1.9679995, -42.874413 ]], dtype=float32)
time = 48500	action = 0	current_phase = 1	next_phase = 0	reward = 1.000422	array([[ -1.983491, -42.881905]], dtype=float32)
time = 48505	action = 0	current_phase = 1	next_phase = 0	reward = 0.437364	array([[ -1.9758368, -42.87625  ]], dtype=float32)
time = 48510	action = 0	current_phase = 1	next_phase = 0	reward = 1.003674	array([[ -1.9910831, -42.88873  ]], dtype=float32)
time = 48515	action = 0	current_phase = 1	next_phase = 0	reward = 0.724237	array([[ -1.9936123, -42.878113 ]], dtype=float32)
time = 48520	action = 0	current_phase = 1	next_phase = 0	reward = 0.718698	array([[ -1.979167, -42.878414]], dtype=float32)
time = 48525	action = 0	current_phase = 1	next_phase = 0	reward = 0.443361	array([[ -1.9790154, -42.88186  ]], dtype=float32)
time = 48530	action = 0	current_phase = 1	next_phase = 0	reward = 1.008241	array([[ -1.9743357, -42.88073  ]], dtype=float32)
time = 48535	action = 0	current_phase = 1	next_phase = 0	reward = 0.730785	array([[ -1.9897442, -42.888985 ]], dtype=float32)
time = 48540	action = 0	current_phase = 1	next_phase = 0	reward = 0.725022	array([[ -1.9760218, -42.880383 ]], dtype=float32)
time = 48545	action = 0	current_phase = 1	next_phase = 0	reward = 0.720449	array([[ -1.9797754, -42.900948 ]], dtype=float32)
time = 48550	action = 0	current_phase = 1	next_phase = 0	reward = 0.713648	array([[ -1.9945316, -42.88411  ]], dtype=float32)
time = 48555	action = 0	current_phase = 1	next_phase = 0	reward = 0.723988	array([[ -1.9710217, -42.882027 ]], dtype=float32)
time = 48560	action = 0	current_phase = 1	next_phase = 0	reward = 0.725183	array([[ -1.9837856, -42.881023 ]], dtype=float32)
time = 48565	action = 0	current_phase = 1	next_phase = 0	reward = 0.723768	array([[ -1.961216, -42.8744  ]], dtype=float32)
time = 48570	action = 0	current_phase = 1	next_phase = 0	reward = 0.713735	array([[ -1.9659681, -42.872894 ]], dtype=float32)
time = 48575	action = 0	current_phase = 1	next_phase = 0	reward = 0.717546	array([[ -1.9618397, -42.86743  ]], dtype=float32)
time = 48580	action = 0	current_phase = 1	next_phase = 0	reward = 0.721902	array([[ -1.981247, -42.8805  ]], dtype=float32)
time = 48585	action = 0	current_phase = 1	next_phase = 0	reward = 0.721324	array([[ -1.9685678, -42.873253 ]], dtype=float32)
time = 48590	action = 0	current_phase = 1	next_phase = 0	reward = 0.720856	array([[ -1.9822302, -42.882347 ]], dtype=float32)
time = 48595	action = 0	current_phase = 1	next_phase = 0	reward = 0.440784	array([[ -1.9836798, -42.87527  ]], dtype=float32)
time = 48600	action = 0	current_phase = 1	next_phase = 0	reward = 0.725471	array([[ -1.9906902, -42.882626 ]], dtype=float32)
time = 48605	action = 0	current_phase = 1	next_phase = 0	reward = 1.001163	array([[ -1.9723969, -42.882515 ]], dtype=float32)
time = 48610	action = 0	current_phase = 1	next_phase = 0	reward = 0.715853	array([[ -1.9246435, -42.845318 ]], dtype=float32)
time = 48615	action = 0	current_phase = 1	next_phase = 0	reward = 0.716968	array([[ -1.9370832, -42.851776 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3467.8536 - val_loss: 3117.1746
Epoch 2/50
 - 4s - loss: 3469.9200 - val_loss: 3112.0136
Epoch 3/50
 - 4s - loss: 3457.1188 - val_loss: 3106.9557
Epoch 4/50
 - 4s - loss: 3462.2500 - val_loss: 3103.4194
Epoch 5/50
 - 4s - loss: 3450.9669 - val_loss: 3096.4690
Epoch 6/50
 - 4s - loss: 3457.1162 - val_loss: 3091.8840
Epoch 7/50
 - 4s - loss: 3448.5479 - val_loss: 3086.8592
Epoch 8/50
 - 4s - loss: 3447.3153 - val_loss: 3081.5505
Epoch 9/50
 - 4s - loss: 3435.4589 - val_loss: 3077.6201
Epoch 10/50
 - 4s - loss: 3448.0376 - val_loss: 3073.0948
Epoch 11/50
 - 4s - loss: 3439.1082 - val_loss: 3084.6066
Epoch 12/50
 - 4s - loss: 3440.5203 - val_loss: 3065.6594
Epoch 13/50
 - 4s - loss: 3458.6306 - val_loss: 3060.1543
Epoch 14/50
 - 4s - loss: 3422.7085 - val_loss: 3057.7676
Epoch 15/50
 - 4s - loss: 3428.8527 - val_loss: 3051.9477
Epoch 16/50
 - 4s - loss: 3424.5030 - val_loss: 3050.7210
Epoch 17/50
 - 4s - loss: 3423.2962 - val_loss: 3041.1380
Epoch 18/50
 - 4s - loss: 3415.4265 - val_loss: 3036.9032
Epoch 19/50
 - 4s - loss: 3419.2538 - val_loss: 3037.2559
Epoch 20/50
 - 4s - loss: 3420.0977 - val_loss: 3029.0289
Epoch 21/50
 - 4s - loss: 3416.0417 - val_loss: 3026.0333
Epoch 22/50
 - 4s - loss: 3409.1143 - val_loss: 3019.5415
Epoch 23/50
 - 4s - loss: 3418.8572 - val_loss: 3013.5050
Epoch 24/50
 - 4s - loss: 3407.8561 - val_loss: 3010.8972
Epoch 25/50
 - 4s - loss: 3399.5739 - val_loss: 3006.0263
Epoch 26/50
 - 4s - loss: 3396.6249 - val_loss: 3005.6729
Epoch 27/50
 - 4s - loss: 3395.4515 - val_loss: 2999.5224
Epoch 28/50
 - 4s - loss: 3399.5014 - val_loss: 2993.5615
Epoch 29/50
 - 4s - loss: 3391.6319 - val_loss: 2993.1640
Epoch 30/50
 - 4s - loss: 3393.8287 - val_loss: 2983.5536
Epoch 31/50
 - 4s - loss: 3391.5567 - val_loss: 2983.8695
Epoch 32/50
 - 4s - loss: 3396.5206 - val_loss: 2976.3975
Epoch 33/50
 - 4s - loss: 3385.6381 - val_loss: 2976.3267
Epoch 34/50
 - 4s - loss: 3374.5724 - val_loss: 2965.7466
Epoch 35/50
 - 4s - loss: 3376.6758 - val_loss: 2961.4724
Epoch 36/50
 - 4s - loss: 3370.5041 - val_loss: 2964.0213
Epoch 37/50
 - 4s - loss: 3378.6571 - val_loss: 2973.2737
Epoch 38/50
 - 4s - loss: 3373.9342 - val_loss: 2948.7899
Epoch 39/50
 - 4s - loss: 3372.6596 - val_loss: 2943.6463
Epoch 40/50
 - 4s - loss: 3376.5718 - val_loss: 2939.8185
Epoch 41/50
 - 4s - loss: 3375.7496 - val_loss: 2938.0078
Epoch 42/50
 - 4s - loss: 3366.7281 - val_loss: 2930.9729
Epoch 43/50
 - 4s - loss: 3362.1199 - val_loss: 2926.7332
Epoch 44/50
 - 4s - loss: 3353.0995 - val_loss: 2926.1360
Epoch 45/50
 - 4s - loss: 3347.8301 - val_loss: 2912.8986
Epoch 46/50
 - 4s - loss: 3341.7152 - val_loss: 2909.5195
Epoch 47/50
 - 4s - loss: 3348.9735 - val_loss: 2906.2589
Epoch 48/50
 - 4s - loss: 3336.8270 - val_loss: 2901.8417
Epoch 49/50
 - 4s - loss: 3342.0260 - val_loss: 2900.7423
Epoch 50/50
 - 4s - loss: 3352.9782 - val_loss: 2897.2698
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 48620	action = 0	current_phase = 1	next_phase = 0	reward = 0.444179	array([[ -1.8619757, -42.86655  ]], dtype=float32)
time = 48625	action = 0	current_phase = 1	next_phase = 0	reward = 1.000726	array([[ -1.8808222, -42.8606   ]], dtype=float32)
time = 48630	action = 0	current_phase = 1	next_phase = 0	reward = 0.714752	array([[ -1.8287039, -42.85769  ]], dtype=float32)
time = 48635	action = 0	current_phase = 1	next_phase = 0	reward = 0.718473	array([[ -1.8942156, -42.865173 ]], dtype=float32)
time = 48640	action = 0	current_phase = 1	next_phase = 0	reward = 0.722226	array([[ -1.8411436, -42.85757  ]], dtype=float32)
time = 48645	action = 0	current_phase = 1	next_phase = 0	reward = 0.716558	array([[ -1.8535166, -42.858498 ]], dtype=float32)
time = 48650	action = 0	current_phase = 1	next_phase = 0	reward = 0.711940	array([[ -1.8399801, -42.858124 ]], dtype=float32)
time = 48655	action = 0	current_phase = 1	next_phase = 0	reward = 0.713382	array([[ -1.8091516, -42.85127  ]], dtype=float32)
time = 48660	action = 0	current_phase = 1	next_phase = 0	reward = 0.448234	array([[ -1.8126183, -42.85607  ]], dtype=float32)
time = 48665	action = 0	current_phase = 1	next_phase = 0	reward = 1.001525	array([[ -1.8315992, -42.857693 ]], dtype=float32)
time = 48670	action = 0	current_phase = 1	next_phase = 0	reward = 0.720588	array([[ -1.8696299, -42.861958 ]], dtype=float32)
time = 48675	action = 0	current_phase = 1	next_phase = 0	reward = 0.720031	array([[ -1.8725681, -42.86315  ]], dtype=float32)
time = 48680	action = 0	current_phase = 1	next_phase = 0	reward = 0.726532	array([[ -1.8727627, -42.86365  ]], dtype=float32)
time = 48685	action = 0	current_phase = 1	next_phase = 0	reward = 0.723743	array([[ -1.8903809, -42.86475  ]], dtype=float32)
time = 48690	action = 0	current_phase = 1	next_phase = 0	reward = 0.721180	array([[ -1.8624592, -42.862396 ]], dtype=float32)
time = 48695	action = 0	current_phase = 1	next_phase = 0	reward = 0.718470	array([[ -1.8491287, -42.858032 ]], dtype=float32)
time = 48700	action = 0	current_phase = 1	next_phase = 0	reward = 0.443772	array([[ -1.8524818, -42.86206  ]], dtype=float32)
time = 48705	action = 0	current_phase = 1	next_phase = 0	reward = 1.007921	array([[ -1.8726654, -42.86374  ]], dtype=float32)
time = 48710	action = 0	current_phase = 1	next_phase = 0	reward = 0.719206	array([[ -1.8299494, -42.85491  ]], dtype=float32)
time = 48715	action = 0	current_phase = 1	next_phase = 0	reward = 0.442397	array([[ -1.8100481, -42.849503 ]], dtype=float32)
time = 48720	action = 0	current_phase = 1	next_phase = 0	reward = 1.004185	array([[ -1.8580313, -42.860565 ]], dtype=float32)
time = 48725	action = 0	current_phase = 1	next_phase = 0	reward = 0.717605	array([[ -1.8334551, -42.857162 ]], dtype=float32)
time = 48730	action = 0	current_phase = 1	next_phase = 0	reward = 0.440553	array([[ -1.886756, -42.864002]], dtype=float32)
time = 48735	action = 0	current_phase = 1	next_phase = 0	reward = 0.999747	array([[ -1.7711153, -42.838673 ]], dtype=float32)
time = 48740	action = 0	current_phase = 1	next_phase = 0	reward = 0.716246	array([[ -1.8723536, -42.861217 ]], dtype=float32)
time = 48745	action = 0	current_phase = 1	next_phase = 0	reward = 0.726635	array([[ -1.847743, -42.863895]], dtype=float32)
time = 48750	action = 0	current_phase = 1	next_phase = 0	reward = 0.452487	array([[ -1.8553944, -42.863174 ]], dtype=float32)
time = 48755	action = 0	current_phase = 1	next_phase = 0	reward = 1.014234	array([[ -1.8318014, -42.854958 ]], dtype=float32)
time = 48760	action = 0	current_phase = 1	next_phase = 0	reward = 0.721857	array([[ -1.8686914, -42.86288  ]], dtype=float32)
time = 48765	action = 0	current_phase = 1	next_phase = 0	reward = 0.720258	array([[ -1.8123283, -42.85396  ]], dtype=float32)
time = 48770	action = 0	current_phase = 1	next_phase = 0	reward = 0.715827	array([[ -1.8861799, -42.854084 ]], dtype=float32)
time = 48775	action = 0	current_phase = 1	next_phase = 0	reward = 0.728225	array([[ -1.8403625, -42.859493 ]], dtype=float32)
time = 48780	action = 0	current_phase = 1	next_phase = 0	reward = 0.721139	array([[ -1.8647089, -42.86211  ]], dtype=float32)
time = 48785	action = 0	current_phase = 1	next_phase = 0	reward = 0.711669	array([[ -1.8610563, -42.859486 ]], dtype=float32)
time = 48790	action = 0	current_phase = 1	next_phase = 0	reward = 0.717437	array([[ -1.8298092, -42.85736  ]], dtype=float32)
time = 48795	action = 0	current_phase = 1	next_phase = 0	reward = 0.720008	array([[ -1.8842373, -42.870884 ]], dtype=float32)
time = 48800	action = 0	current_phase = 1	next_phase = 0	reward = 0.436016	array([[ -1.8349762, -42.85398  ]], dtype=float32)
time = 48805	action = 0	current_phase = 1	next_phase = 0	reward = 1.007997	array([[ -1.8680792, -42.86087  ]], dtype=float32)
time = 48810	action = 0	current_phase = 1	next_phase = 0	reward = 0.720623	array([[ -1.8480129, -42.85457  ]], dtype=float32)
time = 48815	action = 0	current_phase = 1	next_phase = 0	reward = 0.443108	array([[ -1.8671246, -42.862213 ]], dtype=float32)
time = 48820	action = 0	current_phase = 1	next_phase = 0	reward = 1.005151	array([[ -1.8470936, -42.859005 ]], dtype=float32)
time = 48825	action = 0	current_phase = 1	next_phase = 0	reward = 0.712880	array([[ -1.888897, -42.864777]], dtype=float32)
time = 48830	action = 0	current_phase = 1	next_phase = 0	reward = 0.719298	array([[ -1.8601828, -42.856503 ]], dtype=float32)
time = 48835	action = 0	current_phase = 1	next_phase = 0	reward = 0.715560	array([[ -1.8529882, -42.86196  ]], dtype=float32)
time = 48840	action = 0	current_phase = 1	next_phase = 0	reward = 0.713764	array([[ -1.8507795, -42.862816 ]], dtype=float32)
time = 48845	action = 0	current_phase = 1	next_phase = 0	reward = 0.713454	array([[ -1.8404055, -42.856262 ]], dtype=float32)
time = 48850	action = 0	current_phase = 1	next_phase = 0	reward = 0.446799	array([[ -1.8325796, -42.85562  ]], dtype=float32)
time = 48855	action = 0	current_phase = 1	next_phase = 0	reward = 0.730234	array([[ -1.8610096, -42.864307 ]], dtype=float32)
time = 48860	action = 0	current_phase = 1	next_phase = 0	reward = 1.000648	array([[ -1.8614769, -42.86049  ]], dtype=float32)
time = 48865	action = 0	current_phase = 1	next_phase = 0	reward = 0.715561	array([[ -1.8065414, -42.850372 ]], dtype=float32)
time = 48870	action = 0	current_phase = 1	next_phase = 0	reward = 0.436291	array([[ -1.8111763, -42.86025  ]], dtype=float32)
time = 48875	action = 0	current_phase = 1	next_phase = 0	reward = 0.724419	array([[ -1.8697519, -42.861164 ]], dtype=float32)
time = 48880	action = 0	current_phase = 1	next_phase = 0	reward = 1.009123	array([[ -1.808938, -42.848637]], dtype=float32)
time = 48885	action = 0	current_phase = 1	next_phase = 0	reward = 0.721380	array([[ -1.8410883, -42.85887  ]], dtype=float32)
time = 48890	action = 0	current_phase = 1	next_phase = 0	reward = 0.447192	array([[ -1.8787079, -42.86442  ]], dtype=float32)
time = 48895	action = 0	current_phase = 1	next_phase = 0	reward = 1.000637	array([[ -1.8241358, -42.854458 ]], dtype=float32)
time = 48900	action = 0	current_phase = 1	next_phase = 0	reward = 0.723044	array([[ -1.8917112, -42.86625  ]], dtype=float32)
time = 48905	action = 0	current_phase = 1	next_phase = 0	reward = 0.720386	array([[ -1.8626003, -42.861824 ]], dtype=float32)
time = 48910	action = 0	current_phase = 1	next_phase = 0	reward = 0.719268	array([[ -1.8623247, -42.86168  ]], dtype=float32)
time = 48915	action = 0	current_phase = 1	next_phase = 0	reward = 0.717525	array([[ -1.8854647, -42.867172 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3484.1949 - val_loss: 944.5180
Epoch 2/50
 - 4s - loss: 3499.2522 - val_loss: 988.4948
Epoch 3/50
 - 4s - loss: 3476.7780 - val_loss: 938.4232
Epoch 4/50
 - 4s - loss: 3458.8060 - val_loss: 972.5262
Epoch 5/50
 - 4s - loss: 3479.5644 - val_loss: 937.4379
Epoch 6/50
 - 4s - loss: 3471.9285 - val_loss: 962.9507
Epoch 7/50
 - 4s - loss: 3471.1950 - val_loss: 935.4141
Epoch 8/50
 - 4s - loss: 3471.8437 - val_loss: 943.9661
Epoch 9/50
 - 4s - loss: 3458.1422 - val_loss: 932.2788
Epoch 10/50
 - 4s - loss: 3448.8365 - val_loss: 933.7192
Epoch 11/50
 - 4s - loss: 3459.8755 - val_loss: 952.4360
Epoch 12/50
 - 4s - loss: 3462.2127 - val_loss: 945.5363
Epoch 13/50
 - 4s - loss: 3444.9984 - val_loss: 946.1422
Epoch 14/50
 - 4s - loss: 3446.3471 - val_loss: 942.3082
Epoch 15/50
 - 4s - loss: 3444.1401 - val_loss: 938.8497
Epoch 16/50
 - 4s - loss: 3438.8940 - val_loss: 942.1147
Epoch 17/50
 - 4s - loss: 3434.0065 - val_loss: 921.7064
Epoch 18/50
 - 4s - loss: 3430.2284 - val_loss: 938.6033
Epoch 19/50
 - 4s - loss: 3425.6059 - val_loss: 929.8385
Epoch 20/50
 - 4s - loss: 3442.3780 - val_loss: 938.9530
Epoch 21/50
 - 4s - loss: 3432.8366 - val_loss: 939.7858
Epoch 22/50
 - 4s - loss: 3420.5940 - val_loss: 918.0003
Epoch 23/50
 - 4s - loss: 3435.8019 - val_loss: 913.3675
Epoch 24/50
 - 4s - loss: 3423.0920 - val_loss: 920.4847
Epoch 25/50
 - 4s - loss: 3420.4221 - val_loss: 920.9301
Epoch 26/50
 - 4s - loss: 3413.0304 - val_loss: 919.8896
Epoch 27/50
 - 4s - loss: 3420.0988 - val_loss: 916.2700
Epoch 28/50
 - 4s - loss: 3404.5869 - val_loss: 910.7469
Epoch 29/50
 - 4s - loss: 3422.1931 - val_loss: 914.5379
Epoch 30/50
 - 4s - loss: 3423.0878 - val_loss: 909.4356
Epoch 31/50
 - 4s - loss: 3395.4682 - val_loss: 912.8122
Epoch 32/50
 - 4s - loss: 3408.3735 - val_loss: 919.1672
Epoch 33/50
 - 4s - loss: 3414.8107 - val_loss: 919.1566
Epoch 34/50
 - 4s - loss: 3384.0606 - val_loss: 907.9733
Epoch 35/50
 - 4s - loss: 3420.1231 - val_loss: 902.1314
Epoch 36/50
 - 4s - loss: 3394.7986 - val_loss: 895.1123
Epoch 37/50
 - 4s - loss: 3388.7647 - val_loss: 919.5863
Epoch 38/50
 - 4s - loss: 3388.0933 - val_loss: 914.6945
Epoch 39/50
 - 4s - loss: 3406.7574 - val_loss: 926.4108
Epoch 40/50
 - 4s - loss: 3387.0266 - val_loss: 895.3855
Epoch 41/50
 - 4s - loss: 3381.1384 - val_loss: 912.1683
Epoch 42/50
 - 4s - loss: 3388.2669 - val_loss: 900.2428
Epoch 43/50
 - 4s - loss: 3388.6815 - val_loss: 900.8423
Epoch 44/50
 - 4s - loss: 3372.7875 - val_loss: 897.6380
Epoch 45/50
 - 4s - loss: 3369.5452 - val_loss: 905.3017
Epoch 46/50
 - 4s - loss: 3379.6937 - val_loss: 898.6481
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 48920	action = 0	current_phase = 1	next_phase = 0	reward = 0.714446	array([[ -1.9191713, -42.906193 ]], dtype=float32)
time = 48925	action = 0	current_phase = 1	next_phase = 0	reward = 0.722948	array([[ -1.8752546, -42.912384 ]], dtype=float32)
time = 48930	action = 0	current_phase = 1	next_phase = 0	reward = 0.721309	array([[ -1.9284353, -42.905266 ]], dtype=float32)
time = 48935	action = 0	current_phase = 1	next_phase = 0	reward = 0.731098	array([[ -1.9286442, -42.905186 ]], dtype=float32)
time = 48940	action = 0	current_phase = 1	next_phase = 0	reward = 0.731785	array([[ -1.9281502, -42.90551  ]], dtype=float32)
time = 48945	action = 0	current_phase = 1	next_phase = 0	reward = 0.726028	array([[ -1.8935804, -42.910034 ]], dtype=float32)
time = 48950	action = 0	current_phase = 1	next_phase = 0	reward = 0.727759	array([[ -1.9289627, -42.905216 ]], dtype=float32)
time = 48955	action = 0	current_phase = 1	next_phase = 0	reward = 0.729639	array([[ -1.9361677, -42.903152 ]], dtype=float32)
time = 48960	action = 0	current_phase = 1	next_phase = 0	reward = 0.716305	array([[ -1.9295359, -42.904305 ]], dtype=float32)
time = 48965	action = 0	current_phase = 1	next_phase = 0	reward = 0.719521	array([[ -1.8850546, -42.911118 ]], dtype=float32)
time = 48970	action = 0	current_phase = 1	next_phase = 0	reward = 0.713165	array([[ -1.9340343, -42.903664 ]], dtype=float32)
time = 48975	action = 0	current_phase = 1	next_phase = 0	reward = 0.441146	array([[ -1.927618, -42.904984]], dtype=float32)
time = 48980	action = 0	current_phase = 1	next_phase = 0	reward = 1.008593	array([[ -1.9196701, -42.908813 ]], dtype=float32)
time = 48985	action = 0	current_phase = 1	next_phase = 0	reward = 0.719852	array([[ -1.8998976, -42.911842 ]], dtype=float32)
time = 48990	action = 0	current_phase = 1	next_phase = 0	reward = 0.716657	array([[ -1.9092293, -42.90859  ]], dtype=float32)
time = 48995	action = 0	current_phase = 1	next_phase = 0	reward = 0.720910	array([[ -1.925169, -42.90673 ]], dtype=float32)
time = 49000	action = 0	current_phase = 1	next_phase = 0	reward = 0.437549	array([[ -1.9265041, -42.905758 ]], dtype=float32)
time = 49005	action = 0	current_phase = 1	next_phase = 0	reward = 0.996621	array([[ -1.9321089, -42.90343  ]], dtype=float32)
time = 49010	action = 0	current_phase = 1	next_phase = 0	reward = 0.168310	array([[ -1.924654, -42.90542 ]], dtype=float32)
time = 49015	action = 0	current_phase = 1	next_phase = 0	reward = 1.006616	array([[ -1.9344854, -42.904324 ]], dtype=float32)
time = 49020	action = 0	current_phase = 1	next_phase = 0	reward = 1.014506	array([[ -1.9040766, -42.908764 ]], dtype=float32)
time = 49025	action = 0	current_phase = 1	next_phase = 0	reward = 0.719365	array([[ -1.9231567, -42.90497  ]], dtype=float32)
time = 49030	action = 0	current_phase = 1	next_phase = 0	reward = 0.719616	array([[ -1.9462271, -42.900784 ]], dtype=float32)
time = 49035	action = 0	current_phase = 1	next_phase = 0	reward = 0.720316	array([[ -1.8952408, -42.910355 ]], dtype=float32)
time = 49040	action = 0	current_phase = 1	next_phase = 0	reward = 0.728139	array([[ -1.931282, -42.905167]], dtype=float32)
time = 49045	action = 0	current_phase = 1	next_phase = 0	reward = 0.723084	array([[ -1.91261 , -42.906258]], dtype=float32)
time = 49050	action = 0	current_phase = 1	next_phase = 0	reward = 0.714408	array([[ -1.9241667, -42.90535  ]], dtype=float32)
time = 49055	action = 0	current_phase = 1	next_phase = 0	reward = 0.724115	array([[ -1.9205074, -42.905415 ]], dtype=float32)
time = 49060	action = 0	current_phase = 1	next_phase = 0	reward = 0.716603	array([[ -1.899786, -42.909706]], dtype=float32)
time = 49065	action = 0	current_phase = 1	next_phase = 0	reward = 0.718359	array([[ -1.9130888, -42.90612  ]], dtype=float32)
time = 49070	action = 0	current_phase = 1	next_phase = 0	reward = 0.717639	array([[ -1.9370737, -42.902115 ]], dtype=float32)
time = 49075	action = 0	current_phase = 1	next_phase = 0	reward = 0.708364	array([[ -1.8781137, -42.91312  ]], dtype=float32)
time = 49080	action = 0	current_phase = 1	next_phase = 0	reward = 0.714913	array([[ -1.8825817, -42.911545 ]], dtype=float32)
time = 49085	action = 0	current_phase = 1	next_phase = 0	reward = 0.443361	array([[ -1.9296627, -42.90487  ]], dtype=float32)
time = 49090	action = 0	current_phase = 1	next_phase = 0	reward = 1.002792	array([[ -1.8603554, -42.915276 ]], dtype=float32)
time = 49095	action = 0	current_phase = 1	next_phase = 0	reward = 0.453201	array([[ -1.9406652, -42.901997 ]], dtype=float32)
time = 49100	action = 0	current_phase = 1	next_phase = 0	reward = 0.450692	array([[ -1.8857365, -42.912346 ]], dtype=float32)
time = 49105	action = 0	current_phase = 1	next_phase = 0	reward = 1.281626	array([[ -1.9355545, -42.903305 ]], dtype=float32)
time = 49110	action = 0	current_phase = 1	next_phase = 0	reward = 0.444279	array([[ -1.9348574, -42.902317 ]], dtype=float32)
time = 49115	action = 0	current_phase = 1	next_phase = 0	reward = 1.003123	array([[ -1.9319496, -42.90429  ]], dtype=float32)
time = 49120	action = 0	current_phase = 1	next_phase = 0	reward = 0.717556	array([[ -1.8758402, -42.91357  ]], dtype=float32)
time = 49125	action = 0	current_phase = 1	next_phase = 0	reward = 0.716061	array([[ -1.9080477, -42.90971  ]], dtype=float32)
time = 49130	action = 0	current_phase = 1	next_phase = 0	reward = 0.716229	array([[ -1.9050064, -42.90825  ]], dtype=float32)
time = 49135	action = 0	current_phase = 1	next_phase = 0	reward = 0.716990	array([[ -1.9247952, -42.907433 ]], dtype=float32)
time = 49140	action = 0	current_phase = 1	next_phase = 0	reward = 0.447155	array([[ -1.8811226, -42.91462  ]], dtype=float32)
time = 49145	action = 0	current_phase = 1	next_phase = 0	reward = 1.013014	array([[ -1.9321146, -42.903618 ]], dtype=float32)
time = 49150	action = 0	current_phase = 1	next_phase = 0	reward = 0.715203	array([[ -1.8871384, -42.912727 ]], dtype=float32)
time = 49155	action = 0	current_phase = 1	next_phase = 0	reward = 0.714983	array([[ -1.9288921, -42.90486  ]], dtype=float32)
time = 49160	action = 0	current_phase = 1	next_phase = 0	reward = 0.719202	array([[ -1.9219913, -42.905125 ]], dtype=float32)
time = 49165	action = 0	current_phase = 1	next_phase = 0	reward = 0.725830	array([[ -1.9308815, -42.904003 ]], dtype=float32)
time = 49170	action = 0	current_phase = 1	next_phase = 0	reward = 0.725040	array([[ -1.9112673, -42.907616 ]], dtype=float32)
time = 49175	action = 0	current_phase = 1	next_phase = 0	reward = 0.715912	array([[ -1.940299, -42.90227 ]], dtype=float32)
time = 49180	action = 0	current_phase = 1	next_phase = 0	reward = 0.723646	array([[ -1.9380398, -42.902184 ]], dtype=float32)
time = 49185	action = 0	current_phase = 1	next_phase = 0	reward = 0.725584	array([[ -1.9308386, -42.90374  ]], dtype=float32)
time = 49190	action = 0	current_phase = 1	next_phase = 0	reward = 0.722574	array([[ -1.922966, -42.906403]], dtype=float32)
time = 49195	action = 0	current_phase = 1	next_phase = 0	reward = 0.714969	array([[ -1.9340534, -42.903343 ]], dtype=float32)
time = 49200	action = 0	current_phase = 1	next_phase = 0	reward = 0.437931	array([[ -1.9367285, -42.9028   ]], dtype=float32)
time = 49205	action = 0	current_phase = 1	next_phase = 0	reward = 0.724240	array([[ -1.9163256, -42.90631  ]], dtype=float32)
time = 49210	action = 0	current_phase = 1	next_phase = 0	reward = 1.006456	array([[ -1.9080181, -42.907608 ]], dtype=float32)
time = 49215	action = 0	current_phase = 1	next_phase = 0	reward = 0.728377	array([[ -1.8950138, -42.909035 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3715.2727 - val_loss: 1378.3680
Epoch 2/50
 - 4s - loss: 3719.4810 - val_loss: 1358.7588
Epoch 3/50
 - 4s - loss: 3730.8836 - val_loss: 1362.6018
Epoch 4/50
 - 4s - loss: 3723.5109 - val_loss: 1355.8556
Epoch 5/50
 - 4s - loss: 3723.9947 - val_loss: 1341.6942
Epoch 6/50
 - 4s - loss: 3718.5187 - val_loss: 1339.4295
Epoch 7/50
 - 4s - loss: 3707.4638 - val_loss: 1361.5886
Epoch 8/50
 - 4s - loss: 3701.6718 - val_loss: 1386.0743
Epoch 9/50
 - 4s - loss: 3691.4957 - val_loss: 1337.5374
Epoch 10/50
 - 4s - loss: 3695.6403 - val_loss: 1342.8778
Epoch 11/50
 - 4s - loss: 3689.0445 - val_loss: 1345.4211
Epoch 12/50
 - 4s - loss: 3704.5937 - val_loss: 1338.3801
Epoch 13/50
 - 4s - loss: 3683.0217 - val_loss: 1343.7217
Epoch 14/50
 - 4s - loss: 3692.1227 - val_loss: 1326.9203
Epoch 15/50
 - 4s - loss: 3692.3145 - val_loss: 1334.4195
Epoch 16/50
 - 4s - loss: 3670.8146 - val_loss: 1335.2211
Epoch 17/50
 - 4s - loss: 3672.7162 - val_loss: 1322.5633
Epoch 18/50
 - 4s - loss: 3673.4913 - val_loss: 1326.3280
Epoch 19/50
 - 4s - loss: 3663.1187 - val_loss: 1337.3883
Epoch 20/50
 - 4s - loss: 3662.4085 - val_loss: 1309.7426
Epoch 21/50
 - 4s - loss: 3675.3891 - val_loss: 1347.4774
Epoch 22/50
 - 4s - loss: 3649.3725 - val_loss: 1315.8007
Epoch 23/50
 - 4s - loss: 3661.2793 - val_loss: 1330.3043
Epoch 24/50
 - 4s - loss: 3656.0912 - val_loss: 1313.1857
Epoch 25/50
 - 4s - loss: 3651.9223 - val_loss: 1307.8559
Epoch 26/50
 - 4s - loss: 3651.7388 - val_loss: 1344.9117
Epoch 27/50
 - 4s - loss: 3647.0715 - val_loss: 1322.9448
Epoch 28/50
 - 4s - loss: 3642.5388 - val_loss: 1299.8854
Epoch 29/50
 - 4s - loss: 3630.8018 - val_loss: 1317.1168
Epoch 30/50
 - 4s - loss: 3644.9469 - val_loss: 1336.7402
Epoch 31/50
 - 4s - loss: 3643.9197 - val_loss: 1305.7239
Epoch 32/50
 - 4s - loss: 3624.6571 - val_loss: 1306.3287
Epoch 33/50
 - 4s - loss: 3623.4253 - val_loss: 1308.4273
Epoch 34/50
 - 4s - loss: 3625.9471 - val_loss: 1304.4445
Epoch 35/50
 - 4s - loss: 3624.2997 - val_loss: 1319.4415
Epoch 36/50
 - 4s - loss: 3617.9663 - val_loss: 1305.4942
Epoch 37/50
 - 4s - loss: 3610.6823 - val_loss: 1311.9103
Epoch 38/50
 - 4s - loss: 3621.1380 - val_loss: 1284.6518
Epoch 39/50
 - 4s - loss: 3612.9694 - val_loss: 1305.9689
Epoch 40/50
 - 4s - loss: 3604.7341 - val_loss: 1293.2995
Epoch 41/50
 - 4s - loss: 3613.5362 - val_loss: 1307.1310
Epoch 42/50
 - 4s - loss: 3601.2558 - val_loss: 1291.2434
Epoch 43/50
 - 4s - loss: 3601.2551 - val_loss: 1297.0052
Epoch 44/50
 - 4s - loss: 3604.9714 - val_loss: 1306.0268
Epoch 45/50
 - 4s - loss: 3591.1701 - val_loss: 1295.4183
Epoch 46/50
 - 4s - loss: 3580.7204 - val_loss: 1301.3176
Epoch 47/50
 - 4s - loss: 3594.5554 - val_loss: 1283.0292
Epoch 48/50
 - 4s - loss: 3612.0310 - val_loss: 1281.7639
Epoch 49/50
 - 4s - loss: 3575.7683 - val_loss: 1300.1190
Epoch 50/50
 - 4s - loss: 3574.5522 - val_loss: 1278.3154
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 49220	action = 0	current_phase = 1	next_phase = 0	reward = 0.718409	array([[ -1.8955679, -42.95499  ]], dtype=float32)
time = 49225	action = 0	current_phase = 1	next_phase = 0	reward = 0.721530	array([[ -1.8354836, -42.957413 ]], dtype=float32)
time = 49230	action = 0	current_phase = 1	next_phase = 0	reward = 0.717139	array([[ -1.8271627, -42.96429  ]], dtype=float32)
time = 49235	action = 0	current_phase = 1	next_phase = 0	reward = 0.442917	array([[ -1.8008003, -42.96607  ]], dtype=float32)
time = 49240	action = 0	current_phase = 1	next_phase = 0	reward = 1.006262	array([[ -1.8545446, -42.957275 ]], dtype=float32)
time = 49245	action = 0	current_phase = 1	next_phase = 0	reward = 0.720866	array([[ -1.8119202, -42.95841  ]], dtype=float32)
time = 49250	action = 0	current_phase = 1	next_phase = 0	reward = 0.715793	array([[ -1.8470716, -42.957508 ]], dtype=float32)
time = 49255	action = 0	current_phase = 1	next_phase = 0	reward = 0.432869	array([[ -1.8638525, -42.961067 ]], dtype=float32)
time = 49260	action = 0	current_phase = 1	next_phase = 0	reward = 0.723374	array([[ -1.7858477, -42.957733 ]], dtype=float32)
time = 49265	action = 0	current_phase = 1	next_phase = 0	reward = 0.730404	array([[ -1.8786707, -42.95595  ]], dtype=float32)
time = 49270	action = 0	current_phase = 1	next_phase = 0	reward = 1.005362	array([[ -1.824029, -42.95736 ]], dtype=float32)
time = 49275	action = 0	current_phase = 1	next_phase = 0	reward = 0.723250	array([[ -1.8542547, -42.959324 ]], dtype=float32)
time = 49280	action = 0	current_phase = 1	next_phase = 0	reward = 0.722210	array([[ -1.8534269, -42.95983  ]], dtype=float32)
time = 49285	action = 0	current_phase = 1	next_phase = 0	reward = 0.710579	array([[ -1.862668, -42.953445]], dtype=float32)
time = 49290	action = 0	current_phase = 1	next_phase = 0	reward = 0.713007	array([[ -1.7835045, -42.959682 ]], dtype=float32)
time = 49295	action = 0	current_phase = 1	next_phase = 0	reward = 0.728536	array([[ -1.7906609, -42.962807 ]], dtype=float32)
time = 49300	action = 0	current_phase = 1	next_phase = 0	reward = 0.729401	array([[ -1.8158779, -42.96039  ]], dtype=float32)
time = 49305	action = 0	current_phase = 1	next_phase = 0	reward = 0.726459	array([[ -1.8215094, -42.960052 ]], dtype=float32)
time = 49310	action = 0	current_phase = 1	next_phase = 0	reward = 0.729752	array([[ -1.863759, -42.958164]], dtype=float32)
time = 49315	action = 0	current_phase = 1	next_phase = 0	reward = 0.726346	array([[ -1.8602886, -42.9556   ]], dtype=float32)
time = 49320	action = 0	current_phase = 1	next_phase = 0	reward = 0.723421	array([[ -1.8147554, -42.958355 ]], dtype=float32)
time = 49325	action = 0	current_phase = 1	next_phase = 0	reward = 0.719609	array([[ -1.7942867, -42.960876 ]], dtype=float32)
time = 49330	action = 0	current_phase = 1	next_phase = 0	reward = 0.712039	array([[ -1.833416, -42.96012 ]], dtype=float32)
time = 49335	action = 0	current_phase = 1	next_phase = 0	reward = 0.442653	array([[ -1.8700352, -42.95537  ]], dtype=float32)
time = 49340	action = 0	current_phase = 1	next_phase = 0	reward = 1.014210	array([[ -1.853795, -42.957764]], dtype=float32)
time = 49345	action = 0	current_phase = 1	next_phase = 0	reward = 0.720804	array([[ -1.840354, -42.957596]], dtype=float32)
time = 49350	action = 0	current_phase = 1	next_phase = 0	reward = 0.706631	array([[ -1.8394852, -42.961113 ]], dtype=float32)
time = 49355	action = 0	current_phase = 1	next_phase = 0	reward = 0.442603	array([[ -1.8453112, -42.96065  ]], dtype=float32)
time = 49360	action = 0	current_phase = 1	next_phase = 0	reward = 0.725451	array([[ -1.8367853, -42.9579   ]], dtype=float32)
time = 49365	action = 0	current_phase = 1	next_phase = 0	reward = 0.992227	array([[ -1.8262482, -42.949623 ]], dtype=float32)
time = 49370	action = 0	current_phase = 1	next_phase = 0	reward = 0.716626	array([[ -1.8335476, -42.95942  ]], dtype=float32)
time = 49375	action = 0	current_phase = 1	next_phase = 0	reward = 0.723799	array([[ -1.8040104, -42.95672  ]], dtype=float32)
time = 49380	action = 0	current_phase = 1	next_phase = 0	reward = 0.717996	array([[ -1.8265123, -42.967743 ]], dtype=float32)
time = 49385	action = 0	current_phase = 1	next_phase = 0	reward = 0.713840	array([[ -1.8411818, -42.958714 ]], dtype=float32)
time = 49390	action = 0	current_phase = 1	next_phase = 0	reward = 0.714490	array([[ -1.8525009, -42.962875 ]], dtype=float32)
time = 49395	action = 0	current_phase = 1	next_phase = 0	reward = 0.719057	array([[ -1.7979603, -42.962723 ]], dtype=float32)
time = 49400	action = 0	current_phase = 1	next_phase = 0	reward = 0.451993	array([[ -1.7798367, -42.955654 ]], dtype=float32)
time = 49405	action = 0	current_phase = 1	next_phase = 0	reward = 1.001046	array([[ -1.8714314, -42.956856 ]], dtype=float32)
time = 49410	action = 0	current_phase = 1	next_phase = 0	reward = 0.443599	array([[ -1.8525343, -42.96207  ]], dtype=float32)
time = 49415	action = 0	current_phase = 1	next_phase = 0	reward = 1.005996	array([[ -1.86376 , -42.955395]], dtype=float32)
time = 49420	action = 0	current_phase = 1	next_phase = 0	reward = 0.719878	array([[ -1.8527079, -42.958103 ]], dtype=float32)
time = 49425	action = 0	current_phase = 1	next_phase = 0	reward = 0.720547	array([[ -1.7767124, -42.962185 ]], dtype=float32)
time = 49430	action = 0	current_phase = 1	next_phase = 0	reward = 0.724743	array([[ -1.8939476, -42.95465  ]], dtype=float32)
time = 49435	action = 0	current_phase = 1	next_phase = 0	reward = 0.729606	array([[ -1.8467884, -42.958904 ]], dtype=float32)
time = 49440	action = 0	current_phase = 1	next_phase = 0	reward = 0.715406	array([[ -1.8649492, -42.959774 ]], dtype=float32)
time = 49445	action = 0	current_phase = 1	next_phase = 0	reward = 0.716918	array([[ -1.8828754, -42.955437 ]], dtype=float32)
time = 49450	action = 0	current_phase = 1	next_phase = 0	reward = 0.442570	array([[ -1.8268013, -42.95979  ]], dtype=float32)
time = 49455	action = 0	current_phase = 1	next_phase = 0	reward = 1.006048	array([[ -1.7798367, -42.958256 ]], dtype=float32)
time = 49460	action = 0	current_phase = 1	next_phase = 0	reward = 0.730019	array([[ -1.8745184, -42.95811  ]], dtype=float32)
time = 49465	action = 0	current_phase = 1	next_phase = 0	reward = 0.725355	array([[ -1.8957605, -42.953728 ]], dtype=float32)
time = 49470	action = 0	current_phase = 1	next_phase = 0	reward = 0.720890	array([[ -1.8099546, -42.96001  ]], dtype=float32)
time = 49475	action = 0	current_phase = 1	next_phase = 0	reward = 0.716382	array([[ -1.8384151, -42.96232  ]], dtype=float32)
time = 49480	action = 0	current_phase = 1	next_phase = 0	reward = 0.708874	array([[ -1.7923756, -42.958027 ]], dtype=float32)
time = 49485	action = 0	current_phase = 1	next_phase = 0	reward = 0.715889	array([[ -1.8295317, -42.95963  ]], dtype=float32)
time = 49490	action = 0	current_phase = 1	next_phase = 0	reward = 0.445238	array([[ -1.8490877, -42.958538 ]], dtype=float32)
time = 49495	action = 0	current_phase = 1	next_phase = 0	reward = 1.003215	array([[ -1.8406019, -42.95619  ]], dtype=float32)
time = 49500	action = 0	current_phase = 1	next_phase = 0	reward = 0.723361	array([[ -1.8685961, -42.959225 ]], dtype=float32)
time = 49505	action = 0	current_phase = 1	next_phase = 0	reward = 0.735471	array([[ -1.8501043, -42.960297 ]], dtype=float32)
time = 49510	action = 0	current_phase = 1	next_phase = 0	reward = 0.725978	array([[ -1.8723164, -42.955128 ]], dtype=float32)
time = 49515	action = 0	current_phase = 1	next_phase = 0	reward = 0.722293	array([[ -1.8657131, -42.959774 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2053.6262 - val_loss: 5438.3135
Epoch 2/50
 - 4s - loss: 2028.7982 - val_loss: 5413.9342
Epoch 3/50
 - 4s - loss: 2015.6539 - val_loss: 5427.0059
Epoch 4/50
 - 4s - loss: 2028.0771 - val_loss: 5433.0773
Epoch 5/50
 - 4s - loss: 2010.3334 - val_loss: 5415.8407
Epoch 6/50
 - 4s - loss: 1997.7797 - val_loss: 5423.3826
Epoch 7/50
 - 4s - loss: 2000.9911 - val_loss: 5423.9508
Epoch 8/50
 - 4s - loss: 1983.3288 - val_loss: 5430.6699
Epoch 9/50
 - 4s - loss: 1987.5861 - val_loss: 5407.7310
Epoch 10/50
 - 4s - loss: 1981.8485 - val_loss: 5396.3401
Epoch 11/50
 - 4s - loss: 2000.3544 - val_loss: 5397.5090
Epoch 12/50
 - 4s - loss: 1976.3017 - val_loss: 5413.1016
Epoch 13/50
 - 4s - loss: 1978.7934 - val_loss: 5418.4283
Epoch 14/50
 - 4s - loss: 1969.1624 - val_loss: 5405.4534
Epoch 15/50
 - 4s - loss: 1965.0407 - val_loss: 5415.4282
Epoch 16/50
 - 4s - loss: 1970.6707 - val_loss: 5419.3800
Epoch 17/50
 - 4s - loss: 1972.7618 - val_loss: 5398.8946
Epoch 18/50
 - 4s - loss: 1974.6178 - val_loss: 5412.6721
Epoch 19/50
 - 4s - loss: 1961.6225 - val_loss: 5394.3895
Epoch 20/50
 - 4s - loss: 1958.4470 - val_loss: 5392.0783
Epoch 21/50
 - 4s - loss: 1946.3106 - val_loss: 5382.2286
Epoch 22/50
 - 4s - loss: 1942.2552 - val_loss: 5395.3579
Epoch 23/50
 - 4s - loss: 1941.6448 - val_loss: 5382.3536
Epoch 24/50
 - 4s - loss: 1940.2257 - val_loss: 5398.5072
Epoch 25/50
 - 4s - loss: 1954.0512 - val_loss: 5392.0516
Epoch 26/50
 - 4s - loss: 1936.0810 - val_loss: 5361.6242
Epoch 27/50
 - 4s - loss: 1929.5447 - val_loss: 5366.5990
Epoch 28/50
 - 4s - loss: 1927.9985 - val_loss: 5382.1962
Epoch 29/50
 - 4s - loss: 1923.9313 - val_loss: 5358.3761
Epoch 30/50
 - 4s - loss: 1923.4361 - val_loss: 5385.1405
Epoch 31/50
 - 4s - loss: 1918.1918 - val_loss: 5378.2548
Epoch 32/50
 - 4s - loss: 1909.6495 - val_loss: 5378.7364
Epoch 33/50
 - 4s - loss: 1916.8715 - val_loss: 5376.1836
Epoch 34/50
 - 4s - loss: 1907.5489 - val_loss: 5356.5594
Epoch 35/50
 - 4s - loss: 1896.3748 - val_loss: 5372.5960
Epoch 36/50
 - 4s - loss: 1914.0460 - val_loss: 5361.4566
Epoch 37/50
 - 4s - loss: 1908.6442 - val_loss: 5347.3506
Epoch 38/50
 - 4s - loss: 1896.5330 - val_loss: 5356.2148
Epoch 39/50
 - 4s - loss: 1898.6318 - val_loss: 5357.9080
Epoch 40/50
 - 4s - loss: 1897.9868 - val_loss: 5356.2333
Epoch 41/50
 - 4s - loss: 1885.1308 - val_loss: 5369.3698
Epoch 42/50
 - 4s - loss: 1890.9392 - val_loss: 5344.8172
Epoch 43/50
 - 4s - loss: 1881.3424 - val_loss: 5361.0316
Epoch 44/50
 - 4s - loss: 1879.1276 - val_loss: 5350.4889
Epoch 45/50
 - 4s - loss: 1876.9459 - val_loss: 5342.3850
Epoch 46/50
 - 4s - loss: 1880.5993 - val_loss: 5359.1728
Epoch 47/50
 - 4s - loss: 1883.7300 - val_loss: 5334.8240
Epoch 48/50
 - 4s - loss: 1856.6568 - val_loss: 5354.2686
Epoch 49/50
 - 4s - loss: 1870.2045 - val_loss: 5337.0360
Epoch 50/50
 - 4s - loss: 1865.1489 - val_loss: 5346.0259
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 49520	action = 0	current_phase = 1	next_phase = 0	reward = 0.725612	array([[ -1.8445959, -43.00863  ]], dtype=float32)
time = 49525	action = 0	current_phase = 1	next_phase = 0	reward = 0.719238	array([[ -1.8039122, -43.00686  ]], dtype=float32)
time = 49530	action = 0	current_phase = 1	next_phase = 0	reward = 0.723705	array([[ -1.7766304, -43.010216 ]], dtype=float32)
time = 49535	action = 0	current_phase = 1	next_phase = 0	reward = 0.722301	array([[ -1.8502388, -43.01196  ]], dtype=float32)
time = 49540	action = 0	current_phase = 1	next_phase = 0	reward = 0.713261	array([[ -1.8491707, -43.013565 ]], dtype=float32)
time = 49545	action = 0	current_phase = 1	next_phase = 0	reward = 0.446106	array([[ -1.8036356, -43.005608 ]], dtype=float32)
time = 49550	action = 0	current_phase = 1	next_phase = 0	reward = 1.008673	array([[ -1.8089142, -43.005505 ]], dtype=float32)
time = 49555	action = 0	current_phase = 1	next_phase = 0	reward = 0.723523	array([[ -1.80266 , -43.013275]], dtype=float32)
time = 49560	action = 0	current_phase = 1	next_phase = 0	reward = 0.719884	array([[ -1.831111, -43.013405]], dtype=float32)
time = 49565	action = 0	current_phase = 1	next_phase = 0	reward = 0.435434	array([[ -1.8305874, -43.008938 ]], dtype=float32)
time = 49570	action = 0	current_phase = 1	next_phase = 0	reward = 0.719416	array([[ -1.7967758, -43.00866  ]], dtype=float32)
time = 49575	action = 0	current_phase = 1	next_phase = 0	reward = 0.720363	array([[ -1.7648573, -42.99994  ]], dtype=float32)
time = 49580	action = 0	current_phase = 1	next_phase = 0	reward = 0.717503	array([[ -1.8613482, -43.01512  ]], dtype=float32)
time = 49585	action = 0	current_phase = 1	next_phase = 0	reward = 1.004469	array([[ -1.8330784, -43.012844 ]], dtype=float32)
time = 49590	action = 0	current_phase = 1	next_phase = 0	reward = 0.719679	array([[ -1.855298, -43.01544 ]], dtype=float32)
time = 49595	action = 0	current_phase = 1	next_phase = 0	reward = 0.717705	array([[ -1.8072796, -43.001205 ]], dtype=float32)
time = 49600	action = 0	current_phase = 1	next_phase = 0	reward = 0.714640	array([[ -1.8078794, -43.00338  ]], dtype=float32)
time = 49605	action = 0	current_phase = 1	next_phase = 0	reward = 0.722938	array([[ -1.812726, -43.00982 ]], dtype=float32)
time = 49610	action = 0	current_phase = 1	next_phase = 0	reward = 0.723416	array([[ -1.7997627, -43.003204 ]], dtype=float32)
time = 49615	action = 0	current_phase = 1	next_phase = 0	reward = 0.716217	array([[ -1.8342333, -43.02034  ]], dtype=float32)
time = 49620	action = 0	current_phase = 1	next_phase = 0	reward = 0.715819	array([[ -1.8086977, -43.006714 ]], dtype=float32)
time = 49625	action = 0	current_phase = 1	next_phase = 0	reward = 0.439619	array([[ -1.844656, -43.01326 ]], dtype=float32)
time = 49630	action = 0	current_phase = 1	next_phase = 0	reward = 1.004049	array([[ -1.8160801, -43.005684 ]], dtype=float32)
time = 49635	action = 0	current_phase = 1	next_phase = 0	reward = 0.728517	array([[ -1.8442183, -43.0101   ]], dtype=float32)
time = 49640	action = 0	current_phase = 1	next_phase = 0	reward = 0.718124	array([[ -1.8248396, -43.01349  ]], dtype=float32)
time = 49645	action = 0	current_phase = 1	next_phase = 0	reward = 0.716180	array([[ -1.835042, -43.012356]], dtype=float32)
time = 49650	action = 0	current_phase = 1	next_phase = 0	reward = 0.715908	array([[ -1.8045826, -43.011787 ]], dtype=float32)
time = 49655	action = 0	current_phase = 1	next_phase = 0	reward = 0.443241	array([[ -1.8661308, -43.00843  ]], dtype=float32)
time = 49660	action = 0	current_phase = 1	next_phase = 0	reward = 0.727348	array([[ -1.8096828, -43.00597  ]], dtype=float32)
time = 49665	action = 0	current_phase = 1	next_phase = 0	reward = 1.004380	array([[ -1.8056126, -43.005955 ]], dtype=float32)
time = 49670	action = 0	current_phase = 1	next_phase = 0	reward = 0.716828	array([[ -1.818141, -43.00905 ]], dtype=float32)
time = 49675	action = 0	current_phase = 1	next_phase = 0	reward = 0.719806	array([[ -1.8480463, -43.010883 ]], dtype=float32)
time = 49680	action = 0	current_phase = 1	next_phase = 0	reward = 0.728322	array([[ -1.8586283, -43.014324 ]], dtype=float32)
time = 49685	action = 0	current_phase = 1	next_phase = 0	reward = 0.728520	array([[ -1.8497362, -43.012592 ]], dtype=float32)
time = 49690	action = 0	current_phase = 1	next_phase = 0	reward = 0.713210	array([[ -1.8558083, -43.01427  ]], dtype=float32)
time = 49695	action = 0	current_phase = 1	next_phase = 0	reward = 0.717554	array([[ -1.8554239, -43.017876 ]], dtype=float32)
time = 49700	action = 0	current_phase = 1	next_phase = 0	reward = 0.718273	array([[ -1.8105068, -43.010345 ]], dtype=float32)
time = 49705	action = 0	current_phase = 1	next_phase = 0	reward = 0.720059	array([[ -1.8483105, -43.00457  ]], dtype=float32)
time = 49710	action = 0	current_phase = 1	next_phase = 0	reward = 0.443088	array([[ -1.8023233, -43.009132 ]], dtype=float32)
time = 49715	action = 0	current_phase = 1	next_phase = 0	reward = 0.995636	array([[ -1.8598948, -43.01313  ]], dtype=float32)
time = 49720	action = 0	current_phase = 1	next_phase = 0	reward = 0.715699	array([[ -1.8311329, -43.005753 ]], dtype=float32)
time = 49725	action = 0	current_phase = 1	next_phase = 0	reward = 0.448116	array([[ -1.8417025, -43.02151  ]], dtype=float32)
time = 49730	action = 0	current_phase = 1	next_phase = 0	reward = 1.003085	array([[ -1.822093, -43.009674]], dtype=float32)
time = 49735	action = 0	current_phase = 1	next_phase = 0	reward = 0.719244	array([[ -1.8311901, -43.0119   ]], dtype=float32)
time = 49740	action = 0	current_phase = 1	next_phase = 0	reward = 0.722577	array([[ -1.856533, -43.012352]], dtype=float32)
time = 49745	action = 0	current_phase = 1	next_phase = 0	reward = 0.719951	array([[ -1.7894688, -43.010902 ]], dtype=float32)
time = 49750	action = 0	current_phase = 1	next_phase = 0	reward = 0.719923	array([[ -1.8037062, -43.005844 ]], dtype=float32)
time = 49755	action = 0	current_phase = 1	next_phase = 0	reward = 0.718818	array([[ -1.8485031, -43.00911  ]], dtype=float32)
time = 49760	action = 0	current_phase = 1	next_phase = 0	reward = 0.442660	array([[ -1.8501186, -43.011528 ]], dtype=float32)
time = 49765	action = 0	current_phase = 1	next_phase = 0	reward = 1.000532	array([[ -1.8727789, -43.017445 ]], dtype=float32)
time = 49770	action = 0	current_phase = 1	next_phase = 0	reward = 0.714627	array([[ -1.8265533, -43.0111   ]], dtype=float32)
time = 49775	action = 0	current_phase = 1	next_phase = 0	reward = 0.436620	array([[ -1.8639803, -43.014088 ]], dtype=float32)
time = 49780	action = 0	current_phase = 1	next_phase = 0	reward = 0.726301	array([[ -1.8421688, -43.012688 ]], dtype=float32)
time = 49785	action = 0	current_phase = 1	next_phase = 0	reward = 0.724230	array([[ -1.8441744, -43.00957  ]], dtype=float32)
time = 49790	action = 0	current_phase = 1	next_phase = 0	reward = 0.997540	array([[ -1.8376989, -43.013382 ]], dtype=float32)
time = 49795	action = 0	current_phase = 1	next_phase = 0	reward = 0.716691	array([[ -1.8125324, -43.014275 ]], dtype=float32)
time = 49800	action = 0	current_phase = 1	next_phase = 0	reward = 0.719325	array([[ -1.7709732, -42.994984 ]], dtype=float32)
time = 49805	action = 0	current_phase = 1	next_phase = 0	reward = 0.441190	array([[ -1.8433237, -43.01484  ]], dtype=float32)
time = 49810	action = 0	current_phase = 1	next_phase = 0	reward = 1.000882	array([[ -1.8622437, -43.013344 ]], dtype=float32)
time = 49815	action = 0	current_phase = 1	next_phase = 0	reward = 0.718759	array([[ -1.8337002, -43.006958 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2875.0484 - val_loss: 2485.3083
Epoch 2/50
 - 4s - loss: 2863.2487 - val_loss: 2443.7847
Epoch 3/50
 - 4s - loss: 2876.1165 - val_loss: 2439.1759
Epoch 4/50
 - 4s - loss: 2864.8360 - val_loss: 2451.0635
Epoch 5/50
 - 4s - loss: 2851.7004 - val_loss: 2427.9018
Epoch 6/50
 - 4s - loss: 2861.4240 - val_loss: 2432.0676
Epoch 7/50
 - 4s - loss: 2859.7342 - val_loss: 2425.3457
Epoch 8/50
 - 4s - loss: 2860.5278 - val_loss: 2426.7569
Epoch 9/50
 - 4s - loss: 2842.8598 - val_loss: 2416.7487
Epoch 10/50
 - 4s - loss: 2852.5423 - val_loss: 2418.6053
Epoch 11/50
 - 4s - loss: 2832.4907 - val_loss: 2415.6236
Epoch 12/50
 - 4s - loss: 2841.8408 - val_loss: 2414.6696
Epoch 13/50
 - 4s - loss: 2834.9203 - val_loss: 2429.8037
Epoch 14/50
 - 4s - loss: 2841.2292 - val_loss: 2395.7872
Epoch 15/50
 - 4s - loss: 2842.3257 - val_loss: 2396.4225
Epoch 16/50
 - 4s - loss: 2832.5991 - val_loss: 2400.0938
Epoch 17/50
 - 4s - loss: 2833.5670 - val_loss: 2392.2932
Epoch 18/50
 - 4s - loss: 2826.9316 - val_loss: 2389.1458
Epoch 19/50
 - 4s - loss: 2836.2972 - val_loss: 2397.8568
Epoch 20/50
 - 4s - loss: 2816.1994 - val_loss: 2395.9876
Epoch 21/50
 - 4s - loss: 2820.1564 - val_loss: 2374.5682
Epoch 22/50
 - 4s - loss: 2814.9958 - val_loss: 2391.9705
Epoch 23/50
 - 4s - loss: 2817.4680 - val_loss: 2370.9111
Epoch 24/50
 - 4s - loss: 2817.7225 - val_loss: 2366.8454
Epoch 25/50
 - 4s - loss: 2813.7442 - val_loss: 2376.2069
Epoch 26/50
 - 4s - loss: 2805.4066 - val_loss: 2370.8897
Epoch 27/50
 - 4s - loss: 2804.5015 - val_loss: 2371.8862
Epoch 28/50
 - 4s - loss: 2798.6475 - val_loss: 2354.4062
Epoch 29/50
 - 4s - loss: 2799.3124 - val_loss: 2345.7072
Epoch 30/50
 - 4s - loss: 2798.9734 - val_loss: 2343.9984
Epoch 31/50
 - 4s - loss: 2795.3657 - val_loss: 2344.2928
Epoch 32/50
 - 4s - loss: 2795.8306 - val_loss: 2340.2796
Epoch 33/50
 - 4s - loss: 2785.7349 - val_loss: 2339.0892
Epoch 34/50
 - 4s - loss: 2782.8045 - val_loss: 2369.7322
Epoch 35/50
 - 4s - loss: 2793.8349 - val_loss: 2343.1374
Epoch 36/50
 - 4s - loss: 2791.3827 - val_loss: 2345.7623
Epoch 37/50
 - 4s - loss: 2782.7120 - val_loss: 2353.6405
Epoch 38/50
 - 4s - loss: 2790.5446 - val_loss: 2334.4020
Epoch 39/50
 - 4s - loss: 2779.2619 - val_loss: 2316.0076
Epoch 40/50
 - 4s - loss: 2781.0325 - val_loss: 2317.5131
Epoch 41/50
 - 4s - loss: 2783.2261 - val_loss: 2311.9868
Epoch 42/50
 - 4s - loss: 2768.3433 - val_loss: 2328.2693
Epoch 43/50
 - 4s - loss: 2776.1796 - val_loss: 2315.8555
Epoch 44/50
 - 4s - loss: 2775.9742 - val_loss: 2312.5931
Epoch 45/50
 - 4s - loss: 2772.4983 - val_loss: 2300.4393
Epoch 46/50
 - 4s - loss: 2762.7095 - val_loss: 2303.8712
Epoch 47/50
 - 4s - loss: 2771.6678 - val_loss: 2294.4035
Epoch 48/50
 - 4s - loss: 2761.4966 - val_loss: 2290.2954
Epoch 49/50
 - 4s - loss: 2760.9945 - val_loss: 2282.5047
Epoch 50/50
 - 4s - loss: 2756.1298 - val_loss: 2293.1736
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 49820	action = 0	current_phase = 1	next_phase = 0	reward = 0.716103	array([[ -0.8392515, -43.114124 ]], dtype=float32)
time = 49825	action = 0	current_phase = 1	next_phase = 0	reward = 0.450768	array([[ -0.90258217, -43.12903   ]], dtype=float32)
time = 49830	action = 0	current_phase = 1	next_phase = 0	reward = 1.009009	array([[ -0.89447975, -43.124733  ]], dtype=float32)
time = 49835	action = 0	current_phase = 1	next_phase = 0	reward = 0.724980	array([[ -0.8496876, -43.10453  ]], dtype=float32)
time = 49840	action = 0	current_phase = 1	next_phase = 0	reward = 0.720926	array([[ -0.8761778, -43.126335 ]], dtype=float32)
time = 49845	action = 0	current_phase = 1	next_phase = 0	reward = 0.713917	array([[ -0.87748814, -43.116203  ]], dtype=float32)
time = 49850	action = 0	current_phase = 1	next_phase = 0	reward = 0.717418	array([[ -0.84368896, -43.08313   ]], dtype=float32)
time = 49855	action = 0	current_phase = 1	next_phase = 0	reward = 0.715182	array([[ -0.8767252, -43.12735  ]], dtype=float32)
time = 49860	action = 0	current_phase = 1	next_phase = 0	reward = 0.439511	array([[ -0.88799477, -43.120277  ]], dtype=float32)
time = 49865	action = 0	current_phase = 1	next_phase = 0	reward = 1.006779	array([[ -0.8712034, -43.117073 ]], dtype=float32)
time = 49870	action = 0	current_phase = 1	next_phase = 0	reward = 0.442658	array([[ -0.8722811, -43.12367  ]], dtype=float32)
time = 49875	action = 0	current_phase = 1	next_phase = 0	reward = 1.000652	array([[ -0.8849039, -43.12449  ]], dtype=float32)
time = 49880	action = 0	current_phase = 1	next_phase = 0	reward = 0.715382	array([[ -0.90964794, -43.00276   ]], dtype=float32)
time = 49885	action = 0	current_phase = 1	next_phase = 0	reward = 0.719585	array([[ -0.88848877, -43.12398   ]], dtype=float32)
time = 49890	action = 0	current_phase = 1	next_phase = 0	reward = 0.715413	array([[ -0.8899059, -43.1255   ]], dtype=float32)
time = 49895	action = 0	current_phase = 1	next_phase = 0	reward = 0.713553	array([[ -0.85809326, -43.108536  ]], dtype=float32)
time = 49900	action = 0	current_phase = 1	next_phase = 0	reward = 0.437268	array([[ -0.84938335, -43.115402  ]], dtype=float32)
time = 49905	action = 0	current_phase = 1	next_phase = 0	reward = 1.006313	array([[ -0.8832216, -43.125534 ]], dtype=float32)
time = 49910	action = 0	current_phase = 1	next_phase = 0	reward = 0.724669	array([[ -0.84753704, -43.117085  ]], dtype=float32)
time = 49915	action = 0	current_phase = 1	next_phase = 0	reward = 0.720614	array([[ -0.8753996, -43.1274   ]], dtype=float32)
time = 49920	action = 0	current_phase = 1	next_phase = 0	reward = 0.725649	array([[ -0.87555313, -43.126404  ]], dtype=float32)
time = 49925	action = 0	current_phase = 1	next_phase = 0	reward = 0.731318	array([[ -0.8877783, -43.124092 ]], dtype=float32)
time = 49930	action = 0	current_phase = 1	next_phase = 0	reward = 0.710800	array([[ -0.8918848, -43.125023 ]], dtype=float32)
time = 49935	action = 0	current_phase = 1	next_phase = 0	reward = 0.711808	array([[ -0.8286905, -43.121464 ]], dtype=float32)
time = 49940	action = 0	current_phase = 1	next_phase = 0	reward = 0.720176	array([[ -0.8401594, -43.103127 ]], dtype=float32)
time = 49945	action = 0	current_phase = 1	next_phase = 0	reward = 0.722505	array([[ -0.8990202, -43.12781  ]], dtype=float32)
time = 49950	action = 0	current_phase = 1	next_phase = 0	reward = 0.723060	array([[ -0.8494072, -43.118927 ]], dtype=float32)
time = 49955	action = 0	current_phase = 1	next_phase = 0	reward = 0.719633	array([[ -0.9126911, -43.127045 ]], dtype=float32)
time = 49960	action = 0	current_phase = 1	next_phase = 0	reward = 0.716923	array([[ -0.79494476, -43.09642   ]], dtype=float32)
time = 49965	action = 0	current_phase = 1	next_phase = 0	reward = 0.441769	array([[ -0.83990765, -43.11843   ]], dtype=float32)
time = 49970	action = 0	current_phase = 1	next_phase = 0	reward = 1.002483	array([[ -0.89348125, -43.12642   ]], dtype=float32)
time = 49975	action = 0	current_phase = 1	next_phase = 0	reward = 0.440794	array([[ -0.87836456, -43.12478   ]], dtype=float32)
time = 49980	action = 0	current_phase = 1	next_phase = 0	reward = 1.004534	array([[ -0.87468433, -43.12597   ]], dtype=float32)
time = 49985	action = 0	current_phase = 1	next_phase = 0	reward = 0.729517	array([[ -0.89295673, -43.12812   ]], dtype=float32)
time = 49990	action = 0	current_phase = 1	next_phase = 0	reward = 0.723317	array([[ -0.83979034, -43.115234  ]], dtype=float32)
time = 49995	action = 0	current_phase = 1	next_phase = 0	reward = 0.720725	array([[ -0.8424177, -43.12103  ]], dtype=float32)
time = 50000	action = 0	current_phase = 1	next_phase = 0	reward = 0.718614	array([[ -0.8953533, -43.126152 ]], dtype=float32)
time = 50005	action = 0	current_phase = 1	next_phase = 0	reward = 0.718072	array([[ -0.8688183, -43.12652  ]], dtype=float32)
time = 50010	action = 0	current_phase = 1	next_phase = 0	reward = 0.717625	array([[ -0.85189915, -43.12472   ]], dtype=float32)
time = 50015	action = 0	current_phase = 1	next_phase = 0	reward = 0.444116	array([[ -0.893137, -43.124863]], dtype=float32)
time = 50020	action = 0	current_phase = 1	next_phase = 0	reward = 1.001743	array([[ -0.8843708, -43.12325  ]], dtype=float32)
time = 50025	action = 0	current_phase = 1	next_phase = 0	reward = 0.730256	array([[ -0.86841583, -43.121616  ]], dtype=float32)
time = 50030	action = 0	current_phase = 1	next_phase = 0	reward = 0.443467	array([[ -0.8497915, -43.10373  ]], dtype=float32)
time = 50035	action = 0	current_phase = 1	next_phase = 0	reward = 1.005899	array([[ -0.9062481, -43.12633  ]], dtype=float32)
time = 50040	action = 0	current_phase = 1	next_phase = 0	reward = 0.713736	array([[ -0.864666, -43.120724]], dtype=float32)
time = 50045	action = 0	current_phase = 1	next_phase = 0	reward = 0.721119	array([[ -0.8741627, -43.121452 ]], dtype=float32)
time = 50050	action = 0	current_phase = 1	next_phase = 0	reward = 0.719051	array([[ -0.82139015, -43.117508  ]], dtype=float32)
time = 50055	action = 0	current_phase = 1	next_phase = 0	reward = 0.709868	array([[ -0.8668661, -43.12006  ]], dtype=float32)
time = 50060	action = 0	current_phase = 1	next_phase = 0	reward = 0.443894	array([[ -0.86391735, -43.121613  ]], dtype=float32)
time = 50065	action = 0	current_phase = 1	next_phase = 0	reward = 1.000085	array([[ -0.86894226, -43.1288    ]], dtype=float32)
time = 50070	action = 0	current_phase = 1	next_phase = 0	reward = 0.719458	array([[ -0.84050846, -43.118393  ]], dtype=float32)
time = 50075	action = 0	current_phase = 1	next_phase = 0	reward = 0.445574	array([[ -0.8519039, -43.12114  ]], dtype=float32)
time = 50080	action = 0	current_phase = 1	next_phase = 0	reward = 0.734858	array([[ -0.9043274, -43.127266 ]], dtype=float32)
time = 50085	action = 0	current_phase = 1	next_phase = 0	reward = 1.007971	array([[ -0.86543083, -43.119614  ]], dtype=float32)
time = 50090	action = 0	current_phase = 1	next_phase = 0	reward = 0.722121	array([[ -0.8711786, -43.12529  ]], dtype=float32)
time = 50095	action = 0	current_phase = 1	next_phase = 0	reward = 0.720740	array([[ -0.89535236, -43.126087  ]], dtype=float32)
time = 50100	action = 0	current_phase = 1	next_phase = 0	reward = 0.717735	array([[ -0.8293171, -43.12009  ]], dtype=float32)
time = 50105	action = 0	current_phase = 1	next_phase = 0	reward = 0.445206	array([[ -0.88029957, -43.125374  ]], dtype=float32)
time = 50110	action = 0	current_phase = 1	next_phase = 0	reward = 1.006840	array([[ -0.7690935, -43.086174 ]], dtype=float32)
time = 50115	action = 0	current_phase = 1	next_phase = 0	reward = 0.722231	array([[ -0.8581743, -43.121243 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3760.8357 - val_loss: 1394.1110
Epoch 2/50
 - 4s - loss: 3743.1401 - val_loss: 1388.2093
Epoch 3/50
 - 4s - loss: 3740.5947 - val_loss: 1401.6160
Epoch 4/50
 - 4s - loss: 3740.8224 - val_loss: 1390.3345
Epoch 5/50
 - 4s - loss: 3723.4956 - val_loss: 1403.9170
Epoch 6/50
 - 4s - loss: 3740.3502 - val_loss: 1397.7884
Epoch 7/50
 - 4s - loss: 3727.1400 - val_loss: 1404.4654
Epoch 8/50
 - 4s - loss: 3721.0645 - val_loss: 1392.2381
Epoch 9/50
 - 4s - loss: 3715.8531 - val_loss: 1377.6951
Epoch 10/50
 - 4s - loss: 3717.7904 - val_loss: 1388.4242
Epoch 11/50
 - 4s - loss: 3711.9154 - val_loss: 1380.6245
Epoch 12/50
 - 4s - loss: 3704.1746 - val_loss: 1381.8622
Epoch 13/50
 - 4s - loss: 3700.8214 - val_loss: 1380.6170
Epoch 14/50
 - 4s - loss: 3693.7376 - val_loss: 1379.0978
Epoch 15/50
 - 4s - loss: 3699.7796 - val_loss: 1386.4252
Epoch 16/50
 - 4s - loss: 3691.9980 - val_loss: 1370.0596
Epoch 17/50
 - 4s - loss: 3683.5483 - val_loss: 1382.1240
Epoch 18/50
 - 4s - loss: 3688.4326 - val_loss: 1392.8281
Epoch 19/50
 - 4s - loss: 3677.3601 - val_loss: 1359.3432
Epoch 20/50
 - 4s - loss: 3679.5034 - val_loss: 1360.8001
Epoch 21/50
 - 4s - loss: 3674.9398 - val_loss: 1365.6567
Epoch 22/50
 - 4s - loss: 3677.9405 - val_loss: 1360.8922
Epoch 23/50
 - 4s - loss: 3665.9573 - val_loss: 1354.4340
Epoch 24/50
 - 4s - loss: 3666.9494 - val_loss: 1364.4918
Epoch 25/50
 - 4s - loss: 3660.9948 - val_loss: 1362.8607
Epoch 26/50
 - 4s - loss: 3664.1156 - val_loss: 1337.2198
Epoch 27/50
 - 4s - loss: 3661.3896 - val_loss: 1368.3265
Epoch 28/50
 - 4s - loss: 3659.0585 - val_loss: 1352.3825
Epoch 29/50
 - 4s - loss: 3650.1731 - val_loss: 1355.2562
Epoch 30/50
 - 4s - loss: 3658.8520 - val_loss: 1364.1335
Epoch 31/50
 - 4s - loss: 3653.4160 - val_loss: 1349.2680
Epoch 32/50
 - 4s - loss: 3656.4209 - val_loss: 1376.2577
Epoch 33/50
 - 4s - loss: 3649.2141 - val_loss: 1334.1732
Epoch 34/50
 - 4s - loss: 3637.0789 - val_loss: 1344.1230
Epoch 35/50
 - 4s - loss: 3631.3421 - val_loss: 1332.9835
Epoch 36/50
 - 4s - loss: 3633.3686 - val_loss: 1342.7453
Epoch 37/50
 - 4s - loss: 3638.9948 - val_loss: 1346.0193
Epoch 38/50
 - 4s - loss: 3630.7382 - val_loss: 1343.7969
Epoch 39/50
 - 4s - loss: 3626.8672 - val_loss: 1328.9532
Epoch 40/50
 - 4s - loss: 3620.8626 - val_loss: 1349.9319
Epoch 41/50
 - 4s - loss: 3614.9172 - val_loss: 1316.2680
Epoch 42/50
 - 4s - loss: 3611.9563 - val_loss: 1314.2023
Epoch 43/50
 - 4s - loss: 3618.0950 - val_loss: 1319.9263
Epoch 44/50
 - 4s - loss: 3610.2284 - val_loss: 1339.3619
Epoch 45/50
 - 4s - loss: 3604.8124 - val_loss: 1340.9614
Epoch 46/50
 - 4s - loss: 3601.8835 - val_loss: 1340.3753
Epoch 47/50
 - 4s - loss: 3597.6878 - val_loss: 1311.7930
Epoch 48/50
 - 4s - loss: 3605.1498 - val_loss: 1332.4595
Epoch 49/50
 - 4s - loss: 3590.7386 - val_loss: 1328.3238
Epoch 50/50
 - 4s - loss: 3588.6124 - val_loss: 1313.8916
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 50120	action = 0	current_phase = 1	next_phase = 0	reward = 0.723825	array([[ -0.84235954, -43.251667  ]], dtype=float32)
time = 50125	action = 0	current_phase = 1	next_phase = 0	reward = 0.726982	array([[ -0.7830763, -43.23886  ]], dtype=float32)
time = 50130	action = 0	current_phase = 1	next_phase = 0	reward = 0.716230	array([[ -0.85637, -43.24222]], dtype=float32)
time = 50135	action = 0	current_phase = 1	next_phase = 0	reward = 0.710404	array([[ -0.7609644, -43.23534  ]], dtype=float32)
time = 50140	action = 0	current_phase = 1	next_phase = 0	reward = 0.716724	array([[ -0.78139305, -43.239532  ]], dtype=float32)
time = 50145	action = 0	current_phase = 1	next_phase = 0	reward = 0.716373	array([[ -0.80852604, -43.240536  ]], dtype=float32)
time = 50150	action = 0	current_phase = 1	next_phase = 0	reward = 0.716158	array([[ -0.77522564, -43.24058   ]], dtype=float32)
time = 50155	action = 0	current_phase = 1	next_phase = 0	reward = 0.722186	array([[ -0.80826473, -43.233105  ]], dtype=float32)
time = 50160	action = 0	current_phase = 1	next_phase = 0	reward = 0.723094	array([[ -0.85054684, -43.247913  ]], dtype=float32)
time = 50165	action = 0	current_phase = 1	next_phase = 0	reward = 0.721011	array([[ -0.7589712, -43.240013 ]], dtype=float32)
time = 50170	action = 0	current_phase = 1	next_phase = 0	reward = 0.723006	array([[ -0.7394028, -43.225407 ]], dtype=float32)
time = 50175	action = 0	current_phase = 1	next_phase = 0	reward = 0.441112	array([[ -0.80400944, -43.23174   ]], dtype=float32)
time = 50180	action = 0	current_phase = 1	next_phase = 0	reward = 1.008724	array([[ -0.77613926, -43.24369   ]], dtype=float32)
time = 50185	action = 0	current_phase = 1	next_phase = 0	reward = 0.728746	array([[ -0.79886913, -43.244305  ]], dtype=float32)
time = 50190	action = 0	current_phase = 1	next_phase = 0	reward = 0.720611	array([[ -0.82358646, -43.137302  ]], dtype=float32)
time = 50195	action = 0	current_phase = 1	next_phase = 0	reward = 0.711077	array([[ -0.85924435, -43.20335   ]], dtype=float32)
time = 50200	action = 0	current_phase = 1	next_phase = 0	reward = 0.716824	array([[ -0.75582504, -43.238297  ]], dtype=float32)
time = 50205	action = 0	current_phase = 1	next_phase = 0	reward = 0.731931	array([[ -0.7715435, -43.21167  ]], dtype=float32)
time = 50210	action = 0	current_phase = 1	next_phase = 0	reward = 0.715552	array([[ -0.78440285, -43.24401   ]], dtype=float32)
time = 50215	action = 0	current_phase = 1	next_phase = 0	reward = 0.715713	array([[ -0.82363796, -43.248077  ]], dtype=float32)
time = 50220	action = 0	current_phase = 1	next_phase = 0	reward = 0.714602	array([[ -0.75886536, -43.231323  ]], dtype=float32)
time = 50225	action = 0	current_phase = 1	next_phase = 0	reward = 0.162081	array([[ -0.8255291, -43.242607 ]], dtype=float32)
time = 50230	action = 0	current_phase = 1	next_phase = 0	reward = 1.010354	array([[ -0.8191252, -43.24475  ]], dtype=float32)
time = 50235	action = 0	current_phase = 1	next_phase = 0	reward = 1.007347	array([[ -0.8242712, -43.23668  ]], dtype=float32)
time = 50240	action = 0	current_phase = 1	next_phase = 0	reward = 0.722881	array([[ -0.84403706, -43.246147  ]], dtype=float32)
time = 50245	action = 0	current_phase = 1	next_phase = 0	reward = 0.732326	array([[ -0.82555676, -43.239983  ]], dtype=float32)
time = 50250	action = 0	current_phase = 1	next_phase = 0	reward = 0.713915	array([[ -0.80497074, -43.239418  ]], dtype=float32)
time = 50255	action = 0	current_phase = 1	next_phase = 0	reward = 0.717212	array([[ -0.7981148, -43.240475 ]], dtype=float32)
time = 50260	action = 0	current_phase = 1	next_phase = 0	reward = 0.717361	array([[ -0.7932472, -43.22254  ]], dtype=float32)
time = 50265	action = 0	current_phase = 1	next_phase = 0	reward = 0.719725	array([[ -0.81594944, -43.237633  ]], dtype=float32)
time = 50270	action = 0	current_phase = 1	next_phase = 0	reward = 0.439567	array([[ -0.7811537, -43.23401  ]], dtype=float32)
time = 50275	action = 0	current_phase = 1	next_phase = 0	reward = 0.723937	array([[ -0.8235254, -43.240486 ]], dtype=float32)
time = 50280	action = 0	current_phase = 1	next_phase = 0	reward = 0.995755	array([[ -0.8670492, -43.24249  ]], dtype=float32)
time = 50285	action = 0	current_phase = 1	next_phase = 0	reward = 0.719146	array([[ -0.84416866, -43.24148   ]], dtype=float32)
time = 50290	action = 0	current_phase = 1	next_phase = 0	reward = 0.717313	array([[ -0.81503296, -43.241104  ]], dtype=float32)
time = 50295	action = 0	current_phase = 1	next_phase = 0	reward = 0.716710	array([[ -0.84504795, -43.244568  ]], dtype=float32)
time = 50300	action = 0	current_phase = 1	next_phase = 0	reward = 0.441446	array([[ -0.86282635, -43.243977  ]], dtype=float32)
time = 50305	action = 0	current_phase = 1	next_phase = 0	reward = 0.999926	array([[ -0.8502264, -43.244186 ]], dtype=float32)
time = 50310	action = 0	current_phase = 1	next_phase = 0	reward = 0.715062	array([[ -0.7739811, -43.242046 ]], dtype=float32)
time = 50315	action = 0	current_phase = 1	next_phase = 0	reward = 0.439427	array([[ -0.839139, -43.240044]], dtype=float32)
time = 50320	action = 0	current_phase = 1	next_phase = 0	reward = 1.009234	array([[ -0.85430336, -43.207596  ]], dtype=float32)
time = 50325	action = 0	current_phase = 1	next_phase = 0	reward = 0.721002	array([[ -0.7674179, -43.240257 ]], dtype=float32)
time = 50330	action = 0	current_phase = 1	next_phase = 0	reward = 0.724425	array([[ -0.79735565, -43.24495   ]], dtype=float32)
time = 50335	action = 0	current_phase = 1	next_phase = 0	reward = 0.722155	array([[ -0.8256006, -43.239143 ]], dtype=float32)
time = 50340	action = 0	current_phase = 1	next_phase = 0	reward = 0.726790	array([[ -0.82862186, -43.241474  ]], dtype=float32)
time = 50345	action = 0	current_phase = 1	next_phase = 0	reward = 0.728259	array([[ -0.826519, -43.239956]], dtype=float32)
time = 50350	action = 0	current_phase = 1	next_phase = 0	reward = 0.727078	array([[ -0.7588825, -43.241676 ]], dtype=float32)
time = 50355	action = 0	current_phase = 1	next_phase = 0	reward = 0.714968	array([[ -0.7366171, -43.21416  ]], dtype=float32)
time = 50360	action = 0	current_phase = 1	next_phase = 0	reward = 0.712743	array([[ -0.8326521, -43.243305 ]], dtype=float32)
time = 50365	action = 0	current_phase = 1	next_phase = 0	reward = 0.722033	array([[ -0.8280163, -43.240055 ]], dtype=float32)
time = 50370	action = 0	current_phase = 1	next_phase = 0	reward = 0.718399	array([[ -0.7952204, -43.24077  ]], dtype=float32)
time = 50375	action = 0	current_phase = 1	next_phase = 0	reward = 0.436238	array([[ -0.77234745, -43.24489   ]], dtype=float32)
time = 50380	action = 0	current_phase = 1	next_phase = 0	reward = 0.992272	array([[ -0.8113575, -43.23412  ]], dtype=float32)
time = 50385	action = 0	current_phase = 1	next_phase = 0	reward = 0.439040	array([[ -0.84599876, -43.245777  ]], dtype=float32)
time = 50390	action = 0	current_phase = 1	next_phase = 0	reward = 0.720500	array([[ -0.85437393, -43.242622  ]], dtype=float32)
time = 50395	action = 0	current_phase = 1	next_phase = 0	reward = 0.721827	array([[ -0.8366499, -43.239132 ]], dtype=float32)
time = 50400	action = 0	current_phase = 1	next_phase = 0	reward = 0.722195	array([[ -0.8419342, -43.240875 ]], dtype=float32)
time = 50405	action = 0	current_phase = 1	next_phase = 0	reward = 1.005717	array([[ -0.84755707, -43.241695  ]], dtype=float32)
time = 50410	action = 0	current_phase = 1	next_phase = 0	reward = 0.729372	array([[ -0.80818653, -43.245552  ]], dtype=float32)
time = 50415	action = 0	current_phase = 1	next_phase = 0	reward = 0.715575	array([[ -0.762002, -43.23774 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3053.0518 - val_loss: 1720.7644
Epoch 2/50
 - 4s - loss: 3048.9404 - val_loss: 1753.4905
Epoch 3/50
 - 4s - loss: 3044.9682 - val_loss: 1706.3418
Epoch 4/50
 - 4s - loss: 3035.8759 - val_loss: 1700.9237
Epoch 5/50
 - 4s - loss: 3037.3595 - val_loss: 1704.2882
Epoch 6/50
 - 4s - loss: 3039.5761 - val_loss: 1687.5763
Epoch 7/50
 - 4s - loss: 3032.5722 - val_loss: 1688.2445
Epoch 8/50
 - 4s - loss: 3020.1432 - val_loss: 1696.6360
Epoch 9/50
 - 4s - loss: 3015.1166 - val_loss: 1709.5684
Epoch 10/50
 - 4s - loss: 3026.4412 - val_loss: 1693.5259
Epoch 11/50
 - 4s - loss: 3011.7598 - val_loss: 1696.8527
Epoch 12/50
 - 4s - loss: 3016.6674 - val_loss: 1671.3133
Epoch 13/50
 - 4s - loss: 3011.8108 - val_loss: 1687.9469
Epoch 14/50
 - 4s - loss: 3006.0669 - val_loss: 1667.5502
Epoch 15/50
 - 4s - loss: 3006.7289 - val_loss: 1680.6049
Epoch 16/50
 - 4s - loss: 3011.5887 - val_loss: 1668.0975
Epoch 17/50
 - 4s - loss: 3004.6894 - val_loss: 1685.7857
Epoch 18/50
 - 4s - loss: 3006.3518 - val_loss: 1676.9841
Epoch 19/50
 - 4s - loss: 2999.4686 - val_loss: 1660.1653
Epoch 20/50
 - 4s - loss: 3002.8130 - val_loss: 1666.7132
Epoch 21/50
 - 4s - loss: 2998.7698 - val_loss: 1669.2803
Epoch 22/50
 - 4s - loss: 3010.0033 - val_loss: 1660.2993
Epoch 23/50
 - 4s - loss: 2991.3740 - val_loss: 1673.0068
Epoch 24/50
 - 4s - loss: 2993.8428 - val_loss: 1656.1796
Epoch 25/50
 - 4s - loss: 2988.8587 - val_loss: 1677.9076
Epoch 26/50
 - 4s - loss: 2986.4017 - val_loss: 1687.5258
Epoch 27/50
 - 4s - loss: 2985.0045 - val_loss: 1643.6231
Epoch 28/50
 - 4s - loss: 2982.9449 - val_loss: 1643.7874
Epoch 29/50
 - 4s - loss: 2979.7540 - val_loss: 1655.2674
Epoch 30/50
 - 4s - loss: 2983.9775 - val_loss: 1644.2936
Epoch 31/50
 - 4s - loss: 2983.0692 - val_loss: 1635.2428
Epoch 32/50
 - 4s - loss: 2974.5981 - val_loss: 1623.7552
Epoch 33/50
 - 4s - loss: 2973.4828 - val_loss: 1654.5212
Epoch 34/50
 - 4s - loss: 2976.6458 - val_loss: 1641.0991
Epoch 35/50
 - 4s - loss: 2965.6145 - val_loss: 1639.1614
Epoch 36/50
 - 4s - loss: 2966.4465 - val_loss: 1625.0358
Epoch 37/50
 - 4s - loss: 2972.7570 - val_loss: 1623.4041
Epoch 38/50
 - 4s - loss: 2968.4549 - val_loss: 1629.9879
Epoch 39/50
 - 4s - loss: 2965.1275 - val_loss: 1622.8750
Epoch 40/50
 - 4s - loss: 2974.5403 - val_loss: 1612.7209
Epoch 41/50
 - 4s - loss: 2954.4784 - val_loss: 1613.9527
Epoch 42/50
 - 4s - loss: 2956.1045 - val_loss: 1616.0556
Epoch 43/50
 - 4s - loss: 2955.5245 - val_loss: 1614.3497
Epoch 44/50
 - 4s - loss: 2960.8650 - val_loss: 1612.8719
Epoch 45/50
 - 4s - loss: 2957.3354 - val_loss: 1617.8789
Epoch 46/50
 - 4s - loss: 2953.3876 - val_loss: 1623.8212
Epoch 47/50
 - 4s - loss: 2953.3160 - val_loss: 1613.9054
Epoch 48/50
 - 4s - loss: 2947.0853 - val_loss: 1629.0754
Epoch 49/50
 - 4s - loss: 2952.4513 - val_loss: 1626.9365
Epoch 50/50
 - 4s - loss: 2951.6010 - val_loss: 1606.3286
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 50420	action = 0	current_phase = 1	next_phase = 0	reward = 0.715964	array([[ -0.7702303, -43.335464 ]], dtype=float32)
time = 50425	action = 0	current_phase = 1	next_phase = 0	reward = 0.716061	array([[ -0.78078175, -43.343     ]], dtype=float32)
time = 50430	action = 0	current_phase = 1	next_phase = 0	reward = 0.718222	array([[ -0.7983351, -43.36652  ]], dtype=float32)
time = 50435	action = 0	current_phase = 1	next_phase = 0	reward = 0.445378	array([[ -0.7768278, -43.355095 ]], dtype=float32)
time = 50440	action = 0	current_phase = 1	next_phase = 0	reward = 1.005743	array([[ -0.79609776, -43.36107   ]], dtype=float32)
time = 50445	action = 0	current_phase = 1	next_phase = 0	reward = 0.724573	array([[ -0.7841377, -43.350357 ]], dtype=float32)
time = 50450	action = 0	current_phase = 1	next_phase = 0	reward = 0.716387	array([[ -0.802639, -43.353466]], dtype=float32)
time = 50455	action = 0	current_phase = 1	next_phase = 0	reward = 0.723583	array([[ -0.81157494, -43.346886  ]], dtype=float32)
time = 50460	action = 0	current_phase = 1	next_phase = 0	reward = 0.721720	array([[ -0.79986954, -43.356728  ]], dtype=float32)
time = 50465	action = 0	current_phase = 1	next_phase = 0	reward = 0.441497	array([[ -0.78036594, -43.342834  ]], dtype=float32)
time = 50470	action = 0	current_phase = 1	next_phase = 0	reward = 0.998203	array([[ -0.78044605, -43.34871   ]], dtype=float32)
time = 50475	action = 0	current_phase = 1	next_phase = 0	reward = 0.711000	array([[ -0.7706661, -43.345562 ]], dtype=float32)
time = 50480	action = 0	current_phase = 1	next_phase = 0	reward = 0.720973	array([[ -0.78260136, -43.34441   ]], dtype=float32)
time = 50485	action = 0	current_phase = 1	next_phase = 0	reward = 0.723144	array([[ -0.74902534, -43.3191    ]], dtype=float32)
time = 50490	action = 0	current_phase = 1	next_phase = 0	reward = 0.443195	array([[ -0.80113506, -43.354446  ]], dtype=float32)
time = 50495	action = 0	current_phase = 1	next_phase = 0	reward = 0.997976	array([[ -0.7584009, -43.33059  ]], dtype=float32)
time = 50500	action = 0	current_phase = 1	next_phase = 0	reward = 0.718925	array([[ -0.78342247, -43.344692  ]], dtype=float32)
time = 50505	action = 0	current_phase = 1	next_phase = 0	reward = 0.716399	array([[ -0.7902832, -43.347656 ]], dtype=float32)
time = 50510	action = 0	current_phase = 1	next_phase = 0	reward = 0.717856	array([[ -0.7861986, -43.35768  ]], dtype=float32)
time = 50515	action = 0	current_phase = 1	next_phase = 0	reward = 0.722093	array([[ -0.7431822, -43.323257 ]], dtype=float32)
time = 50520	action = 0	current_phase = 1	next_phase = 0	reward = 0.167294	array([[ -0.7725067, -43.352554 ]], dtype=float32)
time = 50525	action = 0	current_phase = 1	next_phase = 0	reward = 1.290441	array([[ -0.8111248, -43.35869  ]], dtype=float32)
time = 50530	action = 0	current_phase = 1	next_phase = 0	reward = 0.719898	array([[ -0.76855755, -43.3363    ]], dtype=float32)
time = 50535	action = 0	current_phase = 1	next_phase = 0	reward = 0.718421	array([[ -0.81209373, -43.356018  ]], dtype=float32)
time = 50540	action = 0	current_phase = 1	next_phase = 0	reward = 0.439292	array([[ -0.79433346, -43.35103   ]], dtype=float32)
time = 50545	action = 0	current_phase = 1	next_phase = 0	reward = 0.997771	array([[ -0.8012991, -43.35527  ]], dtype=float32)
time = 50550	action = 0	current_phase = 1	next_phase = 0	reward = 0.710805	array([[ -0.80148697, -43.352287  ]], dtype=float32)
time = 50555	action = 0	current_phase = 1	next_phase = 0	reward = 0.440556	array([[ -0.7989607, -43.35428  ]], dtype=float32)
time = 50560	action = 0	current_phase = 1	next_phase = 0	reward = 0.723883	array([[ -0.78895664, -43.351402  ]], dtype=float32)
time = 50565	action = 0	current_phase = 1	next_phase = 0	reward = 1.002169	array([[ -0.78932285, -43.349426  ]], dtype=float32)
time = 50570	action = 0	current_phase = 1	next_phase = 0	reward = 0.720824	array([[ -0.8041687, -43.357628 ]], dtype=float32)
time = 50575	action = 0	current_phase = 1	next_phase = 0	reward = 0.444687	array([[ -0.75464153, -43.32216   ]], dtype=float32)
time = 50580	action = 0	current_phase = 1	next_phase = 0	reward = 1.003956	array([[ -0.7940073, -43.34957  ]], dtype=float32)
time = 50585	action = 0	current_phase = 1	next_phase = 0	reward = 0.440848	array([[ -0.78477573, -43.36512   ]], dtype=float32)
time = 50590	action = 0	current_phase = 1	next_phase = 0	reward = 0.998863	array([[ -0.79212475, -43.348186  ]], dtype=float32)
time = 50595	action = 0	current_phase = 1	next_phase = 0	reward = 0.441783	array([[ -0.78843975, -43.37194   ]], dtype=float32)
time = 50600	action = 0	current_phase = 1	next_phase = 0	reward = 1.009864	array([[ -0.7902355, -43.34854  ]], dtype=float32)
time = 50605	action = 0	current_phase = 1	next_phase = 0	reward = 0.717062	array([[ -0.8131199, -43.35882  ]], dtype=float32)
time = 50610	action = 0	current_phase = 1	next_phase = 0	reward = 0.711540	array([[ -0.80041313, -43.354958  ]], dtype=float32)
time = 50615	action = 0	current_phase = 1	next_phase = 0	reward = 0.438231	array([[ -0.78434277, -43.3628    ]], dtype=float32)
time = 50620	action = 0	current_phase = 1	next_phase = 0	reward = 0.999887	array([[ -0.76937485, -43.334007  ]], dtype=float32)
time = 50625	action = 0	current_phase = 1	next_phase = 0	reward = 0.446188	array([[ -0.7842436, -43.35331  ]], dtype=float32)
time = 50630	action = 0	current_phase = 1	next_phase = 0	reward = 1.001494	array([[ -0.7961788, -43.35077  ]], dtype=float32)
time = 50635	action = 0	current_phase = 1	next_phase = 0	reward = 0.716090	array([[ -0.7960253, -43.350483 ]], dtype=float32)
time = 50640	action = 0	current_phase = 1	next_phase = 0	reward = 0.448396	array([[ -0.79371643, -43.357918  ]], dtype=float32)
time = 50645	action = 0	current_phase = 1	next_phase = 0	reward = 1.005499	array([[ -0.7773247, -43.338547 ]], dtype=float32)
time = 50650	action = 0	current_phase = 1	next_phase = 0	reward = 0.720273	array([[ -0.8046999, -43.35694  ]], dtype=float32)
time = 50655	action = 0	current_phase = 1	next_phase = 0	reward = 0.726379	array([[ -0.77790165, -43.3404    ]], dtype=float32)
time = 50660	action = 0	current_phase = 1	next_phase = 0	reward = 0.713247	array([[ -0.79528713, -43.349236  ]], dtype=float32)
time = 50665	action = 0	current_phase = 1	next_phase = 0	reward = 0.437776	array([[ -0.77591133, -43.346497  ]], dtype=float32)
time = 50670	action = 0	current_phase = 1	next_phase = 0	reward = 0.719625	array([[ -0.7239847, -43.30882  ]], dtype=float32)
time = 50675	action = 0	current_phase = 1	next_phase = 0	reward = 0.995868	array([[ -0.8130913, -43.362503 ]], dtype=float32)
time = 50680	action = 0	current_phase = 1	next_phase = 0	reward = 0.439881	array([[ -0.782403, -43.348698]], dtype=float32)
time = 50685	action = 0	current_phase = 1	next_phase = 0	reward = 1.000613	array([[ -0.78851223, -43.34693   ]], dtype=float32)
time = 50690	action = 0	current_phase = 1	next_phase = 0	reward = 0.725607	array([[ -0.79101276, -43.34062   ]], dtype=float32)
time = 50695	action = 0	current_phase = 1	next_phase = 0	reward = 0.446485	array([[ -0.8128023, -43.35859  ]], dtype=float32)
time = 50700	action = 0	current_phase = 1	next_phase = 0	reward = 0.997878	array([[ -0.78056717, -43.343334  ]], dtype=float32)
time = 50705	action = 0	current_phase = 1	next_phase = 0	reward = 0.720325	array([[ -0.76944065, -43.362     ]], dtype=float32)
time = 50710	action = 0	current_phase = 1	next_phase = 0	reward = 0.720775	array([[ -0.7618189, -43.33115  ]], dtype=float32)
time = 50715	action = 0	current_phase = 1	next_phase = 0	reward = 0.726666	array([[ -0.80942345, -43.35661   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 1306.8580 - val_loss: 784.4979
Epoch 2/50
 - 4s - loss: 1297.9880 - val_loss: 741.0543
Epoch 3/50
 - 4s - loss: 1282.6346 - val_loss: 735.7619
Epoch 4/50
 - 4s - loss: 1282.9762 - val_loss: 742.6696
Epoch 5/50
 - 4s - loss: 1282.2505 - val_loss: 744.5509
Epoch 6/50
 - 4s - loss: 1277.0528 - val_loss: 769.7065
Epoch 7/50
 - 4s - loss: 1277.4764 - val_loss: 749.1969
Epoch 8/50
 - 4s - loss: 1274.0747 - val_loss: 784.7692
Epoch 9/50
 - 4s - loss: 1285.3926 - val_loss: 754.0227
Epoch 10/50
 - 4s - loss: 1275.6661 - val_loss: 767.4453
Epoch 11/50
 - 4s - loss: 1277.5608 - val_loss: 798.9185
Epoch 12/50
 - 4s - loss: 1277.2314 - val_loss: 759.1264
Epoch 13/50
 - 4s - loss: 1258.3650 - val_loss: 762.8925
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 50720	action = 0	current_phase = 1	next_phase = 0	reward = 0.723322	array([[ -0.80664444, -43.34326   ]], dtype=float32)
time = 50725	action = 0	current_phase = 1	next_phase = 0	reward = 0.720752	array([[ -0.7755146, -43.33737  ]], dtype=float32)
time = 50730	action = 0	current_phase = 1	next_phase = 0	reward = 0.713530	array([[ -0.74874496, -43.284058  ]], dtype=float32)
time = 50735	action = 0	current_phase = 1	next_phase = 0	reward = 0.725973	array([[ -0.80837727, -43.33139   ]], dtype=float32)
time = 50740	action = 0	current_phase = 1	next_phase = 0	reward = 0.721926	array([[ -0.7756586, -43.35415  ]], dtype=float32)
time = 50745	action = 0	current_phase = 1	next_phase = 0	reward = 0.445231	array([[ -0.8133402, -43.354424 ]], dtype=float32)
time = 50750	action = 0	current_phase = 1	next_phase = 0	reward = 1.004898	array([[ -0.78021336, -43.31528   ]], dtype=float32)
time = 50755	action = 0	current_phase = 1	next_phase = 0	reward = 0.721841	array([[ -0.773118, -43.30835 ]], dtype=float32)
time = 50760	action = 0	current_phase = 1	next_phase = 0	reward = 0.717725	array([[ -0.800457, -43.341652]], dtype=float32)
time = 50765	action = 0	current_phase = 1	next_phase = 0	reward = 0.436985	array([[ -0.8097305, -43.333836 ]], dtype=float32)
time = 50770	action = 0	current_phase = 1	next_phase = 0	reward = 0.996830	array([[ -0.7963505, -43.33639  ]], dtype=float32)
time = 50775	action = 0	current_phase = 1	next_phase = 0	reward = 0.717233	array([[ -0.79541683, -43.335587  ]], dtype=float32)
time = 50780	action = 0	current_phase = 1	next_phase = 0	reward = 0.732736	array([[ -0.78531075, -43.33107   ]], dtype=float32)
time = 50785	action = 0	current_phase = 1	next_phase = 0	reward = 0.722580	array([[ -0.77985764, -43.33288   ]], dtype=float32)
time = 50790	action = 0	current_phase = 1	next_phase = 0	reward = 0.727519	array([[ -0.77458096, -43.335384  ]], dtype=float32)
time = 50795	action = 0	current_phase = 1	next_phase = 0	reward = 0.719600	array([[ -0.7940731, -43.343464 ]], dtype=float32)
time = 50800	action = 0	current_phase = 1	next_phase = 0	reward = 0.720153	array([[ -0.76912785, -43.328957  ]], dtype=float32)
time = 50805	action = 0	current_phase = 1	next_phase = 0	reward = 0.729486	array([[ -0.80084896, -43.370567  ]], dtype=float32)
time = 50810	action = 0	current_phase = 1	next_phase = 0	reward = 0.722317	array([[ -0.7861414, -43.290672 ]], dtype=float32)
time = 50815	action = 0	current_phase = 1	next_phase = 0	reward = 0.720957	array([[ -0.7865982, -43.326744 ]], dtype=float32)
time = 50820	action = 0	current_phase = 1	next_phase = 0	reward = 0.712819	array([[ -0.7634287, -43.310097 ]], dtype=float32)
time = 50825	action = 0	current_phase = 1	next_phase = 0	reward = 0.714309	array([[ -0.7569542, -43.305702 ]], dtype=float32)
time = 50830	action = 0	current_phase = 1	next_phase = 0	reward = 0.716365	array([[ -0.6996336, -43.2196   ]], dtype=float32)
time = 50835	action = 0	current_phase = 1	next_phase = 0	reward = 0.442691	array([[ -0.7733393, -43.308056 ]], dtype=float32)
time = 50840	action = 0	current_phase = 1	next_phase = 0	reward = 1.004101	array([[ -0.80156994, -43.33869   ]], dtype=float32)
time = 50845	action = 0	current_phase = 1	next_phase = 0	reward = 0.719423	array([[ -0.78173065, -43.314106  ]], dtype=float32)
time = 50850	action = 0	current_phase = 1	next_phase = 0	reward = 0.721300	array([[ -0.7965431, -43.32478  ]], dtype=float32)
time = 50855	action = 0	current_phase = 1	next_phase = 0	reward = 0.719396	array([[ -0.7918205, -43.301773 ]], dtype=float32)
time = 50860	action = 0	current_phase = 1	next_phase = 0	reward = 0.718947	array([[ -0.7897501, -43.332565 ]], dtype=float32)
time = 50865	action = 0	current_phase = 1	next_phase = 0	reward = 0.727173	array([[ -0.7923374, -43.336636 ]], dtype=float32)
time = 50870	action = 0	current_phase = 1	next_phase = 0	reward = 0.721445	array([[ -0.7912693, -43.333733 ]], dtype=float32)
time = 50875	action = 0	current_phase = 1	next_phase = 0	reward = 0.718298	array([[ -0.75531006, -43.30051   ]], dtype=float32)
time = 50880	action = 0	current_phase = 1	next_phase = 0	reward = 0.723646	array([[ -0.78116226, -43.331337  ]], dtype=float32)
time = 50885	action = 0	current_phase = 1	next_phase = 0	reward = 0.719753	array([[ -0.80621815, -43.335014  ]], dtype=float32)
time = 50890	action = 0	current_phase = 1	next_phase = 0	reward = 0.716961	array([[ -0.76159096, -43.344776  ]], dtype=float32)
time = 50895	action = 0	current_phase = 1	next_phase = 0	reward = 0.714889	array([[ -0.78639984, -43.33185   ]], dtype=float32)
time = 50900	action = 0	current_phase = 1	next_phase = 0	reward = 0.435346	array([[ -0.80842113, -43.340115  ]], dtype=float32)
time = 50905	action = 0	current_phase = 1	next_phase = 0	reward = 0.995710	array([[ -0.76735973, -43.317917  ]], dtype=float32)
time = 50910	action = 0	current_phase = 1	next_phase = 0	reward = 0.722361	array([[ -0.80872154, -43.348705  ]], dtype=float32)
time = 50915	action = 0	current_phase = 1	next_phase = 0	reward = 0.445504	array([[ -0.81187534, -43.341255  ]], dtype=float32)
time = 50920	action = 0	current_phase = 1	next_phase = 0	reward = 1.001107	array([[ -0.8004608, -43.350296 ]], dtype=float32)
time = 50925	action = 0	current_phase = 1	next_phase = 0	reward = 0.719753	array([[ -0.7539406, -43.315613 ]], dtype=float32)
time = 50930	action = 0	current_phase = 1	next_phase = 0	reward = 0.713473	array([[ -0.79858017, -43.342632  ]], dtype=float32)
time = 50935	action = 0	current_phase = 1	next_phase = 0	reward = 0.444509	array([[ -0.78950787, -43.33794   ]], dtype=float32)
time = 50940	action = 0	current_phase = 1	next_phase = 0	reward = 0.716346	array([[ -0.7938061, -43.316525 ]], dtype=float32)
time = 50945	action = 0	current_phase = 1	next_phase = 0	reward = 0.996335	array([[ -0.7406635, -43.328762 ]], dtype=float32)
time = 50950	action = 0	current_phase = 1	next_phase = 0	reward = 0.718524	array([[ -0.80435944, -43.34295   ]], dtype=float32)
time = 50955	action = 0	current_phase = 1	next_phase = 0	reward = 0.718072	array([[ -0.8120804, -43.267838 ]], dtype=float32)
time = 50960	action = 0	current_phase = 1	next_phase = 0	reward = 0.729715	array([[ -0.72356415, -43.33581   ]], dtype=float32)
time = 50965	action = 0	current_phase = 1	next_phase = 0	reward = 0.721017	array([[ -0.7752886, -43.325016 ]], dtype=float32)
time = 50970	action = 0	current_phase = 1	next_phase = 0	reward = 0.728546	array([[ -0.8279915, -43.30346  ]], dtype=float32)
time = 50975	action = 0	current_phase = 1	next_phase = 0	reward = 0.727024	array([[ -0.7713442, -43.313034 ]], dtype=float32)
time = 50980	action = 0	current_phase = 1	next_phase = 0	reward = 0.715071	array([[ -0.78248596, -43.333206  ]], dtype=float32)
time = 50985	action = 0	current_phase = 1	next_phase = 0	reward = 0.719593	array([[ -0.8151369, -43.32396  ]], dtype=float32)
time = 50990	action = 0	current_phase = 1	next_phase = 0	reward = 0.721319	array([[ -0.80268764, -43.3327    ]], dtype=float32)
time = 50995	action = 0	current_phase = 1	next_phase = 0	reward = 0.443217	array([[ -0.80816936, -43.336395  ]], dtype=float32)
time = 51000	action = 0	current_phase = 1	next_phase = 0	reward = 1.005928	array([[ -0.80583954, -43.350037  ]], dtype=float32)
time = 51005	action = 0	current_phase = 1	next_phase = 0	reward = 0.718452	array([[ -0.8014326, -43.33612  ]], dtype=float32)
time = 51010	action = 0	current_phase = 1	next_phase = 0	reward = 0.729457	array([[ -0.8017225, -43.336555 ]], dtype=float32)
time = 51015	action = 0	current_phase = 1	next_phase = 0	reward = 0.723230	array([[ -0.8003273, -43.343716 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 1381.3918 - val_loss: 295.8963
Epoch 2/50
 - 4s - loss: 1380.2014 - val_loss: 314.1788
Epoch 3/50
 - 4s - loss: 1361.7155 - val_loss: 357.6289
Epoch 4/50
 - 4s - loss: 1375.3995 - val_loss: 302.1170
Epoch 5/50
 - 4s - loss: 1364.4434 - val_loss: 286.9107
Epoch 6/50
 - 4s - loss: 1361.0408 - val_loss: 310.8783
Epoch 7/50
 - 4s - loss: 1352.5017 - val_loss: 307.8565
Epoch 8/50
 - 4s - loss: 1341.5899 - val_loss: 311.4407
Epoch 9/50
 - 4s - loss: 1359.2533 - val_loss: 308.2658
Epoch 10/50
 - 4s - loss: 1345.1435 - val_loss: 308.2608
Epoch 11/50
 - 4s - loss: 1357.0698 - val_loss: 293.3991
Epoch 12/50
 - 4s - loss: 1342.7615 - val_loss: 290.0882
Epoch 13/50
 - 4s - loss: 1334.6594 - val_loss: 300.9472
Epoch 14/50
 - 4s - loss: 1331.7746 - val_loss: 301.3296
Epoch 15/50
 - 4s - loss: 1332.7896 - val_loss: 312.4991
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 51020	action = 0	current_phase = 1	next_phase = 0	reward = 0.439886	array([[ -0.963294, -43.244564]], dtype=float32)
time = 51025	action = 0	current_phase = 1	next_phase = 0	reward = 1.003993	array([[ -0.97653866, -43.239822  ]], dtype=float32)
time = 51030	action = 0	current_phase = 1	next_phase = 0	reward = 0.721487	array([[ -0.9566536, -43.217453 ]], dtype=float32)
time = 51035	action = 0	current_phase = 1	next_phase = 0	reward = 0.711535	array([[ -0.9748411, -43.2481   ]], dtype=float32)
time = 51040	action = 0	current_phase = 1	next_phase = 0	reward = 0.719751	array([[ -0.96441746, -43.257885  ]], dtype=float32)
time = 51045	action = 0	current_phase = 1	next_phase = 0	reward = 0.717589	array([[ -0.9779606, -43.239788 ]], dtype=float32)
time = 51050	action = 0	current_phase = 1	next_phase = 0	reward = 0.716651	array([[ -0.9245157, -43.211617 ]], dtype=float32)
time = 51055	action = 0	current_phase = 1	next_phase = 0	reward = 0.712491	array([[ -0.92436695, -43.220463  ]], dtype=float32)
time = 51060	action = 0	current_phase = 1	next_phase = 0	reward = 0.716797	array([[ -0.9902563, -43.255817 ]], dtype=float32)
time = 51065	action = 0	current_phase = 1	next_phase = 0	reward = 0.443737	array([[ -0.90335655, -43.181896  ]], dtype=float32)
time = 51070	action = 0	current_phase = 1	next_phase = 0	reward = 0.725568	array([[ -0.9486532, -43.22013  ]], dtype=float32)
time = 51075	action = 0	current_phase = 1	next_phase = 0	reward = 1.003546	array([[ -0.991127, -43.240456]], dtype=float32)
time = 51080	action = 0	current_phase = 1	next_phase = 0	reward = 0.725972	array([[ -0.9610634, -43.225616 ]], dtype=float32)
time = 51085	action = 0	current_phase = 1	next_phase = 0	reward = 0.721314	array([[ -0.9428396, -43.14272  ]], dtype=float32)
time = 51090	action = 0	current_phase = 1	next_phase = 0	reward = 0.721303	array([[ -0.95340824, -43.226532  ]], dtype=float32)
time = 51095	action = 0	current_phase = 1	next_phase = 0	reward = 0.721008	array([[ -0.9741888, -43.237556 ]], dtype=float32)
time = 51100	action = 0	current_phase = 1	next_phase = 0	reward = 0.720945	array([[ -0.8982477, -43.211548 ]], dtype=float32)
time = 51105	action = 0	current_phase = 1	next_phase = 0	reward = 0.715953	array([[ -0.95262814, -43.231388  ]], dtype=float32)
time = 51110	action = 0	current_phase = 1	next_phase = 0	reward = 0.715979	array([[ -0.9974146, -43.243122 ]], dtype=float32)
time = 51115	action = 0	current_phase = 1	next_phase = 0	reward = 0.446772	array([[ -0.9547844, -43.241356 ]], dtype=float32)
time = 51120	action = 0	current_phase = 1	next_phase = 0	reward = 0.733753	array([[ -0.9683523, -43.237556 ]], dtype=float32)
time = 51125	action = 0	current_phase = 1	next_phase = 0	reward = 1.012575	array([[ -0.908247, -43.200653]], dtype=float32)
time = 51130	action = 0	current_phase = 1	next_phase = 0	reward = 0.718745	array([[ -0.9542618, -43.21892  ]], dtype=float32)
time = 51135	action = 0	current_phase = 1	next_phase = 0	reward = 0.437849	array([[ -0.9450121, -43.243057 ]], dtype=float32)
time = 51140	action = 0	current_phase = 1	next_phase = 0	reward = 1.009533	array([[ -0.96441746, -43.228306  ]], dtype=float32)
time = 51145	action = 0	current_phase = 1	next_phase = 0	reward = 0.714555	array([[ -0.91564655, -43.214787  ]], dtype=float32)
time = 51150	action = 0	current_phase = 1	next_phase = 0	reward = 0.443171	array([[ -0.9574709, -43.233135 ]], dtype=float32)
time = 51155	action = 0	current_phase = 1	next_phase = 0	reward = 1.003630	array([[ -0.9602833, -43.234177 ]], dtype=float32)
time = 51160	action = 0	current_phase = 1	next_phase = 0	reward = 0.444345	array([[ -0.94221973, -43.209488  ]], dtype=float32)
time = 51165	action = 0	current_phase = 1	next_phase = 0	reward = 1.002288	array([[ -0.923007, -43.213886]], dtype=float32)
time = 51170	action = 0	current_phase = 1	next_phase = 0	reward = 0.717022	array([[ -0.9244623, -43.259808 ]], dtype=float32)
time = 51175	action = 0	current_phase = 1	next_phase = 0	reward = 0.716958	array([[ -0.95159054, -43.2417    ]], dtype=float32)
time = 51180	action = 0	current_phase = 1	next_phase = 0	reward = 0.721126	array([[ -0.97887707, -43.23625   ]], dtype=float32)
time = 51185	action = 0	current_phase = 1	next_phase = 0	reward = 0.724808	array([[ -0.94882965, -43.22567   ]], dtype=float32)
time = 51190	action = 0	current_phase = 1	next_phase = 0	reward = 0.722982	array([[ -0.95504475, -43.211136  ]], dtype=float32)
time = 51195	action = 0	current_phase = 1	next_phase = 0	reward = 0.721808	array([[ -0.9690132, -43.235477 ]], dtype=float32)
time = 51200	action = 0	current_phase = 1	next_phase = 0	reward = 0.718940	array([[ -0.94151306, -43.242645  ]], dtype=float32)
time = 51205	action = 0	current_phase = 1	next_phase = 0	reward = 0.718069	array([[ -0.98053455, -43.252464  ]], dtype=float32)
time = 51210	action = 0	current_phase = 1	next_phase = 0	reward = 0.719402	array([[ -0.96882343, -43.231674  ]], dtype=float32)
time = 51215	action = 0	current_phase = 1	next_phase = 0	reward = 0.726456	array([[ -0.96904755, -43.245815  ]], dtype=float32)
time = 51220	action = 0	current_phase = 1	next_phase = 0	reward = 0.716049	array([[ -0.9610748, -43.22716  ]], dtype=float32)
time = 51225	action = 0	current_phase = 1	next_phase = 0	reward = 0.720782	array([[ -0.9733238, -43.23513  ]], dtype=float32)
time = 51230	action = 0	current_phase = 1	next_phase = 0	reward = 0.720383	array([[ -0.88952065, -43.21623   ]], dtype=float32)
time = 51235	action = 0	current_phase = 1	next_phase = 0	reward = 0.443023	array([[ -0.9750252, -43.249813 ]], dtype=float32)
time = 51240	action = 0	current_phase = 1	next_phase = 0	reward = 1.004057	array([[ -0.9606352, -43.23539  ]], dtype=float32)
time = 51245	action = 0	current_phase = 1	next_phase = 0	reward = 0.719077	array([[ -0.9663124, -43.231766 ]], dtype=float32)
time = 51250	action = 0	current_phase = 1	next_phase = 0	reward = 0.721512	array([[ -0.9767866, -43.2339   ]], dtype=float32)
time = 51255	action = 0	current_phase = 1	next_phase = 0	reward = 0.726627	array([[ -0.93610096, -43.21339   ]], dtype=float32)
time = 51260	action = 0	current_phase = 1	next_phase = 0	reward = 0.724979	array([[ -0.9968834, -43.242947 ]], dtype=float32)
time = 51265	action = 0	current_phase = 1	next_phase = 0	reward = 0.723306	array([[ -0.9101429, -43.215435 ]], dtype=float32)
time = 51270	action = 0	current_phase = 1	next_phase = 0	reward = 0.710592	array([[ -0.88582134, -43.161312  ]], dtype=float32)
time = 51275	action = 0	current_phase = 1	next_phase = 0	reward = 0.715594	array([[ -0.9414463, -43.188374 ]], dtype=float32)
time = 51280	action = 0	current_phase = 1	next_phase = 0	reward = 0.445796	array([[ -0.9448166, -43.21628  ]], dtype=float32)
time = 51285	action = 0	current_phase = 1	next_phase = 0	reward = 0.732782	array([[ -0.9945679, -43.246025 ]], dtype=float32)
time = 51290	action = 0	current_phase = 1	next_phase = 0	reward = 1.000887	array([[ -0.91753006, -43.227997  ]], dtype=float32)
time = 51295	action = 0	current_phase = 1	next_phase = 0	reward = 0.716930	array([[ -0.9654331, -43.2121   ]], dtype=float32)
time = 51300	action = 0	current_phase = 1	next_phase = 0	reward = 0.718723	array([[ -0.98770237, -43.24681   ]], dtype=float32)
time = 51305	action = 0	current_phase = 1	next_phase = 0	reward = 0.447027	array([[ -0.9534168, -43.221687 ]], dtype=float32)
time = 51310	action = 0	current_phase = 1	next_phase = 0	reward = 1.001655	array([[ -0.97039795, -43.23135   ]], dtype=float32)
time = 51315	action = 0	current_phase = 1	next_phase = 0	reward = 0.718201	array([[ -0.9227629, -43.223972 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 1133.2666 - val_loss: 5137.8078
Epoch 2/50
 - 4s - loss: 1100.7234 - val_loss: 5138.1868
Epoch 3/50
 - 4s - loss: 1100.4408 - val_loss: 5130.6005
Epoch 4/50
 - 4s - loss: 1090.4663 - val_loss: 5139.9383
Epoch 5/50
 - 4s - loss: 1084.8904 - val_loss: 5151.1612
Epoch 6/50
 - 4s - loss: 1079.9198 - val_loss: 5140.8651
Epoch 7/50
 - 4s - loss: 1077.8743 - val_loss: 5142.8444
Epoch 8/50
 - 4s - loss: 1083.8065 - val_loss: 5130.3462
Epoch 9/50
 - 4s - loss: 1077.7736 - val_loss: 5115.3364
Epoch 10/50
 - 4s - loss: 1067.0391 - val_loss: 5125.0660
Epoch 11/50
 - 4s - loss: 1079.5084 - val_loss: 5159.3063
Epoch 12/50
 - 4s - loss: 1073.5966 - val_loss: 5126.7924
Epoch 13/50
 - 4s - loss: 1074.3463 - val_loss: 5117.9739
Epoch 14/50
 - 4s - loss: 1063.0312 - val_loss: 5127.2955
Epoch 15/50
 - 4s - loss: 1072.2851 - val_loss: 5103.7104
Epoch 16/50
 - 4s - loss: 1073.2020 - val_loss: 5118.8240
Epoch 17/50
 - 4s - loss: 1067.2184 - val_loss: 5099.0919
Epoch 18/50
 - 4s - loss: 1054.3957 - val_loss: 5100.9179
Epoch 19/50
 - 4s - loss: 1060.3537 - val_loss: 5095.4215
Epoch 20/50
 - 4s - loss: 1057.1531 - val_loss: 5119.5289
Epoch 21/50
 - 4s - loss: 1046.6162 - val_loss: 5119.4559
Epoch 22/50
 - 4s - loss: 1060.7995 - val_loss: 5114.0513
Epoch 23/50
 - 4s - loss: 1048.9355 - val_loss: 5134.0133
Epoch 24/50
 - 4s - loss: 1057.4519 - val_loss: 5140.9355
Epoch 25/50
 - 4s - loss: 1058.8432 - val_loss: 5108.1857
Epoch 26/50
 - 4s - loss: 1034.0595 - val_loss: 5132.3440
Epoch 27/50
 - 4s - loss: 1047.1647 - val_loss: 5134.9931
Epoch 28/50
 - 4s - loss: 1035.8748 - val_loss: 5108.5768
Epoch 29/50
 - 4s - loss: 1033.8406 - val_loss: 5101.2726
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 51320	action = 0	current_phase = 1	next_phase = 0	reward = 0.716932	array([[ -0.25565624, -43.350224  ]], dtype=float32)
time = 51325	action = 0	current_phase = 1	next_phase = 0	reward = 0.723532	array([[ -0.35370922, -43.442127  ]], dtype=float32)
time = 51330	action = 0	current_phase = 1	next_phase = 0	reward = 0.725667	array([[ -0.36441326, -43.44409   ]], dtype=float32)
time = 51335	action = 0	current_phase = 1	next_phase = 0	reward = 0.724490	array([[ -0.2821703, -43.414722 ]], dtype=float32)
time = 51340	action = 0	current_phase = 1	next_phase = 0	reward = 0.714693	array([[ -0.33399296, -43.42742   ]], dtype=float32)
time = 51345	action = 0	current_phase = 1	next_phase = 0	reward = 0.716925	array([[ -0.24315548, -43.426693  ]], dtype=float32)
time = 51350	action = 0	current_phase = 1	next_phase = 0	reward = 0.717050	array([[ -0.26710606, -43.35967   ]], dtype=float32)
time = 51355	action = 0	current_phase = 1	next_phase = 0	reward = 0.718922	array([[ -0.28106022, -43.36875   ]], dtype=float32)
time = 51360	action = 0	current_phase = 1	next_phase = 0	reward = 0.714864	array([[ -0.23611927, -43.35431   ]], dtype=float32)
time = 51365	action = 0	current_phase = 1	next_phase = 0	reward = 0.435484	array([[ -0.28515148, -43.385384  ]], dtype=float32)
time = 51370	action = 0	current_phase = 1	next_phase = 0	reward = 0.999954	array([[ -0.29843616, -43.424202  ]], dtype=float32)
time = 51375	action = 0	current_phase = 1	next_phase = 0	reward = 0.716887	array([[ -0.31513977, -43.414253  ]], dtype=float32)
time = 51380	action = 0	current_phase = 1	next_phase = 0	reward = 0.452285	array([[ -0.35186577, -43.43876   ]], dtype=float32)
time = 51385	action = 0	current_phase = 1	next_phase = 0	reward = 1.013112	array([[ -0.33921432, -43.441208  ]], dtype=float32)
time = 51390	action = 0	current_phase = 1	next_phase = 0	reward = 0.726093	array([[ -0.32899666, -43.438858  ]], dtype=float32)
time = 51395	action = 0	current_phase = 1	next_phase = 0	reward = 0.726426	array([[ -0.27232265, -43.393295  ]], dtype=float32)
time = 51400	action = 0	current_phase = 1	next_phase = 0	reward = 0.723195	array([[ -0.28442574, -43.39862   ]], dtype=float32)
time = 51405	action = 0	current_phase = 1	next_phase = 0	reward = 0.716282	array([[ -0.37412167, -43.453453  ]], dtype=float32)
time = 51410	action = 0	current_phase = 1	next_phase = 0	reward = 0.442870	array([[ -0.32173824, -43.415695  ]], dtype=float32)
time = 51415	action = 0	current_phase = 1	next_phase = 0	reward = 1.006302	array([[ -0.27157974, -43.361     ]], dtype=float32)
time = 51420	action = 0	current_phase = 1	next_phase = 0	reward = 0.721856	array([[ -0.37905312, -43.455017  ]], dtype=float32)
time = 51425	action = 0	current_phase = 1	next_phase = 0	reward = 0.726633	array([[ -0.26280785, -43.361885  ]], dtype=float32)
time = 51430	action = 0	current_phase = 1	next_phase = 0	reward = 0.445322	array([[ -0.2122097, -43.28003  ]], dtype=float32)
time = 51435	action = 0	current_phase = 1	next_phase = 0	reward = 0.997541	array([[ -0.3450241, -43.443825 ]], dtype=float32)
time = 51440	action = 0	current_phase = 1	next_phase = 0	reward = 0.716424	array([[ -0.26720715, -43.35916   ]], dtype=float32)
time = 51445	action = 0	current_phase = 1	next_phase = 0	reward = 0.435205	array([[ -0.28765583, -43.425125  ]], dtype=float32)
time = 51450	action = 0	current_phase = 1	next_phase = 0	reward = 1.016272	array([[ -0.2375822, -43.27967  ]], dtype=float32)
time = 51455	action = 0	current_phase = 1	next_phase = 0	reward = 0.722034	array([[ -0.27193642, -43.395016  ]], dtype=float32)
time = 51460	action = 0	current_phase = 1	next_phase = 0	reward = 0.721148	array([[ -0.36886883, -43.455322  ]], dtype=float32)
time = 51465	action = 0	current_phase = 1	next_phase = 0	reward = 0.443657	array([[ -0.31260777, -43.405838  ]], dtype=float32)
time = 51470	action = 0	current_phase = 1	next_phase = 0	reward = 1.009448	array([[ -0.29876423, -43.425766  ]], dtype=float32)
time = 51475	action = 0	current_phase = 1	next_phase = 0	reward = 0.719767	array([[ -0.22749329, -43.30229   ]], dtype=float32)
time = 51480	action = 0	current_phase = 1	next_phase = 0	reward = 0.716632	array([[ -0.3090706, -43.423004 ]], dtype=float32)
time = 51485	action = 0	current_phase = 1	next_phase = 0	reward = 0.711921	array([[ -0.34920502, -43.441044  ]], dtype=float32)
time = 51490	action = 0	current_phase = 1	next_phase = 0	reward = 0.721715	array([[ -0.2751379, -43.40051  ]], dtype=float32)
time = 51495	action = 0	current_phase = 1	next_phase = 0	reward = 0.714653	array([[ -0.28536892, -43.41858   ]], dtype=float32)
time = 51500	action = 0	current_phase = 1	next_phase = 0	reward = 0.722954	array([[ -0.30111027, -43.41008   ]], dtype=float32)
time = 51505	action = 0	current_phase = 1	next_phase = 0	reward = 0.165922	array([[ -0.31010818, -43.40554   ]], dtype=float32)
time = 51510	action = 0	current_phase = 1	next_phase = 0	reward = 1.282045	array([[ -0.24020481, -43.338676  ]], dtype=float32)
time = 51515	action = 0	current_phase = 1	next_phase = 0	reward = 0.727200	array([[ -0.2708149, -43.361523 ]], dtype=float32)
time = 51520	action = 0	current_phase = 1	next_phase = 0	reward = 0.717493	array([[ -0.22195911, -43.2953    ]], dtype=float32)
time = 51525	action = 0	current_phase = 1	next_phase = 0	reward = 0.716363	array([[ -0.36135292, -43.46806   ]], dtype=float32)
time = 51530	action = 0	current_phase = 1	next_phase = 0	reward = 0.716877	array([[ -0.32933807, -43.45314   ]], dtype=float32)
time = 51535	action = 0	current_phase = 1	next_phase = 0	reward = 0.715527	array([[ -0.2541771, -43.328674 ]], dtype=float32)
time = 51540	action = 0	current_phase = 1	next_phase = 0	reward = 0.436808	array([[ -0.2860918, -43.40136  ]], dtype=float32)
time = 51545	action = 0	current_phase = 1	next_phase = 0	reward = 1.001038	array([[ -0.3178339, -43.43238  ]], dtype=float32)
time = 51550	action = 0	current_phase = 1	next_phase = 0	reward = 0.455148	array([[ -0.22474957, -43.309387  ]], dtype=float32)
time = 51555	action = 0	current_phase = 1	next_phase = 0	reward = 1.010342	array([[ -0.27436733, -43.386192  ]], dtype=float32)
time = 51560	action = 0	current_phase = 1	next_phase = 0	reward = 0.725632	array([[ -0.27675247, -43.37848   ]], dtype=float32)
time = 51565	action = 0	current_phase = 1	next_phase = 0	reward = 0.722230	array([[ -0.29583836, -43.407116  ]], dtype=float32)
time = 51570	action = 0	current_phase = 1	next_phase = 0	reward = 0.717424	array([[ -0.26646614, -43.39689   ]], dtype=float32)
time = 51575	action = 0	current_phase = 1	next_phase = 0	reward = 0.716469	array([[ -0.31825733, -43.458694  ]], dtype=float32)
time = 51580	action = 0	current_phase = 1	next_phase = 0	reward = 0.433766	array([[ -0.27905273, -43.378746  ]], dtype=float32)
time = 51585	action = 0	current_phase = 1	next_phase = 0	reward = 1.009122	array([[ -0.33638382, -43.44124   ]], dtype=float32)
time = 51590	action = 0	current_phase = 1	next_phase = 0	reward = 0.723935	array([[ -0.2546978, -43.319088 ]], dtype=float32)
time = 51595	action = 0	current_phase = 1	next_phase = 0	reward = 0.720375	array([[ -0.30014706, -43.427795  ]], dtype=float32)
time = 51600	action = 0	current_phase = 1	next_phase = 0	reward = 0.718063	array([[ -0.25043583, -43.337074  ]], dtype=float32)
time = 51605	action = 0	current_phase = 1	next_phase = 0	reward = 0.723965	array([[ -0.19922543, -43.318478  ]], dtype=float32)
time = 51610	action = 0	current_phase = 1	next_phase = 0	reward = 0.723316	array([[ -0.30568504, -43.415062  ]], dtype=float32)
time = 51615	action = 0	current_phase = 1	next_phase = 0	reward = 0.719084	array([[ -0.31956673, -43.43608   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3199.7263 - val_loss: 985.2038
Epoch 2/50
 - 4s - loss: 3187.1747 - val_loss: 995.0004
Epoch 3/50
 - 4s - loss: 3198.6090 - val_loss: 1018.8408
Epoch 4/50
 - 4s - loss: 3182.6575 - val_loss: 1004.1700
Epoch 5/50
 - 4s - loss: 3191.2852 - val_loss: 991.8849
Epoch 6/50
 - 4s - loss: 3171.8023 - val_loss: 976.0640
Epoch 7/50
 - 4s - loss: 3182.2211 - val_loss: 969.7561
Epoch 8/50
 - 4s - loss: 3178.8628 - val_loss: 971.4512
Epoch 9/50
 - 4s - loss: 3170.9463 - val_loss: 960.8592
Epoch 10/50
 - 4s - loss: 3170.7209 - val_loss: 970.6624
Epoch 11/50
 - 4s - loss: 3167.8323 - val_loss: 974.1351
Epoch 12/50
 - 4s - loss: 3158.5114 - val_loss: 961.5330
Epoch 13/50
 - 4s - loss: 3161.3550 - val_loss: 957.8039
Epoch 14/50
 - 4s - loss: 3180.3956 - val_loss: 976.1948
Epoch 15/50
 - 4s - loss: 3151.2269 - val_loss: 964.3641
Epoch 16/50
 - 4s - loss: 3155.3236 - val_loss: 956.7335
Epoch 17/50
 - 4s - loss: 3159.9502 - val_loss: 988.3964
Epoch 18/50
 - 4s - loss: 3154.5112 - val_loss: 972.5534
Epoch 19/50
 - 4s - loss: 3148.0212 - val_loss: 958.1445
Epoch 20/50
 - 4s - loss: 3141.0668 - val_loss: 993.8842
Epoch 21/50
 - 4s - loss: 3145.3949 - val_loss: 952.2479
Epoch 22/50
 - 4s - loss: 3147.5702 - val_loss: 959.4791
Epoch 23/50
 - 4s - loss: 3135.5876 - val_loss: 996.4183
Epoch 24/50
 - 4s - loss: 3149.6704 - val_loss: 950.0208
Epoch 25/50
 - 4s - loss: 3123.3972 - val_loss: 978.5044
Epoch 26/50
 - 4s - loss: 3121.2583 - val_loss: 971.1519
Epoch 27/50
 - 4s - loss: 3122.2932 - val_loss: 940.1514
Epoch 28/50
 - 4s - loss: 3154.4567 - val_loss: 943.3093
Epoch 29/50
 - 4s - loss: 3107.7697 - val_loss: 965.0574
Epoch 30/50
 - 4s - loss: 3123.9772 - val_loss: 932.6898
Epoch 31/50
 - 4s - loss: 3149.7874 - val_loss: 935.4869
Epoch 32/50
 - 4s - loss: 3115.9649 - val_loss: 935.2936
Epoch 33/50
 - 4s - loss: 3116.5948 - val_loss: 964.3574
Epoch 34/50
 - 4s - loss: 3107.9711 - val_loss: 945.8184
Epoch 35/50
 - 4s - loss: 3137.2848 - val_loss: 969.1365
Epoch 36/50
 - 4s - loss: 3121.3430 - val_loss: 931.0891
Epoch 37/50
 - 4s - loss: 3102.2213 - val_loss: 918.6104
Epoch 38/50
 - 4s - loss: 3102.8595 - val_loss: 917.7952
Epoch 39/50
 - 4s - loss: 3125.8338 - val_loss: 916.6746
Epoch 40/50
 - 4s - loss: 3093.9530 - val_loss: 918.6716
Epoch 41/50
 - 4s - loss: 3106.4407 - val_loss: 952.6701
Epoch 42/50
 - 4s - loss: 3112.3568 - val_loss: 931.5475
Epoch 43/50
 - 4s - loss: 3090.0757 - val_loss: 921.7270
Epoch 44/50
 - 4s - loss: 3097.2768 - val_loss: 932.8801
Epoch 45/50
 - 4s - loss: 3103.3344 - val_loss: 920.0299
Epoch 46/50
 - 4s - loss: 3084.1510 - val_loss: 926.5566
Epoch 47/50
 - 4s - loss: 3081.5606 - val_loss: 915.5946
Epoch 48/50
 - 4s - loss: 3087.7399 - val_loss: 908.2911
Epoch 49/50
 - 4s - loss: 3090.2414 - val_loss: 908.6893
Epoch 50/50
 - 4s - loss: 3092.1325 - val_loss: 908.1027
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 51620	action = 0	current_phase = 1	next_phase = 0	reward = 0.717398	array([[ -0.18166351, -43.43064   ]], dtype=float32)
time = 51625	action = 0	current_phase = 1	next_phase = 0	reward = 0.712931	array([[ -0.188941, -43.425232]], dtype=float32)
time = 51630	action = 0	current_phase = 1	next_phase = 0	reward = 0.716354	array([[ -0.14984608, -43.374508  ]], dtype=float32)
time = 51635	action = 0	current_phase = 1	next_phase = 0	reward = 0.443741	array([[ -0.21806622, -43.462418  ]], dtype=float32)
time = 51640	action = 0	current_phase = 1	next_phase = 0	reward = 1.006682	array([[ -0.2294035, -43.469246 ]], dtype=float32)
time = 51645	action = 0	current_phase = 1	next_phase = 0	reward = 0.725003	array([[ -0.17551517, -43.42148   ]], dtype=float32)
time = 51650	action = 0	current_phase = 1	next_phase = 0	reward = 0.724581	array([[ -0.15365505, -43.382236  ]], dtype=float32)
time = 51655	action = 0	current_phase = 1	next_phase = 0	reward = 0.720309	array([[ -0.17094135, -43.419945  ]], dtype=float32)
time = 51660	action = 0	current_phase = 1	next_phase = 0	reward = 0.722517	array([[ -0.22847652, -43.473114  ]], dtype=float32)
time = 51665	action = 0	current_phase = 1	next_phase = 0	reward = 0.718014	array([[ -0.12803268, -43.29448   ]], dtype=float32)
time = 51670	action = 0	current_phase = 1	next_phase = 0	reward = 0.714552	array([[ -0.18884563, -43.417282  ]], dtype=float32)
time = 51675	action = 0	current_phase = 1	next_phase = 0	reward = 0.715370	array([[ -0.21730042, -43.45732   ]], dtype=float32)
time = 51680	action = 0	current_phase = 1	next_phase = 0	reward = 0.718318	array([[ -0.18402767, -43.432396  ]], dtype=float32)
time = 51685	action = 0	current_phase = 1	next_phase = 0	reward = 0.724284	array([[ -0.22744751, -43.472828  ]], dtype=float32)
time = 51690	action = 0	current_phase = 1	next_phase = 0	reward = 0.719245	array([[ -0.22905254, -43.47178   ]], dtype=float32)
time = 51695	action = 0	current_phase = 1	next_phase = 0	reward = 0.718113	array([[ -0.16712284, -43.41042   ]], dtype=float32)
time = 51700	action = 0	current_phase = 1	next_phase = 0	reward = 0.717393	array([[ -0.1917429, -43.445934 ]], dtype=float32)
time = 51705	action = 0	current_phase = 1	next_phase = 0	reward = 0.714966	array([[ -0.21134758, -43.4561    ]], dtype=float32)
time = 51710	action = 0	current_phase = 1	next_phase = 0	reward = 0.436244	array([[ -0.1424408, -43.32145  ]], dtype=float32)
time = 51715	action = 0	current_phase = 1	next_phase = 0	reward = 1.000641	array([[ -0.20774555, -43.420372  ]], dtype=float32)
time = 51720	action = 0	current_phase = 1	next_phase = 0	reward = 0.723171	array([[ -0.19745922, -43.447273  ]], dtype=float32)
time = 51725	action = 0	current_phase = 1	next_phase = 0	reward = 0.444025	array([[ -0.20876217, -43.45084   ]], dtype=float32)
time = 51730	action = 0	current_phase = 1	next_phase = 0	reward = 1.007644	array([[ -0.20203781, -43.439247  ]], dtype=float32)
time = 51735	action = 0	current_phase = 1	next_phase = 0	reward = 0.725368	array([[ -0.20340061, -43.432865  ]], dtype=float32)
time = 51740	action = 0	current_phase = 1	next_phase = 0	reward = 0.724635	array([[ -0.15261555, -43.399277  ]], dtype=float32)
time = 51745	action = 0	current_phase = 1	next_phase = 0	reward = 0.722245	array([[ -0.19861794, -43.429905  ]], dtype=float32)
time = 51750	action = 0	current_phase = 1	next_phase = 0	reward = 0.718152	array([[ -0.2140665, -43.459366 ]], dtype=float32)
time = 51755	action = 0	current_phase = 1	next_phase = 0	reward = 0.713717	array([[ -0.13689232, -43.338886  ]], dtype=float32)
time = 51760	action = 0	current_phase = 1	next_phase = 0	reward = 0.714218	array([[ -0.2195797, -43.454777 ]], dtype=float32)
time = 51765	action = 0	current_phase = 1	next_phase = 0	reward = 0.445659	array([[ -0.15204239, -43.3848    ]], dtype=float32)
time = 51770	action = 0	current_phase = 1	next_phase = 0	reward = 1.003373	array([[ -0.19622421, -43.402744  ]], dtype=float32)
time = 51775	action = 0	current_phase = 1	next_phase = 0	reward = 0.725422	array([[ -0.21261787, -43.45179   ]], dtype=float32)
time = 51780	action = 0	current_phase = 1	next_phase = 0	reward = 0.718707	array([[ -0.22408772, -43.451317  ]], dtype=float32)
time = 51785	action = 0	current_phase = 1	next_phase = 0	reward = 0.723498	array([[ -0.22556686, -43.47708   ]], dtype=float32)
time = 51790	action = 0	current_phase = 1	next_phase = 0	reward = 0.718397	array([[ -0.14249611, -43.390762  ]], dtype=float32)
time = 51795	action = 0	current_phase = 1	next_phase = 0	reward = 0.720539	array([[ -0.16813183, -43.40567   ]], dtype=float32)
time = 51800	action = 0	current_phase = 1	next_phase = 0	reward = 0.444669	array([[ -0.1895771, -43.42892  ]], dtype=float32)
time = 51805	action = 0	current_phase = 1	next_phase = 0	reward = 0.996904	array([[ -0.21106434, -43.467567  ]], dtype=float32)
time = 51810	action = 0	current_phase = 1	next_phase = 0	reward = 0.717441	array([[ -0.1972189, -43.456997 ]], dtype=float32)
time = 51815	action = 0	current_phase = 1	next_phase = 0	reward = 0.716784	array([[ -0.22792053, -43.46502   ]], dtype=float32)
time = 51820	action = 0	current_phase = 1	next_phase = 0	reward = 0.440389	array([[ -0.16134834, -43.405575  ]], dtype=float32)
time = 51825	action = 0	current_phase = 1	next_phase = 0	reward = 0.998721	array([[ -0.13419819, -43.373295  ]], dtype=float32)
time = 51830	action = 0	current_phase = 1	next_phase = 0	reward = 0.437952	array([[ -0.19908714, -43.4436    ]], dtype=float32)
time = 51835	action = 0	current_phase = 1	next_phase = 0	reward = 1.004917	array([[ -0.1838646, -43.41865  ]], dtype=float32)
time = 51840	action = 0	current_phase = 1	next_phase = 0	reward = 0.438307	array([[ -0.16858864, -43.420002  ]], dtype=float32)
time = 51845	action = 0	current_phase = 1	next_phase = 0	reward = 1.000096	array([[ -0.18762875, -43.44661   ]], dtype=float32)
time = 51850	action = 0	current_phase = 1	next_phase = 0	reward = 0.440272	array([[ -0.18897533, -43.43235   ]], dtype=float32)
time = 51855	action = 0	current_phase = 1	next_phase = 0	reward = 0.726420	array([[ -0.19058132, -43.42881   ]], dtype=float32)
time = 51860	action = 0	current_phase = 1	next_phase = 0	reward = 1.011247	array([[ -0.20724392, -43.452065  ]], dtype=float32)
time = 51865	action = 0	current_phase = 1	next_phase = 0	reward = 0.721357	array([[ -0.2059555, -43.455803 ]], dtype=float32)
time = 51870	action = 0	current_phase = 1	next_phase = 0	reward = 0.433186	array([[ -0.18160152, -43.425484  ]], dtype=float32)
time = 51875	action = 0	current_phase = 1	next_phase = 0	reward = 0.987685	array([[ -0.2178402, -43.452538 ]], dtype=float32)
time = 51880	action = 0	current_phase = 1	next_phase = 0	reward = 0.712725	array([[ -0.19205189, -43.43741   ]], dtype=float32)
time = 51885	action = 0	current_phase = 1	next_phase = 0	reward = 0.442991	array([[ -0.17250252, -43.434795  ]], dtype=float32)
time = 51890	action = 0	current_phase = 1	next_phase = 0	reward = 1.014218	array([[ -0.18790627, -43.434586  ]], dtype=float32)
time = 51895	action = 0	current_phase = 1	next_phase = 0	reward = 0.729307	array([[ -0.18754959, -43.45091   ]], dtype=float32)
time = 51900	action = 0	current_phase = 1	next_phase = 0	reward = 0.720050	array([[ -0.15139008, -43.393223  ]], dtype=float32)
time = 51905	action = 0	current_phase = 1	next_phase = 0	reward = 0.716585	array([[ -0.17342377, -43.408638  ]], dtype=float32)
time = 51910	action = 0	current_phase = 1	next_phase = 0	reward = 0.436384	array([[ -0.20969677, -43.428658  ]], dtype=float32)
time = 51915	action = 0	current_phase = 1	next_phase = 0	reward = 0.716378	array([[ -0.19183445, -43.451607  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 1112.5251 - val_loss: 6186.0252
Epoch 2/50
 - 4s - loss: 1111.2333 - val_loss: 6261.3257
Epoch 3/50
 - 4s - loss: 1109.7991 - val_loss: 6217.9636
Epoch 4/50
 - 4s - loss: 1110.8026 - val_loss: 6174.3845
Epoch 5/50
 - 4s - loss: 1113.4631 - val_loss: 6161.2135
Epoch 6/50
 - 4s - loss: 1099.0451 - val_loss: 6160.1579
Epoch 7/50
 - 4s - loss: 1077.7353 - val_loss: 6161.5767
Epoch 8/50
 - 4s - loss: 1091.2015 - val_loss: 6143.3048
Epoch 9/50
 - 4s - loss: 1081.2352 - val_loss: 6170.9543
Epoch 10/50
 - 4s - loss: 1078.7677 - val_loss: 6166.8348
Epoch 11/50
 - 4s - loss: 1082.5476 - val_loss: 6214.9034
Epoch 12/50
 - 4s - loss: 1088.4706 - val_loss: 6163.6082
Epoch 13/50
 - 4s - loss: 1078.4761 - val_loss: 6151.2166
Epoch 14/50
 - 4s - loss: 1072.0667 - val_loss: 6175.8599
Epoch 15/50
 - 4s - loss: 1077.3665 - val_loss: 6150.0636
Epoch 16/50
 - 4s - loss: 1055.4733 - val_loss: 6121.1746
Epoch 17/50
 - 4s - loss: 1073.2483 - val_loss: 6117.5123
Epoch 18/50
 - 4s - loss: 1071.2996 - val_loss: 6128.9374
Epoch 19/50
 - 4s - loss: 1056.1157 - val_loss: 6162.4334
Epoch 20/50
 - 4s - loss: 1068.8162 - val_loss: 6121.8814
Epoch 21/50
 - 4s - loss: 1066.0976 - val_loss: 6132.5548
Epoch 22/50
 - 4s - loss: 1056.9306 - val_loss: 6106.0449
Epoch 23/50
 - 4s - loss: 1054.0425 - val_loss: 6126.7519
Epoch 24/50
 - 4s - loss: 1060.6848 - val_loss: 6210.3828
Epoch 25/50
 - 4s - loss: 1064.6132 - val_loss: 6107.0277
Epoch 26/50
 - 4s - loss: 1050.3308 - val_loss: 6109.3008
Epoch 27/50
 - 4s - loss: 1049.7574 - val_loss: 6098.4256
Epoch 28/50
 - 4s - loss: 1045.5594 - val_loss: 6105.5627
Epoch 29/50
 - 4s - loss: 1044.5201 - val_loss: 6143.8528
Epoch 30/50
 - 4s - loss: 1033.7647 - val_loss: 6092.3184
Epoch 31/50
 - 4s - loss: 1044.9344 - val_loss: 6105.5137
Epoch 32/50
 - 4s - loss: 1047.2274 - val_loss: 6097.3122
Epoch 33/50
 - 4s - loss: 1034.5540 - val_loss: 6105.9811
Epoch 34/50
 - 4s - loss: 1036.5127 - val_loss: 6077.4720
Epoch 35/50
 - 4s - loss: 1028.4824 - val_loss: 6091.9903
Epoch 36/50
 - 4s - loss: 1044.9991 - val_loss: 6086.3293
Epoch 37/50
 - 4s - loss: 1035.9396 - val_loss: 6174.3322
Epoch 38/50
 - 4s - loss: 1032.9955 - val_loss: 6070.1989
Epoch 39/50
 - 4s - loss: 1033.8584 - val_loss: 6090.5502
Epoch 40/50
 - 4s - loss: 1023.8786 - val_loss: 6064.8093
Epoch 41/50
 - 4s - loss: 1016.1312 - val_loss: 6072.9083
Epoch 42/50
 - 4s - loss: 1023.6932 - val_loss: 6130.1957
Epoch 43/50
 - 4s - loss: 1012.7067 - val_loss: 6067.7540
Epoch 44/50
 - 4s - loss: 1002.2713 - val_loss: 6079.2047
Epoch 45/50
 - 4s - loss: 1013.4529 - val_loss: 6093.9214
Epoch 46/50
 - 4s - loss: 1017.4409 - val_loss: 6073.8679
Epoch 47/50
 - 4s - loss: 1018.3314 - val_loss: 6079.3453
Epoch 48/50
 - 4s - loss: 1024.0691 - val_loss: 6096.3540
Epoch 49/50
 - 4s - loss: 1011.6825 - val_loss: 6075.9776
Epoch 50/50
 - 4s - loss: 1002.4154 - val_loss: 6071.2857
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 51920	action = 0	current_phase = 1	next_phase = 0	reward = 1.016802	array([[ -0.13868904, -43.468422  ]], dtype=float32)
time = 51925	action = 0	current_phase = 1	next_phase = 0	reward = 0.724506	array([[ -0.16011715, -43.498474  ]], dtype=float32)
time = 51930	action = 0	current_phase = 1	next_phase = 0	reward = 0.720553	array([[ -0.13861656, -43.482605  ]], dtype=float32)
time = 51935	action = 0	current_phase = 1	next_phase = 0	reward = 0.721446	array([[ -0.11218739, -43.444374  ]], dtype=float32)
time = 51940	action = 0	current_phase = 1	next_phase = 0	reward = 0.724625	array([[ -0.07839203, -43.371162  ]], dtype=float32)
time = 51945	action = 0	current_phase = 1	next_phase = 0	reward = 0.722726	array([[ -0.07952881, -43.355125  ]], dtype=float32)
time = 51950	action = 0	current_phase = 1	next_phase = 0	reward = 0.722634	array([[ -0.14277649, -43.482533  ]], dtype=float32)
time = 51955	action = 0	current_phase = 1	next_phase = 0	reward = 0.722198	array([[ -0.14822865, -43.48645   ]], dtype=float32)
time = 51960	action = 0	current_phase = 1	next_phase = 0	reward = 0.726369	array([[ -0.12198067, -43.45662   ]], dtype=float32)
time = 51965	action = 0	current_phase = 1	next_phase = 0	reward = 0.438923	array([[ -0.13048935, -43.466084  ]], dtype=float32)
time = 51970	action = 0	current_phase = 1	next_phase = 0	reward = 1.000410	array([[ -0.13465595, -43.464424  ]], dtype=float32)
time = 51975	action = 0	current_phase = 1	next_phase = 0	reward = 0.719866	array([[ -0.18083763, -43.518032  ]], dtype=float32)
time = 51980	action = 0	current_phase = 1	next_phase = 0	reward = 0.714561	array([[ -0.14927673, -43.493813  ]], dtype=float32)
time = 51985	action = 0	current_phase = 1	next_phase = 0	reward = 0.710633	array([[ -0.14408779, -43.480095  ]], dtype=float32)
time = 51990	action = 0	current_phase = 1	next_phase = 0	reward = 0.434447	array([[ -0.17211628, -43.506516  ]], dtype=float32)
time = 51995	action = 0	current_phase = 1	next_phase = 0	reward = 0.995829	array([[ -0.0770359, -43.242687 ]], dtype=float32)
time = 52000	action = 0	current_phase = 1	next_phase = 0	reward = 0.162380	array([[ -0.14531517, -43.486233  ]], dtype=float32)
time = 52005	action = 0	current_phase = 1	next_phase = 0	reward = 1.285073	array([[ -0.15924263, -43.49987   ]], dtype=float32)
time = 52010	action = 0	current_phase = 1	next_phase = 0	reward = 0.445572	array([[ -0.1547451, -43.49707  ]], dtype=float32)
time = 52015	action = 0	current_phase = 1	next_phase = 0	reward = 1.009188	array([[ -0.15366459, -43.49463   ]], dtype=float32)
time = 52020	action = 0	current_phase = 1	next_phase = 0	reward = 0.726951	array([[ -0.15909863, -43.49737   ]], dtype=float32)
time = 52025	action = 0	current_phase = 1	next_phase = 0	reward = 0.435768	array([[ -0.15615463, -43.4914    ]], dtype=float32)
time = 52030	action = 0	current_phase = 1	next_phase = 0	reward = 0.992473	array([[ -0.13904381, -43.40689   ]], dtype=float32)
time = 52035	action = 0	current_phase = 1	next_phase = 0	reward = 0.716212	array([[ -0.1281395, -43.428997 ]], dtype=float32)
time = 52040	action = 0	current_phase = 1	next_phase = 0	reward = 0.718662	array([[ -0.12554836, -43.461983  ]], dtype=float32)
time = 52045	action = 0	current_phase = 1	next_phase = 0	reward = 0.717754	array([[ -0.08603287, -43.399986  ]], dtype=float32)
time = 52050	action = 0	current_phase = 1	next_phase = 0	reward = 0.720165	array([[ -0.10928917, -43.451904  ]], dtype=float32)
time = 52055	action = 0	current_phase = 1	next_phase = 0	reward = 0.725711	array([[ -0.16846085, -43.50258   ]], dtype=float32)
time = 52060	action = 0	current_phase = 1	next_phase = 0	reward = 0.442596	array([[ -0.12770367, -43.47322   ]], dtype=float32)
time = 52065	action = 0	current_phase = 1	next_phase = 0	reward = 0.997117	array([[ -0.10213089, -43.393173  ]], dtype=float32)
time = 52070	action = 0	current_phase = 1	next_phase = 0	reward = 0.721040	array([[ -0.12804317, -43.4694    ]], dtype=float32)
time = 52075	action = 0	current_phase = 1	next_phase = 0	reward = 0.715658	array([[ -0.18089294, -43.507675  ]], dtype=float32)
time = 52080	action = 0	current_phase = 1	next_phase = 0	reward = 0.712692	array([[ -0.1331234, -43.471325 ]], dtype=float32)
time = 52085	action = 0	current_phase = 1	next_phase = 0	reward = 0.719701	array([[ -0.11471939, -43.45662   ]], dtype=float32)
time = 52090	action = 0	current_phase = 1	next_phase = 0	reward = 0.157045	array([[ -0.15518665, -43.454117  ]], dtype=float32)
time = 52095	action = 0	current_phase = 1	next_phase = 0	reward = 1.289837	array([[ -0.13853645, -43.482384  ]], dtype=float32)
time = 52100	action = 0	current_phase = 1	next_phase = 0	reward = 0.722941	array([[ -0.15218735, -43.49504   ]], dtype=float32)
time = 52105	action = 0	current_phase = 1	next_phase = 0	reward = 0.716782	array([[ -0.09342957, -43.41632   ]], dtype=float32)
time = 52110	action = 0	current_phase = 1	next_phase = 0	reward = 0.443904	array([[ -0.15908623, -43.50303   ]], dtype=float32)
time = 52115	action = 0	current_phase = 1	next_phase = 0	reward = 1.001995	array([[ -0.11856937, -43.445133  ]], dtype=float32)
time = 52120	action = 0	current_phase = 1	next_phase = 0	reward = 0.724718	array([[ -0.15671062, -43.49231   ]], dtype=float32)
time = 52125	action = 0	current_phase = 1	next_phase = 0	reward = 0.720185	array([[ -0.10627937, -43.435196  ]], dtype=float32)
time = 52130	action = 0	current_phase = 1	next_phase = 0	reward = 0.437909	array([[ -0.11696053, -43.47332   ]], dtype=float32)
time = 52135	action = 0	current_phase = 1	next_phase = 0	reward = 1.004393	array([[ -0.13546467, -43.451942  ]], dtype=float32)
time = 52140	action = 0	current_phase = 1	next_phase = 0	reward = 0.718915	array([[ -0.121665, -43.431816]], dtype=float32)
time = 52145	action = 0	current_phase = 1	next_phase = 0	reward = 0.717114	array([[ -0.12392139, -43.444695  ]], dtype=float32)
time = 52150	action = 0	current_phase = 1	next_phase = 0	reward = 0.718366	array([[ -0.15333271, -43.49264   ]], dtype=float32)
time = 52155	action = 0	current_phase = 1	next_phase = 0	reward = 0.727780	array([[ -0.14659691, -43.48842   ]], dtype=float32)
time = 52160	action = 0	current_phase = 1	next_phase = 0	reward = 0.721188	array([[ -0.13003731, -43.467094  ]], dtype=float32)
time = 52165	action = 0	current_phase = 1	next_phase = 0	reward = 0.721099	array([[ -0.13508892, -43.477226  ]], dtype=float32)
time = 52170	action = 0	current_phase = 1	next_phase = 0	reward = 0.723563	array([[ -0.15786743, -43.49511   ]], dtype=float32)
time = 52175	action = 0	current_phase = 1	next_phase = 0	reward = 0.719738	array([[ -0.12980843, -43.455772  ]], dtype=float32)
time = 52180	action = 0	current_phase = 1	next_phase = 0	reward = 0.432090	array([[ -0.11297512, -43.44588   ]], dtype=float32)
time = 52185	action = 0	current_phase = 1	next_phase = 0	reward = 0.725158	array([[ -0.12469959, -43.46424   ]], dtype=float32)
time = 52190	action = 0	current_phase = 1	next_phase = 0	reward = 1.011189	array([[ -0.14928341, -43.48948   ]], dtype=float32)
time = 52195	action = 0	current_phase = 1	next_phase = 0	reward = 0.727264	array([[ -0.14002609, -43.47599   ]], dtype=float32)
time = 52200	action = 0	current_phase = 1	next_phase = 0	reward = 0.720492	array([[ -0.16664028, -43.501923  ]], dtype=float32)
time = 52205	action = 0	current_phase = 1	next_phase = 0	reward = 0.723648	array([[ -0.15998173, -43.490303  ]], dtype=float32)
time = 52210	action = 0	current_phase = 1	next_phase = 0	reward = 0.712441	array([[ -0.10877991, -43.443245  ]], dtype=float32)
time = 52215	action = 0	current_phase = 1	next_phase = 0	reward = 0.723443	array([[ -0.12636185, -43.463005  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2682.4935 - val_loss: 800.2879
Epoch 2/50
 - 4s - loss: 2647.4175 - val_loss: 795.4599
Epoch 3/50
 - 4s - loss: 2638.8106 - val_loss: 797.1894
Epoch 4/50
 - 4s - loss: 2651.9405 - val_loss: 798.0191
Epoch 5/50
 - 4s - loss: 2639.4592 - val_loss: 834.1734
Epoch 6/50
 - 4s - loss: 2664.9040 - val_loss: 785.4648
Epoch 7/50
 - 4s - loss: 2638.9549 - val_loss: 775.3483
Epoch 8/50
 - 4s - loss: 2635.3214 - val_loss: 793.5753
Epoch 9/50
 - 4s - loss: 2635.8285 - val_loss: 787.5206
Epoch 10/50
 - 4s - loss: 2641.4858 - val_loss: 793.3403
Epoch 11/50
 - 4s - loss: 2650.4877 - val_loss: 826.2444
Epoch 12/50
 - 4s - loss: 2636.6472 - val_loss: 771.2576
Epoch 13/50
 - 4s - loss: 2638.0534 - val_loss: 775.2780
Epoch 14/50
 - 4s - loss: 2627.7108 - val_loss: 771.6106
Epoch 15/50
 - 4s - loss: 2625.3493 - val_loss: 789.9637
Epoch 16/50
 - 4s - loss: 2624.6506 - val_loss: 772.2209
Epoch 17/50
 - 4s - loss: 2632.2709 - val_loss: 782.0274
Epoch 18/50
 - 4s - loss: 2610.0055 - val_loss: 814.4356
Epoch 19/50
 - 4s - loss: 2638.9819 - val_loss: 767.4947
Epoch 20/50
 - 4s - loss: 2626.9308 - val_loss: 753.4920
Epoch 21/50
 - 4s - loss: 2619.2895 - val_loss: 760.0857
Epoch 22/50
 - 4s - loss: 2624.0488 - val_loss: 769.6442
Epoch 23/50
 - 4s - loss: 2617.2200 - val_loss: 803.9700
Epoch 24/50
 - 4s - loss: 2630.4284 - val_loss: 751.4192
Epoch 25/50
 - 4s - loss: 2609.2040 - val_loss: 754.7119
Epoch 26/50
 - 4s - loss: 2618.7731 - val_loss: 789.2033
Epoch 27/50
 - 4s - loss: 2622.7941 - val_loss: 761.2530
Epoch 28/50
 - 4s - loss: 2621.3539 - val_loss: 756.9459
Epoch 29/50
 - 4s - loss: 2605.4644 - val_loss: 761.2455
Epoch 30/50
 - 4s - loss: 2617.3072 - val_loss: 763.9912
Epoch 31/50
 - 4s - loss: 2606.8430 - val_loss: 749.7018
Epoch 32/50
 - 4s - loss: 2603.7200 - val_loss: 756.8012
Epoch 33/50
 - 4s - loss: 2619.6935 - val_loss: 763.9842
Epoch 34/50
 - 4s - loss: 2590.1619 - val_loss: 750.7844
Epoch 35/50
 - 4s - loss: 2601.8714 - val_loss: 734.6717
Epoch 36/50
 - 4s - loss: 2593.8041 - val_loss: 749.8605
Epoch 37/50
 - 4s - loss: 2605.8460 - val_loss: 746.9239
Epoch 38/50
 - 4s - loss: 2608.5039 - val_loss: 779.1929
Epoch 39/50
 - 4s - loss: 2616.8249 - val_loss: 781.3092
Epoch 40/50
 - 4s - loss: 2597.7578 - val_loss: 756.1385
Epoch 41/50
 - 4s - loss: 2587.0759 - val_loss: 769.8536
Epoch 42/50
 - 4s - loss: 2633.7554 - val_loss: 740.1487
Epoch 43/50
 - 4s - loss: 2595.1305 - val_loss: 749.3103
Epoch 44/50
 - 4s - loss: 2597.6751 - val_loss: 747.3011
Epoch 45/50
 - 4s - loss: 2586.2539 - val_loss: 762.4602
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 52220	action = 0	current_phase = 1	next_phase = 0	reward = 0.723089	array([[ -0.16716003, -43.53279   ]], dtype=float32)
time = 52225	action = 0	current_phase = 1	next_phase = 0	reward = 0.721547	array([[ -0.15300179, -43.50026   ]], dtype=float32)
time = 52230	action = 0	current_phase = 1	next_phase = 0	reward = 0.446017	array([[ -0.12805748, -43.431915  ]], dtype=float32)
time = 52235	action = 0	current_phase = 1	next_phase = 0	reward = 0.997186	array([[ -0.15601349, -43.482147  ]], dtype=float32)
time = 52240	action = 0	current_phase = 1	next_phase = 0	reward = 0.721801	array([[ -0.1298685, -43.438854 ]], dtype=float32)
time = 52245	action = 0	current_phase = 1	next_phase = 0	reward = 0.721669	array([[ -0.15706444, -43.51336   ]], dtype=float32)
time = 52250	action = 0	current_phase = 1	next_phase = 0	reward = 0.719312	array([[ -0.19093323, -43.4207    ]], dtype=float32)
time = 52255	action = 0	current_phase = 1	next_phase = 0	reward = 0.443366	array([[ -0.15874863, -43.513096  ]], dtype=float32)
time = 52260	action = 0	current_phase = 1	next_phase = 0	reward = 1.007552	array([[ -0.14576721, -43.48076   ]], dtype=float32)
time = 52265	action = 0	current_phase = 1	next_phase = 0	reward = 0.725746	array([[ -0.13827896, -43.464783  ]], dtype=float32)
time = 52270	action = 0	current_phase = 1	next_phase = 0	reward = 0.723716	array([[ -0.1642704, -43.529987 ]], dtype=float32)
time = 52275	action = 0	current_phase = 1	next_phase = 0	reward = 0.721820	array([[ -0.14904499, -43.46161   ]], dtype=float32)
time = 52280	action = 0	current_phase = 1	next_phase = 0	reward = 0.444650	array([[ -0.16737747, -43.330727  ]], dtype=float32)
time = 52285	action = 0	current_phase = 1	next_phase = 0	reward = 1.005736	array([[ -0.13696289, -43.465267  ]], dtype=float32)
time = 52290	action = 0	current_phase = 1	next_phase = 0	reward = 0.726913	array([[ -0.14050102, -43.454384  ]], dtype=float32)
time = 52295	action = 0	current_phase = 1	next_phase = 0	reward = 0.719665	array([[ -0.13798332, -43.456924  ]], dtype=float32)
time = 52300	action = 0	current_phase = 1	next_phase = 0	reward = 0.721273	array([[ -0.16163445, -43.52224   ]], dtype=float32)
time = 52305	action = 0	current_phase = 1	next_phase = 0	reward = 0.724247	array([[ -0.13673878, -43.452568  ]], dtype=float32)
time = 52310	action = 0	current_phase = 1	next_phase = 0	reward = 0.726038	array([[ -0.139328, -43.470116]], dtype=float32)
time = 52315	action = 0	current_phase = 1	next_phase = 0	reward = 0.716770	array([[ -0.14973164, -43.500114  ]], dtype=float32)
time = 52320	action = 0	current_phase = 1	next_phase = 0	reward = 0.718509	array([[ -0.11907482, -43.407364  ]], dtype=float32)
time = 52325	action = 0	current_phase = 1	next_phase = 0	reward = 0.722749	array([[ -0.13240433, -43.451378  ]], dtype=float32)
time = 52330	action = 0	current_phase = 1	next_phase = 0	reward = 0.449853	array([[ -0.13766003, -43.477932  ]], dtype=float32)
time = 52335	action = 0	current_phase = 1	next_phase = 0	reward = 1.009320	array([[ -0.13973427, -43.467377  ]], dtype=float32)
time = 52340	action = 0	current_phase = 1	next_phase = 0	reward = 0.723918	array([[ -0.13498783, -43.455406  ]], dtype=float32)
time = 52345	action = 0	current_phase = 1	next_phase = 0	reward = 0.723132	array([[ -0.14221 , -43.474632]], dtype=float32)
time = 52350	action = 0	current_phase = 1	next_phase = 0	reward = 0.722292	array([[ -0.15795994, -43.517303  ]], dtype=float32)
time = 52355	action = 0	current_phase = 1	next_phase = 0	reward = 0.446224	array([[ -0.13757992, -43.426476  ]], dtype=float32)
time = 52360	action = 0	current_phase = 1	next_phase = 0	reward = 1.005389	array([[ -0.13437653, -43.443737  ]], dtype=float32)
time = 52365	action = 0	current_phase = 1	next_phase = 0	reward = 0.723062	array([[ -0.15612793, -43.51163   ]], dtype=float32)
time = 52370	action = 0	current_phase = 1	next_phase = 0	reward = 0.724556	array([[ -0.1658783, -43.52481  ]], dtype=float32)
time = 52375	action = 0	current_phase = 1	next_phase = 0	reward = 0.722284	array([[ -0.13812065, -43.48861   ]], dtype=float32)
time = 52380	action = 0	current_phase = 1	next_phase = 0	reward = 0.716349	array([[ -0.12909508, -43.39998   ]], dtype=float32)
time = 52385	action = 0	current_phase = 1	next_phase = 0	reward = 0.710097	array([[ -0.16867256, -43.535545  ]], dtype=float32)
time = 52390	action = 0	current_phase = 1	next_phase = 0	reward = 0.437553	array([[ -0.1493473, -43.50019  ]], dtype=float32)
time = 52395	action = 0	current_phase = 1	next_phase = 0	reward = 1.006838	array([[ -0.15369797, -43.499363  ]], dtype=float32)
time = 52400	action = 0	current_phase = 1	next_phase = 0	reward = 0.726670	array([[ -0.14449024, -43.474777  ]], dtype=float32)
time = 52405	action = 0	current_phase = 1	next_phase = 0	reward = 0.720651	array([[ -0.130867, -43.45025 ]], dtype=float32)
time = 52410	action = 0	current_phase = 1	next_phase = 0	reward = 0.726849	array([[ -0.13312054, -43.4319    ]], dtype=float32)
time = 52415	action = 0	current_phase = 1	next_phase = 0	reward = 0.726853	array([[ -0.12931442, -43.40531   ]], dtype=float32)
time = 52420	action = 0	current_phase = 1	next_phase = 0	reward = 0.726344	array([[ -0.13022804, -43.442955  ]], dtype=float32)
time = 52425	action = 0	current_phase = 1	next_phase = 0	reward = 0.720004	array([[ -0.14576054, -43.46186   ]], dtype=float32)
time = 52430	action = 0	current_phase = 1	next_phase = 0	reward = 0.719037	array([[ -0.14777184, -43.466743  ]], dtype=float32)
time = 52435	action = 0	current_phase = 1	next_phase = 0	reward = 0.719812	array([[ -0.14484024, -43.481792  ]], dtype=float32)
time = 52440	action = 0	current_phase = 1	next_phase = 0	reward = 0.433874	array([[ -0.15193939, -43.507202  ]], dtype=float32)
time = 52445	action = 0	current_phase = 1	next_phase = 0	reward = 1.003571	array([[ -0.13784218, -43.383347  ]], dtype=float32)
time = 52450	action = 0	current_phase = 1	next_phase = 0	reward = 0.450285	array([[ -0.15209484, -43.504417  ]], dtype=float32)
time = 52455	action = 0	current_phase = 1	next_phase = 0	reward = 1.006536	array([[ -0.13967896, -43.44331   ]], dtype=float32)
time = 52460	action = 0	current_phase = 1	next_phase = 0	reward = 0.716415	array([[ -0.13597679, -43.470604  ]], dtype=float32)
time = 52465	action = 0	current_phase = 1	next_phase = 0	reward = 0.723774	array([[ -0.14960766, -43.502922  ]], dtype=float32)
time = 52470	action = 0	current_phase = 1	next_phase = 0	reward = 0.719556	array([[ -0.14621639, -43.47795   ]], dtype=float32)
time = 52475	action = 0	current_phase = 1	next_phase = 0	reward = 0.721508	array([[ -0.17112923, -43.483994  ]], dtype=float32)
time = 52480	action = 0	current_phase = 1	next_phase = 0	reward = 0.718907	array([[ -0.12735844, -43.40103   ]], dtype=float32)
time = 52485	action = 0	current_phase = 1	next_phase = 0	reward = 0.719169	array([[ -0.15614796, -43.510696  ]], dtype=float32)
time = 52490	action = 0	current_phase = 1	next_phase = 0	reward = 0.719328	array([[ -0.1356287, -43.400856 ]], dtype=float32)
time = 52495	action = 0	current_phase = 1	next_phase = 0	reward = 0.715284	array([[ -0.1262474, -43.437508 ]], dtype=float32)
time = 52500	action = 0	current_phase = 1	next_phase = 0	reward = 0.437260	array([[ -0.13548088, -43.42428   ]], dtype=float32)
time = 52505	action = 0	current_phase = 1	next_phase = 0	reward = 0.723010	array([[ -0.14728642, -43.486427  ]], dtype=float32)
time = 52510	action = 0	current_phase = 1	next_phase = 0	reward = 1.005243	array([[ -0.14323235, -43.471725  ]], dtype=float32)
time = 52515	action = 0	current_phase = 1	next_phase = 0	reward = 0.716183	array([[ -0.14394283, -43.49881   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 3222.6745 - val_loss: 320.7241
Epoch 2/50
 - 4s - loss: 3206.8214 - val_loss: 329.8329
Epoch 3/50
 - 4s - loss: 3226.2526 - val_loss: 305.9417
Epoch 4/50
 - 4s - loss: 3205.4003 - val_loss: 328.2173
Epoch 5/50
 - 4s - loss: 3211.4854 - val_loss: 371.5150
Epoch 6/50
 - 4s - loss: 3216.9171 - val_loss: 362.3277
Epoch 7/50
 - 4s - loss: 3214.2709 - val_loss: 332.2835
Epoch 8/50
 - 4s - loss: 3192.9422 - val_loss: 335.3534
Epoch 9/50
 - 4s - loss: 3190.9025 - val_loss: 335.4515
Epoch 10/50
 - 4s - loss: 3190.5154 - val_loss: 325.8655
Epoch 11/50
 - 4s - loss: 3192.2413 - val_loss: 330.2151
Epoch 12/50
 - 4s - loss: 3179.2068 - val_loss: 333.2564
Epoch 13/50
 - 4s - loss: 3176.5410 - val_loss: 343.4085
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 52520	action = 0	current_phase = 1	next_phase = 0	reward = 0.445813	array([[ -0.21875 , -43.475647]], dtype=float32)
time = 52525	action = 0	current_phase = 1	next_phase = 0	reward = 1.002263	array([[ -0.19965267, -43.44147   ]], dtype=float32)
time = 52530	action = 0	current_phase = 1	next_phase = 0	reward = 0.444822	array([[ -0.19437408, -43.418724  ]], dtype=float32)
time = 52535	action = 0	current_phase = 1	next_phase = 0	reward = 1.003525	array([[ -0.18377018, -43.336876  ]], dtype=float32)
time = 52540	action = 0	current_phase = 1	next_phase = 0	reward = 0.444373	array([[ -0.19963741, -43.44584   ]], dtype=float32)
time = 52545	action = 0	current_phase = 1	next_phase = 0	reward = 1.005850	array([[ -0.22045135, -43.490715  ]], dtype=float32)
time = 52550	action = 0	current_phase = 1	next_phase = 0	reward = 0.720944	array([[ -0.21742153, -43.479084  ]], dtype=float32)
time = 52555	action = 0	current_phase = 1	next_phase = 0	reward = 0.445776	array([[ -0.20855904, -43.435444  ]], dtype=float32)
time = 52560	action = 0	current_phase = 1	next_phase = 0	reward = 1.003133	array([[ -0.21358776, -43.479996  ]], dtype=float32)
time = 52565	action = 0	current_phase = 1	next_phase = 0	reward = 0.723605	array([[ -0.20613003, -43.450912  ]], dtype=float32)
time = 52570	action = 0	current_phase = 1	next_phase = 0	reward = 0.712659	array([[ -0.22375679, -43.499588  ]], dtype=float32)
time = 52575	action = 0	current_phase = 1	next_phase = 0	reward = 0.711107	array([[ -0.22322369, -43.493988  ]], dtype=float32)
time = 52580	action = 0	current_phase = 1	next_phase = 0	reward = 0.160928	array([[ -0.20194721, -43.450317  ]], dtype=float32)
time = 52585	action = 0	current_phase = 1	next_phase = 0	reward = 1.015973	array([[ -0.21187782, -43.46923   ]], dtype=float32)
time = 52590	action = 0	current_phase = 1	next_phase = 0	reward = 1.017170	array([[ -0.19894409, -43.430847  ]], dtype=float32)
time = 52595	action = 0	current_phase = 1	next_phase = 0	reward = 0.725704	array([[ -0.21634388, -43.48612   ]], dtype=float32)
time = 52600	action = 0	current_phase = 1	next_phase = 0	reward = 0.724918	array([[ -0.22750282, -43.505314  ]], dtype=float32)
time = 52605	action = 0	current_phase = 1	next_phase = 0	reward = 0.720524	array([[ -0.17784023, -43.342514  ]], dtype=float32)
time = 52610	action = 0	current_phase = 1	next_phase = 0	reward = 0.716470	array([[ -0.18355179, -43.23706   ]], dtype=float32)
time = 52615	action = 0	current_phase = 1	next_phase = 0	reward = 0.704317	array([[ -0.20544434, -43.372383  ]], dtype=float32)
time = 52620	action = 0	current_phase = 1	next_phase = 0	reward = 0.722446	array([[ -0.20258904, -43.429646  ]], dtype=float32)
time = 52625	action = 0	current_phase = 1	next_phase = 0	reward = 0.712848	array([[ -0.18134308, -43.407547  ]], dtype=float32)
time = 52630	action = 0	current_phase = 1	next_phase = 0	reward = 0.728621	array([[ -0.18265629, -43.348293  ]], dtype=float32)
time = 52635	action = 0	current_phase = 1	next_phase = 0	reward = 0.722838	array([[ -0.21061516, -43.447548  ]], dtype=float32)
time = 52640	action = 0	current_phase = 1	next_phase = 0	reward = 0.718284	array([[ -0.20248699, -43.283714  ]], dtype=float32)
time = 52645	action = 0	current_phase = 1	next_phase = 0	reward = 0.721290	array([[ -0.18716812, -43.38401   ]], dtype=float32)
time = 52650	action = 0	current_phase = 1	next_phase = 0	reward = 0.720716	array([[ -0.20580292, -43.455975  ]], dtype=float32)
time = 52655	action = 0	current_phase = 1	next_phase = 0	reward = 0.440572	array([[ -0.20355797, -43.380802  ]], dtype=float32)
time = 52660	action = 0	current_phase = 1	next_phase = 0	reward = 0.999487	array([[ -0.2394476, -43.52153  ]], dtype=float32)
time = 52665	action = 0	current_phase = 1	next_phase = 0	reward = 0.722953	array([[ -0.1891489, -43.367203 ]], dtype=float32)
time = 52670	action = 0	current_phase = 1	next_phase = 0	reward = 0.443191	array([[ -0.19397068, -43.321182  ]], dtype=float32)
time = 52675	action = 0	current_phase = 1	next_phase = 0	reward = 1.004163	array([[ -0.23714733, -43.506897  ]], dtype=float32)
time = 52680	action = 0	current_phase = 1	next_phase = 0	reward = 0.724495	array([[ -0.21908092, -43.472782  ]], dtype=float32)
time = 52685	action = 0	current_phase = 1	next_phase = 0	reward = 0.720659	array([[ -0.21115494, -43.473022  ]], dtype=float32)
time = 52690	action = 0	current_phase = 1	next_phase = 0	reward = 0.724477	array([[ -0.218997, -43.480743]], dtype=float32)
time = 52695	action = 0	current_phase = 1	next_phase = 0	reward = 0.714734	array([[ -0.21751022, -43.48154   ]], dtype=float32)
time = 52700	action = 0	current_phase = 1	next_phase = 0	reward = 0.711583	array([[ -0.21217251, -43.477875  ]], dtype=float32)
time = 52705	action = 0	current_phase = 1	next_phase = 0	reward = 0.718567	array([[ -0.18636131, -43.374817  ]], dtype=float32)
time = 52710	action = 0	current_phase = 1	next_phase = 0	reward = 0.718907	array([[ -0.2087965, -43.391357 ]], dtype=float32)
time = 52715	action = 0	current_phase = 1	next_phase = 0	reward = 0.729228	array([[ -0.21111774, -43.46396   ]], dtype=float32)
time = 52720	action = 0	current_phase = 1	next_phase = 0	reward = 0.724253	array([[ -0.23178482, -43.51159   ]], dtype=float32)
time = 52725	action = 0	current_phase = 1	next_phase = 0	reward = 0.721697	array([[ -0.2052288, -43.455627 ]], dtype=float32)
time = 52730	action = 0	current_phase = 1	next_phase = 0	reward = 0.715828	array([[ -0.20787907, -43.459343  ]], dtype=float32)
time = 52735	action = 0	current_phase = 1	next_phase = 0	reward = 0.717051	array([[ -0.22150135, -43.492645  ]], dtype=float32)
time = 52740	action = 0	current_phase = 1	next_phase = 0	reward = 0.722371	array([[ -0.18703842, -43.391296  ]], dtype=float32)
time = 52745	action = 0	current_phase = 1	next_phase = 0	reward = 0.446552	array([[ -0.22644329, -43.48632   ]], dtype=float32)
time = 52750	action = 0	current_phase = 1	next_phase = 0	reward = 1.003341	array([[ -0.22621346, -43.500084  ]], dtype=float32)
time = 52755	action = 0	current_phase = 1	next_phase = 0	reward = 0.716847	array([[ -0.18715858, -43.4058    ]], dtype=float32)
time = 52760	action = 0	current_phase = 1	next_phase = 0	reward = 0.715330	array([[ -0.21427345, -43.47914   ]], dtype=float32)
time = 52765	action = 0	current_phase = 1	next_phase = 0	reward = 0.717075	array([[ -0.20273685, -43.447746  ]], dtype=float32)
time = 52770	action = 0	current_phase = 1	next_phase = 0	reward = 0.719657	array([[ -0.20905876, -43.466324  ]], dtype=float32)
time = 52775	action = 0	current_phase = 1	next_phase = 0	reward = 0.719527	array([[ -0.2326746, -43.513695 ]], dtype=float32)
time = 52780	action = 0	current_phase = 1	next_phase = 0	reward = 0.718350	array([[ -0.21386147, -43.479446  ]], dtype=float32)
time = 52785	action = 0	current_phase = 1	next_phase = 0	reward = 0.718100	array([[ -0.21039867, -43.444595  ]], dtype=float32)
time = 52790	action = 0	current_phase = 1	next_phase = 0	reward = 0.443601	array([[ -0.21320248, -43.475563  ]], dtype=float32)
time = 52795	action = 0	current_phase = 1	next_phase = 0	reward = 1.008413	array([[ -0.21368694, -43.474396  ]], dtype=float32)
time = 52800	action = 0	current_phase = 1	next_phase = 0	reward = 0.713754	array([[ -0.2303009, -43.47029  ]], dtype=float32)
time = 52805	action = 0	current_phase = 1	next_phase = 0	reward = 0.718533	array([[ -0.21669292, -43.479374  ]], dtype=float32)
time = 52810	action = 0	current_phase = 1	next_phase = 0	reward = 0.717193	array([[ -0.23519611, -43.52372   ]], dtype=float32)
time = 52815	action = 0	current_phase = 1	next_phase = 0	reward = 0.438009	array([[ -0.19063759, -43.392647  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 717.3459 - val_loss: 1586.8522
Epoch 2/50
 - 4s - loss: 734.8062 - val_loss: 1622.1425
Epoch 3/50
 - 4s - loss: 742.3655 - val_loss: 1607.3559
Epoch 4/50
 - 4s - loss: 733.8234 - val_loss: 1619.4866
Epoch 5/50
 - 4s - loss: 734.2406 - val_loss: 1639.0495
Epoch 6/50
 - 4s - loss: 734.5491 - val_loss: 1591.7088
Epoch 7/50
 - 4s - loss: 717.2881 - val_loss: 1599.9906
Epoch 8/50
 - 4s - loss: 736.7794 - val_loss: 1569.8099
Epoch 9/50
 - 4s - loss: 698.3336 - val_loss: 1633.9264
Epoch 10/50
 - 4s - loss: 720.9160 - val_loss: 1594.7750
Epoch 11/50
 - 4s - loss: 727.7777 - val_loss: 1587.4565
Epoch 12/50
 - 4s - loss: 717.3184 - val_loss: 1622.8382
Epoch 13/50
 - 4s - loss: 729.9282 - val_loss: 1582.2891
Epoch 14/50
 - 4s - loss: 705.1712 - val_loss: 1628.9229
Epoch 15/50
 - 4s - loss: 715.6056 - val_loss: 1637.3720
Epoch 16/50
 - 4s - loss: 717.5593 - val_loss: 1609.7836
Epoch 17/50
 - 4s - loss: 715.6091 - val_loss: 1552.3331
Epoch 18/50
 - 4s - loss: 685.6114 - val_loss: 1601.6758
Epoch 19/50
 - 4s - loss: 707.7931 - val_loss: 1542.2653
Epoch 20/50
 - 4s - loss: 705.7259 - val_loss: 1557.0844
Epoch 21/50
 - 4s - loss: 709.6417 - val_loss: 1570.4178
Epoch 22/50
 - 4s - loss: 711.8418 - val_loss: 1578.8368
Epoch 23/50
 - 4s - loss: 694.5876 - val_loss: 1639.6685
Epoch 24/50
 - 4s - loss: 697.6636 - val_loss: 1577.2816
Epoch 25/50
 - 4s - loss: 716.5527 - val_loss: 1581.3542
Epoch 26/50
 - 4s - loss: 691.6294 - val_loss: 1563.4804
Epoch 27/50
 - 4s - loss: 694.8101 - val_loss: 1558.2570
Epoch 28/50
 - 4s - loss: 695.8336 - val_loss: 1545.1183
Epoch 29/50
 - 4s - loss: 683.5108 - val_loss: 1575.3713
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 52820	action = 0	current_phase = 1	next_phase = 0	reward = 1.001822	array([[  0.38046932, -43.559433  ]], dtype=float32)
time = 52825	action = 0	current_phase = 1	next_phase = 0	reward = 0.722322	array([[  0.38554382, -43.523468  ]], dtype=float32)
time = 52830	action = 0	current_phase = 1	next_phase = 0	reward = 0.717518	array([[  0.38493252, -43.50995   ]], dtype=float32)
time = 52835	action = 0	current_phase = 1	next_phase = 0	reward = 0.721338	array([[  0.37636566, -43.534935  ]], dtype=float32)
time = 52840	action = 0	current_phase = 1	next_phase = 0	reward = 0.718726	array([[  0.3833046, -43.528904 ]], dtype=float32)
time = 52845	action = 0	current_phase = 1	next_phase = 0	reward = 0.728622	array([[  0.3852625, -43.552593 ]], dtype=float32)
time = 52850	action = 0	current_phase = 1	next_phase = 0	reward = 0.723400	array([[  0.38524628, -43.52797   ]], dtype=float32)
time = 52855	action = 0	current_phase = 1	next_phase = 0	reward = 0.724686	array([[  0.36318684, -43.46318   ]], dtype=float32)
time = 52860	action = 0	current_phase = 1	next_phase = 0	reward = 0.721189	array([[  0.39084625, -43.424404  ]], dtype=float32)
time = 52865	action = 0	current_phase = 1	next_phase = 0	reward = 0.709404	array([[  0.34767532, -43.527416  ]], dtype=float32)
time = 52870	action = 0	current_phase = 1	next_phase = 0	reward = 0.709940	array([[  0.3630066, -43.523827 ]], dtype=float32)
time = 52875	action = 0	current_phase = 1	next_phase = 0	reward = 0.719150	array([[  0.37522125, -43.605145  ]], dtype=float32)
time = 52880	action = 0	current_phase = 1	next_phase = 0	reward = 0.727642	array([[  0.3814354, -43.551666 ]], dtype=float32)
time = 52885	action = 0	current_phase = 1	next_phase = 0	reward = 0.726590	array([[  0.39237595, -43.438995  ]], dtype=float32)
time = 52890	action = 0	current_phase = 1	next_phase = 0	reward = 0.723491	array([[  0.38147736, -43.558594  ]], dtype=float32)
time = 52895	action = 0	current_phase = 1	next_phase = 0	reward = 0.712203	array([[  0.37320995, -43.61666   ]], dtype=float32)
time = 52900	action = 0	current_phase = 1	next_phase = 0	reward = 0.724050	array([[  0.37013912, -43.607586  ]], dtype=float32)
time = 52905	action = 0	current_phase = 1	next_phase = 0	reward = 0.721697	array([[  0.38552284, -43.46878   ]], dtype=float32)
time = 52910	action = 0	current_phase = 1	next_phase = 0	reward = 0.719403	array([[  0.38287544, -43.540718  ]], dtype=float32)
time = 52915	action = 0	current_phase = 1	next_phase = 0	reward = 0.725755	array([[  0.37761307, -43.599983  ]], dtype=float32)
time = 52920	action = 0	current_phase = 1	next_phase = 0	reward = 0.718097	array([[  0.38273716, -43.56212   ]], dtype=float32)
time = 52925	action = 0	current_phase = 1	next_phase = 0	reward = 0.435314	array([[  0.38135147, -43.46008   ]], dtype=float32)
time = 52930	action = 0	current_phase = 1	next_phase = 0	reward = 0.721447	array([[  0.3809204, -43.52001  ]], dtype=float32)
time = 52935	action = 0	current_phase = 1	next_phase = 0	reward = 1.001815	array([[  0.38616276, -43.45059   ]], dtype=float32)
time = 52940	action = 0	current_phase = 1	next_phase = 0	reward = 0.446331	array([[  0.38539886, -43.462997  ]], dtype=float32)
time = 52945	action = 0	current_phase = 1	next_phase = 0	reward = 1.009002	array([[  0.37425232, -43.597054  ]], dtype=float32)
time = 52950	action = 0	current_phase = 1	next_phase = 0	reward = 0.714395	array([[  0.37954235, -43.53096   ]], dtype=float32)
time = 52955	action = 0	current_phase = 1	next_phase = 0	reward = 0.441053	array([[  0.39546394, -43.484123  ]], dtype=float32)
time = 52960	action = 0	current_phase = 1	next_phase = 0	reward = 0.992738	array([[  0.3863783, -43.546047 ]], dtype=float32)
time = 52965	action = 0	current_phase = 1	next_phase = 0	reward = 0.437903	array([[  0.3903885, -43.53818  ]], dtype=float32)
time = 52970	action = 0	current_phase = 1	next_phase = 0	reward = 0.998749	array([[  0.3559761, -43.51645  ]], dtype=float32)
time = 52975	action = 0	current_phase = 1	next_phase = 0	reward = 0.167024	array([[  0.38432312, -43.546246  ]], dtype=float32)
time = 52980	action = 0	current_phase = 1	next_phase = 0	reward = 1.002734	array([[  0.35827827, -43.445652  ]], dtype=float32)
time = 52985	action = 0	current_phase = 1	next_phase = 0	reward = 0.734639	array([[  0.3696642, -43.62771  ]], dtype=float32)
time = 52990	action = 0	current_phase = 1	next_phase = 0	reward = 1.004050	array([[  0.3826332, -43.5391   ]], dtype=float32)
time = 52995	action = 0	current_phase = 1	next_phase = 0	reward = 0.720177	array([[  0.37819195, -43.475044  ]], dtype=float32)
time = 53000	action = 0	current_phase = 1	next_phase = 0	reward = 0.718523	array([[  0.3872366, -43.557865 ]], dtype=float32)
time = 53005	action = 0	current_phase = 1	next_phase = 0	reward = 0.719742	array([[  0.38601112, -43.463234  ]], dtype=float32)
time = 53010	action = 0	current_phase = 1	next_phase = 0	reward = 0.718711	array([[  0.383605, -43.571754]], dtype=float32)
time = 53015	action = 0	current_phase = 1	next_phase = 0	reward = 0.718705	array([[  0.37335777, -43.607613  ]], dtype=float32)
time = 53020	action = 0	current_phase = 1	next_phase = 0	reward = 0.716816	array([[  0.38277817, -43.53912   ]], dtype=float32)
time = 53025	action = 0	current_phase = 1	next_phase = 0	reward = 0.721457	array([[  0.36828423, -43.634895  ]], dtype=float32)
time = 53030	action = 0	current_phase = 1	next_phase = 0	reward = 0.722806	array([[  0.38974667, -43.50374   ]], dtype=float32)
time = 53035	action = 0	current_phase = 1	next_phase = 0	reward = 0.722087	array([[  0.3867302, -43.55195  ]], dtype=float32)
time = 53040	action = 0	current_phase = 1	next_phase = 0	reward = 0.440993	array([[  0.38504505, -43.481747  ]], dtype=float32)
time = 53045	action = 0	current_phase = 1	next_phase = 0	reward = 1.011893	array([[  0.3285122, -43.41133  ]], dtype=float32)
time = 53050	action = 0	current_phase = 1	next_phase = 0	reward = 0.720504	array([[  0.35566616, -43.339813  ]], dtype=float32)
time = 53055	action = 0	current_phase = 1	next_phase = 0	reward = 0.720644	array([[  0.37052345, -43.629074  ]], dtype=float32)
time = 53060	action = 0	current_phase = 1	next_phase = 0	reward = 0.725404	array([[  0.38127327, -43.58256   ]], dtype=float32)
time = 53065	action = 0	current_phase = 1	next_phase = 0	reward = 0.452657	array([[  0.37825108, -43.56932   ]], dtype=float32)
time = 53070	action = 0	current_phase = 1	next_phase = 0	reward = 1.008433	array([[  0.38274956, -43.356705  ]], dtype=float32)
time = 53075	action = 0	current_phase = 1	next_phase = 0	reward = 0.718120	array([[  0.383667, -43.58274 ]], dtype=float32)
time = 53080	action = 0	current_phase = 1	next_phase = 0	reward = 0.716195	array([[  0.38024235, -43.577087  ]], dtype=float32)
time = 53085	action = 0	current_phase = 1	next_phase = 0	reward = 0.712003	array([[  0.38160515, -43.578743  ]], dtype=float32)
time = 53090	action = 0	current_phase = 1	next_phase = 0	reward = 0.715036	array([[  0.39016342, -43.429512  ]], dtype=float32)
time = 53095	action = 0	current_phase = 1	next_phase = 0	reward = 0.437924	array([[  0.39514923, -43.45      ]], dtype=float32)
time = 53100	action = 0	current_phase = 1	next_phase = 0	reward = 0.999510	array([[  0.3756094, -43.587822 ]], dtype=float32)
time = 53105	action = 0	current_phase = 1	next_phase = 0	reward = 0.439065	array([[  0.38437366, -43.38856   ]], dtype=float32)
time = 53110	action = 0	current_phase = 1	next_phase = 0	reward = 1.000547	array([[  0.38072586, -43.582047  ]], dtype=float32)
time = 53115	action = 0	current_phase = 1	next_phase = 0	reward = 0.725292	array([[  0.39327812, -43.536564  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 978.4205 - val_loss: 5046.0172
Epoch 2/50
 - 4s - loss: 972.6628 - val_loss: 5036.9144
Epoch 3/50
 - 4s - loss: 979.6239 - val_loss: 5059.8296
Epoch 4/50
 - 4s - loss: 964.2463 - val_loss: 5027.6468
Epoch 5/50
 - 4s - loss: 972.3039 - val_loss: 5038.2770
Epoch 6/50
 - 4s - loss: 950.3177 - val_loss: 5036.2363
Epoch 7/50
 - 4s - loss: 973.7522 - val_loss: 5047.2196
Epoch 8/50
 - 4s - loss: 958.2992 - val_loss: 5041.5518
Epoch 9/50
 - 4s - loss: 969.1566 - val_loss: 5028.7334
Epoch 10/50
 - 4s - loss: 981.8519 - val_loss: 5045.4966
Epoch 11/50
 - 4s - loss: 950.2147 - val_loss: 5033.2912
Epoch 12/50
 - 4s - loss: 945.3162 - val_loss: 5058.1092
Epoch 13/50
 - 4s - loss: 971.2457 - val_loss: 5030.3199
Epoch 14/50
 - 4s - loss: 943.3358 - val_loss: 5056.3014
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 53120	action = 0	current_phase = 1	next_phase = 0	reward = 0.724576	array([[  0.41330242, -43.586136  ]], dtype=float32)
time = 53125	action = 0	current_phase = 1	next_phase = 0	reward = 0.725835	array([[  0.40268707, -43.62931   ]], dtype=float32)
time = 53130	action = 0	current_phase = 1	next_phase = 0	reward = 0.443915	array([[  0.37114525, -43.615128  ]], dtype=float32)
time = 53135	action = 0	current_phase = 1	next_phase = 0	reward = 1.005628	array([[  0.3803978, -43.64782  ]], dtype=float32)
time = 53140	action = 0	current_phase = 1	next_phase = 0	reward = 0.721429	array([[  0.4202633, -43.580284 ]], dtype=float32)
time = 53145	action = 0	current_phase = 1	next_phase = 0	reward = 0.722569	array([[  0.41890812, -43.567696  ]], dtype=float32)
time = 53150	action = 0	current_phase = 1	next_phase = 0	reward = 0.724014	array([[  0.44081974, -43.546528  ]], dtype=float32)
time = 53155	action = 0	current_phase = 1	next_phase = 0	reward = 0.443873	array([[  0.383276, -43.64253 ]], dtype=float32)
time = 53160	action = 0	current_phase = 1	next_phase = 0	reward = 0.999165	array([[  0.38921452, -43.634712  ]], dtype=float32)
time = 53165	action = 0	current_phase = 1	next_phase = 0	reward = 0.713266	array([[  0.37671852, -43.644516  ]], dtype=float32)
time = 53170	action = 0	current_phase = 1	next_phase = 0	reward = 0.442128	array([[  0.3988638, -43.611702 ]], dtype=float32)
time = 53175	action = 0	current_phase = 1	next_phase = 0	reward = 0.731654	array([[  0.40323544, -43.60974   ]], dtype=float32)
time = 53180	action = 0	current_phase = 1	next_phase = 0	reward = 1.006785	array([[  0.391057, -43.632393]], dtype=float32)
time = 53185	action = 0	current_phase = 1	next_phase = 0	reward = 0.719426	array([[  0.3789158, -43.65017  ]], dtype=float32)
time = 53190	action = 0	current_phase = 1	next_phase = 0	reward = 0.711675	array([[  0.39604187, -43.607742  ]], dtype=float32)
time = 53195	action = 0	current_phase = 1	next_phase = 0	reward = 0.438568	array([[  0.39790058, -43.578674  ]], dtype=float32)
time = 53200	action = 0	current_phase = 1	next_phase = 0	reward = 0.998067	array([[  0.4083948, -43.593422 ]], dtype=float32)
time = 53205	action = 0	current_phase = 1	next_phase = 0	reward = 0.438997	array([[  0.41403103, -43.568687  ]], dtype=float32)
time = 53210	action = 0	current_phase = 1	next_phase = 0	reward = 1.009929	array([[  0.40997887, -43.595284  ]], dtype=float32)
time = 53215	action = 0	current_phase = 1	next_phase = 0	reward = 0.443203	array([[  0.38263512, -43.643234  ]], dtype=float32)
time = 53220	action = 0	current_phase = 1	next_phase = 0	reward = 1.000629	array([[  0.41235352, -43.51689   ]], dtype=float32)
time = 53225	action = 0	current_phase = 1	next_phase = 0	reward = 0.715629	array([[  0.41105843, -43.587112  ]], dtype=float32)
time = 53230	action = 0	current_phase = 1	next_phase = 0	reward = 0.712996	array([[  0.41243172, -43.59098   ]], dtype=float32)
time = 53235	action = 0	current_phase = 1	next_phase = 0	reward = 0.444791	array([[  0.43676376, -43.513275  ]], dtype=float32)
time = 53240	action = 0	current_phase = 1	next_phase = 0	reward = 1.001970	array([[  0.39543915, -43.621735  ]], dtype=float32)
time = 53245	action = 0	current_phase = 1	next_phase = 0	reward = 0.721894	array([[  0.43468952, -43.503944  ]], dtype=float32)
time = 53250	action = 0	current_phase = 1	next_phase = 0	reward = 0.717772	array([[  0.38097095, -43.641266  ]], dtype=float32)
time = 53255	action = 0	current_phase = 1	next_phase = 0	reward = 0.724808	array([[  0.43526077, -43.55657   ]], dtype=float32)
time = 53260	action = 0	current_phase = 1	next_phase = 0	reward = 0.717040	array([[  0.41374302, -43.60474   ]], dtype=float32)
time = 53265	action = 0	current_phase = 1	next_phase = 0	reward = 0.718821	array([[  0.39325523, -43.626892  ]], dtype=float32)
time = 53270	action = 0	current_phase = 1	next_phase = 0	reward = 0.720504	array([[  0.4028654, -43.6025   ]], dtype=float32)
time = 53275	action = 0	current_phase = 1	next_phase = 0	reward = 0.435428	array([[  0.38543415, -43.643024  ]], dtype=float32)
time = 53280	action = 0	current_phase = 1	next_phase = 0	reward = 1.004638	array([[  0.39608765, -43.613075  ]], dtype=float32)
time = 53285	action = 0	current_phase = 1	next_phase = 0	reward = 0.714618	array([[  0.37518978, -43.585625  ]], dtype=float32)
time = 53290	action = 0	current_phase = 1	next_phase = 0	reward = 0.727333	array([[  0.4286766, -43.531593 ]], dtype=float32)
time = 53295	action = 0	current_phase = 1	next_phase = 0	reward = 0.457238	array([[  0.4152832, -43.567413 ]], dtype=float32)
time = 53300	action = 0	current_phase = 1	next_phase = 0	reward = 1.007175	array([[  0.4051342, -43.589752 ]], dtype=float32)
time = 53305	action = 0	current_phase = 1	next_phase = 0	reward = 0.722989	array([[  0.42261887, -43.568344  ]], dtype=float32)
time = 53310	action = 0	current_phase = 1	next_phase = 0	reward = 0.720416	array([[  0.3840971, -43.591644 ]], dtype=float32)
time = 53315	action = 0	current_phase = 1	next_phase = 0	reward = 0.721774	array([[  0.40945244, -43.593903  ]], dtype=float32)
time = 53320	action = 0	current_phase = 1	next_phase = 0	reward = 0.726952	array([[  0.41923523, -43.578667  ]], dtype=float32)
time = 53325	action = 0	current_phase = 1	next_phase = 0	reward = 0.718922	array([[  0.40208435, -43.60386   ]], dtype=float32)
time = 53330	action = 0	current_phase = 1	next_phase = 0	reward = 0.721292	array([[  0.38659382, -43.631336  ]], dtype=float32)
time = 53335	action = 0	current_phase = 1	next_phase = 0	reward = 0.720743	array([[  0.41356564, -43.57625   ]], dtype=float32)
time = 53340	action = 0	current_phase = 1	next_phase = 0	reward = 0.722767	array([[  0.40524006, -43.60457   ]], dtype=float32)
time = 53345	action = 0	current_phase = 1	next_phase = 0	reward = 0.730078	array([[  0.42338943, -43.602543  ]], dtype=float32)
time = 53350	action = 0	current_phase = 1	next_phase = 0	reward = 0.722659	array([[  0.395607, -43.61199 ]], dtype=float32)
time = 53355	action = 0	current_phase = 1	next_phase = 0	reward = 0.710308	array([[  0.39134884, -43.632217  ]], dtype=float32)
time = 53360	action = 0	current_phase = 1	next_phase = 0	reward = 0.719040	array([[  0.38914585, -43.633972  ]], dtype=float32)
time = 53365	action = 0	current_phase = 1	next_phase = 0	reward = 0.442111	array([[  0.4317646, -43.53565  ]], dtype=float32)
time = 53370	action = 0	current_phase = 1	next_phase = 0	reward = 1.003386	array([[  0.41754627, -43.56298   ]], dtype=float32)
time = 53375	action = 0	current_phase = 1	next_phase = 0	reward = 0.717491	array([[  0.4121685, -43.59139  ]], dtype=float32)
time = 53380	action = 0	current_phase = 1	next_phase = 0	reward = 0.440723	array([[  0.3989725, -43.54574  ]], dtype=float32)
time = 53385	action = 0	current_phase = 1	next_phase = 0	reward = 0.999655	array([[  0.39250946, -43.617386  ]], dtype=float32)
time = 53390	action = 0	current_phase = 1	next_phase = 0	reward = 0.715658	array([[  0.4370308, -43.561554 ]], dtype=float32)
time = 53395	action = 0	current_phase = 1	next_phase = 0	reward = 0.717887	array([[  0.4187212, -43.515472 ]], dtype=float32)
time = 53400	action = 0	current_phase = 1	next_phase = 0	reward = 0.733817	array([[  0.36350918, -43.3901    ]], dtype=float32)
time = 53405	action = 0	current_phase = 1	next_phase = 0	reward = 0.722171	array([[  0.39470768, -43.638153  ]], dtype=float32)
time = 53410	action = 0	current_phase = 1	next_phase = 0	reward = 0.718838	array([[  0.42304134, -43.57104   ]], dtype=float32)
time = 53415	action = 0	current_phase = 1	next_phase = 0	reward = 0.721413	array([[  0.40712547, -43.59003   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 984.3417 - val_loss: 878.4875
Epoch 2/50
 - 4s - loss: 991.5283 - val_loss: 856.9185
Epoch 3/50
 - 4s - loss: 979.9755 - val_loss: 831.5859
Epoch 4/50
 - 4s - loss: 970.0041 - val_loss: 836.1665
Epoch 5/50
 - 4s - loss: 981.4286 - val_loss: 830.6475
Epoch 6/50
 - 4s - loss: 971.6255 - val_loss: 833.3013
Epoch 7/50
 - 4s - loss: 967.4825 - val_loss: 849.7794
Epoch 8/50
 - 4s - loss: 965.6749 - val_loss: 851.5971
Epoch 9/50
 - 4s - loss: 966.4474 - val_loss: 827.2296
Epoch 10/50
 - 4s - loss: 962.3874 - val_loss: 831.5004
Epoch 11/50
 - 4s - loss: 963.8420 - val_loss: 827.7021
Epoch 12/50
 - 4s - loss: 964.4633 - val_loss: 822.1601
Epoch 13/50
 - 4s - loss: 947.2433 - val_loss: 822.2460
Epoch 14/50
 - 4s - loss: 952.3446 - val_loss: 825.2725
Epoch 15/50
 - 4s - loss: 937.4447 - val_loss: 819.7103
Epoch 16/50
 - 4s - loss: 935.8999 - val_loss: 824.2453
Epoch 17/50
 - 4s - loss: 947.3249 - val_loss: 822.4619
Epoch 18/50
 - 4s - loss: 938.7064 - val_loss: 818.0273
Epoch 19/50
 - 4s - loss: 936.1686 - val_loss: 835.4457
Epoch 20/50
 - 4s - loss: 960.7070 - val_loss: 849.6327
Epoch 21/50
 - 4s - loss: 935.4146 - val_loss: 817.6254
Epoch 22/50
 - 4s - loss: 931.5526 - val_loss: 820.1584
Epoch 23/50
 - 4s - loss: 939.0854 - val_loss: 820.1100
Epoch 24/50
 - 4s - loss: 924.4776 - val_loss: 811.9369
Epoch 25/50
 - 4s - loss: 923.8846 - val_loss: 815.9856
Epoch 26/50
 - 4s - loss: 925.2683 - val_loss: 824.4141
Epoch 27/50
 - 4s - loss: 934.5487 - val_loss: 803.0400
Epoch 28/50
 - 4s - loss: 914.3014 - val_loss: 806.2863
Epoch 29/50
 - 4s - loss: 923.9203 - val_loss: 806.4485
Epoch 30/50
 - 4s - loss: 937.0069 - val_loss: 810.8922
Epoch 31/50
 - 4s - loss: 911.7897 - val_loss: 804.3455
Epoch 32/50
 - 4s - loss: 912.4702 - val_loss: 804.3383
Epoch 33/50
 - 4s - loss: 911.8902 - val_loss: 804.3164
Epoch 34/50
 - 4s - loss: 899.9460 - val_loss: 806.2206
Epoch 35/50
 - 4s - loss: 914.3806 - val_loss: 797.7701
Epoch 36/50
 - 4s - loss: 907.3328 - val_loss: 798.2840
Epoch 37/50
 - 4s - loss: 898.1152 - val_loss: 814.7130
Epoch 38/50
 - 4s - loss: 909.6863 - val_loss: 800.2948
Epoch 39/50
 - 4s - loss: 891.1078 - val_loss: 798.7912
Epoch 40/50
 - 4s - loss: 907.2072 - val_loss: 818.1576
Epoch 41/50
 - 4s - loss: 898.7863 - val_loss: 796.6902
Epoch 42/50
 - 4s - loss: 896.9400 - val_loss: 793.9938
Epoch 43/50
 - 4s - loss: 890.2865 - val_loss: 794.3765
Epoch 44/50
 - 4s - loss: 900.1538 - val_loss: 797.2406
Epoch 45/50
 - 4s - loss: 887.7404 - val_loss: 789.3600
Epoch 46/50
 - 4s - loss: 875.5961 - val_loss: 782.8382
Epoch 47/50
 - 4s - loss: 876.8153 - val_loss: 836.5112
Epoch 48/50
 - 4s - loss: 889.1415 - val_loss: 786.4174
Epoch 49/50
 - 4s - loss: 883.7466 - val_loss: 795.9117
Epoch 50/50
 - 4s - loss: 883.5831 - val_loss: 794.7493
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 53420	action = 0	current_phase = 1	next_phase = 0	reward = 0.718039	array([[  0.42639065, -43.71511   ]], dtype=float32)
time = 53425	action = 0	current_phase = 1	next_phase = 0	reward = 0.717437	array([[  0.4761982, -43.56884  ]], dtype=float32)
time = 53430	action = 0	current_phase = 1	next_phase = 0	reward = 0.717908	array([[  0.4639988, -43.534264 ]], dtype=float32)
time = 53435	action = 0	current_phase = 1	next_phase = 0	reward = 0.719759	array([[  0.44912052, -43.683483  ]], dtype=float32)
time = 53440	action = 0	current_phase = 1	next_phase = 0	reward = 0.709653	array([[  0.42344856, -43.685287  ]], dtype=float32)
time = 53445	action = 0	current_phase = 1	next_phase = 0	reward = 0.445678	array([[  0.48123074, -43.598427  ]], dtype=float32)
time = 53450	action = 0	current_phase = 1	next_phase = 0	reward = 0.726943	array([[  0.48603535, -43.531876  ]], dtype=float32)
time = 53455	action = 0	current_phase = 1	next_phase = 0	reward = 1.005124	array([[  0.48567867, -43.57143   ]], dtype=float32)
time = 53460	action = 0	current_phase = 1	next_phase = 0	reward = 0.447125	array([[  0.4860916, -43.55671  ]], dtype=float32)
time = 53465	action = 0	current_phase = 1	next_phase = 0	reward = 1.009934	array([[  0.4553833, -43.6692   ]], dtype=float32)
time = 53470	action = 0	current_phase = 1	next_phase = 0	reward = 0.724012	array([[  0.4668169, -43.480766 ]], dtype=float32)
time = 53475	action = 0	current_phase = 1	next_phase = 0	reward = 0.720976	array([[  0.47115898, -43.60953   ]], dtype=float32)
time = 53480	action = 0	current_phase = 1	next_phase = 0	reward = 0.438460	array([[  0.42592907, -43.650986  ]], dtype=float32)
time = 53485	action = 0	current_phase = 1	next_phase = 0	reward = 1.001048	array([[  0.4515772, -43.670586 ]], dtype=float32)
time = 53490	action = 0	current_phase = 1	next_phase = 0	reward = 0.720872	array([[  0.45478535, -43.66825   ]], dtype=float32)
time = 53495	action = 0	current_phase = 1	next_phase = 0	reward = 0.437503	array([[  0.46813297, -43.629887  ]], dtype=float32)
time = 53500	action = 0	current_phase = 1	next_phase = 0	reward = 0.996017	array([[  0.46699905, -43.592545  ]], dtype=float32)
time = 53505	action = 0	current_phase = 1	next_phase = 0	reward = 0.432547	array([[  0.44766235, -43.603935  ]], dtype=float32)
time = 53510	action = 0	current_phase = 1	next_phase = 0	reward = 1.003906	array([[  0.435606, -43.700863]], dtype=float32)
time = 53515	action = 0	current_phase = 1	next_phase = 0	reward = 0.452408	array([[  0.4780941, -43.595802 ]], dtype=float32)
time = 53520	action = 0	current_phase = 1	next_phase = 0	reward = 1.003830	array([[  0.4840002, -43.55301  ]], dtype=float32)
time = 53525	action = 0	current_phase = 1	next_phase = 0	reward = 0.723406	array([[  0.47182083, -43.575714  ]], dtype=float32)
time = 53530	action = 0	current_phase = 1	next_phase = 0	reward = 0.722750	array([[  0.44832516, -43.67428   ]], dtype=float32)
time = 53535	action = 0	current_phase = 1	next_phase = 0	reward = 0.721373	array([[  0.42762852, -43.71627   ]], dtype=float32)
time = 53540	action = 0	current_phase = 1	next_phase = 0	reward = 0.714101	array([[  0.4810524, -43.57322  ]], dtype=float32)
time = 53545	action = 0	current_phase = 1	next_phase = 0	reward = 0.718564	array([[  0.4507351, -43.662865 ]], dtype=float32)
time = 53550	action = 0	current_phase = 1	next_phase = 0	reward = 0.719593	array([[  0.4934206, -43.547356 ]], dtype=float32)
time = 53555	action = 0	current_phase = 1	next_phase = 0	reward = 0.724417	array([[  0.44988823, -43.607647  ]], dtype=float32)
time = 53560	action = 0	current_phase = 1	next_phase = 0	reward = 0.718992	array([[  0.44536686, -43.67669   ]], dtype=float32)
time = 53565	action = 0	current_phase = 1	next_phase = 0	reward = 0.720709	array([[  0.46743298, -43.60634   ]], dtype=float32)
time = 53570	action = 0	current_phase = 1	next_phase = 0	reward = 0.439591	array([[  0.44296932, -43.691     ]], dtype=float32)
time = 53575	action = 0	current_phase = 1	next_phase = 0	reward = 1.001840	array([[  0.462615, -43.50837 ]], dtype=float32)
time = 53580	action = 0	current_phase = 1	next_phase = 0	reward = 0.718395	array([[  0.466712, -43.64885 ]], dtype=float32)
time = 53585	action = 0	current_phase = 1	next_phase = 0	reward = 0.720805	array([[  0.4643221, -43.64405  ]], dtype=float32)
time = 53590	action = 0	current_phase = 1	next_phase = 0	reward = 0.433279	array([[  0.44746685, -43.577248  ]], dtype=float32)
time = 53595	action = 0	current_phase = 1	next_phase = 0	reward = 0.719432	array([[  0.43912697, -43.606606  ]], dtype=float32)
time = 53600	action = 0	current_phase = 1	next_phase = 0	reward = 0.728008	array([[  0.47057343, -43.619087  ]], dtype=float32)
time = 53605	action = 0	current_phase = 1	next_phase = 0	reward = 1.006106	array([[  0.47478676, -43.598717  ]], dtype=float32)
time = 53610	action = 0	current_phase = 1	next_phase = 0	reward = 0.714033	array([[  0.45690632, -43.642105  ]], dtype=float32)
time = 53615	action = 0	current_phase = 1	next_phase = 0	reward = 0.434930	array([[  0.4488535, -43.673416 ]], dtype=float32)
time = 53620	action = 0	current_phase = 1	next_phase = 0	reward = 0.722453	array([[  0.2074852, -43.209393 ]], dtype=float32)
time = 53625	action = 0	current_phase = 1	next_phase = 0	reward = 0.711456	array([[  0.49604607, -43.496834  ]], dtype=float32)
time = 53630	action = 0	current_phase = 1	next_phase = 0	reward = 1.017519	array([[  0.48316383, -43.56153   ]], dtype=float32)
time = 53635	action = 0	current_phase = 1	next_phase = 0	reward = 0.714998	array([[  0.44368362, -43.620193  ]], dtype=float32)
time = 53640	action = 0	current_phase = 1	next_phase = 0	reward = 0.713666	array([[  0.4679289, -43.620506 ]], dtype=float32)
time = 53645	action = 0	current_phase = 1	next_phase = 0	reward = 0.713240	array([[  0.4249401, -43.606884 ]], dtype=float32)
time = 53650	action = 0	current_phase = 1	next_phase = 0	reward = 0.439296	array([[  0.47961903, -43.61087   ]], dtype=float32)
time = 53655	action = 0	current_phase = 1	next_phase = 0	reward = 1.003395	array([[  0.4649315, -43.633305 ]], dtype=float32)
time = 53660	action = 0	current_phase = 1	next_phase = 0	reward = 0.448876	array([[  0.43947983, -43.693657  ]], dtype=float32)
time = 53665	action = 0	current_phase = 1	next_phase = 0	reward = 0.725039	array([[  0.49328804, -43.49752   ]], dtype=float32)
time = 53670	action = 0	current_phase = 1	next_phase = 0	reward = 0.719703	array([[  0.48292542, -43.576775  ]], dtype=float32)
time = 53675	action = 0	current_phase = 1	next_phase = 0	reward = 1.004904	array([[  0.45415688, -43.65125   ]], dtype=float32)
time = 53680	action = 0	current_phase = 1	next_phase = 0	reward = 0.724036	array([[  0.45078468, -43.627182  ]], dtype=float32)
time = 53685	action = 0	current_phase = 1	next_phase = 0	reward = 0.729465	array([[  0.41392708, -43.504093  ]], dtype=float32)
time = 53690	action = 0	current_phase = 1	next_phase = 0	reward = 0.722021	array([[  0.43352985, -43.685463  ]], dtype=float32)
time = 53695	action = 0	current_phase = 1	next_phase = 0	reward = 0.718226	array([[  0.47381592, -43.624493  ]], dtype=float32)
time = 53700	action = 0	current_phase = 1	next_phase = 0	reward = 0.718265	array([[  0.48061943, -43.584595  ]], dtype=float32)
time = 53705	action = 0	current_phase = 1	next_phase = 0	reward = 0.717485	array([[  0.45688534, -43.646545  ]], dtype=float32)
time = 53710	action = 0	current_phase = 1	next_phase = 0	reward = 0.718815	array([[  0.4469242, -43.64669  ]], dtype=float32)
time = 53715	action = 0	current_phase = 1	next_phase = 0	reward = 0.717217	array([[  0.46756268, -43.582436  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 756.4761 - val_loss: 5646.8040
Epoch 2/50
 - 4s - loss: 759.1556 - val_loss: 5649.6469
Epoch 3/50
 - 4s - loss: 765.9610 - val_loss: 5632.5863
Epoch 4/50
 - 4s - loss: 754.8469 - val_loss: 5644.6251
Epoch 5/50
 - 4s - loss: 749.3088 - val_loss: 5643.4883
Epoch 6/50
 - 4s - loss: 749.8951 - val_loss: 5644.5490
Epoch 7/50
 - 4s - loss: 753.6566 - val_loss: 5644.0851
Epoch 8/50
 - 4s - loss: 746.3498 - val_loss: 5657.7183
Epoch 9/50
 - 4s - loss: 753.6363 - val_loss: 5635.0163
Epoch 10/50
 - 4s - loss: 742.4188 - val_loss: 5642.3380
Epoch 11/50
 - 4s - loss: 750.6505 - val_loss: 5643.4966
Epoch 12/50
 - 4s - loss: 736.9077 - val_loss: 5636.3330
Epoch 13/50
 - 4s - loss: 737.8676 - val_loss: 5649.1476
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 53720	action = 0	current_phase = 1	next_phase = 0	reward = 0.438508	array([[  0.38470078, -43.5896    ]], dtype=float32)
time = 53725	action = 0	current_phase = 1	next_phase = 0	reward = 1.005332	array([[  0.40414333, -43.53993   ]], dtype=float32)
time = 53730	action = 0	current_phase = 1	next_phase = 0	reward = 0.728170	array([[  0.36817265, -43.62466   ]], dtype=float32)
time = 53735	action = 0	current_phase = 1	next_phase = 0	reward = 0.714239	array([[  0.38843822, -43.51564   ]], dtype=float32)
time = 53740	action = 0	current_phase = 1	next_phase = 0	reward = 0.722912	array([[  0.3972826, -43.568184 ]], dtype=float32)
time = 53745	action = 0	current_phase = 1	next_phase = 0	reward = 0.724498	array([[  0.4228506, -43.41555  ]], dtype=float32)
time = 53750	action = 0	current_phase = 1	next_phase = 0	reward = 0.728362	array([[  0.37353516, -43.619896  ]], dtype=float32)
time = 53755	action = 0	current_phase = 1	next_phase = 0	reward = 0.716670	array([[  0.3929701, -43.427147 ]], dtype=float32)
time = 53760	action = 0	current_phase = 1	next_phase = 0	reward = 0.714434	array([[  0.4253254, -43.413933 ]], dtype=float32)
time = 53765	action = 0	current_phase = 1	next_phase = 0	reward = 0.727652	array([[  0.4206171, -43.492657 ]], dtype=float32)
time = 53770	action = 0	current_phase = 1	next_phase = 0	reward = 0.729226	array([[  0.39188766, -43.591766  ]], dtype=float32)
time = 53775	action = 0	current_phase = 1	next_phase = 0	reward = 0.719715	array([[  0.39087296, -43.572144  ]], dtype=float32)
time = 53780	action = 0	current_phase = 1	next_phase = 0	reward = 0.716664	array([[  0.39071178, -43.582615  ]], dtype=float32)
time = 53785	action = 0	current_phase = 1	next_phase = 0	reward = 0.723304	array([[  0.40556526, -43.550438  ]], dtype=float32)
time = 53790	action = 0	current_phase = 1	next_phase = 0	reward = 0.438987	array([[  0.37333202, -43.391438  ]], dtype=float32)
time = 53795	action = 0	current_phase = 1	next_phase = 0	reward = 1.008376	array([[  0.4079075, -43.4451   ]], dtype=float32)
time = 53800	action = 0	current_phase = 1	next_phase = 0	reward = 0.714715	array([[  0.3797617, -43.61212  ]], dtype=float32)
time = 53805	action = 0	current_phase = 1	next_phase = 0	reward = 0.726821	array([[  0.4137373, -43.499496 ]], dtype=float32)
time = 53810	action = 0	current_phase = 1	next_phase = 0	reward = 0.722419	array([[  0.41248035, -43.527893  ]], dtype=float32)
time = 53815	action = 0	current_phase = 1	next_phase = 0	reward = 0.442627	array([[  0.38072014, -43.605896  ]], dtype=float32)
time = 53820	action = 0	current_phase = 1	next_phase = 0	reward = 1.002790	array([[  0.39335442, -43.573982  ]], dtype=float32)
time = 53825	action = 0	current_phase = 1	next_phase = 0	reward = 0.726046	array([[  0.41031647, -43.509594  ]], dtype=float32)
time = 53830	action = 0	current_phase = 1	next_phase = 0	reward = 0.707380	array([[  0.39959145, -43.56487   ]], dtype=float32)
time = 53835	action = 0	current_phase = 1	next_phase = 0	reward = 0.718306	array([[  0.38821983, -43.496117  ]], dtype=float32)
time = 53840	action = 0	current_phase = 1	next_phase = 0	reward = 0.716547	array([[  0.38935375, -43.581245  ]], dtype=float32)
time = 53845	action = 0	current_phase = 1	next_phase = 0	reward = 0.434449	array([[  0.38827324, -43.587166  ]], dtype=float32)
time = 53850	action = 0	current_phase = 1	next_phase = 0	reward = 0.723671	array([[  0.394145, -43.573772]], dtype=float32)
time = 53855	action = 0	current_phase = 1	next_phase = 0	reward = 1.004673	array([[  0.38651276, -43.577507  ]], dtype=float32)
time = 53860	action = 0	current_phase = 1	next_phase = 0	reward = 0.717057	array([[  0.42179966, -43.382935  ]], dtype=float32)
time = 53865	action = 0	current_phase = 1	next_phase = 0	reward = 0.715677	array([[  0.4141407, -43.505928 ]], dtype=float32)
time = 53870	action = 0	current_phase = 1	next_phase = 0	reward = 0.719285	array([[  0.40238476, -43.533882  ]], dtype=float32)
time = 53875	action = 0	current_phase = 1	next_phase = 0	reward = 0.729210	array([[  0.42848015, -43.42607   ]], dtype=float32)
time = 53880	action = 0	current_phase = 1	next_phase = 0	reward = 0.722680	array([[  0.41086292, -43.477325  ]], dtype=float32)
time = 53885	action = 0	current_phase = 1	next_phase = 0	reward = 0.445950	array([[  0.39656925, -43.517097  ]], dtype=float32)
time = 53890	action = 0	current_phase = 1	next_phase = 0	reward = 1.005331	array([[  0.39055157, -43.57469   ]], dtype=float32)
time = 53895	action = 0	current_phase = 1	next_phase = 0	reward = 0.438227	array([[  0.39046955, -43.572723  ]], dtype=float32)
time = 53900	action = 0	current_phase = 1	next_phase = 0	reward = 0.992601	array([[  0.38895512, -43.497173  ]], dtype=float32)
time = 53905	action = 0	current_phase = 1	next_phase = 0	reward = 0.441808	array([[  0.40829468, -43.512802  ]], dtype=float32)
time = 53910	action = 0	current_phase = 1	next_phase = 0	reward = 0.732983	array([[  0.38435555, -43.48082   ]], dtype=float32)
time = 53915	action = 0	current_phase = 1	next_phase = 0	reward = 1.003113	array([[  0.42440796, -43.424934  ]], dtype=float32)
time = 53920	action = 0	current_phase = 1	next_phase = 0	reward = 0.727571	array([[  0.41745567, -43.415844  ]], dtype=float32)
time = 53925	action = 0	current_phase = 1	next_phase = 0	reward = 0.725549	array([[  0.41702175, -43.510513  ]], dtype=float32)
time = 53930	action = 0	current_phase = 1	next_phase = 0	reward = 0.721036	array([[  0.42111778, -43.441822  ]], dtype=float32)
time = 53935	action = 0	current_phase = 1	next_phase = 0	reward = 0.712262	array([[  0.39862633, -43.54712   ]], dtype=float32)
time = 53940	action = 0	current_phase = 1	next_phase = 0	reward = 0.721501	array([[  0.38907623, -43.501213  ]], dtype=float32)
time = 53945	action = 0	current_phase = 1	next_phase = 0	reward = 0.723343	array([[  0.41675568, -43.512367  ]], dtype=float32)
time = 53950	action = 0	current_phase = 1	next_phase = 0	reward = 0.726812	array([[  0.40882015, -43.524433  ]], dtype=float32)
time = 53955	action = 0	current_phase = 1	next_phase = 0	reward = 0.720489	array([[  0.40243912, -43.55379   ]], dtype=float32)
time = 53960	action = 0	current_phase = 1	next_phase = 0	reward = 0.718980	array([[  0.42085743, -43.394146  ]], dtype=float32)
time = 53965	action = 0	current_phase = 1	next_phase = 0	reward = 0.444846	array([[  0.39112473, -43.586807  ]], dtype=float32)
time = 53970	action = 0	current_phase = 1	next_phase = 0	reward = 1.008515	array([[  0.39000893, -43.588783  ]], dtype=float32)
time = 53975	action = 0	current_phase = 1	next_phase = 0	reward = 0.714324	array([[  0.3993845, -43.407402 ]], dtype=float32)
time = 53980	action = 0	current_phase = 1	next_phase = 0	reward = 0.712962	array([[  0.3970232, -43.558235 ]], dtype=float32)
time = 53985	action = 0	current_phase = 1	next_phase = 0	reward = 0.729141	array([[  0.41191864, -43.52784   ]], dtype=float32)
time = 53990	action = 0	current_phase = 1	next_phase = 0	reward = 0.724892	array([[  0.4026804, -43.556282 ]], dtype=float32)
time = 53995	action = 0	current_phase = 1	next_phase = 0	reward = 0.727289	array([[  0.38528824, -43.59498   ]], dtype=float32)
time = 54000	action = 0	current_phase = 1	next_phase = 0	reward = 0.719226	array([[  0.42546654, -43.45784   ]], dtype=float32)
time = 54005	action = 0	current_phase = 1	next_phase = 0	reward = 0.717733	array([[  0.4096918, -43.507866 ]], dtype=float32)
time = 54010	action = 0	current_phase = 1	next_phase = 0	reward = 0.713897	array([[  0.42617607, -43.443935  ]], dtype=float32)
time = 54015	action = 0	current_phase = 1	next_phase = 0	reward = 0.715963	array([[  0.40282726, -43.54991   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 336.2162 - val_loss: 656.1845
Epoch 2/50
 - 4s - loss: 345.5931 - val_loss: 633.6031
Epoch 3/50
 - 4s - loss: 339.4405 - val_loss: 612.6485
Epoch 4/50
 - 4s - loss: 329.3151 - val_loss: 599.6709
Epoch 5/50
 - 4s - loss: 337.0022 - val_loss: 619.2504
Epoch 6/50
 - 4s - loss: 334.2773 - val_loss: 596.5191
Epoch 7/50
 - 4s - loss: 349.9097 - val_loss: 611.0470
Epoch 8/50
 - 4s - loss: 329.2756 - val_loss: 613.6862
Epoch 9/50
 - 4s - loss: 320.9713 - val_loss: 640.3639
Epoch 10/50
 - 4s - loss: 338.1428 - val_loss: 597.5644
Epoch 11/50
 - 4s - loss: 324.7099 - val_loss: 582.6301
Epoch 12/50
 - 4s - loss: 344.3932 - val_loss: 655.6404
Epoch 13/50
 - 4s - loss: 318.9451 - val_loss: 598.8072
Epoch 14/50
 - 4s - loss: 332.2116 - val_loss: 660.5999
Epoch 15/50
 - 4s - loss: 330.8638 - val_loss: 594.1397
Epoch 16/50
 - 4s - loss: 326.4661 - val_loss: 598.1077
Epoch 17/50
 - 4s - loss: 322.6958 - val_loss: 713.0861
Epoch 18/50
 - 4s - loss: 357.8294 - val_loss: 626.2265
Epoch 19/50
 - 4s - loss: 318.6638 - val_loss: 642.0328
Epoch 20/50
 - 4s - loss: 327.0076 - val_loss: 598.3536
Epoch 21/50
 - 4s - loss: 324.8636 - val_loss: 576.9290
Epoch 22/50
 - 4s - loss: 335.1812 - val_loss: 694.5106
Epoch 23/50
 - 4s - loss: 329.3753 - val_loss: 600.9204
Epoch 24/50
 - 4s - loss: 331.5396 - val_loss: 598.9925
Epoch 25/50
 - 4s - loss: 319.5340 - val_loss: 662.5423
Epoch 26/50
 - 4s - loss: 329.2291 - val_loss: 613.9906
Epoch 27/50
 - 4s - loss: 319.4720 - val_loss: 603.9220
Epoch 28/50
 - 4s - loss: 312.2580 - val_loss: 615.4445
Epoch 29/50
 - 4s - loss: 336.3506 - val_loss: 621.7308
Epoch 30/50
 - 4s - loss: 329.8078 - val_loss: 598.7771
Epoch 31/50
 - 4s - loss: 324.9688 - val_loss: 606.5781
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 54020	action = 0	current_phase = 1	next_phase = 0	reward = 0.717942	array([[  0.41426563, -43.179543  ]], dtype=float32)
time = 54025	action = 0	current_phase = 1	next_phase = 0	reward = 0.729569	array([[  0.464859, -43.305264]], dtype=float32)
time = 54030	action = 0	current_phase = 1	next_phase = 0	reward = 0.452760	array([[  0.50028324, -43.57131   ]], dtype=float32)
time = 54035	action = 0	current_phase = 1	next_phase = 0	reward = 1.004413	array([[  0.4978428, -43.699505 ]], dtype=float32)
time = 54040	action = 0	current_phase = 1	next_phase = 0	reward = 0.716198	array([[  0.48263454, -43.42016   ]], dtype=float32)
time = 54045	action = 0	current_phase = 1	next_phase = 0	reward = 0.709486	array([[  0.4996872, -43.63331  ]], dtype=float32)
time = 54050	action = 0	current_phase = 1	next_phase = 0	reward = 0.718683	array([[  0.50347424, -43.60556   ]], dtype=float32)
time = 54055	action = 0	current_phase = 1	next_phase = 0	reward = 0.722223	array([[  0.48997498, -43.45723   ]], dtype=float32)
time = 54060	action = 0	current_phase = 1	next_phase = 0	reward = 0.448245	array([[  0.49704838, -43.51712   ]], dtype=float32)
time = 54065	action = 0	current_phase = 1	next_phase = 0	reward = 1.003070	array([[  0.4810772, -43.415962 ]], dtype=float32)
time = 54070	action = 0	current_phase = 1	next_phase = 0	reward = 0.725143	array([[  0.47676277, -43.474545  ]], dtype=float32)
time = 54075	action = 0	current_phase = 1	next_phase = 0	reward = 0.724569	array([[  0.4631939, -43.33098  ]], dtype=float32)
time = 54080	action = 0	current_phase = 1	next_phase = 0	reward = 0.724763	array([[  0.48845577, -43.44317   ]], dtype=float32)
time = 54085	action = 0	current_phase = 1	next_phase = 0	reward = 0.722954	array([[  0.49881554, -43.51184   ]], dtype=float32)
time = 54090	action = 0	current_phase = 1	next_phase = 0	reward = 0.719771	array([[  0.5000124, -43.5832   ]], dtype=float32)
time = 54095	action = 0	current_phase = 1	next_phase = 0	reward = 0.718394	array([[  0.46693134, -43.338634  ]], dtype=float32)
time = 54100	action = 0	current_phase = 1	next_phase = 0	reward = 0.721509	array([[  0.47140694, -43.36022   ]], dtype=float32)
time = 54105	action = 0	current_phase = 1	next_phase = 0	reward = 0.451880	array([[  0.49069977, -43.471695  ]], dtype=float32)
time = 54110	action = 0	current_phase = 1	next_phase = 0	reward = 1.004375	array([[  0.49888706, -43.52197   ]], dtype=float32)
time = 54115	action = 0	current_phase = 1	next_phase = 0	reward = 0.439829	array([[  0.5000906, -43.71306  ]], dtype=float32)
time = 54120	action = 0	current_phase = 1	next_phase = 0	reward = 1.000665	array([[  0.47974586, -43.423367  ]], dtype=float32)
time = 54125	action = 0	current_phase = 1	next_phase = 0	reward = 0.431313	array([[  0.50587654, -43.644176  ]], dtype=float32)
time = 54130	action = 0	current_phase = 1	next_phase = 0	reward = 0.999298	array([[  0.5013132, -43.649887 ]], dtype=float32)
time = 54135	action = 0	current_phase = 1	next_phase = 0	reward = 0.727263	array([[  0.45202637, -43.27101   ]], dtype=float32)
time = 54140	action = 0	current_phase = 1	next_phase = 0	reward = 0.448981	array([[  0.49910927, -43.622246  ]], dtype=float32)
time = 54145	action = 0	current_phase = 1	next_phase = 0	reward = 1.006485	array([[  0.50156593, -43.621616  ]], dtype=float32)
time = 54150	action = 0	current_phase = 1	next_phase = 0	reward = 0.716291	array([[  0.4833231, -43.44864  ]], dtype=float32)
time = 54155	action = 0	current_phase = 1	next_phase = 0	reward = 0.708284	array([[  0.45392895, -43.571106  ]], dtype=float32)
time = 54160	action = 0	current_phase = 1	next_phase = 0	reward = 0.445554	array([[  0.42702484, -43.216232  ]], dtype=float32)
time = 54165	action = 0	current_phase = 1	next_phase = 0	reward = 1.000025	array([[  0.47247982, -43.430542  ]], dtype=float32)
time = 54170	action = 0	current_phase = 1	next_phase = 0	reward = 0.438084	array([[  0.500535, -43.539833]], dtype=float32)
time = 54175	action = 0	current_phase = 1	next_phase = 0	reward = 0.723682	array([[  0.4711113, -43.38624  ]], dtype=float32)
time = 54180	action = 0	current_phase = 1	next_phase = 0	reward = 1.006700	array([[  0.46907234, -43.366653  ]], dtype=float32)
time = 54185	action = 0	current_phase = 1	next_phase = 0	reward = 0.734565	array([[  0.4987259, -43.581627 ]], dtype=float32)
time = 54190	action = 0	current_phase = 1	next_phase = 0	reward = 0.713862	array([[  0.5004387, -43.557182 ]], dtype=float32)
time = 54195	action = 0	current_phase = 1	next_phase = 0	reward = 0.712294	array([[  0.47355556, -43.343147  ]], dtype=float32)
time = 54200	action = 0	current_phase = 1	next_phase = 0	reward = 0.436290	array([[  0.5050955, -43.63257  ]], dtype=float32)
time = 54205	action = 0	current_phase = 1	next_phase = 0	reward = 0.997617	array([[  0.47960377, -43.385513  ]], dtype=float32)
time = 54210	action = 0	current_phase = 1	next_phase = 0	reward = 0.433840	array([[  0.51006126, -43.61199   ]], dtype=float32)
time = 54215	action = 0	current_phase = 1	next_phase = 0	reward = 0.998568	array([[  0.50255203, -43.671993  ]], dtype=float32)
time = 54220	action = 0	current_phase = 1	next_phase = 0	reward = 0.446875	array([[  0.49497604, -43.47663   ]], dtype=float32)
time = 54225	action = 0	current_phase = 1	next_phase = 0	reward = 1.004487	array([[  0.47720814, -43.383995  ]], dtype=float32)
time = 54230	action = 0	current_phase = 1	next_phase = 0	reward = 0.724895	array([[  0.46812248, -43.32699   ]], dtype=float32)
time = 54235	action = 0	current_phase = 1	next_phase = 0	reward = 0.721581	array([[  0.48392296, -43.40811   ]], dtype=float32)
time = 54240	action = 0	current_phase = 1	next_phase = 0	reward = 0.724858	array([[  0.48575497, -43.46136   ]], dtype=float32)
time = 54245	action = 0	current_phase = 1	next_phase = 0	reward = 0.713371	array([[  0.4856758, -43.421997 ]], dtype=float32)
time = 54250	action = 0	current_phase = 1	next_phase = 0	reward = 0.716662	array([[  0.5120449, -43.567657 ]], dtype=float32)
time = 54255	action = 0	current_phase = 1	next_phase = 0	reward = 0.718748	array([[  0.4929781, -43.483513 ]], dtype=float32)
time = 54260	action = 0	current_phase = 1	next_phase = 0	reward = 0.442746	array([[  0.49106407, -43.516335  ]], dtype=float32)
time = 54265	action = 0	current_phase = 1	next_phase = 0	reward = 1.003237	array([[  0.50148964, -43.657463  ]], dtype=float32)
time = 54270	action = 0	current_phase = 1	next_phase = 0	reward = 0.717203	array([[  0.50178623, -43.641552  ]], dtype=float32)
time = 54275	action = 0	current_phase = 1	next_phase = 0	reward = 0.441386	array([[  0.4837284, -43.572945 ]], dtype=float32)
time = 54280	action = 0	current_phase = 1	next_phase = 0	reward = 1.004663	array([[  0.46101093, -43.331528  ]], dtype=float32)
time = 54285	action = 0	current_phase = 1	next_phase = 0	reward = 0.728537	array([[  0.4924116, -43.446503 ]], dtype=float32)
time = 54290	action = 0	current_phase = 1	next_phase = 0	reward = 0.718079	array([[  0.5043411, -43.550503 ]], dtype=float32)
time = 54295	action = 0	current_phase = 1	next_phase = 0	reward = 0.719409	array([[  0.496953, -43.56475 ]], dtype=float32)
time = 54300	action = 0	current_phase = 1	next_phase = 0	reward = 0.726488	array([[  0.43743038, -43.26585   ]], dtype=float32)
time = 54305	action = 0	current_phase = 1	next_phase = 0	reward = 0.716804	array([[  0.45327568, -43.277122  ]], dtype=float32)
time = 54310	action = 0	current_phase = 1	next_phase = 0	reward = 0.721017	array([[  0.5000391, -43.498337 ]], dtype=float32)
time = 54315	action = 0	current_phase = 1	next_phase = 0	reward = 0.718946	array([[  0.49500942, -43.73406   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2915.9091 - val_loss: 898.3621
Epoch 2/50
 - 4s - loss: 2917.2341 - val_loss: 888.2848
Epoch 3/50
 - 4s - loss: 2913.9155 - val_loss: 887.7520
Epoch 4/50
 - 4s - loss: 2905.5795 - val_loss: 904.6217
Epoch 5/50
 - 4s - loss: 2911.5653 - val_loss: 874.8623
Epoch 6/50
 - 4s - loss: 2894.6869 - val_loss: 882.6010
Epoch 7/50
 - 4s - loss: 2900.5278 - val_loss: 874.7160
Epoch 8/50
 - 4s - loss: 2900.9949 - val_loss: 872.5471
Epoch 9/50
 - 4s - loss: 2896.4767 - val_loss: 881.4387
Epoch 10/50
 - 4s - loss: 2899.4043 - val_loss: 895.7419
Epoch 11/50
 - 4s - loss: 2894.5934 - val_loss: 924.0279
Epoch 12/50
 - 4s - loss: 2914.7909 - val_loss: 891.3851
Epoch 13/50
 - 4s - loss: 2887.3798 - val_loss: 884.4600
Epoch 14/50
 - 4s - loss: 2885.4003 - val_loss: 864.8248
Epoch 15/50
 - 4s - loss: 2872.7817 - val_loss: 862.0910
Epoch 16/50
 - 4s - loss: 2884.0785 - val_loss: 868.4983
Epoch 17/50
 - 4s - loss: 2874.3440 - val_loss: 867.1883
Epoch 18/50
 - 4s - loss: 2874.0570 - val_loss: 859.1706
Epoch 19/50
 - 4s - loss: 2871.6085 - val_loss: 890.2662
Epoch 20/50
 - 4s - loss: 2877.1796 - val_loss: 867.2518
Epoch 21/50
 - 4s - loss: 2868.3798 - val_loss: 866.2908
Epoch 22/50
 - 4s - loss: 2866.2789 - val_loss: 882.0144
Epoch 23/50
 - 4s - loss: 2858.9345 - val_loss: 870.3794
Epoch 24/50
 - 4s - loss: 2860.8738 - val_loss: 866.3094
Epoch 25/50
 - 4s - loss: 2853.0434 - val_loss: 878.2447
Epoch 26/50
 - 4s - loss: 2873.8353 - val_loss: 856.4358
Epoch 27/50
 - 4s - loss: 2853.3344 - val_loss: 863.7037
Epoch 28/50
 - 4s - loss: 2857.6367 - val_loss: 877.0872
Epoch 29/50
 - 4s - loss: 2846.6650 - val_loss: 862.1982
Epoch 30/50
 - 4s - loss: 2861.2039 - val_loss: 880.8207
Epoch 31/50
 - 4s - loss: 2864.6172 - val_loss: 875.7115
Epoch 32/50
 - 4s - loss: 2849.6232 - val_loss: 856.6078
Epoch 33/50
 - 4s - loss: 2859.3733 - val_loss: 860.0917
Epoch 34/50
 - 4s - loss: 2880.1936 - val_loss: 901.7374
Epoch 35/50
 - 4s - loss: 2852.7861 - val_loss: 846.3974
Epoch 36/50
 - 4s - loss: 2864.9727 - val_loss: 930.8410
Epoch 37/50
 - 4s - loss: 2848.6635 - val_loss: 855.2207
Epoch 38/50
 - 4s - loss: 2836.7721 - val_loss: 841.8337
Epoch 39/50
 - 4s - loss: 2829.7166 - val_loss: 853.2376
Epoch 40/50
 - 4s - loss: 2847.6963 - val_loss: 853.6190
Epoch 41/50
 - 4s - loss: 2822.1115 - val_loss: 862.0722
Epoch 42/50
 - 4s - loss: 2845.9553 - val_loss: 841.7623
Epoch 43/50
 - 4s - loss: 2841.1274 - val_loss: 835.1234
Epoch 44/50
 - 4s - loss: 2820.1782 - val_loss: 908.6984
Epoch 45/50
 - 4s - loss: 2819.4224 - val_loss: 853.9509
Epoch 46/50
 - 4s - loss: 2830.4648 - val_loss: 841.0984
Epoch 47/50
 - 4s - loss: 2815.2155 - val_loss: 826.8717
Epoch 48/50
 - 4s - loss: 2827.5269 - val_loss: 839.6235
Epoch 49/50
 - 4s - loss: 2806.0743 - val_loss: 825.2201
Epoch 50/50
 - 4s - loss: 2815.3970 - val_loss: 813.3212
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 54320	action = 0	current_phase = 1	next_phase = 0	reward = 0.163243	array([[  1.0488815, -43.70222  ]], dtype=float32)
time = 54325	action = 0	current_phase = 1	next_phase = 0	reward = 1.286766	array([[  1.0459042, -43.630127 ]], dtype=float32)
time = 54330	action = 0	current_phase = 1	next_phase = 0	reward = 0.727882	array([[  1.0518055, -43.702652 ]], dtype=float32)
time = 54335	action = 0	current_phase = 1	next_phase = 0	reward = 0.721543	array([[  1.0309324, -43.61688  ]], dtype=float32)
time = 54340	action = 0	current_phase = 1	next_phase = 0	reward = 0.717950	array([[  1.0270939, -43.52095  ]], dtype=float32)
time = 54345	action = 0	current_phase = 1	next_phase = 0	reward = 0.727441	array([[  1.0376396, -43.636692 ]], dtype=float32)
time = 54350	action = 0	current_phase = 1	next_phase = 0	reward = 0.719203	array([[  1.0548964, -43.810143 ]], dtype=float32)
time = 54355	action = 0	current_phase = 1	next_phase = 0	reward = 0.719524	array([[  1.0523882, -43.736755 ]], dtype=float32)
time = 54360	action = 0	current_phase = 1	next_phase = 0	reward = 0.448125	array([[  1.0553207, -43.809223 ]], dtype=float32)
time = 54365	action = 0	current_phase = 1	next_phase = 0	reward = 1.008927	array([[  1.0064468, -43.41912  ]], dtype=float32)
time = 54370	action = 0	current_phase = 1	next_phase = 0	reward = 0.723464	array([[  1.0555754, -43.80954  ]], dtype=float32)
time = 54375	action = 0	current_phase = 1	next_phase = 0	reward = 0.718284	array([[  1.0487871, -43.793114 ]], dtype=float32)
time = 54380	action = 0	current_phase = 1	next_phase = 0	reward = 0.716223	array([[  1.0349417, -43.582237 ]], dtype=float32)
time = 54385	action = 0	current_phase = 1	next_phase = 0	reward = 0.711734	array([[  1.0466042, -43.787178 ]], dtype=float32)
time = 54390	action = 0	current_phase = 1	next_phase = 0	reward = 0.440995	array([[  1.0091457, -43.816048 ]], dtype=float32)
time = 54395	action = 0	current_phase = 1	next_phase = 0	reward = 1.002806	array([[  1.0540953, -43.83308  ]], dtype=float32)
time = 54400	action = 0	current_phase = 1	next_phase = 0	reward = 0.439177	array([[  1.0547237, -43.787018 ]], dtype=float32)
time = 54405	action = 0	current_phase = 1	next_phase = 0	reward = 1.003621	array([[  1.0583534, -43.817657 ]], dtype=float32)
time = 54410	action = 0	current_phase = 1	next_phase = 0	reward = 0.719664	array([[  1.0511942, -43.67329  ]], dtype=float32)
time = 54415	action = 0	current_phase = 1	next_phase = 0	reward = 0.449402	array([[  1.0282593, -43.546246 ]], dtype=float32)
time = 54420	action = 0	current_phase = 1	next_phase = 0	reward = 1.007762	array([[  1.0543156, -43.810825 ]], dtype=float32)
time = 54425	action = 0	current_phase = 1	next_phase = 0	reward = 0.434742	array([[  1.0529728, -43.758453 ]], dtype=float32)
time = 54430	action = 0	current_phase = 1	next_phase = 0	reward = 0.998700	array([[  1.0540733, -43.854294 ]], dtype=float32)
time = 54435	action = 0	current_phase = 1	next_phase = 0	reward = 0.439677	array([[  1.0410147, -43.607895 ]], dtype=float32)
time = 54440	action = 0	current_phase = 1	next_phase = 0	reward = 0.729314	array([[  1.0476589, -43.70229  ]], dtype=float32)
time = 54445	action = 0	current_phase = 1	next_phase = 0	reward = 0.728158	array([[  1.01682 , -43.464397]], dtype=float32)
time = 54450	action = 0	current_phase = 1	next_phase = 0	reward = 1.005617	array([[  1.061511, -43.815784]], dtype=float32)
time = 54455	action = 0	current_phase = 1	next_phase = 0	reward = 0.715069	array([[  1.0595198, -43.760975 ]], dtype=float32)
time = 54460	action = 0	current_phase = 1	next_phase = 0	reward = 0.717853	array([[  1.0299301, -43.582905 ]], dtype=float32)
time = 54465	action = 0	current_phase = 1	next_phase = 0	reward = 0.712556	array([[  1.0483198, -43.74009  ]], dtype=float32)
time = 54470	action = 0	current_phase = 1	next_phase = 0	reward = 0.436813	array([[  1.0510864, -43.692535 ]], dtype=float32)
time = 54475	action = 0	current_phase = 1	next_phase = 0	reward = 1.000882	array([[  1.0550556, -43.72976  ]], dtype=float32)
time = 54480	action = 0	current_phase = 1	next_phase = 0	reward = 0.722832	array([[  1.053072, -43.686714]], dtype=float32)
time = 54485	action = 0	current_phase = 1	next_phase = 0	reward = 0.160590	array([[  1.0572205, -43.8347   ]], dtype=float32)
time = 54490	action = 0	current_phase = 1	next_phase = 0	reward = 1.279640	array([[  1.0370054, -43.553    ]], dtype=float32)
time = 54495	action = 0	current_phase = 1	next_phase = 0	reward = 0.717700	array([[  1.0484829, -43.737797 ]], dtype=float32)
time = 54500	action = 0	current_phase = 1	next_phase = 0	reward = 0.721585	array([[  1.0510378, -43.68699  ]], dtype=float32)
time = 54505	action = 0	current_phase = 1	next_phase = 0	reward = 0.437593	array([[  0.98585033, -43.680626  ]], dtype=float32)
time = 54510	action = 0	current_phase = 1	next_phase = 0	reward = 1.001667	array([[  1.031785, -43.537052]], dtype=float32)
time = 54515	action = 0	current_phase = 1	next_phase = 0	reward = 0.717662	array([[  1.0514641, -43.694416 ]], dtype=float32)
time = 54520	action = 0	current_phase = 1	next_phase = 0	reward = 0.719375	array([[  1.0580626, -43.736946 ]], dtype=float32)
time = 54525	action = 0	current_phase = 1	next_phase = 0	reward = 0.443184	array([[  1.0555553, -43.83367  ]], dtype=float32)
time = 54530	action = 0	current_phase = 1	next_phase = 0	reward = 1.006312	array([[  1.0559902, -43.7632   ]], dtype=float32)
time = 54535	action = 0	current_phase = 1	next_phase = 0	reward = 0.722791	array([[  1.0579348, -43.710346 ]], dtype=float32)
time = 54540	action = 0	current_phase = 1	next_phase = 0	reward = 0.720162	array([[  1.0574121, -43.85662  ]], dtype=float32)
time = 54545	action = 0	current_phase = 1	next_phase = 0	reward = 0.717809	array([[  1.0359488, -43.64485  ]], dtype=float32)
time = 54550	action = 0	current_phase = 1	next_phase = 0	reward = 0.711185	array([[  1.0472832, -43.606262 ]], dtype=float32)
time = 54555	action = 0	current_phase = 1	next_phase = 0	reward = 0.714341	array([[  1.0442591, -43.634773 ]], dtype=float32)
time = 54560	action = 0	current_phase = 1	next_phase = 0	reward = 0.451374	array([[  1.0513124, -43.757946 ]], dtype=float32)
time = 54565	action = 0	current_phase = 1	next_phase = 0	reward = 0.995707	array([[  1.0621557, -43.837456 ]], dtype=float32)
time = 54570	action = 0	current_phase = 1	next_phase = 0	reward = 0.717227	array([[  1.0525827, -43.74533  ]], dtype=float32)
time = 54575	action = 0	current_phase = 1	next_phase = 0	reward = 0.438882	array([[  1.0618954, -43.819115 ]], dtype=float32)
time = 54580	action = 0	current_phase = 1	next_phase = 0	reward = 0.999163	array([[  1.0123224, -43.469425 ]], dtype=float32)
time = 54585	action = 0	current_phase = 1	next_phase = 0	reward = 0.435569	array([[  0.95572853, -43.44044   ]], dtype=float32)
time = 54590	action = 0	current_phase = 1	next_phase = 0	reward = 0.995098	array([[  1.0462437, -43.763832 ]], dtype=float32)
time = 54595	action = 0	current_phase = 1	next_phase = 0	reward = 0.720554	array([[  1.0407991, -43.589577 ]], dtype=float32)
time = 54600	action = 0	current_phase = 1	next_phase = 0	reward = 0.437208	array([[  0.9980364, -43.448288 ]], dtype=float32)
time = 54605	action = 0	current_phase = 1	next_phase = 0	reward = 0.440250	array([[  1.0568724, -43.81478  ]], dtype=float32)
time = 54610	action = 0	current_phase = 1	next_phase = 0	reward = 1.287327	array([[  1.0535564, -43.728966 ]], dtype=float32)
time = 54615	action = 0	current_phase = 1	next_phase = 0	reward = 0.720725	array([[  1.0503292, -43.656418 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2664.3756 - val_loss: 582.1026
Epoch 2/50
 - 4s - loss: 2658.3771 - val_loss: 605.9991
Epoch 3/50
 - 4s - loss: 2644.2526 - val_loss: 590.5421
Epoch 4/50
 - 4s - loss: 2652.5859 - val_loss: 611.2457
Epoch 5/50
 - 4s - loss: 2635.1446 - val_loss: 634.1856
Epoch 6/50
 - 4s - loss: 2696.4752 - val_loss: 588.3858
Epoch 7/50
 - 4s - loss: 2629.3128 - val_loss: 576.7957
Epoch 8/50
 - 4s - loss: 2626.7397 - val_loss: 599.5408
Epoch 9/50
 - 4s - loss: 2685.9479 - val_loss: 579.8793
Epoch 10/50
 - 4s - loss: 2639.4721 - val_loss: 591.7845
Epoch 11/50
 - 4s - loss: 2624.0607 - val_loss: 573.5751
Epoch 12/50
 - 4s - loss: 2634.8299 - val_loss: 574.6661
Epoch 13/50
 - 4s - loss: 2622.0977 - val_loss: 561.3866
Epoch 14/50
 - 4s - loss: 2622.6510 - val_loss: 579.7594
Epoch 15/50
 - 4s - loss: 2627.5868 - val_loss: 573.9746
Epoch 16/50
 - 4s - loss: 2622.8537 - val_loss: 562.9996
Epoch 17/50
 - 4s - loss: 2640.7876 - val_loss: 566.4601
Epoch 18/50
 - 4s - loss: 2621.2066 - val_loss: 564.2280
Epoch 19/50
 - 4s - loss: 2615.4276 - val_loss: 619.3944
Epoch 20/50
 - 4s - loss: 2624.3766 - val_loss: 562.4800
Epoch 21/50
 - 4s - loss: 2617.3566 - val_loss: 565.5621
Epoch 22/50
 - 4s - loss: 2622.1672 - val_loss: 578.4014
Epoch 23/50
 - 4s - loss: 2611.5171 - val_loss: 550.6815
Epoch 24/50
 - 4s - loss: 2615.0979 - val_loss: 560.5760
Epoch 25/50
 - 4s - loss: 2612.8175 - val_loss: 556.4918
Epoch 26/50
 - 4s - loss: 2625.9520 - val_loss: 559.4493
Epoch 27/50
 - 4s - loss: 2616.3788 - val_loss: 549.9056
Epoch 28/50
 - 4s - loss: 2609.7042 - val_loss: 572.3226
Epoch 29/50
 - 4s - loss: 2615.0624 - val_loss: 551.1450
Epoch 30/50
 - 4s - loss: 2608.9339 - val_loss: 570.1945
Epoch 31/50
 - 4s - loss: 2615.6394 - val_loss: 542.0190
Epoch 32/50
 - 4s - loss: 2607.9982 - val_loss: 545.9315
Epoch 33/50
 - 4s - loss: 2577.7597 - val_loss: 540.4566
Epoch 34/50
 - 4s - loss: 2602.4287 - val_loss: 555.0307
Epoch 35/50
 - 4s - loss: 2605.4593 - val_loss: 609.0900
Epoch 36/50
 - 4s - loss: 2594.3457 - val_loss: 538.3759
Epoch 37/50
 - 4s - loss: 2604.7399 - val_loss: 536.4819
Epoch 38/50
 - 4s - loss: 2591.6028 - val_loss: 548.7835
Epoch 39/50
 - 4s - loss: 2596.3285 - val_loss: 586.2612
Epoch 40/50
 - 4s - loss: 2590.0953 - val_loss: 540.2933
Epoch 41/50
 - 4s - loss: 2593.1572 - val_loss: 537.6974
Epoch 42/50
 - 4s - loss: 2600.8485 - val_loss: 560.5119
Epoch 43/50
 - 4s - loss: 2600.2046 - val_loss: 531.1224
Epoch 44/50
 - 4s - loss: 2578.8168 - val_loss: 559.8284
Epoch 45/50
 - 4s - loss: 2570.4397 - val_loss: 554.6956
Epoch 46/50
 - 4s - loss: 2594.3623 - val_loss: 550.9090
Epoch 47/50
 - 4s - loss: 2591.6440 - val_loss: 545.6939
Epoch 48/50
 - 4s - loss: 2580.8029 - val_loss: 539.6791
Epoch 49/50
 - 4s - loss: 2590.3703 - val_loss: 561.1672
Epoch 50/50
 - 4s - loss: 2580.6031 - val_loss: 534.9806
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 54620	action = 0	current_phase = 1	next_phase = 0	reward = 0.730650	array([[  1.0431747, -43.78305  ]], dtype=float32)
time = 54625	action = 0	current_phase = 1	next_phase = 0	reward = 0.721730	array([[  0.98878765, -43.31141   ]], dtype=float32)
time = 54630	action = 0	current_phase = 1	next_phase = 0	reward = 0.441476	array([[  1.0824003, -43.872005 ]], dtype=float32)
time = 54635	action = 0	current_phase = 1	next_phase = 0	reward = 1.006220	array([[  1.0679379, -43.63748  ]], dtype=float32)
time = 54640	action = 0	current_phase = 1	next_phase = 0	reward = 0.716390	array([[  1.0778046, -43.792248 ]], dtype=float32)
time = 54645	action = 0	current_phase = 1	next_phase = 0	reward = 0.721785	array([[  1.0848866, -43.872307 ]], dtype=float32)
time = 54650	action = 0	current_phase = 1	next_phase = 0	reward = 0.713371	array([[  1.0776052, -43.905045 ]], dtype=float32)
time = 54655	action = 0	current_phase = 1	next_phase = 0	reward = 0.718351	array([[  1.0635605, -43.658512 ]], dtype=float32)
time = 54660	action = 0	current_phase = 1	next_phase = 0	reward = 0.717274	array([[  1.0315323, -43.45     ]], dtype=float32)
time = 54665	action = 0	current_phase = 1	next_phase = 0	reward = 0.720451	array([[  1.0789547, -43.82072  ]], dtype=float32)
time = 54670	action = 0	current_phase = 1	next_phase = 0	reward = 0.723438	array([[  1.0306807, -43.54302  ]], dtype=float32)
time = 54675	action = 0	current_phase = 1	next_phase = 0	reward = 0.719772	array([[  1.0493832, -43.56939  ]], dtype=float32)
time = 54680	action = 0	current_phase = 1	next_phase = 0	reward = 0.724338	array([[  1.0745888, -43.79949  ]], dtype=float32)
time = 54685	action = 0	current_phase = 1	next_phase = 0	reward = 0.731388	array([[  0.99069977, -43.43244   ]], dtype=float32)
time = 54690	action = 0	current_phase = 1	next_phase = 0	reward = 0.724376	array([[  1.0180826, -43.428207 ]], dtype=float32)
time = 54695	action = 0	current_phase = 1	next_phase = 0	reward = 0.724295	array([[  1.0627985, -43.632206 ]], dtype=float32)
time = 54700	action = 0	current_phase = 1	next_phase = 0	reward = 0.722967	array([[  1.0853729, -43.731438 ]], dtype=float32)
time = 54705	action = 0	current_phase = 1	next_phase = 0	reward = 0.720543	array([[  1.0648985, -43.659134 ]], dtype=float32)
time = 54710	action = 0	current_phase = 1	next_phase = 0	reward = 0.441682	array([[  0.93009377, -43.327248  ]], dtype=float32)
time = 54715	action = 0	current_phase = 1	next_phase = 0	reward = 1.004477	array([[  1.0736809, -43.641003 ]], dtype=float32)
time = 54720	action = 0	current_phase = 1	next_phase = 0	reward = 0.722055	array([[  1.0552521, -43.567314 ]], dtype=float32)
time = 54725	action = 0	current_phase = 1	next_phase = 0	reward = 0.723589	array([[  1.0746403, -43.810295 ]], dtype=float32)
time = 54730	action = 0	current_phase = 1	next_phase = 0	reward = 0.721597	array([[  1.0813732, -43.77664  ]], dtype=float32)
time = 54735	action = 0	current_phase = 1	next_phase = 0	reward = 0.444517	array([[  1.0743561, -43.863476 ]], dtype=float32)
time = 54740	action = 0	current_phase = 1	next_phase = 0	reward = 1.009393	array([[  1.0105791, -43.362976 ]], dtype=float32)
time = 54745	action = 0	current_phase = 1	next_phase = 0	reward = 0.722028	array([[  1.0699406, -43.63665  ]], dtype=float32)
time = 54750	action = 0	current_phase = 1	next_phase = 0	reward = 0.713860	array([[  1.0650244, -43.692986 ]], dtype=float32)
time = 54755	action = 0	current_phase = 1	next_phase = 0	reward = 0.708901	array([[  1.0444622, -43.53222  ]], dtype=float32)
time = 54760	action = 0	current_phase = 1	next_phase = 0	reward = 0.437964	array([[  1.0700922, -43.632214 ]], dtype=float32)
time = 54765	action = 0	current_phase = 1	next_phase = 0	reward = 0.994770	array([[  1.0780964, -43.774254 ]], dtype=float32)
time = 54770	action = 0	current_phase = 1	next_phase = 0	reward = 0.727500	array([[  1.0397358, -43.502197 ]], dtype=float32)
time = 54775	action = 0	current_phase = 1	next_phase = 0	reward = 0.721970	array([[  1.077776, -43.678772]], dtype=float32)
time = 54780	action = 0	current_phase = 1	next_phase = 0	reward = 0.724913	array([[  1.0804472, -43.84836  ]], dtype=float32)
time = 54785	action = 0	current_phase = 1	next_phase = 0	reward = 0.444434	array([[  1.042016, -43.622032]], dtype=float32)
time = 54790	action = 0	current_phase = 1	next_phase = 0	reward = 1.001598	array([[  0.7299671, -43.257812 ]], dtype=float32)
time = 54795	action = 0	current_phase = 1	next_phase = 0	reward = 0.721363	array([[  1.0612545, -43.852776 ]], dtype=float32)
time = 54800	action = 0	current_phase = 1	next_phase = 0	reward = 0.723808	array([[  1.043005, -43.479877]], dtype=float32)
time = 54805	action = 0	current_phase = 1	next_phase = 0	reward = 0.728765	array([[  1.0310526, -43.46029  ]], dtype=float32)
time = 54810	action = 0	current_phase = 1	next_phase = 0	reward = 0.722986	array([[  1.0823259, -43.844246 ]], dtype=float32)
time = 54815	action = 0	current_phase = 1	next_phase = 0	reward = 0.715195	array([[  1.0474586, -43.50608  ]], dtype=float32)
time = 54820	action = 0	current_phase = 1	next_phase = 0	reward = 0.710955	array([[  1.0677862, -43.762573 ]], dtype=float32)
time = 54825	action = 0	current_phase = 1	next_phase = 0	reward = 0.717239	array([[  1.0548658, -43.74101  ]], dtype=float32)
time = 54830	action = 0	current_phase = 1	next_phase = 0	reward = 0.722866	array([[  1.0836496, -43.81785  ]], dtype=float32)
time = 54835	action = 0	current_phase = 1	next_phase = 0	reward = 0.440027	array([[  1.045949, -43.541256]], dtype=float32)
time = 54840	action = 0	current_phase = 1	next_phase = 0	reward = 0.725245	array([[  1.0822077, -43.72594  ]], dtype=float32)
time = 54845	action = 0	current_phase = 1	next_phase = 0	reward = 1.004426	array([[  1.0324717, -43.618954 ]], dtype=float32)
time = 54850	action = 0	current_phase = 1	next_phase = 0	reward = 0.720138	array([[  1.08004 , -43.829536]], dtype=float32)
time = 54855	action = 0	current_phase = 1	next_phase = 0	reward = 0.443497	array([[  1.0828133, -43.797028 ]], dtype=float32)
time = 54860	action = 0	current_phase = 1	next_phase = 0	reward = 1.002539	array([[  1.0747213, -43.710983 ]], dtype=float32)
time = 54865	action = 0	current_phase = 1	next_phase = 0	reward = 0.717022	array([[  1.0524712, -43.532787 ]], dtype=float32)
time = 54870	action = 0	current_phase = 1	next_phase = 0	reward = 0.719032	array([[  1.0854588, -43.797207 ]], dtype=float32)
time = 54875	action = 0	current_phase = 1	next_phase = 0	reward = 0.720570	array([[  1.0821152, -43.72694  ]], dtype=float32)
time = 54880	action = 0	current_phase = 1	next_phase = 0	reward = 0.720425	array([[  1.0741405, -43.66912  ]], dtype=float32)
time = 54885	action = 0	current_phase = 1	next_phase = 0	reward = 0.716808	array([[  1.0435266, -43.484283 ]], dtype=float32)
time = 54890	action = 0	current_phase = 1	next_phase = 0	reward = 0.711505	array([[  1.0504589, -43.589867 ]], dtype=float32)
time = 54895	action = 0	current_phase = 1	next_phase = 0	reward = 0.726709	array([[  1.0804052, -43.74295  ]], dtype=float32)
time = 54900	action = 0	current_phase = 1	next_phase = 0	reward = 0.722702	array([[  1.0590734, -43.651455 ]], dtype=float32)
time = 54905	action = 0	current_phase = 1	next_phase = 0	reward = 0.725102	array([[  1.054182, -43.795677]], dtype=float32)
time = 54910	action = 0	current_phase = 1	next_phase = 0	reward = 0.715889	array([[  1.066906, -43.938583]], dtype=float32)
time = 54915	action = 0	current_phase = 1	next_phase = 0	reward = 0.716625	array([[  1.0526791, -43.519123 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2736.0300 - val_loss: 710.3478
Epoch 2/50
 - 4s - loss: 2729.9806 - val_loss: 770.3491
Epoch 3/50
 - 4s - loss: 2738.1475 - val_loss: 741.9361
Epoch 4/50
 - 4s - loss: 2734.7087 - val_loss: 817.9378
Epoch 5/50
 - 4s - loss: 2715.5299 - val_loss: 744.3559
Epoch 6/50
 - 4s - loss: 2741.3353 - val_loss: 687.5252
Epoch 7/50
 - 4s - loss: 2726.2927 - val_loss: 713.7604
Epoch 8/50
 - 4s - loss: 2719.5444 - val_loss: 806.1626
Epoch 9/50
 - 4s - loss: 2719.5841 - val_loss: 739.2575
Epoch 10/50
 - 4s - loss: 2718.1027 - val_loss: 719.9915
Epoch 11/50
 - 4s - loss: 2702.7072 - val_loss: 785.7101
Epoch 12/50
 - 4s - loss: 2715.8985 - val_loss: 743.4598
Epoch 13/50
 - 4s - loss: 2706.2714 - val_loss: 834.3998
Epoch 14/50
 - 4s - loss: 2710.7559 - val_loss: 798.2039
Epoch 15/50
 - 4s - loss: 2695.4057 - val_loss: 788.7809
Epoch 16/50
 - 4s - loss: 2731.1698 - val_loss: 693.6516
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 54920	action = 0	current_phase = 1	next_phase = 0	reward = 0.161841	array([[  1.0753002, -44.05082  ]], dtype=float32)
time = 54925	action = 0	current_phase = 1	next_phase = 0	reward = 1.285263	array([[  1.0386381, -43.607574 ]], dtype=float32)
time = 54930	action = 0	current_phase = 1	next_phase = 0	reward = 0.447813	array([[  1.079422, -43.974243]], dtype=float32)
time = 54935	action = 0	current_phase = 1	next_phase = 0	reward = 1.003354	array([[  1.0838346, -43.890137 ]], dtype=float32)
time = 54940	action = 0	current_phase = 1	next_phase = 0	reward = 0.730996	array([[  1.0302763, -43.541206 ]], dtype=float32)
time = 54945	action = 0	current_phase = 1	next_phase = 0	reward = 0.723109	array([[  1.0898209, -43.908615 ]], dtype=float32)
time = 54950	action = 0	current_phase = 1	next_phase = 0	reward = 0.719495	array([[  1.088089, -43.940987]], dtype=float32)
time = 54955	action = 0	current_phase = 1	next_phase = 0	reward = 0.726203	array([[  1.0865908, -43.88137  ]], dtype=float32)
time = 54960	action = 0	current_phase = 1	next_phase = 0	reward = 0.712284	array([[  1.0674534, -43.731598 ]], dtype=float32)
time = 54965	action = 0	current_phase = 1	next_phase = 0	reward = 0.724477	array([[  1.089778, -43.912228]], dtype=float32)
time = 54970	action = 0	current_phase = 1	next_phase = 0	reward = 0.715020	array([[  1.0606308, -43.693733 ]], dtype=float32)
time = 54975	action = 0	current_phase = 1	next_phase = 0	reward = 0.702334	array([[  1.0775738, -44.060932 ]], dtype=float32)
time = 54980	action = 0	current_phase = 1	next_phase = 0	reward = 0.722526	array([[  1.0762501, -43.750225 ]], dtype=float32)
time = 54985	action = 0	current_phase = 1	next_phase = 0	reward = 0.441294	array([[  1.0763283, -43.731438 ]], dtype=float32)
time = 54990	action = 0	current_phase = 1	next_phase = 0	reward = 1.012938	array([[  1.0813475, -43.83024  ]], dtype=float32)
time = 54995	action = 0	current_phase = 1	next_phase = 0	reward = 0.726823	array([[  1.0435638, -43.624092 ]], dtype=float32)
time = 55000	action = 0	current_phase = 1	next_phase = 0	reward = 0.720922	array([[  1.0878401, -43.85513  ]], dtype=float32)
time = 55005	action = 0	current_phase = 1	next_phase = 0	reward = 0.716327	array([[  1.0894365, -43.83589  ]], dtype=float32)
time = 55010	action = 0	current_phase = 1	next_phase = 0	reward = 0.721771	array([[  1.0799723, -43.834213 ]], dtype=float32)
time = 55015	action = 0	current_phase = 1	next_phase = 0	reward = 0.721271	array([[  1.0879917, -43.9053   ]], dtype=float32)
time = 55020	action = 0	current_phase = 1	next_phase = 0	reward = 0.724115	array([[  0.99055004, -43.72814   ]], dtype=float32)
time = 55025	action = 0	current_phase = 1	next_phase = 0	reward = 0.726823	array([[  1.0725555, -43.71483  ]], dtype=float32)
time = 55030	action = 0	current_phase = 1	next_phase = 0	reward = 0.727404	array([[  1.0876245, -43.856216 ]], dtype=float32)
time = 55035	action = 0	current_phase = 1	next_phase = 0	reward = 0.725837	array([[  1.0294638, -43.620125 ]], dtype=float32)
time = 55040	action = 0	current_phase = 1	next_phase = 0	reward = 0.724926	array([[  1.0811996, -43.92056  ]], dtype=float32)
time = 55045	action = 0	current_phase = 1	next_phase = 0	reward = 0.725111	array([[  1.0585346, -44.114326 ]], dtype=float32)
time = 55050	action = 0	current_phase = 1	next_phase = 0	reward = 0.723068	array([[  1.0729895, -44.05925  ]], dtype=float32)
time = 55055	action = 0	current_phase = 1	next_phase = 0	reward = 0.727040	array([[  1.0874214, -43.834976 ]], dtype=float32)
time = 55060	action = 0	current_phase = 1	next_phase = 0	reward = 0.721157	array([[  1.0876341, -44.009186 ]], dtype=float32)
time = 55065	action = 0	current_phase = 1	next_phase = 0	reward = 0.711098	array([[  1.0879202, -43.935925 ]], dtype=float32)
time = 55070	action = 0	current_phase = 1	next_phase = 0	reward = 0.715113	array([[  1.0146418, -43.469524 ]], dtype=float32)
time = 55075	action = 0	current_phase = 1	next_phase = 0	reward = 0.716371	array([[  1.0368471, -43.531532 ]], dtype=float32)
time = 55080	action = 0	current_phase = 1	next_phase = 0	reward = 0.723268	array([[  1.0604506, -43.636517 ]], dtype=float32)
time = 55085	action = 0	current_phase = 1	next_phase = 0	reward = 0.450809	array([[  1.0720005, -43.873505 ]], dtype=float32)
time = 55090	action = 0	current_phase = 1	next_phase = 0	reward = 1.002649	array([[  1.0636778, -43.743095 ]], dtype=float32)
time = 55095	action = 0	current_phase = 1	next_phase = 0	reward = 0.715021	array([[  1.0312243, -43.514698 ]], dtype=float32)
time = 55100	action = 0	current_phase = 1	next_phase = 0	reward = 0.722118	array([[  1.0303736, -43.69313  ]], dtype=float32)
time = 55105	action = 0	current_phase = 1	next_phase = 0	reward = 0.718675	array([[  1.0734339, -43.713882 ]], dtype=float32)
time = 55110	action = 0	current_phase = 1	next_phase = 0	reward = 0.172273	array([[  1.0908232, -43.915596 ]], dtype=float32)
time = 55115	action = 0	current_phase = 1	next_phase = 0	reward = 1.291560	array([[  1.0556993, -43.61299  ]], dtype=float32)
time = 55120	action = 0	current_phase = 1	next_phase = 0	reward = 0.722326	array([[  1.0847874, -43.998924 ]], dtype=float32)
time = 55125	action = 0	current_phase = 1	next_phase = 0	reward = 0.717190	array([[  1.0915976, -43.960945 ]], dtype=float32)
time = 55130	action = 0	current_phase = 1	next_phase = 0	reward = 0.732542	array([[  1.083847, -43.831097]], dtype=float32)
time = 55135	action = 0	current_phase = 1	next_phase = 0	reward = 0.719195	array([[  1.0848436, -43.84166  ]], dtype=float32)
time = 55140	action = 0	current_phase = 1	next_phase = 0	reward = 0.718994	array([[  1.0875139, -43.834686 ]], dtype=float32)
time = 55145	action = 0	current_phase = 1	next_phase = 0	reward = 0.718831	array([[  1.0548544, -43.659805 ]], dtype=float32)
time = 55150	action = 0	current_phase = 1	next_phase = 0	reward = 0.711092	array([[  1.087286, -43.798546]], dtype=float32)
time = 55155	action = 0	current_phase = 1	next_phase = 0	reward = 0.720788	array([[  1.024436, -43.660843]], dtype=float32)
time = 55160	action = 0	current_phase = 1	next_phase = 0	reward = 0.719431	array([[  1.0773821, -43.71124  ]], dtype=float32)
time = 55165	action = 0	current_phase = 1	next_phase = 0	reward = 0.448098	array([[  1.0825596, -43.790077 ]], dtype=float32)
time = 55170	action = 0	current_phase = 1	next_phase = 0	reward = 1.010232	array([[  1.0859861, -43.9258   ]], dtype=float32)
time = 55175	action = 0	current_phase = 1	next_phase = 0	reward = 0.720556	array([[  1.0883608, -43.94397  ]], dtype=float32)
time = 55180	action = 0	current_phase = 1	next_phase = 0	reward = 0.710689	array([[  1.0832796, -43.79699  ]], dtype=float32)
time = 55185	action = 0	current_phase = 1	next_phase = 0	reward = 0.428076	array([[  1.0679836, -43.66101  ]], dtype=float32)
time = 55190	action = 0	current_phase = 1	next_phase = 0	reward = 0.441008	array([[  1.0447483, -43.56724  ]], dtype=float32)
time = 55195	action = 0	current_phase = 1	next_phase = 0	reward = 0.731059	array([[  1.0868921, -43.97532  ]], dtype=float32)
time = 55200	action = 0	current_phase = 1	next_phase = 0	reward = 1.286809	array([[  1.0897312, -43.885933 ]], dtype=float32)
time = 55205	action = 0	current_phase = 1	next_phase = 0	reward = 0.718664	array([[  1.04212, -43.73815]], dtype=float32)
time = 55210	action = 0	current_phase = 1	next_phase = 0	reward = 0.719629	array([[  1.0604925, -43.710995 ]], dtype=float32)
time = 55215	action = 0	current_phase = 1	next_phase = 0	reward = 0.720964	array([[  1.0799551, -43.908524 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2495.5914 - val_loss: 801.3594
Epoch 2/50
 - 4s - loss: 2491.0576 - val_loss: 817.7984
Epoch 3/50
 - 4s - loss: 2483.3489 - val_loss: 811.3034
Epoch 4/50
 - 4s - loss: 2510.4453 - val_loss: 785.6856
Epoch 5/50
 - 4s - loss: 2476.4530 - val_loss: 795.4190
Epoch 6/50
 - 4s - loss: 2484.2824 - val_loss: 799.6385
Epoch 7/50
 - 4s - loss: 2493.2221 - val_loss: 779.1541
Epoch 8/50
 - 4s - loss: 2456.7014 - val_loss: 774.6771
Epoch 9/50
 - 4s - loss: 2468.7224 - val_loss: 781.2783
Epoch 10/50
 - 4s - loss: 2474.2842 - val_loss: 803.7720
Epoch 11/50
 - 4s - loss: 2514.0067 - val_loss: 804.0684
Epoch 12/50
 - 4s - loss: 2475.1737 - val_loss: 776.2363
Epoch 13/50
 - 4s - loss: 2480.5424 - val_loss: 791.7334
Epoch 14/50
 - 4s - loss: 2499.4936 - val_loss: 784.3716
Epoch 15/50
 - 4s - loss: 2475.6652 - val_loss: 789.9764
Epoch 16/50
 - 4s - loss: 2465.0688 - val_loss: 783.9347
Epoch 17/50
 - 4s - loss: 2477.1476 - val_loss: 772.6078
Epoch 18/50
 - 4s - loss: 2450.7935 - val_loss: 765.5528
Epoch 19/50
 - 4s - loss: 2478.8150 - val_loss: 784.4361
Epoch 20/50
 - 4s - loss: 2470.5571 - val_loss: 778.0136
Epoch 21/50
 - 4s - loss: 2459.5675 - val_loss: 793.1491
Epoch 22/50
 - 4s - loss: 2495.6834 - val_loss: 780.5063
Epoch 23/50
 - 4s - loss: 2459.3124 - val_loss: 772.6820
Epoch 24/50
 - 4s - loss: 2473.5531 - val_loss: 768.7338
Epoch 25/50
 - 4s - loss: 2460.5788 - val_loss: 765.1946
Epoch 26/50
 - 4s - loss: 2447.9251 - val_loss: 794.6501
Epoch 27/50
 - 4s - loss: 2457.2550 - val_loss: 781.5156
Epoch 28/50
 - 4s - loss: 2439.5635 - val_loss: 784.6551
Epoch 29/50
 - 4s - loss: 2448.2613 - val_loss: 760.6125
Epoch 30/50
 - 4s - loss: 2455.1723 - val_loss: 767.5735
Epoch 31/50
 - 4s - loss: 2438.2897 - val_loss: 781.8439
Epoch 32/50
 - 4s - loss: 2447.0029 - val_loss: 762.5011
Epoch 33/50
 - 4s - loss: 2438.9798 - val_loss: 765.9981
Epoch 34/50
 - 4s - loss: 2442.7770 - val_loss: 764.8445
Epoch 35/50
 - 4s - loss: 2443.1744 - val_loss: 766.6781
Epoch 36/50
 - 4s - loss: 2465.3461 - val_loss: 764.9393
Epoch 37/50
 - 4s - loss: 2434.9670 - val_loss: 770.0754
Epoch 38/50
 - 4s - loss: 2447.8397 - val_loss: 775.4167
Epoch 39/50
 - 4s - loss: 2446.0796 - val_loss: 764.0615
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 55220	action = 0	current_phase = 1	next_phase = 0	reward = 0.726165	array([[  0.93531036, -43.86416   ]], dtype=float32)
time = 55225	action = 0	current_phase = 1	next_phase = 0	reward = 0.722618	array([[  0.936553, -43.660652]], dtype=float32)
time = 55230	action = 0	current_phase = 1	next_phase = 0	reward = 0.721429	array([[  0.9082804, -43.483833 ]], dtype=float32)
time = 55235	action = 0	current_phase = 1	next_phase = 0	reward = 0.718216	array([[  0.9239397, -43.800476 ]], dtype=float32)
time = 55240	action = 0	current_phase = 1	next_phase = 0	reward = 0.443086	array([[  0.9351301, -43.840477 ]], dtype=float32)
time = 55245	action = 0	current_phase = 1	next_phase = 0	reward = 1.011524	array([[  0.887764, -43.44644 ]], dtype=float32)
time = 55250	action = 0	current_phase = 1	next_phase = 0	reward = 0.722429	array([[  0.913929, -43.834488]], dtype=float32)
time = 55255	action = 0	current_phase = 1	next_phase = 0	reward = 0.720301	array([[  0.9033184, -43.561424 ]], dtype=float32)
time = 55260	action = 0	current_phase = 1	next_phase = 0	reward = 0.719084	array([[  0.93783665, -43.694443  ]], dtype=float32)
time = 55265	action = 0	current_phase = 1	next_phase = 0	reward = 0.718335	array([[  0.9383068, -43.689087 ]], dtype=float32)
time = 55270	action = 0	current_phase = 1	next_phase = 0	reward = 0.447967	array([[  0.9083252, -43.528492 ]], dtype=float32)
time = 55275	action = 0	current_phase = 1	next_phase = 0	reward = 1.003951	array([[  0.92268753, -43.585358  ]], dtype=float32)
time = 55280	action = 0	current_phase = 1	next_phase = 0	reward = 0.719295	array([[  0.8396492, -43.24625  ]], dtype=float32)
time = 55285	action = 0	current_phase = 1	next_phase = 0	reward = 0.447905	array([[  0.92654324, -43.729874  ]], dtype=float32)
time = 55290	action = 0	current_phase = 1	next_phase = 0	reward = 1.007847	array([[  0.9038315, -43.486748 ]], dtype=float32)
time = 55295	action = 0	current_phase = 1	next_phase = 0	reward = 0.721634	array([[  0.9206991, -43.963345 ]], dtype=float32)
time = 55300	action = 0	current_phase = 1	next_phase = 0	reward = 0.726065	array([[  0.9292145, -43.71837  ]], dtype=float32)
time = 55305	action = 0	current_phase = 1	next_phase = 0	reward = 0.169224	array([[  0.9312601, -43.897457 ]], dtype=float32)
time = 55310	action = 0	current_phase = 1	next_phase = 0	reward = 1.283472	array([[  0.8772478, -43.49962  ]], dtype=float32)
time = 55315	action = 0	current_phase = 1	next_phase = 0	reward = 0.443418	array([[  0.7726984, -43.180786 ]], dtype=float32)
time = 55320	action = 0	current_phase = 1	next_phase = 0	reward = 0.986986	array([[  0.8832779, -43.522133 ]], dtype=float32)
time = 55325	action = 0	current_phase = 1	next_phase = 0	reward = 0.719047	array([[  0.90325165, -43.5089    ]], dtype=float32)
time = 55330	action = 0	current_phase = 1	next_phase = 0	reward = 0.436144	array([[  0.93320084, -43.721222  ]], dtype=float32)
time = 55335	action = 0	current_phase = 1	next_phase = 0	reward = 0.444508	array([[  0.91088104, -43.787437  ]], dtype=float32)
time = 55340	action = 0	current_phase = 1	next_phase = 0	reward = 1.284158	array([[  0.9225626, -43.677567 ]], dtype=float32)
time = 55345	action = 0	current_phase = 1	next_phase = 0	reward = 0.722091	array([[  0.9446974, -43.81871  ]], dtype=float32)
time = 55350	action = 0	current_phase = 1	next_phase = 0	reward = 0.446761	array([[  0.92062473, -43.61222   ]], dtype=float32)
time = 55355	action = 0	current_phase = 1	next_phase = 0	reward = 1.005989	array([[  0.91977406, -43.59767   ]], dtype=float32)
time = 55360	action = 0	current_phase = 1	next_phase = 0	reward = 0.719822	array([[  0.93847084, -43.857918  ]], dtype=float32)
time = 55365	action = 0	current_phase = 1	next_phase = 0	reward = 0.715609	array([[  0.8574219, -43.299313 ]], dtype=float32)
time = 55370	action = 0	current_phase = 1	next_phase = 0	reward = 0.717464	array([[  0.91604424, -43.50173   ]], dtype=float32)
time = 55375	action = 0	current_phase = 1	next_phase = 0	reward = 0.716892	array([[  0.91886044, -43.580666  ]], dtype=float32)
time = 55380	action = 0	current_phase = 1	next_phase = 0	reward = 0.441842	array([[  0.8959055, -43.50991  ]], dtype=float32)
time = 55385	action = 0	current_phase = 1	next_phase = 0	reward = 1.000362	array([[  0.9436016, -43.8787   ]], dtype=float32)
time = 55390	action = 0	current_phase = 1	next_phase = 0	reward = 0.720488	array([[  0.9345856, -43.75118  ]], dtype=float32)
time = 55395	action = 0	current_phase = 1	next_phase = 0	reward = 0.453209	array([[  0.9386015, -43.70159  ]], dtype=float32)
time = 55400	action = 0	current_phase = 1	next_phase = 0	reward = 1.009739	array([[  0.9283285, -43.89337  ]], dtype=float32)
time = 55405	action = 0	current_phase = 1	next_phase = 0	reward = 0.723233	array([[  0.89955616, -43.78472   ]], dtype=float32)
time = 55410	action = 0	current_phase = 1	next_phase = 0	reward = 0.721104	array([[  0.8932028, -43.413193 ]], dtype=float32)
time = 55415	action = 0	current_phase = 1	next_phase = 0	reward = 0.722397	array([[  0.85819817, -43.427032  ]], dtype=float32)
time = 55420	action = 0	current_phase = 1	next_phase = 0	reward = 0.721226	array([[  0.92615414, -43.79082   ]], dtype=float32)
time = 55425	action = 0	current_phase = 1	next_phase = 0	reward = 0.447794	array([[  0.9227762, -43.64386  ]], dtype=float32)
time = 55430	action = 0	current_phase = 1	next_phase = 0	reward = 1.018232	array([[  0.9328804, -43.766045 ]], dtype=float32)
time = 55435	action = 0	current_phase = 1	next_phase = 0	reward = 0.721855	array([[  0.832674, -43.200867]], dtype=float32)
time = 55440	action = 0	current_phase = 1	next_phase = 0	reward = 0.718445	array([[  0.9125252, -43.908638 ]], dtype=float32)
time = 55445	action = 0	current_phase = 1	next_phase = 0	reward = 0.719537	array([[  0.88251305, -43.544197  ]], dtype=float32)
time = 55450	action = 0	current_phase = 1	next_phase = 0	reward = 0.720645	array([[  0.9234257, -43.940643 ]], dtype=float32)
time = 55455	action = 0	current_phase = 1	next_phase = 0	reward = 0.722177	array([[  0.9352331, -43.79242  ]], dtype=float32)
time = 55460	action = 0	current_phase = 1	next_phase = 0	reward = 0.448015	array([[  0.9093008, -43.544724 ]], dtype=float32)
time = 55465	action = 0	current_phase = 1	next_phase = 0	reward = 1.004777	array([[  0.93776417, -43.747803  ]], dtype=float32)
time = 55470	action = 0	current_phase = 1	next_phase = 0	reward = 0.714230	array([[  0.9154787, -43.627148 ]], dtype=float32)
time = 55475	action = 0	current_phase = 1	next_phase = 0	reward = 0.717211	array([[  0.90858364, -43.76895   ]], dtype=float32)
time = 55480	action = 0	current_phase = 1	next_phase = 0	reward = 0.717191	array([[  0.91802216, -43.651676  ]], dtype=float32)
time = 55485	action = 0	current_phase = 1	next_phase = 0	reward = 0.712774	array([[  0.9183483, -43.659286 ]], dtype=float32)
time = 55490	action = 0	current_phase = 1	next_phase = 0	reward = 0.435635	array([[  0.8853264, -43.487125 ]], dtype=float32)
time = 55495	action = 0	current_phase = 1	next_phase = 0	reward = 0.723274	array([[  0.9326706, -43.636055 ]], dtype=float32)
time = 55500	action = 0	current_phase = 1	next_phase = 0	reward = 0.996129	array([[  0.9055643, -43.764797 ]], dtype=float32)
time = 55505	action = 0	current_phase = 1	next_phase = 0	reward = 0.715742	array([[  0.9327879, -43.86181  ]], dtype=float32)
time = 55510	action = 0	current_phase = 1	next_phase = 0	reward = 0.452807	array([[  0.93137836, -43.85946   ]], dtype=float32)
time = 55515	action = 0	current_phase = 1	next_phase = 0	reward = 1.004847	array([[  0.9243164, -43.708122 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 689.7268 - val_loss: 435.6996
Epoch 2/50
 - 4s - loss: 665.0760 - val_loss: 440.0285
Epoch 3/50
 - 4s - loss: 657.1629 - val_loss: 421.5139
Epoch 4/50
 - 4s - loss: 660.5953 - val_loss: 382.8278
Epoch 5/50
 - 4s - loss: 673.0005 - val_loss: 388.7286
Epoch 6/50
 - 4s - loss: 668.8090 - val_loss: 417.7448
Epoch 7/50
 - 4s - loss: 662.4796 - val_loss: 409.6886
Epoch 8/50
 - 4s - loss: 665.5515 - val_loss: 395.3107
Epoch 9/50
 - 4s - loss: 658.3724 - val_loss: 419.8286
Epoch 10/50
 - 4s - loss: 658.6227 - val_loss: 404.8361
Epoch 11/50
 - 4s - loss: 652.9644 - val_loss: 382.2696
Epoch 12/50
 - 4s - loss: 680.7409 - val_loss: 388.1242
Epoch 13/50
 - 4s - loss: 658.3574 - val_loss: 381.0278
Epoch 14/50
 - 4s - loss: 654.8557 - val_loss: 423.5672
Epoch 15/50
 - 4s - loss: 660.3996 - val_loss: 396.7013
Epoch 16/50
 - 4s - loss: 648.1656 - val_loss: 376.3733
Epoch 17/50
 - 4s - loss: 640.5356 - val_loss: 384.7892
Epoch 18/50
 - 4s - loss: 644.1652 - val_loss: 397.7443
Epoch 19/50
 - 4s - loss: 644.2353 - val_loss: 398.3348
Epoch 20/50
 - 4s - loss: 645.7645 - val_loss: 373.6817
Epoch 21/50
 - 4s - loss: 636.9494 - val_loss: 375.0674
Epoch 22/50
 - 4s - loss: 628.0942 - val_loss: 413.6697
Epoch 23/50
 - 4s - loss: 636.7915 - val_loss: 428.3537
Epoch 24/50
 - 4s - loss: 667.8170 - val_loss: 443.9189
Epoch 25/50
 - 4s - loss: 635.3513 - val_loss: 384.0876
Epoch 26/50
 - 4s - loss: 626.2994 - val_loss: 425.7477
Epoch 27/50
 - 4s - loss: 629.4800 - val_loss: 387.0503
Epoch 28/50
 - 4s - loss: 635.2027 - val_loss: 462.9012
Epoch 29/50
 - 4s - loss: 637.7368 - val_loss: 399.2934
Epoch 30/50
 - 4s - loss: 620.2045 - val_loss: 385.2163
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 55520	action = 0	current_phase = 1	next_phase = 0	reward = 0.723375	array([[  1.085844, -43.649773]], dtype=float32)
time = 55525	action = 0	current_phase = 1	next_phase = 0	reward = 0.719906	array([[  1.112443, -43.85472 ]], dtype=float32)
time = 55530	action = 0	current_phase = 1	next_phase = 0	reward = 0.720522	array([[  0.9942236, -43.742184 ]], dtype=float32)
time = 55535	action = 0	current_phase = 1	next_phase = 0	reward = 0.442476	array([[  1.1063471, -43.88102  ]], dtype=float32)
time = 55540	action = 0	current_phase = 1	next_phase = 0	reward = 1.006623	array([[  1.0421076, -43.69519  ]], dtype=float32)
time = 55545	action = 0	current_phase = 1	next_phase = 0	reward = 0.720851	array([[  1.1314135, -44.103382 ]], dtype=float32)
time = 55550	action = 0	current_phase = 1	next_phase = 0	reward = 0.717683	array([[  1.1292076, -44.071323 ]], dtype=float32)
time = 55555	action = 0	current_phase = 1	next_phase = 0	reward = 0.715466	array([[  1.1059895, -44.04841  ]], dtype=float32)
time = 55560	action = 0	current_phase = 1	next_phase = 0	reward = 0.440230	array([[  1.1107893, -43.894444 ]], dtype=float32)
time = 55565	action = 0	current_phase = 1	next_phase = 0	reward = 0.722611	array([[  1.1230793, -44.075317 ]], dtype=float32)
time = 55570	action = 0	current_phase = 1	next_phase = 0	reward = 1.006331	array([[  1.0789852, -43.87919  ]], dtype=float32)
time = 55575	action = 0	current_phase = 1	next_phase = 0	reward = 0.714790	array([[  1.0836077, -43.9429   ]], dtype=float32)
time = 55580	action = 0	current_phase = 1	next_phase = 0	reward = 0.446465	array([[  1.0959597, -43.92926  ]], dtype=float32)
time = 55585	action = 0	current_phase = 1	next_phase = 0	reward = 1.002971	array([[  1.0519791, -43.82293  ]], dtype=float32)
time = 55590	action = 0	current_phase = 1	next_phase = 0	reward = 0.726470	array([[  1.0273647, -43.597256 ]], dtype=float32)
time = 55595	action = 0	current_phase = 1	next_phase = 0	reward = 0.722252	array([[  1.1094799, -43.88495  ]], dtype=float32)
time = 55600	action = 0	current_phase = 1	next_phase = 0	reward = 0.719890	array([[  1.0253563, -43.767605 ]], dtype=float32)
time = 55605	action = 0	current_phase = 1	next_phase = 0	reward = 0.719928	array([[  1.0234871, -43.79458  ]], dtype=float32)
time = 55610	action = 0	current_phase = 1	next_phase = 0	reward = 0.722397	array([[  1.082284, -43.879505]], dtype=float32)
time = 55615	action = 0	current_phase = 1	next_phase = 0	reward = 0.444222	array([[  1.1181631, -43.882206 ]], dtype=float32)
time = 55620	action = 0	current_phase = 1	next_phase = 0	reward = 1.007346	array([[  1.1273441, -44.018703 ]], dtype=float32)
time = 55625	action = 0	current_phase = 1	next_phase = 0	reward = 0.721171	array([[  1.1168995, -43.840904 ]], dtype=float32)
time = 55630	action = 0	current_phase = 1	next_phase = 0	reward = 0.722450	array([[  1.0491562, -43.717766 ]], dtype=float32)
time = 55635	action = 0	current_phase = 1	next_phase = 0	reward = 0.726431	array([[  1.0960865, -44.09204  ]], dtype=float32)
time = 55640	action = 0	current_phase = 1	next_phase = 0	reward = 0.716362	array([[  1.1307411, -43.971737 ]], dtype=float32)
time = 55645	action = 0	current_phase = 1	next_phase = 0	reward = 0.714899	array([[  1.1268892, -43.960083 ]], dtype=float32)
time = 55650	action = 0	current_phase = 1	next_phase = 0	reward = 0.714250	array([[  1.1063099, -43.772007 ]], dtype=float32)
time = 55655	action = 0	current_phase = 1	next_phase = 0	reward = 0.443948	array([[  1.0856857, -43.95209  ]], dtype=float32)
time = 55660	action = 0	current_phase = 1	next_phase = 0	reward = 1.001819	array([[  1.1279631, -44.061615 ]], dtype=float32)
time = 55665	action = 0	current_phase = 1	next_phase = 0	reward = 0.448723	array([[  1.0724592, -43.639038 ]], dtype=float32)
time = 55670	action = 0	current_phase = 1	next_phase = 0	reward = 1.004940	array([[  1.1179705, -44.123066 ]], dtype=float32)
time = 55675	action = 0	current_phase = 1	next_phase = 0	reward = 0.168607	array([[  1.114994, -44.149746]], dtype=float32)
time = 55680	action = 0	current_phase = 1	next_phase = 0	reward = 1.283596	array([[  1.0703602, -43.720314 ]], dtype=float32)
time = 55685	action = 0	current_phase = 1	next_phase = 0	reward = 0.717703	array([[  0.9907036, -43.80004  ]], dtype=float32)
time = 55690	action = 0	current_phase = 1	next_phase = 0	reward = 0.720267	array([[  1.1000748, -43.86222  ]], dtype=float32)
time = 55695	action = 0	current_phase = 1	next_phase = 0	reward = 0.726573	array([[  1.1375151, -44.042313 ]], dtype=float32)
time = 55700	action = 0	current_phase = 1	next_phase = 0	reward = 0.723428	array([[  1.1105003, -44.100037 ]], dtype=float32)
time = 55705	action = 0	current_phase = 1	next_phase = 0	reward = 0.722025	array([[  1.0692768, -43.715477 ]], dtype=float32)
time = 55710	action = 0	current_phase = 1	next_phase = 0	reward = 0.718272	array([[  1.0150595, -43.54068  ]], dtype=float32)
time = 55715	action = 0	current_phase = 1	next_phase = 0	reward = 0.723717	array([[  1.0569258, -44.101845 ]], dtype=float32)
time = 55720	action = 0	current_phase = 1	next_phase = 0	reward = 0.720225	array([[  1.1162081, -44.16427  ]], dtype=float32)
time = 55725	action = 0	current_phase = 1	next_phase = 0	reward = 0.730538	array([[  1.1287203, -43.97763  ]], dtype=float32)
time = 55730	action = 0	current_phase = 1	next_phase = 0	reward = 0.726084	array([[  1.0824146, -44.052547 ]], dtype=float32)
time = 55735	action = 0	current_phase = 1	next_phase = 0	reward = 0.726899	array([[  1.0901728, -43.85163  ]], dtype=float32)
time = 55740	action = 0	current_phase = 1	next_phase = 0	reward = 0.726124	array([[  1.1341114, -44.015057 ]], dtype=float32)
time = 55745	action = 0	current_phase = 1	next_phase = 0	reward = 0.721540	array([[  1.0890636, -43.87887  ]], dtype=float32)
time = 55750	action = 0	current_phase = 1	next_phase = 0	reward = 0.719325	array([[  1.071928, -43.923523]], dtype=float32)
time = 55755	action = 0	current_phase = 1	next_phase = 0	reward = 0.721631	array([[  1.094533, -43.770874]], dtype=float32)
time = 55760	action = 0	current_phase = 1	next_phase = 0	reward = 0.727690	array([[  1.1080084, -43.966515 ]], dtype=float32)
time = 55765	action = 0	current_phase = 1	next_phase = 0	reward = 0.718414	array([[  0.9984627, -43.580162 ]], dtype=float32)
time = 55770	action = 0	current_phase = 1	next_phase = 0	reward = 0.710292	array([[  1.1044416, -43.95128  ]], dtype=float32)
time = 55775	action = 0	current_phase = 1	next_phase = 0	reward = 0.444561	array([[  1.1296768, -44.071648 ]], dtype=float32)
time = 55780	action = 0	current_phase = 1	next_phase = 0	reward = 1.006806	array([[  1.0727863, -43.747902 ]], dtype=float32)
time = 55785	action = 0	current_phase = 1	next_phase = 0	reward = 0.719346	array([[  1.132266, -44.08075 ]], dtype=float32)
time = 55790	action = 0	current_phase = 1	next_phase = 0	reward = 0.714692	array([[  1.0980988, -43.755424 ]], dtype=float32)
time = 55795	action = 0	current_phase = 1	next_phase = 0	reward = 0.718414	array([[  1.0701771, -43.888844 ]], dtype=float32)
time = 55800	action = 0	current_phase = 1	next_phase = 0	reward = 0.715753	array([[  1.0862808, -43.841164 ]], dtype=float32)
time = 55805	action = 0	current_phase = 1	next_phase = 0	reward = 0.711068	array([[  1.0482016, -43.889137 ]], dtype=float32)
time = 55810	action = 0	current_phase = 1	next_phase = 0	reward = 0.439572	array([[  1.0570736, -43.94816  ]], dtype=float32)
time = 55815	action = 0	current_phase = 1	next_phase = 0	reward = 0.999290	array([[  1.119957, -44.00373 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 762.0044 - val_loss: 4823.8820
Epoch 2/50
 - 4s - loss: 721.8138 - val_loss: 4808.6575
Epoch 3/50
 - 4s - loss: 758.2536 - val_loss: 4816.9480
Epoch 4/50
 - 4s - loss: 721.1350 - val_loss: 4819.0600
Epoch 5/50
 - 4s - loss: 732.0400 - val_loss: 4878.3173
Epoch 6/50
 - 4s - loss: 734.5348 - val_loss: 4836.0670
Epoch 7/50
 - 4s - loss: 758.2879 - val_loss: 4873.8284
Epoch 8/50
 - 4s - loss: 735.2114 - val_loss: 4820.1829
Epoch 9/50
 - 4s - loss: 717.7881 - val_loss: 4805.7499
Epoch 10/50
 - 4s - loss: 721.0305 - val_loss: 4824.9299
Epoch 11/50
 - 4s - loss: 728.3634 - val_loss: 4792.6625
Epoch 12/50
 - 4s - loss: 715.0234 - val_loss: 4815.3992
Epoch 13/50
 - 4s - loss: 727.9074 - val_loss: 4881.7492
Epoch 14/50
 - 4s - loss: 709.5401 - val_loss: 4792.2804
Epoch 15/50
 - 4s - loss: 713.1229 - val_loss: 4806.2716
Epoch 16/50
 - 4s - loss: 705.3423 - val_loss: 4832.0822
Epoch 17/50
 - 4s - loss: 708.6953 - val_loss: 4813.2394
Epoch 18/50
 - 4s - loss: 701.5741 - val_loss: 4810.0512
Epoch 19/50
 - 4s - loss: 700.2885 - val_loss: 4828.4078
Epoch 20/50
 - 4s - loss: 711.8859 - val_loss: 4784.3421
Epoch 21/50
 - 4s - loss: 699.6349 - val_loss: 4810.6628
Epoch 22/50
 - 4s - loss: 707.6846 - val_loss: 4796.0044
Epoch 23/50
 - 4s - loss: 690.5941 - val_loss: 4788.0861
Epoch 24/50
 - 4s - loss: 704.3778 - val_loss: 4810.4901
Epoch 25/50
 - 4s - loss: 693.3895 - val_loss: 4798.3025
Epoch 26/50
 - 4s - loss: 697.7253 - val_loss: 4801.0153
Epoch 27/50
 - 4s - loss: 679.0804 - val_loss: 4868.3803
Epoch 28/50
 - 4s - loss: 723.1366 - val_loss: 4832.8699
Epoch 29/50
 - 4s - loss: 696.3324 - val_loss: 4835.6681
Epoch 30/50
 - 4s - loss: 709.9206 - val_loss: 4870.7181
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 55820	action = 0	current_phase = 1	next_phase = 0	reward = 0.719384	array([[  1.4099579, -43.67421  ]], dtype=float32)
time = 55825	action = 0	current_phase = 1	next_phase = 0	reward = 0.721767	array([[  1.4835997, -43.822468 ]], dtype=float32)
time = 55830	action = 0	current_phase = 1	next_phase = 0	reward = 0.440182	array([[  1.49403 , -43.930244]], dtype=float32)
time = 55835	action = 0	current_phase = 1	next_phase = 0	reward = 1.007389	array([[  1.5280848, -43.957275 ]], dtype=float32)
time = 55840	action = 0	current_phase = 1	next_phase = 0	reward = 0.721671	array([[  1.3827438, -43.52716  ]], dtype=float32)
time = 55845	action = 0	current_phase = 1	next_phase = 0	reward = 0.719572	array([[  1.5021486, -43.994186 ]], dtype=float32)
time = 55850	action = 0	current_phase = 1	next_phase = 0	reward = 0.717771	array([[  1.5402479, -44.024166 ]], dtype=float32)
time = 55855	action = 0	current_phase = 1	next_phase = 0	reward = 0.716393	array([[  1.5286903, -43.951454 ]], dtype=float32)
time = 55860	action = 0	current_phase = 1	next_phase = 0	reward = 0.716614	array([[  1.5221729, -44.060646 ]], dtype=float32)
time = 55865	action = 0	current_phase = 1	next_phase = 0	reward = 0.436935	array([[  1.5220671, -43.949383 ]], dtype=float32)
time = 55870	action = 0	current_phase = 1	next_phase = 0	reward = 1.012776	array([[  1.5089178, -43.941784 ]], dtype=float32)
time = 55875	action = 0	current_phase = 1	next_phase = 0	reward = 0.729121	array([[  1.524148, -43.951416]], dtype=float32)
time = 55880	action = 0	current_phase = 1	next_phase = 0	reward = 0.726712	array([[  1.5349092, -44.116974 ]], dtype=float32)
time = 55885	action = 0	current_phase = 1	next_phase = 0	reward = 0.715345	array([[  1.5019617, -43.797836 ]], dtype=float32)
time = 55890	action = 0	current_phase = 1	next_phase = 0	reward = 0.717763	array([[  1.5175962, -44.12786  ]], dtype=float32)
time = 55895	action = 0	current_phase = 1	next_phase = 0	reward = 0.711616	array([[  1.5209236, -44.153645 ]], dtype=float32)
time = 55900	action = 0	current_phase = 1	next_phase = 0	reward = 0.717576	array([[  1.5190401, -43.904797 ]], dtype=float32)
time = 55905	action = 0	current_phase = 1	next_phase = 0	reward = 0.717850	array([[  1.5034962, -43.949463 ]], dtype=float32)
time = 55910	action = 0	current_phase = 1	next_phase = 0	reward = 0.711129	array([[  1.3060532, -43.85504  ]], dtype=float32)
time = 55915	action = 0	current_phase = 1	next_phase = 0	reward = 0.720794	array([[  1.4486618, -43.62584  ]], dtype=float32)
time = 55920	action = 0	current_phase = 1	next_phase = 0	reward = 0.730104	array([[  1.4814539, -43.845634 ]], dtype=float32)
time = 55925	action = 0	current_phase = 1	next_phase = 0	reward = 0.725981	array([[  1.4918461, -43.93248  ]], dtype=float32)
time = 55930	action = 0	current_phase = 1	next_phase = 0	reward = 0.447567	array([[  1.5082245, -43.857994 ]], dtype=float32)
time = 55935	action = 0	current_phase = 1	next_phase = 0	reward = 1.007007	array([[  1.5393705, -44.08412  ]], dtype=float32)
time = 55940	action = 0	current_phase = 1	next_phase = 0	reward = 0.719680	array([[  1.4671707, -43.76999  ]], dtype=float32)
time = 55945	action = 0	current_phase = 1	next_phase = 0	reward = 0.717495	array([[  1.5050898, -43.915977 ]], dtype=float32)
time = 55950	action = 0	current_phase = 1	next_phase = 0	reward = 0.715905	array([[  1.4761972, -43.726257 ]], dtype=float32)
time = 55955	action = 0	current_phase = 1	next_phase = 0	reward = 0.714050	array([[  1.4999466, -44.11532  ]], dtype=float32)
time = 55960	action = 0	current_phase = 1	next_phase = 0	reward = 0.714808	array([[  1.4451427, -43.921978 ]], dtype=float32)
time = 55965	action = 0	current_phase = 1	next_phase = 0	reward = 0.444578	array([[  1.5137796, -43.874798 ]], dtype=float32)
time = 55970	action = 0	current_phase = 1	next_phase = 0	reward = 1.002348	array([[  1.5209599, -44.14278  ]], dtype=float32)
time = 55975	action = 0	current_phase = 1	next_phase = 0	reward = 0.446975	array([[  1.5162401, -44.06137  ]], dtype=float32)
time = 55980	action = 0	current_phase = 1	next_phase = 0	reward = 1.000128	array([[  1.4934378, -43.826515 ]], dtype=float32)
time = 55985	action = 0	current_phase = 1	next_phase = 0	reward = 0.716516	array([[  1.5124664, -44.09468  ]], dtype=float32)
time = 55990	action = 0	current_phase = 1	next_phase = 0	reward = 0.718263	array([[  1.4946442, -43.74562  ]], dtype=float32)
time = 55995	action = 0	current_phase = 1	next_phase = 0	reward = 0.719228	array([[  1.5019312, -43.79151  ]], dtype=float32)
time = 56000	action = 0	current_phase = 1	next_phase = 0	reward = 0.723702	array([[  1.5329504, -44.039505 ]], dtype=float32)
time = 56005	action = 0	current_phase = 1	next_phase = 0	reward = 0.720732	array([[  1.4110193, -43.729683 ]], dtype=float32)
time = 56010	action = 0	current_phase = 1	next_phase = 0	reward = 0.713903	array([[  1.5340185, -44.068    ]], dtype=float32)
time = 56015	action = 0	current_phase = 1	next_phase = 0	reward = 0.719757	array([[  1.4799471, -43.697803 ]], dtype=float32)
time = 56020	action = 0	current_phase = 1	next_phase = 0	reward = 0.718625	array([[  1.5260277, -44.001114 ]], dtype=float32)
time = 56025	action = 0	current_phase = 1	next_phase = 0	reward = 0.437513	array([[  1.2788944, -43.629135 ]], dtype=float32)
time = 56030	action = 0	current_phase = 1	next_phase = 0	reward = 1.009928	array([[  1.5011969, -43.834938 ]], dtype=float32)
time = 56035	action = 0	current_phase = 1	next_phase = 0	reward = 0.440115	array([[  1.5005503, -43.826675 ]], dtype=float32)
time = 56040	action = 0	current_phase = 1	next_phase = 0	reward = 0.717342	array([[  1.4732018, -43.939228 ]], dtype=float32)
time = 56045	action = 0	current_phase = 1	next_phase = 0	reward = 0.997413	array([[  1.5081043, -43.887894 ]], dtype=float32)
time = 56050	action = 0	current_phase = 1	next_phase = 0	reward = 0.715574	array([[  1.5052795, -44.15435  ]], dtype=float32)
time = 56055	action = 0	current_phase = 1	next_phase = 0	reward = 0.721971	array([[  1.5355396, -44.048325 ]], dtype=float32)
time = 56060	action = 0	current_phase = 1	next_phase = 0	reward = 0.437723	array([[  1.4790564, -43.873608 ]], dtype=float32)
time = 56065	action = 0	current_phase = 1	next_phase = 0	reward = 0.722556	array([[  1.5285873, -44.003616 ]], dtype=float32)
time = 56070	action = 0	current_phase = 1	next_phase = 0	reward = 1.007916	array([[  1.4745169, -43.75286  ]], dtype=float32)
time = 56075	action = 0	current_phase = 1	next_phase = 0	reward = 0.734680	array([[  1.5171242, -44.009914 ]], dtype=float32)
time = 56080	action = 0	current_phase = 1	next_phase = 0	reward = 0.721346	array([[  1.454133, -43.635696]], dtype=float32)
time = 56085	action = 0	current_phase = 1	next_phase = 0	reward = 0.725053	array([[  1.4540396, -43.93231  ]], dtype=float32)
time = 56090	action = 0	current_phase = 1	next_phase = 0	reward = 0.440166	array([[  1.5100441, -44.059273 ]], dtype=float32)
time = 56095	action = 0	current_phase = 1	next_phase = 0	reward = 1.000621	array([[  1.4420872, -43.708878 ]], dtype=float32)
time = 56100	action = 0	current_phase = 1	next_phase = 0	reward = 0.715313	array([[  1.465539, -44.02497 ]], dtype=float32)
time = 56105	action = 0	current_phase = 1	next_phase = 0	reward = 0.717354	array([[  1.5267448, -43.90793  ]], dtype=float32)
time = 56110	action = 0	current_phase = 1	next_phase = 0	reward = 0.433704	array([[  1.3241978, -43.705853 ]], dtype=float32)
time = 56115	action = 0	current_phase = 1	next_phase = 0	reward = 0.723461	array([[  1.5185986, -43.878586 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2555.7205 - val_loss: 358.3977
Epoch 2/50
 - 4s - loss: 2555.5992 - val_loss: 299.3675
Epoch 3/50
 - 4s - loss: 2520.9764 - val_loss: 306.7697
Epoch 4/50
 - 4s - loss: 2515.1948 - val_loss: 273.9857
Epoch 5/50
 - 4s - loss: 2577.1390 - val_loss: 355.7178
Epoch 6/50
 - 4s - loss: 2508.4643 - val_loss: 287.9243
Epoch 7/50
 - 4s - loss: 2511.7541 - val_loss: 299.9902
Epoch 8/50
 - 4s - loss: 2549.1699 - val_loss: 323.5756
Epoch 9/50
 - 4s - loss: 2518.7835 - val_loss: 305.1026
Epoch 10/50
 - 4s - loss: 2525.1261 - val_loss: 321.8215
Epoch 11/50
 - 4s - loss: 2530.4851 - val_loss: 308.0064
Epoch 12/50
 - 4s - loss: 2520.6725 - val_loss: 320.1696
Epoch 13/50
 - 4s - loss: 2519.7858 - val_loss: 292.2265
Epoch 14/50
 - 4s - loss: 2517.0013 - val_loss: 385.5769
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 56120	action = 0	current_phase = 1	next_phase = 0	reward = 1.004484	array([[  1.5411568, -43.73897  ]], dtype=float32)
time = 56125	action = 0	current_phase = 1	next_phase = 0	reward = 0.720353	array([[  1.7197313, -44.29731  ]], dtype=float32)
time = 56130	action = 0	current_phase = 1	next_phase = 0	reward = 0.718966	array([[  1.5539656, -43.737843 ]], dtype=float32)
time = 56135	action = 0	current_phase = 1	next_phase = 0	reward = 0.711484	array([[  1.6143732, -44.049026 ]], dtype=float32)
time = 56140	action = 0	current_phase = 1	next_phase = 0	reward = 0.721145	array([[  1.6119137, -43.897316 ]], dtype=float32)
time = 56145	action = 0	current_phase = 1	next_phase = 0	reward = 0.724930	array([[  1.5163002, -43.727715 ]], dtype=float32)
time = 56150	action = 0	current_phase = 1	next_phase = 0	reward = 0.715144	array([[  1.641881, -44.0103  ]], dtype=float32)
time = 56155	action = 0	current_phase = 1	next_phase = 0	reward = 0.716773	array([[  1.7253551, -44.356842 ]], dtype=float32)
time = 56160	action = 0	current_phase = 1	next_phase = 0	reward = 0.727251	array([[  1.6108027, -43.887783 ]], dtype=float32)
time = 56165	action = 0	current_phase = 1	next_phase = 0	reward = 0.722189	array([[  1.5919971, -43.832726 ]], dtype=float32)
time = 56170	action = 0	current_phase = 1	next_phase = 0	reward = 0.722334	array([[  1.5224972, -43.68625  ]], dtype=float32)
time = 56175	action = 0	current_phase = 1	next_phase = 0	reward = 0.720111	array([[  1.5192909, -43.699013 ]], dtype=float32)
time = 56180	action = 0	current_phase = 1	next_phase = 0	reward = 0.724441	array([[  1.6250162, -43.92479  ]], dtype=float32)
time = 56185	action = 0	current_phase = 1	next_phase = 0	reward = 0.729728	array([[  1.6196356, -43.974594 ]], dtype=float32)
time = 56190	action = 0	current_phase = 1	next_phase = 0	reward = 0.445981	array([[  1.6174707, -43.921524 ]], dtype=float32)
time = 56195	action = 0	current_phase = 1	next_phase = 0	reward = 1.007418	array([[  1.6291981, -43.94167  ]], dtype=float32)
time = 56200	action = 0	current_phase = 1	next_phase = 0	reward = 0.723677	array([[  1.6628666, -44.0543   ]], dtype=float32)
time = 56205	action = 0	current_phase = 1	next_phase = 0	reward = 0.722064	array([[  1.4822035, -43.600334 ]], dtype=float32)
time = 56210	action = 0	current_phase = 1	next_phase = 0	reward = 0.722065	array([[  1.5446615, -43.76989  ]], dtype=float32)
time = 56215	action = 0	current_phase = 1	next_phase = 0	reward = 0.720477	array([[  1.6674957, -44.07985  ]], dtype=float32)
time = 56220	action = 0	current_phase = 1	next_phase = 0	reward = 0.714927	array([[  1.5662861, -43.79588  ]], dtype=float32)
time = 56225	action = 0	current_phase = 1	next_phase = 0	reward = 0.436585	array([[  1.6243086, -43.965668 ]], dtype=float32)
time = 56230	action = 0	current_phase = 1	next_phase = 0	reward = 1.000251	array([[  1.6870527, -44.147926 ]], dtype=float32)
time = 56235	action = 0	current_phase = 1	next_phase = 0	reward = 0.162420	array([[  1.7031546, -44.227177 ]], dtype=float32)
time = 56240	action = 0	current_phase = 1	next_phase = 0	reward = 1.015237	array([[  1.631794, -43.962536]], dtype=float32)
time = 56245	action = 0	current_phase = 1	next_phase = 0	reward = 1.003869	array([[  1.5634413, -43.843582 ]], dtype=float32)
time = 56250	action = 0	current_phase = 1	next_phase = 0	reward = 0.717640	array([[  1.6573124, -44.07421  ]], dtype=float32)
time = 56255	action = 0	current_phase = 1	next_phase = 0	reward = 0.719015	array([[  1.6127605, -43.904716 ]], dtype=float32)
time = 56260	action = 0	current_phase = 1	next_phase = 0	reward = 0.444196	array([[  1.6223192, -43.936443 ]], dtype=float32)
time = 56265	action = 0	current_phase = 1	next_phase = 0	reward = 1.000065	array([[  1.4687595, -43.6505   ]], dtype=float32)
time = 56270	action = 0	current_phase = 1	next_phase = 0	reward = 0.441128	array([[  1.6048193, -43.873764 ]], dtype=float32)
time = 56275	action = 0	current_phase = 1	next_phase = 0	reward = 0.726070	array([[  1.5863457, -43.832268 ]], dtype=float32)
time = 56280	action = 0	current_phase = 1	next_phase = 0	reward = 1.002019	array([[  1.5826588, -43.85777  ]], dtype=float32)
time = 56285	action = 0	current_phase = 1	next_phase = 0	reward = 0.717090	array([[  1.5279636, -43.68531  ]], dtype=float32)
time = 56290	action = 0	current_phase = 1	next_phase = 0	reward = 0.716234	array([[  1.5703316, -43.862026 ]], dtype=float32)
time = 56295	action = 0	current_phase = 1	next_phase = 0	reward = 0.723930	array([[  1.6258554, -43.932747 ]], dtype=float32)
time = 56300	action = 0	current_phase = 1	next_phase = 0	reward = 0.716828	array([[  1.556469, -43.76194 ]], dtype=float32)
time = 56305	action = 0	current_phase = 1	next_phase = 0	reward = 0.716977	array([[  1.580348, -43.817673]], dtype=float32)
time = 56310	action = 0	current_phase = 1	next_phase = 0	reward = 0.718056	array([[  1.6630421, -44.09675  ]], dtype=float32)
time = 56315	action = 0	current_phase = 1	next_phase = 0	reward = 0.443013	array([[  1.5476809, -43.736366 ]], dtype=float32)
time = 56320	action = 0	current_phase = 1	next_phase = 0	reward = 1.010224	array([[  1.6886768, -44.1593   ]], dtype=float32)
time = 56325	action = 0	current_phase = 1	next_phase = 0	reward = 0.721782	array([[  1.6480398, -44.0027   ]], dtype=float32)
time = 56330	action = 0	current_phase = 1	next_phase = 0	reward = 0.712651	array([[  1.5215101, -43.673325 ]], dtype=float32)
time = 56335	action = 0	current_phase = 1	next_phase = 0	reward = 0.721019	array([[  1.5305643, -43.70101  ]], dtype=float32)
time = 56340	action = 0	current_phase = 1	next_phase = 0	reward = 0.716954	array([[  1.548811, -43.76043 ]], dtype=float32)
time = 56345	action = 0	current_phase = 1	next_phase = 0	reward = 0.718462	array([[  1.5871763, -43.8724   ]], dtype=float32)
time = 56350	action = 0	current_phase = 1	next_phase = 0	reward = 0.442190	array([[  1.6952124, -44.25035  ]], dtype=float32)
time = 56355	action = 0	current_phase = 1	next_phase = 0	reward = 0.999910	array([[  1.5827723, -43.828476 ]], dtype=float32)
time = 56360	action = 0	current_phase = 1	next_phase = 0	reward = 0.434114	array([[  1.5052824, -43.644375 ]], dtype=float32)
time = 56365	action = 0	current_phase = 1	next_phase = 0	reward = 0.714313	array([[  1.6158438, -43.922005 ]], dtype=float32)
time = 56370	action = 0	current_phase = 1	next_phase = 0	reward = 0.740129	array([[  1.6216574, -43.932182 ]], dtype=float32)
time = 56375	action = 0	current_phase = 1	next_phase = 0	reward = 1.003386	array([[  1.435709, -43.44504 ]], dtype=float32)
time = 56380	action = 0	current_phase = 1	next_phase = 0	reward = 0.718276	array([[  1.5143661, -43.693054 ]], dtype=float32)
time = 56385	action = 0	current_phase = 1	next_phase = 0	reward = 0.721347	array([[  1.5809288, -43.817463 ]], dtype=float32)
time = 56390	action = 0	current_phase = 1	next_phase = 0	reward = 0.720226	array([[  1.5406752, -43.785988 ]], dtype=float32)
time = 56395	action = 0	current_phase = 1	next_phase = 0	reward = 0.728539	array([[  1.681716, -44.157444]], dtype=float32)
time = 56400	action = 0	current_phase = 1	next_phase = 0	reward = 0.721322	array([[  1.6093998, -43.910282 ]], dtype=float32)
time = 56405	action = 0	current_phase = 1	next_phase = 0	reward = 0.715239	array([[  1.6969652, -44.186874 ]], dtype=float32)
time = 56410	action = 0	current_phase = 1	next_phase = 0	reward = 0.709984	array([[  1.7020769, -44.223145 ]], dtype=float32)
time = 56415	action = 0	current_phase = 1	next_phase = 0	reward = 0.450749	array([[  1.6476412, -44.00007  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 553.1448 - val_loss: 696.7392
Epoch 2/50
 - 4s - loss: 579.8269 - val_loss: 696.7659
Epoch 3/50
 - 4s - loss: 576.8261 - val_loss: 699.4915
Epoch 4/50
 - 4s - loss: 602.5278 - val_loss: 698.5222
Epoch 5/50
 - 4s - loss: 571.9338 - val_loss: 700.4728
Epoch 6/50
 - 4s - loss: 531.7650 - val_loss: 714.3864
Epoch 7/50
 - 4s - loss: 570.9055 - val_loss: 718.6466
Epoch 8/50
 - 4s - loss: 545.0087 - val_loss: 709.6691
Epoch 9/50
 - 4s - loss: 551.6939 - val_loss: 705.2411
Epoch 10/50
 - 4s - loss: 534.3160 - val_loss: 719.4524
Epoch 11/50
 - 4s - loss: 582.3460 - val_loss: 716.3055
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 56420	action = 0	current_phase = 1	next_phase = 0	reward = 1.000573	array([[  1.5938606, -44.167755 ]], dtype=float32)
time = 56425	action = 0	current_phase = 1	next_phase = 0	reward = 0.723485	array([[  1.5001764, -43.82888  ]], dtype=float32)
time = 56430	action = 0	current_phase = 1	next_phase = 0	reward = 0.720258	array([[  1.5731268, -44.01963  ]], dtype=float32)
time = 56435	action = 0	current_phase = 1	next_phase = 0	reward = 0.715017	array([[  1.5434256, -43.954987 ]], dtype=float32)
time = 56440	action = 0	current_phase = 1	next_phase = 0	reward = 0.437690	array([[  1.2442875, -43.400078 ]], dtype=float32)
time = 56445	action = 0	current_phase = 1	next_phase = 0	reward = 0.999434	array([[  1.5177479, -43.84879  ]], dtype=float32)
time = 56450	action = 0	current_phase = 1	next_phase = 0	reward = 0.717105	array([[  1.5212364, -43.84286  ]], dtype=float32)
time = 56455	action = 0	current_phase = 1	next_phase = 0	reward = 0.718233	array([[  1.5331726, -43.856735 ]], dtype=float32)
time = 56460	action = 0	current_phase = 1	next_phase = 0	reward = 0.449860	array([[  1.590539, -44.219257]], dtype=float32)
time = 56465	action = 0	current_phase = 1	next_phase = 0	reward = 1.006443	array([[  1.4962645, -43.778786 ]], dtype=float32)
time = 56470	action = 0	current_phase = 1	next_phase = 0	reward = 0.726105	array([[  1.5720596, -44.05519  ]], dtype=float32)
time = 56475	action = 0	current_phase = 1	next_phase = 0	reward = 0.721031	array([[  1.2948294, -43.301826 ]], dtype=float32)
time = 56480	action = 0	current_phase = 1	next_phase = 0	reward = 0.426402	array([[  1.5625076, -43.99801  ]], dtype=float32)
time = 56485	action = 0	current_phase = 1	next_phase = 0	reward = 0.994494	array([[  1.4119568, -43.52658  ]], dtype=float32)
time = 56490	action = 0	current_phase = 1	next_phase = 0	reward = 0.717906	array([[  1.5277348, -43.882393 ]], dtype=float32)
time = 56495	action = 0	current_phase = 1	next_phase = 0	reward = 0.717099	array([[  1.5139103, -43.80703  ]], dtype=float32)
time = 56500	action = 0	current_phase = 1	next_phase = 0	reward = 0.720899	array([[  1.5678959, -44.01004  ]], dtype=float32)
time = 56505	action = 0	current_phase = 1	next_phase = 0	reward = 0.439738	array([[  1.5455284, -43.91574  ]], dtype=float32)
time = 56510	action = 0	current_phase = 1	next_phase = 0	reward = 1.003069	array([[  1.5737257, -44.070816 ]], dtype=float32)
time = 56515	action = 0	current_phase = 1	next_phase = 0	reward = 0.446282	array([[  1.5090828, -43.91754  ]], dtype=float32)
time = 56520	action = 0	current_phase = 1	next_phase = 0	reward = 1.006592	array([[  1.5864182, -44.153988 ]], dtype=float32)
time = 56525	action = 0	current_phase = 1	next_phase = 0	reward = 0.725156	array([[  1.5586653, -43.957718 ]], dtype=float32)
time = 56530	action = 0	current_phase = 1	next_phase = 0	reward = 0.445236	array([[  1.5185375, -43.837936 ]], dtype=float32)
time = 56535	action = 0	current_phase = 1	next_phase = 0	reward = 0.999186	array([[  1.4990463, -43.869804 ]], dtype=float32)
time = 56540	action = 0	current_phase = 1	next_phase = 0	reward = 0.722974	array([[  1.5436687, -43.920773 ]], dtype=float32)
time = 56545	action = 0	current_phase = 1	next_phase = 0	reward = 0.721873	array([[  1.486311, -43.72828 ]], dtype=float32)
time = 56550	action = 0	current_phase = 1	next_phase = 0	reward = 0.710565	array([[  1.4897451, -43.756645 ]], dtype=float32)
time = 56555	action = 0	current_phase = 1	next_phase = 0	reward = 0.713123	array([[  1.531621, -43.883472]], dtype=float32)
time = 56560	action = 0	current_phase = 1	next_phase = 0	reward = 0.439810	array([[  1.59799 , -44.173477]], dtype=float32)
time = 56565	action = 0	current_phase = 1	next_phase = 0	reward = 0.731290	array([[  1.4949512, -43.75602  ]], dtype=float32)
time = 56570	action = 0	current_phase = 1	next_phase = 0	reward = 0.723141	array([[  1.5005102, -43.75486  ]], dtype=float32)
time = 56575	action = 0	current_phase = 1	next_phase = 0	reward = 1.000221	array([[  1.5223274, -43.896065 ]], dtype=float32)
time = 56580	action = 0	current_phase = 1	next_phase = 0	reward = 0.718167	array([[  1.5831165, -44.11197  ]], dtype=float32)
time = 56585	action = 0	current_phase = 1	next_phase = 0	reward = 0.440932	array([[  1.5219564, -43.854504 ]], dtype=float32)
time = 56590	action = 0	current_phase = 1	next_phase = 0	reward = 0.729294	array([[  1.5269184, -43.87091  ]], dtype=float32)
time = 56595	action = 0	current_phase = 1	next_phase = 0	reward = 1.004934	array([[  1.5515928, -43.954895 ]], dtype=float32)
time = 56600	action = 0	current_phase = 1	next_phase = 0	reward = 0.712583	array([[  1.5301876, -43.85905  ]], dtype=float32)
time = 56605	action = 0	current_phase = 1	next_phase = 0	reward = 0.721995	array([[  1.5557442, -43.953213 ]], dtype=float32)
time = 56610	action = 0	current_phase = 1	next_phase = 0	reward = 0.436917	array([[  1.5473061, -43.951267 ]], dtype=float32)
time = 56615	action = 0	current_phase = 1	next_phase = 0	reward = 0.720410	array([[  1.5086613, -43.77459  ]], dtype=float32)
time = 56620	action = 0	current_phase = 1	next_phase = 0	reward = 0.728950	array([[  1.4002724, -43.481495 ]], dtype=float32)
time = 56625	action = 0	current_phase = 1	next_phase = 0	reward = 0.723581	array([[  1.460329, -43.64857 ]], dtype=float32)
time = 56630	action = 0	current_phase = 1	next_phase = 0	reward = 0.996641	array([[  1.4975061, -43.757645 ]], dtype=float32)
time = 56635	action = 0	current_phase = 1	next_phase = 0	reward = 0.718945	array([[  1.5648451, -44.06494  ]], dtype=float32)
time = 56640	action = 0	current_phase = 1	next_phase = 0	reward = 0.453127	array([[  1.5147295, -43.958897 ]], dtype=float32)
time = 56645	action = 0	current_phase = 1	next_phase = 0	reward = 0.725784	array([[  1.481843, -43.71741 ]], dtype=float32)
time = 56650	action = 0	current_phase = 1	next_phase = 0	reward = 0.726785	array([[  1.5920935, -44.16443  ]], dtype=float32)
time = 56655	action = 0	current_phase = 1	next_phase = 0	reward = 1.005342	array([[  1.5800285, -44.067165 ]], dtype=float32)
time = 56660	action = 0	current_phase = 1	next_phase = 0	reward = 0.719339	array([[  1.464551, -43.68139 ]], dtype=float32)
time = 56665	action = 0	current_phase = 1	next_phase = 0	reward = 0.444137	array([[  1.5867252, -44.13305  ]], dtype=float32)
time = 56670	action = 0	current_phase = 1	next_phase = 0	reward = 0.716220	array([[  1.5495815, -43.940422 ]], dtype=float32)
time = 56675	action = 0	current_phase = 1	next_phase = 0	reward = 0.995459	array([[  1.5599127, -43.998894 ]], dtype=float32)
time = 56680	action = 0	current_phase = 1	next_phase = 0	reward = 0.441681	array([[  1.5763226, -44.052883 ]], dtype=float32)
time = 56685	action = 0	current_phase = 1	next_phase = 0	reward = 1.010028	array([[  1.5338974, -43.931282 ]], dtype=float32)
time = 56690	action = 0	current_phase = 1	next_phase = 0	reward = 0.727096	array([[  1.5637035, -44.068436 ]], dtype=float32)
time = 56695	action = 0	current_phase = 1	next_phase = 0	reward = 0.729766	array([[  1.5538416, -43.958694 ]], dtype=float32)
time = 56700	action = 0	current_phase = 1	next_phase = 0	reward = 0.728484	array([[  1.4003181, -43.56946  ]], dtype=float32)
time = 56705	action = 0	current_phase = 1	next_phase = 0	reward = 0.718840	array([[  1.5793409, -44.119053 ]], dtype=float32)
time = 56710	action = 0	current_phase = 1	next_phase = 0	reward = 0.702979	array([[  1.4775772, -43.782547 ]], dtype=float32)
time = 56715	action = 0	current_phase = 1	next_phase = 0	reward = 0.715092	array([[  1.5862322, -44.127357 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 502.5010 - val_loss: 5143.7250
Epoch 2/50
 - 4s - loss: 517.9751 - val_loss: 5108.2181
Epoch 3/50
 - 4s - loss: 523.2865 - val_loss: 5092.1612
Epoch 4/50
 - 4s - loss: 514.8860 - val_loss: 5108.8254
Epoch 5/50
 - 4s - loss: 498.1994 - val_loss: 5157.3053
Epoch 6/50
 - 4s - loss: 491.6166 - val_loss: 5100.6196
Epoch 7/50
 - 4s - loss: 483.4905 - val_loss: 5101.6201
Epoch 8/50
 - 4s - loss: 499.2234 - val_loss: 5094.4096
Epoch 9/50
 - 4s - loss: 495.1928 - val_loss: 5122.0871
Epoch 10/50
 - 4s - loss: 480.3248 - val_loss: 5111.0585
Epoch 11/50
 - 4s - loss: 500.4796 - val_loss: 5093.9032
Epoch 12/50
 - 4s - loss: 490.8966 - val_loss: 5129.6611
Epoch 13/50
 - 4s - loss: 496.9447 - val_loss: 5087.2721
Epoch 14/50
 - 4s - loss: 488.1657 - val_loss: 5101.4831
Epoch 15/50
 - 4s - loss: 473.1952 - val_loss: 5189.4016
Epoch 16/50
 - 4s - loss: 485.3700 - val_loss: 5128.5466
Epoch 17/50
 - 4s - loss: 501.1628 - val_loss: 5076.1385
Epoch 18/50
 - 4s - loss: 479.9766 - val_loss: 5113.0029
Epoch 19/50
 - 4s - loss: 500.8355 - val_loss: 5134.5895
Epoch 20/50
 - 4s - loss: 490.7369 - val_loss: 5073.4209
Epoch 21/50
 - 4s - loss: 472.1039 - val_loss: 5080.6734
Epoch 22/50
 - 4s - loss: 502.9319 - val_loss: 5094.2388
Epoch 23/50
 - 4s - loss: 488.9218 - val_loss: 5080.6544
Epoch 24/50
 - 4s - loss: 466.6712 - val_loss: 5072.2833
Epoch 25/50
 - 4s - loss: 464.8466 - val_loss: 5138.7422
Epoch 26/50
 - 4s - loss: 466.5306 - val_loss: 5084.3373
Epoch 27/50
 - 4s - loss: 464.2242 - val_loss: 5123.7198
Epoch 28/50
 - 4s - loss: 455.6845 - val_loss: 5061.6755
Epoch 29/50
 - 4s - loss: 462.4557 - val_loss: 5085.9379
Epoch 30/50
 - 4s - loss: 464.9952 - val_loss: 5091.9408
Epoch 31/50
 - 4s - loss: 501.5767 - val_loss: 5078.5517
Epoch 32/50
 - 4s - loss: 454.2007 - val_loss: 5085.3637
Epoch 33/50
 - 4s - loss: 499.8616 - val_loss: 5064.8481
Epoch 34/50
 - 4s - loss: 458.3811 - val_loss: 5142.5021
Epoch 35/50
 - 4s - loss: 457.0496 - val_loss: 5088.2526
Epoch 36/50
 - 4s - loss: 490.1857 - val_loss: 5061.3145
Epoch 37/50
 - 4s - loss: 459.5812 - val_loss: 5171.9050
Epoch 38/50
 - 4s - loss: 451.6441 - val_loss: 5084.5607
Epoch 39/50
 - 4s - loss: 449.9140 - val_loss: 5066.3684
Epoch 40/50
 - 4s - loss: 442.4267 - val_loss: 5086.7117
Epoch 41/50
 - 4s - loss: 471.6103 - val_loss: 5087.1929
Epoch 42/50
 - 4s - loss: 475.2907 - val_loss: 5183.2144
Epoch 43/50
 - 4s - loss: 442.7891 - val_loss: 5096.3859
Epoch 44/50
 - 4s - loss: 446.0846 - val_loss: 5191.7926
Epoch 45/50
 - 4s - loss: 454.1220 - val_loss: 5131.2098
Epoch 46/50
 - 4s - loss: 446.6705 - val_loss: 5085.6774
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 56720	action = 0	current_phase = 1	next_phase = 0	reward = 0.720136	array([[  1.4580221, -43.927788 ]], dtype=float32)
time = 56725	action = 0	current_phase = 1	next_phase = 0	reward = 0.444176	array([[  1.380147, -43.65138 ]], dtype=float32)
time = 56730	action = 0	current_phase = 1	next_phase = 0	reward = 1.004132	array([[  1.4610329, -43.975624 ]], dtype=float32)
time = 56735	action = 0	current_phase = 1	next_phase = 0	reward = 0.720452	array([[  1.467412, -44.108387]], dtype=float32)
time = 56740	action = 0	current_phase = 1	next_phase = 0	reward = 0.716275	array([[  1.4283905, -43.793938 ]], dtype=float32)
time = 56745	action = 0	current_phase = 1	next_phase = 0	reward = 0.715213	array([[  1.4404573, -43.867325 ]], dtype=float32)
time = 56750	action = 0	current_phase = 1	next_phase = 0	reward = 0.440512	array([[  1.4056864, -43.690758 ]], dtype=float32)
time = 56755	action = 0	current_phase = 1	next_phase = 0	reward = 0.725829	array([[  1.4634447, -43.917896 ]], dtype=float32)
time = 56760	action = 0	current_phase = 1	next_phase = 0	reward = 1.010418	array([[  1.4618597, -43.95453  ]], dtype=float32)
time = 56765	action = 0	current_phase = 1	next_phase = 0	reward = 0.724719	array([[  1.4703465, -44.009567 ]], dtype=float32)
time = 56770	action = 0	current_phase = 1	next_phase = 0	reward = 0.735307	array([[  1.3413372, -43.596703 ]], dtype=float32)
time = 56775	action = 0	current_phase = 1	next_phase = 0	reward = 0.715489	array([[  1.4164944, -43.739742 ]], dtype=float32)
time = 56780	action = 0	current_phase = 1	next_phase = 0	reward = 0.714338	array([[  1.4099283, -43.7165   ]], dtype=float32)
time = 56785	action = 0	current_phase = 1	next_phase = 0	reward = 0.439299	array([[  1.4593678, -43.89502  ]], dtype=float32)
time = 56790	action = 0	current_phase = 1	next_phase = 0	reward = 0.997744	array([[  1.4081478, -43.775196 ]], dtype=float32)
time = 56795	action = 0	current_phase = 1	next_phase = 0	reward = 0.716123	array([[  1.452364, -43.93992 ]], dtype=float32)
time = 56800	action = 0	current_phase = 1	next_phase = 0	reward = 0.447364	array([[  1.4552469, -43.936573 ]], dtype=float32)
time = 56805	action = 0	current_phase = 1	next_phase = 0	reward = 1.001938	array([[  1.3122873, -43.551582 ]], dtype=float32)
time = 56810	action = 0	current_phase = 1	next_phase = 0	reward = 0.719783	array([[  1.440279, -43.830605]], dtype=float32)
time = 56815	action = 0	current_phase = 1	next_phase = 0	reward = 0.721055	array([[  1.438385, -43.889126]], dtype=float32)
time = 56820	action = 0	current_phase = 1	next_phase = 0	reward = 0.721745	array([[  1.4282541, -43.862724 ]], dtype=float32)
time = 56825	action = 0	current_phase = 1	next_phase = 0	reward = 0.711794	array([[  1.4224157, -43.825188 ]], dtype=float32)
time = 56830	action = 0	current_phase = 1	next_phase = 0	reward = 0.718843	array([[  1.4571543, -43.93431  ]], dtype=float32)
time = 56835	action = 0	current_phase = 1	next_phase = 0	reward = 0.724238	array([[  1.3491821, -43.546562 ]], dtype=float32)
time = 56840	action = 0	current_phase = 1	next_phase = 0	reward = 0.731115	array([[  1.4263306, -43.783607 ]], dtype=float32)
time = 56845	action = 0	current_phase = 1	next_phase = 0	reward = 0.731020	array([[  1.3932676, -43.700012 ]], dtype=float32)
time = 56850	action = 0	current_phase = 1	next_phase = 0	reward = 0.724188	array([[  1.4447508, -43.83116  ]], dtype=float32)
time = 56855	action = 0	current_phase = 1	next_phase = 0	reward = 0.725136	array([[  1.4694033, -44.025978 ]], dtype=float32)
time = 56860	action = 0	current_phase = 1	next_phase = 0	reward = 0.726941	array([[  1.3548822, -43.638    ]], dtype=float32)
time = 56865	action = 0	current_phase = 1	next_phase = 0	reward = 0.713462	array([[  1.4654512, -43.933434 ]], dtype=float32)
time = 56870	action = 0	current_phase = 1	next_phase = 0	reward = 0.718627	array([[  1.4649858, -43.988716 ]], dtype=float32)
time = 56875	action = 0	current_phase = 1	next_phase = 0	reward = 0.719745	array([[  1.4195375, -43.76219  ]], dtype=float32)
time = 56880	action = 0	current_phase = 1	next_phase = 0	reward = 0.434570	array([[  1.4472618, -43.90502  ]], dtype=float32)
time = 56885	action = 0	current_phase = 1	next_phase = 0	reward = 0.722681	array([[  1.4434223, -43.87983  ]], dtype=float32)
time = 56890	action = 0	current_phase = 1	next_phase = 0	reward = 1.002919	array([[  1.4490108, -43.883644 ]], dtype=float32)
time = 56895	action = 0	current_phase = 1	next_phase = 0	reward = 0.721053	array([[  1.4736519, -44.01815  ]], dtype=float32)
time = 56900	action = 0	current_phase = 1	next_phase = 0	reward = 0.727706	array([[  1.4282494, -43.829117 ]], dtype=float32)
time = 56905	action = 0	current_phase = 1	next_phase = 0	reward = 0.725649	array([[  1.4333649, -43.823196 ]], dtype=float32)
time = 56910	action = 0	current_phase = 1	next_phase = 0	reward = 0.712040	array([[  1.466835, -43.952805]], dtype=float32)
time = 56915	action = 0	current_phase = 1	next_phase = 0	reward = 0.442955	array([[  1.415062, -43.82142 ]], dtype=float32)
time = 56920	action = 0	current_phase = 1	next_phase = 0	reward = 1.005032	array([[  1.4272776, -43.82386  ]], dtype=float32)
time = 56925	action = 0	current_phase = 1	next_phase = 0	reward = 0.728595	array([[  1.4603443, -44.013885 ]], dtype=float32)
time = 56930	action = 0	current_phase = 1	next_phase = 0	reward = 0.721961	array([[  1.331418, -43.56781 ]], dtype=float32)
time = 56935	action = 0	current_phase = 1	next_phase = 0	reward = 0.720055	array([[  1.422884, -43.81959 ]], dtype=float32)
time = 56940	action = 0	current_phase = 1	next_phase = 0	reward = 0.716119	array([[  1.4139996, -43.76049  ]], dtype=float32)
time = 56945	action = 0	current_phase = 1	next_phase = 0	reward = 0.714391	array([[  1.4294119, -43.826286 ]], dtype=float32)
time = 56950	action = 0	current_phase = 1	next_phase = 0	reward = 0.718130	array([[  1.4397087, -43.83525  ]], dtype=float32)
time = 56955	action = 0	current_phase = 1	next_phase = 0	reward = 0.437711	array([[  1.4193821, -43.727905 ]], dtype=float32)
time = 56960	action = 0	current_phase = 1	next_phase = 0	reward = 1.005755	array([[  1.4525032, -43.861984 ]], dtype=float32)
time = 56965	action = 0	current_phase = 1	next_phase = 0	reward = 0.715614	array([[  1.4183435, -43.77015  ]], dtype=float32)
time = 56970	action = 0	current_phase = 1	next_phase = 0	reward = 0.716350	array([[  1.4497223, -43.887936 ]], dtype=float32)
time = 56975	action = 0	current_phase = 1	next_phase = 0	reward = 0.722361	array([[  1.4166307, -43.73835  ]], dtype=float32)
time = 56980	action = 0	current_phase = 1	next_phase = 0	reward = 0.732867	array([[  1.4215393, -43.86093  ]], dtype=float32)
time = 56985	action = 0	current_phase = 1	next_phase = 0	reward = 0.731679	array([[  1.4378357, -43.816948 ]], dtype=float32)
time = 56990	action = 0	current_phase = 1	next_phase = 0	reward = 0.722439	array([[  1.4001427, -43.719643 ]], dtype=float32)
time = 56995	action = 0	current_phase = 1	next_phase = 0	reward = 0.720922	array([[  1.4406347, -43.846245 ]], dtype=float32)
time = 57000	action = 0	current_phase = 1	next_phase = 0	reward = 0.720156	array([[  1.4774399, -44.131184 ]], dtype=float32)
time = 57005	action = 0	current_phase = 1	next_phase = 0	reward = 0.722789	array([[  1.3885813, -43.684875 ]], dtype=float32)
time = 57010	action = 0	current_phase = 1	next_phase = 0	reward = 0.716543	array([[  1.3767643, -43.685993 ]], dtype=float32)
time = 57015	action = 0	current_phase = 1	next_phase = 0	reward = 0.719666	array([[  1.4699259, -44.025627 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2290.4963 - val_loss: 676.4423
Epoch 2/50
 - 4s - loss: 2296.8684 - val_loss: 641.5663
Epoch 3/50
 - 4s - loss: 2321.5066 - val_loss: 640.4239
Epoch 4/50
 - 4s - loss: 2262.7802 - val_loss: 633.1059
Epoch 5/50
 - 4s - loss: 2286.3798 - val_loss: 680.5413
Epoch 6/50
 - 4s - loss: 2258.0027 - val_loss: 644.3975
Epoch 7/50
 - 4s - loss: 2266.0248 - val_loss: 661.3132
Epoch 8/50
 - 4s - loss: 2248.5753 - val_loss: 630.8607
Epoch 9/50
 - 4s - loss: 2300.4738 - val_loss: 637.1998
Epoch 10/50
 - 4s - loss: 2272.9738 - val_loss: 578.4045
Epoch 11/50
 - 4s - loss: 2287.2519 - val_loss: 752.6675
Epoch 12/50
 - 4s - loss: 2254.2603 - val_loss: 651.3741
Epoch 13/50
 - 4s - loss: 2324.2813 - val_loss: 672.4762
Epoch 14/50
 - 4s - loss: 2239.7551 - val_loss: 587.8075
Epoch 15/50
 - 4s - loss: 2232.5002 - val_loss: 639.0132
Epoch 16/50
 - 4s - loss: 2229.5244 - val_loss: 641.6440
Epoch 17/50
 - 4s - loss: 2240.7388 - val_loss: 639.1785
Epoch 18/50
 - 4s - loss: 2303.7632 - val_loss: 621.1274
Epoch 19/50
 - 4s - loss: 2286.2859 - val_loss: 699.4826
Epoch 20/50
 - 4s - loss: 2279.1936 - val_loss: 647.7612
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 57020	action = 0	current_phase = 1	next_phase = 0	reward = 0.717923	array([[  1.5576544, -43.892044 ]], dtype=float32)
time = 57025	action = 0	current_phase = 1	next_phase = 0	reward = 0.714970	array([[  1.5678864, -43.942406 ]], dtype=float32)
time = 57030	action = 0	current_phase = 1	next_phase = 0	reward = 0.715397	array([[  1.5413637, -43.81989  ]], dtype=float32)
time = 57035	action = 0	current_phase = 1	next_phase = 0	reward = 0.723628	array([[  1.5551672, -43.8602   ]], dtype=float32)
time = 57040	action = 0	current_phase = 1	next_phase = 0	reward = 0.718430	array([[  1.4427023, -43.571144 ]], dtype=float32)
time = 57045	action = 0	current_phase = 1	next_phase = 0	reward = 0.441344	array([[  1.5809917, -44.02482  ]], dtype=float32)
time = 57050	action = 0	current_phase = 1	next_phase = 0	reward = 1.004616	array([[  1.5938711, -44.02382  ]], dtype=float32)
time = 57055	action = 0	current_phase = 1	next_phase = 0	reward = 0.719600	array([[  1.5463743, -43.83658  ]], dtype=float32)
time = 57060	action = 0	current_phase = 1	next_phase = 0	reward = 0.440571	array([[  1.4376993, -43.724236 ]], dtype=float32)
time = 57065	action = 0	current_phase = 1	next_phase = 0	reward = 0.718709	array([[  1.5118275, -43.843315 ]], dtype=float32)
time = 57070	action = 0	current_phase = 1	next_phase = 0	reward = 1.008880	array([[  1.5357838, -43.804142 ]], dtype=float32)
time = 57075	action = 0	current_phase = 1	next_phase = 0	reward = 0.719913	array([[  1.5306005, -43.769455 ]], dtype=float32)
time = 57080	action = 0	current_phase = 1	next_phase = 0	reward = 0.435728	array([[  1.6102858, -44.085777 ]], dtype=float32)
time = 57085	action = 0	current_phase = 1	next_phase = 0	reward = 0.721878	array([[  1.5880499, -44.002792 ]], dtype=float32)
time = 57090	action = 0	current_phase = 1	next_phase = 0	reward = 0.996085	array([[  1.4141264, -43.475822 ]], dtype=float32)
time = 57095	action = 0	current_phase = 1	next_phase = 0	reward = 0.164077	array([[  1.5808849, -43.971664 ]], dtype=float32)
time = 57100	action = 0	current_phase = 1	next_phase = 0	reward = 1.018486	array([[  1.5363369, -43.85709  ]], dtype=float32)
time = 57105	action = 0	current_phase = 1	next_phase = 0	reward = 1.003792	array([[  1.440484, -43.618263]], dtype=float32)
time = 57110	action = 0	current_phase = 1	next_phase = 0	reward = 0.723887	array([[  1.469243, -43.715492]], dtype=float32)
time = 57115	action = 0	current_phase = 1	next_phase = 0	reward = 0.446484	array([[  1.595334, -44.046097]], dtype=float32)
time = 57120	action = 0	current_phase = 1	next_phase = 0	reward = 0.999479	array([[  1.5581865, -43.87393  ]], dtype=float32)
time = 57125	action = 0	current_phase = 1	next_phase = 0	reward = 0.427646	array([[  1.5833006, -44.111877 ]], dtype=float32)
time = 57130	action = 0	current_phase = 1	next_phase = 0	reward = 1.007141	array([[  1.6038971, -44.046448 ]], dtype=float32)
time = 57135	action = 0	current_phase = 1	next_phase = 0	reward = 0.444991	array([[  1.5717268, -43.940025 ]], dtype=float32)
time = 57140	action = 0	current_phase = 1	next_phase = 0	reward = 0.725460	array([[  1.5995703, -44.055435 ]], dtype=float32)
time = 57145	action = 0	current_phase = 1	next_phase = 0	reward = 0.999734	array([[  1.5619545, -43.89789  ]], dtype=float32)
time = 57150	action = 0	current_phase = 1	next_phase = 0	reward = 0.722433	array([[  1.5069904, -43.74364  ]], dtype=float32)
time = 57155	action = 0	current_phase = 1	next_phase = 0	reward = 0.723928	array([[  1.4446325, -43.70291  ]], dtype=float32)
time = 57160	action = 0	current_phase = 1	next_phase = 0	reward = 0.720335	array([[  1.5026913, -43.72004  ]], dtype=float32)
time = 57165	action = 0	current_phase = 1	next_phase = 0	reward = 0.439984	array([[  1.5233212, -43.76808  ]], dtype=float32)
time = 57170	action = 0	current_phase = 1	next_phase = 0	reward = 0.994424	array([[  1.567359, -43.969406]], dtype=float32)
time = 57175	action = 0	current_phase = 1	next_phase = 0	reward = 0.444541	array([[  1.4946175, -43.77724  ]], dtype=float32)
time = 57180	action = 0	current_phase = 1	next_phase = 0	reward = 1.009238	array([[  1.5443792, -43.850574 ]], dtype=float32)
time = 57185	action = 0	current_phase = 1	next_phase = 0	reward = 0.719564	array([[  1.5317211, -43.826332 ]], dtype=float32)
time = 57190	action = 0	current_phase = 1	next_phase = 0	reward = 0.731951	array([[  1.5432272, -43.827873 ]], dtype=float32)
time = 57195	action = 0	current_phase = 1	next_phase = 0	reward = 0.718871	array([[  1.5987768, -44.05509  ]], dtype=float32)
time = 57200	action = 0	current_phase = 1	next_phase = 0	reward = 0.724325	array([[  1.6155844, -44.11642  ]], dtype=float32)
time = 57205	action = 0	current_phase = 1	next_phase = 0	reward = 0.719877	array([[  1.5890436, -44.03308  ]], dtype=float32)
time = 57210	action = 0	current_phase = 1	next_phase = 0	reward = 0.717791	array([[  1.5517893, -43.86248  ]], dtype=float32)
time = 57215	action = 0	current_phase = 1	next_phase = 0	reward = 0.438678	array([[  1.5855694, -44.082523 ]], dtype=float32)
time = 57220	action = 0	current_phase = 1	next_phase = 0	reward = 0.998554	array([[  1.5419617, -43.820484 ]], dtype=float32)
time = 57225	action = 0	current_phase = 1	next_phase = 0	reward = 0.719612	array([[  1.6035671, -44.093796 ]], dtype=float32)
time = 57230	action = 0	current_phase = 1	next_phase = 0	reward = 0.444200	array([[  1.5738821, -43.961067 ]], dtype=float32)
time = 57235	action = 0	current_phase = 1	next_phase = 0	reward = 0.731674	array([[  1.5706549, -43.91645  ]], dtype=float32)
time = 57240	action = 0	current_phase = 1	next_phase = 0	reward = 1.005855	array([[  1.5653477, -43.897205 ]], dtype=float32)
time = 57245	action = 0	current_phase = 1	next_phase = 0	reward = 0.716844	array([[  1.4617043, -43.796654 ]], dtype=float32)
time = 57250	action = 0	current_phase = 1	next_phase = 0	reward = 0.721640	array([[  1.5510798, -43.867126 ]], dtype=float32)
time = 57255	action = 0	current_phase = 1	next_phase = 0	reward = 0.448212	array([[  1.5586967, -43.891846 ]], dtype=float32)
time = 57260	action = 0	current_phase = 1	next_phase = 0	reward = 1.007659	array([[  1.5497541, -43.851246 ]], dtype=float32)
time = 57265	action = 0	current_phase = 1	next_phase = 0	reward = 0.716428	array([[  1.5925503, -44.015877 ]], dtype=float32)
time = 57270	action = 0	current_phase = 1	next_phase = 0	reward = 0.720951	array([[  1.5348864, -43.837452 ]], dtype=float32)
time = 57275	action = 0	current_phase = 1	next_phase = 0	reward = 0.453008	array([[  1.6228952, -44.22818  ]], dtype=float32)
time = 57280	action = 0	current_phase = 1	next_phase = 0	reward = 1.008193	array([[  1.588644, -43.980988]], dtype=float32)
time = 57285	action = 0	current_phase = 1	next_phase = 0	reward = 0.722247	array([[  1.5920153, -44.043636 ]], dtype=float32)
time = 57290	action = 0	current_phase = 1	next_phase = 0	reward = 0.715287	array([[  1.3603497, -43.535763 ]], dtype=float32)
time = 57295	action = 0	current_phase = 1	next_phase = 0	reward = 0.714562	array([[  1.6109791, -44.1462   ]], dtype=float32)
time = 57300	action = 0	current_phase = 1	next_phase = 0	reward = 0.720742	array([[  1.4367838, -43.632088 ]], dtype=float32)
time = 57305	action = 0	current_phase = 1	next_phase = 0	reward = 0.719777	array([[  1.6026525, -44.049118 ]], dtype=float32)
time = 57310	action = 0	current_phase = 1	next_phase = 0	reward = 0.446120	array([[  1.5247965, -43.806503 ]], dtype=float32)
time = 57315	action = 0	current_phase = 1	next_phase = 0	reward = 1.010229	array([[  1.5811443, -43.956406 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 647.4960 - val_loss: 752.2227
Epoch 2/50
 - 4s - loss: 698.9475 - val_loss: 752.7680
Epoch 3/50
 - 4s - loss: 617.5060 - val_loss: 742.8137
Epoch 4/50
 - 4s - loss: 612.4778 - val_loss: 728.6826
Epoch 5/50
 - 4s - loss: 618.9076 - val_loss: 736.0354
Epoch 6/50
 - 4s - loss: 586.2854 - val_loss: 738.7410
Epoch 7/50
 - 4s - loss: 601.1850 - val_loss: 725.9847
Epoch 8/50
 - 4s - loss: 592.9614 - val_loss: 732.6398
Epoch 9/50
 - 4s - loss: 609.4637 - val_loss: 726.7520
Epoch 10/50
 - 4s - loss: 599.2317 - val_loss: 750.8498
Epoch 11/50
 - 4s - loss: 593.6206 - val_loss: 731.0461
Epoch 12/50
 - 4s - loss: 617.2106 - val_loss: 730.0924
Epoch 13/50
 - 4s - loss: 593.1068 - val_loss: 765.0283
Epoch 14/50
 - 4s - loss: 597.6509 - val_loss: 737.8805
Epoch 15/50
 - 4s - loss: 602.4813 - val_loss: 736.1154
Epoch 16/50
 - 4s - loss: 572.6335 - val_loss: 716.4884
Epoch 17/50
 - 4s - loss: 593.4865 - val_loss: 726.7890
Epoch 18/50
 - 4s - loss: 599.6943 - val_loss: 723.7876
Epoch 19/50
 - 4s - loss: 560.3137 - val_loss: 702.9404
Epoch 20/50
 - 4s - loss: 562.1435 - val_loss: 716.5453
Epoch 21/50
 - 4s - loss: 628.2483 - val_loss: 730.6013
Epoch 22/50
 - 4s - loss: 544.2781 - val_loss: 703.2341
Epoch 23/50
 - 4s - loss: 598.3221 - val_loss: 700.1926
Epoch 24/50
 - 4s - loss: 558.8550 - val_loss: 695.5457
Epoch 25/50
 - 4s - loss: 617.2845 - val_loss: 700.6487
Epoch 26/50
 - 4s - loss: 549.9448 - val_loss: 692.4854
Epoch 27/50
 - 4s - loss: 591.5686 - val_loss: 708.7142
Epoch 28/50
 - 4s - loss: 578.5104 - val_loss: 704.4124
Epoch 29/50
 - 4s - loss: 575.7163 - val_loss: 709.0342
Epoch 30/50
 - 4s - loss: 567.8618 - val_loss: 695.0994
Epoch 31/50
 - 4s - loss: 543.2269 - val_loss: 689.1612
Epoch 32/50
 - 4s - loss: 568.9816 - val_loss: 707.8502
Epoch 33/50
 - 4s - loss: 540.7633 - val_loss: 692.3677
Epoch 34/50
 - 4s - loss: 612.7471 - val_loss: 696.5661
Epoch 35/50
 - 4s - loss: 545.7027 - val_loss: 709.2205
Epoch 36/50
 - 4s - loss: 544.2242 - val_loss: 718.8975
Epoch 37/50
 - 4s - loss: 555.9397 - val_loss: 712.5463
Epoch 38/50
 - 4s - loss: 566.9415 - val_loss: 683.7188
Epoch 39/50
 - 4s - loss: 593.8634 - val_loss: 703.4852
Epoch 40/50
 - 4s - loss: 552.0751 - val_loss: 688.3710
Epoch 41/50
 - 4s - loss: 559.0008 - val_loss: 683.8146
Epoch 42/50
 - 4s - loss: 524.5990 - val_loss: 715.1506
Epoch 43/50
 - 4s - loss: 540.0850 - val_loss: 681.5904
Epoch 44/50
 - 4s - loss: 545.9009 - val_loss: 682.3434
Epoch 45/50
 - 4s - loss: 571.0895 - val_loss: 685.9418
Epoch 46/50
 - 4s - loss: 527.3902 - val_loss: 707.2444
Epoch 47/50
 - 4s - loss: 531.9445 - val_loss: 696.8235
Epoch 48/50
 - 4s - loss: 551.7711 - val_loss: 710.4919
Epoch 49/50
 - 4s - loss: 563.6419 - val_loss: 702.5057
Epoch 50/50
 - 4s - loss: 561.2419 - val_loss: 681.3832
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 57320	action = 0	current_phase = 1	next_phase = 0	reward = 0.721234	array([[  1.8184919, -43.7729   ]], dtype=float32)
time = 57325	action = 0	current_phase = 1	next_phase = 0	reward = 0.449136	array([[  1.8473148, -43.842655 ]], dtype=float32)
time = 57330	action = 0	current_phase = 1	next_phase = 0	reward = 1.009432	array([[  1.8940763, -43.954185 ]], dtype=float32)
time = 57335	action = 0	current_phase = 1	next_phase = 0	reward = 0.725798	array([[  1.9205046, -44.150246 ]], dtype=float32)
time = 57340	action = 0	current_phase = 1	next_phase = 0	reward = 0.722075	array([[  1.9003668, -43.968277 ]], dtype=float32)
time = 57345	action = 0	current_phase = 1	next_phase = 0	reward = 0.721144	array([[  1.927537, -44.13401 ]], dtype=float32)
time = 57350	action = 0	current_phase = 1	next_phase = 0	reward = 0.444557	array([[  1.8913641, -43.961205 ]], dtype=float32)
time = 57355	action = 0	current_phase = 1	next_phase = 0	reward = 1.005246	array([[  1.8909979, -43.934837 ]], dtype=float32)
time = 57360	action = 0	current_phase = 1	next_phase = 0	reward = 0.724066	array([[  1.8993206, -44.00802  ]], dtype=float32)
time = 57365	action = 0	current_phase = 1	next_phase = 0	reward = 0.726358	array([[  1.8976793, -44.013374 ]], dtype=float32)
time = 57370	action = 0	current_phase = 1	next_phase = 0	reward = 0.732261	array([[  1.9138985, -44.07908  ]], dtype=float32)
time = 57375	action = 0	current_phase = 1	next_phase = 0	reward = 0.728753	array([[  1.881566, -43.879253]], dtype=float32)
time = 57380	action = 0	current_phase = 1	next_phase = 0	reward = 0.723966	array([[  1.8811798, -43.897125 ]], dtype=float32)
time = 57385	action = 0	current_phase = 1	next_phase = 0	reward = 0.715180	array([[  1.9039001, -43.976826 ]], dtype=float32)
time = 57390	action = 0	current_phase = 1	next_phase = 0	reward = 0.719489	array([[  1.891819, -43.95401 ]], dtype=float32)
time = 57395	action = 0	current_phase = 1	next_phase = 0	reward = 0.719404	array([[  1.9181719, -44.074932 ]], dtype=float32)
time = 57400	action = 0	current_phase = 1	next_phase = 0	reward = 0.446759	array([[  1.8461056, -43.762295 ]], dtype=float32)
time = 57405	action = 0	current_phase = 1	next_phase = 0	reward = 1.007852	array([[  1.8680782, -43.863846 ]], dtype=float32)
time = 57410	action = 0	current_phase = 1	next_phase = 0	reward = 0.715355	array([[  1.8189087, -43.693626 ]], dtype=float32)
time = 57415	action = 0	current_phase = 1	next_phase = 0	reward = 0.715220	array([[  1.732913, -43.58245 ]], dtype=float32)
time = 57420	action = 0	current_phase = 1	next_phase = 0	reward = 0.721534	array([[  1.836957, -43.747444]], dtype=float32)
time = 57425	action = 0	current_phase = 1	next_phase = 0	reward = 0.727011	array([[  1.9092789, -44.028305 ]], dtype=float32)
time = 57430	action = 0	current_phase = 1	next_phase = 0	reward = 0.719919	array([[  1.8627892, -43.814255 ]], dtype=float32)
time = 57435	action = 0	current_phase = 1	next_phase = 0	reward = 0.714008	array([[  1.8749886, -43.89415  ]], dtype=float32)
time = 57440	action = 0	current_phase = 1	next_phase = 0	reward = 0.710068	array([[  1.8239145, -43.82798  ]], dtype=float32)
time = 57445	action = 0	current_phase = 1	next_phase = 0	reward = 0.716721	array([[  1.9240265, -44.105743 ]], dtype=float32)
time = 57450	action = 0	current_phase = 1	next_phase = 0	reward = 0.725787	array([[  1.893774, -43.951668]], dtype=float32)
time = 57455	action = 0	current_phase = 1	next_phase = 0	reward = 0.444070	array([[  1.807064, -43.70685 ]], dtype=float32)
time = 57460	action = 0	current_phase = 1	next_phase = 0	reward = 1.001641	array([[  1.9197159, -44.093285 ]], dtype=float32)
time = 57465	action = 0	current_phase = 1	next_phase = 0	reward = 0.441342	array([[  1.9325781, -44.24642  ]], dtype=float32)
time = 57470	action = 0	current_phase = 1	next_phase = 0	reward = 0.997519	array([[  1.892355, -43.945526]], dtype=float32)
time = 57475	action = 0	current_phase = 1	next_phase = 0	reward = 0.719168	array([[  1.9048033, -43.974953 ]], dtype=float32)
time = 57480	action = 0	current_phase = 1	next_phase = 0	reward = 0.724731	array([[  1.9269552, -44.13302  ]], dtype=float32)
time = 57485	action = 0	current_phase = 1	next_phase = 0	reward = 0.725319	array([[  1.8657703, -43.886086 ]], dtype=float32)
time = 57490	action = 0	current_phase = 1	next_phase = 0	reward = 0.721700	array([[  1.9121647, -44.06458  ]], dtype=float32)
time = 57495	action = 0	current_phase = 1	next_phase = 0	reward = 0.720007	array([[  1.9097576, -44.02246  ]], dtype=float32)
time = 57500	action = 0	current_phase = 1	next_phase = 0	reward = 0.717799	array([[  1.8174601, -43.69129  ]], dtype=float32)
time = 57505	action = 0	current_phase = 1	next_phase = 0	reward = 0.718633	array([[  1.8886967, -43.94444  ]], dtype=float32)
time = 57510	action = 0	current_phase = 1	next_phase = 0	reward = 0.720557	array([[  1.8925562, -43.945595 ]], dtype=float32)
time = 57515	action = 0	current_phase = 1	next_phase = 0	reward = 0.725899	array([[  1.925765, -44.128357]], dtype=float32)
time = 57520	action = 0	current_phase = 1	next_phase = 0	reward = 0.714683	array([[  1.9092894, -44.02671  ]], dtype=float32)
time = 57525	action = 0	current_phase = 1	next_phase = 0	reward = 0.719604	array([[  1.8244648, -43.72007  ]], dtype=float32)
time = 57530	action = 0	current_phase = 1	next_phase = 0	reward = 0.721380	array([[  1.8917665, -43.931675 ]], dtype=float32)
time = 57535	action = 0	current_phase = 1	next_phase = 0	reward = 0.719188	array([[  1.8777227, -43.901962 ]], dtype=float32)
time = 57540	action = 0	current_phase = 1	next_phase = 0	reward = 0.718062	array([[  1.9115477, -44.05945  ]], dtype=float32)
time = 57545	action = 0	current_phase = 1	next_phase = 0	reward = 0.719254	array([[  1.904439, -44.009117]], dtype=float32)
time = 57550	action = 0	current_phase = 1	next_phase = 0	reward = 0.719457	array([[  1.8359098, -43.73448  ]], dtype=float32)
time = 57555	action = 0	current_phase = 1	next_phase = 0	reward = 0.450721	array([[  1.923665, -44.143852]], dtype=float32)
time = 57560	action = 0	current_phase = 1	next_phase = 0	reward = 1.004973	array([[  1.8514042, -43.792946 ]], dtype=float32)
time = 57565	action = 0	current_phase = 1	next_phase = 0	reward = 0.720681	array([[  1.91012, -44.05322]], dtype=float32)
time = 57570	action = 0	current_phase = 1	next_phase = 0	reward = 0.720461	array([[  1.8730841, -43.856857 ]], dtype=float32)
time = 57575	action = 0	current_phase = 1	next_phase = 0	reward = 0.721727	array([[  1.917058, -44.070595]], dtype=float32)
time = 57580	action = 0	current_phase = 1	next_phase = 0	reward = 0.718854	array([[  1.9238272, -44.09362  ]], dtype=float32)
time = 57585	action = 0	current_phase = 1	next_phase = 0	reward = 0.732063	array([[  1.929802, -44.1455  ]], dtype=float32)
time = 57590	action = 0	current_phase = 1	next_phase = 0	reward = 0.721605	array([[  1.9199247, -44.087437 ]], dtype=float32)
time = 57595	action = 0	current_phase = 1	next_phase = 0	reward = 0.724374	array([[  1.8968105, -43.936405 ]], dtype=float32)
time = 57600	action = 0	current_phase = 1	next_phase = 0	reward = 0.449276	array([[  1.8884783, -43.914627 ]], dtype=float32)
time = 57605	action = 0	current_phase = 1	next_phase = 0	reward = 1.009354	array([[  1.7954502, -43.627075 ]], dtype=float32)
time = 57610	action = 0	current_phase = 1	next_phase = 0	reward = 0.719418	array([[  1.8921862, -43.960815 ]], dtype=float32)
time = 57615	action = 0	current_phase = 1	next_phase = 0	reward = 0.723320	array([[  1.8958807, -43.96402  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 489.5224 - val_loss: 304.7613
Epoch 2/50
 - 4s - loss: 497.3718 - val_loss: 308.5048
Epoch 3/50
 - 4s - loss: 485.9230 - val_loss: 320.5027
Epoch 4/50
 - 4s - loss: 493.8728 - val_loss: 302.2467
Epoch 5/50
 - 4s - loss: 497.8808 - val_loss: 298.6552
Epoch 6/50
 - 4s - loss: 481.4092 - val_loss: 354.0304
Epoch 7/50
 - 4s - loss: 480.2212 - val_loss: 310.2952
Epoch 8/50
 - 4s - loss: 474.8908 - val_loss: 317.2513
Epoch 9/50
 - 4s - loss: 502.4411 - val_loss: 317.9874
Epoch 10/50
 - 4s - loss: 469.2021 - val_loss: 369.3641
Epoch 11/50
 - 4s - loss: 493.2234 - val_loss: 318.2163
Epoch 12/50
 - 4s - loss: 471.5840 - val_loss: 326.7015
Epoch 13/50
 - 4s - loss: 465.7831 - val_loss: 308.5379
Epoch 14/50
 - 4s - loss: 484.3031 - val_loss: 308.0688
Epoch 15/50
 - 4s - loss: 467.7395 - val_loss: 336.1887
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 57620	action = 0	current_phase = 1	next_phase = 0	reward = 0.445575	array([[  1.8946133, -44.08903  ]], dtype=float32)
time = 57625	action = 0	current_phase = 1	next_phase = 0	reward = 0.726654	array([[  1.6591482, -43.42614  ]], dtype=float32)
time = 57630	action = 0	current_phase = 1	next_phase = 0	reward = 1.002592	array([[  1.8634949, -43.969254 ]], dtype=float32)
time = 57635	action = 0	current_phase = 1	next_phase = 0	reward = 0.438303	array([[  1.8675299, -43.99508  ]], dtype=float32)
time = 57640	action = 0	current_phase = 1	next_phase = 0	reward = 1.003914	array([[  1.6855202, -43.481514 ]], dtype=float32)
time = 57645	action = 0	current_phase = 1	next_phase = 0	reward = 0.715707	array([[  1.7692747, -43.756397 ]], dtype=float32)
time = 57650	action = 0	current_phase = 1	next_phase = 0	reward = 0.439001	array([[  1.7843847, -43.745644 ]], dtype=float32)
time = 57655	action = 0	current_phase = 1	next_phase = 0	reward = 0.999434	array([[  1.7857428, -43.705326 ]], dtype=float32)
time = 57660	action = 0	current_phase = 1	next_phase = 0	reward = 0.719719	array([[  1.7538528, -43.774406 ]], dtype=float32)
time = 57665	action = 0	current_phase = 1	next_phase = 0	reward = 0.442144	array([[  1.7668276, -43.77133  ]], dtype=float32)
time = 57670	action = 0	current_phase = 1	next_phase = 0	reward = 1.007019	array([[  1.8197889, -43.817554 ]], dtype=float32)
time = 57675	action = 0	current_phase = 1	next_phase = 0	reward = 0.449001	array([[  1.7578297, -43.708233 ]], dtype=float32)
time = 57680	action = 0	current_phase = 1	next_phase = 0	reward = 1.008143	array([[  1.7939005, -43.76535  ]], dtype=float32)
time = 57685	action = 0	current_phase = 1	next_phase = 0	reward = 0.731791	array([[  1.8702059, -44.013294 ]], dtype=float32)
time = 57690	action = 0	current_phase = 1	next_phase = 0	reward = 0.715507	array([[  1.7523727, -43.696423 ]], dtype=float32)
time = 57695	action = 0	current_phase = 1	next_phase = 0	reward = 0.713584	array([[  1.8842611, -44.03219  ]], dtype=float32)
time = 57700	action = 0	current_phase = 1	next_phase = 0	reward = 0.718920	array([[  1.9132881, -44.197716 ]], dtype=float32)
time = 57705	action = 0	current_phase = 1	next_phase = 0	reward = 0.715807	array([[  1.8877745, -44.084316 ]], dtype=float32)
time = 57710	action = 0	current_phase = 1	next_phase = 0	reward = 0.439067	array([[  1.8579979, -44.025204 ]], dtype=float32)
time = 57715	action = 0	current_phase = 1	next_phase = 0	reward = 0.727421	array([[  1.8029261, -43.77565  ]], dtype=float32)
time = 57720	action = 0	current_phase = 1	next_phase = 0	reward = 0.729859	array([[  1.8800192, -44.046906 ]], dtype=float32)
time = 57725	action = 0	current_phase = 1	next_phase = 0	reward = 1.000199	array([[  1.8583498, -43.99018  ]], dtype=float32)
time = 57730	action = 0	current_phase = 1	next_phase = 0	reward = 0.719499	array([[  1.772232, -43.730972]], dtype=float32)
time = 57735	action = 0	current_phase = 1	next_phase = 0	reward = 0.441748	array([[  1.8867893, -44.073486 ]], dtype=float32)
time = 57740	action = 0	current_phase = 1	next_phase = 0	reward = 1.007674	array([[  1.7960854, -43.778435 ]], dtype=float32)
time = 57745	action = 0	current_phase = 1	next_phase = 0	reward = 0.714453	array([[  1.8001871, -43.768276 ]], dtype=float32)
time = 57750	action = 0	current_phase = 1	next_phase = 0	reward = 0.443639	array([[  1.7556725, -43.72717  ]], dtype=float32)
time = 57755	action = 0	current_phase = 1	next_phase = 0	reward = 1.003295	array([[  1.7409639, -43.60194  ]], dtype=float32)
time = 57760	action = 0	current_phase = 1	next_phase = 0	reward = 0.719542	array([[  1.8484268, -43.913277 ]], dtype=float32)
time = 57765	action = 0	current_phase = 1	next_phase = 0	reward = 0.440870	array([[  1.883255, -44.05476 ]], dtype=float32)
time = 57770	action = 0	current_phase = 1	next_phase = 0	reward = 0.725969	array([[  1.827138, -43.84394 ]], dtype=float32)
time = 57775	action = 0	current_phase = 1	next_phase = 0	reward = 1.004904	array([[  1.8177614, -43.84117  ]], dtype=float32)
time = 57780	action = 0	current_phase = 1	next_phase = 0	reward = 0.721717	array([[  1.845294, -43.950912]], dtype=float32)
time = 57785	action = 0	current_phase = 1	next_phase = 0	reward = 0.724038	array([[  1.8132591, -43.810905 ]], dtype=float32)
time = 57790	action = 0	current_phase = 1	next_phase = 0	reward = 0.727211	array([[  1.8121815, -43.800743 ]], dtype=float32)
time = 57795	action = 0	current_phase = 1	next_phase = 0	reward = 0.727948	array([[  1.8256359, -43.855717 ]], dtype=float32)
time = 57800	action = 0	current_phase = 1	next_phase = 0	reward = 0.725013	array([[  1.7409706, -43.62043  ]], dtype=float32)
time = 57805	action = 0	current_phase = 1	next_phase = 0	reward = 0.725206	array([[  1.8416853, -43.89274  ]], dtype=float32)
time = 57810	action = 0	current_phase = 1	next_phase = 0	reward = 0.722277	array([[  1.8071527, -43.79974  ]], dtype=float32)
time = 57815	action = 0	current_phase = 1	next_phase = 0	reward = 0.444934	array([[  1.7832527, -43.776276 ]], dtype=float32)
time = 57820	action = 0	current_phase = 1	next_phase = 0	reward = 1.003208	array([[  1.8785496, -44.019737 ]], dtype=float32)
time = 57825	action = 0	current_phase = 1	next_phase = 0	reward = 0.719659	array([[  1.7607632, -43.69222  ]], dtype=float32)
time = 57830	action = 0	current_phase = 1	next_phase = 0	reward = 0.724451	array([[  1.9140358, -44.17973  ]], dtype=float32)
time = 57835	action = 0	current_phase = 1	next_phase = 0	reward = 0.445454	array([[  1.7100048, -43.544983 ]], dtype=float32)
time = 57840	action = 0	current_phase = 1	next_phase = 0	reward = 0.998922	array([[  1.8164883, -43.867016 ]], dtype=float32)
time = 57845	action = 0	current_phase = 1	next_phase = 0	reward = 0.714175	array([[  1.882474, -44.058075]], dtype=float32)
time = 57850	action = 0	current_phase = 1	next_phase = 0	reward = 0.714347	array([[  1.7257357, -43.622833 ]], dtype=float32)
time = 57855	action = 0	current_phase = 1	next_phase = 0	reward = 0.713287	array([[  1.8595724, -43.946182 ]], dtype=float32)
time = 57860	action = 0	current_phase = 1	next_phase = 0	reward = 0.447246	array([[  1.7830276, -43.697456 ]], dtype=float32)
time = 57865	action = 0	current_phase = 1	next_phase = 0	reward = 1.005790	array([[  1.784873, -43.71573 ]], dtype=float32)
time = 57870	action = 0	current_phase = 1	next_phase = 0	reward = 0.167729	array([[  1.8820114, -44.075058 ]], dtype=float32)
time = 57875	action = 0	current_phase = 1	next_phase = 0	reward = 1.281736	array([[  1.8057232, -43.811928 ]], dtype=float32)
time = 57880	action = 0	current_phase = 1	next_phase = 0	reward = 0.712613	array([[  1.8751631, -44.025917 ]], dtype=float32)
time = 57885	action = 0	current_phase = 1	next_phase = 0	reward = 0.438735	array([[  1.8518791, -43.924694 ]], dtype=float32)
time = 57890	action = 0	current_phase = 1	next_phase = 0	reward = 0.715787	array([[  1.8605595, -43.99812  ]], dtype=float32)
time = 57895	action = 0	current_phase = 1	next_phase = 0	reward = 0.716229	array([[  1.6668148, -43.44149  ]], dtype=float32)
time = 57900	action = 0	current_phase = 1	next_phase = 0	reward = 0.728591	array([[  1.9060802, -44.150444 ]], dtype=float32)
time = 57905	action = 0	current_phase = 1	next_phase = 0	reward = 1.003776	array([[  1.744237, -43.60309 ]], dtype=float32)
time = 57910	action = 0	current_phase = 1	next_phase = 0	reward = 0.447592	array([[  1.872405, -44.064785]], dtype=float32)
time = 57915	action = 0	current_phase = 1	next_phase = 0	reward = 1.001796	array([[  1.8895502, -44.092213 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2430.7511 - val_loss: 436.7891
Epoch 2/50
 - 4s - loss: 2425.9579 - val_loss: 434.0432
Epoch 3/50
 - 4s - loss: 2412.9601 - val_loss: 441.7062
Epoch 4/50
 - 4s - loss: 2427.8576 - val_loss: 424.6293
Epoch 5/50
 - 4s - loss: 2424.2977 - val_loss: 421.3676
Epoch 6/50
 - 4s - loss: 2428.1301 - val_loss: 433.2270
Epoch 7/50
 - 4s - loss: 2413.2613 - val_loss: 450.7033
Epoch 8/50
 - 4s - loss: 2407.3245 - val_loss: 411.6385
Epoch 9/50
 - 4s - loss: 2411.6977 - val_loss: 415.3056
Epoch 10/50
 - 4s - loss: 2433.7137 - val_loss: 403.5651
Epoch 11/50
 - 4s - loss: 2405.6465 - val_loss: 533.1140
Epoch 12/50
 - 4s - loss: 2464.4864 - val_loss: 406.9600
Epoch 13/50
 - 4s - loss: 2420.3659 - val_loss: 420.2988
Epoch 14/50
 - 4s - loss: 2401.3592 - val_loss: 476.9703
Epoch 15/50
 - 4s - loss: 2405.8975 - val_loss: 419.7320
Epoch 16/50
 - 4s - loss: 2411.6672 - val_loss: 512.1756
Epoch 17/50
 - 4s - loss: 2434.6490 - val_loss: 401.3143
Epoch 18/50
 - 4s - loss: 2404.0961 - val_loss: 417.0360
Epoch 19/50
 - 4s - loss: 2413.5813 - val_loss: 422.4475
Epoch 20/50
 - 4s - loss: 2385.3593 - val_loss: 398.2973
Epoch 21/50
 - 4s - loss: 2393.6439 - val_loss: 417.2745
Epoch 22/50
 - 4s - loss: 2385.3179 - val_loss: 411.3155
Epoch 23/50
 - 4s - loss: 2425.5035 - val_loss: 423.6724
Epoch 24/50
 - 4s - loss: 2395.2922 - val_loss: 435.6229
Epoch 25/50
 - 4s - loss: 2387.9371 - val_loss: 433.7174
Epoch 26/50
 - 4s - loss: 2408.4781 - val_loss: 425.4548
Epoch 27/50
 - 4s - loss: 2406.6166 - val_loss: 397.8428
Epoch 28/50
 - 4s - loss: 2390.4437 - val_loss: 406.8588
Epoch 29/50
 - 4s - loss: 2399.5914 - val_loss: 399.4832
Epoch 30/50
 - 4s - loss: 2389.6640 - val_loss: 443.4333
Epoch 31/50
 - 4s - loss: 2369.0182 - val_loss: 397.5124
Epoch 32/50
 - 4s - loss: 2376.5729 - val_loss: 412.4710
Epoch 33/50
 - 4s - loss: 2385.0692 - val_loss: 442.0266
Epoch 34/50
 - 4s - loss: 2438.5529 - val_loss: 399.7360
Epoch 35/50
 - 4s - loss: 2375.6982 - val_loss: 401.1872
Epoch 36/50
 - 4s - loss: 2404.2505 - val_loss: 402.1184
Epoch 37/50
 - 4s - loss: 2374.8274 - val_loss: 396.1330
Epoch 38/50
 - 4s - loss: 2388.8999 - val_loss: 401.3147
Epoch 39/50
 - 4s - loss: 2362.5218 - val_loss: 418.8667
Epoch 40/50
 - 4s - loss: 2375.7457 - val_loss: 401.5953
Epoch 41/50
 - 4s - loss: 2374.7570 - val_loss: 430.1385
Epoch 42/50
 - 4s - loss: 2376.0763 - val_loss: 412.3566
Epoch 43/50
 - 4s - loss: 2377.1442 - val_loss: 406.2041
Epoch 44/50
 - 4s - loss: 2354.0997 - val_loss: 414.0647
Epoch 45/50
 - 4s - loss: 2364.4168 - val_loss: 402.1080
Epoch 46/50
 - 4s - loss: 2353.8089 - val_loss: 404.5518
Epoch 47/50
 - 4s - loss: 2377.5680 - val_loss: 382.8758
Epoch 48/50
 - 4s - loss: 2357.7853 - val_loss: 397.2623
Epoch 49/50
 - 4s - loss: 2364.6643 - val_loss: 381.4834
Epoch 50/50
 - 4s - loss: 2380.0499 - val_loss: 395.4239
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 57920	action = 0	current_phase = 1	next_phase = 0	reward = 0.716647	array([[  1.6551962, -43.66317  ]], dtype=float32)
time = 57925	action = 0	current_phase = 1	next_phase = 0	reward = 0.719136	array([[  1.717185, -43.82763 ]], dtype=float32)
time = 57930	action = 0	current_phase = 1	next_phase = 0	reward = 0.724289	array([[  1.6761217, -43.75847  ]], dtype=float32)
time = 57935	action = 0	current_phase = 1	next_phase = 0	reward = 0.718000	array([[  1.7809687, -44.020058 ]], dtype=float32)
time = 57940	action = 0	current_phase = 1	next_phase = 0	reward = 0.718852	array([[  1.717412, -43.866337]], dtype=float32)
time = 57945	action = 0	current_phase = 1	next_phase = 0	reward = 0.721318	array([[  1.7720222, -43.994503 ]], dtype=float32)
time = 57950	action = 0	current_phase = 1	next_phase = 0	reward = 0.716149	array([[  1.7538147, -43.94757  ]], dtype=float32)
time = 57955	action = 0	current_phase = 1	next_phase = 0	reward = 0.720075	array([[  1.7324362, -43.871475 ]], dtype=float32)
time = 57960	action = 0	current_phase = 1	next_phase = 0	reward = 0.721461	array([[  1.7148647, -43.822224 ]], dtype=float32)
time = 57965	action = 0	current_phase = 1	next_phase = 0	reward = 0.449004	array([[  1.7484884, -43.932518 ]], dtype=float32)
time = 57970	action = 0	current_phase = 1	next_phase = 0	reward = 1.006038	array([[  1.7485399, -43.908234 ]], dtype=float32)
time = 57975	action = 0	current_phase = 1	next_phase = 0	reward = 0.719780	array([[  1.8181114, -44.141327 ]], dtype=float32)
time = 57980	action = 0	current_phase = 1	next_phase = 0	reward = 0.717646	array([[  1.7791147, -44.018215 ]], dtype=float32)
time = 57985	action = 0	current_phase = 1	next_phase = 0	reward = 0.438548	array([[  1.725627, -43.869774]], dtype=float32)
time = 57990	action = 0	current_phase = 1	next_phase = 0	reward = 1.006318	array([[  1.7917852, -44.057854 ]], dtype=float32)
time = 57995	action = 0	current_phase = 1	next_phase = 0	reward = 0.444989	array([[  1.6296673, -43.59044  ]], dtype=float32)
time = 58000	action = 0	current_phase = 1	next_phase = 0	reward = 1.011022	array([[  1.7598963, -43.961548 ]], dtype=float32)
time = 58005	action = 0	current_phase = 1	next_phase = 0	reward = 0.721762	array([[  1.7194777, -43.82437  ]], dtype=float32)
time = 58010	action = 0	current_phase = 1	next_phase = 0	reward = 0.725498	array([[  1.7770615, -43.993965 ]], dtype=float32)
time = 58015	action = 0	current_phase = 1	next_phase = 0	reward = 0.730570	array([[  1.7555733, -43.936974 ]], dtype=float32)
time = 58020	action = 0	current_phase = 1	next_phase = 0	reward = 0.435323	array([[  1.8027458, -44.08633  ]], dtype=float32)
time = 58025	action = 0	current_phase = 1	next_phase = 0	reward = 0.990316	array([[  1.6755953, -43.710648 ]], dtype=float32)
time = 58030	action = 0	current_phase = 1	next_phase = 0	reward = 0.714749	array([[  1.6234303, -43.557747 ]], dtype=float32)
time = 58035	action = 0	current_phase = 1	next_phase = 0	reward = 0.723081	array([[  1.7620096, -43.951805 ]], dtype=float32)
time = 58040	action = 0	current_phase = 1	next_phase = 0	reward = 0.438603	array([[  1.7441521, -43.904686 ]], dtype=float32)
time = 58045	action = 0	current_phase = 1	next_phase = 0	reward = 1.011044	array([[  1.8026199, -44.085354 ]], dtype=float32)
time = 58050	action = 0	current_phase = 1	next_phase = 0	reward = 0.723192	array([[  1.7702589, -43.986794 ]], dtype=float32)
time = 58055	action = 0	current_phase = 1	next_phase = 0	reward = 0.715754	array([[  1.8116045, -44.131165 ]], dtype=float32)
time = 58060	action = 0	current_phase = 1	next_phase = 0	reward = 0.438982	array([[  1.7758703, -44.00526  ]], dtype=float32)
time = 58065	action = 0	current_phase = 1	next_phase = 0	reward = 1.006983	array([[  1.7577362, -43.940865 ]], dtype=float32)
time = 58070	action = 0	current_phase = 1	next_phase = 0	reward = 0.723484	array([[  1.7928295, -44.05719  ]], dtype=float32)
time = 58075	action = 0	current_phase = 1	next_phase = 0	reward = 0.733888	array([[  1.8334408, -44.198948 ]], dtype=float32)
time = 58080	action = 0	current_phase = 1	next_phase = 0	reward = 0.727860	array([[  1.7201309, -43.849    ]], dtype=float32)
time = 58085	action = 0	current_phase = 1	next_phase = 0	reward = 0.722534	array([[  1.7479649, -43.922287 ]], dtype=float32)
time = 58090	action = 0	current_phase = 1	next_phase = 0	reward = 0.714206	array([[  1.7376518, -43.885067 ]], dtype=float32)
time = 58095	action = 0	current_phase = 1	next_phase = 0	reward = 0.720171	array([[  1.738411, -43.913647]], dtype=float32)
time = 58100	action = 0	current_phase = 1	next_phase = 0	reward = 0.716952	array([[  1.7035255, -43.76481  ]], dtype=float32)
time = 58105	action = 0	current_phase = 1	next_phase = 0	reward = 0.432677	array([[  1.6542692, -43.654293 ]], dtype=float32)
time = 58110	action = 0	current_phase = 1	next_phase = 0	reward = 1.008275	array([[  1.6662169, -43.693375 ]], dtype=float32)
time = 58115	action = 0	current_phase = 1	next_phase = 0	reward = 0.446642	array([[  1.7815247, -44.010414 ]], dtype=float32)
time = 58120	action = 0	current_phase = 1	next_phase = 0	reward = 1.006730	array([[  1.7646084, -43.965885 ]], dtype=float32)
time = 58125	action = 0	current_phase = 1	next_phase = 0	reward = 0.721699	array([[  1.7801876, -44.019386 ]], dtype=float32)
time = 58130	action = 0	current_phase = 1	next_phase = 0	reward = 0.710006	array([[  1.8033371, -44.0996   ]], dtype=float32)
time = 58135	action = 0	current_phase = 1	next_phase = 0	reward = 0.446591	array([[  1.8372974, -44.21356  ]], dtype=float32)
time = 58140	action = 0	current_phase = 1	next_phase = 0	reward = 1.005858	array([[  1.6646099, -43.690575 ]], dtype=float32)
time = 58145	action = 0	current_phase = 1	next_phase = 0	reward = 0.725287	array([[  1.7643633, -43.953056 ]], dtype=float32)
time = 58150	action = 0	current_phase = 1	next_phase = 0	reward = 0.720981	array([[  1.6537771, -43.66153  ]], dtype=float32)
time = 58155	action = 0	current_phase = 1	next_phase = 0	reward = 0.716501	array([[  1.7719069, -44.01296  ]], dtype=float32)
time = 58160	action = 0	current_phase = 1	next_phase = 0	reward = 0.708812	array([[  1.7601376, -43.948463 ]], dtype=float32)
time = 58165	action = 0	current_phase = 1	next_phase = 0	reward = 0.714505	array([[  1.628972, -43.582108]], dtype=float32)
time = 58170	action = 0	current_phase = 1	next_phase = 0	reward = 0.450008	array([[  1.7140436, -43.80336  ]], dtype=float32)
time = 58175	action = 0	current_phase = 1	next_phase = 0	reward = 1.005340	array([[  1.6878395, -43.74995  ]], dtype=float32)
time = 58180	action = 0	current_phase = 1	next_phase = 0	reward = 0.724770	array([[  1.8284979, -44.174004 ]], dtype=float32)
time = 58185	action = 0	current_phase = 1	next_phase = 0	reward = 0.724445	array([[  1.7905703, -44.044594 ]], dtype=float32)
time = 58190	action = 0	current_phase = 1	next_phase = 0	reward = 0.720254	array([[  1.8092575, -44.10398  ]], dtype=float32)
time = 58195	action = 0	current_phase = 1	next_phase = 0	reward = 0.716689	array([[  1.761879, -43.95799 ]], dtype=float32)
time = 58200	action = 0	current_phase = 1	next_phase = 0	reward = 0.711410	array([[  1.7776861, -44.009438 ]], dtype=float32)
time = 58205	action = 0	current_phase = 1	next_phase = 0	reward = 0.432698	array([[  1.8440084, -44.241108 ]], dtype=float32)
time = 58210	action = 0	current_phase = 1	next_phase = 0	reward = 1.011899	array([[  1.758852, -43.941914]], dtype=float32)
time = 58215	action = 0	current_phase = 1	next_phase = 0	reward = 0.730501	array([[  1.7996397, -44.073154 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2341.3118 - val_loss: 307.9039
Epoch 2/50
 - 4s - loss: 2326.2625 - val_loss: 317.5690
Epoch 3/50
 - 4s - loss: 2386.3149 - val_loss: 324.8353
Epoch 4/50
 - 4s - loss: 2315.1592 - val_loss: 329.8916
Epoch 5/50
 - 4s - loss: 2364.8384 - val_loss: 319.6202
Epoch 6/50
 - 4s - loss: 2314.1614 - val_loss: 340.2687
Epoch 7/50
 - 4s - loss: 2316.2549 - val_loss: 316.7804
Epoch 8/50
 - 4s - loss: 2311.9023 - val_loss: 337.2078
Epoch 9/50
 - 4s - loss: 2326.8956 - val_loss: 322.7746
Epoch 10/50
 - 4s - loss: 2326.8225 - val_loss: 303.1002
Epoch 11/50
 - 4s - loss: 2324.0838 - val_loss: 301.0939
Epoch 12/50
 - 4s - loss: 2297.3784 - val_loss: 315.8542
Epoch 13/50
 - 4s - loss: 2297.1912 - val_loss: 326.3053
Epoch 14/50
 - 4s - loss: 2298.4985 - val_loss: 311.8553
Epoch 15/50
 - 4s - loss: 2339.0569 - val_loss: 306.4775
Epoch 16/50
 - 4s - loss: 2300.0722 - val_loss: 299.8830
Epoch 17/50
 - 4s - loss: 2303.4731 - val_loss: 319.1729
Epoch 18/50
 - 4s - loss: 2312.5687 - val_loss: 299.0763
Epoch 19/50
 - 4s - loss: 2297.8541 - val_loss: 309.5127
Epoch 20/50
 - 4s - loss: 2297.5867 - val_loss: 371.6818
Epoch 21/50
 - 4s - loss: 2313.9378 - val_loss: 284.6350
Epoch 22/50
 - 4s - loss: 2283.8452 - val_loss: 315.4222
Epoch 23/50
 - 4s - loss: 2305.3257 - val_loss: 312.5403
Epoch 24/50
 - 4s - loss: 2284.3423 - val_loss: 310.9761
Epoch 25/50
 - 4s - loss: 2286.9252 - val_loss: 348.4139
Epoch 26/50
 - 4s - loss: 2320.5110 - val_loss: 321.3112
Epoch 27/50
 - 4s - loss: 2334.5477 - val_loss: 317.0908
Epoch 28/50
 - 4s - loss: 2282.2531 - val_loss: 320.1466
Epoch 29/50
 - 4s - loss: 2290.1346 - val_loss: 321.7041
Epoch 30/50
 - 4s - loss: 2296.4282 - val_loss: 326.3794
Epoch 31/50
 - 4s - loss: 2281.8418 - val_loss: 292.5062
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 58220	action = 0	current_phase = 1	next_phase = 0	reward = 0.724235	array([[  1.9273472, -44.272713 ]], dtype=float32)
time = 58225	action = 0	current_phase = 1	next_phase = 0	reward = 0.717832	array([[  1.9942036, -44.45115  ]], dtype=float32)
time = 58230	action = 0	current_phase = 1	next_phase = 0	reward = 0.715693	array([[  1.9799585, -44.436943 ]], dtype=float32)
time = 58235	action = 0	current_phase = 1	next_phase = 0	reward = 0.723280	array([[  1.8138018, -43.970886 ]], dtype=float32)
time = 58240	action = 0	current_phase = 1	next_phase = 0	reward = 0.715152	array([[  1.9347773, -44.28189  ]], dtype=float32)
time = 58245	action = 0	current_phase = 1	next_phase = 0	reward = 0.717973	array([[  1.8593779, -44.087082 ]], dtype=float32)
time = 58250	action = 0	current_phase = 1	next_phase = 0	reward = 0.717158	array([[  1.8743057, -44.129204 ]], dtype=float32)
time = 58255	action = 0	current_phase = 1	next_phase = 0	reward = 0.723185	array([[  1.9247627, -44.26393  ]], dtype=float32)
time = 58260	action = 0	current_phase = 1	next_phase = 0	reward = 0.720426	array([[  1.9697924, -44.390312 ]], dtype=float32)
time = 58265	action = 0	current_phase = 1	next_phase = 0	reward = 0.440005	array([[  1.959609, -44.35695 ]], dtype=float32)
time = 58270	action = 0	current_phase = 1	next_phase = 0	reward = 0.441003	array([[  1.8506823, -44.075237 ]], dtype=float32)
time = 58275	action = 0	current_phase = 1	next_phase = 0	reward = 1.279611	array([[  1.9238281, -44.259766 ]], dtype=float32)
time = 58280	action = 0	current_phase = 1	next_phase = 0	reward = 0.449985	array([[  1.8299885, -44.01137  ]], dtype=float32)
time = 58285	action = 0	current_phase = 1	next_phase = 0	reward = 1.001075	array([[  1.7396431, -43.797585 ]], dtype=float32)
time = 58290	action = 0	current_phase = 1	next_phase = 0	reward = 0.714090	array([[  1.8045378, -43.9416   ]], dtype=float32)
time = 58295	action = 0	current_phase = 1	next_phase = 0	reward = 0.717797	array([[  1.8789568, -44.13022  ]], dtype=float32)
time = 58300	action = 0	current_phase = 1	next_phase = 0	reward = 0.448881	array([[  1.8567057, -44.086113 ]], dtype=float32)
time = 58305	action = 0	current_phase = 1	next_phase = 0	reward = 0.726016	array([[  1.8592949, -44.096382 ]], dtype=float32)
time = 58310	action = 0	current_phase = 1	next_phase = 0	reward = 0.997459	array([[  1.9319801, -44.282806 ]], dtype=float32)
time = 58315	action = 0	current_phase = 1	next_phase = 0	reward = 0.720126	array([[  1.8576956, -44.15882  ]], dtype=float32)
time = 58320	action = 0	current_phase = 1	next_phase = 0	reward = 0.722878	array([[  1.9018526, -44.19857  ]], dtype=float32)
time = 58325	action = 0	current_phase = 1	next_phase = 0	reward = 0.721264	array([[  1.8602772, -44.10596  ]], dtype=float32)
time = 58330	action = 0	current_phase = 1	next_phase = 0	reward = 0.718593	array([[  1.8577766, -44.11589  ]], dtype=float32)
time = 58335	action = 0	current_phase = 1	next_phase = 0	reward = 0.715239	array([[  1.8786526, -44.127716 ]], dtype=float32)
time = 58340	action = 0	current_phase = 1	next_phase = 0	reward = 0.712241	array([[  1.9186878, -44.247566 ]], dtype=float32)
time = 58345	action = 0	current_phase = 1	next_phase = 0	reward = 0.729377	array([[  1.9392004, -44.301445 ]], dtype=float32)
time = 58350	action = 0	current_phase = 1	next_phase = 0	reward = 0.444456	array([[  1.8173952, -44.00685  ]], dtype=float32)
time = 58355	action = 0	current_phase = 1	next_phase = 0	reward = 1.001663	array([[  1.8444815, -44.05432  ]], dtype=float32)
time = 58360	action = 0	current_phase = 1	next_phase = 0	reward = 0.716077	array([[  1.9399805, -44.304237 ]], dtype=float32)
time = 58365	action = 0	current_phase = 1	next_phase = 0	reward = 0.717558	array([[  1.8107138, -43.96552  ]], dtype=float32)
time = 58370	action = 0	current_phase = 1	next_phase = 0	reward = 0.722483	array([[  1.8749504, -44.11916  ]], dtype=float32)
time = 58375	action = 0	current_phase = 1	next_phase = 0	reward = 0.722312	array([[  1.9379492, -44.299606 ]], dtype=float32)
time = 58380	action = 0	current_phase = 1	next_phase = 0	reward = 0.722099	array([[  1.8273058, -44.021446 ]], dtype=float32)
time = 58385	action = 0	current_phase = 1	next_phase = 0	reward = 0.726169	array([[  1.9201269, -44.25838  ]], dtype=float32)
time = 58390	action = 0	current_phase = 1	next_phase = 0	reward = 0.717962	array([[  1.8706083, -44.106636 ]], dtype=float32)
time = 58395	action = 0	current_phase = 1	next_phase = 0	reward = 0.713049	array([[  1.9208069, -44.251907 ]], dtype=float32)
time = 58400	action = 0	current_phase = 1	next_phase = 0	reward = 0.716053	array([[  1.9021559, -44.20041  ]], dtype=float32)
time = 58405	action = 0	current_phase = 1	next_phase = 0	reward = 0.719853	array([[  1.9278984, -44.270203 ]], dtype=float32)
time = 58410	action = 0	current_phase = 1	next_phase = 0	reward = 0.718708	array([[  1.7901402, -43.926186 ]], dtype=float32)
time = 58415	action = 0	current_phase = 1	next_phase = 0	reward = 0.720682	array([[  1.9199734, -44.249176 ]], dtype=float32)
time = 58420	action = 0	current_phase = 1	next_phase = 0	reward = 0.718972	array([[  1.8801718, -44.135498 ]], dtype=float32)
time = 58425	action = 0	current_phase = 1	next_phase = 0	reward = 0.441892	array([[  1.8581362, -44.11167  ]], dtype=float32)
time = 58430	action = 0	current_phase = 1	next_phase = 0	reward = 0.991906	array([[  1.9887648, -44.44873  ]], dtype=float32)
time = 58435	action = 0	current_phase = 1	next_phase = 0	reward = 0.714131	array([[  1.9087906, -44.213722 ]], dtype=float32)
time = 58440	action = 0	current_phase = 1	next_phase = 0	reward = 0.170631	array([[  1.8436222, -44.05053  ]], dtype=float32)
time = 58445	action = 0	current_phase = 1	next_phase = 0	reward = 1.284195	array([[  1.7600946, -43.84861  ]], dtype=float32)
time = 58450	action = 0	current_phase = 1	next_phase = 0	reward = 0.445096	array([[  1.9429607, -44.3142   ]], dtype=float32)
time = 58455	action = 0	current_phase = 1	next_phase = 0	reward = 1.006985	array([[  1.8298969, -44.011635 ]], dtype=float32)
time = 58460	action = 0	current_phase = 1	next_phase = 0	reward = 0.450526	array([[  1.8896341, -44.170265 ]], dtype=float32)
time = 58465	action = 0	current_phase = 1	next_phase = 0	reward = 1.009561	array([[  1.9595232, -44.35772  ]], dtype=float32)
time = 58470	action = 0	current_phase = 1	next_phase = 0	reward = 0.721538	array([[  1.9845524, -44.436127 ]], dtype=float32)
time = 58475	action = 0	current_phase = 1	next_phase = 0	reward = 0.720945	array([[  1.9026251, -44.21402  ]], dtype=float32)
time = 58480	action = 0	current_phase = 1	next_phase = 0	reward = 0.718124	array([[  1.9374256, -44.296516 ]], dtype=float32)
time = 58485	action = 0	current_phase = 1	next_phase = 0	reward = 0.718526	array([[  1.9812775, -44.425995 ]], dtype=float32)
time = 58490	action = 0	current_phase = 1	next_phase = 0	reward = 0.718333	array([[  1.9094477, -44.21396  ]], dtype=float32)
time = 58495	action = 0	current_phase = 1	next_phase = 0	reward = 0.718661	array([[  1.9470472, -44.319275 ]], dtype=float32)
time = 58500	action = 0	current_phase = 1	next_phase = 0	reward = 0.723840	array([[  1.8690405, -44.10878  ]], dtype=float32)
time = 58505	action = 0	current_phase = 1	next_phase = 0	reward = 0.730298	array([[  1.8720694, -44.117832 ]], dtype=float32)
time = 58510	action = 0	current_phase = 1	next_phase = 0	reward = 0.439755	array([[  1.9976254, -44.481857 ]], dtype=float32)
time = 58515	action = 0	current_phase = 1	next_phase = 0	reward = 0.997597	array([[  1.8473043, -44.03971  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 292.7472 - val_loss: 762.9572
Epoch 2/50
 - 4s - loss: 274.9945 - val_loss: 742.6009
Epoch 3/50
 - 4s - loss: 285.6081 - val_loss: 656.6782
Epoch 4/50
 - 4s - loss: 290.8850 - val_loss: 706.0595
Epoch 5/50
 - 4s - loss: 284.4860 - val_loss: 719.2397
Epoch 6/50
 - 4s - loss: 282.1497 - val_loss: 737.1967
Epoch 7/50
 - 4s - loss: 280.4680 - val_loss: 703.5080
Epoch 8/50
 - 4s - loss: 282.1045 - val_loss: 737.2466
Epoch 9/50
 - 4s - loss: 273.9761 - val_loss: 717.3504
Epoch 10/50
 - 4s - loss: 299.0999 - val_loss: 812.9349
Epoch 11/50
 - 4s - loss: 311.3447 - val_loss: 717.8192
Epoch 12/50
 - 4s - loss: 292.3961 - val_loss: 716.1677
Epoch 13/50
 - 4s - loss: 319.4437 - val_loss: 752.3971
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 58520	action = 0	current_phase = 1	next_phase = 0	reward = 0.724195	array([[  1.8913946, -44.302803 ]], dtype=float32)
time = 58525	action = 0	current_phase = 1	next_phase = 0	reward = 0.447827	array([[  1.8479528, -44.169952 ]], dtype=float32)
time = 58530	action = 0	current_phase = 1	next_phase = 0	reward = 1.003201	array([[  1.8824062, -44.29335  ]], dtype=float32)
time = 58535	action = 0	current_phase = 1	next_phase = 0	reward = 0.719155	array([[  1.8785105, -44.230423 ]], dtype=float32)
time = 58540	action = 0	current_phase = 1	next_phase = 0	reward = 0.719657	array([[  1.8390179, -44.13373  ]], dtype=float32)
time = 58545	action = 0	current_phase = 1	next_phase = 0	reward = 0.727507	array([[  1.8350716, -44.14101  ]], dtype=float32)
time = 58550	action = 0	current_phase = 1	next_phase = 0	reward = 0.719719	array([[  1.857955, -44.20437 ]], dtype=float32)
time = 58555	action = 0	current_phase = 1	next_phase = 0	reward = 0.717201	array([[  1.907608, -44.365734]], dtype=float32)
time = 58560	action = 0	current_phase = 1	next_phase = 0	reward = 0.719418	array([[  1.871316, -44.25466 ]], dtype=float32)
time = 58565	action = 0	current_phase = 1	next_phase = 0	reward = 0.433498	array([[  1.8881941, -44.30595  ]], dtype=float32)
time = 58570	action = 0	current_phase = 1	next_phase = 0	reward = 1.000846	array([[  1.8180943, -44.09233  ]], dtype=float32)
time = 58575	action = 0	current_phase = 1	next_phase = 0	reward = 0.718302	array([[  1.8673391, -44.230103 ]], dtype=float32)
time = 58580	action = 0	current_phase = 1	next_phase = 0	reward = 0.726418	array([[  1.9001551, -44.342384 ]], dtype=float32)
time = 58585	action = 0	current_phase = 1	next_phase = 0	reward = 0.722419	array([[  1.7578831, -43.922318 ]], dtype=float32)
time = 58590	action = 0	current_phase = 1	next_phase = 0	reward = 0.710367	array([[  1.905386, -44.3539  ]], dtype=float32)
time = 58595	action = 0	current_phase = 1	next_phase = 0	reward = 0.716190	array([[  1.8605852, -44.223206 ]], dtype=float32)
time = 58600	action = 0	current_phase = 1	next_phase = 0	reward = 0.715476	array([[  1.809022, -44.056084]], dtype=float32)
time = 58605	action = 0	current_phase = 1	next_phase = 0	reward = 0.718748	array([[  1.7557669, -43.949936 ]], dtype=float32)
time = 58610	action = 0	current_phase = 1	next_phase = 0	reward = 0.440427	array([[  1.785264, -43.97496 ]], dtype=float32)
time = 58615	action = 0	current_phase = 1	next_phase = 0	reward = 1.009924	array([[  1.8857298, -44.293213 ]], dtype=float32)
time = 58620	action = 0	current_phase = 1	next_phase = 0	reward = 0.445302	array([[  1.7880859, -44.022964 ]], dtype=float32)
time = 58625	action = 0	current_phase = 1	next_phase = 0	reward = 0.998303	array([[  1.8318443, -44.13301  ]], dtype=float32)
time = 58630	action = 0	current_phase = 1	next_phase = 0	reward = 0.441273	array([[  1.8362522, -44.143078 ]], dtype=float32)
time = 58635	action = 0	current_phase = 1	next_phase = 0	reward = 0.997445	array([[  1.8465061, -44.16815  ]], dtype=float32)
time = 58640	action = 0	current_phase = 1	next_phase = 0	reward = 0.719995	array([[  1.8750954, -44.26599  ]], dtype=float32)
time = 58645	action = 0	current_phase = 1	next_phase = 0	reward = 0.723159	array([[  1.9034176, -44.360107 ]], dtype=float32)
time = 58650	action = 0	current_phase = 1	next_phase = 0	reward = 0.724273	array([[  1.8967991, -44.31626  ]], dtype=float32)
time = 58655	action = 0	current_phase = 1	next_phase = 0	reward = 0.722898	array([[  1.7997103, -44.05268  ]], dtype=float32)
time = 58660	action = 0	current_phase = 1	next_phase = 0	reward = 0.726035	array([[  1.8733873, -44.24923  ]], dtype=float32)
time = 58665	action = 0	current_phase = 1	next_phase = 0	reward = 0.725286	array([[  1.874094, -44.267166]], dtype=float32)
time = 58670	action = 0	current_phase = 1	next_phase = 0	reward = 0.711159	array([[  1.8549976, -44.228733 ]], dtype=float32)
time = 58675	action = 0	current_phase = 1	next_phase = 0	reward = 0.707506	array([[  1.9022341, -44.371887 ]], dtype=float32)
time = 58680	action = 0	current_phase = 1	next_phase = 0	reward = 0.711101	array([[  1.8413658, -44.155308 ]], dtype=float32)
time = 58685	action = 0	current_phase = 1	next_phase = 0	reward = 0.711835	array([[  1.8410931, -44.161926 ]], dtype=float32)
time = 58690	action = 0	current_phase = 1	next_phase = 0	reward = 0.720870	array([[  1.7437649, -43.87352  ]], dtype=float32)
time = 58695	action = 0	current_phase = 1	next_phase = 0	reward = 0.442683	array([[  1.8711853, -44.25722  ]], dtype=float32)
time = 58700	action = 0	current_phase = 1	next_phase = 0	reward = 0.995275	array([[  1.7995443, -44.037052 ]], dtype=float32)
time = 58705	action = 0	current_phase = 1	next_phase = 0	reward = 0.710726	array([[  1.8844872, -44.288692 ]], dtype=float32)
time = 58710	action = 0	current_phase = 1	next_phase = 0	reward = 0.718882	array([[  1.8624811, -44.207764 ]], dtype=float32)
time = 58715	action = 0	current_phase = 1	next_phase = 0	reward = 0.443515	array([[  1.8381577, -44.12678  ]], dtype=float32)
time = 58720	action = 0	current_phase = 1	next_phase = 0	reward = 0.726191	array([[  1.788702, -44.027077]], dtype=float32)
time = 58725	action = 0	current_phase = 1	next_phase = 0	reward = 1.004855	array([[  1.8574381, -44.206745 ]], dtype=float32)
time = 58730	action = 0	current_phase = 1	next_phase = 0	reward = 0.723227	array([[  1.9329996, -44.390663 ]], dtype=float32)
time = 58735	action = 0	current_phase = 1	next_phase = 0	reward = 0.443454	array([[  1.9140453, -44.397705 ]], dtype=float32)
time = 58740	action = 0	current_phase = 1	next_phase = 0	reward = 1.003004	array([[  1.8625555, -44.235085 ]], dtype=float32)
time = 58745	action = 0	current_phase = 1	next_phase = 0	reward = 0.718611	array([[  1.8360605, -44.146408 ]], dtype=float32)
time = 58750	action = 0	current_phase = 1	next_phase = 0	reward = 0.718379	array([[  1.8666468, -44.22191  ]], dtype=float32)
time = 58755	action = 0	current_phase = 1	next_phase = 0	reward = 0.718535	array([[  1.8075504, -44.06502  ]], dtype=float32)
time = 58760	action = 0	current_phase = 1	next_phase = 0	reward = 0.167174	array([[  1.9019308, -44.34271  ]], dtype=float32)
time = 58765	action = 0	current_phase = 1	next_phase = 0	reward = 1.283580	array([[  1.8956642, -44.306763 ]], dtype=float32)
time = 58770	action = 0	current_phase = 1	next_phase = 0	reward = 0.719984	array([[  1.8107624, -44.04624  ]], dtype=float32)
time = 58775	action = 0	current_phase = 1	next_phase = 0	reward = 0.722777	array([[  1.8988533, -44.32103  ]], dtype=float32)
time = 58780	action = 0	current_phase = 1	next_phase = 0	reward = 0.444010	array([[  1.8105536, -44.095806 ]], dtype=float32)
time = 58785	action = 0	current_phase = 1	next_phase = 0	reward = 0.997905	array([[  1.8466549, -44.16579  ]], dtype=float32)
time = 58790	action = 0	current_phase = 1	next_phase = 0	reward = 0.713611	array([[  1.8502855, -44.186966 ]], dtype=float32)
time = 58795	action = 0	current_phase = 1	next_phase = 0	reward = 0.719045	array([[  1.8613176, -44.25924  ]], dtype=float32)
time = 58800	action = 0	current_phase = 1	next_phase = 0	reward = 0.720232	array([[  1.8694363, -44.209976 ]], dtype=float32)
time = 58805	action = 0	current_phase = 1	next_phase = 0	reward = 0.728285	array([[  1.8828678, -44.278362 ]], dtype=float32)
time = 58810	action = 0	current_phase = 1	next_phase = 0	reward = 0.708882	array([[  1.8305035, -44.134052 ]], dtype=float32)
time = 58815	action = 0	current_phase = 1	next_phase = 0	reward = 0.710479	array([[  1.8728361, -44.252274 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2277.1589 - val_loss: 549.4526
Epoch 2/50
 - 4s - loss: 2279.0909 - val_loss: 556.0630
Epoch 3/50
 - 4s - loss: 2242.6085 - val_loss: 589.6217
Epoch 4/50
 - 4s - loss: 2241.0244 - val_loss: 621.3169
Epoch 5/50
 - 4s - loss: 2261.3935 - val_loss: 576.2706
Epoch 6/50
 - 4s - loss: 2251.7293 - val_loss: 552.8543
Epoch 7/50
 - 4s - loss: 2234.7213 - val_loss: 588.5754
Epoch 8/50
 - 4s - loss: 2230.8316 - val_loss: 559.4109
Epoch 9/50
 - 4s - loss: 2227.4159 - val_loss: 699.2648
Epoch 10/50
 - 4s - loss: 2236.8436 - val_loss: 553.9179
Epoch 11/50
 - 4s - loss: 2249.8181 - val_loss: 808.9663
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 58820	action = 0	current_phase = 1	next_phase = 0	reward = 0.727186	array([[  1.978653, -44.1817  ]], dtype=float32)
time = 58825	action = 0	current_phase = 1	next_phase = 0	reward = 0.446698	array([[  2.0486155, -44.39188  ]], dtype=float32)
time = 58830	action = 0	current_phase = 1	next_phase = 0	reward = 1.004569	array([[  2.0161324, -44.295044 ]], dtype=float32)
time = 58835	action = 0	current_phase = 1	next_phase = 0	reward = 0.724528	array([[  2.081316, -44.504032]], dtype=float32)
time = 58840	action = 0	current_phase = 1	next_phase = 0	reward = 0.716190	array([[  2.0244513, -44.313583 ]], dtype=float32)
time = 58845	action = 0	current_phase = 1	next_phase = 0	reward = 0.445576	array([[  2.0820503, -44.514797 ]], dtype=float32)
time = 58850	action = 0	current_phase = 1	next_phase = 0	reward = 0.993766	array([[  2.0361404, -44.349586 ]], dtype=float32)
time = 58855	action = 0	current_phase = 1	next_phase = 0	reward = 0.718593	array([[  2.038663, -44.3553  ]], dtype=float32)
time = 58860	action = 0	current_phase = 1	next_phase = 0	reward = 0.716750	array([[  2.0087738, -44.2684   ]], dtype=float32)
time = 58865	action = 0	current_phase = 1	next_phase = 0	reward = 0.716135	array([[  2.069354, -44.468773]], dtype=float32)
time = 58870	action = 0	current_phase = 1	next_phase = 0	reward = 0.717876	array([[  1.9997292, -44.26651  ]], dtype=float32)
time = 58875	action = 0	current_phase = 1	next_phase = 0	reward = 0.722722	array([[  2.075244, -44.486305]], dtype=float32)
time = 58880	action = 0	current_phase = 1	next_phase = 0	reward = 0.713979	array([[  2.051876, -44.408356]], dtype=float32)
time = 58885	action = 0	current_phase = 1	next_phase = 0	reward = 0.717572	array([[  2.0054655, -44.26771  ]], dtype=float32)
time = 58890	action = 0	current_phase = 1	next_phase = 0	reward = 0.440964	array([[  2.095008, -44.563065]], dtype=float32)
time = 58895	action = 0	current_phase = 1	next_phase = 0	reward = 0.995787	array([[  1.8869267, -44.01467  ]], dtype=float32)
time = 58900	action = 0	current_phase = 1	next_phase = 0	reward = 0.446616	array([[  2.0018587, -44.247124 ]], dtype=float32)
time = 58905	action = 0	current_phase = 1	next_phase = 0	reward = 1.000912	array([[  2.0444632, -44.3752   ]], dtype=float32)
time = 58910	action = 0	current_phase = 1	next_phase = 0	reward = 0.718274	array([[  2.0336857, -44.34443  ]], dtype=float32)
time = 58915	action = 0	current_phase = 1	next_phase = 0	reward = 0.442523	array([[  2.0316  , -44.334335]], dtype=float32)
time = 58920	action = 0	current_phase = 1	next_phase = 0	reward = 1.004148	array([[  2.0605564, -44.435326 ]], dtype=float32)
time = 58925	action = 0	current_phase = 1	next_phase = 0	reward = 0.725748	array([[  2.0435705, -44.37963  ]], dtype=float32)
time = 58930	action = 0	current_phase = 1	next_phase = 0	reward = 0.712794	array([[  1.8651228, -43.883007 ]], dtype=float32)
time = 58935	action = 0	current_phase = 1	next_phase = 0	reward = 0.715028	array([[  2.0094795, -44.268475 ]], dtype=float32)
time = 58940	action = 0	current_phase = 1	next_phase = 0	reward = 0.446373	array([[  2.0221825, -44.309376 ]], dtype=float32)
time = 58945	action = 0	current_phase = 1	next_phase = 0	reward = 1.001748	array([[  2.0065498, -44.26722  ]], dtype=float32)
time = 58950	action = 0	current_phase = 1	next_phase = 0	reward = 0.716379	array([[  1.9612255, -44.134315 ]], dtype=float32)
time = 58955	action = 0	current_phase = 1	next_phase = 0	reward = 0.439293	array([[  2.0106812, -44.29442  ]], dtype=float32)
time = 58960	action = 0	current_phase = 1	next_phase = 0	reward = 0.722715	array([[  2.0814438, -44.504425 ]], dtype=float32)
time = 58965	action = 0	current_phase = 1	next_phase = 0	reward = 1.001721	array([[  2.0716314, -44.46728  ]], dtype=float32)
time = 58970	action = 0	current_phase = 1	next_phase = 0	reward = 0.723328	array([[  2.028226, -44.32747 ]], dtype=float32)
time = 58975	action = 0	current_phase = 1	next_phase = 0	reward = 0.719516	array([[  2.1191244, -44.66893  ]], dtype=float32)
time = 58980	action = 0	current_phase = 1	next_phase = 0	reward = 0.728226	array([[  2.0575333, -44.421555 ]], dtype=float32)
time = 58985	action = 0	current_phase = 1	next_phase = 0	reward = 0.443003	array([[  2.099019, -44.578583]], dtype=float32)
time = 58990	action = 0	current_phase = 1	next_phase = 0	reward = 0.727944	array([[  2.0680952, -44.458214 ]], dtype=float32)
time = 58995	action = 0	current_phase = 1	next_phase = 0	reward = 1.005520	array([[  1.9452162, -44.081444 ]], dtype=float32)
time = 59000	action = 0	current_phase = 1	next_phase = 0	reward = 0.724117	array([[  2.063301, -44.452244]], dtype=float32)
time = 59005	action = 0	current_phase = 1	next_phase = 0	reward = 0.715683	array([[  1.9824486, -44.18799  ]], dtype=float32)
time = 59010	action = 0	current_phase = 1	next_phase = 0	reward = 0.719889	array([[  1.9766836, -44.23762  ]], dtype=float32)
time = 59015	action = 0	current_phase = 1	next_phase = 0	reward = 0.717839	array([[  1.9721355, -44.151237 ]], dtype=float32)
time = 59020	action = 0	current_phase = 1	next_phase = 0	reward = 0.726117	array([[  2.087531, -44.529877]], dtype=float32)
time = 59025	action = 0	current_phase = 1	next_phase = 0	reward = 0.721811	array([[  2.0277462, -44.32556  ]], dtype=float32)
time = 59030	action = 0	current_phase = 1	next_phase = 0	reward = 0.712587	array([[  2.0810432, -44.492805 ]], dtype=float32)
time = 59035	action = 0	current_phase = 1	next_phase = 0	reward = 0.444496	array([[  2.010354, -44.281864]], dtype=float32)
time = 59040	action = 0	current_phase = 1	next_phase = 0	reward = 0.727416	array([[  2.014573, -44.277374]], dtype=float32)
time = 59045	action = 0	current_phase = 1	next_phase = 0	reward = 1.004421	array([[  2.0033445, -44.255283 ]], dtype=float32)
time = 59050	action = 0	current_phase = 1	next_phase = 0	reward = 0.723224	array([[  1.8954182, -43.96241  ]], dtype=float32)
time = 59055	action = 0	current_phase = 1	next_phase = 0	reward = 0.721509	array([[  2.09449 , -44.546223]], dtype=float32)
time = 59060	action = 0	current_phase = 1	next_phase = 0	reward = 0.717612	array([[  2.0265656, -44.31457  ]], dtype=float32)
time = 59065	action = 0	current_phase = 1	next_phase = 0	reward = 0.714104	array([[  1.9382973, -44.146496 ]], dtype=float32)
time = 59070	action = 0	current_phase = 1	next_phase = 0	reward = 0.717443	array([[  2.0506964, -44.399708 ]], dtype=float32)
time = 59075	action = 0	current_phase = 1	next_phase = 0	reward = 0.722899	array([[  2.0166588, -44.31015  ]], dtype=float32)
time = 59080	action = 0	current_phase = 1	next_phase = 0	reward = 0.719613	array([[  2.0687876, -44.464226 ]], dtype=float32)
time = 59085	action = 0	current_phase = 1	next_phase = 0	reward = 0.727399	array([[  2.0801802, -44.494125 ]], dtype=float32)
time = 59090	action = 0	current_phase = 1	next_phase = 0	reward = 0.720279	array([[  2.0185747, -44.297386 ]], dtype=float32)
time = 59095	action = 0	current_phase = 1	next_phase = 0	reward = 0.714834	array([[  1.9988527, -44.23777  ]], dtype=float32)
time = 59100	action = 0	current_phase = 1	next_phase = 0	reward = 0.715241	array([[  2.0585918, -44.429585 ]], dtype=float32)
time = 59105	action = 0	current_phase = 1	next_phase = 0	reward = 0.716242	array([[  2.037074, -44.35687 ]], dtype=float32)
time = 59110	action = 0	current_phase = 1	next_phase = 0	reward = 0.727299	array([[  1.9878254, -44.206394 ]], dtype=float32)
time = 59115	action = 0	current_phase = 1	next_phase = 0	reward = 0.722631	array([[  2.072401, -44.468445]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 5s - loss: 2399.7521 - val_loss: 538.3310
Epoch 2/50
 - 4s - loss: 2375.5513 - val_loss: 576.5973
Epoch 3/50
 - 4s - loss: 2374.3696 - val_loss: 643.1067
Epoch 4/50
 - 4s - loss: 2375.0115 - val_loss: 469.6154
Epoch 5/50
 - 5s - loss: 2374.4324 - val_loss: 546.0360
Epoch 6/50
 - 5s - loss: 2355.4087 - val_loss: 827.6123
Epoch 7/50
 - 5s - loss: 2388.0880 - val_loss: 632.0538
Epoch 8/50
 - 5s - loss: 2367.0511 - val_loss: 709.5780
Epoch 9/50
 - 5s - loss: 2402.5307 - val_loss: 484.3747
Epoch 10/50
 - 5s - loss: 2373.5063 - val_loss: 636.9831
Epoch 11/50
 - 5s - loss: 2380.2756 - val_loss: 624.5598
Epoch 12/50
 - 5s - loss: 2356.4485 - val_loss: 678.1290
Epoch 13/50
 - 4s - loss: 2380.1791 - val_loss: 485.1096
Epoch 14/50
 - 4s - loss: 2356.7127 - val_loss: 504.3536
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 59120	action = 0	current_phase = 1	next_phase = 0	reward = 0.440517	array([[  2.1565256, -44.418465 ]], dtype=float32)
time = 59125	action = 0	current_phase = 1	next_phase = 0	reward = 0.725462	array([[  2.0541544, -44.14476  ]], dtype=float32)
time = 59130	action = 0	current_phase = 1	next_phase = 0	reward = 1.003643	array([[  2.1838741, -44.516922 ]], dtype=float32)
time = 59135	action = 0	current_phase = 1	next_phase = 0	reward = 0.720034	array([[  2.0941992, -44.244934 ]], dtype=float32)
time = 59140	action = 0	current_phase = 1	next_phase = 0	reward = 0.726596	array([[  2.2140284, -44.61759  ]], dtype=float32)
time = 59145	action = 0	current_phase = 1	next_phase = 0	reward = 0.735663	array([[  2.0697756, -44.191956 ]], dtype=float32)
time = 59150	action = 0	current_phase = 1	next_phase = 0	reward = 0.726682	array([[  2.1844091, -44.507587 ]], dtype=float32)
time = 59155	action = 0	current_phase = 1	next_phase = 0	reward = 0.725798	array([[  2.174739, -44.47277 ]], dtype=float32)
time = 59160	action = 0	current_phase = 1	next_phase = 0	reward = 0.721559	array([[  2.1759958, -44.46531  ]], dtype=float32)
time = 59165	action = 0	current_phase = 1	next_phase = 0	reward = 0.711962	array([[  2.216648, -44.615017]], dtype=float32)
time = 59170	action = 0	current_phase = 1	next_phase = 0	reward = 0.727988	array([[  1.9848366, -43.976612 ]], dtype=float32)
time = 59175	action = 0	current_phase = 1	next_phase = 0	reward = 0.728045	array([[  2.1233206, -44.32409  ]], dtype=float32)
time = 59180	action = 0	current_phase = 1	next_phase = 0	reward = 0.718705	array([[  2.237319, -44.69315 ]], dtype=float32)
time = 59185	action = 0	current_phase = 1	next_phase = 0	reward = 0.721027	array([[  2.1578636, -44.42488  ]], dtype=float32)
time = 59190	action = 0	current_phase = 1	next_phase = 0	reward = 0.725923	array([[  2.1107988, -44.282177 ]], dtype=float32)
time = 59195	action = 0	current_phase = 1	next_phase = 0	reward = 0.723855	array([[  2.0809097, -44.20872  ]], dtype=float32)
time = 59200	action = 0	current_phase = 1	next_phase = 0	reward = 0.723729	array([[  2.1727934, -44.48085  ]], dtype=float32)
time = 59205	action = 0	current_phase = 1	next_phase = 0	reward = 0.717145	array([[  2.1665306, -44.455044 ]], dtype=float32)
time = 59210	action = 0	current_phase = 1	next_phase = 0	reward = 0.730026	array([[  2.1628056, -44.443176 ]], dtype=float32)
time = 59215	action = 0	current_phase = 1	next_phase = 0	reward = 0.723141	array([[  2.1490717, -44.403984 ]], dtype=float32)
time = 59220	action = 0	current_phase = 1	next_phase = 0	reward = 0.707183	array([[  2.0814667, -44.215607 ]], dtype=float32)
time = 59225	action = 0	current_phase = 1	next_phase = 0	reward = 0.439301	array([[  2.1304388, -44.358704 ]], dtype=float32)
time = 59230	action = 0	current_phase = 1	next_phase = 0	reward = 1.009701	array([[  2.1878242, -44.517166 ]], dtype=float32)
time = 59235	action = 0	current_phase = 1	next_phase = 0	reward = 0.715700	array([[  2.1938944, -44.535454 ]], dtype=float32)
time = 59240	action = 0	current_phase = 1	next_phase = 0	reward = 0.715113	array([[  2.2622232, -44.813988 ]], dtype=float32)
time = 59245	action = 0	current_phase = 1	next_phase = 0	reward = 0.438092	array([[  2.1935081, -44.52883  ]], dtype=float32)
time = 59250	action = 0	current_phase = 1	next_phase = 0	reward = 0.717763	array([[  2.040779, -44.105377]], dtype=float32)
time = 59255	action = 0	current_phase = 1	next_phase = 0	reward = 1.007810	array([[  2.153141, -44.414898]], dtype=float32)
time = 59260	action = 0	current_phase = 1	next_phase = 0	reward = 0.721608	array([[  2.0736523, -44.220566 ]], dtype=float32)
time = 59265	action = 0	current_phase = 1	next_phase = 0	reward = 0.727006	array([[  2.1471872, -44.429295 ]], dtype=float32)
time = 59270	action = 0	current_phase = 1	next_phase = 0	reward = 0.721662	array([[  2.12259, -44.31091]], dtype=float32)
time = 59275	action = 0	current_phase = 1	next_phase = 0	reward = 0.729320	array([[  2.0548668, -44.144333 ]], dtype=float32)
time = 59280	action = 0	current_phase = 1	next_phase = 0	reward = 0.719134	array([[  1.9980736, -44.045044 ]], dtype=float32)
time = 59285	action = 0	current_phase = 1	next_phase = 0	reward = 0.450243	array([[  1.9847269, -43.961327 ]], dtype=float32)
time = 59290	action = 0	current_phase = 1	next_phase = 0	reward = 1.002843	array([[  2.1047306, -44.286835 ]], dtype=float32)
time = 59295	action = 0	current_phase = 1	next_phase = 0	reward = 0.716128	array([[  2.1322737, -44.346718 ]], dtype=float32)
time = 59300	action = 0	current_phase = 1	next_phase = 0	reward = 0.712954	array([[  2.249279, -44.774208]], dtype=float32)
time = 59305	action = 0	current_phase = 1	next_phase = 0	reward = 0.714630	array([[  2.1893597, -44.524857 ]], dtype=float32)
time = 59310	action = 0	current_phase = 1	next_phase = 0	reward = 0.708717	array([[  2.181572, -44.4952  ]], dtype=float32)
time = 59315	action = 0	current_phase = 1	next_phase = 0	reward = 0.444516	array([[  2.0969133, -44.24425  ]], dtype=float32)
time = 59320	action = 0	current_phase = 1	next_phase = 0	reward = 1.011912	array([[  2.17795 , -44.487972]], dtype=float32)
time = 59325	action = 0	current_phase = 1	next_phase = 0	reward = 0.450039	array([[  2.1463366, -44.417374 ]], dtype=float32)
time = 59330	action = 0	current_phase = 1	next_phase = 0	reward = 1.006282	array([[  2.175333, -44.468063]], dtype=float32)
time = 59335	action = 0	current_phase = 1	next_phase = 0	reward = 0.721495	array([[  2.1346188, -44.352924 ]], dtype=float32)
time = 59340	action = 0	current_phase = 1	next_phase = 0	reward = 0.715181	array([[  2.1621885, -44.438984 ]], dtype=float32)
time = 59345	action = 0	current_phase = 1	next_phase = 0	reward = 0.442499	array([[  2.228837, -44.660378]], dtype=float32)
time = 59350	action = 0	current_phase = 1	next_phase = 0	reward = 1.002093	array([[  2.1147833, -44.299835 ]], dtype=float32)
time = 59355	action = 0	current_phase = 1	next_phase = 0	reward = 0.720787	array([[  2.197585, -44.545387]], dtype=float32)
time = 59360	action = 0	current_phase = 1	next_phase = 0	reward = 0.722913	array([[  2.1845484, -44.51086  ]], dtype=float32)
time = 59365	action = 0	current_phase = 1	next_phase = 0	reward = 0.718384	array([[  2.1964626, -44.541946 ]], dtype=float32)
time = 59370	action = 0	current_phase = 1	next_phase = 0	reward = 0.715240	array([[  2.1666222, -44.45228  ]], dtype=float32)
time = 59375	action = 0	current_phase = 1	next_phase = 0	reward = 0.436399	array([[  2.0720453, -44.185017 ]], dtype=float32)
time = 59380	action = 0	current_phase = 1	next_phase = 0	reward = 1.011965	array([[  1.9696798, -43.944595 ]], dtype=float32)
time = 59385	action = 0	current_phase = 1	next_phase = 0	reward = 0.722979	array([[  1.8655014, -43.757034 ]], dtype=float32)
time = 59390	action = 0	current_phase = 1	next_phase = 0	reward = 0.723213	array([[  2.1791372, -44.512077 ]], dtype=float32)
time = 59395	action = 0	current_phase = 1	next_phase = 0	reward = 0.722198	array([[  2.1771564, -44.48224  ]], dtype=float32)
time = 59400	action = 0	current_phase = 1	next_phase = 0	reward = 0.721903	array([[  2.066845, -44.178463]], dtype=float32)
time = 59405	action = 0	current_phase = 1	next_phase = 0	reward = 0.719552	array([[  2.1687012, -44.4672   ]], dtype=float32)
time = 59410	action = 0	current_phase = 1	next_phase = 0	reward = 0.715004	array([[  2.2208672, -44.612396 ]], dtype=float32)
time = 59415	action = 0	current_phase = 1	next_phase = 0	reward = 0.719127	array([[  2.1721497, -44.475166 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 382.5370 - val_loss: 423.4532
Epoch 2/50
 - 4s - loss: 393.9873 - val_loss: 469.2019
Epoch 3/50
 - 4s - loss: 393.4049 - val_loss: 541.7221
Epoch 4/50
 - 4s - loss: 366.9001 - val_loss: 514.8119
Epoch 5/50
 - 4s - loss: 375.3654 - val_loss: 516.0881
Epoch 6/50
 - 4s - loss: 365.5460 - val_loss: 516.2835
Epoch 7/50
 - 4s - loss: 366.5548 - val_loss: 510.2806
Epoch 8/50
 - 4s - loss: 368.3482 - val_loss: 492.1309
Epoch 9/50
 - 4s - loss: 356.0321 - val_loss: 533.1951
Epoch 10/50
 - 4s - loss: 373.0027 - val_loss: 506.7169
Epoch 11/50
 - 4s - loss: 362.3977 - val_loss: 497.9737
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 59420	action = 0	current_phase = 1	next_phase = 0	reward = 0.721535	array([[  2.0994778, -44.489212 ]], dtype=float32)
time = 59425	action = 0	current_phase = 1	next_phase = 0	reward = 0.731470	array([[  2.0622673, -44.383812 ]], dtype=float32)
time = 59430	action = 0	current_phase = 1	next_phase = 0	reward = 0.733215	array([[  2.0647554, -44.38241  ]], dtype=float32)
time = 59435	action = 0	current_phase = 1	next_phase = 0	reward = 0.721532	array([[  2.0967703, -44.477333 ]], dtype=float32)
time = 59440	action = 0	current_phase = 1	next_phase = 0	reward = 0.718283	array([[  1.985467, -44.157288]], dtype=float32)
time = 59445	action = 0	current_phase = 1	next_phase = 0	reward = 0.714516	array([[  2.059846, -44.366302]], dtype=float32)
time = 59450	action = 0	current_phase = 1	next_phase = 0	reward = 0.718264	array([[  2.04533 , -44.327835]], dtype=float32)
time = 59455	action = 0	current_phase = 1	next_phase = 0	reward = 0.443910	array([[  1.9600725, -44.093643 ]], dtype=float32)
time = 59460	action = 0	current_phase = 1	next_phase = 0	reward = 1.004169	array([[  2.0957012, -44.530888 ]], dtype=float32)
time = 59465	action = 0	current_phase = 1	next_phase = 0	reward = 0.724731	array([[  1.9917841, -44.29087  ]], dtype=float32)
time = 59470	action = 0	current_phase = 1	next_phase = 0	reward = 0.717283	array([[  2.0896559, -44.49523  ]], dtype=float32)
time = 59475	action = 0	current_phase = 1	next_phase = 0	reward = 0.442901	array([[  2.0503883, -44.35051  ]], dtype=float32)
time = 59480	action = 0	current_phase = 1	next_phase = 0	reward = 1.005753	array([[  1.9129963, -44.00084  ]], dtype=float32)
time = 59485	action = 0	current_phase = 1	next_phase = 0	reward = 0.450304	array([[  2.0278616, -44.267857 ]], dtype=float32)
time = 59490	action = 0	current_phase = 1	next_phase = 0	reward = 0.993783	array([[  2.1166048, -44.633644 ]], dtype=float32)
time = 59495	action = 0	current_phase = 1	next_phase = 0	reward = 0.715559	array([[  2.0987482, -44.533752 ]], dtype=float32)
time = 59500	action = 0	current_phase = 1	next_phase = 0	reward = 0.443276	array([[  2.1197681, -44.613804 ]], dtype=float32)
time = 59505	action = 0	current_phase = 1	next_phase = 0	reward = 1.003986	array([[  2.0265493, -44.253296 ]], dtype=float32)
time = 59510	action = 0	current_phase = 1	next_phase = 0	reward = 0.727641	array([[  2.1152172, -44.60235  ]], dtype=float32)
time = 59515	action = 0	current_phase = 1	next_phase = 0	reward = 0.725266	array([[  1.9730768, -44.109016 ]], dtype=float32)
time = 59520	action = 0	current_phase = 1	next_phase = 0	reward = 0.724518	array([[  2.0695648, -44.401398 ]], dtype=float32)
time = 59525	action = 0	current_phase = 1	next_phase = 0	reward = 0.722475	array([[  2.0140705, -44.226486 ]], dtype=float32)
time = 59530	action = 0	current_phase = 1	next_phase = 0	reward = 0.718589	array([[  2.0550652, -44.360825 ]], dtype=float32)
time = 59535	action = 0	current_phase = 1	next_phase = 0	reward = 0.449153	array([[  1.9704838, -44.099274 ]], dtype=float32)
time = 59540	action = 0	current_phase = 1	next_phase = 0	reward = 1.000797	array([[  2.085845, -44.460976]], dtype=float32)
time = 59545	action = 0	current_phase = 1	next_phase = 0	reward = 0.715916	array([[  2.1145391, -44.592625 ]], dtype=float32)
time = 59550	action = 0	current_phase = 1	next_phase = 0	reward = 0.714285	array([[  2.021494, -44.251373]], dtype=float32)
time = 59555	action = 0	current_phase = 1	next_phase = 0	reward = 0.710008	array([[  2.0370579, -44.299164 ]], dtype=float32)
time = 59560	action = 0	current_phase = 1	next_phase = 0	reward = 0.719255	array([[  2.0055943, -44.195183 ]], dtype=float32)
time = 59565	action = 0	current_phase = 1	next_phase = 0	reward = 0.719699	array([[  2.1022158, -44.529236 ]], dtype=float32)
time = 59570	action = 0	current_phase = 1	next_phase = 0	reward = 0.444843	array([[  2.0755835, -44.430683 ]], dtype=float32)
time = 59575	action = 0	current_phase = 1	next_phase = 0	reward = 1.000323	array([[  2.0751524, -44.4423   ]], dtype=float32)
time = 59580	action = 0	current_phase = 1	next_phase = 0	reward = 0.718678	array([[  2.0018454, -44.19454  ]], dtype=float32)
time = 59585	action = 0	current_phase = 1	next_phase = 0	reward = 0.719836	array([[  2.061038, -44.375877]], dtype=float32)
time = 59590	action = 0	current_phase = 1	next_phase = 0	reward = 0.717576	array([[  1.9898739, -44.18905  ]], dtype=float32)
time = 59595	action = 0	current_phase = 1	next_phase = 0	reward = 0.719233	array([[  2.0345383, -44.28514  ]], dtype=float32)
time = 59600	action = 0	current_phase = 1	next_phase = 0	reward = 0.721710	array([[  2.0914307, -44.48829  ]], dtype=float32)
time = 59605	action = 0	current_phase = 1	next_phase = 0	reward = 0.733003	array([[  2.0736265, -44.415924 ]], dtype=float32)
time = 59610	action = 0	current_phase = 1	next_phase = 0	reward = 0.724718	array([[  2.0547771, -44.438072 ]], dtype=float32)
time = 59615	action = 0	current_phase = 1	next_phase = 0	reward = 0.716253	array([[  2.0540333, -44.34543  ]], dtype=float32)
time = 59620	action = 0	current_phase = 1	next_phase = 0	reward = 0.719268	array([[  2.006343, -44.256485]], dtype=float32)
time = 59625	action = 0	current_phase = 1	next_phase = 0	reward = 0.720899	array([[  2.048605, -44.33024 ]], dtype=float32)
time = 59630	action = 0	current_phase = 1	next_phase = 0	reward = 0.728824	array([[  2.0589933, -44.36281  ]], dtype=float32)
time = 59635	action = 0	current_phase = 1	next_phase = 0	reward = 0.720555	array([[  2.087162, -44.47511 ]], dtype=float32)
time = 59640	action = 0	current_phase = 1	next_phase = 0	reward = 0.718290	array([[  2.0284548, -44.267113 ]], dtype=float32)
time = 59645	action = 0	current_phase = 1	next_phase = 0	reward = 0.719818	array([[  2.0624924, -44.392353 ]], dtype=float32)
time = 59650	action = 0	current_phase = 1	next_phase = 0	reward = 0.724888	array([[  2.0806055, -44.450714 ]], dtype=float32)
time = 59655	action = 0	current_phase = 1	next_phase = 0	reward = 0.721595	array([[  2.0863924, -44.477936 ]], dtype=float32)
time = 59660	action = 0	current_phase = 1	next_phase = 0	reward = 0.727429	array([[  2.099349, -44.49206 ]], dtype=float32)
time = 59665	action = 0	current_phase = 1	next_phase = 0	reward = 0.723992	array([[  2.0966063, -44.52211  ]], dtype=float32)
time = 59670	action = 0	current_phase = 1	next_phase = 0	reward = 0.441863	array([[  2.0630007, -44.385216 ]], dtype=float32)
time = 59675	action = 0	current_phase = 1	next_phase = 0	reward = 0.989900	array([[  2.0503712, -44.339443 ]], dtype=float32)
time = 59680	action = 0	current_phase = 1	next_phase = 0	reward = 0.433621	array([[  2.0733213, -44.424355 ]], dtype=float32)
time = 59685	action = 0	current_phase = 1	next_phase = 0	reward = 1.006887	array([[  1.9823542, -44.127617 ]], dtype=float32)
time = 59690	action = 0	current_phase = 1	next_phase = 0	reward = 0.724325	array([[  2.0521955, -44.348656 ]], dtype=float32)
time = 59695	action = 0	current_phase = 1	next_phase = 0	reward = 0.720437	array([[  2.0433588, -44.318256 ]], dtype=float32)
time = 59700	action = 0	current_phase = 1	next_phase = 0	reward = 0.719243	array([[  2.0754337, -44.419403 ]], dtype=float32)
time = 59705	action = 0	current_phase = 1	next_phase = 0	reward = 0.718729	array([[  1.9719582, -44.107334 ]], dtype=float32)
time = 59710	action = 0	current_phase = 1	next_phase = 0	reward = 0.722170	array([[  1.9797611, -44.184456 ]], dtype=float32)
time = 59715	action = 0	current_phase = 1	next_phase = 0	reward = 0.724675	array([[  2.1147528, -44.59935  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2336.4990 - val_loss: 547.8164
Epoch 2/50
 - 4s - loss: 2356.0507 - val_loss: 542.0586
Epoch 3/50
 - 4s - loss: 2346.5920 - val_loss: 572.0396
Epoch 4/50
 - 4s - loss: 2354.4410 - val_loss: 575.9626
Epoch 5/50
 - 4s - loss: 2338.6852 - val_loss: 709.5781
Epoch 6/50
 - 4s - loss: 2343.9437 - val_loss: 540.5286
Epoch 7/50
 - 4s - loss: 2343.3908 - val_loss: 546.7311
Epoch 8/50
 - 4s - loss: 2338.5995 - val_loss: 580.0532
Epoch 9/50
 - 4s - loss: 2317.2048 - val_loss: 553.4120
Epoch 10/50
 - 4s - loss: 2338.4387 - val_loss: 560.5569
Epoch 11/50
 - 4s - loss: 2320.0115 - val_loss: 437.2021
Epoch 12/50
 - 4s - loss: 2340.1679 - val_loss: 570.7147
Epoch 13/50
 - 4s - loss: 2308.4776 - val_loss: 544.9019
Epoch 14/50
 - 4s - loss: 2307.7771 - val_loss: 560.9309
Epoch 15/50
 - 4s - loss: 2297.7948 - val_loss: 492.3811
Epoch 16/50
 - 4s - loss: 2309.5043 - val_loss: 473.8228
Epoch 17/50
 - 4s - loss: 2306.1453 - val_loss: 477.0355
Epoch 18/50
 - 4s - loss: 2318.1708 - val_loss: 506.2646
Epoch 19/50
 - 4s - loss: 2314.3842 - val_loss: 590.9739
Epoch 20/50
 - 4s - loss: 2325.2319 - val_loss: 511.3806
Epoch 21/50
 - 4s - loss: 2303.7791 - val_loss: 503.7474
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 59720	action = 0	current_phase = 1	next_phase = 0	reward = 0.725041	array([[  2.0619507, -44.338203 ]], dtype=float32)
time = 59725	action = 0	current_phase = 1	next_phase = 0	reward = 0.721483	array([[  2.0421295, -44.231804 ]], dtype=float32)
time = 59730	action = 0	current_phase = 1	next_phase = 0	reward = 0.438346	array([[  2.0515518, -44.26339  ]], dtype=float32)
time = 59735	action = 0	current_phase = 1	next_phase = 0	reward = 0.997024	array([[  2.0747728, -44.40313  ]], dtype=float32)
time = 59740	action = 0	current_phase = 1	next_phase = 0	reward = 0.708194	array([[  2.0410213, -44.230316 ]], dtype=float32)
time = 59745	action = 0	current_phase = 1	next_phase = 0	reward = 0.718934	array([[  2.076313, -44.398655]], dtype=float32)
time = 59750	action = 0	current_phase = 1	next_phase = 0	reward = 0.439111	array([[  2.0714092, -44.36702  ]], dtype=float32)
time = 59755	action = 0	current_phase = 1	next_phase = 0	reward = 0.723573	array([[  2.083621, -44.496853]], dtype=float32)
time = 59760	action = 0	current_phase = 1	next_phase = 0	reward = 1.011315	array([[  2.0288382, -44.178047 ]], dtype=float32)
time = 59765	action = 0	current_phase = 1	next_phase = 0	reward = 0.444086	array([[  2.0243673, -44.177048 ]], dtype=float32)
time = 59770	action = 0	current_phase = 1	next_phase = 0	reward = 1.006545	array([[  2.0213442, -44.156612 ]], dtype=float32)
time = 59775	action = 0	current_phase = 1	next_phase = 0	reward = 0.722289	array([[  2.0511894, -44.27429  ]], dtype=float32)
time = 59780	action = 0	current_phase = 1	next_phase = 0	reward = 0.721412	array([[  2.0708876, -44.38519  ]], dtype=float32)
time = 59785	action = 0	current_phase = 1	next_phase = 0	reward = 0.726441	array([[  2.038536, -44.23893 ]], dtype=float32)
time = 59790	action = 0	current_phase = 1	next_phase = 0	reward = 0.722602	array([[  2.0793076, -44.440025 ]], dtype=float32)
time = 59795	action = 0	current_phase = 1	next_phase = 0	reward = 0.724176	array([[  2.0747042, -44.382042 ]], dtype=float32)
time = 59800	action = 0	current_phase = 1	next_phase = 0	reward = 0.725463	array([[  1.9701633, -44.01481  ]], dtype=float32)
time = 59805	action = 0	current_phase = 1	next_phase = 0	reward = 0.727479	array([[  2.0727339, -44.39364  ]], dtype=float32)
time = 59810	action = 0	current_phase = 1	next_phase = 0	reward = 0.723325	array([[  2.081812, -44.44821 ]], dtype=float32)
time = 59815	action = 0	current_phase = 1	next_phase = 0	reward = 0.721474	array([[  1.9749641, -44.040615 ]], dtype=float32)
time = 59820	action = 0	current_phase = 1	next_phase = 0	reward = 0.710638	array([[  2.0322933, -44.196793 ]], dtype=float32)
time = 59825	action = 0	current_phase = 1	next_phase = 0	reward = 0.721909	array([[  2.0533066, -44.29992  ]], dtype=float32)
time = 59830	action = 0	current_phase = 1	next_phase = 0	reward = 0.719154	array([[  2.0439873, -44.238678 ]], dtype=float32)
time = 59835	action = 0	current_phase = 1	next_phase = 0	reward = 0.720495	array([[  2.078477, -44.427696]], dtype=float32)
time = 59840	action = 0	current_phase = 1	next_phase = 0	reward = 0.719526	array([[  2.0586615, -44.300842 ]], dtype=float32)
time = 59845	action = 0	current_phase = 1	next_phase = 0	reward = 0.718743	array([[  2.000368, -44.076607]], dtype=float32)
time = 59850	action = 0	current_phase = 1	next_phase = 0	reward = 0.716454	array([[  2.049487, -44.282387]], dtype=float32)
time = 59855	action = 0	current_phase = 1	next_phase = 0	reward = 0.717072	array([[  2.065508, -44.341484]], dtype=float32)
time = 59860	action = 0	current_phase = 1	next_phase = 0	reward = 0.709177	array([[  2.0393658, -44.191574 ]], dtype=float32)
time = 59865	action = 0	current_phase = 1	next_phase = 0	reward = 0.716156	array([[  1.9943886, -44.05471  ]], dtype=float32)
time = 59870	action = 0	current_phase = 1	next_phase = 0	reward = 0.448470	array([[  1.9936543, -44.052456 ]], dtype=float32)
time = 59875	action = 0	current_phase = 1	next_phase = 0	reward = 1.002995	array([[  2.0027113, -44.1016   ]], dtype=float32)
time = 59880	action = 0	current_phase = 1	next_phase = 0	reward = 0.713679	array([[  2.041253, -44.200783]], dtype=float32)
time = 59885	action = 0	current_phase = 1	next_phase = 0	reward = 0.718137	array([[  2.0400372, -44.210278 ]], dtype=float32)
time = 59890	action = 0	current_phase = 1	next_phase = 0	reward = 0.716510	array([[  2.0262632, -44.196587 ]], dtype=float32)
time = 59895	action = 0	current_phase = 1	next_phase = 0	reward = 0.727017	array([[  2.0472975, -44.292755 ]], dtype=float32)
time = 59900	action = 0	current_phase = 1	next_phase = 0	reward = 0.718633	array([[  1.984415, -44.043327]], dtype=float32)
time = 59905	action = 0	current_phase = 1	next_phase = 0	reward = 0.439790	array([[  2.0528755, -44.3014   ]], dtype=float32)
time = 59910	action = 0	current_phase = 1	next_phase = 0	reward = 0.722875	array([[  2.0799007, -44.494747 ]], dtype=float32)
time = 59915	action = 0	current_phase = 1	next_phase = 0	reward = 1.012940	array([[  2.0548458, -44.31332  ]], dtype=float32)
time = 59920	action = 0	current_phase = 1	next_phase = 0	reward = 0.722533	array([[  2.0847893, -44.46647  ]], dtype=float32)
time = 59925	action = 0	current_phase = 1	next_phase = 0	reward = 0.723255	array([[  2.0609055, -44.331192 ]], dtype=float32)
time = 59930	action = 0	current_phase = 1	next_phase = 0	reward = 0.718408	array([[  2.0430622, -44.25148  ]], dtype=float32)
time = 59935	action = 0	current_phase = 1	next_phase = 0	reward = 0.711956	array([[  1.981246, -44.016335]], dtype=float32)
time = 59940	action = 0	current_phase = 1	next_phase = 0	reward = 0.718676	array([[  2.025424, -44.195103]], dtype=float32)
time = 59945	action = 0	current_phase = 1	next_phase = 0	reward = 0.721419	array([[  2.0901976, -44.44491  ]], dtype=float32)
time = 59950	action = 0	current_phase = 1	next_phase = 0	reward = 0.728737	array([[  1.9335995, -43.8868   ]], dtype=float32)
time = 59955	action = 0	current_phase = 1	next_phase = 0	reward = 0.723907	array([[  2.0635672, -44.32688  ]], dtype=float32)
time = 59960	action = 0	current_phase = 1	next_phase = 0	reward = 0.712238	array([[  1.9859858, -44.020298 ]], dtype=float32)
time = 59965	action = 0	current_phase = 1	next_phase = 0	reward = 0.715836	array([[  2.0200443, -44.15641  ]], dtype=float32)
time = 59970	action = 0	current_phase = 1	next_phase = 0	reward = 0.718390	array([[  2.0021658, -44.076393 ]], dtype=float32)
time = 59975	action = 0	current_phase = 1	next_phase = 0	reward = 0.716085	array([[  1.9828882, -44.06856  ]], dtype=float32)
time = 59980	action = 0	current_phase = 1	next_phase = 0	reward = 0.726759	array([[  2.0379467, -44.23874  ]], dtype=float32)
time = 59985	action = 0	current_phase = 1	next_phase = 0	reward = 0.728316	array([[  1.9558821, -43.942596 ]], dtype=float32)
time = 59990	action = 0	current_phase = 1	next_phase = 0	reward = 0.721737	array([[  2.0703678, -44.395016 ]], dtype=float32)
time = 59995	action = 0	current_phase = 1	next_phase = 0	reward = 0.721311	array([[  2.0666294, -44.351192 ]], dtype=float32)
time = 60000	action = 0	current_phase = 1	next_phase = 0	reward = 0.720842	array([[  1.9099703, -43.831516 ]], dtype=float32)
time = 60005	action = 0	current_phase = 1	next_phase = 0	reward = 0.721827	array([[  2.0570927, -44.304756 ]], dtype=float32)
time = 60010	action = 0	current_phase = 1	next_phase = 0	reward = 0.723735	array([[  2.0555058, -44.304207 ]], dtype=float32)
time = 60015	action = 0	current_phase = 1	next_phase = 0	reward = 0.724095	array([[  2.0481377, -44.2959   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 474.4444 - val_loss: 4511.6906
Epoch 2/50
 - 4s - loss: 449.9212 - val_loss: 4545.2874
Epoch 3/50
 - 4s - loss: 442.9783 - val_loss: 4525.5954
Epoch 4/50
 - 4s - loss: 441.5272 - val_loss: 4551.6779
Epoch 5/50
 - 4s - loss: 453.0126 - val_loss: 4537.1745
Epoch 6/50
 - 4s - loss: 455.4298 - val_loss: 4533.3745
Epoch 7/50
 - 4s - loss: 446.6166 - val_loss: 4546.6556
Epoch 8/50
 - 4s - loss: 448.8237 - val_loss: 4541.8873
Epoch 9/50
 - 4s - loss: 476.8970 - val_loss: 4527.6158
Epoch 10/50
 - 4s - loss: 435.0877 - val_loss: 4547.3510
Epoch 11/50
 - 4s - loss: 445.8816 - val_loss: 4523.0429
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 60020	action = 0	current_phase = 1	next_phase = 0	reward = 0.443601	array([[  2.0366936, -44.435364 ]], dtype=float32)
time = 60025	action = 0	current_phase = 1	next_phase = 0	reward = 0.999696	array([[  2.059248, -44.435303]], dtype=float32)
time = 60030	action = 0	current_phase = 1	next_phase = 0	reward = 0.723763	array([[  2.0396185, -44.45414  ]], dtype=float32)
time = 60035	action = 0	current_phase = 1	next_phase = 0	reward = 0.446151	array([[  2.0378008, -44.429855 ]], dtype=float32)
time = 60040	action = 0	current_phase = 1	next_phase = 0	reward = 1.007541	array([[  2.0440245, -44.49469  ]], dtype=float32)
time = 60045	action = 0	current_phase = 1	next_phase = 0	reward = 0.724328	array([[  2.014554, -44.2573  ]], dtype=float32)
time = 60050	action = 0	current_phase = 1	next_phase = 0	reward = 0.719808	array([[  2.0427284, -44.465218 ]], dtype=float32)
time = 60055	action = 0	current_phase = 1	next_phase = 0	reward = 0.723576	array([[  2.0413637, -44.48166  ]], dtype=float32)
time = 60060	action = 0	current_phase = 1	next_phase = 0	reward = 0.721640	array([[  2.013547, -44.38253 ]], dtype=float32)
time = 60065	action = 0	current_phase = 1	next_phase = 0	reward = 0.716844	array([[  2.0139894, -44.27597  ]], dtype=float32)
time = 60070	action = 0	current_phase = 1	next_phase = 0	reward = 0.433679	array([[  2.0480108, -44.48007  ]], dtype=float32)
time = 60075	action = 0	current_phase = 1	next_phase = 0	reward = 1.001227	array([[  2.014779, -44.305996]], dtype=float32)
time = 60080	action = 0	current_phase = 1	next_phase = 0	reward = 0.441760	array([[  2.0440578, -44.437004 ]], dtype=float32)
time = 60085	action = 0	current_phase = 1	next_phase = 0	reward = 1.002503	array([[  2.0262623, -44.38768  ]], dtype=float32)
time = 60090	action = 0	current_phase = 1	next_phase = 0	reward = 0.439274	array([[  2.0009823, -44.22088  ]], dtype=float32)
time = 60095	action = 0	current_phase = 1	next_phase = 0	reward = 0.997946	array([[  2.0248594, -44.41647  ]], dtype=float32)
time = 60100	action = 0	current_phase = 1	next_phase = 0	reward = 0.446484	array([[  2.0451155, -44.45684  ]], dtype=float32)
time = 60105	action = 0	current_phase = 1	next_phase = 0	reward = 1.002786	array([[  1.9867773, -44.21614  ]], dtype=float32)
time = 60110	action = 0	current_phase = 1	next_phase = 0	reward = 0.446312	array([[  1.9917088, -44.226883 ]], dtype=float32)
time = 60115	action = 0	current_phase = 1	next_phase = 0	reward = 1.012319	array([[  1.9560328, -44.11649  ]], dtype=float32)
time = 60120	action = 0	current_phase = 1	next_phase = 0	reward = 0.720387	array([[  2.0371113, -44.44754  ]], dtype=float32)
time = 60125	action = 0	current_phase = 1	next_phase = 0	reward = 0.717469	array([[  2.0367966, -44.453217 ]], dtype=float32)
time = 60130	action = 0	current_phase = 1	next_phase = 0	reward = 0.722694	array([[  2.0404644, -44.445793 ]], dtype=float32)
time = 60135	action = 0	current_phase = 1	next_phase = 0	reward = 0.722529	array([[  2.0449514, -44.50393  ]], dtype=float32)
time = 60140	action = 0	current_phase = 1	next_phase = 0	reward = 0.717332	array([[  1.9995451, -44.2305   ]], dtype=float32)
time = 60145	action = 0	current_phase = 1	next_phase = 0	reward = 0.721000	array([[  2.0209837, -44.338127 ]], dtype=float32)
time = 60150	action = 0	current_phase = 1	next_phase = 0	reward = 0.719184	array([[  2.027835, -44.383587]], dtype=float32)
time = 60155	action = 0	current_phase = 1	next_phase = 0	reward = 0.439493	array([[  2.0580359, -44.547752 ]], dtype=float32)
time = 60160	action = 0	current_phase = 1	next_phase = 0	reward = 1.008695	array([[  2.0009146, -44.22191  ]], dtype=float32)
time = 60165	action = 0	current_phase = 1	next_phase = 0	reward = 0.718286	array([[  2.00348, -44.29373]], dtype=float32)
time = 60170	action = 0	current_phase = 1	next_phase = 0	reward = 0.717594	array([[  2.0357447, -44.438496 ]], dtype=float32)
time = 60175	action = 0	current_phase = 1	next_phase = 0	reward = 0.439087	array([[  2.00352, -44.31201]], dtype=float32)
time = 60180	action = 0	current_phase = 1	next_phase = 0	reward = 1.005098	array([[  1.9663029, -44.119072 ]], dtype=float32)
time = 60185	action = 0	current_phase = 1	next_phase = 0	reward = 0.719533	array([[  2.0269432, -44.50437  ]], dtype=float32)
time = 60190	action = 0	current_phase = 1	next_phase = 0	reward = 0.447810	array([[  2.0211267, -44.332775 ]], dtype=float32)
time = 60195	action = 0	current_phase = 1	next_phase = 0	reward = 1.002717	array([[  2.042284, -44.464226]], dtype=float32)
time = 60200	action = 0	current_phase = 1	next_phase = 0	reward = 0.722451	array([[  2.051794, -44.49405 ]], dtype=float32)
time = 60205	action = 0	current_phase = 1	next_phase = 0	reward = 0.444754	array([[  2.0455856, -44.4629   ]], dtype=float32)
time = 60210	action = 0	current_phase = 1	next_phase = 0	reward = 1.011069	array([[  2.0368357, -44.466255 ]], dtype=float32)
time = 60215	action = 0	current_phase = 1	next_phase = 0	reward = 0.724619	array([[  1.9940786, -44.206505 ]], dtype=float32)
time = 60220	action = 0	current_phase = 1	next_phase = 0	reward = 0.719470	array([[  2.030673, -44.399864]], dtype=float32)
time = 60225	action = 0	current_phase = 1	next_phase = 0	reward = 0.434003	array([[  1.9875364, -44.20388  ]], dtype=float32)
time = 60230	action = 0	current_phase = 1	next_phase = 0	reward = 1.004549	array([[  2.0362854, -44.506462 ]], dtype=float32)
time = 60235	action = 0	current_phase = 1	next_phase = 0	reward = 0.721308	array([[  1.981204, -44.134193]], dtype=float32)
time = 60240	action = 0	current_phase = 1	next_phase = 0	reward = 0.719145	array([[  2.0420446, -44.505184 ]], dtype=float32)
time = 60245	action = 0	current_phase = 1	next_phase = 0	reward = 0.440852	array([[  2.0432606, -44.542053 ]], dtype=float32)
time = 60250	action = 0	current_phase = 1	next_phase = 0	reward = 0.724357	array([[  2.0536766, -44.53306  ]], dtype=float32)
time = 60255	action = 0	current_phase = 1	next_phase = 0	reward = 0.995763	array([[  2.0232124, -44.300793 ]], dtype=float32)
time = 60260	action = 0	current_phase = 1	next_phase = 0	reward = 0.446153	array([[  1.9956913, -44.258476 ]], dtype=float32)
time = 60265	action = 0	current_phase = 1	next_phase = 0	reward = 1.003720	array([[  2.0433655, -44.541954 ]], dtype=float32)
time = 60270	action = 0	current_phase = 1	next_phase = 0	reward = 0.437724	array([[  2.032217, -44.473232]], dtype=float32)
time = 60275	action = 0	current_phase = 1	next_phase = 0	reward = 0.989530	array([[  2.0580082, -44.53672  ]], dtype=float32)
time = 60280	action = 0	current_phase = 1	next_phase = 0	reward = 0.712172	array([[  2.0185404, -44.28118  ]], dtype=float32)
time = 60285	action = 0	current_phase = 1	next_phase = 0	reward = 0.718165	array([[  2.0359135, -44.428574 ]], dtype=float32)
time = 60290	action = 0	current_phase = 1	next_phase = 0	reward = 0.167494	array([[  2.0392723, -44.49497  ]], dtype=float32)
time = 60295	action = 0	current_phase = 1	next_phase = 0	reward = 1.298002	array([[  2.0388956, -44.43701  ]], dtype=float32)
time = 60300	action = 0	current_phase = 1	next_phase = 0	reward = 0.723455	array([[  2.0357847, -44.378082 ]], dtype=float32)
time = 60305	action = 0	current_phase = 1	next_phase = 0	reward = 0.724635	array([[  2.0390549, -44.44628  ]], dtype=float32)
time = 60310	action = 0	current_phase = 1	next_phase = 0	reward = 0.715852	array([[  2.0182943, -44.28147  ]], dtype=float32)
time = 60315	action = 0	current_phase = 1	next_phase = 0	reward = 0.723211	array([[  2.0429926, -44.47409  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2413.4939 - val_loss: 368.2013
Epoch 2/50
 - 4s - loss: 2433.1062 - val_loss: 372.9552
Epoch 3/50
 - 4s - loss: 2411.8658 - val_loss: 418.1305
Epoch 4/50
 - 4s - loss: 2471.9640 - val_loss: 410.1044
Epoch 5/50
 - 4s - loss: 2412.3922 - val_loss: 394.0985
Epoch 6/50
 - 4s - loss: 2409.9161 - val_loss: 367.2195
Epoch 7/50
 - 4s - loss: 2412.6451 - val_loss: 363.5407
Epoch 8/50
 - 4s - loss: 2446.0323 - val_loss: 373.4126
Epoch 9/50
 - 4s - loss: 2405.2993 - val_loss: 361.4885
Epoch 10/50
 - 4s - loss: 2397.4538 - val_loss: 366.1221
Epoch 11/50
 - 4s - loss: 2389.1095 - val_loss: 380.0649
Epoch 12/50
 - 4s - loss: 2399.9668 - val_loss: 380.2414
Epoch 13/50
 - 4s - loss: 2388.1433 - val_loss: 380.1705
Epoch 14/50
 - 4s - loss: 2396.4628 - val_loss: 362.0054
Epoch 15/50
 - 4s - loss: 2420.7421 - val_loss: 365.5327
Epoch 16/50
 - 4s - loss: 2415.4307 - val_loss: 369.9214
Epoch 17/50
 - 4s - loss: 2398.9885 - val_loss: 391.5621
Epoch 18/50
 - 4s - loss: 2427.9673 - val_loss: 368.0717
Epoch 19/50
 - 4s - loss: 2408.7922 - val_loss: 374.0256
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 60320	action = 0	current_phase = 1	next_phase = 0	reward = 0.724846	array([[  2.2567434, -44.752426 ]], dtype=float32)
time = 60325	action = 0	current_phase = 1	next_phase = 0	reward = 0.441173	array([[  2.255251, -44.740368]], dtype=float32)
time = 60330	action = 0	current_phase = 1	next_phase = 0	reward = 1.001049	array([[  2.2552567, -44.7539   ]], dtype=float32)
time = 60335	action = 0	current_phase = 1	next_phase = 0	reward = 0.716049	array([[  2.169711, -44.385166]], dtype=float32)
time = 60340	action = 0	current_phase = 1	next_phase = 0	reward = 0.441838	array([[  2.26124 , -44.733437]], dtype=float32)
time = 60345	action = 0	current_phase = 1	next_phase = 0	reward = 1.005883	array([[  2.210678, -44.51851 ]], dtype=float32)
time = 60350	action = 0	current_phase = 1	next_phase = 0	reward = 0.716504	array([[  2.1994047, -44.473625 ]], dtype=float32)
time = 60355	action = 0	current_phase = 1	next_phase = 0	reward = 0.716764	array([[  2.1953754, -44.48108  ]], dtype=float32)
time = 60360	action = 0	current_phase = 1	next_phase = 0	reward = 0.171852	array([[  2.2402906, -44.63658  ]], dtype=float32)
time = 60365	action = 0	current_phase = 1	next_phase = 0	reward = 1.296612	array([[  2.1035433, -44.18006  ]], dtype=float32)
time = 60370	action = 0	current_phase = 1	next_phase = 0	reward = 0.723400	array([[  2.1681242, -44.35805  ]], dtype=float32)
time = 60375	action = 0	current_phase = 1	next_phase = 0	reward = 0.720281	array([[  2.179634, -44.482235]], dtype=float32)
time = 60380	action = 0	current_phase = 1	next_phase = 0	reward = 0.716269	array([[  2.2506056, -44.70318  ]], dtype=float32)
time = 60385	action = 0	current_phase = 1	next_phase = 0	reward = 0.718253	array([[  2.2050428, -44.49743  ]], dtype=float32)
time = 60390	action = 0	current_phase = 1	next_phase = 0	reward = 0.725452	array([[  2.2244616, -44.56458  ]], dtype=float32)
time = 60395	action = 0	current_phase = 1	next_phase = 0	reward = 0.721105	array([[  2.1453218, -44.331055 ]], dtype=float32)
time = 60400	action = 0	current_phase = 1	next_phase = 0	reward = 0.723846	array([[  2.2493677, -44.68888  ]], dtype=float32)
time = 60405	action = 0	current_phase = 1	next_phase = 0	reward = 0.445079	array([[  2.213354, -44.57269 ]], dtype=float32)
time = 60410	action = 0	current_phase = 1	next_phase = 0	reward = 1.001931	array([[  2.2450218, -44.678696 ]], dtype=float32)
time = 60415	action = 0	current_phase = 1	next_phase = 0	reward = 0.722509	array([[  2.253686, -44.782238]], dtype=float32)
time = 60420	action = 0	current_phase = 1	next_phase = 0	reward = 0.721301	array([[  2.1789932, -44.39549  ]], dtype=float32)
time = 60425	action = 0	current_phase = 1	next_phase = 0	reward = 0.718689	array([[  2.2561054, -44.76763  ]], dtype=float32)
time = 60430	action = 0	current_phase = 1	next_phase = 0	reward = 0.717138	array([[  2.2248945, -44.53496  ]], dtype=float32)
time = 60435	action = 0	current_phase = 1	next_phase = 0	reward = 0.440838	array([[  2.240408, -44.654457]], dtype=float32)
time = 60440	action = 0	current_phase = 1	next_phase = 0	reward = 1.001015	array([[  2.202773, -44.473377]], dtype=float32)
time = 60445	action = 0	current_phase = 1	next_phase = 0	reward = 0.722306	array([[  2.2510939, -44.69345  ]], dtype=float32)
time = 60450	action = 0	current_phase = 1	next_phase = 0	reward = 0.721775	array([[  2.1834126, -44.42959  ]], dtype=float32)
time = 60455	action = 0	current_phase = 1	next_phase = 0	reward = 0.440826	array([[  2.1846752, -44.410652 ]], dtype=float32)
time = 60460	action = 0	current_phase = 1	next_phase = 0	reward = 0.734772	array([[  2.2439194, -44.677128 ]], dtype=float32)
time = 60465	action = 0	current_phase = 1	next_phase = 0	reward = 1.008676	array([[  2.2426605, -44.67382  ]], dtype=float32)
time = 60470	action = 0	current_phase = 1	next_phase = 0	reward = 0.724984	array([[  2.2290268, -44.665894 ]], dtype=float32)
time = 60475	action = 0	current_phase = 1	next_phase = 0	reward = 0.722279	array([[  2.2470446, -44.707226 ]], dtype=float32)
time = 60480	action = 0	current_phase = 1	next_phase = 0	reward = 0.724469	array([[  2.1524658, -44.38179  ]], dtype=float32)
time = 60485	action = 0	current_phase = 1	next_phase = 0	reward = 0.723649	array([[  2.2209358, -44.558052 ]], dtype=float32)
time = 60490	action = 0	current_phase = 1	next_phase = 0	reward = 0.713383	array([[  2.1793213, -44.39331  ]], dtype=float32)
time = 60495	action = 0	current_phase = 1	next_phase = 0	reward = 0.720047	array([[  2.249443, -44.70752 ]], dtype=float32)
time = 60500	action = 0	current_phase = 1	next_phase = 0	reward = 0.711185	array([[  2.2485437, -44.700157 ]], dtype=float32)
time = 60505	action = 0	current_phase = 1	next_phase = 0	reward = 0.722303	array([[  2.196105, -44.482754]], dtype=float32)
time = 60510	action = 0	current_phase = 1	next_phase = 0	reward = 0.720745	array([[  2.131528, -44.246468]], dtype=float32)
time = 60515	action = 0	current_phase = 1	next_phase = 0	reward = 0.446292	array([[  2.1098824, -44.264294 ]], dtype=float32)
time = 60520	action = 0	current_phase = 1	next_phase = 0	reward = 1.004658	array([[  2.2665825, -44.79155  ]], dtype=float32)
time = 60525	action = 0	current_phase = 1	next_phase = 0	reward = 0.719590	array([[  2.0891323, -44.224495 ]], dtype=float32)
time = 60530	action = 0	current_phase = 1	next_phase = 0	reward = 0.714465	array([[  2.200797, -44.4746  ]], dtype=float32)
time = 60535	action = 0	current_phase = 1	next_phase = 0	reward = 0.439099	array([[  2.2053356, -44.496582 ]], dtype=float32)
time = 60540	action = 0	current_phase = 1	next_phase = 0	reward = 1.006844	array([[  2.2010603, -44.52198  ]], dtype=float32)
time = 60545	action = 0	current_phase = 1	next_phase = 0	reward = 0.723020	array([[  2.2248516, -44.64875  ]], dtype=float32)
time = 60550	action = 0	current_phase = 1	next_phase = 0	reward = 0.720980	array([[  2.196208, -44.46157 ]], dtype=float32)
time = 60555	action = 0	current_phase = 1	next_phase = 0	reward = 0.727367	array([[  2.2505474, -44.691105 ]], dtype=float32)
time = 60560	action = 0	current_phase = 1	next_phase = 0	reward = 0.729941	array([[  2.206808, -44.48526 ]], dtype=float32)
time = 60565	action = 0	current_phase = 1	next_phase = 0	reward = 0.713090	array([[  2.237914, -44.609955]], dtype=float32)
time = 60570	action = 0	current_phase = 1	next_phase = 0	reward = 0.709097	array([[  2.2471905, -44.657608 ]], dtype=float32)
time = 60575	action = 0	current_phase = 1	next_phase = 0	reward = 0.715847	array([[  2.2416925, -44.62564  ]], dtype=float32)
time = 60580	action = 0	current_phase = 1	next_phase = 0	reward = 0.724423	array([[  2.1666346, -44.357914 ]], dtype=float32)
time = 60585	action = 0	current_phase = 1	next_phase = 0	reward = 0.440951	array([[  2.185152, -44.41005 ]], dtype=float32)
time = 60590	action = 0	current_phase = 1	next_phase = 0	reward = 1.001033	array([[  2.1763115, -44.400696 ]], dtype=float32)
time = 60595	action = 0	current_phase = 1	next_phase = 0	reward = 0.720298	array([[  2.2149801, -44.56381  ]], dtype=float32)
time = 60600	action = 0	current_phase = 1	next_phase = 0	reward = 0.440961	array([[  2.2516985, -44.665817 ]], dtype=float32)
time = 60605	action = 0	current_phase = 1	next_phase = 0	reward = 1.001735	array([[  2.2338686, -44.60846  ]], dtype=float32)
time = 60610	action = 0	current_phase = 1	next_phase = 0	reward = 0.724349	array([[  2.1227694, -44.31038  ]], dtype=float32)
time = 60615	action = 0	current_phase = 1	next_phase = 0	reward = 0.723032	array([[  2.2109318, -44.5066   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2202.6210 - val_loss: 508.1103
Epoch 2/50
 - 4s - loss: 2193.0129 - val_loss: 513.8051
Epoch 3/50
 - 4s - loss: 2206.1134 - val_loss: 529.0221
Epoch 4/50
 - 4s - loss: 2252.1907 - val_loss: 513.2447
Epoch 5/50
 - 4s - loss: 2204.5447 - val_loss: 510.6601
Epoch 6/50
 - 4s - loss: 2205.9495 - val_loss: 540.8883
Epoch 7/50
 - 4s - loss: 2190.1471 - val_loss: 529.2590
Epoch 8/50
 - 4s - loss: 2202.9263 - val_loss: 525.2715
Epoch 9/50
 - 4s - loss: 2210.5513 - val_loss: 510.2140
Epoch 10/50
 - 4s - loss: 2223.3150 - val_loss: 521.8859
Epoch 11/50
 - 4s - loss: 2208.3160 - val_loss: 554.4663
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 60620	action = 0	current_phase = 1	next_phase = 0	reward = 0.721040	array([[  2.1974306, -44.49386  ]], dtype=float32)
time = 60625	action = 0	current_phase = 1	next_phase = 0	reward = 0.719240	array([[  2.1283617, -44.278572 ]], dtype=float32)
time = 60630	action = 0	current_phase = 1	next_phase = 0	reward = 0.726835	array([[  2.2581272, -44.71289  ]], dtype=float32)
time = 60635	action = 0	current_phase = 1	next_phase = 0	reward = 0.728293	array([[  2.2041016, -44.530663 ]], dtype=float32)
time = 60640	action = 0	current_phase = 1	next_phase = 0	reward = 0.721672	array([[  2.255989, -44.726048]], dtype=float32)
time = 60645	action = 0	current_phase = 1	next_phase = 0	reward = 0.721743	array([[  2.2271814, -44.63698  ]], dtype=float32)
time = 60650	action = 0	current_phase = 1	next_phase = 0	reward = 0.435617	array([[  2.1870718, -44.511757 ]], dtype=float32)
time = 60655	action = 0	current_phase = 1	next_phase = 0	reward = 0.723926	array([[  2.2330847, -44.632225 ]], dtype=float32)
time = 60660	action = 0	current_phase = 1	next_phase = 0	reward = 1.002078	array([[  2.210473, -44.642338]], dtype=float32)
time = 60665	action = 0	current_phase = 1	next_phase = 0	reward = 0.715229	array([[  2.1933088, -44.47435  ]], dtype=float32)
time = 60670	action = 0	current_phase = 1	next_phase = 0	reward = 0.712401	array([[  2.2591171, -44.792988 ]], dtype=float32)
time = 60675	action = 0	current_phase = 1	next_phase = 0	reward = 0.439418	array([[  2.2247248, -44.598076 ]], dtype=float32)
time = 60680	action = 0	current_phase = 1	next_phase = 0	reward = 0.998440	array([[  2.1655264, -44.447525 ]], dtype=float32)
time = 60685	action = 0	current_phase = 1	next_phase = 0	reward = 0.440866	array([[  2.2770472, -44.893707 ]], dtype=float32)
time = 60690	action = 0	current_phase = 1	next_phase = 0	reward = 1.010148	array([[  2.146676, -44.326942]], dtype=float32)
time = 60695	action = 0	current_phase = 1	next_phase = 0	reward = 0.444530	array([[  2.1191187, -44.251495 ]], dtype=float32)
time = 60700	action = 0	current_phase = 1	next_phase = 0	reward = 1.007202	array([[  2.1887255, -44.467796 ]], dtype=float32)
time = 60705	action = 0	current_phase = 1	next_phase = 0	reward = 0.715867	array([[  2.1830072, -44.553017 ]], dtype=float32)
time = 60710	action = 0	current_phase = 1	next_phase = 0	reward = 0.720161	array([[  2.1827097, -44.433365 ]], dtype=float32)
time = 60715	action = 0	current_phase = 1	next_phase = 0	reward = 0.709101	array([[  2.1502495, -44.399067 ]], dtype=float32)
time = 60720	action = 0	current_phase = 1	next_phase = 0	reward = 0.719509	array([[  2.2325249, -44.66754  ]], dtype=float32)
time = 60725	action = 0	current_phase = 1	next_phase = 0	reward = 0.726017	array([[  2.0739145, -44.1772   ]], dtype=float32)
time = 60730	action = 0	current_phase = 1	next_phase = 0	reward = 0.719466	array([[  2.1844435, -44.477448 ]], dtype=float32)
time = 60735	action = 0	current_phase = 1	next_phase = 0	reward = 0.719214	array([[  2.246276, -44.67135 ]], dtype=float32)
time = 60740	action = 0	current_phase = 1	next_phase = 0	reward = 0.720297	array([[  2.2678566, -44.766937 ]], dtype=float32)
time = 60745	action = 0	current_phase = 1	next_phase = 0	reward = 0.722901	array([[  2.1711454, -44.480824 ]], dtype=float32)
time = 60750	action = 0	current_phase = 1	next_phase = 0	reward = 0.714522	array([[  2.176855, -44.411003]], dtype=float32)
time = 60755	action = 0	current_phase = 1	next_phase = 0	reward = 0.432757	array([[  2.2230244, -44.56905  ]], dtype=float32)
time = 60760	action = 0	current_phase = 1	next_phase = 0	reward = 0.999732	array([[  1.1162415, -42.914604 ]], dtype=float32)
time = 60765	action = 0	current_phase = 1	next_phase = 0	reward = 0.716873	array([[  2.26441 , -44.768227]], dtype=float32)
time = 60770	action = 0	current_phase = 1	next_phase = 0	reward = 0.718542	array([[  2.1966248, -44.492527 ]], dtype=float32)
time = 60775	action = 0	current_phase = 1	next_phase = 0	reward = 0.445108	array([[  2.2150307, -44.59279  ]], dtype=float32)
time = 60780	action = 0	current_phase = 1	next_phase = 0	reward = 1.014999	array([[  2.2739573, -44.847313 ]], dtype=float32)
time = 60785	action = 0	current_phase = 1	next_phase = 0	reward = 0.718809	array([[  2.271862, -44.838554]], dtype=float32)
time = 60790	action = 0	current_phase = 1	next_phase = 0	reward = 0.723047	array([[  2.251997, -44.688923]], dtype=float32)
time = 60795	action = 0	current_phase = 1	next_phase = 0	reward = 0.719422	array([[  2.1812868, -44.4442   ]], dtype=float32)
time = 60800	action = 0	current_phase = 1	next_phase = 0	reward = 0.721483	array([[  2.2045145, -44.54197  ]], dtype=float32)
time = 60805	action = 0	current_phase = 1	next_phase = 0	reward = 0.715263	array([[  2.2687302, -44.80648  ]], dtype=float32)
time = 60810	action = 0	current_phase = 1	next_phase = 0	reward = 0.726842	array([[  2.2083426, -44.515507 ]], dtype=float32)
time = 60815	action = 0	current_phase = 1	next_phase = 0	reward = 0.446240	array([[  2.158577, -44.42708 ]], dtype=float32)
time = 60820	action = 0	current_phase = 1	next_phase = 0	reward = 1.000204	array([[  2.2461824, -44.72985  ]], dtype=float32)
time = 60825	action = 0	current_phase = 1	next_phase = 0	reward = 0.717515	array([[  2.2423983, -44.644077 ]], dtype=float32)
time = 60830	action = 0	current_phase = 1	next_phase = 0	reward = 0.709981	array([[  2.2706747, -44.82994  ]], dtype=float32)
time = 60835	action = 0	current_phase = 1	next_phase = 0	reward = 0.716232	array([[  2.2325392, -44.609917 ]], dtype=float32)
time = 60840	action = 0	current_phase = 1	next_phase = 0	reward = 0.439638	array([[  2.154025, -44.332253]], dtype=float32)
time = 60845	action = 0	current_phase = 1	next_phase = 0	reward = 1.009341	array([[  2.2510357, -44.71471  ]], dtype=float32)
time = 60850	action = 0	current_phase = 1	next_phase = 0	reward = 0.718887	array([[  2.2615871, -44.75067  ]], dtype=float32)
time = 60855	action = 0	current_phase = 1	next_phase = 0	reward = 0.712520	array([[  2.2196493, -44.60415  ]], dtype=float32)
time = 60860	action = 0	current_phase = 1	next_phase = 0	reward = 0.719081	array([[  2.217391, -44.547928]], dtype=float32)
time = 60865	action = 0	current_phase = 1	next_phase = 0	reward = 0.731088	array([[  2.2657404, -44.79068  ]], dtype=float32)
time = 60870	action = 0	current_phase = 1	next_phase = 0	reward = 0.717515	array([[  2.1976233, -44.48797  ]], dtype=float32)
time = 60875	action = 0	current_phase = 1	next_phase = 0	reward = 0.711812	array([[  2.232666, -44.630417]], dtype=float32)
time = 60880	action = 0	current_phase = 1	next_phase = 0	reward = 0.716548	array([[  2.1614332, -44.41548  ]], dtype=float32)
time = 60885	action = 0	current_phase = 1	next_phase = 0	reward = 0.720830	array([[  2.2246866, -44.560345 ]], dtype=float32)
time = 60890	action = 0	current_phase = 1	next_phase = 0	reward = 0.719604	array([[  1.9528608, -43.976074 ]], dtype=float32)
time = 60895	action = 0	current_phase = 1	next_phase = 0	reward = 0.719039	array([[  2.2254295, -44.607903 ]], dtype=float32)
time = 60900	action = 0	current_phase = 1	next_phase = 0	reward = 0.718001	array([[  2.1524258, -44.43108  ]], dtype=float32)
time = 60905	action = 0	current_phase = 1	next_phase = 0	reward = 0.716773	array([[  2.116498, -44.389336]], dtype=float32)
time = 60910	action = 0	current_phase = 1	next_phase = 0	reward = 0.160906	array([[  2.1747904, -44.45974  ]], dtype=float32)
time = 60915	action = 0	current_phase = 1	next_phase = 0	reward = 1.007472	array([[  2.1954832, -44.51151  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2293.0753 - val_loss: 252.4493
Epoch 2/50
 - 4s - loss: 2280.1213 - val_loss: 473.2432
Epoch 3/50
 - 4s - loss: 2309.5140 - val_loss: 263.7583
Epoch 4/50
 - 4s - loss: 2291.9280 - val_loss: 250.9088
Epoch 5/50
 - 4s - loss: 2307.0497 - val_loss: 223.3680
Epoch 6/50
 - 4s - loss: 2261.8281 - val_loss: 264.1948
Epoch 7/50
 - 4s - loss: 2284.5508 - val_loss: 232.4948
Epoch 8/50
 - 4s - loss: 2314.1140 - val_loss: 274.7312
Epoch 9/50
 - 4s - loss: 2295.2506 - val_loss: 217.8088
Epoch 10/50
 - 4s - loss: 2294.3494 - val_loss: 275.0966
Epoch 11/50
 - 4s - loss: 2300.5351 - val_loss: 235.3484
Epoch 12/50
 - 4s - loss: 2278.1774 - val_loss: 255.5387
Epoch 13/50
 - 4s - loss: 2307.2337 - val_loss: 250.7719
Epoch 14/50
 - 4s - loss: 2258.8719 - val_loss: 259.8947
Epoch 15/50
 - 4s - loss: 2272.2147 - val_loss: 232.2246
Epoch 16/50
 - 4s - loss: 2285.5767 - val_loss: 280.4159
Epoch 17/50
 - 4s - loss: 2303.8354 - val_loss: 356.2989
Epoch 18/50
 - 4s - loss: 2277.5254 - val_loss: 232.7544
Epoch 19/50
 - 4s - loss: 2268.7619 - val_loss: 353.6301
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 60920	action = 0	current_phase = 1	next_phase = 0	reward = 1.009235	array([[  2.344327, -44.968124]], dtype=float32)
time = 60925	action = 0	current_phase = 1	next_phase = 0	reward = 0.443928	array([[  2.3244696, -44.93258  ]], dtype=float32)
time = 60930	action = 0	current_phase = 1	next_phase = 0	reward = 0.999456	array([[  2.136651, -44.307343]], dtype=float32)
time = 60935	action = 0	current_phase = 1	next_phase = 0	reward = 0.435837	array([[  2.2418022, -44.59549  ]], dtype=float32)
time = 60940	action = 0	current_phase = 1	next_phase = 0	reward = 1.000091	array([[  2.2267914, -44.567024 ]], dtype=float32)
time = 60945	action = 0	current_phase = 1	next_phase = 0	reward = 0.435259	array([[  2.1118917, -44.234135 ]], dtype=float32)
time = 60950	action = 0	current_phase = 1	next_phase = 0	reward = 0.731760	array([[  2.2987757, -44.846886 ]], dtype=float32)
time = 60955	action = 0	current_phase = 1	next_phase = 0	reward = 1.006548	array([[  2.3236132, -44.8655   ]], dtype=float32)
time = 60960	action = 0	current_phase = 1	next_phase = 0	reward = 0.715503	array([[  2.305522, -44.81135 ]], dtype=float32)
time = 60965	action = 0	current_phase = 1	next_phase = 0	reward = 0.721789	array([[  2.226534, -44.52043 ]], dtype=float32)
time = 60970	action = 0	current_phase = 1	next_phase = 0	reward = 0.446099	array([[  2.2989864, -44.81104  ]], dtype=float32)
time = 60975	action = 0	current_phase = 1	next_phase = 0	reward = 1.001261	array([[  2.1266146, -44.282707 ]], dtype=float32)
time = 60980	action = 0	current_phase = 1	next_phase = 0	reward = 0.721531	array([[  2.2545357, -44.678093 ]], dtype=float32)
time = 60985	action = 0	current_phase = 1	next_phase = 0	reward = 0.720012	array([[  2.2311106, -44.568764 ]], dtype=float32)
time = 60990	action = 0	current_phase = 1	next_phase = 0	reward = 0.720972	array([[  2.320733, -44.891666]], dtype=float32)
time = 60995	action = 0	current_phase = 1	next_phase = 0	reward = 0.721523	array([[  2.1940594, -44.44764  ]], dtype=float32)
time = 61000	action = 0	current_phase = 1	next_phase = 0	reward = 0.728143	array([[  2.2200193, -44.5355   ]], dtype=float32)
time = 61005	action = 0	current_phase = 1	next_phase = 0	reward = 0.732401	array([[  2.3024416, -44.813705 ]], dtype=float32)
time = 61010	action = 0	current_phase = 1	next_phase = 0	reward = 0.714706	array([[  2.1426897, -44.31407  ]], dtype=float32)
time = 61015	action = 0	current_phase = 1	next_phase = 0	reward = 0.716438	array([[  2.2636147, -44.6512   ]], dtype=float32)
time = 61020	action = 0	current_phase = 1	next_phase = 0	reward = 0.715779	array([[  2.2786922, -44.708176 ]], dtype=float32)
time = 61025	action = 0	current_phase = 1	next_phase = 0	reward = 0.430871	array([[  2.2458115, -44.616394 ]], dtype=float32)
time = 61030	action = 0	current_phase = 1	next_phase = 0	reward = 0.723049	array([[  2.3010397, -44.798416 ]], dtype=float32)
time = 61035	action = 0	current_phase = 1	next_phase = 0	reward = 1.006902	array([[  2.295413, -44.74852 ]], dtype=float32)
time = 61040	action = 0	current_phase = 1	next_phase = 0	reward = 0.722842	array([[  2.281824, -44.71616 ]], dtype=float32)
time = 61045	action = 0	current_phase = 1	next_phase = 0	reward = 0.726323	array([[  2.2145252, -44.505756 ]], dtype=float32)
time = 61050	action = 0	current_phase = 1	next_phase = 0	reward = 0.723285	array([[  2.143571, -44.31322 ]], dtype=float32)
time = 61055	action = 0	current_phase = 1	next_phase = 0	reward = 0.722115	array([[  2.3098583, -44.848217 ]], dtype=float32)
time = 61060	action = 0	current_phase = 1	next_phase = 0	reward = 0.713638	array([[  2.2419977, -44.58857  ]], dtype=float32)
time = 61065	action = 0	current_phase = 1	next_phase = 0	reward = 0.722028	array([[  2.1374893, -44.391132 ]], dtype=float32)
time = 61070	action = 0	current_phase = 1	next_phase = 0	reward = 0.729420	array([[  2.1760893, -44.3984   ]], dtype=float32)
time = 61075	action = 0	current_phase = 1	next_phase = 0	reward = 0.722101	array([[  2.206811, -44.485817]], dtype=float32)
time = 61080	action = 0	current_phase = 1	next_phase = 0	reward = 0.725414	array([[  2.313446, -44.85614 ]], dtype=float32)
time = 61085	action = 0	current_phase = 1	next_phase = 0	reward = 0.726631	array([[  2.227808, -44.541245]], dtype=float32)
time = 61090	action = 0	current_phase = 1	next_phase = 0	reward = 0.723791	array([[  2.2521486, -44.636772 ]], dtype=float32)
time = 61095	action = 0	current_phase = 1	next_phase = 0	reward = 0.721517	array([[  2.3031425, -44.80551  ]], dtype=float32)
time = 61100	action = 0	current_phase = 1	next_phase = 0	reward = 0.718387	array([[  2.2870808, -44.76067  ]], dtype=float32)
time = 61105	action = 0	current_phase = 1	next_phase = 0	reward = 0.720018	array([[  2.24924 , -44.604294]], dtype=float32)
time = 61110	action = 0	current_phase = 1	next_phase = 0	reward = 0.721033	array([[  2.323289, -44.886368]], dtype=float32)
time = 61115	action = 0	current_phase = 1	next_phase = 0	reward = 0.730719	array([[  2.2798986, -44.7266   ]], dtype=float32)
time = 61120	action = 0	current_phase = 1	next_phase = 0	reward = 0.722218	array([[  2.2447357, -44.600418 ]], dtype=float32)
time = 61125	action = 0	current_phase = 1	next_phase = 0	reward = 0.723004	array([[  2.2854471, -44.713142 ]], dtype=float32)
time = 61130	action = 0	current_phase = 1	next_phase = 0	reward = 0.719426	array([[  2.3227816, -44.9663   ]], dtype=float32)
time = 61135	action = 0	current_phase = 1	next_phase = 0	reward = 0.722498	array([[  2.2938232, -44.79339  ]], dtype=float32)
time = 61140	action = 0	current_phase = 1	next_phase = 0	reward = 0.725106	array([[  2.3045282, -44.8266   ]], dtype=float32)
time = 61145	action = 0	current_phase = 1	next_phase = 0	reward = 0.440939	array([[  2.293684, -44.756447]], dtype=float32)
time = 61150	action = 0	current_phase = 1	next_phase = 0	reward = 0.997307	array([[  2.2191029, -44.510483 ]], dtype=float32)
time = 61155	action = 0	current_phase = 1	next_phase = 0	reward = 0.715553	array([[  2.303174, -44.793724]], dtype=float32)
time = 61160	action = 0	current_phase = 1	next_phase = 0	reward = 0.438320	array([[  2.277296, -44.712875]], dtype=float32)
time = 61165	action = 0	current_phase = 1	next_phase = 0	reward = 1.005990	array([[  2.323553, -44.906334]], dtype=float32)
time = 61170	action = 0	current_phase = 1	next_phase = 0	reward = 0.442323	array([[  2.222455, -44.57145 ]], dtype=float32)
time = 61175	action = 0	current_phase = 1	next_phase = 0	reward = 1.000271	array([[  2.3065872, -44.86103  ]], dtype=float32)
time = 61180	action = 0	current_phase = 1	next_phase = 0	reward = 0.708956	array([[  2.2693377, -44.68483  ]], dtype=float32)
time = 61185	action = 0	current_phase = 1	next_phase = 0	reward = 0.439883	array([[  2.244748, -44.626717]], dtype=float32)
time = 61190	action = 0	current_phase = 1	next_phase = 0	reward = 1.002664	array([[  2.201089, -44.49646 ]], dtype=float32)
time = 61195	action = 0	current_phase = 1	next_phase = 0	reward = 0.444372	array([[  2.2118492, -44.51106  ]], dtype=float32)
time = 61200	action = 0	current_phase = 1	next_phase = 0	reward = 0.733144	array([[  2.2254791, -44.553913 ]], dtype=float32)
time = 61205	action = 0	current_phase = 1	next_phase = 0	reward = 1.006709	array([[  2.227645, -44.541946]], dtype=float32)
time = 61210	action = 0	current_phase = 1	next_phase = 0	reward = 0.446257	array([[  2.3363562, -44.98026  ]], dtype=float32)
time = 61215	action = 0	current_phase = 1	next_phase = 0	reward = 1.001448	array([[  2.3039103, -44.805145 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2251.8505 - val_loss: 164.5939
Epoch 2/50
 - 4s - loss: 2243.8162 - val_loss: 179.1434
Epoch 3/50
 - 4s - loss: 2202.9423 - val_loss: 161.3857
Epoch 4/50
 - 4s - loss: 2218.0690 - val_loss: 197.2569
Epoch 5/50
 - 4s - loss: 2183.6421 - val_loss: 210.6076
Epoch 6/50
 - 4s - loss: 2231.0270 - val_loss: 172.9699
Epoch 7/50
 - 4s - loss: 2236.3552 - val_loss: 175.9822
Epoch 8/50
 - 4s - loss: 2220.8299 - val_loss: 209.6644
Epoch 9/50
 - 4s - loss: 2190.0088 - val_loss: 175.8468
Epoch 10/50
 - 4s - loss: 2234.5503 - val_loss: 187.6634
Epoch 11/50
 - 4s - loss: 2165.4756 - val_loss: 236.9807
Epoch 12/50
 - 4s - loss: 2182.2844 - val_loss: 228.1195
Epoch 13/50
 - 4s - loss: 2220.3710 - val_loss: 215.8845
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 61220	action = 0	current_phase = 1	next_phase = 0	reward = 0.718147	array([[  2.0652485, -44.60553  ]], dtype=float32)
time = 61225	action = 0	current_phase = 1	next_phase = 0	reward = 0.718279	array([[  2.2782393, -44.879246 ]], dtype=float32)
time = 61230	action = 0	current_phase = 1	next_phase = 0	reward = 0.442222	array([[  2.2623281, -44.84912  ]], dtype=float32)
time = 61235	action = 0	current_phase = 1	next_phase = 0	reward = 1.002470	array([[  2.2871218, -44.982082 ]], dtype=float32)
time = 61240	action = 0	current_phase = 1	next_phase = 0	reward = 0.720293	array([[  2.2704773, -44.97386  ]], dtype=float32)
time = 61245	action = 0	current_phase = 1	next_phase = 0	reward = 0.720009	array([[  2.2457876, -44.80017  ]], dtype=float32)
time = 61250	action = 0	current_phase = 1	next_phase = 0	reward = 0.718314	array([[  2.1708317, -44.628944 ]], dtype=float32)
time = 61255	action = 0	current_phase = 1	next_phase = 0	reward = 0.716023	array([[  2.2739859, -44.945206 ]], dtype=float32)
time = 61260	action = 0	current_phase = 1	next_phase = 0	reward = 0.440211	array([[  2.2581186, -44.823837 ]], dtype=float32)
time = 61265	action = 0	current_phase = 1	next_phase = 0	reward = 0.714011	array([[  2.1580124, -44.66503  ]], dtype=float32)
time = 61270	action = 0	current_phase = 1	next_phase = 0	reward = 0.720623	array([[  2.1697779, -44.497124 ]], dtype=float32)
time = 61275	action = 0	current_phase = 1	next_phase = 0	reward = 1.003074	array([[  2.1641674, -44.495453 ]], dtype=float32)
time = 61280	action = 0	current_phase = 1	next_phase = 0	reward = 0.727705	array([[  2.2267237, -44.74353  ]], dtype=float32)
time = 61285	action = 0	current_phase = 1	next_phase = 0	reward = 0.718037	array([[  2.2633514, -44.927063 ]], dtype=float32)
time = 61290	action = 0	current_phase = 1	next_phase = 0	reward = 0.719063	array([[  2.2727022, -44.842056 ]], dtype=float32)
time = 61295	action = 0	current_phase = 1	next_phase = 0	reward = 0.443403	array([[  2.1539679, -44.709316 ]], dtype=float32)
time = 61300	action = 0	current_phase = 1	next_phase = 0	reward = 1.000146	array([[  2.2881002, -45.000114 ]], dtype=float32)
time = 61305	action = 0	current_phase = 1	next_phase = 0	reward = 0.445651	array([[  2.259347, -44.91632 ]], dtype=float32)
time = 61310	action = 0	current_phase = 1	next_phase = 0	reward = 1.004215	array([[  2.1914358, -44.64138  ]], dtype=float32)
time = 61315	action = 0	current_phase = 1	next_phase = 0	reward = 0.714522	array([[  2.201438, -44.70813 ]], dtype=float32)
time = 61320	action = 0	current_phase = 1	next_phase = 0	reward = 0.719757	array([[  2.2337723, -44.729744 ]], dtype=float32)
time = 61325	action = 0	current_phase = 1	next_phase = 0	reward = 0.718026	array([[  2.270195, -44.9756  ]], dtype=float32)
time = 61330	action = 0	current_phase = 1	next_phase = 0	reward = 0.723641	array([[  2.187173, -44.745476]], dtype=float32)
time = 61335	action = 0	current_phase = 1	next_phase = 0	reward = 0.710174	array([[  2.2690144, -44.91246  ]], dtype=float32)
time = 61340	action = 0	current_phase = 1	next_phase = 0	reward = 0.436463	array([[  2.239997, -44.73076 ]], dtype=float32)
time = 61345	action = 0	current_phase = 1	next_phase = 0	reward = 1.007359	array([[  2.2102003, -44.683037 ]], dtype=float32)
time = 61350	action = 0	current_phase = 1	next_phase = 0	reward = 0.722565	array([[  2.294382, -45.005627]], dtype=float32)
time = 61355	action = 0	current_phase = 1	next_phase = 0	reward = 0.446615	array([[  2.0765152, -44.401352 ]], dtype=float32)
time = 61360	action = 0	current_phase = 1	next_phase = 0	reward = 1.007631	array([[  2.270461, -44.862274]], dtype=float32)
time = 61365	action = 0	current_phase = 1	next_phase = 0	reward = 0.436134	array([[  2.2271128, -44.68903  ]], dtype=float32)
time = 61370	action = 0	current_phase = 1	next_phase = 0	reward = 1.000279	array([[  2.1554155, -44.635975 ]], dtype=float32)
time = 61375	action = 0	current_phase = 1	next_phase = 0	reward = 0.439643	array([[  2.2890673, -45.11373  ]], dtype=float32)
time = 61380	action = 0	current_phase = 1	next_phase = 0	reward = 0.725136	array([[  2.266449, -44.82387 ]], dtype=float32)
time = 61385	action = 0	current_phase = 1	next_phase = 0	reward = 1.002442	array([[  2.2372923, -44.712967 ]], dtype=float32)
time = 61390	action = 0	current_phase = 1	next_phase = 0	reward = 0.714637	array([[  2.261466, -44.780415]], dtype=float32)
time = 61395	action = 0	current_phase = 1	next_phase = 0	reward = 0.715132	array([[  2.1787415, -44.869873 ]], dtype=float32)
time = 61400	action = 0	current_phase = 1	next_phase = 0	reward = 0.722981	array([[  2.1846094, -44.629234 ]], dtype=float32)
time = 61405	action = 0	current_phase = 1	next_phase = 0	reward = 0.439648	array([[  2.279625, -44.873985]], dtype=float32)
time = 61410	action = 0	current_phase = 1	next_phase = 0	reward = 0.996169	array([[  2.2473688, -44.746338 ]], dtype=float32)
time = 61415	action = 0	current_phase = 1	next_phase = 0	reward = 0.721882	array([[  2.1770267, -44.66619  ]], dtype=float32)
time = 61420	action = 0	current_phase = 1	next_phase = 0	reward = 0.440797	array([[  2.1864223, -44.625015 ]], dtype=float32)
time = 61425	action = 0	current_phase = 1	next_phase = 0	reward = 1.000691	array([[  2.2498283, -44.72797  ]], dtype=float32)
time = 61430	action = 0	current_phase = 1	next_phase = 0	reward = 0.719024	array([[  2.264638, -44.82592 ]], dtype=float32)
time = 61435	action = 0	current_phase = 1	next_phase = 0	reward = 0.713939	array([[  2.1651888, -44.90159  ]], dtype=float32)
time = 61440	action = 0	current_phase = 1	next_phase = 0	reward = 0.442677	array([[  2.2599955, -44.810913 ]], dtype=float32)
time = 61445	action = 0	current_phase = 1	next_phase = 0	reward = 0.724096	array([[  2.2867203, -44.959442 ]], dtype=float32)
time = 61450	action = 0	current_phase = 1	next_phase = 0	reward = 1.008741	array([[  2.2803001, -44.92108  ]], dtype=float32)
time = 61455	action = 0	current_phase = 1	next_phase = 0	reward = 0.718715	array([[  2.2940083, -44.994995 ]], dtype=float32)
time = 61460	action = 0	current_phase = 1	next_phase = 0	reward = 0.442577	array([[  2.2437935, -44.781    ]], dtype=float32)
time = 61465	action = 0	current_phase = 1	next_phase = 0	reward = 0.998589	array([[  2.255105, -44.89074 ]], dtype=float32)
time = 61470	action = 0	current_phase = 1	next_phase = 0	reward = 0.718159	array([[  2.1134539, -44.57901  ]], dtype=float32)
time = 61475	action = 0	current_phase = 1	next_phase = 0	reward = 0.724553	array([[  2.2157488, -44.881668 ]], dtype=float32)
time = 61480	action = 0	current_phase = 1	next_phase = 0	reward = 0.712176	array([[  2.1434917, -44.578682 ]], dtype=float32)
time = 61485	action = 0	current_phase = 1	next_phase = 0	reward = 0.433296	array([[  2.2086754, -44.705753 ]], dtype=float32)
time = 61490	action = 0	current_phase = 1	next_phase = 0	reward = 0.720467	array([[  2.315854, -45.13822 ]], dtype=float32)
time = 61495	action = 0	current_phase = 1	next_phase = 0	reward = 0.733484	array([[  2.2771568, -44.901176 ]], dtype=float32)
time = 61500	action = 0	current_phase = 1	next_phase = 0	reward = 0.734564	array([[  2.2383108, -44.726433 ]], dtype=float32)
time = 61505	action = 0	current_phase = 1	next_phase = 0	reward = 1.002366	array([[  2.1679459, -44.5698   ]], dtype=float32)
time = 61510	action = 0	current_phase = 1	next_phase = 0	reward = 0.709714	array([[  2.2738972, -44.884586 ]], dtype=float32)
time = 61515	action = 0	current_phase = 1	next_phase = 0	reward = 0.719931	array([[  2.264371, -44.8311  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2256.5464 - val_loss: 885.2234
Epoch 2/50
 - 4s - loss: 2197.6587 - val_loss: 805.6417
Epoch 3/50
 - 4s - loss: 2299.9557 - val_loss: 803.7838
Epoch 4/50
 - 4s - loss: 2247.3614 - val_loss: 787.1173
Epoch 5/50
 - 4s - loss: 2286.0619 - val_loss: 883.3075
Epoch 6/50
 - 4s - loss: 2209.0215 - val_loss: 809.7683
Epoch 7/50
 - 4s - loss: 2187.5203 - val_loss: 789.8378
Epoch 8/50
 - 4s - loss: 2290.0215 - val_loss: 818.6095
Epoch 9/50
 - 4s - loss: 2184.9149 - val_loss: 783.6395
Epoch 10/50
 - 4s - loss: 2207.4784 - val_loss: 791.0324
Epoch 11/50
 - 4s - loss: 2250.5158 - val_loss: 777.9316
Epoch 12/50
 - 4s - loss: 2209.7646 - val_loss: 806.9370
Epoch 13/50
 - 4s - loss: 2190.3016 - val_loss: 802.0977
Epoch 14/50
 - 4s - loss: 2178.0008 - val_loss: 819.3116
Epoch 15/50
 - 4s - loss: 2221.8432 - val_loss: 801.1135
Epoch 16/50
 - 4s - loss: 2257.2646 - val_loss: 761.8123
Epoch 17/50
 - 4s - loss: 2230.9552 - val_loss: 733.5788
Epoch 18/50
 - 4s - loss: 2225.2608 - val_loss: 779.9318
Epoch 19/50
 - 4s - loss: 2294.3928 - val_loss: 732.3859
Epoch 20/50
 - 4s - loss: 2210.9109 - val_loss: 788.9718
Epoch 21/50
 - 4s - loss: 2175.7097 - val_loss: 803.0132
Epoch 22/50
 - 4s - loss: 2301.3304 - val_loss: 797.3168
Epoch 23/50
 - 4s - loss: 2237.2209 - val_loss: 893.7758
Epoch 24/50
 - 4s - loss: 2180.2157 - val_loss: 785.6055
Epoch 25/50
 - 4s - loss: 2182.0762 - val_loss: 847.0590
Epoch 26/50
 - 4s - loss: 2174.2166 - val_loss: 818.2153
Epoch 27/50
 - 4s - loss: 2213.8257 - val_loss: 794.0543
Epoch 28/50
 - 4s - loss: 2203.4503 - val_loss: 800.9256
Epoch 29/50
 - 4s - loss: 2167.3000 - val_loss: 792.9593
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 61520	action = 0	current_phase = 1	next_phase = 0	reward = 0.722621	array([[  2.3587914, -45.13562  ]], dtype=float32)
time = 61525	action = 0	current_phase = 1	next_phase = 0	reward = 0.450462	array([[  2.270957, -44.845917]], dtype=float32)
time = 61530	action = 0	current_phase = 1	next_phase = 0	reward = 0.998323	array([[  2.3585777, -45.130478 ]], dtype=float32)
time = 61535	action = 0	current_phase = 1	next_phase = 0	reward = 0.720246	array([[  2.366726, -45.186783]], dtype=float32)
time = 61540	action = 0	current_phase = 1	next_phase = 0	reward = 0.713462	array([[  2.381917, -45.3387  ]], dtype=float32)
time = 61545	action = 0	current_phase = 1	next_phase = 0	reward = 0.714106	array([[  2.2915144, -44.937622 ]], dtype=float32)
time = 61550	action = 0	current_phase = 1	next_phase = 0	reward = 0.443634	array([[  2.390232, -45.37356 ]], dtype=float32)
time = 61555	action = 0	current_phase = 1	next_phase = 0	reward = 0.999637	array([[  2.2779999, -44.8741   ]], dtype=float32)
time = 61560	action = 0	current_phase = 1	next_phase = 0	reward = 0.719288	array([[  2.3806467, -45.294907 ]], dtype=float32)
time = 61565	action = 0	current_phase = 1	next_phase = 0	reward = 0.720456	array([[  2.3888512, -45.36799  ]], dtype=float32)
time = 61570	action = 0	current_phase = 1	next_phase = 0	reward = 0.720586	array([[  2.3823967, -45.268333 ]], dtype=float32)
time = 61575	action = 0	current_phase = 1	next_phase = 0	reward = 0.723642	array([[  2.2676535, -44.872284 ]], dtype=float32)
time = 61580	action = 0	current_phase = 1	next_phase = 0	reward = 0.438948	array([[  2.3709774, -45.152233 ]], dtype=float32)
time = 61585	action = 0	current_phase = 1	next_phase = 0	reward = 1.005438	array([[  2.3797884, -45.234272 ]], dtype=float32)
time = 61590	action = 0	current_phase = 1	next_phase = 0	reward = 0.726165	array([[  2.386753, -45.239555]], dtype=float32)
time = 61595	action = 0	current_phase = 1	next_phase = 0	reward = 0.718371	array([[  2.3716812, -45.22938  ]], dtype=float32)
time = 61600	action = 0	current_phase = 1	next_phase = 0	reward = 0.717550	array([[  2.3215685, -45.043297 ]], dtype=float32)
time = 61605	action = 0	current_phase = 1	next_phase = 0	reward = 0.454533	array([[  2.3746624, -45.227333 ]], dtype=float32)
time = 61610	action = 0	current_phase = 1	next_phase = 0	reward = 0.996679	array([[  2.3632326, -45.163544 ]], dtype=float32)
time = 61615	action = 0	current_phase = 1	next_phase = 0	reward = 0.714405	array([[  2.3457842, -45.062515 ]], dtype=float32)
time = 61620	action = 0	current_phase = 1	next_phase = 0	reward = 0.723951	array([[  2.3578663, -45.20935  ]], dtype=float32)
time = 61625	action = 0	current_phase = 1	next_phase = 0	reward = 0.725968	array([[  2.35254, -45.1594 ]], dtype=float32)
time = 61630	action = 0	current_phase = 1	next_phase = 0	reward = 0.727603	array([[  2.3564901, -45.12893  ]], dtype=float32)
time = 61635	action = 0	current_phase = 1	next_phase = 0	reward = 0.708357	array([[  2.392889, -45.306404]], dtype=float32)
time = 61640	action = 0	current_phase = 1	next_phase = 0	reward = 0.719944	array([[  2.363738, -45.174652]], dtype=float32)
time = 61645	action = 0	current_phase = 1	next_phase = 0	reward = 0.716852	array([[  2.1935463, -44.6902   ]], dtype=float32)
time = 61650	action = 0	current_phase = 1	next_phase = 0	reward = 0.715867	array([[  2.3675594, -45.17673  ]], dtype=float32)
time = 61655	action = 0	current_phase = 1	next_phase = 0	reward = 0.440305	array([[  2.3937387, -45.350655 ]], dtype=float32)
time = 61660	action = 0	current_phase = 1	next_phase = 0	reward = 0.999504	array([[  2.3805943, -45.25312  ]], dtype=float32)
time = 61665	action = 0	current_phase = 1	next_phase = 0	reward = 0.444413	array([[  2.3694096, -45.186478 ]], dtype=float32)
time = 61670	action = 0	current_phase = 1	next_phase = 0	reward = 1.003261	array([[  2.2263231, -44.69947  ]], dtype=float32)
time = 61675	action = 0	current_phase = 1	next_phase = 0	reward = 0.717088	array([[  2.3878489, -45.362415 ]], dtype=float32)
time = 61680	action = 0	current_phase = 1	next_phase = 0	reward = 0.721336	array([[  2.3816624, -45.228928 ]], dtype=float32)
time = 61685	action = 0	current_phase = 1	next_phase = 0	reward = 0.439370	array([[  2.378106, -45.247612]], dtype=float32)
time = 61690	action = 0	current_phase = 1	next_phase = 0	reward = 1.004617	array([[  2.2931538, -44.916008 ]], dtype=float32)
time = 61695	action = 0	current_phase = 1	next_phase = 0	reward = 0.711760	array([[  2.3669071, -45.165604 ]], dtype=float32)
time = 61700	action = 0	current_phase = 1	next_phase = 0	reward = 0.713623	array([[  2.3594456, -45.128815 ]], dtype=float32)
time = 61705	action = 0	current_phase = 1	next_phase = 0	reward = 0.446077	array([[  2.3768148, -45.21763  ]], dtype=float32)
time = 61710	action = 0	current_phase = 1	next_phase = 0	reward = 1.011989	array([[  2.331602, -45.03377 ]], dtype=float32)
time = 61715	action = 0	current_phase = 1	next_phase = 0	reward = 0.725313	array([[  2.366354, -45.23373 ]], dtype=float32)
time = 61720	action = 0	current_phase = 1	next_phase = 0	reward = 0.716401	array([[  2.366825, -45.11873 ]], dtype=float32)
time = 61725	action = 0	current_phase = 1	next_phase = 0	reward = 0.726080	array([[  2.3893185, -45.378517 ]], dtype=float32)
time = 61730	action = 0	current_phase = 1	next_phase = 0	reward = 0.732102	array([[  2.3173962, -45.095646 ]], dtype=float32)
time = 61735	action = 0	current_phase = 1	next_phase = 0	reward = 0.706998	array([[  2.3745708, -45.232147 ]], dtype=float32)
time = 61740	action = 0	current_phase = 1	next_phase = 0	reward = 0.719799	array([[  2.3314981, -45.07692  ]], dtype=float32)
time = 61745	action = 0	current_phase = 1	next_phase = 0	reward = 0.720144	array([[  2.384673, -45.322014]], dtype=float32)
time = 61750	action = 0	current_phase = 1	next_phase = 0	reward = 0.718318	array([[  2.3655405, -45.19084  ]], dtype=float32)
time = 61755	action = 0	current_phase = 1	next_phase = 0	reward = 0.716973	array([[  2.3314981, -45.031456 ]], dtype=float32)
time = 61760	action = 0	current_phase = 1	next_phase = 0	reward = 0.714410	array([[  2.3695402, -45.154716 ]], dtype=float32)
time = 61765	action = 0	current_phase = 1	next_phase = 0	reward = 0.722587	array([[  2.3540192, -45.252083 ]], dtype=float32)
time = 61770	action = 0	current_phase = 1	next_phase = 0	reward = 0.716957	array([[  2.3286533, -44.981808 ]], dtype=float32)
time = 61775	action = 0	current_phase = 1	next_phase = 0	reward = 0.436877	array([[  2.3835897, -45.341408 ]], dtype=float32)
time = 61780	action = 0	current_phase = 1	next_phase = 0	reward = 0.996291	array([[  2.3609047, -45.218983 ]], dtype=float32)
time = 61785	action = 0	current_phase = 1	next_phase = 0	reward = 0.715626	array([[  2.3269672, -45.03305  ]], dtype=float32)
time = 61790	action = 0	current_phase = 1	next_phase = 0	reward = 0.439978	array([[  2.3094587, -44.915497 ]], dtype=float32)
time = 61795	action = 0	current_phase = 1	next_phase = 0	reward = 1.006904	array([[  2.3844004, -45.276733 ]], dtype=float32)
time = 61800	action = 0	current_phase = 1	next_phase = 0	reward = 0.719994	array([[  2.3463488, -45.099968 ]], dtype=float32)
time = 61805	action = 0	current_phase = 1	next_phase = 0	reward = 0.724156	array([[  2.3796425, -45.27442  ]], dtype=float32)
time = 61810	action = 0	current_phase = 1	next_phase = 0	reward = 0.732953	array([[  2.3640623, -45.243866 ]], dtype=float32)
time = 61815	action = 0	current_phase = 1	next_phase = 0	reward = 0.724795	array([[  2.325386, -44.97609 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 322.5001 - val_loss: 4650.1775
Epoch 2/50
 - 4s - loss: 330.9182 - val_loss: 4672.8629
Epoch 3/50
 - 4s - loss: 302.0752 - val_loss: 4645.6554
Epoch 4/50
 - 4s - loss: 311.8279 - val_loss: 4658.6918
Epoch 5/50
 - 4s - loss: 376.3043 - val_loss: 4651.7117
Epoch 6/50
 - 4s - loss: 386.2474 - val_loss: 4688.2366
Epoch 7/50
 - 4s - loss: 321.0481 - val_loss: 4674.0427
Epoch 8/50
 - 4s - loss: 290.8598 - val_loss: 4652.0937
Epoch 9/50
 - 4s - loss: 290.5804 - val_loss: 4655.7368
Epoch 10/50
 - 4s - loss: 337.3324 - val_loss: 4651.8452
Epoch 11/50
 - 4s - loss: 332.9002 - val_loss: 4685.1019
Epoch 12/50
 - 4s - loss: 299.5304 - val_loss: 4699.9349
Epoch 13/50
 - 4s - loss: 292.6057 - val_loss: 4686.6392
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 61820	action = 0	current_phase = 1	next_phase = 0	reward = 0.720477	array([[  2.4241629, -45.111267 ]], dtype=float32)
time = 61825	action = 0	current_phase = 1	next_phase = 0	reward = 0.718713	array([[  2.505971, -45.398563]], dtype=float32)
time = 61830	action = 0	current_phase = 1	next_phase = 0	reward = 0.714534	array([[  2.4304848, -45.02953  ]], dtype=float32)
time = 61835	action = 0	current_phase = 1	next_phase = 0	reward = 0.725838	array([[  2.4985151, -45.490753 ]], dtype=float32)
time = 61840	action = 0	current_phase = 1	next_phase = 0	reward = 0.716416	array([[  2.501524, -45.336758]], dtype=float32)
time = 61845	action = 0	current_phase = 1	next_phase = 0	reward = 0.440218	array([[  2.5035772, -45.50406  ]], dtype=float32)
time = 61850	action = 0	current_phase = 1	next_phase = 0	reward = 1.005045	array([[  2.4092846, -44.963383 ]], dtype=float32)
time = 61855	action = 0	current_phase = 1	next_phase = 0	reward = 0.721084	array([[  2.4597597, -45.130642 ]], dtype=float32)
time = 61860	action = 0	current_phase = 1	next_phase = 0	reward = 0.726168	array([[  2.4456348, -45.06877  ]], dtype=float32)
time = 61865	action = 0	current_phase = 1	next_phase = 0	reward = 0.722182	array([[  2.4990187, -45.465057 ]], dtype=float32)
time = 61870	action = 0	current_phase = 1	next_phase = 0	reward = 0.724632	array([[  2.4802027, -45.190567 ]], dtype=float32)
time = 61875	action = 0	current_phase = 1	next_phase = 0	reward = 0.720174	array([[  2.4989882, -45.321568 ]], dtype=float32)
time = 61880	action = 0	current_phase = 1	next_phase = 0	reward = 0.717284	array([[  2.5043917, -45.387608 ]], dtype=float32)
time = 61885	action = 0	current_phase = 1	next_phase = 0	reward = 0.716340	array([[  2.441471, -45.128017]], dtype=float32)
time = 61890	action = 0	current_phase = 1	next_phase = 0	reward = 0.716951	array([[  2.4801435, -45.205605 ]], dtype=float32)
time = 61895	action = 0	current_phase = 1	next_phase = 0	reward = 0.726053	array([[  2.498333, -45.428867]], dtype=float32)
time = 61900	action = 0	current_phase = 1	next_phase = 0	reward = 0.444938	array([[  2.4915113, -45.317783 ]], dtype=float32)
time = 61905	action = 0	current_phase = 1	next_phase = 0	reward = 1.001941	array([[  2.4799929, -45.21791  ]], dtype=float32)
time = 61910	action = 0	current_phase = 1	next_phase = 0	reward = 0.717822	array([[  2.4450064, -45.13649  ]], dtype=float32)
time = 61915	action = 0	current_phase = 1	next_phase = 0	reward = 0.716228	array([[  2.496047, -45.419914]], dtype=float32)
time = 61920	action = 0	current_phase = 1	next_phase = 0	reward = 0.441675	array([[  2.4697342, -45.169525 ]], dtype=float32)
time = 61925	action = 0	current_phase = 1	next_phase = 0	reward = 0.726075	array([[  2.500557, -45.296036]], dtype=float32)
time = 61930	action = 0	current_phase = 1	next_phase = 0	reward = 1.003227	array([[  2.4963999, -45.286568 ]], dtype=float32)
time = 61935	action = 0	current_phase = 1	next_phase = 0	reward = 0.728407	array([[  2.4915934, -45.30734  ]], dtype=float32)
time = 61940	action = 0	current_phase = 1	next_phase = 0	reward = 0.725486	array([[  2.506382, -45.38092 ]], dtype=float32)
time = 61945	action = 0	current_phase = 1	next_phase = 0	reward = 0.723619	array([[  2.4977427, -45.46554  ]], dtype=float32)
time = 61950	action = 0	current_phase = 1	next_phase = 0	reward = 0.712016	array([[  2.3806734, -44.91388  ]], dtype=float32)
time = 61955	action = 0	current_phase = 1	next_phase = 0	reward = 0.434847	array([[  2.4993334, -45.45337  ]], dtype=float32)
time = 61960	action = 0	current_phase = 1	next_phase = 0	reward = 1.003305	array([[  2.47122 , -45.223114]], dtype=float32)
time = 61965	action = 0	current_phase = 1	next_phase = 0	reward = 0.720311	array([[  2.431529, -45.012672]], dtype=float32)
time = 61970	action = 0	current_phase = 1	next_phase = 0	reward = 0.722292	array([[  2.502159, -45.443443]], dtype=float32)
time = 61975	action = 0	current_phase = 1	next_phase = 0	reward = 0.726030	array([[  2.4923658, -45.5429   ]], dtype=float32)
time = 61980	action = 0	current_phase = 1	next_phase = 0	reward = 0.721021	array([[  2.4961996, -45.36638  ]], dtype=float32)
time = 61985	action = 0	current_phase = 1	next_phase = 0	reward = 0.717088	array([[  2.5120344, -45.457005 ]], dtype=float32)
time = 61990	action = 0	current_phase = 1	next_phase = 0	reward = 0.727632	array([[  2.4845982, -45.231926 ]], dtype=float32)
time = 61995	action = 0	current_phase = 1	next_phase = 0	reward = 0.732869	array([[  2.5068913, -45.388878 ]], dtype=float32)
time = 62000	action = 0	current_phase = 1	next_phase = 0	reward = 0.720548	array([[  2.5005827, -45.485546 ]], dtype=float32)
time = 62005	action = 0	current_phase = 1	next_phase = 0	reward = 0.709950	array([[  2.4312391, -45.047653 ]], dtype=float32)
time = 62010	action = 0	current_phase = 1	next_phase = 0	reward = 0.715777	array([[  2.502843, -45.491215]], dtype=float32)
time = 62015	action = 0	current_phase = 1	next_phase = 0	reward = 0.439123	array([[  2.496583, -45.334835]], dtype=float32)
time = 62020	action = 0	current_phase = 1	next_phase = 0	reward = 1.004947	array([[  2.461915, -45.138412]], dtype=float32)
time = 62025	action = 0	current_phase = 1	next_phase = 0	reward = 0.724773	array([[  2.4770975, -45.187378 ]], dtype=float32)
time = 62030	action = 0	current_phase = 1	next_phase = 0	reward = 0.724750	array([[  2.496436, -45.37851 ]], dtype=float32)
time = 62035	action = 0	current_phase = 1	next_phase = 0	reward = 0.712746	array([[  2.4401827, -45.07303  ]], dtype=float32)
time = 62040	action = 0	current_phase = 1	next_phase = 0	reward = 0.715027	array([[  2.501686, -45.410946]], dtype=float32)
time = 62045	action = 0	current_phase = 1	next_phase = 0	reward = 0.714382	array([[  2.463356, -45.14274 ]], dtype=float32)
time = 62050	action = 0	current_phase = 1	next_phase = 0	reward = 0.718288	array([[  2.4735603, -45.17994  ]], dtype=float32)
time = 62055	action = 0	current_phase = 1	next_phase = 0	reward = 0.726867	array([[  2.5079832, -45.333916 ]], dtype=float32)
time = 62060	action = 0	current_phase = 1	next_phase = 0	reward = 0.726510	array([[  2.4837656, -45.275032 ]], dtype=float32)
time = 62065	action = 0	current_phase = 1	next_phase = 0	reward = 0.721728	array([[  2.4873123, -45.262924 ]], dtype=float32)
time = 62070	action = 0	current_phase = 1	next_phase = 0	reward = 0.726897	array([[  2.4965153, -45.377804 ]], dtype=float32)
time = 62075	action = 0	current_phase = 1	next_phase = 0	reward = 0.718066	array([[  2.498001, -45.378212]], dtype=float32)
time = 62080	action = 0	current_phase = 1	next_phase = 0	reward = 0.717235	array([[  2.4981794, -45.471657 ]], dtype=float32)
time = 62085	action = 0	current_phase = 1	next_phase = 0	reward = 0.445225	array([[  2.46027 , -45.161255]], dtype=float32)
time = 62090	action = 0	current_phase = 1	next_phase = 0	reward = 1.009771	array([[  2.5010233, -45.34381  ]], dtype=float32)
time = 62095	action = 0	current_phase = 1	next_phase = 0	reward = 0.717354	array([[  2.4866953, -45.275932 ]], dtype=float32)
time = 62100	action = 0	current_phase = 1	next_phase = 0	reward = 0.717378	array([[  2.4657469, -45.238605 ]], dtype=float32)
time = 62105	action = 0	current_phase = 1	next_phase = 0	reward = 0.441518	array([[  2.5024548, -45.38895  ]], dtype=float32)
time = 62110	action = 0	current_phase = 1	next_phase = 0	reward = 0.994887	array([[  2.5023756, -45.415306 ]], dtype=float32)
time = 62115	action = 0	current_phase = 1	next_phase = 0	reward = 0.441834	array([[  2.3513136, -44.960426 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 353.5409 - val_loss: 4487.4143
Epoch 2/50
 - 4s - loss: 390.6914 - val_loss: 4520.7285
Epoch 3/50
 - 4s - loss: 362.3318 - val_loss: 4517.1958
Epoch 4/50
 - 4s - loss: 367.9100 - val_loss: 4515.4562
Epoch 5/50
 - 4s - loss: 349.5976 - val_loss: 4522.8497
Epoch 6/50
 - 4s - loss: 358.3669 - val_loss: 4544.6603
Epoch 7/50
 - 4s - loss: 380.6045 - val_loss: 4538.6734
Epoch 8/50
 - 4s - loss: 379.3123 - val_loss: 4509.2980
Epoch 9/50
 - 4s - loss: 338.2554 - val_loss: 4516.5467
Epoch 10/50
 - 4s - loss: 380.6209 - val_loss: 4516.9928
Epoch 11/50
 - 4s - loss: 366.5198 - val_loss: 4502.6383
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 62120	action = 0	current_phase = 1	next_phase = 0	reward = 1.003957	array([[  2.517539, -45.058014]], dtype=float32)
time = 62125	action = 0	current_phase = 1	next_phase = 0	reward = 0.727992	array([[  2.5453491, -45.1892   ]], dtype=float32)
time = 62130	action = 0	current_phase = 1	next_phase = 0	reward = 0.729995	array([[  2.5700188, -45.264454 ]], dtype=float32)
time = 62135	action = 0	current_phase = 1	next_phase = 0	reward = 0.716804	array([[  2.5915174, -45.440178 ]], dtype=float32)
time = 62140	action = 0	current_phase = 1	next_phase = 0	reward = 0.729197	array([[  2.5407152, -45.16842  ]], dtype=float32)
time = 62145	action = 0	current_phase = 1	next_phase = 0	reward = 0.719102	array([[  2.600793, -45.571823]], dtype=float32)
time = 62150	action = 0	current_phase = 1	next_phase = 0	reward = 0.717710	array([[  2.571681, -45.28192 ]], dtype=float32)
time = 62155	action = 0	current_phase = 1	next_phase = 0	reward = 0.436468	array([[  2.5771055, -45.30225  ]], dtype=float32)
time = 62160	action = 0	current_phase = 1	next_phase = 0	reward = 0.724758	array([[  2.5944939, -45.50605  ]], dtype=float32)
time = 62165	action = 0	current_phase = 1	next_phase = 0	reward = 0.718239	array([[  2.5463896, -45.17456  ]], dtype=float32)
time = 62170	action = 0	current_phase = 1	next_phase = 0	reward = 0.998390	array([[  2.5823803, -45.4088   ]], dtype=float32)
time = 62175	action = 0	current_phase = 1	next_phase = 0	reward = 0.441604	array([[  2.597165, -45.518547]], dtype=float32)
time = 62180	action = 0	current_phase = 1	next_phase = 0	reward = 0.728990	array([[  2.5881166, -45.387405 ]], dtype=float32)
time = 62185	action = 0	current_phase = 1	next_phase = 0	reward = 0.997779	array([[  2.5839748, -45.40798  ]], dtype=float32)
time = 62190	action = 0	current_phase = 1	next_phase = 0	reward = 0.437968	array([[  2.5944471, -45.334183 ]], dtype=float32)
time = 62195	action = 0	current_phase = 1	next_phase = 0	reward = 0.998452	array([[  2.5275269, -45.102306 ]], dtype=float32)
time = 62200	action = 0	current_phase = 1	next_phase = 0	reward = 0.713593	array([[  2.542077, -45.16948 ]], dtype=float32)
time = 62205	action = 0	current_phase = 1	next_phase = 0	reward = 0.717787	array([[  2.5459824, -45.19484  ]], dtype=float32)
time = 62210	action = 0	current_phase = 1	next_phase = 0	reward = 0.722194	array([[  2.5249748, -45.122715 ]], dtype=float32)
time = 62215	action = 0	current_phase = 1	next_phase = 0	reward = 0.441314	array([[  2.5949116, -45.553276 ]], dtype=float32)
time = 62220	action = 0	current_phase = 1	next_phase = 0	reward = 0.452809	array([[  2.5905876, -45.363    ]], dtype=float32)
time = 62225	action = 0	current_phase = 1	next_phase = 0	reward = 1.007819	array([[  2.3305225, -44.724174 ]], dtype=float32)
time = 62230	action = 0	current_phase = 1	next_phase = 0	reward = 0.993418	array([[  2.595849, -45.47058 ]], dtype=float32)
time = 62235	action = 0	current_phase = 1	next_phase = 0	reward = 0.724658	array([[  2.5470123, -45.223385 ]], dtype=float32)
time = 62240	action = 0	current_phase = 1	next_phase = 0	reward = 0.725344	array([[  2.599886, -45.457478]], dtype=float32)
time = 62245	action = 0	current_phase = 1	next_phase = 0	reward = 0.723816	array([[  2.571228, -45.319923]], dtype=float32)
time = 62250	action = 0	current_phase = 1	next_phase = 0	reward = 0.717334	array([[  2.5219145, -45.114594 ]], dtype=float32)
time = 62255	action = 0	current_phase = 1	next_phase = 0	reward = 0.724125	array([[  2.6067762, -45.531536 ]], dtype=float32)
time = 62260	action = 0	current_phase = 1	next_phase = 0	reward = 0.723196	array([[  2.5703173, -45.30407  ]], dtype=float32)
time = 62265	action = 0	current_phase = 1	next_phase = 0	reward = 0.726247	array([[  2.5944033, -45.45241  ]], dtype=float32)
time = 62270	action = 0	current_phase = 1	next_phase = 0	reward = 0.710377	array([[  2.5982075, -45.491306 ]], dtype=float32)
time = 62275	action = 0	current_phase = 1	next_phase = 0	reward = 0.726631	array([[  2.579174, -45.281044]], dtype=float32)
time = 62280	action = 0	current_phase = 1	next_phase = 0	reward = 0.717168	array([[  2.5754442, -45.382843 ]], dtype=float32)
time = 62285	action = 0	current_phase = 1	next_phase = 0	reward = 0.709299	array([[  2.597684, -45.492836]], dtype=float32)
time = 62290	action = 0	current_phase = 1	next_phase = 0	reward = 0.720514	array([[  2.5619926, -45.277836 ]], dtype=float32)
time = 62295	action = 0	current_phase = 1	next_phase = 0	reward = 0.726788	array([[  2.5739765, -45.282536 ]], dtype=float32)
time = 62300	action = 0	current_phase = 1	next_phase = 0	reward = 0.712049	array([[  2.5713873, -45.25109  ]], dtype=float32)
time = 62305	action = 0	current_phase = 1	next_phase = 0	reward = 0.448044	array([[  2.565462, -45.208866]], dtype=float32)
time = 62310	action = 0	current_phase = 1	next_phase = 0	reward = 1.010456	array([[  2.596611, -45.400978]], dtype=float32)
time = 62315	action = 0	current_phase = 1	next_phase = 0	reward = 0.719950	array([[  2.5950184, -45.379097 ]], dtype=float32)
time = 62320	action = 0	current_phase = 1	next_phase = 0	reward = 0.719284	array([[  2.5873833, -45.383957 ]], dtype=float32)
time = 62325	action = 0	current_phase = 1	next_phase = 0	reward = 0.720594	array([[  2.595749, -45.576256]], dtype=float32)
time = 62330	action = 0	current_phase = 1	next_phase = 0	reward = 0.717505	array([[  2.5965014, -45.518047 ]], dtype=float32)
time = 62335	action = 0	current_phase = 1	next_phase = 0	reward = 0.713114	array([[  2.4842558, -44.944775 ]], dtype=float32)
time = 62340	action = 0	current_phase = 1	next_phase = 0	reward = 0.712855	array([[  2.4947662, -45.080795 ]], dtype=float32)
time = 62345	action = 0	current_phase = 1	next_phase = 0	reward = 0.715050	array([[  2.5873327, -45.505753 ]], dtype=float32)
time = 62350	action = 0	current_phase = 1	next_phase = 0	reward = 0.718096	array([[  2.5878267, -45.44036  ]], dtype=float32)
time = 62355	action = 0	current_phase = 1	next_phase = 0	reward = 0.724080	array([[  2.5966005, -45.489388 ]], dtype=float32)
time = 62360	action = 0	current_phase = 1	next_phase = 0	reward = 0.729296	array([[  2.5581284, -45.18284  ]], dtype=float32)
time = 62365	action = 0	current_phase = 1	next_phase = 0	reward = 0.720525	array([[  2.5810843, -45.29541  ]], dtype=float32)
time = 62370	action = 0	current_phase = 1	next_phase = 0	reward = 0.721367	array([[  2.5814075, -45.28894  ]], dtype=float32)
time = 62375	action = 0	current_phase = 1	next_phase = 0	reward = 0.718475	array([[  2.5963373, -45.452583 ]], dtype=float32)
time = 62380	action = 0	current_phase = 1	next_phase = 0	reward = 0.438936	array([[  2.5818424, -45.60724  ]], dtype=float32)
time = 62385	action = 0	current_phase = 1	next_phase = 0	reward = 0.997248	array([[  2.595334, -45.51148 ]], dtype=float32)
time = 62390	action = 0	current_phase = 1	next_phase = 0	reward = 0.714543	array([[  2.57026, -45.24798]], dtype=float32)
time = 62395	action = 0	current_phase = 1	next_phase = 0	reward = 0.449101	array([[  2.5916529, -45.516808 ]], dtype=float32)
time = 62400	action = 0	current_phase = 1	next_phase = 0	reward = 1.013946	array([[  2.5796337, -45.314568 ]], dtype=float32)
time = 62405	action = 0	current_phase = 1	next_phase = 0	reward = 0.446425	array([[  2.6009254, -45.459877 ]], dtype=float32)
time = 62410	action = 0	current_phase = 1	next_phase = 0	reward = 1.005508	array([[  2.59062, -45.38416]], dtype=float32)
time = 62415	action = 0	current_phase = 1	next_phase = 0	reward = 0.707710	array([[  2.5867052, -45.315136 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2192.5676 - val_loss: 394.7111
Epoch 2/50
 - 4s - loss: 2195.8916 - val_loss: 451.2447
Epoch 3/50
 - 4s - loss: 2206.9787 - val_loss: 383.4916
Epoch 4/50
 - 4s - loss: 2211.4012 - val_loss: 409.5872
Epoch 5/50
 - 4s - loss: 2205.2731 - val_loss: 415.3262
Epoch 6/50
 - 4s - loss: 2196.3651 - val_loss: 424.0542
Epoch 7/50
 - 4s - loss: 2217.9211 - val_loss: 409.5780
Epoch 8/50
 - 4s - loss: 2201.7013 - val_loss: 401.5143
Epoch 9/50
 - 4s - loss: 2203.3544 - val_loss: 461.7689
Epoch 10/50
 - 4s - loss: 2195.2672 - val_loss: 449.2297
Epoch 11/50
 - 4s - loss: 2191.5665 - val_loss: 409.8028
Epoch 12/50
 - 4s - loss: 2204.7190 - val_loss: 434.4924
Epoch 13/50
 - 4s - loss: 2189.4309 - val_loss: 418.5205
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 62420	action = 0	current_phase = 1	next_phase = 0	reward = 0.722949	array([[  2.4236298, -44.963806 ]], dtype=float32)
time = 62425	action = 0	current_phase = 1	next_phase = 0	reward = 0.445076	array([[  2.5521412, -45.461716 ]], dtype=float32)
time = 62430	action = 0	current_phase = 1	next_phase = 0	reward = 1.006479	array([[  2.5346375, -45.324203 ]], dtype=float32)
time = 62435	action = 0	current_phase = 1	next_phase = 0	reward = 0.720680	array([[  2.5398731, -45.62578  ]], dtype=float32)
time = 62440	action = 0	current_phase = 1	next_phase = 0	reward = 0.724903	array([[  2.5385551, -45.31104  ]], dtype=float32)
time = 62445	action = 0	current_phase = 1	next_phase = 0	reward = 0.723326	array([[  2.5128832, -45.166435 ]], dtype=float32)
time = 62450	action = 0	current_phase = 1	next_phase = 0	reward = 0.713252	array([[  2.5471048, -45.48192  ]], dtype=float32)
time = 62455	action = 0	current_phase = 1	next_phase = 0	reward = 0.442440	array([[  2.5473442, -45.389122 ]], dtype=float32)
time = 62460	action = 0	current_phase = 1	next_phase = 0	reward = 1.004097	array([[  2.5367231, -45.52234  ]], dtype=float32)
time = 62465	action = 0	current_phase = 1	next_phase = 0	reward = 0.718411	array([[  2.5477905, -45.370884 ]], dtype=float32)
time = 62470	action = 0	current_phase = 1	next_phase = 0	reward = 0.725691	array([[  2.5123682, -45.672142 ]], dtype=float32)
time = 62475	action = 0	current_phase = 1	next_phase = 0	reward = 0.437049	array([[  2.5496502, -45.434525 ]], dtype=float32)
time = 62480	action = 0	current_phase = 1	next_phase = 0	reward = 0.996378	array([[  2.5339956, -45.41929  ]], dtype=float32)
time = 62485	action = 0	current_phase = 1	next_phase = 0	reward = 0.715981	array([[  2.522954, -45.229206]], dtype=float32)
time = 62490	action = 0	current_phase = 1	next_phase = 0	reward = 0.723631	array([[  2.4059067, -44.907738 ]], dtype=float32)
time = 62495	action = 0	current_phase = 1	next_phase = 0	reward = 0.442574	array([[  2.5370598, -45.420166 ]], dtype=float32)
time = 62500	action = 0	current_phase = 1	next_phase = 0	reward = 1.007560	array([[  2.5345345, -45.338455 ]], dtype=float32)
time = 62505	action = 0	current_phase = 1	next_phase = 0	reward = 0.723571	array([[  2.5388403, -45.58255  ]], dtype=float32)
time = 62510	action = 0	current_phase = 1	next_phase = 0	reward = 0.718556	array([[  2.5446882, -45.451324 ]], dtype=float32)
time = 62515	action = 0	current_phase = 1	next_phase = 0	reward = 0.715728	array([[  2.503623, -45.179016]], dtype=float32)
time = 62520	action = 0	current_phase = 1	next_phase = 0	reward = 0.717390	array([[  2.5935287, -45.549522 ]], dtype=float32)
time = 62525	action = 0	current_phase = 1	next_phase = 0	reward = 0.717905	array([[  2.5443115, -45.392223 ]], dtype=float32)
time = 62530	action = 0	current_phase = 1	next_phase = 0	reward = 0.447103	array([[  2.4893293, -45.114204 ]], dtype=float32)
time = 62535	action = 0	current_phase = 1	next_phase = 0	reward = 1.002690	array([[  2.530034, -45.61385 ]], dtype=float32)
time = 62540	action = 0	current_phase = 1	next_phase = 0	reward = 0.725486	array([[  2.542347, -45.46576 ]], dtype=float32)
time = 62545	action = 0	current_phase = 1	next_phase = 0	reward = 0.717667	array([[  2.5340624, -45.364456 ]], dtype=float32)
time = 62550	action = 0	current_phase = 1	next_phase = 0	reward = 0.713953	array([[  2.5558052, -45.552387 ]], dtype=float32)
time = 62555	action = 0	current_phase = 1	next_phase = 0	reward = 0.705876	array([[  2.5419712, -45.39293  ]], dtype=float32)
time = 62560	action = 0	current_phase = 1	next_phase = 0	reward = 0.431043	array([[  2.5435572, -45.413353 ]], dtype=float32)
time = 62565	action = 0	current_phase = 1	next_phase = 0	reward = 0.454797	array([[  2.5616055, -45.477097 ]], dtype=float32)
time = 62570	action = 0	current_phase = 1	next_phase = 0	reward = 1.284406	array([[  2.5494547, -45.284874 ]], dtype=float32)
time = 62575	action = 0	current_phase = 1	next_phase = 0	reward = 0.451674	array([[  2.4901352, -45.101185 ]], dtype=float32)
time = 62580	action = 0	current_phase = 1	next_phase = 0	reward = 0.726819	array([[  2.5368843, -45.45508  ]], dtype=float32)
time = 62585	action = 0	current_phase = 1	next_phase = 0	reward = 1.001215	array([[  2.5491724, -45.342323 ]], dtype=float32)
time = 62590	action = 0	current_phase = 1	next_phase = 0	reward = 0.444451	array([[  2.5054407, -45.3705   ]], dtype=float32)
time = 62595	action = 0	current_phase = 1	next_phase = 0	reward = 0.730413	array([[  2.5401878, -45.406395 ]], dtype=float32)
time = 62600	action = 0	current_phase = 1	next_phase = 0	reward = 1.003918	array([[  2.5490332, -45.493416 ]], dtype=float32)
time = 62605	action = 0	current_phase = 1	next_phase = 0	reward = 0.718025	array([[  2.544239, -45.359016]], dtype=float32)
time = 62610	action = 0	current_phase = 1	next_phase = 0	reward = 0.441501	array([[  2.5059443, -45.16604  ]], dtype=float32)
time = 62615	action = 0	current_phase = 1	next_phase = 0	reward = 1.005717	array([[  2.5183058, -45.36484  ]], dtype=float32)
time = 62620	action = 0	current_phase = 1	next_phase = 0	reward = 0.721906	array([[  2.5309248, -45.290062 ]], dtype=float32)
time = 62625	action = 0	current_phase = 1	next_phase = 0	reward = 0.439264	array([[  2.5304966, -45.441444 ]], dtype=float32)
time = 62630	action = 0	current_phase = 1	next_phase = 0	reward = 0.999064	array([[  2.531909, -45.288223]], dtype=float32)
time = 62635	action = 0	current_phase = 1	next_phase = 0	reward = 0.721650	array([[  2.5516338, -45.483475 ]], dtype=float32)
time = 62640	action = 0	current_phase = 1	next_phase = 0	reward = 0.722761	array([[  2.5262384, -45.30523  ]], dtype=float32)
time = 62645	action = 0	current_phase = 1	next_phase = 0	reward = 0.722232	array([[  2.5267496, -45.36149  ]], dtype=float32)
time = 62650	action = 0	current_phase = 1	next_phase = 0	reward = 0.720519	array([[  2.54564, -45.39428]], dtype=float32)
time = 62655	action = 0	current_phase = 1	next_phase = 0	reward = 0.718886	array([[  2.5385475, -45.30076  ]], dtype=float32)
time = 62660	action = 0	current_phase = 1	next_phase = 0	reward = 0.719119	array([[  2.5310335, -45.448326 ]], dtype=float32)
time = 62665	action = 0	current_phase = 1	next_phase = 0	reward = 0.449348	array([[  2.5404491, -45.5418   ]], dtype=float32)
time = 62670	action = 0	current_phase = 1	next_phase = 0	reward = 1.002261	array([[  2.5431929, -45.423195 ]], dtype=float32)
time = 62675	action = 0	current_phase = 1	next_phase = 0	reward = 0.728750	array([[  2.5311317, -45.312813 ]], dtype=float32)
time = 62680	action = 0	current_phase = 1	next_phase = 0	reward = 0.718937	array([[  2.5523376, -45.426918 ]], dtype=float32)
time = 62685	action = 0	current_phase = 1	next_phase = 0	reward = 0.704571	array([[  2.5595512, -45.388412 ]], dtype=float32)
time = 62690	action = 0	current_phase = 1	next_phase = 0	reward = 0.715876	array([[  2.5277252, -45.256783 ]], dtype=float32)
time = 62695	action = 0	current_phase = 1	next_phase = 0	reward = 0.438172	array([[  2.5478802, -45.531704 ]], dtype=float32)
time = 62700	action = 0	current_phase = 1	next_phase = 0	reward = 1.003831	array([[  2.5025063, -45.22342  ]], dtype=float32)
time = 62705	action = 0	current_phase = 1	next_phase = 0	reward = 0.719102	array([[  2.518258, -45.25447 ]], dtype=float32)
time = 62710	action = 0	current_phase = 1	next_phase = 0	reward = 0.723274	array([[  2.5515347, -45.39582  ]], dtype=float32)
time = 62715	action = 0	current_phase = 1	next_phase = 0	reward = 0.706528	array([[  2.5135994, -45.553833 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 244.0681 - val_loss: 4711.0497
Epoch 2/50
 - 4s - loss: 245.1945 - val_loss: 4797.0610
Epoch 3/50
 - 4s - loss: 229.9560 - val_loss: 4746.5242
Epoch 4/50
 - 4s - loss: 284.9184 - val_loss: 4880.5650
Epoch 5/50
 - 4s - loss: 266.2260 - val_loss: 4824.1977
Epoch 6/50
 - 4s - loss: 237.4656 - val_loss: 4849.0320
Epoch 7/50
 - 4s - loss: 249.1776 - val_loss: 4869.8291
Epoch 8/50
 - 4s - loss: 314.7719 - val_loss: 4885.0084
Epoch 9/50
 - 4s - loss: 274.8132 - val_loss: 4827.2750
Epoch 10/50
 - 4s - loss: 262.3901 - val_loss: 4822.0730
Epoch 11/50
 - 4s - loss: 258.4139 - val_loss: 4953.6648
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 62720	action = 0	current_phase = 1	next_phase = 0	reward = 0.712977	array([[  2.586792, -45.578407]], dtype=float32)
time = 62725	action = 0	current_phase = 1	next_phase = 0	reward = 0.720165	array([[  2.572754, -45.654243]], dtype=float32)
time = 62730	action = 0	current_phase = 1	next_phase = 0	reward = 0.722513	array([[  2.5842981, -45.557076 ]], dtype=float32)
time = 62735	action = 0	current_phase = 1	next_phase = 0	reward = 0.725377	array([[  2.5631952, -45.668602 ]], dtype=float32)
time = 62740	action = 0	current_phase = 1	next_phase = 0	reward = 0.720412	array([[  2.5978727, -45.51917  ]], dtype=float32)
time = 62745	action = 0	current_phase = 1	next_phase = 0	reward = 0.719290	array([[  2.5743399, -45.60541  ]], dtype=float32)
time = 62750	action = 0	current_phase = 1	next_phase = 0	reward = 0.443496	array([[  2.593934, -45.504684]], dtype=float32)
time = 62755	action = 0	current_phase = 1	next_phase = 0	reward = 0.998696	array([[  2.5623264, -45.28492  ]], dtype=float32)
time = 62760	action = 0	current_phase = 1	next_phase = 0	reward = 0.717425	array([[  2.5760565, -45.62887  ]], dtype=float32)
time = 62765	action = 0	current_phase = 1	next_phase = 0	reward = 0.448726	array([[  2.5331287, -45.717655 ]], dtype=float32)
time = 62770	action = 0	current_phase = 1	next_phase = 0	reward = 1.002937	array([[  2.5653677, -45.47     ]], dtype=float32)
time = 62775	action = 0	current_phase = 1	next_phase = 0	reward = 0.715320	array([[  2.540328, -45.71077 ]], dtype=float32)
time = 62780	action = 0	current_phase = 1	next_phase = 0	reward = 0.726094	array([[  2.5789547, -45.654385 ]], dtype=float32)
time = 62785	action = 0	current_phase = 1	next_phase = 0	reward = 0.724012	array([[  2.5906067, -45.49537  ]], dtype=float32)
time = 62790	action = 0	current_phase = 1	next_phase = 0	reward = 0.716537	array([[  2.5758934, -45.373695 ]], dtype=float32)
time = 62795	action = 0	current_phase = 1	next_phase = 0	reward = 0.709594	array([[  2.5857859, -45.565624 ]], dtype=float32)
time = 62800	action = 0	current_phase = 1	next_phase = 0	reward = 0.715859	array([[  2.606247, -45.486755]], dtype=float32)
time = 62805	action = 0	current_phase = 1	next_phase = 0	reward = 0.446998	array([[  2.5733948, -45.664253 ]], dtype=float32)
time = 62810	action = 0	current_phase = 1	next_phase = 0	reward = 1.004898	array([[  2.5890255, -45.486725 ]], dtype=float32)
time = 62815	action = 0	current_phase = 1	next_phase = 0	reward = 0.729744	array([[  2.5369997, -45.76837  ]], dtype=float32)
time = 62820	action = 0	current_phase = 1	next_phase = 0	reward = 0.727088	array([[  2.5740395, -45.444862 ]], dtype=float32)
time = 62825	action = 0	current_phase = 1	next_phase = 0	reward = 0.721688	array([[  2.6274767, -45.597874 ]], dtype=float32)
time = 62830	action = 0	current_phase = 1	next_phase = 0	reward = 0.722198	array([[  2.5627098, -45.686363 ]], dtype=float32)
time = 62835	action = 0	current_phase = 1	next_phase = 0	reward = 0.721084	array([[  2.574173, -45.38801 ]], dtype=float32)
time = 62840	action = 0	current_phase = 1	next_phase = 0	reward = 0.722746	array([[  2.543582, -45.677456]], dtype=float32)
time = 62845	action = 0	current_phase = 1	next_phase = 0	reward = 0.722707	array([[  2.5703535, -45.575996 ]], dtype=float32)
time = 62850	action = 0	current_phase = 1	next_phase = 0	reward = 0.717789	array([[  2.560814, -45.694855]], dtype=float32)
time = 62855	action = 0	current_phase = 1	next_phase = 0	reward = 0.444034	array([[  2.5365295, -45.709885 ]], dtype=float32)
time = 62860	action = 0	current_phase = 1	next_phase = 0	reward = 0.728299	array([[  2.5825434, -45.60679  ]], dtype=float32)
time = 62865	action = 0	current_phase = 1	next_phase = 0	reward = 0.726297	array([[  2.5986843, -45.543076 ]], dtype=float32)
time = 62870	action = 0	current_phase = 1	next_phase = 0	reward = 1.001418	array([[  2.5757647, -45.362846 ]], dtype=float32)
time = 62875	action = 0	current_phase = 1	next_phase = 0	reward = 0.712375	array([[  2.564207, -45.67013 ]], dtype=float32)
time = 62880	action = 0	current_phase = 1	next_phase = 0	reward = 0.716882	array([[  2.584033, -45.47505 ]], dtype=float32)
time = 62885	action = 0	current_phase = 1	next_phase = 0	reward = 0.720534	array([[  2.5556955, -45.676544 ]], dtype=float32)
time = 62890	action = 0	current_phase = 1	next_phase = 0	reward = 0.446046	array([[  2.5262594, -45.751663 ]], dtype=float32)
time = 62895	action = 0	current_phase = 1	next_phase = 0	reward = 1.005490	array([[  2.573763, -45.331356]], dtype=float32)
time = 62900	action = 0	current_phase = 1	next_phase = 0	reward = 0.716330	array([[  2.5516863, -45.664024 ]], dtype=float32)
time = 62905	action = 0	current_phase = 1	next_phase = 0	reward = 0.713132	array([[  2.5917873, -45.53784  ]], dtype=float32)
time = 62910	action = 0	current_phase = 1	next_phase = 0	reward = 0.712656	array([[  2.5612946, -45.71318  ]], dtype=float32)
time = 62915	action = 0	current_phase = 1	next_phase = 0	reward = 0.717159	array([[  2.5749636, -45.63157  ]], dtype=float32)
time = 62920	action = 0	current_phase = 1	next_phase = 0	reward = 0.725936	array([[  2.5637102, -45.30726  ]], dtype=float32)
time = 62925	action = 0	current_phase = 1	next_phase = 0	reward = 0.718119	array([[  2.561513, -45.66066 ]], dtype=float32)
time = 62930	action = 0	current_phase = 1	next_phase = 0	reward = 0.717184	array([[  2.6084461, -45.573944 ]], dtype=float32)
time = 62935	action = 0	current_phase = 1	next_phase = 0	reward = 0.719162	array([[  2.5835142, -45.61944  ]], dtype=float32)
time = 62940	action = 0	current_phase = 1	next_phase = 0	reward = 0.442636	array([[  2.5838575, -45.529358 ]], dtype=float32)
time = 62945	action = 0	current_phase = 1	next_phase = 0	reward = 0.991454	array([[  2.5662565, -45.497902 ]], dtype=float32)
time = 62950	action = 0	current_phase = 1	next_phase = 0	reward = 0.438490	array([[  2.5930262, -45.59828  ]], dtype=float32)
time = 62955	action = 0	current_phase = 1	next_phase = 0	reward = 1.010775	array([[  2.5593615, -45.698647 ]], dtype=float32)
time = 62960	action = 0	current_phase = 1	next_phase = 0	reward = 0.451481	array([[  2.5898113, -45.521397 ]], dtype=float32)
time = 62965	action = 0	current_phase = 1	next_phase = 0	reward = 1.003845	array([[  2.5586004, -45.661556 ]], dtype=float32)
time = 62970	action = 0	current_phase = 1	next_phase = 0	reward = 0.721308	array([[  2.568101, -45.668922]], dtype=float32)
time = 62975	action = 0	current_phase = 1	next_phase = 0	reward = 0.723377	array([[  2.5434465, -45.74036  ]], dtype=float32)
time = 62980	action = 0	current_phase = 1	next_phase = 0	reward = 0.440366	array([[  2.5990906, -45.65056  ]], dtype=float32)
time = 62985	action = 0	current_phase = 1	next_phase = 0	reward = 0.995079	array([[  2.5747156, -45.40172  ]], dtype=float32)
time = 62990	action = 0	current_phase = 1	next_phase = 0	reward = 0.714881	array([[  2.5947275, -45.44746  ]], dtype=float32)
time = 62995	action = 0	current_phase = 1	next_phase = 0	reward = 0.428695	array([[  2.5880556, -45.547806 ]], dtype=float32)
time = 63000	action = 0	current_phase = 1	next_phase = 0	reward = 0.440258	array([[  2.585064, -45.47229 ]], dtype=float32)
time = 63005	action = 0	current_phase = 1	next_phase = 0	reward = 0.732314	array([[  2.5945683, -45.48571  ]], dtype=float32)
time = 63010	action = 0	current_phase = 1	next_phase = 0	reward = 1.283522	array([[  2.5655994, -45.651176 ]], dtype=float32)
time = 63015	action = 0	current_phase = 1	next_phase = 0	reward = 0.444030	array([[  2.4954805, -45.782185 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2187.2025 - val_loss: 361.1638
Epoch 2/50
 - 4s - loss: 2202.1076 - val_loss: 389.6899
Epoch 3/50
 - 4s - loss: 2210.1495 - val_loss: 411.1988
Epoch 4/50
 - 4s - loss: 2168.4342 - val_loss: 322.9229
Epoch 5/50
 - 4s - loss: 2136.5728 - val_loss: 335.0016
Epoch 6/50
 - 4s - loss: 2148.4282 - val_loss: 328.9261
Epoch 7/50
 - 4s - loss: 2134.9832 - val_loss: 478.4961
Epoch 8/50
 - 4s - loss: 2164.5442 - val_loss: 322.9298
Epoch 9/50
 - 4s - loss: 2179.6830 - val_loss: 350.6659
Epoch 10/50
 - 4s - loss: 2191.6207 - val_loss: 319.0684
Epoch 11/50
 - 4s - loss: 2198.5488 - val_loss: 348.4930
Epoch 12/50
 - 4s - loss: 2162.0025 - val_loss: 319.3239
Epoch 13/50
 - 4s - loss: 2199.0220 - val_loss: 331.6553
Epoch 14/50
 - 4s - loss: 2156.9629 - val_loss: 316.6699
Epoch 15/50
 - 4s - loss: 2157.7015 - val_loss: 315.6569
Epoch 16/50
 - 4s - loss: 2160.6420 - val_loss: 315.4913
Epoch 17/50
 - 4s - loss: 2164.8373 - val_loss: 314.8278
Epoch 18/50
 - 4s - loss: 2156.7484 - val_loss: 321.0314
Epoch 19/50
 - 4s - loss: 2178.2731 - val_loss: 337.5696
Epoch 20/50
 - 4s - loss: 2168.2545 - val_loss: 322.0975
Epoch 21/50
 - 4s - loss: 2187.1526 - val_loss: 320.8656
Epoch 22/50
 - 4s - loss: 2181.9278 - val_loss: 332.6825
Epoch 23/50
 - 4s - loss: 2136.1074 - val_loss: 322.3747
Epoch 24/50
 - 4s - loss: 2148.4394 - val_loss: 324.4980
Epoch 25/50
 - 4s - loss: 2153.2948 - val_loss: 321.2058
Epoch 26/50
 - 4s - loss: 2157.3545 - val_loss: 322.9536
Epoch 27/50
 - 4s - loss: 2176.9214 - val_loss: 314.2487
Epoch 28/50
 - 4s - loss: 2185.4317 - val_loss: 315.8380
Epoch 29/50
 - 4s - loss: 2195.8177 - val_loss: 322.6113
Epoch 30/50
 - 4s - loss: 2172.9604 - val_loss: 309.7412
Epoch 31/50
 - 4s - loss: 2201.1291 - val_loss: 318.6303
Epoch 32/50
 - 4s - loss: 2155.2637 - val_loss: 322.9179
Epoch 33/50
 - 4s - loss: 2144.5432 - val_loss: 408.0823
Epoch 34/50
 - 4s - loss: 2207.4806 - val_loss: 407.3452
Epoch 35/50
 - 4s - loss: 2193.6101 - val_loss: 333.6166
Epoch 36/50
 - 4s - loss: 2157.7879 - val_loss: 322.3270
Epoch 37/50
 - 4s - loss: 2176.1884 - val_loss: 366.0427
Epoch 38/50
 - 4s - loss: 2192.5682 - val_loss: 411.5271
Epoch 39/50
 - 4s - loss: 2153.3291 - val_loss: 316.8020
Epoch 40/50
 - 4s - loss: 2167.8789 - val_loss: 338.2111
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 63020	action = 0	current_phase = 1	next_phase = 0	reward = 1.000739	array([[  2.3542156, -45.73829  ]], dtype=float32)
time = 63025	action = 0	current_phase = 1	next_phase = 0	reward = 0.721586	array([[  2.349185, -45.670753]], dtype=float32)
time = 63030	action = 0	current_phase = 1	next_phase = 0	reward = 0.725185	array([[  2.2681684, -45.303925 ]], dtype=float32)
time = 63035	action = 0	current_phase = 1	next_phase = 0	reward = 0.720287	array([[  2.2460184, -45.2386   ]], dtype=float32)
time = 63040	action = 0	current_phase = 1	next_phase = 0	reward = 0.727569	array([[  2.2742462, -45.308693 ]], dtype=float32)
time = 63045	action = 0	current_phase = 1	next_phase = 0	reward = 0.722011	array([[  2.1819525, -45.079987 ]], dtype=float32)
time = 63050	action = 0	current_phase = 1	next_phase = 0	reward = 0.444342	array([[  2.337988, -45.564804]], dtype=float32)
time = 63055	action = 0	current_phase = 1	next_phase = 0	reward = 0.730824	array([[  2.343111, -45.68346 ]], dtype=float32)
time = 63060	action = 0	current_phase = 1	next_phase = 0	reward = 1.007683	array([[  2.3535442, -45.695236 ]], dtype=float32)
time = 63065	action = 0	current_phase = 1	next_phase = 0	reward = 0.724998	array([[  2.2927628, -45.395763 ]], dtype=float32)
time = 63070	action = 0	current_phase = 1	next_phase = 0	reward = 0.728799	array([[  2.3786373, -45.684307 ]], dtype=float32)
time = 63075	action = 0	current_phase = 1	next_phase = 0	reward = 0.723583	array([[  2.3439388, -45.699993 ]], dtype=float32)
time = 63080	action = 0	current_phase = 1	next_phase = 0	reward = 0.725102	array([[  2.2902966, -45.366577 ]], dtype=float32)
time = 63085	action = 0	current_phase = 1	next_phase = 0	reward = 0.719882	array([[  2.3442345, -45.630714 ]], dtype=float32)
time = 63090	action = 0	current_phase = 1	next_phase = 0	reward = 0.721901	array([[  2.2975187, -45.374634 ]], dtype=float32)
time = 63095	action = 0	current_phase = 1	next_phase = 0	reward = 0.719465	array([[  2.2227697, -45.162605 ]], dtype=float32)
time = 63100	action = 0	current_phase = 1	next_phase = 0	reward = 0.713569	array([[  2.2345543, -45.21144  ]], dtype=float32)
time = 63105	action = 0	current_phase = 1	next_phase = 0	reward = 0.721815	array([[  2.2885141, -45.403046 ]], dtype=float32)
time = 63110	action = 0	current_phase = 1	next_phase = 0	reward = 0.726300	array([[  2.3337488, -45.62822  ]], dtype=float32)
time = 63115	action = 0	current_phase = 1	next_phase = 0	reward = 0.723479	array([[  2.2902298, -45.36551  ]], dtype=float32)
time = 63120	action = 0	current_phase = 1	next_phase = 0	reward = 0.715538	array([[  2.341446, -45.55262 ]], dtype=float32)
time = 63125	action = 0	current_phase = 1	next_phase = 0	reward = 0.719505	array([[  2.1037207, -44.89357  ]], dtype=float32)
time = 63130	action = 0	current_phase = 1	next_phase = 0	reward = 0.722070	array([[  2.3207588, -45.502663 ]], dtype=float32)
time = 63135	action = 0	current_phase = 1	next_phase = 0	reward = 0.725999	array([[  2.273178, -45.32247 ]], dtype=float32)
time = 63140	action = 0	current_phase = 1	next_phase = 0	reward = 0.716261	array([[  2.3426466, -45.66067  ]], dtype=float32)
time = 63145	action = 0	current_phase = 1	next_phase = 0	reward = 0.715429	array([[  2.3419905, -45.825226 ]], dtype=float32)
time = 63150	action = 0	current_phase = 1	next_phase = 0	reward = 0.714088	array([[  2.3409777, -45.616318 ]], dtype=float32)
time = 63155	action = 0	current_phase = 1	next_phase = 0	reward = 0.436972	array([[  2.3380737, -45.556007 ]], dtype=float32)
time = 63160	action = 0	current_phase = 1	next_phase = 0	reward = 0.727434	array([[  2.2663164, -45.307667 ]], dtype=float32)
time = 63165	action = 0	current_phase = 1	next_phase = 0	reward = 1.016593	array([[  2.2966185, -45.407593 ]], dtype=float32)
time = 63170	action = 0	current_phase = 1	next_phase = 0	reward = 0.714187	array([[  2.3319378, -45.55664  ]], dtype=float32)
time = 63175	action = 0	current_phase = 1	next_phase = 0	reward = 0.717249	array([[  2.2953882, -45.396732 ]], dtype=float32)
time = 63180	action = 0	current_phase = 1	next_phase = 0	reward = 0.445697	array([[  2.3441525, -45.606213 ]], dtype=float32)
time = 63185	action = 0	current_phase = 1	next_phase = 0	reward = 1.013496	array([[  2.3439817, -45.58648  ]], dtype=float32)
time = 63190	action = 0	current_phase = 1	next_phase = 0	reward = 0.725759	array([[  2.2051191, -45.137474 ]], dtype=float32)
time = 63195	action = 0	current_phase = 1	next_phase = 0	reward = 0.722423	array([[  2.3135824, -45.50157  ]], dtype=float32)
time = 63200	action = 0	current_phase = 1	next_phase = 0	reward = 0.722712	array([[  2.3568964, -45.79269  ]], dtype=float32)
time = 63205	action = 0	current_phase = 1	next_phase = 0	reward = 0.720032	array([[  2.1528606, -45.008293 ]], dtype=float32)
time = 63210	action = 0	current_phase = 1	next_phase = 0	reward = 0.719117	array([[  2.2765217, -45.338634 ]], dtype=float32)
time = 63215	action = 0	current_phase = 1	next_phase = 0	reward = 0.723818	array([[  2.342267, -45.61136 ]], dtype=float32)
time = 63220	action = 0	current_phase = 1	next_phase = 0	reward = 0.719742	array([[  2.1951046, -45.111763 ]], dtype=float32)
time = 63225	action = 0	current_phase = 1	next_phase = 0	reward = 0.448298	array([[  2.332346, -45.558144]], dtype=float32)
time = 63230	action = 0	current_phase = 1	next_phase = 0	reward = 1.007285	array([[  2.339736, -45.551945]], dtype=float32)
time = 63235	action = 0	current_phase = 1	next_phase = 0	reward = 0.711668	array([[  2.3371906, -45.62876  ]], dtype=float32)
time = 63240	action = 0	current_phase = 1	next_phase = 0	reward = 0.712975	array([[  2.354333, -45.79635 ]], dtype=float32)
time = 63245	action = 0	current_phase = 1	next_phase = 0	reward = 0.439466	array([[  2.3396473, -45.60353  ]], dtype=float32)
time = 63250	action = 0	current_phase = 1	next_phase = 0	reward = 0.725422	array([[  2.347005, -45.684425]], dtype=float32)
time = 63255	action = 0	current_phase = 1	next_phase = 0	reward = 1.010164	array([[  2.3487816, -45.638725 ]], dtype=float32)
time = 63260	action = 0	current_phase = 1	next_phase = 0	reward = 0.717694	array([[  2.187498, -45.079895]], dtype=float32)
time = 63265	action = 0	current_phase = 1	next_phase = 0	reward = 0.717595	array([[  2.3495693, -45.750076 ]], dtype=float32)
time = 63270	action = 0	current_phase = 1	next_phase = 0	reward = 0.718123	array([[  2.3015995, -45.43345  ]], dtype=float32)
time = 63275	action = 0	current_phase = 1	next_phase = 0	reward = 0.434583	array([[  2.356328, -45.76685 ]], dtype=float32)
time = 63280	action = 0	current_phase = 1	next_phase = 0	reward = 1.003778	array([[  2.2817154, -45.34966  ]], dtype=float32)
time = 63285	action = 0	current_phase = 1	next_phase = 0	reward = 0.722310	array([[  2.3470335, -45.74726  ]], dtype=float32)
time = 63290	action = 0	current_phase = 1	next_phase = 0	reward = 0.720529	array([[  2.3050041, -45.484657 ]], dtype=float32)
time = 63295	action = 0	current_phase = 1	next_phase = 0	reward = 0.718044	array([[  2.2654228, -45.285576 ]], dtype=float32)
time = 63300	action = 0	current_phase = 1	next_phase = 0	reward = 0.710979	array([[  2.2252617, -45.18094  ]], dtype=float32)
time = 63305	action = 0	current_phase = 1	next_phase = 0	reward = 0.721712	array([[  2.298191, -45.42614 ]], dtype=float32)
time = 63310	action = 0	current_phase = 1	next_phase = 0	reward = 0.718267	array([[  2.3382025, -45.624115 ]], dtype=float32)
time = 63315	action = 0	current_phase = 1	next_phase = 0	reward = 0.723599	array([[  2.315401, -45.461994]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2142.7998 - val_loss: 178.6877
Epoch 2/50
 - 4s - loss: 2140.8660 - val_loss: 228.4196
Epoch 3/50
 - 4s - loss: 2137.0188 - val_loss: 194.6848
Epoch 4/50
 - 4s - loss: 2170.9743 - val_loss: 166.4092
Epoch 5/50
 - 4s - loss: 2173.4515 - val_loss: 166.8481
Epoch 6/50
 - 4s - loss: 2168.9700 - val_loss: 194.8628
Epoch 7/50
 - 4s - loss: 2132.5096 - val_loss: 267.4253
Epoch 8/50
 - 4s - loss: 2150.7934 - val_loss: 161.3409
Epoch 9/50
 - 4s - loss: 2143.0831 - val_loss: 261.7931
Epoch 10/50
 - 4s - loss: 2168.4567 - val_loss: 268.6102
Epoch 11/50
 - 4s - loss: 2170.2044 - val_loss: 221.2176
Epoch 12/50
 - 4s - loss: 2155.5664 - val_loss: 186.5597
Epoch 13/50
 - 4s - loss: 2151.0458 - val_loss: 168.8502
Epoch 14/50
 - 4s - loss: 2146.7274 - val_loss: 197.5163
Epoch 15/50
 - 4s - loss: 2130.8480 - val_loss: 145.6726
Epoch 16/50
 - 4s - loss: 2156.2959 - val_loss: 223.1179
Epoch 17/50
 - 4s - loss: 2174.5914 - val_loss: 186.7407
Epoch 18/50
 - 4s - loss: 2179.2191 - val_loss: 187.2576
Epoch 19/50
 - 4s - loss: 2147.7174 - val_loss: 157.4377
Epoch 20/50
 - 4s - loss: 2128.5977 - val_loss: 183.7340
Epoch 21/50
 - 4s - loss: 2148.8996 - val_loss: 164.0687
Epoch 22/50
 - 4s - loss: 2172.0384 - val_loss: 193.5443
Epoch 23/50
 - 4s - loss: 2144.7847 - val_loss: 162.8481
Epoch 24/50
 - 4s - loss: 2135.7900 - val_loss: 241.5655
Epoch 25/50
 - 4s - loss: 2137.0275 - val_loss: 152.4452
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 63320	action = 0	current_phase = 1	next_phase = 0	reward = 0.720334	array([[  2.5383177, -45.91733  ]], dtype=float32)
time = 63325	action = 0	current_phase = 1	next_phase = 0	reward = 0.715545	array([[  2.5048122, -45.76391  ]], dtype=float32)
time = 63330	action = 0	current_phase = 1	next_phase = 0	reward = 0.437450	array([[  2.5112753, -45.829086 ]], dtype=float32)
time = 63335	action = 0	current_phase = 1	next_phase = 0	reward = 0.722803	array([[  2.3708467, -45.37906  ]], dtype=float32)
time = 63340	action = 0	current_phase = 1	next_phase = 0	reward = 1.000679	array([[  2.4767246, -45.708046 ]], dtype=float32)
time = 63345	action = 0	current_phase = 1	next_phase = 0	reward = 0.720456	array([[  2.508582, -45.757607]], dtype=float32)
time = 63350	action = 0	current_phase = 1	next_phase = 0	reward = 0.445063	array([[  2.430667, -45.5567  ]], dtype=float32)
time = 63355	action = 0	current_phase = 1	next_phase = 0	reward = 1.006345	array([[  2.329012, -45.315434]], dtype=float32)
time = 63360	action = 0	current_phase = 1	next_phase = 0	reward = 0.723471	array([[  2.4032097, -45.460953 ]], dtype=float32)
time = 63365	action = 0	current_phase = 1	next_phase = 0	reward = 0.723828	array([[  2.421959, -45.55794 ]], dtype=float32)
time = 63370	action = 0	current_phase = 1	next_phase = 0	reward = 0.727053	array([[  2.5626965, -46.143036 ]], dtype=float32)
time = 63375	action = 0	current_phase = 1	next_phase = 0	reward = 0.717737	array([[  2.5324678, -45.82065  ]], dtype=float32)
time = 63380	action = 0	current_phase = 1	next_phase = 0	reward = 0.442291	array([[  2.4241428, -45.509064 ]], dtype=float32)
time = 63385	action = 0	current_phase = 1	next_phase = 0	reward = 0.988808	array([[  2.541088, -45.986286]], dtype=float32)
time = 63390	action = 0	current_phase = 1	next_phase = 0	reward = 0.711792	array([[  2.520135, -45.81698 ]], dtype=float32)
time = 63395	action = 0	current_phase = 1	next_phase = 0	reward = 0.726424	array([[  2.3005714, -45.21719  ]], dtype=float32)
time = 63400	action = 0	current_phase = 1	next_phase = 0	reward = 0.448646	array([[  2.5138607, -45.82437  ]], dtype=float32)
time = 63405	action = 0	current_phase = 1	next_phase = 0	reward = 1.010782	array([[  2.4249363, -45.52736  ]], dtype=float32)
time = 63410	action = 0	current_phase = 1	next_phase = 0	reward = 0.714240	array([[  2.4860468, -45.67526  ]], dtype=float32)
time = 63415	action = 0	current_phase = 1	next_phase = 0	reward = 0.719331	array([[  2.4416418, -45.56745  ]], dtype=float32)
time = 63420	action = 0	current_phase = 1	next_phase = 0	reward = 0.718073	array([[  2.5222197, -45.834415 ]], dtype=float32)
time = 63425	action = 0	current_phase = 1	next_phase = 0	reward = 0.719007	array([[  2.5034828, -45.779243 ]], dtype=float32)
time = 63430	action = 0	current_phase = 1	next_phase = 0	reward = 0.728901	array([[  2.482973, -45.686935]], dtype=float32)
time = 63435	action = 0	current_phase = 1	next_phase = 0	reward = 0.722699	array([[  2.5373163, -45.94471  ]], dtype=float32)
time = 63440	action = 0	current_phase = 1	next_phase = 0	reward = 0.724963	array([[  2.5190744, -45.899334 ]], dtype=float32)
time = 63445	action = 0	current_phase = 1	next_phase = 0	reward = 0.726950	array([[  2.5651197, -46.079155 ]], dtype=float32)
time = 63450	action = 0	current_phase = 1	next_phase = 0	reward = 0.718883	array([[  2.498314, -45.76488 ]], dtype=float32)
time = 63455	action = 0	current_phase = 1	next_phase = 0	reward = 0.441814	array([[  2.40203 , -45.450405]], dtype=float32)
time = 63460	action = 0	current_phase = 1	next_phase = 0	reward = 0.996850	array([[  2.5029297, -45.767426 ]], dtype=float32)
time = 63465	action = 0	current_phase = 1	next_phase = 0	reward = 0.439018	array([[  2.539279, -45.96248 ]], dtype=float32)
time = 63470	action = 0	current_phase = 1	next_phase = 0	reward = 1.000056	array([[  2.2986116, -45.19971  ]], dtype=float32)
time = 63475	action = 0	current_phase = 1	next_phase = 0	reward = 0.711365	array([[  2.3224392, -45.24534  ]], dtype=float32)
time = 63480	action = 0	current_phase = 1	next_phase = 0	reward = 0.710310	array([[  2.5400066, -46.12062  ]], dtype=float32)
time = 63485	action = 0	current_phase = 1	next_phase = 0	reward = 0.717141	array([[  2.4028406, -45.44796  ]], dtype=float32)
time = 63490	action = 0	current_phase = 1	next_phase = 0	reward = 0.437966	array([[  2.4549608, -45.58449  ]], dtype=float32)
time = 63495	action = 0	current_phase = 1	next_phase = 0	reward = 1.008478	array([[  2.5382633, -45.941257 ]], dtype=float32)
time = 63500	action = 0	current_phase = 1	next_phase = 0	reward = 0.723326	array([[  2.3601246, -45.351746 ]], dtype=float32)
time = 63505	action = 0	current_phase = 1	next_phase = 0	reward = 0.722474	array([[  2.4135551, -45.486748 ]], dtype=float32)
time = 63510	action = 0	current_phase = 1	next_phase = 0	reward = 0.720568	array([[  2.5384111, -45.91857  ]], dtype=float32)
time = 63515	action = 0	current_phase = 1	next_phase = 0	reward = 0.721225	array([[  2.4688091, -45.617676 ]], dtype=float32)
time = 63520	action = 0	current_phase = 1	next_phase = 0	reward = 0.719263	array([[  2.488535, -45.74984 ]], dtype=float32)
time = 63525	action = 0	current_phase = 1	next_phase = 0	reward = 0.719388	array([[  2.3561087, -45.36728  ]], dtype=float32)
time = 63530	action = 0	current_phase = 1	next_phase = 0	reward = 0.444343	array([[  2.4378357, -45.581562 ]], dtype=float32)
time = 63535	action = 0	current_phase = 1	next_phase = 0	reward = 1.004261	array([[  2.527547, -45.899048]], dtype=float32)
time = 63540	action = 0	current_phase = 1	next_phase = 0	reward = 0.721012	array([[  2.4900274, -45.712376 ]], dtype=float32)
time = 63545	action = 0	current_phase = 1	next_phase = 0	reward = 0.726407	array([[  2.5117369, -45.828537 ]], dtype=float32)
time = 63550	action = 0	current_phase = 1	next_phase = 0	reward = 0.716279	array([[  2.5344944, -45.93061  ]], dtype=float32)
time = 63555	action = 0	current_phase = 1	next_phase = 0	reward = 0.716093	array([[  2.4382687, -45.56845  ]], dtype=float32)
time = 63560	action = 0	current_phase = 1	next_phase = 0	reward = 0.716278	array([[  2.5047312, -45.819    ]], dtype=float32)
time = 63565	action = 0	current_phase = 1	next_phase = 0	reward = 0.441683	array([[  2.456707, -45.6605  ]], dtype=float32)
time = 63570	action = 0	current_phase = 1	next_phase = 0	reward = 0.724123	array([[  2.4405375, -45.54305  ]], dtype=float32)
time = 63575	action = 0	current_phase = 1	next_phase = 0	reward = 0.449814	array([[  2.5251932, -45.917877 ]], dtype=float32)
time = 63580	action = 0	current_phase = 1	next_phase = 0	reward = 1.288872	array([[  2.4849586, -45.700447 ]], dtype=float32)
time = 63585	action = 0	current_phase = 1	next_phase = 0	reward = 0.446221	array([[  2.5442886, -45.903427 ]], dtype=float32)
time = 63590	action = 0	current_phase = 1	next_phase = 0	reward = 1.012838	array([[  2.5376997, -45.912643 ]], dtype=float32)
time = 63595	action = 0	current_phase = 1	next_phase = 0	reward = 0.718855	array([[  2.467536, -45.64384 ]], dtype=float32)
time = 63600	action = 0	current_phase = 1	next_phase = 0	reward = 0.722322	array([[  2.4640837, -45.635685 ]], dtype=float32)
time = 63605	action = 0	current_phase = 1	next_phase = 0	reward = 0.444335	array([[  2.5527601, -46.128616 ]], dtype=float32)
time = 63610	action = 0	current_phase = 1	next_phase = 0	reward = 1.010452	array([[  2.488101, -45.703075]], dtype=float32)
time = 63615	action = 0	current_phase = 1	next_phase = 0	reward = 0.718392	array([[  2.456586, -45.615772]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 361.1772 - val_loss: 483.3069
Epoch 2/50
 - 4s - loss: 307.5274 - val_loss: 451.5970
Epoch 3/50
 - 4s - loss: 299.8108 - val_loss: 457.4785
Epoch 4/50
 - 4s - loss: 311.8089 - val_loss: 471.1343
Epoch 5/50
 - 5s - loss: 319.3720 - val_loss: 444.1927
Epoch 6/50
 - 4s - loss: 384.3857 - val_loss: 451.8186
Epoch 7/50
 - 4s - loss: 313.8112 - val_loss: 499.8448
Epoch 8/50
 - 4s - loss: 317.0139 - val_loss: 484.7624
Epoch 9/50
 - 4s - loss: 308.1814 - val_loss: 480.5637
Epoch 10/50
 - 4s - loss: 332.3093 - val_loss: 516.0949
Epoch 11/50
 - 4s - loss: 358.8059 - val_loss: 537.4816
Epoch 12/50
 - 4s - loss: 370.5245 - val_loss: 534.4580
Epoch 13/50
 - 4s - loss: 344.5948 - val_loss: 479.9721
Epoch 14/50
 - 4s - loss: 377.0214 - val_loss: 486.8272
Epoch 15/50
 - 4s - loss: 376.8706 - val_loss: 511.6225
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 63620	action = 0	current_phase = 1	next_phase = 0	reward = 0.442007	array([[  2.5868788, -46.190033 ]], dtype=float32)
time = 63625	action = 0	current_phase = 1	next_phase = 0	reward = 1.001455	array([[  2.432641, -45.617584]], dtype=float32)
time = 63630	action = 0	current_phase = 1	next_phase = 0	reward = 0.720260	array([[  2.4613771, -45.67095  ]], dtype=float32)
time = 63635	action = 0	current_phase = 1	next_phase = 0	reward = 0.448858	array([[  2.4730225, -45.696465 ]], dtype=float32)
time = 63640	action = 0	current_phase = 1	next_phase = 0	reward = 0.998814	array([[  2.521266, -45.840897]], dtype=float32)
time = 63645	action = 0	current_phase = 1	next_phase = 0	reward = 0.715908	array([[  2.5645285, -46.00832  ]], dtype=float32)
time = 63650	action = 0	current_phase = 1	next_phase = 0	reward = 0.442471	array([[  2.5818415, -46.11414  ]], dtype=float32)
time = 63655	action = 0	current_phase = 1	next_phase = 0	reward = 0.998741	array([[  2.58566 , -46.300095]], dtype=float32)
time = 63660	action = 0	current_phase = 1	next_phase = 0	reward = 0.441650	array([[  2.5906382, -46.235703 ]], dtype=float32)
time = 63665	action = 0	current_phase = 1	next_phase = 0	reward = 1.004415	array([[  2.580758, -46.10955 ]], dtype=float32)
time = 63670	action = 0	current_phase = 1	next_phase = 0	reward = 0.721191	array([[  2.5444803, -45.93424  ]], dtype=float32)
time = 63675	action = 0	current_phase = 1	next_phase = 0	reward = 0.433255	array([[  2.537675, -45.90313 ]], dtype=float32)
time = 63680	action = 0	current_phase = 1	next_phase = 0	reward = 0.999063	array([[  2.5929174, -46.339584 ]], dtype=float32)
time = 63685	action = 0	current_phase = 1	next_phase = 0	reward = 0.718054	array([[  2.5034761, -45.786003 ]], dtype=float32)
time = 63690	action = 0	current_phase = 1	next_phase = 0	reward = 0.710450	array([[  2.4257889, -45.577507 ]], dtype=float32)
time = 63695	action = 0	current_phase = 1	next_phase = 0	reward = 0.442633	array([[  2.489256, -45.782707]], dtype=float32)
time = 63700	action = 0	current_phase = 1	next_phase = 0	reward = 1.004117	array([[  2.4647388, -45.67855  ]], dtype=float32)
time = 63705	action = 0	current_phase = 1	next_phase = 0	reward = 0.715500	array([[  2.5911913, -46.210052 ]], dtype=float32)
time = 63710	action = 0	current_phase = 1	next_phase = 0	reward = 0.723547	array([[  2.5819864, -46.09584  ]], dtype=float32)
time = 63715	action = 0	current_phase = 1	next_phase = 0	reward = 0.717251	array([[  2.4790096, -45.723648 ]], dtype=float32)
time = 63720	action = 0	current_phase = 1	next_phase = 0	reward = 0.718218	array([[  2.5778723, -46.13523  ]], dtype=float32)
time = 63725	action = 0	current_phase = 1	next_phase = 0	reward = 0.443727	array([[  2.584672, -46.12042 ]], dtype=float32)
time = 63730	action = 0	current_phase = 1	next_phase = 0	reward = 0.725922	array([[  2.5709066, -46.032913 ]], dtype=float32)
time = 63735	action = 0	current_phase = 1	next_phase = 0	reward = 1.010245	array([[  2.4690685, -45.690216 ]], dtype=float32)
time = 63740	action = 0	current_phase = 1	next_phase = 0	reward = 0.725375	array([[  2.5467405, -45.97637  ]], dtype=float32)
time = 63745	action = 0	current_phase = 1	next_phase = 0	reward = 0.717499	array([[  2.425249, -45.645264]], dtype=float32)
time = 63750	action = 0	current_phase = 1	next_phase = 0	reward = 0.721704	array([[  2.2791796, -45.32115  ]], dtype=float32)
time = 63755	action = 0	current_phase = 1	next_phase = 0	reward = 0.721138	array([[  2.4958277, -45.76645  ]], dtype=float32)
time = 63760	action = 0	current_phase = 1	next_phase = 0	reward = 0.446126	array([[  2.5841188, -46.20543  ]], dtype=float32)
time = 63765	action = 0	current_phase = 1	next_phase = 0	reward = 1.007940	array([[  2.5691595, -46.051037 ]], dtype=float32)
time = 63770	action = 0	current_phase = 1	next_phase = 0	reward = 0.716286	array([[  2.4470387, -45.636337 ]], dtype=float32)
time = 63775	action = 0	current_phase = 1	next_phase = 0	reward = 0.726598	array([[  2.5946188, -46.327034 ]], dtype=float32)
time = 63780	action = 0	current_phase = 1	next_phase = 0	reward = 0.717487	array([[  2.5360098, -45.899452 ]], dtype=float32)
time = 63785	action = 0	current_phase = 1	next_phase = 0	reward = 0.434528	array([[  2.5367537, -45.89852  ]], dtype=float32)
time = 63790	action = 0	current_phase = 1	next_phase = 0	reward = 1.006554	array([[  2.560504, -45.986572]], dtype=float32)
time = 63795	action = 0	current_phase = 1	next_phase = 0	reward = 0.715953	array([[  2.4928694, -45.766068 ]], dtype=float32)
time = 63800	action = 0	current_phase = 1	next_phase = 0	reward = 0.439397	array([[  2.5137243, -45.85     ]], dtype=float32)
time = 63805	action = 0	current_phase = 1	next_phase = 0	reward = 0.448421	array([[  2.5476942, -45.963947 ]], dtype=float32)
time = 63810	action = 0	current_phase = 1	next_phase = 0	reward = 1.286931	array([[  2.5418444, -45.939716 ]], dtype=float32)
time = 63815	action = 0	current_phase = 1	next_phase = 0	reward = 0.729479	array([[  2.543149, -46.056572]], dtype=float32)
time = 63820	action = 0	current_phase = 1	next_phase = 0	reward = 0.711519	array([[  2.5113344, -45.817696 ]], dtype=float32)
time = 63825	action = 0	current_phase = 1	next_phase = 0	reward = 0.719279	array([[  2.5662775, -46.03586  ]], dtype=float32)
time = 63830	action = 0	current_phase = 1	next_phase = 0	reward = 0.717065	array([[  2.5475874, -45.946533 ]], dtype=float32)
time = 63835	action = 0	current_phase = 1	next_phase = 0	reward = 0.443471	array([[  2.3879652, -45.50946  ]], dtype=float32)
time = 63840	action = 0	current_phase = 1	next_phase = 0	reward = 0.999688	array([[  2.3951483, -45.53414  ]], dtype=float32)
time = 63845	action = 0	current_phase = 1	next_phase = 0	reward = 0.717684	array([[  2.588088, -46.192215]], dtype=float32)
time = 63850	action = 0	current_phase = 1	next_phase = 0	reward = 0.718291	array([[  2.4807997, -45.727592 ]], dtype=float32)
time = 63855	action = 0	current_phase = 1	next_phase = 0	reward = 0.442395	array([[  2.563573, -46.01575 ]], dtype=float32)
time = 63860	action = 0	current_phase = 1	next_phase = 0	reward = 1.003503	array([[  2.4305563, -45.592308 ]], dtype=float32)
time = 63865	action = 0	current_phase = 1	next_phase = 0	reward = 0.716284	array([[  2.552909, -45.979187]], dtype=float32)
time = 63870	action = 0	current_phase = 1	next_phase = 0	reward = 0.720362	array([[  2.5350447, -45.886276 ]], dtype=float32)
time = 63875	action = 0	current_phase = 1	next_phase = 0	reward = 0.719073	array([[  2.5587168, -45.96971  ]], dtype=float32)
time = 63880	action = 0	current_phase = 1	next_phase = 0	reward = 0.444175	array([[  2.5432768, -45.931305 ]], dtype=float32)
time = 63885	action = 0	current_phase = 1	next_phase = 0	reward = 1.005048	array([[  2.5945387, -46.09774  ]], dtype=float32)
time = 63890	action = 0	current_phase = 1	next_phase = 0	reward = 0.717403	array([[  2.5553827, -45.970913 ]], dtype=float32)
time = 63895	action = 0	current_phase = 1	next_phase = 0	reward = 0.437556	array([[  2.4026394, -45.52842  ]], dtype=float32)
time = 63900	action = 0	current_phase = 1	next_phase = 0	reward = 1.000105	array([[  2.5962  , -46.210014]], dtype=float32)
time = 63905	action = 0	current_phase = 1	next_phase = 0	reward = 0.437194	array([[  2.4349957, -45.604454 ]], dtype=float32)
time = 63910	action = 0	current_phase = 1	next_phase = 0	reward = 1.013382	array([[  2.4633112, -45.679977 ]], dtype=float32)
time = 63915	action = 0	current_phase = 1	next_phase = 0	reward = 0.725900	array([[  2.3390036, -45.416092 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2239.9132 - val_loss: 370.0208
Epoch 2/50
 - 4s - loss: 2207.4275 - val_loss: 421.5333
Epoch 3/50
 - 4s - loss: 2238.5715 - val_loss: 402.6525
Epoch 4/50
 - 4s - loss: 2230.0762 - val_loss: 420.3015
Epoch 5/50
 - 4s - loss: 2227.1867 - val_loss: 393.6206
Epoch 6/50
 - 4s - loss: 2225.9645 - val_loss: 382.0584
Epoch 7/50
 - 4s - loss: 2236.7748 - val_loss: 368.2593
Epoch 8/50
 - 4s - loss: 2205.5145 - val_loss: 405.1210
Epoch 9/50
 - 4s - loss: 2316.5309 - val_loss: 379.1309
Epoch 10/50
 - 4s - loss: 2204.3934 - val_loss: 396.6829
Epoch 11/50
 - 4s - loss: 2193.7486 - val_loss: 376.7536
Epoch 12/50
 - 4s - loss: 2274.1510 - val_loss: 398.1826
Epoch 13/50
 - 4s - loss: 2196.1442 - val_loss: 386.2336
Epoch 14/50
 - 4s - loss: 2184.3939 - val_loss: 378.1922
Epoch 15/50
 - 4s - loss: 2188.6022 - val_loss: 387.9261
Epoch 16/50
 - 4s - loss: 2188.7853 - val_loss: 451.4393
Epoch 17/50
 - 4s - loss: 2205.1781 - val_loss: 422.1700
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 63920	action = 0	current_phase = 1	next_phase = 0	reward = 0.719785	array([[  2.323432, -45.82385 ]], dtype=float32)
time = 63925	action = 0	current_phase = 1	next_phase = 0	reward = 0.718744	array([[  2.3708897, -46.003513 ]], dtype=float32)
time = 63930	action = 0	current_phase = 1	next_phase = 0	reward = 0.725497	array([[  2.36098, -46.0506 ]], dtype=float32)
time = 63935	action = 0	current_phase = 1	next_phase = 0	reward = 0.710558	array([[  2.3358545, -45.70991  ]], dtype=float32)
time = 63940	action = 0	current_phase = 1	next_phase = 0	reward = 0.438079	array([[  2.286543, -45.756317]], dtype=float32)
time = 63945	action = 0	current_phase = 1	next_phase = 0	reward = 1.000857	array([[  2.365281, -46.0354  ]], dtype=float32)
time = 63950	action = 0	current_phase = 1	next_phase = 0	reward = 0.439152	array([[  2.3598185, -45.949875 ]], dtype=float32)
time = 63955	action = 0	current_phase = 1	next_phase = 0	reward = 1.006742	array([[  2.2114782, -45.36863  ]], dtype=float32)
time = 63960	action = 0	current_phase = 1	next_phase = 0	reward = 0.729530	array([[  2.2633314, -45.69939  ]], dtype=float32)
time = 63965	action = 0	current_phase = 1	next_phase = 0	reward = 0.723410	array([[  2.329238, -45.68725 ]], dtype=float32)
time = 63970	action = 0	current_phase = 1	next_phase = 0	reward = 0.721825	array([[  2.3491173, -45.97466  ]], dtype=float32)
time = 63975	action = 0	current_phase = 1	next_phase = 0	reward = 0.720265	array([[  2.3546944, -45.840202 ]], dtype=float32)
time = 63980	action = 0	current_phase = 1	next_phase = 0	reward = 0.722478	array([[  2.3447676, -46.07544  ]], dtype=float32)
time = 63985	action = 0	current_phase = 1	next_phase = 0	reward = 0.728474	array([[  2.3714428, -45.95041  ]], dtype=float32)
time = 63990	action = 0	current_phase = 1	next_phase = 0	reward = 0.725473	array([[  2.3454256, -45.742516 ]], dtype=float32)
time = 63995	action = 0	current_phase = 1	next_phase = 0	reward = 0.721030	array([[  2.3608694, -46.016006 ]], dtype=float32)
time = 64000	action = 0	current_phase = 1	next_phase = 0	reward = 0.724093	array([[  2.3419685, -45.84579  ]], dtype=float32)
time = 64005	action = 0	current_phase = 1	next_phase = 0	reward = 0.712958	array([[  2.3349638, -46.107605 ]], dtype=float32)
time = 64010	action = 0	current_phase = 1	next_phase = 0	reward = 0.442823	array([[  2.255519, -45.666702]], dtype=float32)
time = 64015	action = 0	current_phase = 1	next_phase = 0	reward = 1.005254	array([[  2.3585634, -46.062813 ]], dtype=float32)
time = 64020	action = 0	current_phase = 1	next_phase = 0	reward = 0.722026	array([[  2.351181, -45.837566]], dtype=float32)
time = 64025	action = 0	current_phase = 1	next_phase = 0	reward = 0.720019	array([[  2.3411388, -46.016296 ]], dtype=float32)
time = 64030	action = 0	current_phase = 1	next_phase = 0	reward = 0.716767	array([[  2.3528814, -46.031567 ]], dtype=float32)
time = 64035	action = 0	current_phase = 1	next_phase = 0	reward = 0.718598	array([[  2.354824, -45.86815 ]], dtype=float32)
time = 64040	action = 0	current_phase = 1	next_phase = 0	reward = 0.725841	array([[  2.371293, -46.024925]], dtype=float32)
time = 64045	action = 0	current_phase = 1	next_phase = 0	reward = 0.718777	array([[  2.3129349, -45.68776  ]], dtype=float32)
time = 64050	action = 0	current_phase = 1	next_phase = 0	reward = 0.722429	array([[  2.3663988, -45.902084 ]], dtype=float32)
time = 64055	action = 0	current_phase = 1	next_phase = 0	reward = 0.726784	array([[  2.3610897, -45.948753 ]], dtype=float32)
time = 64060	action = 0	current_phase = 1	next_phase = 0	reward = 0.724390	array([[  2.3837442, -45.938354 ]], dtype=float32)
time = 64065	action = 0	current_phase = 1	next_phase = 0	reward = 0.721852	array([[  2.3203678, -45.6885   ]], dtype=float32)
time = 64070	action = 0	current_phase = 1	next_phase = 0	reward = 0.721474	array([[  2.346858, -45.891373]], dtype=float32)
time = 64075	action = 0	current_phase = 1	next_phase = 0	reward = 0.719898	array([[  2.272295, -45.594162]], dtype=float32)
time = 64080	action = 0	current_phase = 1	next_phase = 0	reward = 0.719885	array([[  2.2811794, -45.628838 ]], dtype=float32)
time = 64085	action = 0	current_phase = 1	next_phase = 0	reward = 0.718901	array([[  2.2905502, -45.71231  ]], dtype=float32)
time = 64090	action = 0	current_phase = 1	next_phase = 0	reward = 0.719679	array([[  2.3427267, -46.011948 ]], dtype=float32)
time = 64095	action = 0	current_phase = 1	next_phase = 0	reward = 0.720038	array([[  2.2748032, -45.738113 ]], dtype=float32)
time = 64100	action = 0	current_phase = 1	next_phase = 0	reward = 0.441025	array([[  2.375309, -46.07142 ]], dtype=float32)
time = 64105	action = 0	current_phase = 1	next_phase = 0	reward = 1.002465	array([[  2.3571892, -46.07474  ]], dtype=float32)
time = 64110	action = 0	current_phase = 1	next_phase = 0	reward = 0.718360	array([[  2.222847, -45.354927]], dtype=float32)
time = 64115	action = 0	current_phase = 1	next_phase = 0	reward = 0.717127	array([[  2.3606644, -45.780807 ]], dtype=float32)
time = 64120	action = 0	current_phase = 1	next_phase = 0	reward = 0.711757	array([[  2.3705578, -46.001053 ]], dtype=float32)
time = 64125	action = 0	current_phase = 1	next_phase = 0	reward = 0.447710	array([[  2.329093, -45.63747 ]], dtype=float32)
time = 64130	action = 0	current_phase = 1	next_phase = 0	reward = 1.002414	array([[  2.3346767, -45.706146 ]], dtype=float32)
time = 64135	action = 0	current_phase = 1	next_phase = 0	reward = 0.447506	array([[  2.3445835, -46.045227 ]], dtype=float32)
time = 64140	action = 0	current_phase = 1	next_phase = 0	reward = 1.008228	array([[  2.3654423, -45.949398 ]], dtype=float32)
time = 64145	action = 0	current_phase = 1	next_phase = 0	reward = 0.727691	array([[  2.3295374, -45.66967  ]], dtype=float32)
time = 64150	action = 0	current_phase = 1	next_phase = 0	reward = 0.726046	array([[  2.3635664, -45.998775 ]], dtype=float32)
time = 64155	action = 0	current_phase = 1	next_phase = 0	reward = 0.724577	array([[  2.3395605, -45.824253 ]], dtype=float32)
time = 64160	action = 0	current_phase = 1	next_phase = 0	reward = 0.721028	array([[  2.364606, -45.791065]], dtype=float32)
time = 64165	action = 0	current_phase = 1	next_phase = 0	reward = 0.716401	array([[  2.3706617, -45.863293 ]], dtype=float32)
time = 64170	action = 0	current_phase = 1	next_phase = 0	reward = 0.711951	array([[  2.3763905, -46.000626 ]], dtype=float32)
time = 64175	action = 0	current_phase = 1	next_phase = 0	reward = 0.713808	array([[  2.3401384, -45.70623  ]], dtype=float32)
time = 64180	action = 0	current_phase = 1	next_phase = 0	reward = 0.717736	array([[  2.363451, -45.8109  ]], dtype=float32)
time = 64185	action = 0	current_phase = 1	next_phase = 0	reward = 0.727903	array([[  2.3644094, -45.86115  ]], dtype=float32)
time = 64190	action = 0	current_phase = 1	next_phase = 0	reward = 0.731755	array([[  2.3082676, -45.638245 ]], dtype=float32)
time = 64195	action = 0	current_phase = 1	next_phase = 0	reward = 0.714496	array([[  2.3600874, -45.920277 ]], dtype=float32)
time = 64200	action = 0	current_phase = 1	next_phase = 0	reward = 0.718273	array([[  2.338953, -45.7089  ]], dtype=float32)
time = 64205	action = 0	current_phase = 1	next_phase = 0	reward = 0.439363	array([[  2.333727, -45.72496 ]], dtype=float32)
time = 64210	action = 0	current_phase = 1	next_phase = 0	reward = 0.997228	array([[  2.3010225, -45.56775  ]], dtype=float32)
time = 64215	action = 0	current_phase = 1	next_phase = 0	reward = 0.438402	array([[  2.31048 , -45.569473]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 330.5165 - val_loss: 91.5111
Epoch 2/50
 - 4s - loss: 347.1330 - val_loss: 77.7716
Epoch 3/50
 - 4s - loss: 319.8486 - val_loss: 96.0066
Epoch 4/50
 - 4s - loss: 345.2308 - val_loss: 86.3392
Epoch 5/50
 - 4s - loss: 338.6839 - val_loss: 96.9421
Epoch 6/50
 - 4s - loss: 332.2299 - val_loss: 78.4438
Epoch 7/50
 - 4s - loss: 317.5314 - val_loss: 79.0785
Epoch 8/50
 - 4s - loss: 318.1320 - val_loss: 94.2607
Epoch 9/50
 - 4s - loss: 302.9880 - val_loss: 66.0741
Epoch 10/50
 - 4s - loss: 333.4622 - val_loss: 106.7828
Epoch 11/50
 - 4s - loss: 307.3464 - val_loss: 96.0724
Epoch 12/50
 - 4s - loss: 318.6875 - val_loss: 68.2427
Epoch 13/50
 - 4s - loss: 310.2063 - val_loss: 78.6053
Epoch 14/50
 - 4s - loss: 293.1045 - val_loss: 100.2815
Epoch 15/50
 - 4s - loss: 297.5557 - val_loss: 107.1943
Epoch 16/50
 - 4s - loss: 346.1785 - val_loss: 85.1200
Epoch 17/50
 - 4s - loss: 313.3904 - val_loss: 89.4509
Epoch 18/50
 - 4s - loss: 300.5210 - val_loss: 109.0566
Epoch 19/50
 - 4s - loss: 293.3548 - val_loss: 101.8162
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 64220	action = 0	current_phase = 1	next_phase = 0	reward = 1.011896	array([[  2.4449654, -45.956295 ]], dtype=float32)
time = 64225	action = 0	current_phase = 1	next_phase = 0	reward = 0.722026	array([[  2.4536839, -46.065765 ]], dtype=float32)
time = 64230	action = 0	current_phase = 1	next_phase = 0	reward = 0.720316	array([[  2.352642, -46.41177 ]], dtype=float32)
time = 64235	action = 0	current_phase = 1	next_phase = 0	reward = 0.717551	array([[  2.472721, -46.066452]], dtype=float32)
time = 64240	action = 0	current_phase = 1	next_phase = 0	reward = 0.704510	array([[  2.4272022, -46.278145 ]], dtype=float32)
time = 64245	action = 0	current_phase = 1	next_phase = 0	reward = 0.718824	array([[  2.399992, -45.765305]], dtype=float32)
time = 64250	action = 0	current_phase = 1	next_phase = 0	reward = 0.719979	array([[  2.4658527, -46.14344  ]], dtype=float32)
time = 64255	action = 0	current_phase = 1	next_phase = 0	reward = 0.715252	array([[  2.4584846, -46.059853 ]], dtype=float32)
time = 64260	action = 0	current_phase = 1	next_phase = 0	reward = 0.439903	array([[  2.430481, -45.896156]], dtype=float32)
time = 64265	action = 0	current_phase = 1	next_phase = 0	reward = 0.725481	array([[  2.4447021, -46.220345 ]], dtype=float32)
time = 64270	action = 0	current_phase = 1	next_phase = 0	reward = 1.001829	array([[  2.3208427, -45.69133  ]], dtype=float32)
time = 64275	action = 0	current_phase = 1	next_phase = 0	reward = 0.720740	array([[  2.405528, -45.76506 ]], dtype=float32)
time = 64280	action = 0	current_phase = 1	next_phase = 0	reward = 0.731312	array([[  2.4379025, -46.15895  ]], dtype=float32)
time = 64285	action = 0	current_phase = 1	next_phase = 0	reward = 0.722596	array([[  2.4273434, -46.17221  ]], dtype=float32)
time = 64290	action = 0	current_phase = 1	next_phase = 0	reward = 0.720483	array([[  2.418003, -46.327446]], dtype=float32)
time = 64295	action = 0	current_phase = 1	next_phase = 0	reward = 0.714866	array([[  2.441702, -46.253803]], dtype=float32)
time = 64300	action = 0	current_phase = 1	next_phase = 0	reward = 0.719484	array([[  2.439455, -45.88998 ]], dtype=float32)
time = 64305	action = 0	current_phase = 1	next_phase = 0	reward = 0.722020	array([[  2.4541397, -46.054604 ]], dtype=float32)
time = 64310	action = 0	current_phase = 1	next_phase = 0	reward = 0.724561	array([[  2.4000778, -46.328716 ]], dtype=float32)
time = 64315	action = 0	current_phase = 1	next_phase = 0	reward = 0.710623	array([[  2.3931465, -45.76001  ]], dtype=float32)
time = 64320	action = 0	current_phase = 1	next_phase = 0	reward = 0.714775	array([[  2.3856993, -45.746597 ]], dtype=float32)
time = 64325	action = 0	current_phase = 1	next_phase = 0	reward = 0.724342	array([[  2.4376583, -46.168137 ]], dtype=float32)
time = 64330	action = 0	current_phase = 1	next_phase = 0	reward = 0.715501	array([[  2.4571896, -45.999046 ]], dtype=float32)
time = 64335	action = 0	current_phase = 1	next_phase = 0	reward = 0.721603	array([[  2.4485455, -46.26676  ]], dtype=float32)
time = 64340	action = 0	current_phase = 1	next_phase = 0	reward = 0.727657	array([[  2.4458961, -46.243343 ]], dtype=float32)
time = 64345	action = 0	current_phase = 1	next_phase = 0	reward = 0.733448	array([[  2.4489002, -46.19628  ]], dtype=float32)
time = 64350	action = 0	current_phase = 1	next_phase = 0	reward = 0.719497	array([[  2.4072409, -45.827576 ]], dtype=float32)
time = 64355	action = 0	current_phase = 1	next_phase = 0	reward = 0.713494	array([[  2.45644, -46.08094]], dtype=float32)
time = 64360	action = 0	current_phase = 1	next_phase = 0	reward = 0.719578	array([[  2.426508, -46.25103 ]], dtype=float32)
time = 64365	action = 0	current_phase = 1	next_phase = 0	reward = 0.723584	array([[  2.4320164, -46.100624 ]], dtype=float32)
time = 64370	action = 0	current_phase = 1	next_phase = 0	reward = 0.720219	array([[  2.439539, -45.894226]], dtype=float32)
time = 64375	action = 0	current_phase = 1	next_phase = 0	reward = 0.713921	array([[  2.4317074, -46.291924 ]], dtype=float32)
time = 64380	action = 0	current_phase = 1	next_phase = 0	reward = 0.440452	array([[  2.423441, -46.326763]], dtype=float32)
time = 64385	action = 0	current_phase = 1	next_phase = 0	reward = 0.722477	array([[  2.4352036, -45.87565  ]], dtype=float32)
time = 64390	action = 0	current_phase = 1	next_phase = 0	reward = 0.445054	array([[  2.4644947, -46.122482 ]], dtype=float32)
time = 64395	action = 0	current_phase = 1	next_phase = 0	reward = 1.283875	array([[  2.4394264, -46.243267 ]], dtype=float32)
time = 64400	action = 0	current_phase = 1	next_phase = 0	reward = 0.718107	array([[  2.4433727, -46.143173 ]], dtype=float32)
time = 64405	action = 0	current_phase = 1	next_phase = 0	reward = 0.716458	array([[  2.3994312, -45.744717 ]], dtype=float32)
time = 64410	action = 0	current_phase = 1	next_phase = 0	reward = 0.721618	array([[  2.4744568, -46.09224  ]], dtype=float32)
time = 64415	action = 0	current_phase = 1	next_phase = 0	reward = 0.445274	array([[  2.441206, -45.93849 ]], dtype=float32)
time = 64420	action = 0	current_phase = 1	next_phase = 0	reward = 0.728042	array([[  2.44355 , -46.258396]], dtype=float32)
time = 64425	action = 0	current_phase = 1	next_phase = 0	reward = 1.006377	array([[  2.4454536, -46.275124 ]], dtype=float32)
time = 64430	action = 0	current_phase = 1	next_phase = 0	reward = 0.444187	array([[  2.4698296, -45.99961  ]], dtype=float32)
time = 64435	action = 0	current_phase = 1	next_phase = 0	reward = 1.003812	array([[  2.4448357, -45.892384 ]], dtype=float32)
time = 64440	action = 0	current_phase = 1	next_phase = 0	reward = 0.442056	array([[  2.4291801, -46.109123 ]], dtype=float32)
time = 64445	action = 0	current_phase = 1	next_phase = 0	reward = 0.730275	array([[  2.4682884, -46.1019   ]], dtype=float32)
time = 64450	action = 0	current_phase = 1	next_phase = 0	reward = 1.012950	array([[  2.461689, -46.19577 ]], dtype=float32)
time = 64455	action = 0	current_phase = 1	next_phase = 0	reward = 0.721848	array([[  2.4253693, -45.915985 ]], dtype=float32)
time = 64460	action = 0	current_phase = 1	next_phase = 0	reward = 0.716764	array([[  2.4334831, -45.937675 ]], dtype=float32)
time = 64465	action = 0	current_phase = 1	next_phase = 0	reward = 0.718362	array([[  2.4560661, -46.180004 ]], dtype=float32)
time = 64470	action = 0	current_phase = 1	next_phase = 0	reward = 0.441866	array([[  2.430378, -46.21945 ]], dtype=float32)
time = 64475	action = 0	current_phase = 1	next_phase = 0	reward = 1.003454	array([[  2.4441338, -46.035954 ]], dtype=float32)
time = 64480	action = 0	current_phase = 1	next_phase = 0	reward = 0.718569	array([[  2.4155016, -45.813248 ]], dtype=float32)
time = 64485	action = 0	current_phase = 1	next_phase = 0	reward = 0.439508	array([[  2.4585857, -46.05209  ]], dtype=float32)
time = 64490	action = 0	current_phase = 1	next_phase = 0	reward = 1.001128	array([[  2.441574, -46.249344]], dtype=float32)
time = 64495	action = 0	current_phase = 1	next_phase = 0	reward = 0.717402	array([[  2.4231071, -45.852436 ]], dtype=float32)
time = 64500	action = 0	current_phase = 1	next_phase = 0	reward = 0.165090	array([[  2.444273, -46.156986]], dtype=float32)
time = 64505	action = 0	current_phase = 1	next_phase = 0	reward = 1.288578	array([[  2.4379482, -46.008408 ]], dtype=float32)
time = 64510	action = 0	current_phase = 1	next_phase = 0	reward = 0.721872	array([[  2.4121246, -46.277878 ]], dtype=float32)
time = 64515	action = 0	current_phase = 1	next_phase = 0	reward = 0.718046	array([[  2.4455643, -45.90673  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 328.1865 - val_loss: 187.0786
Epoch 2/50
 - 4s - loss: 311.4818 - val_loss: 175.7230
Epoch 3/50
 - 4s - loss: 319.6500 - val_loss: 169.7925
Epoch 4/50
 - 4s - loss: 305.6327 - val_loss: 192.9353
Epoch 5/50
 - 4s - loss: 298.9993 - val_loss: 162.6039
Epoch 6/50
 - 4s - loss: 311.3724 - val_loss: 160.9771
Epoch 7/50
 - 4s - loss: 352.9837 - val_loss: 219.1308
Epoch 8/50
 - 4s - loss: 312.6643 - val_loss: 257.9799
Epoch 9/50
 - 4s - loss: 375.8466 - val_loss: 265.8838
Epoch 10/50
 - 4s - loss: 336.0913 - val_loss: 190.7299
Epoch 11/50
 - 4s - loss: 363.9762 - val_loss: 378.2719
Epoch 12/50
 - 4s - loss: 349.5035 - val_loss: 342.6785
Epoch 13/50
 - 4s - loss: 344.8854 - val_loss: 196.5993
Epoch 14/50
 - 4s - loss: 303.0368 - val_loss: 193.8506
Epoch 15/50
 - 4s - loss: 331.3505 - val_loss: 215.8273
Epoch 16/50
 - 4s - loss: 346.4508 - val_loss: 192.6589
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 64520	action = 0	current_phase = 1	next_phase = 0	reward = 0.721645	array([[  2.4818573, -46.438858 ]], dtype=float32)
time = 64525	action = 0	current_phase = 1	next_phase = 0	reward = 0.719934	array([[  2.4293327, -45.822495 ]], dtype=float32)
time = 64530	action = 0	current_phase = 1	next_phase = 0	reward = 0.443402	array([[  2.4905243, -46.41027  ]], dtype=float32)
time = 64535	action = 0	current_phase = 1	next_phase = 0	reward = 0.724868	array([[  2.520525, -46.272827]], dtype=float32)
time = 64540	action = 0	current_phase = 1	next_phase = 0	reward = 0.719309	array([[  2.471424, -45.95617 ]], dtype=float32)
time = 64545	action = 0	current_phase = 1	next_phase = 0	reward = 0.729112	array([[  2.518631, -46.20607 ]], dtype=float32)
time = 64550	action = 0	current_phase = 1	next_phase = 0	reward = 1.003901	array([[  2.502369, -46.095222]], dtype=float32)
time = 64555	action = 0	current_phase = 1	next_phase = 0	reward = 0.719522	array([[  2.5295162, -46.23437  ]], dtype=float32)
time = 64560	action = 0	current_phase = 1	next_phase = 0	reward = 0.716422	array([[  2.380581, -45.707634]], dtype=float32)
time = 64565	action = 0	current_phase = 1	next_phase = 0	reward = 0.717281	array([[  2.5366154, -46.33056  ]], dtype=float32)
time = 64570	action = 0	current_phase = 1	next_phase = 0	reward = 0.717602	array([[  2.4944572, -46.14936  ]], dtype=float32)
time = 64575	action = 0	current_phase = 1	next_phase = 0	reward = 0.722085	array([[  2.5208569, -46.238308 ]], dtype=float32)
time = 64580	action = 0	current_phase = 1	next_phase = 0	reward = 0.725426	array([[  2.524065, -46.34764 ]], dtype=float32)
time = 64585	action = 0	current_phase = 1	next_phase = 0	reward = 0.708107	array([[  2.4906864, -46.3777   ]], dtype=float32)
time = 64590	action = 0	current_phase = 1	next_phase = 0	reward = 0.718933	array([[  2.4538097, -45.90238  ]], dtype=float32)
time = 64595	action = 0	current_phase = 1	next_phase = 0	reward = 0.437525	array([[  2.4898815, -46.447968 ]], dtype=float32)
time = 64600	action = 0	current_phase = 1	next_phase = 0	reward = 0.726281	array([[  2.4495296, -45.91468  ]], dtype=float32)
time = 64605	action = 0	current_phase = 1	next_phase = 0	reward = 0.993913	array([[  2.379671, -45.695915]], dtype=float32)
time = 64610	action = 0	current_phase = 1	next_phase = 0	reward = 0.715327	array([[  2.5109959, -46.27134  ]], dtype=float32)
time = 64615	action = 0	current_phase = 1	next_phase = 0	reward = 0.717088	array([[  2.49341, -46.06356]], dtype=float32)
time = 64620	action = 0	current_phase = 1	next_phase = 0	reward = 0.725797	array([[  2.5198154, -46.32448  ]], dtype=float32)
time = 64625	action = 0	current_phase = 1	next_phase = 0	reward = 0.724228	array([[  2.4045486, -45.772163 ]], dtype=float32)
time = 64630	action = 0	current_phase = 1	next_phase = 0	reward = 0.711028	array([[  2.422346, -45.832657]], dtype=float32)
time = 64635	action = 0	current_phase = 1	next_phase = 0	reward = 0.718684	array([[  2.495266, -46.107285]], dtype=float32)
time = 64640	action = 0	current_phase = 1	next_phase = 0	reward = 0.716029	array([[  2.5205917, -46.209984 ]], dtype=float32)
time = 64645	action = 0	current_phase = 1	next_phase = 0	reward = 0.439952	array([[  2.3680801, -45.729607 ]], dtype=float32)
time = 64650	action = 0	current_phase = 1	next_phase = 0	reward = 1.001915	array([[  2.3749428, -45.707123 ]], dtype=float32)
time = 64655	action = 0	current_phase = 1	next_phase = 0	reward = 0.715748	array([[  2.430479, -45.846638]], dtype=float32)
time = 64660	action = 0	current_phase = 1	next_phase = 0	reward = 0.730944	array([[  2.519102, -46.160824]], dtype=float32)
time = 64665	action = 0	current_phase = 1	next_phase = 0	reward = 0.726301	array([[  2.4835606, -46.00705  ]], dtype=float32)
time = 64670	action = 0	current_phase = 1	next_phase = 0	reward = 0.722824	array([[  2.525055, -46.303177]], dtype=float32)
time = 64675	action = 0	current_phase = 1	next_phase = 0	reward = 0.709253	array([[  2.4734955, -46.367393 ]], dtype=float32)
time = 64680	action = 0	current_phase = 1	next_phase = 0	reward = 0.715196	array([[  2.4020023, -45.766113 ]], dtype=float32)
time = 64685	action = 0	current_phase = 1	next_phase = 0	reward = 0.719441	array([[  2.4796276, -45.992004 ]], dtype=float32)
time = 64690	action = 0	current_phase = 1	next_phase = 0	reward = 0.717536	array([[  2.4049797, -45.761944 ]], dtype=float32)
time = 64695	action = 0	current_phase = 1	next_phase = 0	reward = 0.722661	array([[  2.4252815, -45.926407 ]], dtype=float32)
time = 64700	action = 0	current_phase = 1	next_phase = 0	reward = 0.715809	array([[  2.510147, -46.263588]], dtype=float32)
time = 64705	action = 0	current_phase = 1	next_phase = 0	reward = 0.718995	array([[  2.5341835, -46.22972  ]], dtype=float32)
time = 64710	action = 0	current_phase = 1	next_phase = 0	reward = 0.449111	array([[  2.4304829, -45.88521  ]], dtype=float32)
time = 64715	action = 0	current_phase = 1	next_phase = 0	reward = 1.008856	array([[  2.5036297, -46.08772  ]], dtype=float32)
time = 64720	action = 0	current_phase = 1	next_phase = 0	reward = 0.713983	array([[  2.527855, -46.202858]], dtype=float32)
time = 64725	action = 0	current_phase = 1	next_phase = 0	reward = 0.441112	array([[  2.5082474, -46.380924 ]], dtype=float32)
time = 64730	action = 0	current_phase = 1	next_phase = 0	reward = 1.001296	array([[  2.4732418, -45.95165  ]], dtype=float32)
time = 64735	action = 0	current_phase = 1	next_phase = 0	reward = 0.726240	array([[  2.5177326, -46.259377 ]], dtype=float32)
time = 64740	action = 0	current_phase = 1	next_phase = 0	reward = 0.719966	array([[  2.442255, -45.876167]], dtype=float32)
time = 64745	action = 0	current_phase = 1	next_phase = 0	reward = 0.721727	array([[  2.5102863, -46.245182 ]], dtype=float32)
time = 64750	action = 0	current_phase = 1	next_phase = 0	reward = 0.445518	array([[  2.4988327, -46.342155 ]], dtype=float32)
time = 64755	action = 0	current_phase = 1	next_phase = 0	reward = 1.011822	array([[  2.5225315, -46.22622  ]], dtype=float32)
time = 64760	action = 0	current_phase = 1	next_phase = 0	reward = 0.728997	array([[  2.514799, -46.305153]], dtype=float32)
time = 64765	action = 0	current_phase = 1	next_phase = 0	reward = 0.725108	array([[  2.5290184, -46.26372  ]], dtype=float32)
time = 64770	action = 0	current_phase = 1	next_phase = 0	reward = 0.714227	array([[  2.4915657, -46.028683 ]], dtype=float32)
time = 64775	action = 0	current_phase = 1	next_phase = 0	reward = 0.721023	array([[  2.4423733, -45.861588 ]], dtype=float32)
time = 64780	action = 0	current_phase = 1	next_phase = 0	reward = 0.727195	array([[  2.5118828, -46.097603 ]], dtype=float32)
time = 64785	action = 0	current_phase = 1	next_phase = 0	reward = 0.442731	array([[  2.51758, -46.28689]], dtype=float32)
time = 64790	action = 0	current_phase = 1	next_phase = 0	reward = 0.994991	array([[  2.3853703, -45.720276 ]], dtype=float32)
time = 64795	action = 0	current_phase = 1	next_phase = 0	reward = 0.718102	array([[  2.512041, -46.151196]], dtype=float32)
time = 64800	action = 0	current_phase = 1	next_phase = 0	reward = 0.718716	array([[  2.4914265, -46.165844 ]], dtype=float32)
time = 64805	action = 0	current_phase = 1	next_phase = 0	reward = 0.722181	array([[  2.3796158, -45.71679  ]], dtype=float32)
time = 64810	action = 0	current_phase = 1	next_phase = 0	reward = 0.724227	array([[  2.5206337, -46.22193  ]], dtype=float32)
time = 64815	action = 0	current_phase = 1	next_phase = 0	reward = 0.715451	array([[  2.4620361, -45.9111   ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 413.4245 - val_loss: 4568.9806
Epoch 2/50
 - 4s - loss: 332.3059 - val_loss: 4678.8967
Epoch 3/50
 - 4s - loss: 349.2245 - val_loss: 4585.8211
Epoch 4/50
 - 4s - loss: 351.2286 - val_loss: 4700.4743
Epoch 5/50
 - 4s - loss: 340.7568 - val_loss: 4758.2440
Epoch 6/50
 - 4s - loss: 326.0302 - val_loss: 4581.5127
Epoch 7/50
 - 4s - loss: 351.7739 - val_loss: 4594.4063
Epoch 8/50
 - 4s - loss: 327.2172 - val_loss: 4573.1521
Epoch 9/50
 - 4s - loss: 363.3063 - val_loss: 4675.4919
Epoch 10/50
 - 4s - loss: 391.2904 - val_loss: 4595.7269
Epoch 11/50
 - 4s - loss: 351.1567 - val_loss: 4575.0131
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 64820	action = 0	current_phase = 1	next_phase = 0	reward = 0.714020	array([[  2.564497, -46.150593]], dtype=float32)
time = 64825	action = 0	current_phase = 1	next_phase = 0	reward = 0.724046	array([[  2.5694542, -46.16731  ]], dtype=float32)
time = 64830	action = 0	current_phase = 1	next_phase = 0	reward = 0.730451	array([[  2.649725, -46.49333 ]], dtype=float32)
time = 64835	action = 0	current_phase = 1	next_phase = 0	reward = 0.722285	array([[  2.544733, -46.09235 ]], dtype=float32)
time = 64840	action = 0	current_phase = 1	next_phase = 0	reward = 0.724224	array([[  2.5916061, -46.254974 ]], dtype=float32)
time = 64845	action = 0	current_phase = 1	next_phase = 0	reward = 0.713708	array([[  2.5908165, -46.402695 ]], dtype=float32)
time = 64850	action = 0	current_phase = 1	next_phase = 0	reward = 0.439025	array([[  2.5750103, -46.125008 ]], dtype=float32)
time = 64855	action = 0	current_phase = 1	next_phase = 0	reward = 1.005376	array([[  2.5888977, -46.24816  ]], dtype=float32)
time = 64860	action = 0	current_phase = 1	next_phase = 0	reward = 0.724015	array([[  2.5910645, -46.220802 ]], dtype=float32)
time = 64865	action = 0	current_phase = 1	next_phase = 0	reward = 0.719419	array([[  2.6416416, -46.545002 ]], dtype=float32)
time = 64870	action = 0	current_phase = 1	next_phase = 0	reward = 0.720860	array([[  2.6041317, -46.246628 ]], dtype=float32)
time = 64875	action = 0	current_phase = 1	next_phase = 0	reward = 0.445754	array([[  2.5357265, -46.02607  ]], dtype=float32)
time = 64880	action = 0	current_phase = 1	next_phase = 0	reward = 1.002667	array([[  2.6291637, -46.33483  ]], dtype=float32)
time = 64885	action = 0	current_phase = 1	next_phase = 0	reward = 0.729043	array([[  2.6380444, -46.58773  ]], dtype=float32)
time = 64890	action = 0	current_phase = 1	next_phase = 0	reward = 0.717316	array([[  2.5136986, -46.012215 ]], dtype=float32)
time = 64895	action = 0	current_phase = 1	next_phase = 0	reward = 0.716643	array([[  2.6542091, -46.650276 ]], dtype=float32)
time = 64900	action = 0	current_phase = 1	next_phase = 0	reward = 0.719710	array([[  2.6087818, -46.25644  ]], dtype=float32)
time = 64905	action = 0	current_phase = 1	next_phase = 0	reward = 0.725027	array([[  2.5650578, -46.269676 ]], dtype=float32)
time = 64910	action = 0	current_phase = 1	next_phase = 0	reward = 0.716423	array([[  2.621481, -46.408844]], dtype=float32)
time = 64915	action = 0	current_phase = 1	next_phase = 0	reward = 0.719857	array([[  2.5359821, -46.03403  ]], dtype=float32)
time = 64920	action = 0	current_phase = 1	next_phase = 0	reward = 0.721938	array([[  2.594593, -46.20671 ]], dtype=float32)
time = 64925	action = 0	current_phase = 1	next_phase = 0	reward = 0.720878	array([[  2.6445236, -46.42305  ]], dtype=float32)
time = 64930	action = 0	current_phase = 1	next_phase = 0	reward = 0.724862	array([[  2.5928516, -46.203403 ]], dtype=float32)
time = 64935	action = 0	current_phase = 1	next_phase = 0	reward = 0.720334	array([[  2.5792255, -46.252995 ]], dtype=float32)
time = 64940	action = 0	current_phase = 1	next_phase = 0	reward = 0.443023	array([[  2.648941, -46.602196]], dtype=float32)
time = 64945	action = 0	current_phase = 1	next_phase = 0	reward = 1.005132	array([[  2.639101, -46.511486]], dtype=float32)
time = 64950	action = 0	current_phase = 1	next_phase = 0	reward = 0.724768	array([[  2.5771618, -46.171814 ]], dtype=float32)
time = 64955	action = 0	current_phase = 1	next_phase = 0	reward = 0.716372	array([[  2.590807, -46.203793]], dtype=float32)
time = 64960	action = 0	current_phase = 1	next_phase = 0	reward = 0.723345	array([[  2.6185608, -46.34748  ]], dtype=float32)
time = 64965	action = 0	current_phase = 1	next_phase = 0	reward = 0.446026	array([[  2.6284828, -46.68242  ]], dtype=float32)
time = 64970	action = 0	current_phase = 1	next_phase = 0	reward = 1.000960	array([[  2.659748, -46.578537]], dtype=float32)
time = 64975	action = 0	current_phase = 1	next_phase = 0	reward = 0.714553	array([[  2.4915237, -45.92386  ]], dtype=float32)
time = 64980	action = 0	current_phase = 1	next_phase = 0	reward = 0.719465	array([[  2.6360378, -46.398163 ]], dtype=float32)
time = 64985	action = 0	current_phase = 1	next_phase = 0	reward = 0.448363	array([[  2.623642, -46.415607]], dtype=float32)
time = 64990	action = 0	current_phase = 1	next_phase = 0	reward = 0.722948	array([[  2.5753174, -46.14823  ]], dtype=float32)
time = 64995	action = 0	current_phase = 1	next_phase = 0	reward = 0.722495	array([[  2.6293697, -46.415855 ]], dtype=float32)
time = 65000	action = 0	current_phase = 1	next_phase = 0	reward = 0.729790	array([[  2.6470814, -46.48845  ]], dtype=float32)
time = 65005	action = 0	current_phase = 1	next_phase = 0	reward = 1.000060	array([[  2.5847645, -46.226265 ]], dtype=float32)
time = 65010	action = 0	current_phase = 1	next_phase = 0	reward = 0.715471	array([[  2.6064014, -46.43604  ]], dtype=float32)
time = 65015	action = 0	current_phase = 1	next_phase = 0	reward = 0.717791	array([[  2.6003227, -46.262856 ]], dtype=float32)
time = 65020	action = 0	current_phase = 1	next_phase = 0	reward = 0.723237	array([[  2.5299873, -46.099663 ]], dtype=float32)
time = 65025	action = 0	current_phase = 1	next_phase = 0	reward = 0.725443	array([[  2.5471916, -46.108356 ]], dtype=float32)
time = 65030	action = 0	current_phase = 1	next_phase = 0	reward = 0.719812	array([[  2.4753723, -45.909325 ]], dtype=float32)
time = 65035	action = 0	current_phase = 1	next_phase = 0	reward = 0.720410	array([[  2.6393185, -46.436302 ]], dtype=float32)
time = 65040	action = 0	current_phase = 1	next_phase = 0	reward = 0.719991	array([[  2.5877762, -46.206825 ]], dtype=float32)
time = 65045	action = 0	current_phase = 1	next_phase = 0	reward = 0.715786	array([[  2.6201935, -46.455902 ]], dtype=float32)
time = 65050	action = 0	current_phase = 1	next_phase = 0	reward = 0.717915	array([[  2.6424465, -46.566345 ]], dtype=float32)
time = 65055	action = 0	current_phase = 1	next_phase = 0	reward = 0.720669	array([[  2.640417, -46.536747]], dtype=float32)
time = 65060	action = 0	current_phase = 1	next_phase = 0	reward = 0.719281	array([[  2.574623, -46.14633 ]], dtype=float32)
time = 65065	action = 0	current_phase = 1	next_phase = 0	reward = 0.442948	array([[  2.5927143, -46.704224 ]], dtype=float32)
time = 65070	action = 0	current_phase = 1	next_phase = 0	reward = 0.992345	array([[  2.53792 , -46.046974]], dtype=float32)
time = 65075	action = 0	current_phase = 1	next_phase = 0	reward = 0.714540	array([[  2.6128902, -46.380413 ]], dtype=float32)
time = 65080	action = 0	current_phase = 1	next_phase = 0	reward = 0.437616	array([[  2.4741287, -45.911972 ]], dtype=float32)
time = 65085	action = 0	current_phase = 1	next_phase = 0	reward = 1.006767	array([[  2.4611893, -45.87735  ]], dtype=float32)
time = 65090	action = 0	current_phase = 1	next_phase = 0	reward = 0.715632	array([[  2.6377106, -46.43889  ]], dtype=float32)
time = 65095	action = 0	current_phase = 1	next_phase = 0	reward = 0.715846	array([[  2.6374016, -46.64147  ]], dtype=float32)
time = 65100	action = 0	current_phase = 1	next_phase = 0	reward = 0.161107	array([[  2.6136112, -46.389236 ]], dtype=float32)
time = 65105	action = 0	current_phase = 1	next_phase = 0	reward = 1.279771	array([[  2.6514816, -46.46318  ]], dtype=float32)
time = 65110	action = 0	current_phase = 1	next_phase = 0	reward = 0.439499	array([[  2.6256046, -46.474125 ]], dtype=float32)
time = 65115	action = 0	current_phase = 1	next_phase = 0	reward = 1.004241	array([[  2.5490875, -46.083088 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2160.3416 - val_loss: 280.9799
Epoch 2/50
 - 4s - loss: 2156.7744 - val_loss: 590.6683
Epoch 3/50
 - 4s - loss: 2166.3720 - val_loss: 252.8008
Epoch 4/50
 - 4s - loss: 2137.5225 - val_loss: 247.9481
Epoch 5/50
 - 4s - loss: 2132.1731 - val_loss: 240.3492
Epoch 6/50
 - 4s - loss: 2129.9101 - val_loss: 242.7367
Epoch 7/50
 - 4s - loss: 2113.8331 - val_loss: 354.4351
Epoch 8/50
 - 4s - loss: 2126.1380 - val_loss: 241.8250
Epoch 9/50
 - 4s - loss: 2126.6259 - val_loss: 261.5424
Epoch 10/50
 - 4s - loss: 2146.0923 - val_loss: 234.9929
Epoch 11/50
 - 4s - loss: 2117.4589 - val_loss: 308.0730
Epoch 12/50
 - 4s - loss: 2122.5685 - val_loss: 227.2627
Epoch 13/50
 - 4s - loss: 2116.3153 - val_loss: 236.2014
Epoch 14/50
 - 4s - loss: 2148.3121 - val_loss: 326.2399
Epoch 15/50
 - 4s - loss: 2138.3919 - val_loss: 309.6934
Epoch 16/50
 - 4s - loss: 2126.1027 - val_loss: 255.7272
Epoch 17/50
 - 4s - loss: 2111.7158 - val_loss: 282.2888
Epoch 18/50
 - 4s - loss: 2101.6644 - val_loss: 238.4278
Epoch 19/50
 - 4s - loss: 2109.1849 - val_loss: 356.7175
Epoch 20/50
 - 4s - loss: 2122.3626 - val_loss: 239.8917
Epoch 21/50
 - 4s - loss: 2128.1970 - val_loss: 248.9901
Epoch 22/50
 - 4s - loss: 2125.2199 - val_loss: 226.6227
Epoch 23/50
 - 4s - loss: 2103.2367 - val_loss: 340.0919
Epoch 24/50
 - 4s - loss: 2114.6214 - val_loss: 269.8531
Epoch 25/50
 - 4s - loss: 2110.4571 - val_loss: 250.5248
Epoch 26/50
 - 4s - loss: 2104.3565 - val_loss: 270.1248
Epoch 27/50
 - 4s - loss: 2127.9803 - val_loss: 246.8685
Epoch 28/50
 - 4s - loss: 2098.4305 - val_loss: 261.1584
Epoch 29/50
 - 4s - loss: 2101.9995 - val_loss: 253.5861
Epoch 30/50
 - 4s - loss: 2136.2816 - val_loss: 313.8595
Epoch 31/50
 - 4s - loss: 2128.5931 - val_loss: 267.1569
Epoch 32/50
 - 4s - loss: 2125.0574 - val_loss: 259.5771
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 65120	action = 0	current_phase = 1	next_phase = 0	reward = 0.728024	array([[  2.600132, -46.47087 ]], dtype=float32)
time = 65125	action = 0	current_phase = 1	next_phase = 0	reward = 0.450053	array([[  2.4968967, -46.203346 ]], dtype=float32)
time = 65130	action = 0	current_phase = 1	next_phase = 0	reward = 0.994623	array([[  2.5825882, -46.42204  ]], dtype=float32)
time = 65135	action = 0	current_phase = 1	next_phase = 0	reward = 0.713684	array([[  2.4790268, -46.172127 ]], dtype=float32)
time = 65140	action = 0	current_phase = 1	next_phase = 0	reward = 0.437052	array([[  2.710247, -46.83059 ]], dtype=float32)
time = 65145	action = 0	current_phase = 1	next_phase = 0	reward = 0.714238	array([[  2.6429958, -46.618484 ]], dtype=float32)
time = 65150	action = 0	current_phase = 1	next_phase = 0	reward = 1.000022	array([[  2.4810677, -46.168793 ]], dtype=float32)
time = 65155	action = 0	current_phase = 1	next_phase = 0	reward = 0.725941	array([[  2.6878834, -46.880722 ]], dtype=float32)
time = 65160	action = 0	current_phase = 1	next_phase = 0	reward = 0.718376	array([[  2.6069202, -46.4709   ]], dtype=float32)
time = 65165	action = 0	current_phase = 1	next_phase = 0	reward = 0.443886	array([[  2.7019405, -46.887947 ]], dtype=float32)
time = 65170	action = 0	current_phase = 1	next_phase = 0	reward = 1.009223	array([[  2.5947418, -46.45534  ]], dtype=float32)
time = 65175	action = 0	current_phase = 1	next_phase = 0	reward = 0.713920	array([[  2.677225, -46.698265]], dtype=float32)
time = 65180	action = 0	current_phase = 1	next_phase = 0	reward = 0.717536	array([[  2.6562462, -46.622246 ]], dtype=float32)
time = 65185	action = 0	current_phase = 1	next_phase = 0	reward = 0.451281	array([[  2.5800152, -46.401817 ]], dtype=float32)
time = 65190	action = 0	current_phase = 1	next_phase = 0	reward = 0.732672	array([[  2.6169033, -46.51438  ]], dtype=float32)
time = 65195	action = 0	current_phase = 1	next_phase = 0	reward = 1.006585	array([[  2.5988903, -46.45237  ]], dtype=float32)
time = 65200	action = 0	current_phase = 1	next_phase = 0	reward = 0.724294	array([[  2.5245228, -46.261967 ]], dtype=float32)
time = 65205	action = 0	current_phase = 1	next_phase = 0	reward = 0.719386	array([[  2.6466827, -46.65336  ]], dtype=float32)
time = 65210	action = 0	current_phase = 1	next_phase = 0	reward = 0.723082	array([[  2.538021, -46.2884  ]], dtype=float32)
time = 65215	action = 0	current_phase = 1	next_phase = 0	reward = 0.723367	array([[  2.6735497, -46.73929  ]], dtype=float32)
time = 65220	action = 0	current_phase = 1	next_phase = 0	reward = 0.723478	array([[  2.5819473, -46.377876 ]], dtype=float32)
time = 65225	action = 0	current_phase = 1	next_phase = 0	reward = 0.440227	array([[  2.5965004, -46.46773  ]], dtype=float32)
time = 65230	action = 0	current_phase = 1	next_phase = 0	reward = 1.002006	array([[  2.6510868, -46.596863 ]], dtype=float32)
time = 65235	action = 0	current_phase = 1	next_phase = 0	reward = 0.441728	array([[  2.6596088, -46.66362  ]], dtype=float32)
time = 65240	action = 0	current_phase = 1	next_phase = 0	reward = 1.004112	array([[  2.643055, -46.583   ]], dtype=float32)
time = 65245	action = 0	current_phase = 1	next_phase = 0	reward = 0.720168	array([[  2.6271095, -46.52764  ]], dtype=float32)
time = 65250	action = 0	current_phase = 1	next_phase = 0	reward = 0.446300	array([[  2.593773, -46.433533]], dtype=float32)
time = 65255	action = 0	current_phase = 1	next_phase = 0	reward = 1.009465	array([[  2.664938, -46.65317 ]], dtype=float32)
time = 65260	action = 0	current_phase = 1	next_phase = 0	reward = 0.722386	array([[  2.6535091, -46.64603  ]], dtype=float32)
time = 65265	action = 0	current_phase = 1	next_phase = 0	reward = 0.720413	array([[  2.6118412, -46.505013 ]], dtype=float32)
time = 65270	action = 0	current_phase = 1	next_phase = 0	reward = 0.710397	array([[  2.4981594, -46.19059  ]], dtype=float32)
time = 65275	action = 0	current_phase = 1	next_phase = 0	reward = 0.726530	array([[  2.6732197, -46.71162  ]], dtype=float32)
time = 65280	action = 0	current_phase = 1	next_phase = 0	reward = 0.721485	array([[  2.6160698, -46.50643  ]], dtype=float32)
time = 65285	action = 0	current_phase = 1	next_phase = 0	reward = 0.442927	array([[  2.5706348, -46.391487 ]], dtype=float32)
time = 65290	action = 0	current_phase = 1	next_phase = 0	reward = 1.004079	array([[  2.4605064, -46.137405 ]], dtype=float32)
time = 65295	action = 0	current_phase = 1	next_phase = 0	reward = 0.715023	array([[  2.6988106, -46.913845 ]], dtype=float32)
time = 65300	action = 0	current_phase = 1	next_phase = 0	reward = 0.712369	array([[  2.4362411, -46.065113 ]], dtype=float32)
time = 65305	action = 0	current_phase = 1	next_phase = 0	reward = 0.712644	array([[  2.5887718, -46.4426   ]], dtype=float32)
time = 65310	action = 0	current_phase = 1	next_phase = 0	reward = 0.446512	array([[  2.6579876, -46.684357 ]], dtype=float32)
time = 65315	action = 0	current_phase = 1	next_phase = 0	reward = 1.007721	array([[  2.4992046, -46.210487 ]], dtype=float32)
time = 65320	action = 0	current_phase = 1	next_phase = 0	reward = 0.437476	array([[  2.671959, -46.72526 ]], dtype=float32)
time = 65325	action = 0	current_phase = 1	next_phase = 0	reward = 1.003408	array([[  2.6056213, -46.530136 ]], dtype=float32)
time = 65330	action = 0	current_phase = 1	next_phase = 0	reward = 0.726632	array([[  2.631998, -46.617836]], dtype=float32)
time = 65335	action = 0	current_phase = 1	next_phase = 0	reward = 0.721133	array([[  2.522337, -46.25421 ]], dtype=float32)
time = 65340	action = 0	current_phase = 1	next_phase = 0	reward = 0.720507	array([[  2.6614494, -46.684845 ]], dtype=float32)
time = 65345	action = 0	current_phase = 1	next_phase = 0	reward = 0.446318	array([[  2.4845333, -46.187317 ]], dtype=float32)
time = 65350	action = 0	current_phase = 1	next_phase = 0	reward = 1.004280	array([[  2.6141262, -46.4928   ]], dtype=float32)
time = 65355	action = 0	current_phase = 1	next_phase = 0	reward = 0.719503	array([[  2.515585, -46.244816]], dtype=float32)
time = 65360	action = 0	current_phase = 1	next_phase = 0	reward = 0.716502	array([[  2.5917778, -46.421467 ]], dtype=float32)
time = 65365	action = 0	current_phase = 1	next_phase = 0	reward = 0.722531	array([[  2.603983, -46.490356]], dtype=float32)
time = 65370	action = 0	current_phase = 1	next_phase = 0	reward = 0.732654	array([[  2.6796722, -46.710083 ]], dtype=float32)
time = 65375	action = 0	current_phase = 1	next_phase = 0	reward = 0.720219	array([[  2.6147022, -46.444817 ]], dtype=float32)
time = 65380	action = 0	current_phase = 1	next_phase = 0	reward = 0.718349	array([[  2.5723095, -46.370743 ]], dtype=float32)
time = 65385	action = 0	current_phase = 1	next_phase = 0	reward = 0.706233	array([[  2.592432, -46.432762]], dtype=float32)
time = 65390	action = 0	current_phase = 1	next_phase = 0	reward = 0.719043	array([[  2.6341438, -46.55415  ]], dtype=float32)
time = 65395	action = 0	current_phase = 1	next_phase = 0	reward = 0.448270	array([[  2.6607418, -46.64775  ]], dtype=float32)
time = 65400	action = 0	current_phase = 1	next_phase = 0	reward = 0.998733	array([[  2.4479694, -46.093666 ]], dtype=float32)
time = 65405	action = 0	current_phase = 1	next_phase = 0	reward = 0.433097	array([[  2.6342869, -46.54587  ]], dtype=float32)
time = 65410	action = 0	current_phase = 1	next_phase = 0	reward = 0.989385	array([[  2.582203, -46.439972]], dtype=float32)
time = 65415	action = 0	current_phase = 1	next_phase = 0	reward = 0.164660	array([[  2.5229244, -46.32229  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2092.8624 - val_loss: 361.6895
Epoch 2/50
 - 4s - loss: 2068.6194 - val_loss: 300.4805
Epoch 3/50
 - 4s - loss: 2092.2427 - val_loss: 299.3667
Epoch 4/50
 - 4s - loss: 2089.3193 - val_loss: 318.8172
Epoch 5/50
 - 4s - loss: 2073.2194 - val_loss: 332.5418
Epoch 6/50
 - 4s - loss: 2109.5424 - val_loss: 316.1960
Epoch 7/50
 - 4s - loss: 2078.4969 - val_loss: 312.0981
Epoch 8/50
 - 4s - loss: 2072.0510 - val_loss: 377.7274
Epoch 9/50
 - 4s - loss: 2086.8412 - val_loss: 296.6917
Epoch 10/50
 - 4s - loss: 2067.8188 - val_loss: 364.3282
Epoch 11/50
 - 4s - loss: 2096.5467 - val_loss: 318.2055
Epoch 12/50
 - 4s - loss: 2089.7434 - val_loss: 294.5021
Epoch 13/50
 - 4s - loss: 2100.1639 - val_loss: 305.0019
Epoch 14/50
 - 4s - loss: 2067.7267 - val_loss: 344.5600
Epoch 15/50
 - 4s - loss: 2097.0261 - val_loss: 384.7176
Epoch 16/50
 - 4s - loss: 2103.3835 - val_loss: 327.4923
Epoch 17/50
 - 4s - loss: 2073.0349 - val_loss: 275.2780
Epoch 18/50
 - 4s - loss: 2090.1080 - val_loss: 390.0937
Epoch 19/50
 - 4s - loss: 2083.0632 - val_loss: 288.6393
Epoch 20/50
 - 4s - loss: 2067.8256 - val_loss: 272.6876
Epoch 21/50
 - 4s - loss: 2065.1722 - val_loss: 304.4985
Epoch 22/50
 - 4s - loss: 2058.2613 - val_loss: 285.6605
Epoch 23/50
 - 4s - loss: 2057.3369 - val_loss: 289.0723
Epoch 24/50
 - 4s - loss: 2061.1813 - val_loss: 301.6189
Epoch 25/50
 - 4s - loss: 2062.5049 - val_loss: 305.3133
Epoch 26/50
 - 4s - loss: 2051.4365 - val_loss: 313.2067
Epoch 27/50
 - 4s - loss: 2055.0595 - val_loss: 289.5019
Epoch 28/50
 - 4s - loss: 2068.8378 - val_loss: 340.7407
Epoch 29/50
 - 4s - loss: 2049.0250 - val_loss: 441.4561
Epoch 30/50
 - 4s - loss: 2045.5146 - val_loss: 344.1686
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 65420	action = 0	current_phase = 1	next_phase = 0	reward = 1.008792	array([[  2.3843966, -46.14334  ]], dtype=float32)
time = 65425	action = 0	current_phase = 1	next_phase = 0	reward = 1.000898	array([[  2.4364119, -46.325634 ]], dtype=float32)
time = 65430	action = 0	current_phase = 1	next_phase = 0	reward = 0.719978	array([[  2.4570246, -46.66668  ]], dtype=float32)
time = 65435	action = 0	current_phase = 1	next_phase = 0	reward = 0.725840	array([[  2.3893557, -46.165497 ]], dtype=float32)
time = 65440	action = 0	current_phase = 1	next_phase = 0	reward = 0.716445	array([[  2.3263483, -46.1342   ]], dtype=float32)
time = 65445	action = 0	current_phase = 1	next_phase = 0	reward = 0.717095	array([[  2.4214373, -46.266758 ]], dtype=float32)
time = 65450	action = 0	current_phase = 1	next_phase = 0	reward = 0.451399	array([[  2.5015326, -46.597572 ]], dtype=float32)
time = 65455	action = 0	current_phase = 1	next_phase = 0	reward = 1.007618	array([[  2.4397593, -46.348297 ]], dtype=float32)
time = 65460	action = 0	current_phase = 1	next_phase = 0	reward = 0.735698	array([[  2.4687872, -46.417183 ]], dtype=float32)
time = 65465	action = 0	current_phase = 1	next_phase = 0	reward = 0.722955	array([[  2.4620028, -46.525223 ]], dtype=float32)
time = 65470	action = 0	current_phase = 1	next_phase = 0	reward = 0.715838	array([[  2.4761686, -46.49962  ]], dtype=float32)
time = 65475	action = 0	current_phase = 1	next_phase = 0	reward = 0.723573	array([[  2.4589357, -46.523506 ]], dtype=float32)
time = 65480	action = 0	current_phase = 1	next_phase = 0	reward = 0.715787	array([[  2.5034342, -46.61135  ]], dtype=float32)
time = 65485	action = 0	current_phase = 1	next_phase = 0	reward = 0.714528	array([[  2.4736223, -46.51677  ]], dtype=float32)
time = 65490	action = 0	current_phase = 1	next_phase = 0	reward = 0.440704	array([[  2.4808226, -46.58673  ]], dtype=float32)
time = 65495	action = 0	current_phase = 1	next_phase = 0	reward = 1.001106	array([[  2.491416, -46.632996]], dtype=float32)
time = 65500	action = 0	current_phase = 1	next_phase = 0	reward = 0.446177	array([[  2.4580088, -46.47923  ]], dtype=float32)
time = 65505	action = 0	current_phase = 1	next_phase = 0	reward = 1.009182	array([[  2.4901114, -46.70632  ]], dtype=float32)
time = 65510	action = 0	current_phase = 1	next_phase = 0	reward = 0.726807	array([[  2.4335756, -46.55889  ]], dtype=float32)
time = 65515	action = 0	current_phase = 1	next_phase = 0	reward = 0.724362	array([[  2.4419928, -46.321762 ]], dtype=float32)
time = 65520	action = 0	current_phase = 1	next_phase = 0	reward = 0.713681	array([[  2.4892912, -46.649673 ]], dtype=float32)
time = 65525	action = 0	current_phase = 1	next_phase = 0	reward = 0.716092	array([[  2.4652433, -46.42727  ]], dtype=float32)
time = 65530	action = 0	current_phase = 1	next_phase = 0	reward = 0.718013	array([[  2.5047045, -46.604042 ]], dtype=float32)
time = 65535	action = 0	current_phase = 1	next_phase = 0	reward = 0.721933	array([[  2.4843397, -46.55767  ]], dtype=float32)
time = 65540	action = 0	current_phase = 1	next_phase = 0	reward = 0.731629	array([[  2.4871073, -46.529762 ]], dtype=float32)
time = 65545	action = 0	current_phase = 1	next_phase = 0	reward = 0.720329	array([[  2.444522, -46.329662]], dtype=float32)
time = 65550	action = 0	current_phase = 1	next_phase = 0	reward = 0.721284	array([[  2.469489, -46.827705]], dtype=float32)
time = 65555	action = 0	current_phase = 1	next_phase = 0	reward = 0.717440	array([[  2.4359446, -46.5259   ]], dtype=float32)
time = 65560	action = 0	current_phase = 1	next_phase = 0	reward = 0.722494	array([[  2.4332952, -46.302723 ]], dtype=float32)
time = 65565	action = 0	current_phase = 1	next_phase = 0	reward = 0.722560	array([[  2.4800615, -46.682877 ]], dtype=float32)
time = 65570	action = 0	current_phase = 1	next_phase = 0	reward = 0.716489	array([[  2.508645, -46.69635 ]], dtype=float32)
time = 65575	action = 0	current_phase = 1	next_phase = 0	reward = 0.716467	array([[  2.4812098, -46.59874  ]], dtype=float32)
time = 65580	action = 0	current_phase = 1	next_phase = 0	reward = 0.722399	array([[  2.4360151, -46.327507 ]], dtype=float32)
time = 65585	action = 0	current_phase = 1	next_phase = 0	reward = 0.714596	array([[  2.414279, -46.316643]], dtype=float32)
time = 65590	action = 0	current_phase = 1	next_phase = 0	reward = 0.437626	array([[  2.4894075, -46.67442  ]], dtype=float32)
time = 65595	action = 0	current_phase = 1	next_phase = 0	reward = 0.724026	array([[  2.485196, -46.54734 ]], dtype=float32)
time = 65600	action = 0	current_phase = 1	next_phase = 0	reward = 1.006323	array([[  2.4814558, -46.50351  ]], dtype=float32)
time = 65605	action = 0	current_phase = 1	next_phase = 0	reward = 0.733872	array([[  2.4807558, -46.66587  ]], dtype=float32)
time = 65610	action = 0	current_phase = 1	next_phase = 0	reward = 0.724245	array([[  2.4502707, -46.377388 ]], dtype=float32)
time = 65615	action = 0	current_phase = 1	next_phase = 0	reward = 0.719355	array([[  2.4733877, -46.769794 ]], dtype=float32)
time = 65620	action = 0	current_phase = 1	next_phase = 0	reward = 0.710682	array([[  2.473794, -46.43176 ]], dtype=float32)
time = 65625	action = 0	current_phase = 1	next_phase = 0	reward = 0.715470	array([[  2.468978, -46.58889 ]], dtype=float32)
time = 65630	action = 0	current_phase = 1	next_phase = 0	reward = 0.170963	array([[  2.4934835, -46.51364  ]], dtype=float32)
time = 65635	action = 0	current_phase = 1	next_phase = 0	reward = 1.282691	array([[  2.4620333, -46.377895 ]], dtype=float32)
time = 65640	action = 0	current_phase = 1	next_phase = 0	reward = 0.722745	array([[  2.5078878, -46.60579  ]], dtype=float32)
time = 65645	action = 0	current_phase = 1	next_phase = 0	reward = 0.728710	array([[  2.4968977, -46.613895 ]], dtype=float32)
time = 65650	action = 0	current_phase = 1	next_phase = 0	reward = 0.719044	array([[  2.4154844, -46.34601  ]], dtype=float32)
time = 65655	action = 0	current_phase = 1	next_phase = 0	reward = 0.719867	array([[  2.466096, -46.756912]], dtype=float32)
time = 65660	action = 0	current_phase = 1	next_phase = 0	reward = 0.439862	array([[  2.461751, -46.76845 ]], dtype=float32)
time = 65665	action = 0	current_phase = 1	next_phase = 0	reward = 0.998016	array([[  2.4893694, -46.606766 ]], dtype=float32)
time = 65670	action = 0	current_phase = 1	next_phase = 0	reward = 0.720049	array([[  2.514554, -46.61181 ]], dtype=float32)
time = 65675	action = 0	current_phase = 1	next_phase = 0	reward = 0.439983	array([[  2.481656, -46.51069 ]], dtype=float32)
time = 65680	action = 0	current_phase = 1	next_phase = 0	reward = 1.007358	array([[  2.4729624, -46.488304 ]], dtype=float32)
time = 65685	action = 0	current_phase = 1	next_phase = 0	reward = 0.717807	array([[  2.4648333, -46.80159  ]], dtype=float32)
time = 65690	action = 0	current_phase = 1	next_phase = 0	reward = 0.437960	array([[  2.4754019, -46.460114 ]], dtype=float32)
time = 65695	action = 0	current_phase = 1	next_phase = 0	reward = 1.010629	array([[  2.4817 , -46.45242]], dtype=float32)
time = 65700	action = 0	current_phase = 1	next_phase = 0	reward = 0.718809	array([[  2.4726057, -46.490124 ]], dtype=float32)
time = 65705	action = 0	current_phase = 1	next_phase = 0	reward = 0.715188	array([[  2.4817133, -46.630775 ]], dtype=float32)
time = 65710	action = 0	current_phase = 1	next_phase = 0	reward = 0.439456	array([[  2.4505453, -46.359455 ]], dtype=float32)
time = 65715	action = 0	current_phase = 1	next_phase = 0	reward = 1.006040	array([[  2.472474, -46.46643 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2197.6037 - val_loss: 209.9244
Epoch 2/50
 - 4s - loss: 2206.5258 - val_loss: 288.5070
Epoch 3/50
 - 4s - loss: 2216.4051 - val_loss: 226.9546
Epoch 4/50
 - 4s - loss: 2186.8301 - val_loss: 256.1650
Epoch 5/50
 - 4s - loss: 2178.0696 - val_loss: 268.5682
Epoch 6/50
 - 4s - loss: 2209.6080 - val_loss: 285.1465
Epoch 7/50
 - 4s - loss: 2189.3822 - val_loss: 201.2600
Epoch 8/50
 - 4s - loss: 2197.2670 - val_loss: 227.6543
Epoch 9/50
 - 4s - loss: 2187.9877 - val_loss: 223.8062
Epoch 10/50
 - 4s - loss: 2201.9914 - val_loss: 252.9803
Epoch 11/50
 - 4s - loss: 2185.5111 - val_loss: 206.6039
Epoch 12/50
 - 4s - loss: 2157.6860 - val_loss: 256.5498
Epoch 13/50
 - 4s - loss: 2214.8956 - val_loss: 211.3195
Epoch 14/50
 - 4s - loss: 2160.8788 - val_loss: 231.1555
Epoch 15/50
 - 4s - loss: 2198.6826 - val_loss: 223.2253
Epoch 16/50
 - 4s - loss: 2173.2329 - val_loss: 205.4755
Epoch 17/50
 - 4s - loss: 2204.3868 - val_loss: 211.4987
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 65720	action = 0	current_phase = 1	next_phase = 0	reward = 0.718071	array([[  2.5430155, -46.50621  ]], dtype=float32)
time = 65725	action = 0	current_phase = 1	next_phase = 0	reward = 0.717710	array([[  2.5696516, -46.911034 ]], dtype=float32)
time = 65730	action = 0	current_phase = 1	next_phase = 0	reward = 0.723054	array([[  2.577218, -46.627728]], dtype=float32)
time = 65735	action = 0	current_phase = 1	next_phase = 0	reward = 0.719796	array([[  2.5425692, -46.858105 ]], dtype=float32)
time = 65740	action = 0	current_phase = 1	next_phase = 0	reward = 0.718541	array([[  2.4439383, -46.442146 ]], dtype=float32)
time = 65745	action = 0	current_phase = 1	next_phase = 0	reward = 0.713400	array([[  2.5606375, -47.01097  ]], dtype=float32)
time = 65750	action = 0	current_phase = 1	next_phase = 0	reward = 0.438537	array([[  2.5945559, -46.74039  ]], dtype=float32)
time = 65755	action = 0	current_phase = 1	next_phase = 0	reward = 1.007731	array([[  2.543624, -46.517677]], dtype=float32)
time = 65760	action = 0	current_phase = 1	next_phase = 0	reward = 0.726501	array([[  2.6089697, -46.886143 ]], dtype=float32)
time = 65765	action = 0	current_phase = 1	next_phase = 0	reward = 0.722850	array([[  2.5485582, -46.665085 ]], dtype=float32)
time = 65770	action = 0	current_phase = 1	next_phase = 0	reward = 0.440854	array([[  2.5379725, -46.914806 ]], dtype=float32)
time = 65775	action = 0	current_phase = 1	next_phase = 0	reward = 1.002940	array([[  2.5454016, -46.502613 ]], dtype=float32)
time = 65780	action = 0	current_phase = 1	next_phase = 0	reward = 0.722462	array([[  2.5791845, -46.87914  ]], dtype=float32)
time = 65785	action = 0	current_phase = 1	next_phase = 0	reward = 0.721991	array([[  2.5967264, -46.8772   ]], dtype=float32)
time = 65790	action = 0	current_phase = 1	next_phase = 0	reward = 0.729794	array([[  2.5463476, -46.53335  ]], dtype=float32)
time = 65795	action = 0	current_phase = 1	next_phase = 0	reward = 0.723621	array([[  2.5899076, -46.89531  ]], dtype=float32)
time = 65800	action = 0	current_phase = 1	next_phase = 0	reward = 0.438828	array([[  2.5982218, -46.717514 ]], dtype=float32)
time = 65805	action = 0	current_phase = 1	next_phase = 0	reward = 1.008750	array([[  2.5732012, -46.612663 ]], dtype=float32)
time = 65810	action = 0	current_phase = 1	next_phase = 0	reward = 0.720737	array([[  2.5671797, -46.577908 ]], dtype=float32)
time = 65815	action = 0	current_phase = 1	next_phase = 0	reward = 0.726982	array([[  2.5290594, -47.009277 ]], dtype=float32)
time = 65820	action = 0	current_phase = 1	next_phase = 0	reward = 0.715985	array([[  2.5812025, -46.72296  ]], dtype=float32)
time = 65825	action = 0	current_phase = 1	next_phase = 0	reward = 0.724220	array([[  2.5493822, -46.671967 ]], dtype=float32)
time = 65830	action = 0	current_phase = 1	next_phase = 0	reward = 0.723894	array([[  2.601325, -46.756897]], dtype=float32)
time = 65835	action = 0	current_phase = 1	next_phase = 0	reward = 0.722087	array([[  2.5802393, -46.935917 ]], dtype=float32)
time = 65840	action = 0	current_phase = 1	next_phase = 0	reward = 0.721031	array([[  2.5753355, -46.646683 ]], dtype=float32)
time = 65845	action = 0	current_phase = 1	next_phase = 0	reward = 0.719843	array([[  2.4848642, -46.436764 ]], dtype=float32)
time = 65850	action = 0	current_phase = 1	next_phase = 0	reward = 0.719387	array([[  2.5927973, -46.703144 ]], dtype=float32)
time = 65855	action = 0	current_phase = 1	next_phase = 0	reward = 0.721208	array([[  2.570239, -46.866722]], dtype=float32)
time = 65860	action = 0	current_phase = 1	next_phase = 0	reward = 0.721433	array([[  2.5607767, -46.613857 ]], dtype=float32)
time = 65865	action = 0	current_phase = 1	next_phase = 0	reward = 0.724548	array([[  2.578082, -46.701935]], dtype=float32)
time = 65870	action = 0	current_phase = 1	next_phase = 0	reward = 0.719484	array([[  2.5830164, -46.691547 ]], dtype=float32)
time = 65875	action = 0	current_phase = 1	next_phase = 0	reward = 0.704627	array([[  2.5753202, -46.80217  ]], dtype=float32)
time = 65880	action = 0	current_phase = 1	next_phase = 0	reward = 0.718531	array([[  2.583377, -46.663773]], dtype=float32)
time = 65885	action = 0	current_phase = 1	next_phase = 0	reward = 0.727715	array([[  2.538415, -46.494034]], dtype=float32)
time = 65890	action = 0	current_phase = 1	next_phase = 0	reward = 0.726165	array([[  2.5426874, -46.753845 ]], dtype=float32)
time = 65895	action = 0	current_phase = 1	next_phase = 0	reward = 0.719820	array([[  2.5244074, -46.47423  ]], dtype=float32)
time = 65900	action = 0	current_phase = 1	next_phase = 0	reward = 0.719324	array([[  2.5897207, -46.896038 ]], dtype=float32)
time = 65905	action = 0	current_phase = 1	next_phase = 0	reward = 0.721568	array([[  2.5790796, -46.64572  ]], dtype=float32)
time = 65910	action = 0	current_phase = 1	next_phase = 0	reward = 0.716721	array([[  2.5601416, -46.880272 ]], dtype=float32)
time = 65915	action = 0	current_phase = 1	next_phase = 0	reward = 0.444619	array([[  2.5983248, -46.907066 ]], dtype=float32)
time = 65920	action = 0	current_phase = 1	next_phase = 0	reward = 1.007545	array([[  2.582183, -46.746666]], dtype=float32)
time = 65925	action = 0	current_phase = 1	next_phase = 0	reward = 0.726337	array([[  2.6047049, -46.79287  ]], dtype=float32)
time = 65930	action = 0	current_phase = 1	next_phase = 0	reward = 0.722143	array([[  2.596898, -46.879898]], dtype=float32)
time = 65935	action = 0	current_phase = 1	next_phase = 0	reward = 0.444241	array([[  2.603282, -46.804287]], dtype=float32)
time = 65940	action = 0	current_phase = 1	next_phase = 0	reward = 0.728652	array([[  2.5112123, -47.061817 ]], dtype=float32)
time = 65945	action = 0	current_phase = 1	next_phase = 0	reward = 1.003950	array([[  2.5881987, -46.673744 ]], dtype=float32)
time = 65950	action = 0	current_phase = 1	next_phase = 0	reward = 0.716516	array([[  2.6155252, -46.860626 ]], dtype=float32)
time = 65955	action = 0	current_phase = 1	next_phase = 0	reward = 0.716002	array([[  2.57026 , -46.709396]], dtype=float32)
time = 65960	action = 0	current_phase = 1	next_phase = 0	reward = 0.716581	array([[  2.589881, -46.66255 ]], dtype=float32)
time = 65965	action = 0	current_phase = 1	next_phase = 0	reward = 0.726090	array([[  2.5607634, -46.574406 ]], dtype=float32)
time = 65970	action = 0	current_phase = 1	next_phase = 0	reward = 0.449254	array([[  2.52802, -46.72918]], dtype=float32)
time = 65975	action = 0	current_phase = 1	next_phase = 0	reward = 0.998904	array([[  2.6018362, -46.814278 ]], dtype=float32)
time = 65980	action = 0	current_phase = 1	next_phase = 0	reward = 0.724839	array([[  2.5988493, -46.88732  ]], dtype=float32)
time = 65985	action = 0	current_phase = 1	next_phase = 0	reward = 0.724805	array([[  2.6058798, -46.788605 ]], dtype=float32)
time = 65990	action = 0	current_phase = 1	next_phase = 0	reward = 0.727237	array([[  2.531396, -46.821827]], dtype=float32)
time = 65995	action = 0	current_phase = 1	next_phase = 0	reward = 0.725763	array([[  2.5570593, -46.62345  ]], dtype=float32)
time = 66000	action = 0	current_phase = 1	next_phase = 0	reward = 0.728849	array([[  2.5524626, -46.819298 ]], dtype=float32)
time = 66005	action = 0	current_phase = 1	next_phase = 0	reward = 0.729819	array([[  2.6038198, -46.771374 ]], dtype=float32)
time = 66010	action = 0	current_phase = 1	next_phase = 0	reward = 0.726263	array([[  2.565341, -46.817932]], dtype=float32)
time = 66015	action = 0	current_phase = 1	next_phase = 0	reward = 0.718914	array([[  2.5347185, -46.48215  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2201.9088 - val_loss: 164.7827
Epoch 2/50
 - 4s - loss: 2212.2530 - val_loss: 167.4739
Epoch 3/50
 - 4s - loss: 2269.9710 - val_loss: 179.3850
Epoch 4/50
 - 4s - loss: 2192.1144 - val_loss: 180.4464
Epoch 5/50
 - 4s - loss: 2194.7718 - val_loss: 184.4243
Epoch 6/50
 - 4s - loss: 2206.9451 - val_loss: 176.1999
Epoch 7/50
 - 4s - loss: 2225.4020 - val_loss: 170.5143
Epoch 8/50
 - 4s - loss: 2212.5793 - val_loss: 163.9976
Epoch 9/50
 - 4s - loss: 2186.6786 - val_loss: 160.6053
Epoch 10/50
 - 4s - loss: 2207.7741 - val_loss: 173.8177
Epoch 11/50
 - 4s - loss: 2169.7543 - val_loss: 165.3896
Epoch 12/50
 - 4s - loss: 2199.2084 - val_loss: 163.8652
Epoch 13/50
 - 4s - loss: 2185.9168 - val_loss: 170.2412
Epoch 14/50
 - 4s - loss: 2203.0987 - val_loss: 167.0551
Epoch 15/50
 - 4s - loss: 2198.3510 - val_loss: 168.4793
Epoch 16/50
 - 4s - loss: 2205.0976 - val_loss: 170.5111
Epoch 17/50
 - 4s - loss: 2209.0055 - val_loss: 160.3162
Epoch 18/50
 - 4s - loss: 2186.6825 - val_loss: 165.9523
Epoch 19/50
 - 4s - loss: 2191.7154 - val_loss: 173.2522
Epoch 20/50
 - 4s - loss: 2192.3557 - val_loss: 168.7495
Epoch 21/50
 - 4s - loss: 2174.8730 - val_loss: 166.9440
Epoch 22/50
 - 4s - loss: 2186.6097 - val_loss: 179.1193
Epoch 23/50
 - 4s - loss: 2185.2169 - val_loss: 162.9467
Epoch 24/50
 - 4s - loss: 2181.1904 - val_loss: 165.5576
Epoch 25/50
 - 4s - loss: 2174.6504 - val_loss: 163.0134
Epoch 26/50
 - 4s - loss: 2179.5037 - val_loss: 175.4125
Epoch 27/50
 - 4s - loss: 2188.4818 - val_loss: 171.2458
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 66020	action = 0	current_phase = 1	next_phase = 0	reward = 0.697099	array([[  2.5820818, -47.358597 ]], dtype=float32)
time = 66025	action = 0	current_phase = 1	next_phase = 0	reward = 0.436780	array([[  2.6331244, -47.000046 ]], dtype=float32)
time = 66030	action = 0	current_phase = 1	next_phase = 0	reward = 0.996094	array([[  2.54922, -46.77632]], dtype=float32)
time = 66035	action = 0	current_phase = 1	next_phase = 0	reward = 0.439907	array([[  2.603673, -47.15234 ]], dtype=float32)
time = 66040	action = 0	current_phase = 1	next_phase = 0	reward = 1.004845	array([[  2.5782995, -46.86448  ]], dtype=float32)
time = 66045	action = 0	current_phase = 1	next_phase = 0	reward = 0.439754	array([[  2.6403933, -47.11037  ]], dtype=float32)
time = 66050	action = 0	current_phase = 1	next_phase = 0	reward = 1.002817	array([[  2.534501, -46.731926]], dtype=float32)
time = 66055	action = 0	current_phase = 1	next_phase = 0	reward = 0.717147	array([[  2.5577974, -46.810123 ]], dtype=float32)
time = 66060	action = 0	current_phase = 1	next_phase = 0	reward = 0.439499	array([[  2.6394663, -47.24471  ]], dtype=float32)
time = 66065	action = 0	current_phase = 1	next_phase = 0	reward = 0.730698	array([[  2.6242628, -47.002106 ]], dtype=float32)
time = 66070	action = 0	current_phase = 1	next_phase = 0	reward = 1.009441	array([[  2.5645952, -46.83941  ]], dtype=float32)
time = 66075	action = 0	current_phase = 1	next_phase = 0	reward = 0.722383	array([[  2.6227846, -47.039474 ]], dtype=float32)
time = 66080	action = 0	current_phase = 1	next_phase = 0	reward = 0.723193	array([[  2.5905275, -46.904644 ]], dtype=float32)
time = 66085	action = 0	current_phase = 1	next_phase = 0	reward = 0.720872	array([[  2.609046, -46.946976]], dtype=float32)
time = 66090	action = 0	current_phase = 1	next_phase = 0	reward = 0.727430	array([[  2.6017199, -46.907616 ]], dtype=float32)
time = 66095	action = 0	current_phase = 1	next_phase = 0	reward = 0.717876	array([[  2.552497, -46.84868 ]], dtype=float32)
time = 66100	action = 0	current_phase = 1	next_phase = 0	reward = 0.720302	array([[  2.6410608, -47.196888 ]], dtype=float32)
time = 66105	action = 0	current_phase = 1	next_phase = 0	reward = 0.728989	array([[  2.6289911, -47.09638  ]], dtype=float32)
time = 66110	action = 0	current_phase = 1	next_phase = 0	reward = 0.723741	array([[  2.6092463, -46.951626 ]], dtype=float32)
time = 66115	action = 0	current_phase = 1	next_phase = 0	reward = 0.436359	array([[  2.6435308, -47.236053 ]], dtype=float32)
time = 66120	action = 0	current_phase = 1	next_phase = 0	reward = 1.003141	array([[  2.507043, -46.665955]], dtype=float32)
time = 66125	action = 0	current_phase = 1	next_phase = 0	reward = 0.724701	array([[  2.6090574, -46.949173 ]], dtype=float32)
time = 66130	action = 0	current_phase = 1	next_phase = 0	reward = 0.713560	array([[  2.6275682, -47.06189  ]], dtype=float32)
time = 66135	action = 0	current_phase = 1	next_phase = 0	reward = 0.718541	array([[  2.6034803, -46.941193 ]], dtype=float32)
time = 66140	action = 0	current_phase = 1	next_phase = 0	reward = 0.441210	array([[  2.516244, -46.674744]], dtype=float32)
time = 66145	action = 0	current_phase = 1	next_phase = 0	reward = 1.001756	array([[  2.6206884, -47.071106 ]], dtype=float32)
time = 66150	action = 0	current_phase = 1	next_phase = 0	reward = 0.720925	array([[  2.6139479, -47.037193 ]], dtype=float32)
time = 66155	action = 0	current_phase = 1	next_phase = 0	reward = 0.722883	array([[  2.6032114, -47.02602  ]], dtype=float32)
time = 66160	action = 0	current_phase = 1	next_phase = 0	reward = 0.726402	array([[  2.632743, -47.236824]], dtype=float32)
time = 66165	action = 0	current_phase = 1	next_phase = 0	reward = 0.717237	array([[  2.4979296, -46.697998 ]], dtype=float32)
time = 66170	action = 0	current_phase = 1	next_phase = 0	reward = 0.714314	array([[  2.6282454, -47.045685 ]], dtype=float32)
time = 66175	action = 0	current_phase = 1	next_phase = 0	reward = 0.442974	array([[  2.5948591, -46.902977 ]], dtype=float32)
time = 66180	action = 0	current_phase = 1	next_phase = 0	reward = 0.996522	array([[  2.6336145, -47.301685 ]], dtype=float32)
time = 66185	action = 0	current_phase = 1	next_phase = 0	reward = 0.712749	array([[  2.621993, -47.104454]], dtype=float32)
time = 66190	action = 0	current_phase = 1	next_phase = 0	reward = 0.722672	array([[  2.5790129, -46.841263 ]], dtype=float32)
time = 66195	action = 0	current_phase = 1	next_phase = 0	reward = 0.724775	array([[  2.6488485, -47.17096  ]], dtype=float32)
time = 66200	action = 0	current_phase = 1	next_phase = 0	reward = 0.727963	array([[  2.6267843, -47.048164 ]], dtype=float32)
time = 66205	action = 0	current_phase = 1	next_phase = 0	reward = 0.715127	array([[  2.5892134, -46.9103   ]], dtype=float32)
time = 66210	action = 0	current_phase = 1	next_phase = 0	reward = 0.440350	array([[  2.6307154, -47.081444 ]], dtype=float32)
time = 66215	action = 0	current_phase = 1	next_phase = 0	reward = 0.723596	array([[  2.6363401, -47.16147  ]], dtype=float32)
time = 66220	action = 0	current_phase = 1	next_phase = 0	reward = 0.998950	array([[  2.5412493, -46.805374 ]], dtype=float32)
time = 66225	action = 0	current_phase = 1	next_phase = 0	reward = 0.431626	array([[  2.5987806, -46.920616 ]], dtype=float32)
time = 66230	action = 0	current_phase = 1	next_phase = 0	reward = 0.997728	array([[  2.6256018, -47.052643 ]], dtype=float32)
time = 66235	action = 0	current_phase = 1	next_phase = 0	reward = 0.719402	array([[  2.6221762, -47.02599  ]], dtype=float32)
time = 66240	action = 0	current_phase = 1	next_phase = 0	reward = 0.715775	array([[  2.508378, -46.65213 ]], dtype=float32)
time = 66245	action = 0	current_phase = 1	next_phase = 0	reward = 0.721015	array([[  2.6391115, -47.061317 ]], dtype=float32)
time = 66250	action = 0	current_phase = 1	next_phase = 0	reward = 0.716832	array([[  2.584466, -46.92947 ]], dtype=float32)
time = 66255	action = 0	current_phase = 1	next_phase = 0	reward = 0.724016	array([[  2.6361265, -47.11402  ]], dtype=float32)
time = 66260	action = 0	current_phase = 1	next_phase = 0	reward = 0.711470	array([[  2.6341925, -47.210896 ]], dtype=float32)
time = 66265	action = 0	current_phase = 1	next_phase = 0	reward = 0.724460	array([[  2.611186, -47.000755]], dtype=float32)
time = 66270	action = 0	current_phase = 1	next_phase = 0	reward = 0.720096	array([[  2.5283136, -46.715576 ]], dtype=float32)
time = 66275	action = 0	current_phase = 1	next_phase = 0	reward = 0.718382	array([[  2.6494646, -47.102325 ]], dtype=float32)
time = 66280	action = 0	current_phase = 1	next_phase = 0	reward = 0.433056	array([[  2.5712385, -46.850964 ]], dtype=float32)
time = 66285	action = 0	current_phase = 1	next_phase = 0	reward = 0.719803	array([[  2.4913568, -46.616756 ]], dtype=float32)
time = 66290	action = 0	current_phase = 1	next_phase = 0	reward = 1.010934	array([[  2.6333685, -47.24478  ]], dtype=float32)
time = 66295	action = 0	current_phase = 1	next_phase = 0	reward = 0.720974	array([[  2.611888, -47.16054 ]], dtype=float32)
time = 66300	action = 0	current_phase = 1	next_phase = 0	reward = 0.446875	array([[  2.6445398, -47.160954 ]], dtype=float32)
time = 66305	action = 0	current_phase = 1	next_phase = 0	reward = 1.006222	array([[  2.6192007, -46.991684 ]], dtype=float32)
time = 66310	action = 0	current_phase = 1	next_phase = 0	reward = 0.715246	array([[  2.6290293, -47.031277 ]], dtype=float32)
time = 66315	action = 0	current_phase = 1	next_phase = 0	reward = 0.723046	array([[  2.5824594, -46.867435 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 341.2200 - val_loss: 212.5277
Epoch 2/50
 - 4s - loss: 371.6519 - val_loss: 197.1128
Epoch 3/50
 - 4s - loss: 331.4508 - val_loss: 193.9406
Epoch 4/50
 - 4s - loss: 335.9746 - val_loss: 204.0727
Epoch 5/50
 - 4s - loss: 333.1321 - val_loss: 224.0616
Epoch 6/50
 - 4s - loss: 349.6904 - val_loss: 206.8073
Epoch 7/50
 - 4s - loss: 334.8392 - val_loss: 219.9461
Epoch 8/50
 - 4s - loss: 327.7171 - val_loss: 198.6760
Epoch 9/50
 - 4s - loss: 322.8209 - val_loss: 198.2872
Epoch 10/50
 - 4s - loss: 319.8227 - val_loss: 203.0776
Epoch 11/50
 - 4s - loss: 317.7590 - val_loss: 194.7241
Epoch 12/50
 - 4s - loss: 323.4508 - val_loss: 196.2712
Epoch 13/50
 - 4s - loss: 323.1744 - val_loss: 208.6201
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 66320	action = 0	current_phase = 1	next_phase = 0	reward = 0.722891	array([[  2.605919, -47.153152]], dtype=float32)
time = 66325	action = 0	current_phase = 1	next_phase = 0	reward = 0.721411	array([[  2.6071014, -47.20955  ]], dtype=float32)
time = 66330	action = 0	current_phase = 1	next_phase = 0	reward = 0.721561	array([[  2.5923195, -47.025486 ]], dtype=float32)
time = 66335	action = 0	current_phase = 1	next_phase = 0	reward = 0.721635	array([[  2.5990238, -47.35373  ]], dtype=float32)
time = 66340	action = 0	current_phase = 1	next_phase = 0	reward = 0.442859	array([[  2.5952187, -47.031845 ]], dtype=float32)
time = 66345	action = 0	current_phase = 1	next_phase = 0	reward = 1.001260	array([[  2.5587444, -46.88937  ]], dtype=float32)
time = 66350	action = 0	current_phase = 1	next_phase = 0	reward = 0.716279	array([[  2.6087246, -47.195663 ]], dtype=float32)
time = 66355	action = 0	current_phase = 1	next_phase = 0	reward = 0.721937	array([[  2.6129475, -47.22272  ]], dtype=float32)
time = 66360	action = 0	current_phase = 1	next_phase = 0	reward = 0.724750	array([[  2.576229, -46.934963]], dtype=float32)
time = 66365	action = 0	current_phase = 1	next_phase = 0	reward = 0.719010	array([[  2.5944328, -47.29406  ]], dtype=float32)
time = 66370	action = 0	current_phase = 1	next_phase = 0	reward = 0.718099	array([[  2.5888348, -46.984444 ]], dtype=float32)
time = 66375	action = 0	current_phase = 1	next_phase = 0	reward = 0.720494	array([[  2.557436, -47.11491 ]], dtype=float32)
time = 66380	action = 0	current_phase = 1	next_phase = 0	reward = 0.444767	array([[  2.5700283, -46.92819  ]], dtype=float32)
time = 66385	action = 0	current_phase = 1	next_phase = 0	reward = 1.001593	array([[  2.620184, -47.25189 ]], dtype=float32)
time = 66390	action = 0	current_phase = 1	next_phase = 0	reward = 0.714650	array([[  2.5588245, -46.946205 ]], dtype=float32)
time = 66395	action = 0	current_phase = 1	next_phase = 0	reward = 0.709161	array([[  2.5496273, -46.864407 ]], dtype=float32)
time = 66400	action = 0	current_phase = 1	next_phase = 0	reward = 0.446071	array([[  2.5503616, -46.84234  ]], dtype=float32)
time = 66405	action = 0	current_phase = 1	next_phase = 0	reward = 1.004418	array([[  2.34544 , -46.472343]], dtype=float32)
time = 66410	action = 0	current_phase = 1	next_phase = 0	reward = 0.716349	array([[  2.51721, -46.75093]], dtype=float32)
time = 66415	action = 0	current_phase = 1	next_phase = 0	reward = 0.719287	array([[  2.5683746, -46.918457 ]], dtype=float32)
time = 66420	action = 0	current_phase = 1	next_phase = 0	reward = 0.721322	array([[  2.5578785, -46.899986 ]], dtype=float32)
time = 66425	action = 0	current_phase = 1	next_phase = 0	reward = 0.719548	array([[  2.5454464, -47.018845 ]], dtype=float32)
time = 66430	action = 0	current_phase = 1	next_phase = 0	reward = 0.722619	array([[  2.3090935, -46.45135  ]], dtype=float32)
time = 66435	action = 0	current_phase = 1	next_phase = 0	reward = 0.723874	array([[  2.5659695, -47.04195  ]], dtype=float32)
time = 66440	action = 0	current_phase = 1	next_phase = 0	reward = 0.732938	array([[  2.5226612, -46.80893  ]], dtype=float32)
time = 66445	action = 0	current_phase = 1	next_phase = 0	reward = 0.712432	array([[  2.561367, -46.90709 ]], dtype=float32)
time = 66450	action = 0	current_phase = 1	next_phase = 0	reward = 0.721317	array([[  2.6343365, -47.196587 ]], dtype=float32)
time = 66455	action = 0	current_phase = 1	next_phase = 0	reward = 0.720885	array([[  2.5415401, -46.937134 ]], dtype=float32)
time = 66460	action = 0	current_phase = 1	next_phase = 0	reward = 0.443865	array([[  2.5506077, -47.01866  ]], dtype=float32)
time = 66465	action = 0	current_phase = 1	next_phase = 0	reward = 1.003385	array([[  2.5976944, -47.06633  ]], dtype=float32)
time = 66470	action = 0	current_phase = 1	next_phase = 0	reward = 0.444525	array([[  2.6090794, -47.08653  ]], dtype=float32)
time = 66475	action = 0	current_phase = 1	next_phase = 0	reward = 1.009419	array([[  2.5973072, -47.05445  ]], dtype=float32)
time = 66480	action = 0	current_phase = 1	next_phase = 0	reward = 0.712329	array([[  2.590416, -47.14357 ]], dtype=float32)
time = 66485	action = 0	current_phase = 1	next_phase = 0	reward = 0.717544	array([[  2.6053238, -47.101208 ]], dtype=float32)
time = 66490	action = 0	current_phase = 1	next_phase = 0	reward = 0.444747	array([[  2.600151, -47.04789 ]], dtype=float32)
time = 66495	action = 0	current_phase = 1	next_phase = 0	reward = 1.007324	array([[  2.5789108, -46.955902 ]], dtype=float32)
time = 66500	action = 0	current_phase = 1	next_phase = 0	reward = 0.445785	array([[  2.598919, -47.064453]], dtype=float32)
time = 66505	action = 0	current_phase = 1	next_phase = 0	reward = 1.005058	array([[  2.5980186, -47.01584  ]], dtype=float32)
time = 66510	action = 0	current_phase = 1	next_phase = 0	reward = 0.720499	array([[  2.6319141, -47.165768 ]], dtype=float32)
time = 66515	action = 0	current_phase = 1	next_phase = 0	reward = 0.443442	array([[  2.5043697, -46.796272 ]], dtype=float32)
time = 66520	action = 0	current_phase = 1	next_phase = 0	reward = 1.003995	array([[  2.6064472, -47.04648  ]], dtype=float32)
time = 66525	action = 0	current_phase = 1	next_phase = 0	reward = 0.438436	array([[  2.4943066, -46.706493 ]], dtype=float32)
time = 66530	action = 0	current_phase = 1	next_phase = 0	reward = 0.996685	array([[  2.5356655, -46.882378 ]], dtype=float32)
time = 66535	action = 0	current_phase = 1	next_phase = 0	reward = 0.720118	array([[  2.6132545, -47.21618  ]], dtype=float32)
time = 66540	action = 0	current_phase = 1	next_phase = 0	reward = 0.711969	array([[  2.574152, -46.96764 ]], dtype=float32)
time = 66545	action = 0	current_phase = 1	next_phase = 0	reward = 0.438692	array([[  2.59416 , -46.990986]], dtype=float32)
time = 66550	action = 0	current_phase = 1	next_phase = 0	reward = 1.007020	array([[  2.6080265, -47.083168 ]], dtype=float32)
time = 66555	action = 0	current_phase = 1	next_phase = 0	reward = 0.727969	array([[  2.5472965, -46.846237 ]], dtype=float32)
time = 66560	action = 0	current_phase = 1	next_phase = 0	reward = 0.728036	array([[  2.5576286, -46.88994  ]], dtype=float32)
time = 66565	action = 0	current_phase = 1	next_phase = 0	reward = 0.437409	array([[  2.5969543, -47.106247 ]], dtype=float32)
time = 66570	action = 0	current_phase = 1	next_phase = 0	reward = 0.998844	array([[  2.6093597, -47.06495  ]], dtype=float32)
time = 66575	action = 0	current_phase = 1	next_phase = 0	reward = 0.718827	array([[  2.4132175, -46.641872 ]], dtype=float32)
time = 66580	action = 0	current_phase = 1	next_phase = 0	reward = 0.718827	array([[  2.5754986, -46.98089  ]], dtype=float32)
time = 66585	action = 0	current_phase = 1	next_phase = 0	reward = 0.717403	array([[  2.5326786, -46.83005  ]], dtype=float32)
time = 66590	action = 0	current_phase = 1	next_phase = 0	reward = 0.718997	array([[  2.4960556, -46.748756 ]], dtype=float32)
time = 66595	action = 0	current_phase = 1	next_phase = 0	reward = 0.719578	array([[  2.5910034, -47.13034  ]], dtype=float32)
time = 66600	action = 0	current_phase = 1	next_phase = 0	reward = 0.722106	array([[  2.3178253, -46.468254 ]], dtype=float32)
time = 66605	action = 0	current_phase = 1	next_phase = 0	reward = 0.719793	array([[  2.62191, -47.21566]], dtype=float32)
time = 66610	action = 0	current_phase = 1	next_phase = 0	reward = 0.721265	array([[  2.5666275, -46.94142  ]], dtype=float32)
time = 66615	action = 0	current_phase = 1	next_phase = 0	reward = 0.725329	array([[  1.7865934, -45.97649  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2092.5307 - val_loss: 188.5008
Epoch 2/50
 - 4s - loss: 2075.9495 - val_loss: 196.6007
Epoch 3/50
 - 4s - loss: 2075.4950 - val_loss: 238.2355
Epoch 4/50
 - 4s - loss: 2070.5824 - val_loss: 171.7958
Epoch 5/50
 - 4s - loss: 2077.1166 - val_loss: 201.2086
Epoch 6/50
 - 4s - loss: 2086.9909 - val_loss: 182.9686
Epoch 7/50
 - 4s - loss: 2096.3545 - val_loss: 154.8726
Epoch 8/50
 - 4s - loss: 2077.8094 - val_loss: 199.2070
Epoch 9/50
 - 4s - loss: 2092.5620 - val_loss: 176.2360
Epoch 10/50
 - 4s - loss: 2059.5271 - val_loss: 163.1605
Epoch 11/50
 - 4s - loss: 2102.2777 - val_loss: 201.2379
Epoch 12/50
 - 4s - loss: 2088.4315 - val_loss: 181.1069
Epoch 13/50
 - 4s - loss: 2098.1654 - val_loss: 164.1620
Epoch 14/50
 - 4s - loss: 2079.8916 - val_loss: 177.6913
Epoch 15/50
 - 4s - loss: 2064.8187 - val_loss: 171.4936
Epoch 16/50
 - 4s - loss: 2081.0367 - val_loss: 160.7844
Epoch 17/50
 - 4s - loss: 2066.6908 - val_loss: 177.7735
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 66620	action = 0	current_phase = 1	next_phase = 0	reward = 0.720146	array([[  2.7374372, -47.588295 ]], dtype=float32)
time = 66625	action = 0	current_phase = 1	next_phase = 0	reward = 0.450217	array([[  2.7586794, -47.333015 ]], dtype=float32)
time = 66630	action = 0	current_phase = 1	next_phase = 0	reward = 1.006197	array([[  2.7595167, -47.455666 ]], dtype=float32)
time = 66635	action = 0	current_phase = 1	next_phase = 0	reward = 0.720074	array([[  2.7720594, -47.512897 ]], dtype=float32)
time = 66640	action = 0	current_phase = 1	next_phase = 0	reward = 0.727555	array([[  2.700467, -47.121574]], dtype=float32)
time = 66645	action = 0	current_phase = 1	next_phase = 0	reward = 0.719654	array([[  2.6047678, -46.849945 ]], dtype=float32)
time = 66650	action = 0	current_phase = 1	next_phase = 0	reward = 0.720128	array([[  2.6804228, -47.02102  ]], dtype=float32)
time = 66655	action = 0	current_phase = 1	next_phase = 0	reward = 0.719666	array([[  2.762271, -47.39969 ]], dtype=float32)
time = 66660	action = 0	current_phase = 1	next_phase = 0	reward = 0.719118	array([[  2.6877317, -47.13926  ]], dtype=float32)
time = 66665	action = 0	current_phase = 1	next_phase = 0	reward = 0.720180	array([[  2.7414484, -47.599945 ]], dtype=float32)
time = 66670	action = 0	current_phase = 1	next_phase = 0	reward = 0.715091	array([[  2.7433043, -47.242928 ]], dtype=float32)
time = 66675	action = 0	current_phase = 1	next_phase = 0	reward = 0.726133	array([[  2.7198725, -47.14513  ]], dtype=float32)
time = 66680	action = 0	current_phase = 1	next_phase = 0	reward = 0.717170	array([[  2.722663, -47.115654]], dtype=float32)
time = 66685	action = 0	current_phase = 1	next_phase = 0	reward = 0.717137	array([[  2.7345762, -47.197197 ]], dtype=float32)
time = 66690	action = 0	current_phase = 1	next_phase = 0	reward = 0.441632	array([[  2.6410646, -46.90818  ]], dtype=float32)
time = 66695	action = 0	current_phase = 1	next_phase = 0	reward = 0.998450	array([[  2.762641, -47.24865 ]], dtype=float32)
time = 66700	action = 0	current_phase = 1	next_phase = 0	reward = 0.715130	array([[  2.735448, -47.376785]], dtype=float32)
time = 66705	action = 0	current_phase = 1	next_phase = 0	reward = 0.719046	array([[  2.7259912, -47.139854 ]], dtype=float32)
time = 66710	action = 0	current_phase = 1	next_phase = 0	reward = 0.436158	array([[  2.7592382, -47.600098 ]], dtype=float32)
time = 66715	action = 0	current_phase = 1	next_phase = 0	reward = 1.000701	array([[  2.774228, -47.392056]], dtype=float32)
time = 66720	action = 0	current_phase = 1	next_phase = 0	reward = 0.715484	array([[  2.7211123, -47.471516 ]], dtype=float32)
time = 66725	action = 0	current_phase = 1	next_phase = 0	reward = 0.442971	array([[  2.758586, -47.33609 ]], dtype=float32)
time = 66730	action = 0	current_phase = 1	next_phase = 0	reward = 0.995449	array([[  2.6463308, -47.000584 ]], dtype=float32)
time = 66735	action = 0	current_phase = 1	next_phase = 0	reward = 0.441115	array([[  2.7497206, -47.213554 ]], dtype=float32)
time = 66740	action = 0	current_phase = 1	next_phase = 0	reward = 1.000122	array([[  2.5876188, -46.99124  ]], dtype=float32)
time = 66745	action = 0	current_phase = 1	next_phase = 0	reward = 0.710967	array([[  2.7621813, -47.30223  ]], dtype=float32)
time = 66750	action = 0	current_phase = 1	next_phase = 0	reward = 0.436948	array([[  2.6944056, -47.051468 ]], dtype=float32)
time = 66755	action = 0	current_phase = 1	next_phase = 0	reward = 0.721971	array([[  2.7597055, -47.551983 ]], dtype=float32)
time = 66760	action = 0	current_phase = 1	next_phase = 0	reward = 1.000839	array([[  2.696519, -47.07955 ]], dtype=float32)
time = 66765	action = 0	current_phase = 1	next_phase = 0	reward = 0.718040	array([[  2.7799654, -47.450146 ]], dtype=float32)
time = 66770	action = 0	current_phase = 1	next_phase = 0	reward = 0.724453	array([[  2.7075167, -47.0792   ]], dtype=float32)
time = 66775	action = 0	current_phase = 1	next_phase = 0	reward = 0.442677	array([[  2.739133, -47.200768]], dtype=float32)
time = 66780	action = 0	current_phase = 1	next_phase = 0	reward = 0.726010	array([[  2.7911024, -47.532196 ]], dtype=float32)
time = 66785	action = 0	current_phase = 1	next_phase = 0	reward = 1.001873	array([[  2.657775, -46.949512]], dtype=float32)
time = 66790	action = 0	current_phase = 1	next_phase = 0	reward = 0.717545	array([[  2.7465658, -47.189926 ]], dtype=float32)
time = 66795	action = 0	current_phase = 1	next_phase = 0	reward = 0.717010	array([[  2.770749, -47.482372]], dtype=float32)
time = 66800	action = 0	current_phase = 1	next_phase = 0	reward = 0.717232	array([[  2.7321844, -47.15632  ]], dtype=float32)
time = 66805	action = 0	current_phase = 1	next_phase = 0	reward = 0.722876	array([[  2.7079515, -47.105217 ]], dtype=float32)
time = 66810	action = 0	current_phase = 1	next_phase = 0	reward = 0.717754	array([[  2.724347, -47.163734]], dtype=float32)
time = 66815	action = 0	current_phase = 1	next_phase = 0	reward = 0.722233	array([[  2.6972857, -47.04682  ]], dtype=float32)
time = 66820	action = 0	current_phase = 1	next_phase = 0	reward = 0.448771	array([[  2.757575, -47.510784]], dtype=float32)
time = 66825	action = 0	current_phase = 1	next_phase = 0	reward = 1.010172	array([[  2.6342669, -46.890305 ]], dtype=float32)
time = 66830	action = 0	current_phase = 1	next_phase = 0	reward = 0.726144	array([[  2.7749605, -47.39969  ]], dtype=float32)
time = 66835	action = 0	current_phase = 1	next_phase = 0	reward = 0.711363	array([[  2.5957117, -46.91414  ]], dtype=float32)
time = 66840	action = 0	current_phase = 1	next_phase = 0	reward = 0.717892	array([[  2.6458426, -47.075104 ]], dtype=float32)
time = 66845	action = 0	current_phase = 1	next_phase = 0	reward = 0.721509	array([[  2.63375, -46.92736]], dtype=float32)
time = 66850	action = 0	current_phase = 1	next_phase = 0	reward = 0.723773	array([[  2.6999788, -47.550526 ]], dtype=float32)
time = 66855	action = 0	current_phase = 1	next_phase = 0	reward = 0.721082	array([[  2.6752405, -46.990143 ]], dtype=float32)
time = 66860	action = 0	current_phase = 1	next_phase = 0	reward = 0.714090	array([[  2.7388906, -47.591633 ]], dtype=float32)
time = 66865	action = 0	current_phase = 1	next_phase = 0	reward = 0.718210	array([[  2.7517538, -47.25168  ]], dtype=float32)
time = 66870	action = 0	current_phase = 1	next_phase = 0	reward = 0.724464	array([[  2.713294, -47.27552 ]], dtype=float32)
time = 66875	action = 0	current_phase = 1	next_phase = 0	reward = 0.442852	array([[  2.7136183, -47.14574  ]], dtype=float32)
time = 66880	action = 0	current_phase = 1	next_phase = 0	reward = 1.001134	array([[  2.758319, -47.552795]], dtype=float32)
time = 66885	action = 0	current_phase = 1	next_phase = 0	reward = 0.725980	array([[  2.6657724, -47.007595 ]], dtype=float32)
time = 66890	action = 0	current_phase = 1	next_phase = 0	reward = 0.721708	array([[  2.7633944, -47.5172   ]], dtype=float32)
time = 66895	action = 0	current_phase = 1	next_phase = 0	reward = 0.724011	array([[  2.6545324, -46.94477  ]], dtype=float32)
time = 66900	action = 0	current_phase = 1	next_phase = 0	reward = 0.719759	array([[  2.747693, -47.223457]], dtype=float32)
time = 66905	action = 0	current_phase = 1	next_phase = 0	reward = 0.723497	array([[  2.784459, -47.431797]], dtype=float32)
time = 66910	action = 0	current_phase = 1	next_phase = 0	reward = 0.726301	array([[  2.6986322, -47.059082 ]], dtype=float32)
time = 66915	action = 0	current_phase = 1	next_phase = 0	reward = 0.723476	array([[  2.705861, -47.104843]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 256.7543 - val_loss: 555.5179
Epoch 2/50
 - 4s - loss: 261.2265 - val_loss: 549.0156
Epoch 3/50
 - 4s - loss: 236.5677 - val_loss: 566.4875
Epoch 4/50
 - 4s - loss: 243.1737 - val_loss: 558.8090
Epoch 5/50
 - 4s - loss: 261.4795 - val_loss: 575.7536
Epoch 6/50
 - 4s - loss: 253.6045 - val_loss: 549.1616
Epoch 7/50
 - 4s - loss: 251.2925 - val_loss: 548.2531
Epoch 8/50
 - 4s - loss: 238.5660 - val_loss: 563.9880
Epoch 9/50
 - 4s - loss: 243.4879 - val_loss: 578.3145
Epoch 10/50
 - 4s - loss: 261.6572 - val_loss: 588.7776
Epoch 11/50
 - 4s - loss: 228.4713 - val_loss: 567.2381
Epoch 12/50
 - 4s - loss: 231.0658 - val_loss: 548.4381
Epoch 13/50
 - 4s - loss: 238.6996 - val_loss: 577.9537
Epoch 14/50
 - 4s - loss: 266.0284 - val_loss: 554.2640
Epoch 15/50
 - 4s - loss: 238.9347 - val_loss: 567.5268
Epoch 16/50
 - 4s - loss: 231.0974 - val_loss: 585.0355
Epoch 17/50
 - 4s - loss: 232.2725 - val_loss: 557.1736
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 66920	action = 0	current_phase = 1	next_phase = 0	reward = 0.723852	array([[  2.7103024, -47.238396 ]], dtype=float32)
time = 66925	action = 0	current_phase = 1	next_phase = 0	reward = 0.721780	array([[  2.8076344, -47.18836  ]], dtype=float32)
time = 66930	action = 0	current_phase = 1	next_phase = 0	reward = 0.719534	array([[  2.887083, -47.465755]], dtype=float32)
time = 66935	action = 0	current_phase = 1	next_phase = 0	reward = 0.721763	array([[  2.8819466, -47.391567 ]], dtype=float32)
time = 66940	action = 0	current_phase = 1	next_phase = 0	reward = 0.713154	array([[  2.905241, -47.75641 ]], dtype=float32)
time = 66945	action = 0	current_phase = 1	next_phase = 0	reward = 0.719817	array([[  2.8727894, -47.394386 ]], dtype=float32)
time = 66950	action = 0	current_phase = 1	next_phase = 0	reward = 0.723752	array([[  2.839264, -47.298737]], dtype=float32)
time = 66955	action = 0	current_phase = 1	next_phase = 0	reward = 0.725822	array([[  2.8534622, -47.28797  ]], dtype=float32)
time = 66960	action = 0	current_phase = 1	next_phase = 0	reward = 0.726789	array([[  2.8073006, -47.242107 ]], dtype=float32)
time = 66965	action = 0	current_phase = 1	next_phase = 0	reward = 0.716931	array([[  2.8970337, -47.4767   ]], dtype=float32)
time = 66970	action = 0	current_phase = 1	next_phase = 0	reward = 0.720592	array([[  2.8288193, -47.26561  ]], dtype=float32)
time = 66975	action = 0	current_phase = 1	next_phase = 0	reward = 0.715011	array([[  2.894575, -47.47812 ]], dtype=float32)
time = 66980	action = 0	current_phase = 1	next_phase = 0	reward = 0.443428	array([[  2.9091873, -47.53916  ]], dtype=float32)
time = 66985	action = 0	current_phase = 1	next_phase = 0	reward = 0.729165	array([[  2.9004154, -47.446075 ]], dtype=float32)
time = 66990	action = 0	current_phase = 1	next_phase = 0	reward = 1.001587	array([[  2.707323, -46.925804]], dtype=float32)
time = 66995	action = 0	current_phase = 1	next_phase = 0	reward = 0.721468	array([[  2.896223, -47.446587]], dtype=float32)
time = 67000	action = 0	current_phase = 1	next_phase = 0	reward = 0.723528	array([[  2.7211628, -47.10614  ]], dtype=float32)
time = 67005	action = 0	current_phase = 1	next_phase = 0	reward = 0.726401	array([[  2.8846836, -47.62342  ]], dtype=float32)
time = 67010	action = 0	current_phase = 1	next_phase = 0	reward = 0.724098	array([[  2.8840218, -47.383324 ]], dtype=float32)
time = 67015	action = 0	current_phase = 1	next_phase = 0	reward = 0.720279	array([[  2.9019413, -47.53665  ]], dtype=float32)
time = 67020	action = 0	current_phase = 1	next_phase = 0	reward = 0.715702	array([[  2.779459, -47.18952 ]], dtype=float32)
time = 67025	action = 0	current_phase = 1	next_phase = 0	reward = 0.442261	array([[  2.7999306, -47.13719  ]], dtype=float32)
time = 67030	action = 0	current_phase = 1	next_phase = 0	reward = 0.987018	array([[  2.9003983, -47.717346 ]], dtype=float32)
time = 67035	action = 0	current_phase = 1	next_phase = 0	reward = 0.719609	array([[  2.8448715, -47.294884 ]], dtype=float32)
time = 67040	action = 0	current_phase = 1	next_phase = 0	reward = 0.718197	array([[  2.8440418, -47.2547   ]], dtype=float32)
time = 67045	action = 0	current_phase = 1	next_phase = 0	reward = 0.727016	array([[  2.8918018, -47.513313 ]], dtype=float32)
time = 67050	action = 0	current_phase = 1	next_phase = 0	reward = 0.718305	array([[  2.8709183, -47.344635 ]], dtype=float32)
time = 67055	action = 0	current_phase = 1	next_phase = 0	reward = 0.717962	array([[  2.8988667, -47.439922 ]], dtype=float32)
time = 67060	action = 0	current_phase = 1	next_phase = 0	reward = 0.720071	array([[  2.760666, -47.101906]], dtype=float32)
time = 67065	action = 0	current_phase = 1	next_phase = 0	reward = 0.713877	array([[  2.8014011, -47.138206 ]], dtype=float32)
time = 67070	action = 0	current_phase = 1	next_phase = 0	reward = 0.716031	array([[  2.8994331, -47.559166 ]], dtype=float32)
time = 67075	action = 0	current_phase = 1	next_phase = 0	reward = 0.439781	array([[  2.7698498, -47.09685  ]], dtype=float32)
time = 67080	action = 0	current_phase = 1	next_phase = 0	reward = 1.007671	array([[  2.8452492, -47.307915 ]], dtype=float32)
time = 67085	action = 0	current_phase = 1	next_phase = 0	reward = 0.445365	array([[  2.8632584, -47.357338 ]], dtype=float32)
time = 67090	action = 0	current_phase = 1	next_phase = 0	reward = 1.003756	array([[  2.8673477, -47.379833 ]], dtype=float32)
time = 67095	action = 0	current_phase = 1	next_phase = 0	reward = 0.720552	array([[  2.8361893, -47.28686  ]], dtype=float32)
time = 67100	action = 0	current_phase = 1	next_phase = 0	reward = 0.446244	array([[  2.7959213, -47.13845  ]], dtype=float32)
time = 67105	action = 0	current_phase = 1	next_phase = 0	reward = 1.004933	array([[  2.8158646, -47.17823  ]], dtype=float32)
time = 67110	action = 0	current_phase = 1	next_phase = 0	reward = 0.718897	array([[  2.847477, -47.270958]], dtype=float32)
time = 67115	action = 0	current_phase = 1	next_phase = 0	reward = 0.710192	array([[  2.8057423, -47.185783 ]], dtype=float32)
time = 67120	action = 0	current_phase = 1	next_phase = 0	reward = 0.721200	array([[  2.7865334, -47.12507  ]], dtype=float32)
time = 67125	action = 0	current_phase = 1	next_phase = 0	reward = 0.721268	array([[  2.9171104, -47.52845  ]], dtype=float32)
time = 67130	action = 0	current_phase = 1	next_phase = 0	reward = 0.452034	array([[  2.8310776, -47.222763 ]], dtype=float32)
time = 67135	action = 0	current_phase = 1	next_phase = 0	reward = 1.008025	array([[  2.8012886, -47.18553  ]], dtype=float32)
time = 67140	action = 0	current_phase = 1	next_phase = 0	reward = 0.726837	array([[  2.8793907, -47.819168 ]], dtype=float32)
time = 67145	action = 0	current_phase = 1	next_phase = 0	reward = 0.727953	array([[  2.8001194, -47.139557 ]], dtype=float32)
time = 67150	action = 0	current_phase = 1	next_phase = 0	reward = 0.727779	array([[  2.887146, -47.402367]], dtype=float32)
time = 67155	action = 0	current_phase = 1	next_phase = 0	reward = 0.713709	array([[  2.9127235, -47.641685 ]], dtype=float32)
time = 67160	action = 0	current_phase = 1	next_phase = 0	reward = 0.720159	array([[  2.833559, -47.278015]], dtype=float32)
time = 67165	action = 0	current_phase = 1	next_phase = 0	reward = 0.721719	array([[  2.8042183, -47.161156 ]], dtype=float32)
time = 67170	action = 0	current_phase = 1	next_phase = 0	reward = 0.709955	array([[  2.8971348, -47.72663  ]], dtype=float32)
time = 67175	action = 0	current_phase = 1	next_phase = 0	reward = 0.713129	array([[  2.8592033, -47.37138  ]], dtype=float32)
time = 67180	action = 0	current_phase = 1	next_phase = 0	reward = 0.714022	array([[  2.8001919, -47.139553 ]], dtype=float32)
time = 67185	action = 0	current_phase = 1	next_phase = 0	reward = 0.443451	array([[  2.84276 , -47.290016]], dtype=float32)
time = 67190	action = 0	current_phase = 1	next_phase = 0	reward = 0.723782	array([[  2.891817, -47.592964]], dtype=float32)
time = 67195	action = 0	current_phase = 1	next_phase = 0	reward = 1.002255	array([[  2.7681637, -47.06753  ]], dtype=float32)
time = 67200	action = 0	current_phase = 1	next_phase = 0	reward = 0.720808	array([[  2.8998241, -47.688065 ]], dtype=float32)
time = 67205	action = 0	current_phase = 1	next_phase = 0	reward = 0.447453	array([[  2.8330727, -47.23546  ]], dtype=float32)
time = 67210	action = 0	current_phase = 1	next_phase = 0	reward = 1.007559	array([[  2.8097286, -47.42748  ]], dtype=float32)
time = 67215	action = 0	current_phase = 1	next_phase = 0	reward = 0.722528	array([[  2.7521915, -47.032204 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2248.7203 - val_loss: 270.6346
Epoch 2/50
 - 4s - loss: 2263.3581 - val_loss: 298.1804
Epoch 3/50
 - 4s - loss: 2271.5814 - val_loss: 315.3218
Epoch 4/50
 - 4s - loss: 2282.7884 - val_loss: 290.0519
Epoch 5/50
 - 4s - loss: 2262.1491 - val_loss: 281.5771
Epoch 6/50
 - 4s - loss: 2270.2990 - val_loss: 283.0143
Epoch 7/50
 - 4s - loss: 2257.7588 - val_loss: 291.0048
Epoch 8/50
 - 4s - loss: 2254.4738 - val_loss: 287.3380
Epoch 9/50
 - 4s - loss: 2272.9884 - val_loss: 273.0145
Epoch 10/50
 - 4s - loss: 2264.8441 - val_loss: 288.7246
Epoch 11/50
 - 4s - loss: 2532.8248 - val_loss: 413.4254
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 67220	action = 0	current_phase = 1	next_phase = 0	reward = 0.723454	array([[  2.676177, -47.155067]], dtype=float32)
time = 67225	action = 0	current_phase = 1	next_phase = 0	reward = 0.722157	array([[  2.7067327, -47.27509  ]], dtype=float32)
time = 67230	action = 0	current_phase = 1	next_phase = 0	reward = 0.716665	array([[  2.6930456, -47.164783 ]], dtype=float32)
time = 67235	action = 0	current_phase = 1	next_phase = 0	reward = 0.444276	array([[  2.7473574, -47.471146 ]], dtype=float32)
time = 67240	action = 0	current_phase = 1	next_phase = 0	reward = 0.995924	array([[  2.7159338, -47.22815  ]], dtype=float32)
time = 67245	action = 0	current_phase = 1	next_phase = 0	reward = 0.714417	array([[  2.663951, -47.127773]], dtype=float32)
time = 67250	action = 0	current_phase = 1	next_phase = 0	reward = 0.712919	array([[  2.6931887, -47.205307 ]], dtype=float32)
time = 67255	action = 0	current_phase = 1	next_phase = 0	reward = 0.444208	array([[  2.6216383, -46.98803  ]], dtype=float32)
time = 67260	action = 0	current_phase = 1	next_phase = 0	reward = 1.001301	array([[  2.6007242, -46.98912  ]], dtype=float32)
time = 67265	action = 0	current_phase = 1	next_phase = 0	reward = 0.714796	array([[  2.6548758, -47.077034 ]], dtype=float32)
time = 67270	action = 0	current_phase = 1	next_phase = 0	reward = 0.717249	array([[  2.638568, -47.031242]], dtype=float32)
time = 67275	action = 0	current_phase = 1	next_phase = 0	reward = 0.727741	array([[  2.755004, -47.369797]], dtype=float32)
time = 67280	action = 0	current_phase = 1	next_phase = 0	reward = 0.720250	array([[  2.6918554, -47.19597  ]], dtype=float32)
time = 67285	action = 0	current_phase = 1	next_phase = 0	reward = 0.438452	array([[  2.7519236, -47.361332 ]], dtype=float32)
time = 67290	action = 0	current_phase = 1	next_phase = 0	reward = 0.993849	array([[  2.6716986, -47.104088 ]], dtype=float32)
time = 67295	action = 0	current_phase = 1	next_phase = 0	reward = 0.436711	array([[  2.7614164, -47.41883  ]], dtype=float32)
time = 67300	action = 0	current_phase = 1	next_phase = 0	reward = 0.722644	array([[  2.6659594, -47.094936 ]], dtype=float32)
time = 67305	action = 0	current_phase = 1	next_phase = 0	reward = 1.001743	array([[  2.654521, -47.141853]], dtype=float32)
time = 67310	action = 0	current_phase = 1	next_phase = 0	reward = 0.718277	array([[  2.7184687, -47.338814 ]], dtype=float32)
time = 67315	action = 0	current_phase = 1	next_phase = 0	reward = 0.730094	array([[  2.5787268, -47.00959  ]], dtype=float32)
time = 67320	action = 0	current_phase = 1	next_phase = 0	reward = 0.718690	array([[  2.5421743, -46.839203 ]], dtype=float32)
time = 67325	action = 0	current_phase = 1	next_phase = 0	reward = 0.716194	array([[  2.760642, -47.42656 ]], dtype=float32)
time = 67330	action = 0	current_phase = 1	next_phase = 0	reward = 0.445621	array([[  2.63202 , -47.014618]], dtype=float32)
time = 67335	action = 0	current_phase = 1	next_phase = 0	reward = 1.001193	array([[  2.769454, -47.49092 ]], dtype=float32)
time = 67340	action = 0	current_phase = 1	next_phase = 0	reward = 0.726359	array([[  2.7162943, -47.258358 ]], dtype=float32)
time = 67345	action = 0	current_phase = 1	next_phase = 0	reward = 0.732126	array([[  2.5404005, -46.7942   ]], dtype=float32)
time = 67350	action = 0	current_phase = 1	next_phase = 0	reward = 0.717690	array([[  2.6645231, -47.148193 ]], dtype=float32)
time = 67355	action = 0	current_phase = 1	next_phase = 0	reward = 0.719197	array([[  2.6040468, -46.951077 ]], dtype=float32)
time = 67360	action = 0	current_phase = 1	next_phase = 0	reward = 0.445161	array([[  2.5407953, -46.807556 ]], dtype=float32)
time = 67365	action = 0	current_phase = 1	next_phase = 0	reward = 0.996827	array([[  2.751771, -47.571594]], dtype=float32)
time = 67370	action = 0	current_phase = 1	next_phase = 0	reward = 0.719989	array([[  2.7580671, -47.413887 ]], dtype=float32)
time = 67375	action = 0	current_phase = 1	next_phase = 0	reward = 0.434004	array([[  2.6426725, -47.05671  ]], dtype=float32)
time = 67380	action = 0	current_phase = 1	next_phase = 0	reward = 0.729077	array([[  2.6772795, -47.13933  ]], dtype=float32)
time = 67385	action = 0	current_phase = 1	next_phase = 0	reward = 0.726258	array([[  2.717101, -47.357094]], dtype=float32)
time = 67390	action = 0	current_phase = 1	next_phase = 0	reward = 0.997170	array([[  2.7573156, -47.419853 ]], dtype=float32)
time = 67395	action = 0	current_phase = 1	next_phase = 0	reward = 0.716486	array([[  2.7945852, -47.67491  ]], dtype=float32)
time = 67400	action = 0	current_phase = 1	next_phase = 0	reward = 0.710937	array([[  2.7744665, -47.54719  ]], dtype=float32)
time = 67405	action = 0	current_phase = 1	next_phase = 0	reward = 0.450103	array([[  2.681695, -47.189728]], dtype=float32)
time = 67410	action = 0	current_phase = 1	next_phase = 0	reward = 0.995679	array([[  2.7143602, -47.260838 ]], dtype=float32)
time = 67415	action = 0	current_phase = 1	next_phase = 0	reward = 0.718134	array([[  2.7927465, -47.587624 ]], dtype=float32)
time = 67420	action = 0	current_phase = 1	next_phase = 0	reward = 0.723263	array([[  2.620469, -46.98386 ]], dtype=float32)
time = 67425	action = 0	current_phase = 1	next_phase = 0	reward = 0.724801	array([[  2.7199602, -47.32911  ]], dtype=float32)
time = 67430	action = 0	current_phase = 1	next_phase = 0	reward = 0.724297	array([[  2.7759733, -47.590607 ]], dtype=float32)
time = 67435	action = 0	current_phase = 1	next_phase = 0	reward = 0.719951	array([[  2.61337 , -47.000305]], dtype=float32)
time = 67440	action = 0	current_phase = 1	next_phase = 0	reward = 0.711592	array([[  2.685853, -47.15964 ]], dtype=float32)
time = 67445	action = 0	current_phase = 1	next_phase = 0	reward = 0.440577	array([[  2.7085352, -47.23413  ]], dtype=float32)
time = 67450	action = 0	current_phase = 1	next_phase = 0	reward = 1.003095	array([[  2.7074118, -47.209534 ]], dtype=float32)
time = 67455	action = 0	current_phase = 1	next_phase = 0	reward = 0.715325	array([[  2.7404032, -47.4019   ]], dtype=float32)
time = 67460	action = 0	current_phase = 1	next_phase = 0	reward = 0.712749	array([[  2.7131891, -47.24539  ]], dtype=float32)
time = 67465	action = 0	current_phase = 1	next_phase = 0	reward = 0.720387	array([[  2.72956 , -47.270187]], dtype=float32)
time = 67470	action = 0	current_phase = 1	next_phase = 0	reward = 0.717522	array([[  2.7555132, -47.381325 ]], dtype=float32)
time = 67475	action = 0	current_phase = 1	next_phase = 0	reward = 0.437567	array([[  2.6692305, -47.219887 ]], dtype=float32)
time = 67480	action = 0	current_phase = 1	next_phase = 0	reward = 1.008299	array([[  2.6750174, -47.19685  ]], dtype=float32)
time = 67485	action = 0	current_phase = 1	next_phase = 0	reward = 0.453775	array([[  2.7554197, -47.496628 ]], dtype=float32)
time = 67490	action = 0	current_phase = 1	next_phase = 0	reward = 0.732692	array([[  2.7481642, -47.380363 ]], dtype=float32)
time = 67495	action = 0	current_phase = 1	next_phase = 0	reward = 1.012578	array([[  2.6540918, -47.052578 ]], dtype=float32)
time = 67500	action = 0	current_phase = 1	next_phase = 0	reward = 0.714267	array([[  2.7778273, -47.6541   ]], dtype=float32)
time = 67505	action = 0	current_phase = 1	next_phase = 0	reward = 0.717868	array([[  2.5969381, -46.937103 ]], dtype=float32)
time = 67510	action = 0	current_phase = 1	next_phase = 0	reward = 0.719675	array([[  2.7823458, -47.50651  ]], dtype=float32)
time = 67515	action = 0	current_phase = 1	next_phase = 0	reward = 0.725056	array([[  2.7554903, -47.434914 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2119.7598 - val_loss: 570.6236
Epoch 2/50
 - 4s - loss: 2151.8049 - val_loss: 507.9941
Epoch 3/50
 - 4s - loss: 2169.4329 - val_loss: 662.2036
Epoch 4/50
 - 4s - loss: 2131.6994 - val_loss: 522.0208
Epoch 5/50
 - 4s - loss: 2164.6042 - val_loss: 565.6793
Epoch 6/50
 - 4s - loss: 2157.6472 - val_loss: 539.5179
Epoch 7/50
 - 4s - loss: 2150.2026 - val_loss: 562.3660
Epoch 8/50
 - 4s - loss: 2156.4122 - val_loss: 543.4518
Epoch 9/50
 - 4s - loss: 2124.2654 - val_loss: 483.9513
Epoch 10/50
 - 4s - loss: 2117.3543 - val_loss: 499.9229
Epoch 11/50
 - 4s - loss: 2140.9747 - val_loss: 346.2106
Epoch 12/50
 - 4s - loss: 2101.5905 - val_loss: 317.0917
Epoch 13/50
 - 4s - loss: 2071.1096 - val_loss: 298.5269
Epoch 14/50
 - 4s - loss: 2076.5452 - val_loss: 420.1248
Epoch 15/50
 - 4s - loss: 2065.0652 - val_loss: 446.3691
Epoch 16/50
 - 4s - loss: 2065.0911 - val_loss: 286.1134
Epoch 17/50
 - 4s - loss: 2070.6385 - val_loss: 378.5952
Epoch 18/50
 - 4s - loss: 2111.3466 - val_loss: 324.4727
Epoch 19/50
 - 4s - loss: 2072.6106 - val_loss: 329.0144
Epoch 20/50
 - 4s - loss: 2065.0364 - val_loss: 311.4994
Epoch 21/50
 - 4s - loss: 2057.8049 - val_loss: 287.6036
Epoch 22/50
 - 4s - loss: 2051.5398 - val_loss: 292.7288
Epoch 23/50
 - 4s - loss: 2064.5232 - val_loss: 300.5690
Epoch 24/50
 - 4s - loss: 2057.5518 - val_loss: 308.7689
Epoch 25/50
 - 4s - loss: 2066.1058 - val_loss: 322.6925
Epoch 26/50
 - 4s - loss: 2053.8422 - val_loss: 404.7035
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 67520	action = 0	current_phase = 1	next_phase = 0	reward = 0.740521	array([[  2.750781, -47.40781 ]], dtype=float32)
time = 67525	action = 0	current_phase = 1	next_phase = 0	reward = 0.722259	array([[  2.7952147, -47.286636 ]], dtype=float32)
time = 67530	action = 0	current_phase = 1	next_phase = 0	reward = 0.717430	array([[  2.8418913, -47.323917 ]], dtype=float32)
time = 67535	action = 0	current_phase = 1	next_phase = 0	reward = 0.719322	array([[  2.8224783, -47.5074   ]], dtype=float32)
time = 67540	action = 0	current_phase = 1	next_phase = 0	reward = 0.726966	array([[  2.8394022, -47.303085 ]], dtype=float32)
time = 67545	action = 0	current_phase = 1	next_phase = 0	reward = 0.715054	array([[  2.7891455, -47.151535 ]], dtype=float32)
time = 67550	action = 0	current_phase = 1	next_phase = 0	reward = 0.431112	array([[  2.8339205, -47.46082  ]], dtype=float32)
time = 67555	action = 0	current_phase = 1	next_phase = 0	reward = 0.997463	array([[  2.7863684, -47.1537   ]], dtype=float32)
time = 67560	action = 0	current_phase = 1	next_phase = 0	reward = 0.717393	array([[  2.7798338, -47.45538  ]], dtype=float32)
time = 67565	action = 0	current_phase = 1	next_phase = 0	reward = 0.455098	array([[  2.8265734, -47.519794 ]], dtype=float32)
time = 67570	action = 0	current_phase = 1	next_phase = 0	reward = 1.003953	array([[  2.8422117, -47.439613 ]], dtype=float32)
time = 67575	action = 0	current_phase = 1	next_phase = 0	reward = 0.721649	array([[  2.8257895, -47.24191  ]], dtype=float32)
time = 67580	action = 0	current_phase = 1	next_phase = 0	reward = 0.726890	array([[  2.834319, -47.514168]], dtype=float32)
time = 67585	action = 0	current_phase = 1	next_phase = 0	reward = 0.719802	array([[  2.7379103, -47.156555 ]], dtype=float32)
time = 67590	action = 0	current_phase = 1	next_phase = 0	reward = 0.721984	array([[  2.7529268, -47.13061  ]], dtype=float32)
time = 67595	action = 0	current_phase = 1	next_phase = 0	reward = 0.720276	array([[  2.835103, -47.392895]], dtype=float32)
time = 67600	action = 0	current_phase = 1	next_phase = 0	reward = 0.734013	array([[  2.798091, -47.274082]], dtype=float32)
time = 67605	action = 0	current_phase = 1	next_phase = 0	reward = 0.728608	array([[  2.7296457, -47.53367  ]], dtype=float32)
time = 67610	action = 0	current_phase = 1	next_phase = 0	reward = 0.728308	array([[  2.757369, -47.683655]], dtype=float32)
time = 67615	action = 0	current_phase = 1	next_phase = 0	reward = 0.725427	array([[  2.839076, -47.46929 ]], dtype=float32)
time = 67620	action = 0	current_phase = 1	next_phase = 0	reward = 0.716540	array([[  2.8266878, -47.248344 ]], dtype=float32)
time = 67625	action = 0	current_phase = 1	next_phase = 0	reward = 0.718578	array([[  2.7942286, -47.177254 ]], dtype=float32)
time = 67630	action = 0	current_phase = 1	next_phase = 0	reward = 0.722759	array([[  2.842122, -47.489708]], dtype=float32)
time = 67635	action = 0	current_phase = 1	next_phase = 0	reward = 0.717894	array([[  2.8142614, -47.310806 ]], dtype=float32)
time = 67640	action = 0	current_phase = 1	next_phase = 0	reward = 0.722574	array([[  2.8049345, -47.31309  ]], dtype=float32)
time = 67645	action = 0	current_phase = 1	next_phase = 0	reward = 0.717317	array([[  2.8042898, -47.26481  ]], dtype=float32)
time = 67650	action = 0	current_phase = 1	next_phase = 0	reward = 0.441521	array([[  2.6924963, -47.486187 ]], dtype=float32)
time = 67655	action = 0	current_phase = 1	next_phase = 0	reward = 1.002873	array([[  2.728963, -47.058357]], dtype=float32)
time = 67660	action = 0	current_phase = 1	next_phase = 0	reward = 0.718209	array([[  2.8223715, -47.458305 ]], dtype=float32)
time = 67665	action = 0	current_phase = 1	next_phase = 0	reward = 0.722794	array([[  2.796523, -47.13587 ]], dtype=float32)
time = 67670	action = 0	current_phase = 1	next_phase = 0	reward = 0.717489	array([[  2.8431559, -47.350685 ]], dtype=float32)
time = 67675	action = 0	current_phase = 1	next_phase = 0	reward = 0.724294	array([[  2.849267, -47.32399 ]], dtype=float32)
time = 67680	action = 0	current_phase = 1	next_phase = 0	reward = 0.441456	array([[  2.737216, -47.56347 ]], dtype=float32)
time = 67685	action = 0	current_phase = 1	next_phase = 0	reward = 0.994734	array([[  2.8105612, -47.228592 ]], dtype=float32)
time = 67690	action = 0	current_phase = 1	next_phase = 0	reward = 0.718291	array([[  2.8236933, -47.44983  ]], dtype=float32)
time = 67695	action = 0	current_phase = 1	next_phase = 0	reward = 0.437236	array([[  2.7796087, -47.53505  ]], dtype=float32)
time = 67700	action = 0	current_phase = 1	next_phase = 0	reward = 0.998896	array([[  2.7621393, -47.33142  ]], dtype=float32)
time = 67705	action = 0	current_phase = 1	next_phase = 0	reward = 0.716615	array([[  2.835393, -47.39009 ]], dtype=float32)
time = 67710	action = 0	current_phase = 1	next_phase = 0	reward = 0.448627	array([[  2.7017527, -47.66175  ]], dtype=float32)
time = 67715	action = 0	current_phase = 1	next_phase = 0	reward = 1.009705	array([[  2.8411531, -47.363525 ]], dtype=float32)
time = 67720	action = 0	current_phase = 1	next_phase = 0	reward = 0.720012	array([[  2.8306074, -47.291397 ]], dtype=float32)
time = 67725	action = 0	current_phase = 1	next_phase = 0	reward = 0.717011	array([[  2.8085508, -47.467113 ]], dtype=float32)
time = 67730	action = 0	current_phase = 1	next_phase = 0	reward = 0.716925	array([[  2.8093214, -47.321987 ]], dtype=float32)
time = 67735	action = 0	current_phase = 1	next_phase = 0	reward = 0.449267	array([[  2.7073164, -47.20547  ]], dtype=float32)
time = 67740	action = 0	current_phase = 1	next_phase = 0	reward = 1.005829	array([[  2.792304, -47.147682]], dtype=float32)
time = 67745	action = 0	current_phase = 1	next_phase = 0	reward = 0.720504	array([[  2.778552, -47.378494]], dtype=float32)
time = 67750	action = 0	current_phase = 1	next_phase = 0	reward = 0.718367	array([[  2.8011732, -47.39441  ]], dtype=float32)
time = 67755	action = 0	current_phase = 1	next_phase = 0	reward = 0.719578	array([[  2.8438826, -47.373474 ]], dtype=float32)
time = 67760	action = 0	current_phase = 1	next_phase = 0	reward = 0.719283	array([[  2.8175707, -47.230446 ]], dtype=float32)
time = 67765	action = 0	current_phase = 1	next_phase = 0	reward = 0.719552	array([[  2.8196096, -47.35929  ]], dtype=float32)
time = 67770	action = 0	current_phase = 1	next_phase = 0	reward = 0.723043	array([[  2.8300123, -47.413673 ]], dtype=float32)
time = 67775	action = 0	current_phase = 1	next_phase = 0	reward = 0.724917	array([[  2.7890596, -47.114307 ]], dtype=float32)
time = 67780	action = 0	current_phase = 1	next_phase = 0	reward = 0.719509	array([[  2.7685003, -47.50219  ]], dtype=float32)
time = 67785	action = 0	current_phase = 1	next_phase = 0	reward = 0.439659	array([[  2.638688, -47.017372]], dtype=float32)
time = 67790	action = 0	current_phase = 1	next_phase = 0	reward = 1.003676	array([[  2.834897, -47.347282]], dtype=float32)
time = 67795	action = 0	current_phase = 1	next_phase = 0	reward = 0.722062	array([[  2.7913523, -47.166626 ]], dtype=float32)
time = 67800	action = 0	current_phase = 1	next_phase = 0	reward = 0.447926	array([[  2.7452707, -47.447098 ]], dtype=float32)
time = 67805	action = 0	current_phase = 1	next_phase = 0	reward = 0.731420	array([[  2.8288908, -47.497566 ]], dtype=float32)
time = 67810	action = 0	current_phase = 1	next_phase = 0	reward = 0.996788	array([[  2.8234758, -47.45068  ]], dtype=float32)
time = 67815	action = 0	current_phase = 1	next_phase = 0	reward = 0.713083	array([[  2.8176203, -47.240463 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 310.3316 - val_loss: 4529.2862
Epoch 2/50
 - 4s - loss: 309.4787 - val_loss: 4537.1642
Epoch 3/50
 - 4s - loss: 316.7546 - val_loss: 4513.0416
Epoch 4/50
 - 4s - loss: 299.9926 - val_loss: 4546.1898
Epoch 5/50
 - 4s - loss: 300.8912 - val_loss: 4518.6229
Epoch 6/50
 - 4s - loss: 297.9314 - val_loss: 4563.1331
Epoch 7/50
 - 4s - loss: 307.8935 - val_loss: 4573.0916
Epoch 8/50
 - 4s - loss: 302.4827 - val_loss: 4579.2322
Epoch 9/50
 - 4s - loss: 323.6043 - val_loss: 4535.0776
Epoch 10/50
 - 4s - loss: 288.6384 - val_loss: 4583.2636
Epoch 11/50
 - 4s - loss: 307.5891 - val_loss: 4597.7177
Epoch 12/50
 - 4s - loss: 308.9366 - val_loss: 4560.7718
Epoch 13/50
 - 4s - loss: 294.1954 - val_loss: 4528.2131
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 67820	action = 0	current_phase = 1	next_phase = 0	reward = 0.718181	array([[  2.9028835, -47.642315 ]], dtype=float32)
time = 67825	action = 0	current_phase = 1	next_phase = 0	reward = 0.712097	array([[  2.8680153, -47.22399  ]], dtype=float32)
time = 67830	action = 0	current_phase = 1	next_phase = 0	reward = 0.722166	array([[  2.8647785, -47.456795 ]], dtype=float32)
time = 67835	action = 0	current_phase = 1	next_phase = 0	reward = 0.453846	array([[  2.9180202, -47.52639  ]], dtype=float32)
time = 67840	action = 0	current_phase = 1	next_phase = 0	reward = 1.005457	array([[  2.8836346, -47.325966 ]], dtype=float32)
time = 67845	action = 0	current_phase = 1	next_phase = 0	reward = 0.711205	array([[  2.8746395, -47.725647 ]], dtype=float32)
time = 67850	action = 0	current_phase = 1	next_phase = 0	reward = 0.714480	array([[  2.8534756, -47.532646 ]], dtype=float32)
time = 67855	action = 0	current_phase = 1	next_phase = 0	reward = 0.435516	array([[  2.899969, -47.342827]], dtype=float32)
time = 67860	action = 0	current_phase = 1	next_phase = 0	reward = 0.997366	array([[  2.8537521, -47.59913  ]], dtype=float32)
time = 67865	action = 0	current_phase = 1	next_phase = 0	reward = 0.448606	array([[  2.9210014, -47.416138 ]], dtype=float32)
time = 67870	action = 0	current_phase = 1	next_phase = 0	reward = 1.001560	array([[  2.8674965, -47.201614 ]], dtype=float32)
time = 67875	action = 0	current_phase = 1	next_phase = 0	reward = 0.713829	array([[  2.909956, -47.51391 ]], dtype=float32)
time = 67880	action = 0	current_phase = 1	next_phase = 0	reward = 0.720512	array([[  2.816042, -47.214046]], dtype=float32)
time = 67885	action = 0	current_phase = 1	next_phase = 0	reward = 0.722583	array([[  2.8711758, -47.22517  ]], dtype=float32)
time = 67890	action = 0	current_phase = 1	next_phase = 0	reward = 0.718811	array([[  2.8002968, -47.222458 ]], dtype=float32)
time = 67895	action = 0	current_phase = 1	next_phase = 0	reward = 0.721328	array([[  2.8297005, -47.614365 ]], dtype=float32)
time = 67900	action = 0	current_phase = 1	next_phase = 0	reward = 0.723082	array([[  2.9037247, -47.66379  ]], dtype=float32)
time = 67905	action = 0	current_phase = 1	next_phase = 0	reward = 0.731473	array([[  2.933897, -47.499634]], dtype=float32)
time = 67910	action = 0	current_phase = 1	next_phase = 0	reward = 0.724328	array([[  2.8918476, -47.5979   ]], dtype=float32)
time = 67915	action = 0	current_phase = 1	next_phase = 0	reward = 0.723359	array([[  2.8609772, -47.422333 ]], dtype=float32)
time = 67920	action = 0	current_phase = 1	next_phase = 0	reward = 0.718847	array([[  2.8998394, -47.471397 ]], dtype=float32)
time = 67925	action = 0	current_phase = 1	next_phase = 0	reward = 0.719413	array([[  2.9290447, -47.58536  ]], dtype=float32)
time = 67930	action = 0	current_phase = 1	next_phase = 0	reward = 0.442119	array([[  2.9190865, -47.476196 ]], dtype=float32)
time = 67935	action = 0	current_phase = 1	next_phase = 0	reward = 0.995134	array([[  2.8838997, -47.61023  ]], dtype=float32)
time = 67940	action = 0	current_phase = 1	next_phase = 0	reward = 0.441216	array([[  2.9032593, -47.38347  ]], dtype=float32)
time = 67945	action = 0	current_phase = 1	next_phase = 0	reward = 0.726671	array([[  2.903288, -47.492455]], dtype=float32)
time = 67950	action = 0	current_phase = 1	next_phase = 0	reward = 1.008607	array([[  2.8925743, -47.71831  ]], dtype=float32)
time = 67955	action = 0	current_phase = 1	next_phase = 0	reward = 0.445625	array([[  2.9080677, -47.673115 ]], dtype=float32)
time = 67960	action = 0	current_phase = 1	next_phase = 0	reward = 0.992829	array([[  2.9273453, -47.50955  ]], dtype=float32)
time = 67965	action = 0	current_phase = 1	next_phase = 0	reward = 0.728462	array([[  2.890915, -47.59988 ]], dtype=float32)
time = 67970	action = 0	current_phase = 1	next_phase = 0	reward = 0.446456	array([[  2.899376, -47.65272 ]], dtype=float32)
time = 67975	action = 0	current_phase = 1	next_phase = 0	reward = 1.007120	array([[  2.9206944, -47.62249  ]], dtype=float32)
time = 67980	action = 0	current_phase = 1	next_phase = 0	reward = 0.452754	array([[  2.8523655, -47.77999  ]], dtype=float32)
time = 67985	action = 0	current_phase = 1	next_phase = 0	reward = 1.003510	array([[  2.8686028, -47.516838 ]], dtype=float32)
time = 67990	action = 0	current_phase = 1	next_phase = 0	reward = 0.715854	array([[  2.9158707, -47.466274 ]], dtype=float32)
time = 67995	action = 0	current_phase = 1	next_phase = 0	reward = 0.440407	array([[  2.8429642, -47.13774  ]], dtype=float32)
time = 68000	action = 0	current_phase = 1	next_phase = 0	reward = 1.005524	array([[  2.8751469, -47.27932  ]], dtype=float32)
time = 68005	action = 0	current_phase = 1	next_phase = 0	reward = 0.732194	array([[  2.877348, -47.72783 ]], dtype=float32)
time = 68010	action = 0	current_phase = 1	next_phase = 0	reward = 0.730472	array([[  2.842783, -47.516438]], dtype=float32)
time = 68015	action = 0	current_phase = 1	next_phase = 0	reward = 0.705807	array([[  2.8602047, -47.189926 ]], dtype=float32)
time = 68020	action = 0	current_phase = 1	next_phase = 0	reward = 0.713176	array([[  2.790184, -47.43982 ]], dtype=float32)
time = 68025	action = 0	current_phase = 1	next_phase = 0	reward = 0.451245	array([[  2.8276615, -47.31431  ]], dtype=float32)
time = 68030	action = 0	current_phase = 1	next_phase = 0	reward = 1.008944	array([[  2.8409195, -47.11692  ]], dtype=float32)
time = 68035	action = 0	current_phase = 1	next_phase = 0	reward = 0.718951	array([[  2.8600502, -47.683975 ]], dtype=float32)
time = 68040	action = 0	current_phase = 1	next_phase = 0	reward = 0.705720	array([[  2.8449554, -47.133904 ]], dtype=float32)
time = 68045	action = 0	current_phase = 1	next_phase = 0	reward = 0.434987	array([[  2.846449, -47.743248]], dtype=float32)
time = 68050	action = 0	current_phase = 1	next_phase = 0	reward = 0.999945	array([[  2.869812, -47.55351 ]], dtype=float32)
time = 68055	action = 0	current_phase = 1	next_phase = 0	reward = 0.449953	array([[  2.8706856, -47.747307 ]], dtype=float32)
time = 68060	action = 0	current_phase = 1	next_phase = 0	reward = 1.004555	array([[  2.9220428, -47.44869  ]], dtype=float32)
time = 68065	action = 0	current_phase = 1	next_phase = 0	reward = 0.722210	array([[  2.8716354, -47.357292 ]], dtype=float32)
time = 68070	action = 0	current_phase = 1	next_phase = 0	reward = 0.438713	array([[  2.877283, -47.543472]], dtype=float32)
time = 68075	action = 0	current_phase = 1	next_phase = 0	reward = 1.003943	array([[  2.865408, -47.427734]], dtype=float32)
time = 68080	action = 0	current_phase = 1	next_phase = 0	reward = 0.720349	array([[  2.8926067, -47.351967 ]], dtype=float32)
time = 68085	action = 0	current_phase = 1	next_phase = 0	reward = 0.718594	array([[  2.8964596, -47.57566  ]], dtype=float32)
time = 68090	action = 0	current_phase = 1	next_phase = 0	reward = 0.707116	array([[  2.8704967, -47.271114 ]], dtype=float32)
time = 68095	action = 0	current_phase = 1	next_phase = 0	reward = 0.440856	array([[  2.8589668, -47.288292 ]], dtype=float32)
time = 68100	action = 0	current_phase = 1	next_phase = 0	reward = 0.726822	array([[  2.8748817, -47.39512  ]], dtype=float32)
time = 68105	action = 0	current_phase = 1	next_phase = 0	reward = 1.002341	array([[  2.885231, -47.27214 ]], dtype=float32)
time = 68110	action = 0	current_phase = 1	next_phase = 0	reward = 0.717709	array([[  2.890993, -47.738045]], dtype=float32)
time = 68115	action = 0	current_phase = 1	next_phase = 0	reward = 0.724666	array([[  2.8984203, -47.34188  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2048.7777 - val_loss: 175.7169
Epoch 2/50
 - 4s - loss: 2087.0797 - val_loss: 94.5003
Epoch 3/50
 - 4s - loss: 2053.8959 - val_loss: 132.2736
Epoch 4/50
 - 4s - loss: 2071.7570 - val_loss: 124.5681
Epoch 5/50
 - 4s - loss: 2084.3313 - val_loss: 107.0366
Epoch 6/50
 - 4s - loss: 2059.8365 - val_loss: 124.9109
Epoch 7/50
 - 4s - loss: 2066.6560 - val_loss: 123.9462
Epoch 8/50
 - 4s - loss: 2062.4426 - val_loss: 96.2822
Epoch 9/50
 - 4s - loss: 2063.4853 - val_loss: 228.9411
Epoch 10/50
 - 4s - loss: 2111.5231 - val_loss: 128.4453
Epoch 11/50
 - 4s - loss: 2085.0855 - val_loss: 213.4933
Epoch 12/50
 - 4s - loss: 2049.9619 - val_loss: 101.8642
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 68120	action = 0	current_phase = 1	next_phase = 0	reward = 0.713212	array([[  2.7368832, -47.65294  ]], dtype=float32)
time = 68125	action = 0	current_phase = 1	next_phase = 0	reward = 0.725363	array([[  2.796877, -47.50358 ]], dtype=float32)
time = 68130	action = 0	current_phase = 1	next_phase = 0	reward = 0.445897	array([[  2.7508125, -47.204727 ]], dtype=float32)
time = 68135	action = 0	current_phase = 1	next_phase = 0	reward = 1.007542	array([[  2.7912788, -47.4562   ]], dtype=float32)
time = 68140	action = 0	current_phase = 1	next_phase = 0	reward = 0.723559	array([[  2.733427, -47.1027  ]], dtype=float32)
time = 68145	action = 0	current_phase = 1	next_phase = 0	reward = 0.718551	array([[  2.793291, -47.353447]], dtype=float32)
time = 68150	action = 0	current_phase = 1	next_phase = 0	reward = 0.433036	array([[  2.7881126, -47.264446 ]], dtype=float32)
time = 68155	action = 0	current_phase = 1	next_phase = 0	reward = 0.724866	array([[  2.7911034, -47.475647 ]], dtype=float32)
time = 68160	action = 0	current_phase = 1	next_phase = 0	reward = 1.005618	array([[  2.7713604, -47.2677   ]], dtype=float32)
time = 68165	action = 0	current_phase = 1	next_phase = 0	reward = 0.437147	array([[  2.7684383, -47.495575 ]], dtype=float32)
time = 68170	action = 0	current_phase = 1	next_phase = 0	reward = 1.003643	array([[  2.7743359, -47.20321  ]], dtype=float32)
time = 68175	action = 0	current_phase = 1	next_phase = 0	reward = 0.718103	array([[  2.6901093, -47.236748 ]], dtype=float32)
time = 68180	action = 0	current_phase = 1	next_phase = 0	reward = 0.723013	array([[  2.7150326, -47.00461  ]], dtype=float32)
time = 68185	action = 0	current_phase = 1	next_phase = 0	reward = 0.725171	array([[  2.7420254, -47.176712 ]], dtype=float32)
time = 68190	action = 0	current_phase = 1	next_phase = 0	reward = 0.722417	array([[  2.7641392, -47.200615 ]], dtype=float32)
time = 68195	action = 0	current_phase = 1	next_phase = 0	reward = 0.724040	array([[  2.7459927, -47.56673  ]], dtype=float32)
time = 68200	action = 0	current_phase = 1	next_phase = 0	reward = 0.725115	array([[  2.7911835, -47.38302  ]], dtype=float32)
time = 68205	action = 0	current_phase = 1	next_phase = 0	reward = 0.721357	array([[  2.791092, -47.40885 ]], dtype=float32)
time = 68210	action = 0	current_phase = 1	next_phase = 0	reward = 0.712855	array([[  2.7800999, -47.536682 ]], dtype=float32)
time = 68215	action = 0	current_phase = 1	next_phase = 0	reward = 0.717975	array([[  2.773882, -47.501472]], dtype=float32)
time = 68220	action = 0	current_phase = 1	next_phase = 0	reward = 0.718079	array([[  2.7213593, -47.66273  ]], dtype=float32)
time = 68225	action = 0	current_phase = 1	next_phase = 0	reward = 0.720638	array([[  2.7844944, -47.273926 ]], dtype=float32)
time = 68230	action = 0	current_phase = 1	next_phase = 0	reward = 0.728949	array([[  2.7861214, -47.34545  ]], dtype=float32)
time = 68235	action = 0	current_phase = 1	next_phase = 0	reward = 0.732797	array([[  2.782364, -47.491547]], dtype=float32)
time = 68240	action = 0	current_phase = 1	next_phase = 0	reward = 0.722639	array([[  2.7817917, -47.388435 ]], dtype=float32)
time = 68245	action = 0	current_phase = 1	next_phase = 0	reward = 0.440521	array([[  2.750431, -47.15145 ]], dtype=float32)
time = 68250	action = 0	current_phase = 1	next_phase = 0	reward = 0.997610	array([[  2.6709824, -46.882957 ]], dtype=float32)
time = 68255	action = 0	current_phase = 1	next_phase = 0	reward = 0.714834	array([[  2.7672672, -47.29426  ]], dtype=float32)
time = 68260	action = 0	current_phase = 1	next_phase = 0	reward = 0.714878	array([[  2.7834187, -47.286118 ]], dtype=float32)
time = 68265	action = 0	current_phase = 1	next_phase = 0	reward = 0.714711	array([[  2.7837563, -47.26572  ]], dtype=float32)
time = 68270	action = 0	current_phase = 1	next_phase = 0	reward = 0.436583	array([[  2.7567596, -47.526    ]], dtype=float32)
time = 68275	action = 0	current_phase = 1	next_phase = 0	reward = 1.002259	array([[  2.7498093, -47.558502 ]], dtype=float32)
time = 68280	action = 0	current_phase = 1	next_phase = 0	reward = 0.453782	array([[  2.789074, -47.42141 ]], dtype=float32)
time = 68285	action = 0	current_phase = 1	next_phase = 0	reward = 1.001326	array([[  2.7685566, -47.54064  ]], dtype=float32)
time = 68290	action = 0	current_phase = 1	next_phase = 0	reward = 0.719645	array([[  2.783743, -47.428436]], dtype=float32)
time = 68295	action = 0	current_phase = 1	next_phase = 0	reward = 0.718372	array([[  2.783146, -47.325233]], dtype=float32)
time = 68300	action = 0	current_phase = 1	next_phase = 0	reward = 0.717902	array([[  2.7976437, -47.35012  ]], dtype=float32)
time = 68305	action = 0	current_phase = 1	next_phase = 0	reward = 0.718540	array([[  2.7790108, -47.447323 ]], dtype=float32)
time = 68310	action = 0	current_phase = 1	next_phase = 0	reward = 0.434384	array([[  2.7830372, -47.278877 ]], dtype=float32)
time = 68315	action = 0	current_phase = 1	next_phase = 0	reward = 1.017168	array([[  2.7568512, -47.158604 ]], dtype=float32)
time = 68320	action = 0	current_phase = 1	next_phase = 0	reward = 0.712291	array([[  2.7839413, -47.416824 ]], dtype=float32)
time = 68325	action = 0	current_phase = 1	next_phase = 0	reward = 0.711601	array([[  2.7912006, -47.329987 ]], dtype=float32)
time = 68330	action = 0	current_phase = 1	next_phase = 0	reward = 0.711730	array([[  2.7645645, -47.172325 ]], dtype=float32)
time = 68335	action = 0	current_phase = 1	next_phase = 0	reward = 0.440494	array([[  2.771658, -47.257713]], dtype=float32)
time = 68340	action = 0	current_phase = 1	next_phase = 0	reward = 0.719773	array([[  2.7595692, -47.599983 ]], dtype=float32)
time = 68345	action = 0	current_phase = 1	next_phase = 0	reward = 1.005253	array([[  2.7808437, -47.469162 ]], dtype=float32)
time = 68350	action = 0	current_phase = 1	next_phase = 0	reward = 0.443127	array([[  2.779827, -47.53431 ]], dtype=float32)
time = 68355	action = 0	current_phase = 1	next_phase = 0	reward = 0.993432	array([[  2.7026386, -46.97078  ]], dtype=float32)
time = 68360	action = 0	current_phase = 1	next_phase = 0	reward = 0.721282	array([[  2.7812767, -47.280197 ]], dtype=float32)
time = 68365	action = 0	current_phase = 1	next_phase = 0	reward = 0.715474	array([[  2.798111, -47.34233 ]], dtype=float32)
time = 68370	action = 0	current_phase = 1	next_phase = 0	reward = 0.442524	array([[  2.7803783, -47.372986 ]], dtype=float32)
time = 68375	action = 0	current_phase = 1	next_phase = 0	reward = 1.003227	array([[  2.7742348, -47.47046  ]], dtype=float32)
time = 68380	action = 0	current_phase = 1	next_phase = 0	reward = 0.721805	array([[  2.786852, -47.30027 ]], dtype=float32)
time = 68385	action = 0	current_phase = 1	next_phase = 0	reward = 0.728125	array([[  2.7466297, -47.195145 ]], dtype=float32)
time = 68390	action = 0	current_phase = 1	next_phase = 0	reward = 0.720120	array([[  2.7267475, -47.12786  ]], dtype=float32)
time = 68395	action = 0	current_phase = 1	next_phase = 0	reward = 0.709700	array([[  2.7429085, -47.655647 ]], dtype=float32)
time = 68400	action = 0	current_phase = 1	next_phase = 0	reward = 0.441187	array([[  2.7864456, -47.3414   ]], dtype=float32)
time = 68405	action = 0	current_phase = 1	next_phase = 0	reward = 1.004484	array([[  2.7724133, -47.196625 ]], dtype=float32)
time = 68410	action = 0	current_phase = 1	next_phase = 0	reward = 0.721557	array([[  2.7638168, -47.180336 ]], dtype=float32)
time = 68415	action = 0	current_phase = 1	next_phase = 0	reward = 0.706528	array([[  2.7260914, -47.49983  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2035.5798 - val_loss: 246.6545
Epoch 2/50
 - 4s - loss: 2040.4976 - val_loss: 341.1223
Epoch 3/50
 - 4s - loss: 2055.4829 - val_loss: 255.8997
Epoch 4/50
 - 4s - loss: 2056.1188 - val_loss: 368.4260
Epoch 5/50
 - 4s - loss: 2087.1800 - val_loss: 369.9593
Epoch 6/50
 - 4s - loss: 2096.4124 - val_loss: 347.3504
Epoch 7/50
 - 4s - loss: 2049.2358 - val_loss: 341.2833
Epoch 8/50
 - 4s - loss: 2043.2952 - val_loss: 292.4103
Epoch 9/50
 - 4s - loss: 2042.1502 - val_loss: 292.7100
Epoch 10/50
 - 4s - loss: 2045.8594 - val_loss: 284.7450
Epoch 11/50
 - 4s - loss: 2049.5949 - val_loss: 348.2948
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 68420	action = 0	current_phase = 1	next_phase = 0	reward = 0.714248	array([[  2.7058487, -47.28624  ]], dtype=float32)
time = 68425	action = 0	current_phase = 1	next_phase = 0	reward = 0.429193	array([[  2.6983452, -47.2613   ]], dtype=float32)
time = 68430	action = 0	current_phase = 1	next_phase = 0	reward = 1.006621	array([[  2.7157211, -47.32293  ]], dtype=float32)
time = 68435	action = 0	current_phase = 1	next_phase = 0	reward = 0.445152	array([[  2.6605034, -47.45571  ]], dtype=float32)
time = 68440	action = 0	current_phase = 1	next_phase = 0	reward = 1.002719	array([[  2.677084, -47.30957 ]], dtype=float32)
time = 68445	action = 0	current_phase = 1	next_phase = 0	reward = 0.444147	array([[  2.6981068, -47.17329  ]], dtype=float32)
time = 68450	action = 0	current_phase = 1	next_phase = 0	reward = 1.004987	array([[  2.5917969, -47.55668  ]], dtype=float32)
time = 68455	action = 0	current_phase = 1	next_phase = 0	reward = 0.720447	array([[  2.6905727, -47.40256  ]], dtype=float32)
time = 68460	action = 0	current_phase = 1	next_phase = 0	reward = 0.719922	array([[  2.675228, -47.38595 ]], dtype=float32)
time = 68465	action = 0	current_phase = 1	next_phase = 0	reward = 0.717800	array([[  2.679449, -47.054634]], dtype=float32)
time = 68470	action = 0	current_phase = 1	next_phase = 0	reward = 0.718837	array([[  2.6881676, -47.432426 ]], dtype=float32)
time = 68475	action = 0	current_phase = 1	next_phase = 0	reward = 0.722555	array([[  2.7102222, -47.312515 ]], dtype=float32)
time = 68480	action = 0	current_phase = 1	next_phase = 0	reward = 0.722574	array([[  2.680828, -47.24337 ]], dtype=float32)
time = 68485	action = 0	current_phase = 1	next_phase = 0	reward = 0.722089	array([[  2.6406155, -47.518913 ]], dtype=float32)
time = 68490	action = 0	current_phase = 1	next_phase = 0	reward = 0.700275	array([[  2.6757717, -47.24903  ]], dtype=float32)
time = 68495	action = 0	current_phase = 1	next_phase = 0	reward = 0.719135	array([[  2.6615334, -47.50363  ]], dtype=float32)
time = 68500	action = 0	current_phase = 1	next_phase = 0	reward = 0.449728	array([[  2.6826801, -47.109818 ]], dtype=float32)
time = 68505	action = 0	current_phase = 1	next_phase = 0	reward = 1.004249	array([[  2.6465645, -47.250347 ]], dtype=float32)
time = 68510	action = 0	current_phase = 1	next_phase = 0	reward = 0.720555	array([[  2.6161423, -47.53606  ]], dtype=float32)
time = 68515	action = 0	current_phase = 1	next_phase = 0	reward = 0.722641	array([[  2.6906796, -47.319145 ]], dtype=float32)
time = 68520	action = 0	current_phase = 1	next_phase = 0	reward = 0.723253	array([[  2.6926918, -47.28859  ]], dtype=float32)
time = 68525	action = 0	current_phase = 1	next_phase = 0	reward = 0.721484	array([[  2.585455, -47.588078]], dtype=float32)
time = 68530	action = 0	current_phase = 1	next_phase = 0	reward = 0.720380	array([[  2.6546936, -47.033318 ]], dtype=float32)
time = 68535	action = 0	current_phase = 1	next_phase = 0	reward = 0.719232	array([[  2.6793556, -47.450874 ]], dtype=float32)
time = 68540	action = 0	current_phase = 1	next_phase = 0	reward = 0.718573	array([[  2.6959724, -47.258812 ]], dtype=float32)
time = 68545	action = 0	current_phase = 1	next_phase = 0	reward = 0.716048	array([[  2.6959496, -47.292156 ]], dtype=float32)
time = 68550	action = 0	current_phase = 1	next_phase = 0	reward = 0.721158	array([[  2.6741714, -47.29554  ]], dtype=float32)
time = 68555	action = 0	current_phase = 1	next_phase = 0	reward = 0.439172	array([[  2.681427, -47.06124 ]], dtype=float32)
time = 68560	action = 0	current_phase = 1	next_phase = 0	reward = 1.005412	array([[  2.6759663, -47.458496 ]], dtype=float32)
time = 68565	action = 0	current_phase = 1	next_phase = 0	reward = 0.723573	array([[  2.6950207, -47.211395 ]], dtype=float32)
time = 68570	action = 0	current_phase = 1	next_phase = 0	reward = 0.725275	array([[  2.66222, -47.46578]], dtype=float32)
time = 68575	action = 0	current_phase = 1	next_phase = 0	reward = 0.715626	array([[  2.6890259, -47.171833 ]], dtype=float32)
time = 68580	action = 0	current_phase = 1	next_phase = 0	reward = 0.719734	array([[  2.6895962, -47.36883  ]], dtype=float32)
time = 68585	action = 0	current_phase = 1	next_phase = 0	reward = 0.719754	array([[  2.6917572, -47.39275  ]], dtype=float32)
time = 68590	action = 0	current_phase = 1	next_phase = 0	reward = 0.444284	array([[  2.686016, -47.271057]], dtype=float32)
time = 68595	action = 0	current_phase = 1	next_phase = 0	reward = 1.002627	array([[  2.7000446, -47.304283 ]], dtype=float32)
time = 68600	action = 0	current_phase = 1	next_phase = 0	reward = 0.723601	array([[  2.6915836, -47.40696  ]], dtype=float32)
time = 68605	action = 0	current_phase = 1	next_phase = 0	reward = 0.717202	array([[  2.7031994, -47.216995 ]], dtype=float32)
time = 68610	action = 0	current_phase = 1	next_phase = 0	reward = 0.440750	array([[  2.6839542, -47.30509  ]], dtype=float32)
time = 68615	action = 0	current_phase = 1	next_phase = 0	reward = 1.000300	array([[  2.7018871, -47.251656 ]], dtype=float32)
time = 68620	action = 0	current_phase = 1	next_phase = 0	reward = 0.714960	array([[  2.703392, -47.286674]], dtype=float32)
time = 68625	action = 0	current_phase = 1	next_phase = 0	reward = 0.712682	array([[  2.611786, -47.56024 ]], dtype=float32)
time = 68630	action = 0	current_phase = 1	next_phase = 0	reward = 0.437724	array([[  2.678299, -47.183777]], dtype=float32)
time = 68635	action = 0	current_phase = 1	next_phase = 0	reward = 1.000956	array([[  2.6997242, -47.190147 ]], dtype=float32)
time = 68640	action = 0	current_phase = 1	next_phase = 0	reward = 0.164904	array([[  2.6650925, -47.483986 ]], dtype=float32)
time = 68645	action = 0	current_phase = 1	next_phase = 0	reward = 1.007206	array([[  2.7005024, -47.32386  ]], dtype=float32)
time = 68650	action = 0	current_phase = 1	next_phase = 0	reward = 0.995917	array([[  2.6532269, -47.517673 ]], dtype=float32)
time = 68655	action = 0	current_phase = 1	next_phase = 0	reward = 0.717102	array([[  2.6376057, -47.036873 ]], dtype=float32)
time = 68660	action = 0	current_phase = 1	next_phase = 0	reward = 0.715674	array([[  2.6831722, -47.11954  ]], dtype=float32)
time = 68665	action = 0	current_phase = 1	next_phase = 0	reward = 0.442222	array([[  2.6656818, -47.003002 ]], dtype=float32)
time = 68670	action = 0	current_phase = 1	next_phase = 0	reward = 1.002439	array([[  2.6977482, -47.349846 ]], dtype=float32)
time = 68675	action = 0	current_phase = 1	next_phase = 0	reward = 0.438870	array([[  2.698677, -47.37463 ]], dtype=float32)
time = 68680	action = 0	current_phase = 1	next_phase = 0	reward = 0.999689	array([[  2.5970287, -47.310333 ]], dtype=float32)
time = 68685	action = 0	current_phase = 1	next_phase = 0	reward = 0.717427	array([[  2.6739311, -47.1571   ]], dtype=float32)
time = 68690	action = 0	current_phase = 1	next_phase = 0	reward = 0.720883	array([[  2.6910553, -47.28003  ]], dtype=float32)
time = 68695	action = 0	current_phase = 1	next_phase = 0	reward = 0.724462	array([[  2.680727, -47.408897]], dtype=float32)
time = 68700	action = 0	current_phase = 1	next_phase = 0	reward = 0.719507	array([[  2.6864185, -47.409992 ]], dtype=float32)
time = 68705	action = 0	current_phase = 1	next_phase = 0	reward = 0.445886	array([[  2.594862, -47.587036]], dtype=float32)
time = 68710	action = 0	current_phase = 1	next_phase = 0	reward = 1.003530	array([[  2.657856, -47.50109 ]], dtype=float32)
time = 68715	action = 0	current_phase = 1	next_phase = 0	reward = 0.438284	array([[  2.4638557, -47.227127 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2202.6985 - val_loss: 273.0136
Epoch 2/50
 - 4s - loss: 2174.4914 - val_loss: 311.0309
Epoch 3/50
 - 4s - loss: 2197.3853 - val_loss: 278.5353
Epoch 4/50
 - 4s - loss: 2150.5328 - val_loss: 304.6351
Epoch 5/50
 - 4s - loss: 2166.9939 - val_loss: 329.5991
Epoch 6/50
 - 4s - loss: 2157.8213 - val_loss: 306.1884
Epoch 7/50
 - 4s - loss: 2144.9081 - val_loss: 312.7321
Epoch 8/50
 - 4s - loss: 2159.9855 - val_loss: 312.8038
Epoch 9/50
 - 4s - loss: 2161.0959 - val_loss: 345.1263
Epoch 10/50
 - 4s - loss: 2141.9016 - val_loss: 309.6307
Epoch 11/50
 - 4s - loss: 2152.3698 - val_loss: 294.2810
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 68720	action = 0	current_phase = 1	next_phase = 0	reward = 0.999634	array([[  2.8614674, -47.642662 ]], dtype=float32)
time = 68725	action = 0	current_phase = 1	next_phase = 0	reward = 0.715912	array([[  2.881895, -47.6448  ]], dtype=float32)
time = 68730	action = 0	current_phase = 1	next_phase = 0	reward = 0.449737	array([[  2.832756, -47.78341 ]], dtype=float32)
time = 68735	action = 0	current_phase = 1	next_phase = 0	reward = 1.008620	array([[  2.885746, -47.442413]], dtype=float32)
time = 68740	action = 0	current_phase = 1	next_phase = 0	reward = 0.715009	array([[  2.7266655, -47.396515 ]], dtype=float32)
time = 68745	action = 0	current_phase = 1	next_phase = 0	reward = 0.725541	array([[  2.882412, -47.400623]], dtype=float32)
time = 68750	action = 0	current_phase = 1	next_phase = 0	reward = 0.717356	array([[  2.763794, -47.715378]], dtype=float32)
time = 68755	action = 0	current_phase = 1	next_phase = 0	reward = 0.716618	array([[  2.7811298, -47.835876 ]], dtype=float32)
time = 68760	action = 0	current_phase = 1	next_phase = 0	reward = 0.445619	array([[  2.8697624, -47.61535  ]], dtype=float32)
time = 68765	action = 0	current_phase = 1	next_phase = 0	reward = 1.006615	array([[  2.8693905, -47.671177 ]], dtype=float32)
time = 68770	action = 0	current_phase = 1	next_phase = 0	reward = 0.716872	array([[  2.7639961, -47.82502  ]], dtype=float32)
time = 68775	action = 0	current_phase = 1	next_phase = 0	reward = 0.440121	array([[  2.8828354, -47.636368 ]], dtype=float32)
time = 68780	action = 0	current_phase = 1	next_phase = 0	reward = 0.999749	array([[  2.7946548, -47.59629  ]], dtype=float32)
time = 68785	action = 0	current_phase = 1	next_phase = 0	reward = 0.717525	array([[  2.8319206, -47.77517  ]], dtype=float32)
time = 68790	action = 0	current_phase = 1	next_phase = 0	reward = 0.719808	array([[  2.8907146, -47.534332 ]], dtype=float32)
time = 68795	action = 0	current_phase = 1	next_phase = 0	reward = 0.724049	array([[  2.8890915, -47.42792  ]], dtype=float32)
time = 68800	action = 0	current_phase = 1	next_phase = 0	reward = 0.446553	array([[  2.8692036, -47.677364 ]], dtype=float32)
time = 68805	action = 0	current_phase = 1	next_phase = 0	reward = 1.008904	array([[  2.8818645, -47.648132 ]], dtype=float32)
time = 68810	action = 0	current_phase = 1	next_phase = 0	reward = 0.720934	array([[  2.8667603, -47.729492 ]], dtype=float32)
time = 68815	action = 0	current_phase = 1	next_phase = 0	reward = 0.713559	array([[  2.8543892, -47.683556 ]], dtype=float32)
time = 68820	action = 0	current_phase = 1	next_phase = 0	reward = 0.724643	array([[  2.873539, -47.55887 ]], dtype=float32)
time = 68825	action = 0	current_phase = 1	next_phase = 0	reward = 0.728159	array([[  2.8650723, -47.72579  ]], dtype=float32)
time = 68830	action = 0	current_phase = 1	next_phase = 0	reward = 0.717568	array([[  2.8583698, -47.611435 ]], dtype=float32)
time = 68835	action = 0	current_phase = 1	next_phase = 0	reward = 0.440212	array([[  2.8151283, -47.788464 ]], dtype=float32)
time = 68840	action = 0	current_phase = 1	next_phase = 0	reward = 1.002090	array([[  2.8776894, -47.635483 ]], dtype=float32)
time = 68845	action = 0	current_phase = 1	next_phase = 0	reward = 0.448675	array([[  2.7088394, -47.70548  ]], dtype=float32)
time = 68850	action = 0	current_phase = 1	next_phase = 0	reward = 1.007879	array([[  2.8813171, -47.400284 ]], dtype=float32)
time = 68855	action = 0	current_phase = 1	next_phase = 0	reward = 0.718862	array([[  2.8799133, -47.654503 ]], dtype=float32)
time = 68860	action = 0	current_phase = 1	next_phase = 0	reward = 0.444417	array([[  2.7717094, -47.798637 ]], dtype=float32)
time = 68865	action = 0	current_phase = 1	next_phase = 0	reward = 0.731231	array([[  2.8878632, -47.621746 ]], dtype=float32)
time = 68870	action = 0	current_phase = 1	next_phase = 0	reward = 1.008401	array([[  2.8352566, -47.769714 ]], dtype=float32)
time = 68875	action = 0	current_phase = 1	next_phase = 0	reward = 0.718176	array([[  2.6941948, -47.789803 ]], dtype=float32)
time = 68880	action = 0	current_phase = 1	next_phase = 0	reward = 0.723030	array([[  2.8343143, -47.763542 ]], dtype=float32)
time = 68885	action = 0	current_phase = 1	next_phase = 0	reward = 0.717529	array([[  2.8895512, -47.60885  ]], dtype=float32)
time = 68890	action = 0	current_phase = 1	next_phase = 0	reward = 0.720362	array([[  2.8851433, -47.56212  ]], dtype=float32)
time = 68895	action = 0	current_phase = 1	next_phase = 0	reward = 0.718332	array([[  2.8094463, -47.818127 ]], dtype=float32)
time = 68900	action = 0	current_phase = 1	next_phase = 0	reward = 0.444164	array([[  2.8954296, -47.558006 ]], dtype=float32)
time = 68905	action = 0	current_phase = 1	next_phase = 0	reward = 1.001308	array([[  2.8697739, -47.62231  ]], dtype=float32)
time = 68910	action = 0	current_phase = 1	next_phase = 0	reward = 0.430958	array([[  2.7179909, -47.881886 ]], dtype=float32)
time = 68915	action = 0	current_phase = 1	next_phase = 0	reward = 0.722149	array([[  2.884653, -47.41481 ]], dtype=float32)
time = 68920	action = 0	current_phase = 1	next_phase = 0	reward = 1.008057	array([[  2.8928642, -47.49884  ]], dtype=float32)
time = 68925	action = 0	current_phase = 1	next_phase = 0	reward = 0.438981	array([[  2.8873444, -47.580803 ]], dtype=float32)
time = 68930	action = 0	current_phase = 1	next_phase = 0	reward = 0.994633	array([[  2.6617508, -47.679474 ]], dtype=float32)
time = 68935	action = 0	current_phase = 1	next_phase = 0	reward = 0.438989	array([[  2.8898754, -47.459183 ]], dtype=float32)
time = 68940	action = 0	current_phase = 1	next_phase = 0	reward = 1.004162	array([[  2.8824253, -47.542683 ]], dtype=float32)
time = 68945	action = 0	current_phase = 1	next_phase = 0	reward = 0.442519	array([[  2.8101273, -47.777718 ]], dtype=float32)
time = 68950	action = 0	current_phase = 1	next_phase = 0	reward = 1.005097	array([[  2.7870483, -47.806396 ]], dtype=float32)
time = 68955	action = 0	current_phase = 1	next_phase = 0	reward = 0.712343	array([[  2.8720398, -47.660988 ]], dtype=float32)
time = 68960	action = 0	current_phase = 1	next_phase = 0	reward = 0.712276	array([[  2.8552513, -47.72691  ]], dtype=float32)
time = 68965	action = 0	current_phase = 1	next_phase = 0	reward = 0.726365	array([[  2.8723888, -47.697388 ]], dtype=float32)
time = 68970	action = 0	current_phase = 1	next_phase = 0	reward = 0.720892	array([[  2.8547878, -47.72624  ]], dtype=float32)
time = 68975	action = 0	current_phase = 1	next_phase = 0	reward = 0.722443	array([[  2.8244553, -47.63925  ]], dtype=float32)
time = 68980	action = 0	current_phase = 1	next_phase = 0	reward = 0.723062	array([[  2.8897247, -47.56469  ]], dtype=float32)
time = 68985	action = 0	current_phase = 1	next_phase = 0	reward = 0.711491	array([[  2.866331, -47.70195 ]], dtype=float32)
time = 68990	action = 0	current_phase = 1	next_phase = 0	reward = 0.441331	array([[  2.8483257, -47.6985   ]], dtype=float32)
time = 68995	action = 0	current_phase = 1	next_phase = 0	reward = 1.003109	array([[  2.8540573, -47.50757  ]], dtype=float32)
time = 69000	action = 0	current_phase = 1	next_phase = 0	reward = 0.713848	array([[  2.8473225, -47.70494  ]], dtype=float32)
time = 69005	action = 0	current_phase = 1	next_phase = 0	reward = 0.723263	array([[  2.8686733, -47.71202  ]], dtype=float32)
time = 69010	action = 0	current_phase = 1	next_phase = 0	reward = 0.726814	array([[  2.8203506, -47.491943 ]], dtype=float32)
time = 69015	action = 0	current_phase = 1	next_phase = 0	reward = 0.446267	array([[  2.8900547, -47.491028 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2070.7228 - val_loss: 166.2205
Epoch 2/50
 - 4s - loss: 2080.9522 - val_loss: 115.7915
Epoch 3/50
 - 4s - loss: 2077.5666 - val_loss: 212.0672
Epoch 4/50
 - 4s - loss: 2067.6453 - val_loss: 128.2332
Epoch 5/50
 - 4s - loss: 2085.0131 - val_loss: 106.8296
Epoch 6/50
 - 4s - loss: 2070.1952 - val_loss: 128.5067
Epoch 7/50
 - 4s - loss: 2072.6969 - val_loss: 178.0183
Epoch 8/50
 - 4s - loss: 2074.4698 - val_loss: 118.2295
Epoch 9/50
 - 4s - loss: 2061.7338 - val_loss: 127.7120
Epoch 10/50
 - 4s - loss: 2055.0912 - val_loss: 128.2350
Epoch 11/50
 - 4s - loss: 2078.6982 - val_loss: 172.6112
Epoch 12/50
 - 4s - loss: 2051.1182 - val_loss: 306.7763
Epoch 13/50
 - 4s - loss: 2076.1172 - val_loss: 165.9433
Epoch 14/50
 - 4s - loss: 2062.1801 - val_loss: 97.3077
Epoch 15/50
 - 4s - loss: 2062.0021 - val_loss: 156.6775
Epoch 16/50
 - 4s - loss: 2064.7167 - val_loss: 210.6889
Epoch 17/50
 - 4s - loss: 2047.0239 - val_loss: 161.8127
Epoch 18/50
 - 4s - loss: 2053.2907 - val_loss: 96.8565
Epoch 19/50
 - 4s - loss: 2053.2073 - val_loss: 109.6774
Epoch 20/50
 - 4s - loss: 2038.6494 - val_loss: 206.7497
Epoch 21/50
 - 4s - loss: 2045.0800 - val_loss: 144.2470
Epoch 22/50
 - 4s - loss: 2067.1533 - val_loss: 308.0563
Epoch 23/50
 - 4s - loss: 2056.1437 - val_loss: 103.8572
Epoch 24/50
 - 4s - loss: 2039.4681 - val_loss: 167.1192
Epoch 25/50
 - 4s - loss: 2058.6911 - val_loss: 90.4011
Epoch 26/50
 - 4s - loss: 2058.6470 - val_loss: 154.1581
Epoch 27/50
 - 4s - loss: 2047.1993 - val_loss: 189.2553
Epoch 28/50
 - 4s - loss: 2055.1342 - val_loss: 123.9349
Epoch 29/50
 - 4s - loss: 2050.9160 - val_loss: 156.8476
Epoch 30/50
 - 4s - loss: 2053.1911 - val_loss: 138.2617
Epoch 31/50
 - 4s - loss: 2046.4290 - val_loss: 136.0665
Epoch 32/50
 - 4s - loss: 2056.5132 - val_loss: 153.8546
Epoch 33/50
 - 4s - loss: 2049.5495 - val_loss: 121.4945
Epoch 34/50
 - 4s - loss: 2040.3414 - val_loss: 116.3700
Epoch 35/50
 - 4s - loss: 2043.6255 - val_loss: 148.6943
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 69020	action = 0	current_phase = 1	next_phase = 0	reward = 1.007815	array([[  2.872613, -47.494713]], dtype=float32)
time = 69025	action = 0	current_phase = 1	next_phase = 0	reward = 0.716478	array([[  2.8362226, -47.317368 ]], dtype=float32)
time = 69030	action = 0	current_phase = 1	next_phase = 0	reward = 0.718450	array([[  2.868249, -47.8238  ]], dtype=float32)
time = 69035	action = 0	current_phase = 1	next_phase = 0	reward = 0.716567	array([[  2.8273554, -47.807877 ]], dtype=float32)
time = 69040	action = 0	current_phase = 1	next_phase = 0	reward = 0.729723	array([[  2.8851328, -47.61841  ]], dtype=float32)
time = 69045	action = 0	current_phase = 1	next_phase = 0	reward = 0.722975	array([[  2.8854647, -47.526115 ]], dtype=float32)
time = 69050	action = 0	current_phase = 1	next_phase = 0	reward = 0.717969	array([[  2.8853655, -47.67045  ]], dtype=float32)
time = 69055	action = 0	current_phase = 1	next_phase = 0	reward = 0.439068	array([[  2.835761, -47.874027]], dtype=float32)
time = 69060	action = 0	current_phase = 1	next_phase = 0	reward = 0.999403	array([[  2.87424 , -47.732433]], dtype=float32)
time = 69065	action = 0	current_phase = 1	next_phase = 0	reward = 0.716091	array([[  2.8725367, -47.62612  ]], dtype=float32)
time = 69070	action = 0	current_phase = 1	next_phase = 0	reward = 0.724956	array([[  2.8805838, -47.757866 ]], dtype=float32)
time = 69075	action = 0	current_phase = 1	next_phase = 0	reward = 0.718880	array([[  2.7382174, -47.978928 ]], dtype=float32)
time = 69080	action = 0	current_phase = 1	next_phase = 0	reward = 0.445078	array([[  2.844699, -47.772415]], dtype=float32)
time = 69085	action = 0	current_phase = 1	next_phase = 0	reward = 1.003006	array([[  2.7379045, -47.975407 ]], dtype=float32)
time = 69090	action = 0	current_phase = 1	next_phase = 0	reward = 0.718008	array([[  2.725646, -47.98378 ]], dtype=float32)
time = 69095	action = 0	current_phase = 1	next_phase = 0	reward = 0.723711	array([[  2.8213644, -47.86738  ]], dtype=float32)
time = 69100	action = 0	current_phase = 1	next_phase = 0	reward = 0.724707	array([[  2.878337, -47.707138]], dtype=float32)
time = 69105	action = 0	current_phase = 1	next_phase = 0	reward = 0.720988	array([[  2.8595228, -47.784492 ]], dtype=float32)
time = 69110	action = 0	current_phase = 1	next_phase = 0	reward = 0.718714	array([[  2.8761797, -47.789436 ]], dtype=float32)
time = 69115	action = 0	current_phase = 1	next_phase = 0	reward = 0.721308	array([[  2.862403, -47.766407]], dtype=float32)
time = 69120	action = 0	current_phase = 1	next_phase = 0	reward = 0.441267	array([[  2.8874636, -47.534286 ]], dtype=float32)
time = 69125	action = 0	current_phase = 1	next_phase = 0	reward = 1.001628	array([[  2.8085146, -47.92443  ]], dtype=float32)
time = 69130	action = 0	current_phase = 1	next_phase = 0	reward = 0.442866	array([[  2.8874483, -47.61811  ]], dtype=float32)
time = 69135	action = 0	current_phase = 1	next_phase = 0	reward = 1.002845	array([[  2.8211012, -47.911453 ]], dtype=float32)
time = 69140	action = 0	current_phase = 1	next_phase = 0	reward = 0.725644	array([[  2.8734407, -47.520027 ]], dtype=float32)
time = 69145	action = 0	current_phase = 1	next_phase = 0	reward = 0.720708	array([[  2.7349005, -47.95536  ]], dtype=float32)
time = 69150	action = 0	current_phase = 1	next_phase = 0	reward = 0.444398	array([[  2.8501291, -47.800774 ]], dtype=float32)
time = 69155	action = 0	current_phase = 1	next_phase = 0	reward = 1.004517	array([[  2.8177824, -47.848206 ]], dtype=float32)
time = 69160	action = 0	current_phase = 1	next_phase = 0	reward = 0.722946	array([[  2.7397776, -47.984604 ]], dtype=float32)
time = 69165	action = 0	current_phase = 1	next_phase = 0	reward = 0.720058	array([[  2.8841047, -47.729237 ]], dtype=float32)
time = 69170	action = 0	current_phase = 1	next_phase = 0	reward = 0.719086	array([[  2.8917952, -47.679386 ]], dtype=float32)
time = 69175	action = 0	current_phase = 1	next_phase = 0	reward = 0.717904	array([[  2.8560724, -47.82951  ]], dtype=float32)
time = 69180	action = 0	current_phase = 1	next_phase = 0	reward = 0.719527	array([[  2.907237, -47.66623 ]], dtype=float32)
time = 69185	action = 0	current_phase = 1	next_phase = 0	reward = 0.721443	array([[  2.8842363, -47.606667 ]], dtype=float32)
time = 69190	action = 0	current_phase = 1	next_phase = 0	reward = 0.725574	array([[  2.8456335, -47.833656 ]], dtype=float32)
time = 69195	action = 0	current_phase = 1	next_phase = 0	reward = 0.725058	array([[  2.8780355, -47.761223 ]], dtype=float32)
time = 69200	action = 0	current_phase = 1	next_phase = 0	reward = 0.719503	array([[  2.8625746, -47.79048  ]], dtype=float32)
time = 69205	action = 0	current_phase = 1	next_phase = 0	reward = 0.442077	array([[  2.8802557, -47.54329  ]], dtype=float32)
time = 69210	action = 0	current_phase = 1	next_phase = 0	reward = 1.001873	array([[  2.863984, -47.79172 ]], dtype=float32)
time = 69215	action = 0	current_phase = 1	next_phase = 0	reward = 0.436252	array([[  2.891797, -47.685295]], dtype=float32)
time = 69220	action = 0	current_phase = 1	next_phase = 0	reward = 0.729633	array([[  2.8906412, -47.65332  ]], dtype=float32)
time = 69225	action = 0	current_phase = 1	next_phase = 0	reward = 1.007181	array([[  2.8560457, -47.73383  ]], dtype=float32)
time = 69230	action = 0	current_phase = 1	next_phase = 0	reward = 0.717385	array([[  2.8906069, -47.684082 ]], dtype=float32)
time = 69235	action = 0	current_phase = 1	next_phase = 0	reward = 0.721162	array([[  2.6206179, -47.48307  ]], dtype=float32)
time = 69240	action = 0	current_phase = 1	next_phase = 0	reward = 0.722974	array([[  2.8178282, -47.857983 ]], dtype=float32)
time = 69245	action = 0	current_phase = 1	next_phase = 0	reward = 0.728918	array([[  2.8694792, -47.787968 ]], dtype=float32)
time = 69250	action = 0	current_phase = 1	next_phase = 0	reward = 0.719991	array([[  2.8820105, -47.70601  ]], dtype=float32)
time = 69255	action = 0	current_phase = 1	next_phase = 0	reward = 0.718356	array([[  2.8625364, -47.710228 ]], dtype=float32)
time = 69260	action = 0	current_phase = 1	next_phase = 0	reward = 0.717106	array([[  2.8847437, -47.66846  ]], dtype=float32)
time = 69265	action = 0	current_phase = 1	next_phase = 0	reward = 0.717156	array([[  2.833846, -47.74115 ]], dtype=float32)
time = 69270	action = 0	current_phase = 1	next_phase = 0	reward = 0.442915	array([[  2.7453356, -47.96453  ]], dtype=float32)
time = 69275	action = 0	current_phase = 1	next_phase = 0	reward = 1.006566	array([[  2.895009, -47.58511 ]], dtype=float32)
time = 69280	action = 0	current_phase = 1	next_phase = 0	reward = 0.166286	array([[  2.8901873, -47.637405 ]], dtype=float32)
time = 69285	action = 0	current_phase = 1	next_phase = 0	reward = 1.273018	array([[  2.8807726, -47.613827 ]], dtype=float32)
time = 69290	action = 0	current_phase = 1	next_phase = 0	reward = 0.438875	array([[  2.8518553, -47.823418 ]], dtype=float32)
time = 69295	action = 0	current_phase = 1	next_phase = 0	reward = 0.993760	array([[  2.8845396, -47.738155 ]], dtype=float32)
time = 69300	action = 0	current_phase = 1	next_phase = 0	reward = 0.718202	array([[  2.8869143, -47.653427 ]], dtype=float32)
time = 69305	action = 0	current_phase = 1	next_phase = 0	reward = 0.728159	array([[  2.8781462, -47.79546  ]], dtype=float32)
time = 69310	action = 0	current_phase = 1	next_phase = 0	reward = 0.721208	array([[  2.8639631, -47.45394  ]], dtype=float32)
time = 69315	action = 0	current_phase = 1	next_phase = 0	reward = 0.722867	array([[  2.8753462, -47.765762 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 246.7243 - val_loss: 4615.6278
Epoch 2/50
 - 4s - loss: 254.8162 - val_loss: 4586.6631
Epoch 3/50
 - 4s - loss: 240.4702 - val_loss: 4567.3990
Epoch 4/50
 - 4s - loss: 241.2132 - val_loss: 4566.4373
Epoch 5/50
 - 4s - loss: 220.2197 - val_loss: 4592.0748
Epoch 6/50
 - 4s - loss: 234.5944 - val_loss: 4601.1649
Epoch 7/50
 - 4s - loss: 238.6992 - val_loss: 4603.1878
Epoch 8/50
 - 4s - loss: 275.6422 - val_loss: 4575.2054
Epoch 9/50
 - 4s - loss: 224.6626 - val_loss: 4596.4734
Epoch 10/50
 - 4s - loss: 242.0854 - val_loss: 4575.0621
Epoch 11/50
 - 4s - loss: 225.5951 - val_loss: 4588.3800
Epoch 12/50
 - 4s - loss: 241.3427 - val_loss: 4599.9189
Epoch 13/50
 - 4s - loss: 258.3256 - val_loss: 4581.3457
Epoch 14/50
 - 4s - loss: 250.9466 - val_loss: 4566.6950
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 69320	action = 0	current_phase = 1	next_phase = 0	reward = 0.723206	array([[  2.9859562, -47.903465 ]], dtype=float32)
time = 69325	action = 0	current_phase = 1	next_phase = 0	reward = 0.729006	array([[  3.0638332, -47.639427 ]], dtype=float32)
time = 69330	action = 0	current_phase = 1	next_phase = 0	reward = 0.719137	array([[  3.016924, -47.82538 ]], dtype=float32)
time = 69335	action = 0	current_phase = 1	next_phase = 0	reward = 0.715380	array([[  3.0783596, -47.744713 ]], dtype=float32)
time = 69340	action = 0	current_phase = 1	next_phase = 0	reward = 0.712723	array([[  3.0113773, -47.958176 ]], dtype=float32)
time = 69345	action = 0	current_phase = 1	next_phase = 0	reward = 0.167357	array([[  3.0568428, -47.643322 ]], dtype=float32)
time = 69350	action = 0	current_phase = 1	next_phase = 0	reward = 1.292099	array([[  3.050085, -47.764145]], dtype=float32)
time = 69355	action = 0	current_phase = 1	next_phase = 0	reward = 0.724612	array([[  3.0752907, -47.717747 ]], dtype=float32)
time = 69360	action = 0	current_phase = 1	next_phase = 0	reward = 0.725137	array([[  3.076004, -47.8221  ]], dtype=float32)
time = 69365	action = 0	current_phase = 1	next_phase = 0	reward = 0.711246	array([[  2.9913292, -47.854362 ]], dtype=float32)
time = 69370	action = 0	current_phase = 1	next_phase = 0	reward = 0.715778	array([[  3.06888 , -47.699936]], dtype=float32)
time = 69375	action = 0	current_phase = 1	next_phase = 0	reward = 0.718172	array([[  3.0314407, -47.928528 ]], dtype=float32)
time = 69380	action = 0	current_phase = 1	next_phase = 0	reward = 0.446647	array([[  3.075346, -47.717957]], dtype=float32)
time = 69385	action = 0	current_phase = 1	next_phase = 0	reward = 0.996374	array([[  3.0801163, -47.767708 ]], dtype=float32)
time = 69390	action = 0	current_phase = 1	next_phase = 0	reward = 0.719080	array([[  3.072033, -47.695908]], dtype=float32)
time = 69395	action = 0	current_phase = 1	next_phase = 0	reward = 0.442583	array([[  2.9792213, -48.010376 ]], dtype=float32)
time = 69400	action = 0	current_phase = 1	next_phase = 0	reward = 1.001457	array([[  3.035408, -47.873283]], dtype=float32)
time = 69405	action = 0	current_phase = 1	next_phase = 0	reward = 0.724446	array([[  3.05694 , -47.684494]], dtype=float32)
time = 69410	action = 0	current_phase = 1	next_phase = 0	reward = 0.725423	array([[  3.078331, -47.727196]], dtype=float32)
time = 69415	action = 0	current_phase = 1	next_phase = 0	reward = 0.717526	array([[  3.064249, -47.574596]], dtype=float32)
time = 69420	action = 0	current_phase = 1	next_phase = 0	reward = 0.436900	array([[  3.0712261, -47.718395 ]], dtype=float32)
time = 69425	action = 0	current_phase = 1	next_phase = 0	reward = 0.997485	array([[  2.9768448, -47.977573 ]], dtype=float32)
time = 69430	action = 0	current_phase = 1	next_phase = 0	reward = 0.724170	array([[  3.072567, -47.704666]], dtype=float32)
time = 69435	action = 0	current_phase = 1	next_phase = 0	reward = 0.717183	array([[  3.063448, -47.70978 ]], dtype=float32)
time = 69440	action = 0	current_phase = 1	next_phase = 0	reward = 0.718258	array([[  3.0333138, -47.908684 ]], dtype=float32)
time = 69445	action = 0	current_phase = 1	next_phase = 0	reward = 0.723000	array([[  3.0423412, -47.89411  ]], dtype=float32)
time = 69450	action = 0	current_phase = 1	next_phase = 0	reward = 0.728192	array([[  3.0076237, -47.477642 ]], dtype=float32)
time = 69455	action = 0	current_phase = 1	next_phase = 0	reward = 0.714388	array([[  3.0133476, -47.72407  ]], dtype=float32)
time = 69460	action = 0	current_phase = 1	next_phase = 0	reward = 0.715094	array([[  2.9249516, -48.020226 ]], dtype=float32)
time = 69465	action = 0	current_phase = 1	next_phase = 0	reward = 0.723480	array([[  3.0451393, -47.85753  ]], dtype=float32)
time = 69470	action = 0	current_phase = 1	next_phase = 0	reward = 0.714684	array([[  3.0442486, -47.934757 ]], dtype=float32)
time = 69475	action = 0	current_phase = 1	next_phase = 0	reward = 0.160189	array([[  3.0623531, -47.908634 ]], dtype=float32)
time = 69480	action = 0	current_phase = 1	next_phase = 0	reward = 1.285698	array([[  3.0421715, -47.741905 ]], dtype=float32)
time = 69485	action = 0	current_phase = 1	next_phase = 0	reward = 0.720253	array([[  2.9750195, -47.973488 ]], dtype=float32)
time = 69490	action = 0	current_phase = 1	next_phase = 0	reward = 0.724253	array([[  3.0884724, -47.900032 ]], dtype=float32)
time = 69495	action = 0	current_phase = 1	next_phase = 0	reward = 0.436878	array([[  3.0663967, -47.76294  ]], dtype=float32)
time = 69500	action = 0	current_phase = 1	next_phase = 0	reward = 1.001055	array([[  3.006197, -47.523605]], dtype=float32)
time = 69505	action = 0	current_phase = 1	next_phase = 0	reward = 0.722189	array([[  3.0257568, -47.941933 ]], dtype=float32)
time = 69510	action = 0	current_phase = 1	next_phase = 0	reward = 0.723829	array([[  3.0769367, -47.837894 ]], dtype=float32)
time = 69515	action = 0	current_phase = 1	next_phase = 0	reward = 0.726481	array([[  3.068142, -47.745483]], dtype=float32)
time = 69520	action = 0	current_phase = 1	next_phase = 0	reward = 0.710608	array([[  3.070963, -47.73408 ]], dtype=float32)
time = 69525	action = 0	current_phase = 1	next_phase = 0	reward = 0.437892	array([[  3.0300312, -47.495174 ]], dtype=float32)
time = 69530	action = 0	current_phase = 1	next_phase = 0	reward = 1.009161	array([[  3.050623, -47.90499 ]], dtype=float32)
time = 69535	action = 0	current_phase = 1	next_phase = 0	reward = 0.446140	array([[  3.0165787, -47.70922  ]], dtype=float32)
time = 69540	action = 0	current_phase = 1	next_phase = 0	reward = 1.006237	array([[  3.0313797, -47.554096 ]], dtype=float32)
time = 69545	action = 0	current_phase = 1	next_phase = 0	reward = 0.721133	array([[  3.041565, -47.83974 ]], dtype=float32)
time = 69550	action = 0	current_phase = 1	next_phase = 0	reward = 0.713033	array([[  2.994934, -47.941475]], dtype=float32)
time = 69555	action = 0	current_phase = 1	next_phase = 0	reward = 0.718761	array([[  3.056158, -47.68158 ]], dtype=float32)
time = 69560	action = 0	current_phase = 1	next_phase = 0	reward = 0.718333	array([[  3.0147572, -47.880325 ]], dtype=float32)
time = 69565	action = 0	current_phase = 1	next_phase = 0	reward = 0.443351	array([[  3.0671406, -47.798706 ]], dtype=float32)
time = 69570	action = 0	current_phase = 1	next_phase = 0	reward = 1.000083	array([[  3.0854378, -47.75673  ]], dtype=float32)
time = 69575	action = 0	current_phase = 1	next_phase = 0	reward = 0.445569	array([[  3.0004425, -47.883293 ]], dtype=float32)
time = 69580	action = 0	current_phase = 1	next_phase = 0	reward = 1.004194	array([[  3.0619583, -47.810516 ]], dtype=float32)
time = 69585	action = 0	current_phase = 1	next_phase = 0	reward = 0.720998	array([[  2.9559917, -47.946938 ]], dtype=float32)
time = 69590	action = 0	current_phase = 1	next_phase = 0	reward = 0.442796	array([[  2.977789, -47.984264]], dtype=float32)
time = 69595	action = 0	current_phase = 1	next_phase = 0	reward = 0.990687	array([[  3.0752354, -47.70014  ]], dtype=float32)
time = 69600	action = 0	current_phase = 1	next_phase = 0	reward = 0.703222	array([[  2.9758358, -47.973557 ]], dtype=float32)
time = 69605	action = 0	current_phase = 1	next_phase = 0	reward = 0.438333	array([[  3.0597878, -47.660713 ]], dtype=float32)
time = 69610	action = 0	current_phase = 1	next_phase = 0	reward = 1.001429	array([[  2.8595219, -48.00554  ]], dtype=float32)
time = 69615	action = 0	current_phase = 1	next_phase = 0	reward = 0.447073	array([[  3.0799751, -47.679672 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2097.7480 - val_loss: 201.8996
Epoch 2/50
 - 4s - loss: 2086.4660 - val_loss: 220.6435
Epoch 3/50
 - 4s - loss: 2115.7301 - val_loss: 216.7385
Epoch 4/50
 - 4s - loss: 2091.2417 - val_loss: 216.4771
Epoch 5/50
 - 4s - loss: 2140.6994 - val_loss: 198.6611
Epoch 6/50
 - 4s - loss: 2086.1510 - val_loss: 178.0241
Epoch 7/50
 - 4s - loss: 2103.0135 - val_loss: 225.3621
Epoch 8/50
 - 4s - loss: 2082.6522 - val_loss: 192.1204
Epoch 9/50
 - 4s - loss: 2099.4315 - val_loss: 249.0327
Epoch 10/50
 - 4s - loss: 2071.1673 - val_loss: 200.4580
Epoch 11/50
 - 4s - loss: 2120.1990 - val_loss: 223.0629
Epoch 12/50
 - 4s - loss: 2076.9657 - val_loss: 189.4833
Epoch 13/50
 - 4s - loss: 2073.9271 - val_loss: 222.9970
Epoch 14/50
 - 4s - loss: 2112.5030 - val_loss: 233.7378
Epoch 15/50
 - 4s - loss: 2087.8972 - val_loss: 218.4417
Epoch 16/50
 - 4s - loss: 2066.9991 - val_loss: 211.2840
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 69620	action = 0	current_phase = 1	next_phase = 0	reward = 1.007557	array([[  3.0809908, -47.882034 ]], dtype=float32)
time = 69625	action = 0	current_phase = 1	next_phase = 0	reward = 0.720969	array([[  3.0854883, -47.79026  ]], dtype=float32)
time = 69630	action = 0	current_phase = 1	next_phase = 0	reward = 0.715402	array([[  3.093318, -47.794594]], dtype=float32)
time = 69635	action = 0	current_phase = 1	next_phase = 0	reward = 0.716790	array([[  3.0566072, -48.06005  ]], dtype=float32)
time = 69640	action = 0	current_phase = 1	next_phase = 0	reward = 0.442707	array([[  3.0445738, -47.626465 ]], dtype=float32)
time = 69645	action = 0	current_phase = 1	next_phase = 0	reward = 1.001673	array([[  3.0880766, -47.77292  ]], dtype=float32)
time = 69650	action = 0	current_phase = 1	next_phase = 0	reward = 0.718268	array([[  3.0962362, -47.833046 ]], dtype=float32)
time = 69655	action = 0	current_phase = 1	next_phase = 0	reward = 0.723583	array([[  3.0759192, -48.033237 ]], dtype=float32)
time = 69660	action = 0	current_phase = 1	next_phase = 0	reward = 0.719185	array([[  3.0063448, -48.09771  ]], dtype=float32)
time = 69665	action = 0	current_phase = 1	next_phase = 0	reward = 0.728505	array([[  3.0962858, -47.815254 ]], dtype=float32)
time = 69670	action = 0	current_phase = 1	next_phase = 0	reward = 0.723371	array([[  3.083764, -47.78808 ]], dtype=float32)
time = 69675	action = 0	current_phase = 1	next_phase = 0	reward = 0.722170	array([[  3.0981245, -47.968254 ]], dtype=float32)
time = 69680	action = 0	current_phase = 1	next_phase = 0	reward = 0.714019	array([[  3.105483, -47.935856]], dtype=float32)
time = 69685	action = 0	current_phase = 1	next_phase = 0	reward = 0.720581	array([[  3.056922, -48.060596]], dtype=float32)
time = 69690	action = 0	current_phase = 1	next_phase = 0	reward = 0.721959	array([[  3.0934954, -48.00129  ]], dtype=float32)
time = 69695	action = 0	current_phase = 1	next_phase = 0	reward = 0.726702	array([[  3.066224, -48.063877]], dtype=float32)
time = 69700	action = 0	current_phase = 1	next_phase = 0	reward = 0.721956	array([[  3.101985, -47.98986 ]], dtype=float32)
time = 69705	action = 0	current_phase = 1	next_phase = 0	reward = 0.723407	array([[  3.0994291, -47.874973 ]], dtype=float32)
time = 69710	action = 0	current_phase = 1	next_phase = 0	reward = 0.721971	array([[  3.0639238, -48.049347 ]], dtype=float32)
time = 69715	action = 0	current_phase = 1	next_phase = 0	reward = 0.717045	array([[  3.0681067, -47.73025  ]], dtype=float32)
time = 69720	action = 0	current_phase = 1	next_phase = 0	reward = 0.716094	array([[  3.082469, -48.032883]], dtype=float32)
time = 69725	action = 0	current_phase = 1	next_phase = 0	reward = 0.718296	array([[  3.085042, -47.78019 ]], dtype=float32)
time = 69730	action = 0	current_phase = 1	next_phase = 0	reward = 0.719198	array([[  3.0984354, -47.876186 ]], dtype=float32)
time = 69735	action = 0	current_phase = 1	next_phase = 0	reward = 0.728311	array([[  3.0747595, -48.05542  ]], dtype=float32)
time = 69740	action = 0	current_phase = 1	next_phase = 0	reward = 0.713743	array([[  3.058982, -47.689323]], dtype=float32)
time = 69745	action = 0	current_phase = 1	next_phase = 0	reward = 0.716076	array([[  3.0593271, -48.03217  ]], dtype=float32)
time = 69750	action = 0	current_phase = 1	next_phase = 0	reward = 0.443678	array([[  3.086709, -47.99778 ]], dtype=float32)
time = 69755	action = 0	current_phase = 1	next_phase = 0	reward = 1.014687	array([[  3.101941, -47.94298 ]], dtype=float32)
time = 69760	action = 0	current_phase = 1	next_phase = 0	reward = 0.717474	array([[  3.071   , -48.028877]], dtype=float32)
time = 69765	action = 0	current_phase = 1	next_phase = 0	reward = 0.436102	array([[  3.0957556, -47.84681  ]], dtype=float32)
time = 69770	action = 0	current_phase = 1	next_phase = 0	reward = 0.725197	array([[  3.085929, -47.792427]], dtype=float32)
time = 69775	action = 0	current_phase = 1	next_phase = 0	reward = 1.005189	array([[  3.0335302, -48.08932  ]], dtype=float32)
time = 69780	action = 0	current_phase = 1	next_phase = 0	reward = 0.721591	array([[  3.0051508, -48.083878 ]], dtype=float32)
time = 69785	action = 0	current_phase = 1	next_phase = 0	reward = 0.717559	array([[  3.065219, -48.04814 ]], dtype=float32)
time = 69790	action = 0	current_phase = 1	next_phase = 0	reward = 0.714164	array([[  3.0979319, -47.937523 ]], dtype=float32)
time = 69795	action = 0	current_phase = 1	next_phase = 0	reward = 0.719900	array([[  2.991477, -48.143444]], dtype=float32)
time = 69800	action = 0	current_phase = 1	next_phase = 0	reward = 0.444802	array([[  3.105733, -47.928337]], dtype=float32)
time = 69805	action = 0	current_phase = 1	next_phase = 0	reward = 1.004371	array([[  2.9905233, -48.128227 ]], dtype=float32)
time = 69810	action = 0	current_phase = 1	next_phase = 0	reward = 0.719278	array([[  3.0859919, -47.979233 ]], dtype=float32)
time = 69815	action = 0	current_phase = 1	next_phase = 0	reward = 0.718702	array([[  3.0570917, -48.08483  ]], dtype=float32)
time = 69820	action = 0	current_phase = 1	next_phase = 0	reward = 0.717488	array([[  3.0151472, -47.717422 ]], dtype=float32)
time = 69825	action = 0	current_phase = 1	next_phase = 0	reward = 0.712526	array([[  3.1006193, -47.86763  ]], dtype=float32)
time = 69830	action = 0	current_phase = 1	next_phase = 0	reward = 0.440020	array([[  2.9532042, -48.153156 ]], dtype=float32)
time = 69835	action = 0	current_phase = 1	next_phase = 0	reward = 0.722907	array([[  3.074195, -47.731365]], dtype=float32)
time = 69840	action = 0	current_phase = 1	next_phase = 0	reward = 0.721325	array([[  3.0825853, -47.765175 ]], dtype=float32)
time = 69845	action = 0	current_phase = 1	next_phase = 0	reward = 0.723480	array([[  3.1026793, -47.870636 ]], dtype=float32)
time = 69850	action = 0	current_phase = 1	next_phase = 0	reward = 0.725576	array([[  3.1013918, -47.881058 ]], dtype=float32)
time = 69855	action = 0	current_phase = 1	next_phase = 0	reward = 0.991900	array([[  3.0112486, -48.079254 ]], dtype=float32)
time = 69860	action = 0	current_phase = 1	next_phase = 0	reward = 0.437211	array([[  3.0883684, -47.765244 ]], dtype=float32)
time = 69865	action = 0	current_phase = 1	next_phase = 0	reward = 0.726511	array([[  3.0246096, -48.10668  ]], dtype=float32)
time = 69870	action = 0	current_phase = 1	next_phase = 0	reward = 1.009275	array([[  3.0645323, -47.69111  ]], dtype=float32)
time = 69875	action = 0	current_phase = 1	next_phase = 0	reward = 0.715789	array([[  3.0952387, -47.9562   ]], dtype=float32)
time = 69880	action = 0	current_phase = 1	next_phase = 0	reward = 0.441057	array([[  3.065112, -47.691635]], dtype=float32)
time = 69885	action = 0	current_phase = 1	next_phase = 0	reward = 1.001677	array([[  3.036151, -48.023643]], dtype=float32)
time = 69890	action = 0	current_phase = 1	next_phase = 0	reward = 0.723636	array([[  3.0736666, -48.03228  ]], dtype=float32)
time = 69895	action = 0	current_phase = 1	next_phase = 0	reward = 0.721031	array([[  3.0756292, -47.801422 ]], dtype=float32)
time = 69900	action = 0	current_phase = 1	next_phase = 0	reward = 0.719982	array([[  3.0593843, -48.090485 ]], dtype=float32)
time = 69905	action = 0	current_phase = 1	next_phase = 0	reward = 0.719431	array([[  3.0929117, -47.79948  ]], dtype=float32)
time = 69910	action = 0	current_phase = 1	next_phase = 0	reward = 0.720221	array([[  3.088008, -47.777878]], dtype=float32)
time = 69915	action = 0	current_phase = 1	next_phase = 0	reward = 0.726986	array([[  3.0251608, -48.031433 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2150.7285 - val_loss: 235.6305
Epoch 2/50
 - 4s - loss: 2126.3765 - val_loss: 220.2672
Epoch 3/50
 - 4s - loss: 2119.9887 - val_loss: 208.2963
Epoch 4/50
 - 4s - loss: 2108.1246 - val_loss: 257.7726
Epoch 5/50
 - 4s - loss: 2132.9759 - val_loss: 271.8313
Epoch 6/50
 - 4s - loss: 2137.1579 - val_loss: 259.1385
Epoch 7/50
 - 4s - loss: 2117.1997 - val_loss: 294.2106
Epoch 8/50
 - 4s - loss: 2160.5519 - val_loss: 269.9508
Epoch 9/50
 - 4s - loss: 2130.3927 - val_loss: 251.8650
Epoch 10/50
 - 4s - loss: 2131.0453 - val_loss: 226.9477
Epoch 11/50
 - 4s - loss: 2116.5397 - val_loss: 237.6997
Epoch 12/50
 - 4s - loss: 2114.1390 - val_loss: 192.1404
Epoch 13/50
 - 4s - loss: 2096.4209 - val_loss: 212.0519
Epoch 14/50
 - 4s - loss: 2106.4437 - val_loss: 195.6545
Epoch 15/50
 - 4s - loss: 2102.4018 - val_loss: 209.2706
Epoch 16/50
 - 4s - loss: 2136.1652 - val_loss: 188.7702
Epoch 17/50
 - 4s - loss: 2118.1459 - val_loss: 220.6456
Epoch 18/50
 - 4s - loss: 2107.9817 - val_loss: 215.0170
Epoch 19/50
 - 4s - loss: 2114.8648 - val_loss: 222.8723
Epoch 20/50
 - 4s - loss: 2106.4035 - val_loss: 274.1551
Epoch 21/50
 - 4s - loss: 2107.0946 - val_loss: 193.4156
Epoch 22/50
 - 4s - loss: 2095.9596 - val_loss: 191.7976
Epoch 23/50
 - 4s - loss: 2113.1710 - val_loss: 221.9534
Epoch 24/50
 - 4s - loss: 2110.0634 - val_loss: 305.8446
Epoch 25/50
 - 4s - loss: 2095.0007 - val_loss: 245.2273
Epoch 26/50
 - 4s - loss: 2093.3337 - val_loss: 215.9417
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 69920	action = 0	current_phase = 1	next_phase = 0	reward = 0.730704	array([[  2.9442282, -48.15165  ]], dtype=float32)
time = 69925	action = 0	current_phase = 1	next_phase = 0	reward = 0.726593	array([[  2.9027834, -48.25589  ]], dtype=float32)
time = 69930	action = 0	current_phase = 1	next_phase = 0	reward = 0.718143	array([[  2.8952742, -47.92789  ]], dtype=float32)
time = 69935	action = 0	current_phase = 1	next_phase = 0	reward = 0.721896	array([[  2.6313944, -48.030876 ]], dtype=float32)
time = 69940	action = 0	current_phase = 1	next_phase = 0	reward = 0.439321	array([[  2.9162912, -48.273094 ]], dtype=float32)
time = 69945	action = 0	current_phase = 1	next_phase = 0	reward = 1.005837	array([[  2.934636, -48.160675]], dtype=float32)
time = 69950	action = 0	current_phase = 1	next_phase = 0	reward = 0.718628	array([[  2.909257, -48.188095]], dtype=float32)
time = 69955	action = 0	current_phase = 1	next_phase = 0	reward = 0.716733	array([[  2.862708, -48.02995 ]], dtype=float32)
time = 69960	action = 0	current_phase = 1	next_phase = 0	reward = 0.716430	array([[  2.867055, -48.334953]], dtype=float32)
time = 69965	action = 0	current_phase = 1	next_phase = 0	reward = 0.714504	array([[  2.9274015, -48.09862  ]], dtype=float32)
time = 69970	action = 0	current_phase = 1	next_phase = 0	reward = 0.443190	array([[  2.925189, -48.19677 ]], dtype=float32)
time = 69975	action = 0	current_phase = 1	next_phase = 0	reward = 1.012833	array([[  2.9078856, -48.004425 ]], dtype=float32)
time = 69980	action = 0	current_phase = 1	next_phase = 0	reward = 0.721258	array([[  2.8818502, -47.858593 ]], dtype=float32)
time = 69985	action = 0	current_phase = 1	next_phase = 0	reward = 0.724899	array([[  2.8208513, -48.40054  ]], dtype=float32)
time = 69990	action = 0	current_phase = 1	next_phase = 0	reward = 0.723552	array([[  2.9210138, -47.992058 ]], dtype=float32)
time = 69995	action = 0	current_phase = 1	next_phase = 0	reward = 0.722100	array([[  2.9209528, -48.085236 ]], dtype=float32)
time = 70000	action = 0	current_phase = 1	next_phase = 0	reward = 0.726169	array([[  2.928832, -48.052513]], dtype=float32)
time = 70005	action = 0	current_phase = 1	next_phase = 0	reward = 0.717351	array([[  2.932828, -48.191875]], dtype=float32)
time = 70010	action = 0	current_phase = 1	next_phase = 0	reward = 0.715210	array([[  2.8443518, -48.37004  ]], dtype=float32)
time = 70015	action = 0	current_phase = 1	next_phase = 0	reward = 0.718944	array([[  2.8965826, -47.973854 ]], dtype=float32)
time = 70020	action = 0	current_phase = 1	next_phase = 0	reward = 0.717932	array([[  2.8695707, -48.350685 ]], dtype=float32)
time = 70025	action = 0	current_phase = 1	next_phase = 0	reward = 0.442159	array([[  2.9471235, -48.21601  ]], dtype=float32)
time = 70030	action = 0	current_phase = 1	next_phase = 0	reward = 1.009730	array([[  2.9331312, -48.21972  ]], dtype=float32)
time = 70035	action = 0	current_phase = 1	next_phase = 0	reward = 0.721625	array([[  2.9060602, -48.12522  ]], dtype=float32)
time = 70040	action = 0	current_phase = 1	next_phase = 0	reward = 0.711057	array([[  2.936782, -48.11525 ]], dtype=float32)
time = 70045	action = 0	current_phase = 1	next_phase = 0	reward = 0.441763	array([[  2.914609, -48.24366 ]], dtype=float32)
time = 70050	action = 0	current_phase = 1	next_phase = 0	reward = 1.000605	array([[  2.933402, -48.223495]], dtype=float32)
time = 70055	action = 0	current_phase = 1	next_phase = 0	reward = 0.441285	array([[  2.9328623, -48.132286 ]], dtype=float32)
time = 70060	action = 0	current_phase = 1	next_phase = 0	reward = 1.008150	array([[  2.9228868, -48.213333 ]], dtype=float32)
time = 70065	action = 0	current_phase = 1	next_phase = 0	reward = 0.720546	array([[  2.8844671, -48.316452 ]], dtype=float32)
time = 70070	action = 0	current_phase = 1	next_phase = 0	reward = 0.722135	array([[  2.9306612, -48.13326  ]], dtype=float32)
time = 70075	action = 0	current_phase = 1	next_phase = 0	reward = 0.726020	array([[  2.8903894, -48.147522 ]], dtype=float32)
time = 70080	action = 0	current_phase = 1	next_phase = 0	reward = 0.441934	array([[  2.8502588, -48.34368  ]], dtype=float32)
time = 70085	action = 0	current_phase = 1	next_phase = 0	reward = 1.005017	array([[  2.9508772, -48.07373  ]], dtype=float32)
time = 70090	action = 0	current_phase = 1	next_phase = 0	reward = 0.722938	array([[  2.8869581, -48.2919   ]], dtype=float32)
time = 70095	action = 0	current_phase = 1	next_phase = 0	reward = 0.725228	array([[  2.8967562, -48.313576 ]], dtype=float32)
time = 70100	action = 0	current_phase = 1	next_phase = 0	reward = 0.720825	array([[  2.9312048, -48.240723 ]], dtype=float32)
time = 70105	action = 0	current_phase = 1	next_phase = 0	reward = 0.442251	array([[  2.8953428, -48.23746  ]], dtype=float32)
time = 70110	action = 0	current_phase = 1	next_phase = 0	reward = 1.000718	array([[  2.871581, -47.82386 ]], dtype=float32)
time = 70115	action = 0	current_phase = 1	next_phase = 0	reward = 0.713101	array([[  2.81009 , -48.324562]], dtype=float32)
time = 70120	action = 0	current_phase = 1	next_phase = 0	reward = 0.436152	array([[  2.9207544, -48.060364 ]], dtype=float32)
time = 70125	action = 0	current_phase = 1	next_phase = 0	reward = 0.991709	array([[  2.9293718, -48.110764 ]], dtype=float32)
time = 70130	action = 0	current_phase = 1	next_phase = 0	reward = 0.437390	array([[  2.9113035, -48.28858  ]], dtype=float32)
time = 70135	action = 0	current_phase = 1	next_phase = 0	reward = 1.009811	array([[  2.9067163, -48.02461  ]], dtype=float32)
time = 70140	action = 0	current_phase = 1	next_phase = 0	reward = 0.441455	array([[  2.9313574, -48.118378 ]], dtype=float32)
time = 70145	action = 0	current_phase = 1	next_phase = 0	reward = 1.001654	array([[  2.8906832, -47.876377 ]], dtype=float32)
time = 70150	action = 0	current_phase = 1	next_phase = 0	reward = 0.716908	array([[  2.9083376, -48.299522 ]], dtype=float32)
time = 70155	action = 0	current_phase = 1	next_phase = 0	reward = 0.438317	array([[  2.9184427, -48.134003 ]], dtype=float32)
time = 70160	action = 0	current_phase = 1	next_phase = 0	reward = 1.006990	array([[  2.8232317, -48.40531  ]], dtype=float32)
time = 70165	action = 0	current_phase = 1	next_phase = 0	reward = 0.726512	array([[  2.9268026, -48.184975 ]], dtype=float32)
time = 70170	action = 0	current_phase = 1	next_phase = 0	reward = 0.732467	array([[  2.9448957, -48.197105 ]], dtype=float32)
time = 70175	action = 0	current_phase = 1	next_phase = 0	reward = 0.714103	array([[  2.9194345, -48.024937 ]], dtype=float32)
time = 70180	action = 0	current_phase = 1	next_phase = 0	reward = 0.719207	array([[  2.909215, -48.10273 ]], dtype=float32)
time = 70185	action = 0	current_phase = 1	next_phase = 0	reward = 0.714902	array([[  2.9329119, -48.244156 ]], dtype=float32)
time = 70190	action = 0	current_phase = 1	next_phase = 0	reward = 0.439628	array([[  2.938489, -48.18029 ]], dtype=float32)
time = 70195	action = 0	current_phase = 1	next_phase = 0	reward = 1.000474	array([[  2.8611383, -48.16049  ]], dtype=float32)
time = 70200	action = 0	current_phase = 1	next_phase = 0	reward = 0.714192	array([[  2.9388628, -48.187935 ]], dtype=float32)
time = 70205	action = 0	current_phase = 1	next_phase = 0	reward = 0.714814	array([[  2.9221773, -48.166878 ]], dtype=float32)
time = 70210	action = 0	current_phase = 1	next_phase = 0	reward = 0.439447	array([[  2.9297724, -48.187424 ]], dtype=float32)
time = 70215	action = 0	current_phase = 1	next_phase = 0	reward = 1.000897	array([[  2.9074469, -48.27173  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 253.4803 - val_loss: 294.4246
Epoch 2/50
 - 4s - loss: 226.6743 - val_loss: 282.6746
Epoch 3/50
 - 4s - loss: 233.3226 - val_loss: 297.6646
Epoch 4/50
 - 4s - loss: 228.3214 - val_loss: 297.1248
Epoch 5/50
 - 4s - loss: 255.1678 - val_loss: 301.9875
Epoch 6/50
 - 4s - loss: 244.9396 - val_loss: 456.9689
Epoch 7/50
 - 4s - loss: 259.5955 - val_loss: 505.9543
Epoch 8/50
 - 4s - loss: 282.2897 - val_loss: 279.0692
Epoch 9/50
 - 4s - loss: 235.5326 - val_loss: 296.1934
Epoch 10/50
 - 4s - loss: 232.5543 - val_loss: 482.7728
Epoch 11/50
 - 4s - loss: 247.9958 - val_loss: 477.2627
Epoch 12/50
 - 4s - loss: 247.0612 - val_loss: 422.7919
Epoch 13/50
 - 4s - loss: 221.3552 - val_loss: 424.0074
Epoch 14/50
 - 4s - loss: 250.0183 - val_loss: 298.6308
Epoch 15/50
 - 4s - loss: 222.6870 - val_loss: 321.5033
Epoch 16/50
 - 4s - loss: 223.4681 - val_loss: 307.4675
Epoch 17/50
 - 4s - loss: 213.8196 - val_loss: 421.1987
Epoch 18/50
 - 4s - loss: 252.4033 - val_loss: 366.8738
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 70220	action = 0	current_phase = 1	next_phase = 0	reward = 0.720058	array([[  2.849286, -48.200565]], dtype=float32)
time = 70225	action = 0	current_phase = 1	next_phase = 0	reward = 0.723936	array([[  2.8324194, -48.199173 ]], dtype=float32)
time = 70230	action = 0	current_phase = 1	next_phase = 0	reward = 0.710791	array([[  2.8821821, -48.08304  ]], dtype=float32)
time = 70235	action = 0	current_phase = 1	next_phase = 0	reward = 0.716585	array([[  2.900838, -48.037773]], dtype=float32)
time = 70240	action = 0	current_phase = 1	next_phase = 0	reward = 0.723215	array([[  2.8711882, -48.167206 ]], dtype=float32)
time = 70245	action = 0	current_phase = 1	next_phase = 0	reward = 0.722013	array([[  2.8663187, -47.98208  ]], dtype=float32)
time = 70250	action = 0	current_phase = 1	next_phase = 0	reward = 0.716730	array([[  2.8299246, -48.094795 ]], dtype=float32)
time = 70255	action = 0	current_phase = 1	next_phase = 0	reward = 0.442102	array([[  2.6348162, -48.141617 ]], dtype=float32)
time = 70260	action = 0	current_phase = 1	next_phase = 0	reward = 1.006804	array([[  2.8978167, -48.026203 ]], dtype=float32)
time = 70265	action = 0	current_phase = 1	next_phase = 0	reward = 0.712300	array([[  2.8041506, -48.235596 ]], dtype=float32)
time = 70270	action = 0	current_phase = 1	next_phase = 0	reward = 0.726546	array([[  2.8719664, -48.132957 ]], dtype=float32)
time = 70275	action = 0	current_phase = 1	next_phase = 0	reward = 0.443821	array([[  2.865119, -48.165596]], dtype=float32)
time = 70280	action = 0	current_phase = 1	next_phase = 0	reward = 1.002840	array([[  2.6582804, -48.321236 ]], dtype=float32)
time = 70285	action = 0	current_phase = 1	next_phase = 0	reward = 0.716509	array([[  2.7968206, -48.26068  ]], dtype=float32)
time = 70290	action = 0	current_phase = 1	next_phase = 0	reward = 0.720888	array([[  2.775567, -48.279137]], dtype=float32)
time = 70295	action = 0	current_phase = 1	next_phase = 0	reward = 0.730357	array([[  2.729226, -48.297737]], dtype=float32)
time = 70300	action = 0	current_phase = 1	next_phase = 0	reward = 0.719121	array([[  2.8637152, -48.18438  ]], dtype=float32)
time = 70305	action = 0	current_phase = 1	next_phase = 0	reward = 0.718713	array([[  2.6773424, -48.03892  ]], dtype=float32)
time = 70310	action = 0	current_phase = 1	next_phase = 0	reward = 0.443875	array([[  2.5811052, -48.19331  ]], dtype=float32)
time = 70315	action = 0	current_phase = 1	next_phase = 0	reward = 0.720681	array([[  2.705989, -48.283985]], dtype=float32)
time = 70320	action = 0	current_phase = 1	next_phase = 0	reward = 1.001907	array([[  2.8552961, -48.13037  ]], dtype=float32)
time = 70325	action = 0	current_phase = 1	next_phase = 0	reward = 0.714352	array([[  2.8378744, -48.218884 ]], dtype=float32)
time = 70330	action = 0	current_phase = 1	next_phase = 0	reward = 0.713360	array([[  2.7461004, -48.275867 ]], dtype=float32)
time = 70335	action = 0	current_phase = 1	next_phase = 0	reward = 0.439207	array([[  2.7499647, -48.268066 ]], dtype=float32)
time = 70340	action = 0	current_phase = 1	next_phase = 0	reward = 0.725231	array([[  2.7756338, -48.067284 ]], dtype=float32)
time = 70345	action = 0	current_phase = 1	next_phase = 0	reward = 0.998783	array([[  2.8747225, -48.104736 ]], dtype=float32)
time = 70350	action = 0	current_phase = 1	next_phase = 0	reward = 0.438170	array([[  2.8863707, -48.17865  ]], dtype=float32)
time = 70355	action = 0	current_phase = 1	next_phase = 0	reward = 0.998759	array([[  2.6933317, -48.270115 ]], dtype=float32)
time = 70360	action = 0	current_phase = 1	next_phase = 0	reward = 0.722267	array([[  2.7365427, -48.226692 ]], dtype=float32)
time = 70365	action = 0	current_phase = 1	next_phase = 0	reward = 0.440775	array([[  2.7739305, -48.269806 ]], dtype=float32)
time = 70370	action = 0	current_phase = 1	next_phase = 0	reward = 0.726473	array([[  2.8977213, -48.062546 ]], dtype=float32)
time = 70375	action = 0	current_phase = 1	next_phase = 0	reward = 1.003026	array([[  2.6411467, -48.316784 ]], dtype=float32)
time = 70380	action = 0	current_phase = 1	next_phase = 0	reward = 0.721401	array([[  2.85571 , -48.159233]], dtype=float32)
time = 70385	action = 0	current_phase = 1	next_phase = 0	reward = 0.723124	array([[  2.846507, -48.06048 ]], dtype=float32)
time = 70390	action = 0	current_phase = 1	next_phase = 0	reward = 0.442865	array([[  2.849599, -48.193462]], dtype=float32)
time = 70395	action = 0	current_phase = 1	next_phase = 0	reward = 1.001331	array([[  2.7849493, -48.258385 ]], dtype=float32)
time = 70400	action = 0	current_phase = 1	next_phase = 0	reward = 0.714314	array([[  2.8424559, -48.10134  ]], dtype=float32)
time = 70405	action = 0	current_phase = 1	next_phase = 0	reward = 0.443527	array([[  2.843255, -48.11943 ]], dtype=float32)
time = 70410	action = 0	current_phase = 1	next_phase = 0	reward = 1.003094	array([[  2.8347769, -48.137978 ]], dtype=float32)
time = 70415	action = 0	current_phase = 1	next_phase = 0	reward = 0.720028	array([[  2.8862982, -47.981247 ]], dtype=float32)
time = 70420	action = 0	current_phase = 1	next_phase = 0	reward = 0.719389	array([[  2.7316294, -48.315598 ]], dtype=float32)
time = 70425	action = 0	current_phase = 1	next_phase = 0	reward = 0.451514	array([[  2.8395147, -48.16855  ]], dtype=float32)
time = 70430	action = 0	current_phase = 1	next_phase = 0	reward = 1.004930	array([[  2.6923018, -47.84375  ]], dtype=float32)
time = 70435	action = 0	current_phase = 1	next_phase = 0	reward = 0.720643	array([[  2.8981657, -48.118675 ]], dtype=float32)
time = 70440	action = 0	current_phase = 1	next_phase = 0	reward = 0.718696	array([[  2.734271, -48.252533]], dtype=float32)
time = 70445	action = 0	current_phase = 1	next_phase = 0	reward = 0.725498	array([[  2.8908548, -48.096504 ]], dtype=float32)
time = 70450	action = 0	current_phase = 1	next_phase = 0	reward = 0.713705	array([[  2.8913336, -48.04017  ]], dtype=float32)
time = 70455	action = 0	current_phase = 1	next_phase = 0	reward = 0.717485	array([[  2.694312, -48.29013 ]], dtype=float32)
time = 70460	action = 0	current_phase = 1	next_phase = 0	reward = 0.719329	array([[  2.8628302, -48.166504 ]], dtype=float32)
time = 70465	action = 0	current_phase = 1	next_phase = 0	reward = 0.720444	array([[  2.7095022, -48.307304 ]], dtype=float32)
time = 70470	action = 0	current_phase = 1	next_phase = 0	reward = 0.718917	array([[  2.8817282, -48.08126  ]], dtype=float32)
time = 70475	action = 0	current_phase = 1	next_phase = 0	reward = 0.719381	array([[  2.8890848, -48.046265 ]], dtype=float32)
time = 70480	action = 0	current_phase = 1	next_phase = 0	reward = 0.442823	array([[  2.7098627, -48.222572 ]], dtype=float32)
time = 70485	action = 0	current_phase = 1	next_phase = 0	reward = 0.994622	array([[  2.9022093, -48.075966 ]], dtype=float32)
time = 70490	action = 0	current_phase = 1	next_phase = 0	reward = 0.719423	array([[  2.8069086, -48.24784  ]], dtype=float32)
time = 70495	action = 0	current_phase = 1	next_phase = 0	reward = 0.729546	array([[  2.7786245, -48.18959  ]], dtype=float32)
time = 70500	action = 0	current_phase = 1	next_phase = 0	reward = 0.714906	array([[  2.833661, -48.20278 ]], dtype=float32)
time = 70505	action = 0	current_phase = 1	next_phase = 0	reward = 0.714125	array([[  2.8670397, -48.044216 ]], dtype=float32)
time = 70510	action = 0	current_phase = 1	next_phase = 0	reward = 0.440213	array([[  2.7888308, -48.24685  ]], dtype=float32)
time = 70515	action = 0	current_phase = 1	next_phase = 0	reward = 1.015149	array([[  2.7360811, -48.27384  ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 158.0476 - val_loss: 304.7420
Epoch 2/50
 - 4s - loss: 175.6923 - val_loss: 296.7028
Epoch 3/50
 - 4s - loss: 191.7573 - val_loss: 433.8618
Epoch 4/50
 - 4s - loss: 200.8716 - val_loss: 293.1639
Epoch 5/50
 - 4s - loss: 210.9775 - val_loss: 308.2573
Epoch 6/50
 - 4s - loss: 155.6275 - val_loss: 378.0387
Epoch 7/50
 - 4s - loss: 191.3101 - val_loss: 308.2640
Epoch 8/50
 - 4s - loss: 181.6639 - val_loss: 314.7903
Epoch 9/50
 - 4s - loss: 214.3089 - val_loss: 311.8194
Epoch 10/50
 - 4s - loss: 186.6620 - val_loss: 297.9731
Epoch 11/50
 - 4s - loss: 163.7741 - val_loss: 326.0269
Epoch 12/50
 - 4s - loss: 161.6905 - val_loss: 372.9188
Epoch 13/50
 - 4s - loss: 188.3256 - val_loss: 294.5767
Epoch 14/50
 - 4s - loss: 176.2938 - val_loss: 321.7468
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 70520	action = 0	current_phase = 1	next_phase = 0	reward = 0.726850	array([[  3.097972, -48.30578 ]], dtype=float32)
time = 70525	action = 0	current_phase = 1	next_phase = 0	reward = 0.721815	array([[  3.048171, -48.42224 ]], dtype=float32)
time = 70530	action = 0	current_phase = 1	next_phase = 0	reward = 0.726974	array([[  3.0919733, -48.195107 ]], dtype=float32)
time = 70535	action = 0	current_phase = 1	next_phase = 0	reward = 0.719745	array([[  2.9679937, -48.514996 ]], dtype=float32)
time = 70540	action = 0	current_phase = 1	next_phase = 0	reward = 0.720955	array([[  3.0926962, -48.324883 ]], dtype=float32)
time = 70545	action = 0	current_phase = 1	next_phase = 0	reward = 0.709952	array([[  3.0563517, -48.413567 ]], dtype=float32)
time = 70550	action = 0	current_phase = 1	next_phase = 0	reward = 0.716273	array([[  3.037961, -48.436295]], dtype=float32)
time = 70555	action = 0	current_phase = 1	next_phase = 0	reward = 0.718713	array([[  2.9652643, -48.516407 ]], dtype=float32)
time = 70560	action = 0	current_phase = 1	next_phase = 0	reward = 0.714468	array([[  3.0874357, -48.36843  ]], dtype=float32)
time = 70565	action = 0	current_phase = 1	next_phase = 0	reward = 0.446645	array([[  3.039939, -48.456978]], dtype=float32)
time = 70570	action = 0	current_phase = 1	next_phase = 0	reward = 1.000408	array([[  2.9922895, -48.469273 ]], dtype=float32)
time = 70575	action = 0	current_phase = 1	next_phase = 0	reward = 0.718981	array([[  3.081441, -48.36961 ]], dtype=float32)
time = 70580	action = 0	current_phase = 1	next_phase = 0	reward = 0.716763	array([[  2.9897356, -48.443436 ]], dtype=float32)
time = 70585	action = 0	current_phase = 1	next_phase = 0	reward = 0.441644	array([[  3.0725908, -48.341064 ]], dtype=float32)
time = 70590	action = 0	current_phase = 1	next_phase = 0	reward = 1.002877	array([[  3.0552702, -48.433178 ]], dtype=float32)
time = 70595	action = 0	current_phase = 1	next_phase = 0	reward = 0.716577	array([[  3.082368, -48.337288]], dtype=float32)
time = 70600	action = 0	current_phase = 1	next_phase = 0	reward = 0.437243	array([[  3.0579271, -48.420174 ]], dtype=float32)
time = 70605	action = 0	current_phase = 1	next_phase = 0	reward = 0.737748	array([[  3.0911665, -48.33364  ]], dtype=float32)
time = 70610	action = 0	current_phase = 1	next_phase = 0	reward = 0.996761	array([[  3.0992403, -48.241184 ]], dtype=float32)
time = 70615	action = 0	current_phase = 1	next_phase = 0	reward = 0.718640	array([[  3.097066, -48.275097]], dtype=float32)
time = 70620	action = 0	current_phase = 1	next_phase = 0	reward = 0.716814	array([[  3.0331316, -48.445347 ]], dtype=float32)
time = 70625	action = 0	current_phase = 1	next_phase = 0	reward = 0.715807	array([[  3.0260782, -48.478016 ]], dtype=float32)
time = 70630	action = 0	current_phase = 1	next_phase = 0	reward = 0.447107	array([[  3.091279, -48.30484 ]], dtype=float32)
time = 70635	action = 0	current_phase = 1	next_phase = 0	reward = 0.729885	array([[  3.099616, -48.285156]], dtype=float32)
time = 70640	action = 0	current_phase = 1	next_phase = 0	reward = 1.012817	array([[  3.0341444, -48.457718 ]], dtype=float32)
time = 70645	action = 0	current_phase = 1	next_phase = 0	reward = 0.713059	array([[  3.0894594, -48.370567 ]], dtype=float32)
time = 70650	action = 0	current_phase = 1	next_phase = 0	reward = 0.715756	array([[  3.026801, -48.477257]], dtype=float32)
time = 70655	action = 0	current_phase = 1	next_phase = 0	reward = 0.445177	array([[  3.0869036, -48.184372 ]], dtype=float32)
time = 70660	action = 0	current_phase = 1	next_phase = 0	reward = 1.003114	array([[  3.095273, -48.27073 ]], dtype=float32)
time = 70665	action = 0	current_phase = 1	next_phase = 0	reward = 0.729732	array([[  3.0900278, -48.35596  ]], dtype=float32)
time = 70670	action = 0	current_phase = 1	next_phase = 0	reward = 0.725794	array([[  3.080699, -48.360447]], dtype=float32)
time = 70675	action = 0	current_phase = 1	next_phase = 0	reward = 0.722818	array([[  3.080287, -48.287624]], dtype=float32)
time = 70680	action = 0	current_phase = 1	next_phase = 0	reward = 0.723395	array([[  3.0751295, -48.37845  ]], dtype=float32)
time = 70685	action = 0	current_phase = 1	next_phase = 0	reward = 0.721277	array([[  3.041276, -48.46605 ]], dtype=float32)
time = 70690	action = 0	current_phase = 1	next_phase = 0	reward = 0.444401	array([[  2.83957 , -48.506466]], dtype=float32)
time = 70695	action = 0	current_phase = 1	next_phase = 0	reward = 1.002246	array([[  3.0746775, -48.11641  ]], dtype=float32)
time = 70700	action = 0	current_phase = 1	next_phase = 0	reward = 0.724469	array([[  3.0723047, -48.398293 ]], dtype=float32)
time = 70705	action = 0	current_phase = 1	next_phase = 0	reward = 0.446407	array([[  3.0852537, -48.341785 ]], dtype=float32)
time = 70710	action = 0	current_phase = 1	next_phase = 0	reward = 1.008199	array([[  3.0875177, -48.271088 ]], dtype=float32)
time = 70715	action = 0	current_phase = 1	next_phase = 0	reward = 0.723612	array([[  2.8807669, -48.522514 ]], dtype=float32)
time = 70720	action = 0	current_phase = 1	next_phase = 0	reward = 0.443507	array([[  3.0899725, -48.239273 ]], dtype=float32)
time = 70725	action = 0	current_phase = 1	next_phase = 0	reward = 0.995973	array([[  3.016038, -48.470123]], dtype=float32)
time = 70730	action = 0	current_phase = 1	next_phase = 0	reward = 0.719961	array([[  3.085208, -48.29643 ]], dtype=float32)
time = 70735	action = 0	current_phase = 1	next_phase = 0	reward = 0.720060	array([[  2.8547907, -48.556213 ]], dtype=float32)
time = 70740	action = 0	current_phase = 1	next_phase = 0	reward = 0.713459	array([[  3.0617247, -48.412807 ]], dtype=float32)
time = 70745	action = 0	current_phase = 1	next_phase = 0	reward = 0.724050	array([[  3.0708513, -48.346405 ]], dtype=float32)
time = 70750	action = 0	current_phase = 1	next_phase = 0	reward = 0.438891	array([[  3.0162039, -48.495903 ]], dtype=float32)
time = 70755	action = 0	current_phase = 1	next_phase = 0	reward = 1.001026	array([[  3.093524, -48.283676]], dtype=float32)
time = 70760	action = 0	current_phase = 1	next_phase = 0	reward = 0.162045	array([[  3.089717, -48.340755]], dtype=float32)
time = 70765	action = 0	current_phase = 1	next_phase = 0	reward = 1.014931	array([[  2.976098, -48.439392]], dtype=float32)
time = 70770	action = 0	current_phase = 1	next_phase = 0	reward = 1.000022	array([[  3.0677824, -48.10565  ]], dtype=float32)
time = 70775	action = 0	current_phase = 1	next_phase = 0	reward = 0.714375	array([[  3.0293036, -48.458862 ]], dtype=float32)
time = 70780	action = 0	current_phase = 1	next_phase = 0	reward = 0.438312	array([[  3.0258322, -48.46521  ]], dtype=float32)
time = 70785	action = 0	current_phase = 1	next_phase = 0	reward = 1.000346	array([[  3.0601168, -48.383564 ]], dtype=float32)
time = 70790	action = 0	current_phase = 1	next_phase = 0	reward = 0.448596	array([[  3.0376482, -48.46191  ]], dtype=float32)
time = 70795	action = 0	current_phase = 1	next_phase = 0	reward = 1.005585	array([[  3.057765, -48.1963  ]], dtype=float32)
time = 70800	action = 0	current_phase = 1	next_phase = 0	reward = 0.719808	array([[  3.0815363, -48.391563 ]], dtype=float32)
time = 70805	action = 0	current_phase = 1	next_phase = 0	reward = 0.721406	array([[  3.0834455, -48.267365 ]], dtype=float32)
time = 70810	action = 0	current_phase = 1	next_phase = 0	reward = 0.443828	array([[  3.0637884, -48.343773 ]], dtype=float32)
time = 70815	action = 0	current_phase = 1	next_phase = 0	reward = 1.001222	array([[  3.0700445, -48.329254 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 1992.0200 - val_loss: 126.8394
Epoch 2/50
 - 4s - loss: 1999.2547 - val_loss: 194.5485
Epoch 3/50
 - 4s - loss: 2000.0155 - val_loss: 118.2887
Epoch 4/50
 - 4s - loss: 2012.4361 - val_loss: 147.2064
Epoch 5/50
 - 4s - loss: 2027.4629 - val_loss: 118.6041
Epoch 6/50
 - 4s - loss: 1976.7783 - val_loss: 212.4682
Epoch 7/50
 - 4s - loss: 2002.9200 - val_loss: 112.3828
Epoch 8/50
 - 4s - loss: 1973.9893 - val_loss: 121.8435
Epoch 9/50
 - 4s - loss: 1982.8143 - val_loss: 176.1685
Epoch 10/50
 - 4s - loss: 2005.3697 - val_loss: 121.2863
Epoch 11/50
 - 4s - loss: 1979.6451 - val_loss: 125.1227
Epoch 12/50
 - 4s - loss: 1982.6242 - val_loss: 145.0228
Epoch 13/50
 - 4s - loss: 1981.9532 - val_loss: 120.1412
Epoch 14/50
 - 4s - loss: 1983.2307 - val_loss: 111.5948
Epoch 15/50
 - 4s - loss: 1981.0041 - val_loss: 205.2577
Epoch 16/50
 - 4s - loss: 1990.0639 - val_loss: 161.4405
Epoch 17/50
 - 4s - loss: 1994.4065 - val_loss: 150.4165
Epoch 18/50
 - 4s - loss: 2018.4733 - val_loss: 187.4101
Epoch 19/50
 - 4s - loss: 1995.3429 - val_loss: 148.6468
Epoch 20/50
 - 4s - loss: 1983.2080 - val_loss: 141.5453
Epoch 21/50
 - 4s - loss: 2001.6813 - val_loss: 141.5675
Epoch 22/50
 - 4s - loss: 2036.5076 - val_loss: 142.8598
Epoch 23/50
 - 4s - loss: 1967.2825 - val_loss: 160.3658
Epoch 24/50
 - 4s - loss: 1999.6505 - val_loss: 145.5162
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 70820	action = 0	current_phase = 1	next_phase = 0	reward = 0.717741	array([[  3.270402, -48.585907]], dtype=float32)
time = 70825	action = 0	current_phase = 1	next_phase = 0	reward = 0.728008	array([[  3.3220968, -48.366447 ]], dtype=float32)
time = 70830	action = 0	current_phase = 1	next_phase = 0	reward = 0.722915	array([[  3.2090006, -48.637146 ]], dtype=float32)
time = 70835	action = 0	current_phase = 1	next_phase = 0	reward = 0.726870	array([[  3.3252382, -48.484367 ]], dtype=float32)
time = 70840	action = 0	current_phase = 1	next_phase = 0	reward = 0.719185	array([[  3.1618395, -48.62204  ]], dtype=float32)
time = 70845	action = 0	current_phase = 1	next_phase = 0	reward = 0.442869	array([[  3.294818, -48.54487 ]], dtype=float32)
time = 70850	action = 0	current_phase = 1	next_phase = 0	reward = 1.009728	array([[  3.077569, -48.652557]], dtype=float32)
time = 70855	action = 0	current_phase = 1	next_phase = 0	reward = 0.446770	array([[  3.2767706, -48.561256 ]], dtype=float32)
time = 70860	action = 0	current_phase = 1	next_phase = 0	reward = 1.005243	array([[  3.3153486, -48.487198 ]], dtype=float32)
time = 70865	action = 0	current_phase = 1	next_phase = 0	reward = 0.718642	array([[  3.031026, -48.677856]], dtype=float32)
time = 70870	action = 0	current_phase = 1	next_phase = 0	reward = 0.715016	array([[  3.2718058, -48.542793 ]], dtype=float32)
time = 70875	action = 0	current_phase = 1	next_phase = 0	reward = 0.720630	array([[  3.2745295, -48.569283 ]], dtype=float32)
time = 70880	action = 0	current_phase = 1	next_phase = 0	reward = 0.449205	array([[  3.2445726, -48.570724 ]], dtype=float32)
time = 70885	action = 0	current_phase = 1	next_phase = 0	reward = 1.004422	array([[  3.328414, -48.41569 ]], dtype=float32)
time = 70890	action = 0	current_phase = 1	next_phase = 0	reward = 0.723346	array([[  3.2894983, -48.549797 ]], dtype=float32)
time = 70895	action = 0	current_phase = 1	next_phase = 0	reward = 0.444217	array([[  3.3247862, -48.424507 ]], dtype=float32)
time = 70900	action = 0	current_phase = 1	next_phase = 0	reward = 0.996904	array([[  3.3230028, -48.440754 ]], dtype=float32)
time = 70905	action = 0	current_phase = 1	next_phase = 0	reward = 0.718712	array([[  3.3186045, -48.346855 ]], dtype=float32)
time = 70910	action = 0	current_phase = 1	next_phase = 0	reward = 0.718198	array([[  3.330514, -48.38221 ]], dtype=float32)
time = 70915	action = 0	current_phase = 1	next_phase = 0	reward = 0.719741	array([[  3.3173723, -48.472664 ]], dtype=float32)
time = 70920	action = 0	current_phase = 1	next_phase = 0	reward = 0.717625	array([[  3.2294512, -48.604763 ]], dtype=float32)
time = 70925	action = 0	current_phase = 1	next_phase = 0	reward = 0.708091	array([[  3.3203802, -48.37285  ]], dtype=float32)
time = 70930	action = 0	current_phase = 1	next_phase = 0	reward = 0.440811	array([[  3.1704245, -48.65236  ]], dtype=float32)
time = 70935	action = 0	current_phase = 1	next_phase = 0	reward = 1.011286	array([[  3.3113356, -48.3434   ]], dtype=float32)
time = 70940	action = 0	current_phase = 1	next_phase = 0	reward = 0.723248	array([[  3.3300753, -48.515396 ]], dtype=float32)
time = 70945	action = 0	current_phase = 1	next_phase = 0	reward = 0.723368	array([[  3.2931852, -48.238995 ]], dtype=float32)
time = 70950	action = 0	current_phase = 1	next_phase = 0	reward = 0.724031	array([[  3.3186178, -48.396866 ]], dtype=float32)
time = 70955	action = 0	current_phase = 1	next_phase = 0	reward = 0.721626	array([[  3.291541, -48.535545]], dtype=float32)
time = 70960	action = 0	current_phase = 1	next_phase = 0	reward = 0.717247	array([[  3.1076212, -48.66948  ]], dtype=float32)
time = 70965	action = 0	current_phase = 1	next_phase = 0	reward = 0.446557	array([[  3.219346, -48.631638]], dtype=float32)
time = 70970	action = 0	current_phase = 1	next_phase = 0	reward = 1.004949	array([[  3.1170015, -48.669044 ]], dtype=float32)
time = 70975	action = 0	current_phase = 1	next_phase = 0	reward = 0.715666	array([[  3.3201094, -48.49543  ]], dtype=float32)
time = 70980	action = 0	current_phase = 1	next_phase = 0	reward = 0.721720	array([[  3.304185, -48.517555]], dtype=float32)
time = 70985	action = 0	current_phase = 1	next_phase = 0	reward = 0.714002	array([[  3.296979, -48.490974]], dtype=float32)
time = 70990	action = 0	current_phase = 1	next_phase = 0	reward = 0.719561	array([[  3.3177423, -48.49295  ]], dtype=float32)
time = 70995	action = 0	current_phase = 1	next_phase = 0	reward = 0.710997	array([[  3.3223066, -48.37449  ]], dtype=float32)
time = 71000	action = 0	current_phase = 1	next_phase = 0	reward = 0.721026	array([[  3.2636213, -48.575718 ]], dtype=float32)
time = 71005	action = 0	current_phase = 1	next_phase = 0	reward = 0.436227	array([[  3.156392, -48.643703]], dtype=float32)
time = 71010	action = 0	current_phase = 1	next_phase = 0	reward = 0.721404	array([[  3.3023481, -48.54052  ]], dtype=float32)
time = 71015	action = 0	current_phase = 1	next_phase = 0	reward = 0.728824	array([[  3.3172255, -48.49817  ]], dtype=float32)
time = 71020	action = 0	current_phase = 1	next_phase = 0	reward = 1.003454	array([[  3.3244429, -48.40502  ]], dtype=float32)
time = 71025	action = 0	current_phase = 1	next_phase = 0	reward = 0.719789	array([[  3.3287954, -48.46505  ]], dtype=float32)
time = 71030	action = 0	current_phase = 1	next_phase = 0	reward = 0.442275	array([[  3.277091, -48.578705]], dtype=float32)
time = 71035	action = 0	current_phase = 1	next_phase = 0	reward = 1.001461	array([[  3.322547, -48.422684]], dtype=float32)
time = 71040	action = 0	current_phase = 1	next_phase = 0	reward = 0.717667	array([[  3.2943926, -48.526123 ]], dtype=float32)
time = 71045	action = 0	current_phase = 1	next_phase = 0	reward = 0.439212	array([[  3.228713, -48.5766  ]], dtype=float32)
time = 71050	action = 0	current_phase = 1	next_phase = 0	reward = 1.011287	array([[  3.3101873, -48.318653 ]], dtype=float32)
time = 71055	action = 0	current_phase = 1	next_phase = 0	reward = 0.713579	array([[  3.3209143, -48.46116  ]], dtype=float32)
time = 71060	action = 0	current_phase = 1	next_phase = 0	reward = 0.721594	array([[  3.0656996, -48.680172 ]], dtype=float32)
time = 71065	action = 0	current_phase = 1	next_phase = 0	reward = 0.441731	array([[  3.223956, -48.626442]], dtype=float32)
time = 71070	action = 0	current_phase = 1	next_phase = 0	reward = 0.993988	array([[  3.309081, -48.53231 ]], dtype=float32)
time = 71075	action = 0	current_phase = 1	next_phase = 0	reward = 0.717462	array([[  3.281623, -48.56775 ]], dtype=float32)
time = 71080	action = 0	current_phase = 1	next_phase = 0	reward = 0.721284	array([[  3.2745047, -48.58864  ]], dtype=float32)
time = 71085	action = 0	current_phase = 1	next_phase = 0	reward = 0.710584	array([[  3.3223734, -48.41075  ]], dtype=float32)
time = 71090	action = 0	current_phase = 1	next_phase = 0	reward = 0.446138	array([[  3.2457342, -48.626587 ]], dtype=float32)
time = 71095	action = 0	current_phase = 1	next_phase = 0	reward = 0.732277	array([[  3.3236094, -48.47651  ]], dtype=float32)
time = 71100	action = 0	current_phase = 1	next_phase = 0	reward = 1.002752	array([[  3.092946, -48.670837]], dtype=float32)
time = 71105	action = 0	current_phase = 1	next_phase = 0	reward = 0.719159	array([[  3.3200655, -48.344765 ]], dtype=float32)
time = 71110	action = 0	current_phase = 1	next_phase = 0	reward = 0.434842	array([[  3.159751, -48.640224]], dtype=float32)
time = 71115	action = 0	current_phase = 1	next_phase = 0	reward = 1.004938	array([[  3.3264265, -48.411964 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2054.7582 - val_loss: 322.8060
Epoch 2/50
 - 4s - loss: 2066.0156 - val_loss: 202.5509
Epoch 3/50
 - 4s - loss: 2016.6367 - val_loss: 222.5691
Epoch 4/50
 - 4s - loss: 2001.9424 - val_loss: 207.5075
Epoch 5/50
 - 4s - loss: 2006.4930 - val_loss: 217.0573
Epoch 6/50
 - 4s - loss: 1989.1401 - val_loss: 221.3168
Epoch 7/50
 - 4s - loss: 1979.8150 - val_loss: 205.0905
Epoch 8/50
 - 4s - loss: 1999.4641 - val_loss: 208.7926
Epoch 9/50
 - 4s - loss: 1997.9027 - val_loss: 278.7692
Epoch 10/50
 - 4s - loss: 2024.2993 - val_loss: 229.3538
Epoch 11/50
 - 4s - loss: 1983.7316 - val_loss: 215.7642
Epoch 12/50
 - 4s - loss: 2029.5794 - val_loss: 233.9855
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 71120	action = 0	current_phase = 1	next_phase = 0	reward = 0.722272	array([[  3.2121153, -48.50853  ]], dtype=float32)
time = 71125	action = 0	current_phase = 1	next_phase = 0	reward = 0.723301	array([[  3.228322, -48.39405 ]], dtype=float32)
time = 71130	action = 0	current_phase = 1	next_phase = 0	reward = 0.723735	array([[  3.2164354, -48.33542  ]], dtype=float32)
time = 71135	action = 0	current_phase = 1	next_phase = 0	reward = 0.726621	array([[  3.212018, -48.51059 ]], dtype=float32)
time = 71140	action = 0	current_phase = 1	next_phase = 0	reward = 0.723468	array([[  3.2201967, -48.396507 ]], dtype=float32)
time = 71145	action = 0	current_phase = 1	next_phase = 0	reward = 0.721004	array([[  3.0810404, -48.641075 ]], dtype=float32)
time = 71150	action = 0	current_phase = 1	next_phase = 0	reward = 0.727909	array([[  3.2214708, -48.34733  ]], dtype=float32)
time = 71155	action = 0	current_phase = 1	next_phase = 0	reward = 0.716959	array([[  3.2132578, -48.491306 ]], dtype=float32)
time = 71160	action = 0	current_phase = 1	next_phase = 0	reward = 0.720114	array([[  3.1848383, -48.554794 ]], dtype=float32)
time = 71165	action = 0	current_phase = 1	next_phase = 0	reward = 0.717437	array([[  3.1740618, -48.548946 ]], dtype=float32)
time = 71170	action = 0	current_phase = 1	next_phase = 0	reward = 0.717245	array([[  3.1874895, -48.55832  ]], dtype=float32)
time = 71175	action = 0	current_phase = 1	next_phase = 0	reward = 0.440848	array([[  3.2076464, -48.527885 ]], dtype=float32)
time = 71180	action = 0	current_phase = 1	next_phase = 0	reward = 1.000665	array([[  3.2090902, -48.504456 ]], dtype=float32)
time = 71185	action = 0	current_phase = 1	next_phase = 0	reward = 0.720736	array([[  3.0741282, -48.634315 ]], dtype=float32)
time = 71190	action = 0	current_phase = 1	next_phase = 0	reward = 0.723329	array([[  3.2259417, -48.386787 ]], dtype=float32)
time = 71195	action = 0	current_phase = 1	next_phase = 0	reward = 0.722169	array([[  3.2209044, -48.3554   ]], dtype=float32)
time = 71200	action = 0	current_phase = 1	next_phase = 0	reward = 0.446315	array([[  3.2254095, -48.461353 ]], dtype=float32)
time = 71205	action = 0	current_phase = 1	next_phase = 0	reward = 1.007173	array([[  3.2426577, -48.378292 ]], dtype=float32)
time = 71210	action = 0	current_phase = 1	next_phase = 0	reward = 0.721449	array([[  3.2338362, -48.428013 ]], dtype=float32)
time = 71215	action = 0	current_phase = 1	next_phase = 0	reward = 0.727251	array([[  3.2189302, -48.43863  ]], dtype=float32)
time = 71220	action = 0	current_phase = 1	next_phase = 0	reward = 0.717703	array([[  3.2235556, -48.38592  ]], dtype=float32)
time = 71225	action = 0	current_phase = 1	next_phase = 0	reward = 0.725502	array([[  3.2087774, -48.50009  ]], dtype=float32)
time = 71230	action = 0	current_phase = 1	next_phase = 0	reward = 0.443088	array([[  3.2274733, -48.386864 ]], dtype=float32)
time = 71235	action = 0	current_phase = 1	next_phase = 0	reward = 1.006083	array([[  3.223609, -48.428574]], dtype=float32)
time = 71240	action = 0	current_phase = 1	next_phase = 0	reward = 0.716840	array([[  3.2092104, -48.494682 ]], dtype=float32)
time = 71245	action = 0	current_phase = 1	next_phase = 0	reward = 0.443621	array([[  3.211339, -48.488895]], dtype=float32)
time = 71250	action = 0	current_phase = 1	next_phase = 0	reward = 1.008041	array([[  3.2139769, -48.376305 ]], dtype=float32)
time = 71255	action = 0	current_phase = 1	next_phase = 0	reward = 0.717552	array([[  3.2219858, -48.337967 ]], dtype=float32)
time = 71260	action = 0	current_phase = 1	next_phase = 0	reward = 0.715390	array([[  3.2214231, -48.350693 ]], dtype=float32)
time = 71265	action = 0	current_phase = 1	next_phase = 0	reward = 0.440918	array([[  3.2090483, -48.272636 ]], dtype=float32)
time = 71270	action = 0	current_phase = 1	next_phase = 0	reward = 0.998803	array([[  3.1928663, -48.524788 ]], dtype=float32)
time = 71275	action = 0	current_phase = 1	next_phase = 0	reward = 0.446940	array([[  3.1272955, -48.61757  ]], dtype=float32)
time = 71280	action = 0	current_phase = 1	next_phase = 0	reward = 0.727380	array([[  3.2201242, -48.313313 ]], dtype=float32)
time = 71285	action = 0	current_phase = 1	next_phase = 0	reward = 1.006366	array([[  3.2261515, -48.441917 ]], dtype=float32)
time = 71290	action = 0	current_phase = 1	next_phase = 0	reward = 0.721354	array([[  3.1612997, -48.588783 ]], dtype=float32)
time = 71295	action = 0	current_phase = 1	next_phase = 0	reward = 0.714639	array([[  3.2151365, -48.30175  ]], dtype=float32)
time = 71300	action = 0	current_phase = 1	next_phase = 0	reward = 0.712705	array([[  3.19773 , -48.532387]], dtype=float32)
time = 71305	action = 0	current_phase = 1	next_phase = 0	reward = 0.724188	array([[  3.2217722, -48.41719  ]], dtype=float32)
time = 71310	action = 0	current_phase = 1	next_phase = 0	reward = 0.727007	array([[  3.2198706, -48.32952  ]], dtype=float32)
time = 71315	action = 0	current_phase = 1	next_phase = 0	reward = 0.728112	array([[  3.2093344, -48.471375 ]], dtype=float32)
time = 71320	action = 0	current_phase = 1	next_phase = 0	reward = 0.719537	array([[  3.2167406, -48.498127 ]], dtype=float32)
time = 71325	action = 0	current_phase = 1	next_phase = 0	reward = 0.718281	array([[  3.1445646, -48.58277  ]], dtype=float32)
time = 71330	action = 0	current_phase = 1	next_phase = 0	reward = 0.714057	array([[  3.2247686, -48.41311  ]], dtype=float32)
time = 71335	action = 0	current_phase = 1	next_phase = 0	reward = 0.725585	array([[  3.221427, -48.302437]], dtype=float32)
time = 71340	action = 0	current_phase = 1	next_phase = 0	reward = 0.720399	array([[  3.2158308, -48.32601  ]], dtype=float32)
time = 71345	action = 0	current_phase = 1	next_phase = 0	reward = 0.717596	array([[  3.1772451, -48.562225 ]], dtype=float32)
time = 71350	action = 0	current_phase = 1	next_phase = 0	reward = 0.441136	array([[  3.222886, -48.362404]], dtype=float32)
time = 71355	action = 0	current_phase = 1	next_phase = 0	reward = 1.004983	array([[  3.2255297, -48.365967 ]], dtype=float32)
time = 71360	action = 0	current_phase = 1	next_phase = 0	reward = 0.723081	array([[  3.2097197, -48.522663 ]], dtype=float32)
time = 71365	action = 0	current_phase = 1	next_phase = 0	reward = 0.723526	array([[  3.1580515, -48.4676   ]], dtype=float32)
time = 71370	action = 0	current_phase = 1	next_phase = 0	reward = 0.719482	array([[  3.2288046, -48.396233 ]], dtype=float32)
time = 71375	action = 0	current_phase = 1	next_phase = 0	reward = 0.728994	array([[  3.2150412, -48.309746 ]], dtype=float32)
time = 71380	action = 0	current_phase = 1	next_phase = 0	reward = 0.725621	array([[  3.2109022, -48.493935 ]], dtype=float32)
time = 71385	action = 0	current_phase = 1	next_phase = 0	reward = 0.714003	array([[  3.22194 , -48.461502]], dtype=float32)
time = 71390	action = 0	current_phase = 1	next_phase = 0	reward = 0.714008	array([[  3.2178335, -48.302536 ]], dtype=float32)
time = 71395	action = 0	current_phase = 1	next_phase = 0	reward = 0.716194	array([[  3.2164946, -48.426437 ]], dtype=float32)
time = 71400	action = 0	current_phase = 1	next_phase = 0	reward = 0.713290	array([[  3.222642, -48.409016]], dtype=float32)
time = 71405	action = 0	current_phase = 1	next_phase = 0	reward = 0.722858	array([[  3.2241678, -48.428795 ]], dtype=float32)
time = 71410	action = 0	current_phase = 1	next_phase = 0	reward = 0.725033	array([[  3.2153025, -48.318222 ]], dtype=float32)
time = 71415	action = 0	current_phase = 1	next_phase = 0	reward = 0.443715	array([[  3.1118593, -48.401623 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 1999.5446 - val_loss: 312.5900
Epoch 2/50
 - 4s - loss: 2017.6160 - val_loss: 282.1873
Epoch 3/50
 - 4s - loss: 1976.5978 - val_loss: 296.9057
Epoch 4/50
 - 4s - loss: 1986.7989 - val_loss: 290.9364
Epoch 5/50
 - 4s - loss: 1973.6385 - val_loss: 290.1847
Epoch 6/50
 - 4s - loss: 1971.2276 - val_loss: 292.2857
Epoch 7/50
 - 4s - loss: 1992.1786 - val_loss: 302.0909
Epoch 8/50
 - 4s - loss: 1981.1627 - val_loss: 278.0846
Epoch 9/50
 - 4s - loss: 1998.6560 - val_loss: 290.8550
Epoch 10/50
 - 4s - loss: 1973.6850 - val_loss: 272.8081
Epoch 11/50
 - 4s - loss: 1971.5534 - val_loss: 273.7322
Epoch 12/50
 - 4s - loss: 1987.8847 - val_loss: 335.7782
Epoch 13/50
 - 4s - loss: 1972.3061 - val_loss: 320.9052
Epoch 14/50
 - 4s - loss: 1978.4908 - val_loss: 276.2988
Epoch 15/50
 - 4s - loss: 1960.1739 - val_loss: 289.6836
Epoch 16/50
 - 4s - loss: 1997.0824 - val_loss: 310.7239
Epoch 17/50
 - 4s - loss: 1978.0968 - val_loss: 340.4275
Epoch 18/50
 - 4s - loss: 1998.5229 - val_loss: 389.7462
Epoch 19/50
 - 4s - loss: 2019.9943 - val_loss: 304.1108
Epoch 20/50
 - 4s - loss: 2003.5348 - val_loss: 304.2597
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 71420	action = 0	current_phase = 1	next_phase = 0	reward = 1.001731	array([[  3.102934, -48.661644]], dtype=float32)
time = 71425	action = 0	current_phase = 1	next_phase = 0	reward = 0.442063	array([[  3.0934372, -48.694008 ]], dtype=float32)
time = 71430	action = 0	current_phase = 1	next_phase = 0	reward = 0.999143	array([[  3.1782722, -48.54802  ]], dtype=float32)
time = 71435	action = 0	current_phase = 1	next_phase = 0	reward = 0.718639	array([[  3.173523, -48.5452  ]], dtype=float32)
time = 71440	action = 0	current_phase = 1	next_phase = 0	reward = 0.724139	array([[  3.1625137, -48.57837  ]], dtype=float32)
time = 71445	action = 0	current_phase = 1	next_phase = 0	reward = 0.446251	array([[  2.9898987, -48.73516  ]], dtype=float32)
time = 71450	action = 0	current_phase = 1	next_phase = 0	reward = 1.017291	array([[  3.0842628, -48.701935 ]], dtype=float32)
time = 71455	action = 0	current_phase = 1	next_phase = 0	reward = 0.729222	array([[  3.1928902, -48.512493 ]], dtype=float32)
time = 71460	action = 0	current_phase = 1	next_phase = 0	reward = 0.728406	array([[  3.0146217, -48.573135 ]], dtype=float32)
time = 71465	action = 0	current_phase = 1	next_phase = 0	reward = 0.713879	array([[  2.9759636, -48.716095 ]], dtype=float32)
time = 71470	action = 0	current_phase = 1	next_phase = 0	reward = 0.706377	array([[  3.0774517, -48.702034 ]], dtype=float32)
time = 71475	action = 0	current_phase = 1	next_phase = 0	reward = 0.716067	array([[  3.1450882, -48.612938 ]], dtype=float32)
time = 71480	action = 0	current_phase = 1	next_phase = 0	reward = 0.718672	array([[  2.9912949, -48.76149  ]], dtype=float32)
time = 71485	action = 0	current_phase = 1	next_phase = 0	reward = 0.450319	array([[  3.1839027, -48.530136 ]], dtype=float32)
time = 71490	action = 0	current_phase = 1	next_phase = 0	reward = 1.002741	array([[  2.9693012, -48.77297  ]], dtype=float32)
time = 71495	action = 0	current_phase = 1	next_phase = 0	reward = 0.715758	array([[  3.1220207, -48.642956 ]], dtype=float32)
time = 71500	action = 0	current_phase = 1	next_phase = 0	reward = 0.437657	array([[  2.979515, -48.771095]], dtype=float32)
time = 71505	action = 0	current_phase = 1	next_phase = 0	reward = 0.998065	array([[  2.6445904, -48.46184  ]], dtype=float32)
time = 71510	action = 0	current_phase = 1	next_phase = 0	reward = 0.727219	array([[  3.0989952, -48.694145 ]], dtype=float32)
time = 71515	action = 0	current_phase = 1	next_phase = 0	reward = 0.719330	array([[  3.1953201, -48.494843 ]], dtype=float32)
time = 71520	action = 0	current_phase = 1	next_phase = 0	reward = 0.716568	array([[  3.0474281, -48.72669  ]], dtype=float32)
time = 71525	action = 0	current_phase = 1	next_phase = 0	reward = 0.724520	array([[  3.1488495, -48.60063  ]], dtype=float32)
time = 71530	action = 0	current_phase = 1	next_phase = 0	reward = 0.726809	array([[  3.1886864, -48.59236  ]], dtype=float32)
time = 71535	action = 0	current_phase = 1	next_phase = 0	reward = 0.718644	array([[  3.1747398, -48.40186  ]], dtype=float32)
time = 71540	action = 0	current_phase = 1	next_phase = 0	reward = 0.717549	array([[  3.0357552, -48.665527 ]], dtype=float32)
time = 71545	action = 0	current_phase = 1	next_phase = 0	reward = 0.716052	array([[  3.0628338, -48.716637 ]], dtype=float32)
time = 71550	action = 0	current_phase = 1	next_phase = 0	reward = 0.718199	array([[  3.1052513, -48.688038 ]], dtype=float32)
time = 71555	action = 0	current_phase = 1	next_phase = 0	reward = 0.725365	array([[  3.1316948, -48.598892 ]], dtype=float32)
time = 71560	action = 0	current_phase = 1	next_phase = 0	reward = 0.719578	array([[  2.6483402, -47.956657 ]], dtype=float32)
time = 71565	action = 0	current_phase = 1	next_phase = 0	reward = 0.441299	array([[  3.0987625, -48.692795 ]], dtype=float32)
time = 71570	action = 0	current_phase = 1	next_phase = 0	reward = 1.001649	array([[  2.8981094, -48.7878   ]], dtype=float32)
time = 71575	action = 0	current_phase = 1	next_phase = 0	reward = 0.724199	array([[  3.075592, -48.65686 ]], dtype=float32)
time = 71580	action = 0	current_phase = 1	next_phase = 0	reward = 0.728149	array([[  3.1522617, -48.646133 ]], dtype=float32)
time = 71585	action = 0	current_phase = 1	next_phase = 0	reward = 0.714858	array([[  3.160593, -48.60246 ]], dtype=float32)
time = 71590	action = 0	current_phase = 1	next_phase = 0	reward = 0.721648	array([[  3.05933, -48.73099]], dtype=float32)
time = 71595	action = 0	current_phase = 1	next_phase = 0	reward = 0.445498	array([[  3.0445652, -48.69263  ]], dtype=float32)
time = 71600	action = 0	current_phase = 1	next_phase = 0	reward = 1.006326	array([[  3.1440086, -48.64819  ]], dtype=float32)
time = 71605	action = 0	current_phase = 1	next_phase = 0	reward = 0.442653	array([[  3.0069675, -48.761917 ]], dtype=float32)
time = 71610	action = 0	current_phase = 1	next_phase = 0	reward = 0.993733	array([[  3.1047554, -48.58532  ]], dtype=float32)
time = 71615	action = 0	current_phase = 1	next_phase = 0	reward = 0.717620	array([[  3.1597328, -48.624516 ]], dtype=float32)
time = 71620	action = 0	current_phase = 1	next_phase = 0	reward = 0.440869	array([[  3.1733723, -48.574795 ]], dtype=float32)
time = 71625	action = 0	current_phase = 1	next_phase = 0	reward = 1.003909	array([[  3.1354885, -48.660435 ]], dtype=float32)
time = 71630	action = 0	current_phase = 1	next_phase = 0	reward = 0.716403	array([[  3.193962, -48.49218 ]], dtype=float32)
time = 71635	action = 0	current_phase = 1	next_phase = 0	reward = 0.720518	array([[  3.0886917, -48.671722 ]], dtype=float32)
time = 71640	action = 0	current_phase = 1	next_phase = 0	reward = 0.450048	array([[  3.1693916, -48.619293 ]], dtype=float32)
time = 71645	action = 0	current_phase = 1	next_phase = 0	reward = 0.734083	array([[  3.1454926, -48.653374 ]], dtype=float32)
time = 71650	action = 0	current_phase = 1	next_phase = 0	reward = 1.007133	array([[  2.9623604, -48.74769  ]], dtype=float32)
time = 71655	action = 0	current_phase = 1	next_phase = 0	reward = 0.715322	array([[  3.1856956, -48.557564 ]], dtype=float32)
time = 71660	action = 0	current_phase = 1	next_phase = 0	reward = 0.716800	array([[  2.9682274, -48.768856 ]], dtype=float32)
time = 71665	action = 0	current_phase = 1	next_phase = 0	reward = 0.709163	array([[  3.0982304, -48.627365 ]], dtype=float32)
time = 71670	action = 0	current_phase = 1	next_phase = 0	reward = 0.723484	array([[  3.103386, -48.685112]], dtype=float32)
time = 71675	action = 0	current_phase = 1	next_phase = 0	reward = 0.444533	array([[  3.163372, -48.59913 ]], dtype=float32)
time = 71680	action = 0	current_phase = 1	next_phase = 0	reward = 1.002595	array([[  3.0401287, -48.716286 ]], dtype=float32)
time = 71685	action = 0	current_phase = 1	next_phase = 0	reward = 0.719544	array([[  3.1676922, -48.62559  ]], dtype=float32)
time = 71690	action = 0	current_phase = 1	next_phase = 0	reward = 0.710886	array([[  2.9978313, -48.57843  ]], dtype=float32)
time = 71695	action = 0	current_phase = 1	next_phase = 0	reward = 0.436247	array([[  2.8521233, -48.354923 ]], dtype=float32)
time = 71700	action = 0	current_phase = 1	next_phase = 0	reward = 0.727275	array([[  3.0701256, -48.68344  ]], dtype=float32)
time = 71705	action = 0	current_phase = 1	next_phase = 0	reward = 0.724627	array([[  3.1985912, -48.4877   ]], dtype=float32)
time = 71710	action = 0	current_phase = 1	next_phase = 0	reward = 0.722604	array([[  3.1406631, -48.65693  ]], dtype=float32)
time = 71715	action = 0	current_phase = 1	next_phase = 0	reward = 0.996516	array([[  2.9902973, -48.691525 ]], dtype=float32)
Train on 840 samples, validate on 360 samples
Epoch 1/50
 - 4s - loss: 2121.6813 - val_loss: 297.1357
Epoch 2/50
 - 4s - loss: 2124.6060 - val_loss: 218.3261
Epoch 3/50
 - 4s - loss: 2114.6625 - val_loss: 251.3391
Epoch 4/50
 - 4s - loss: 2111.1113 - val_loss: 223.6643
Epoch 5/50
 - 4s - loss: 2129.8064 - val_loss: 293.0997
Epoch 6/50
 - 4s - loss: 2159.9490 - val_loss: 212.0632
Epoch 7/50
 - 4s - loss: 2143.9354 - val_loss: 211.7415
Epoch 8/50
 - 4s - loss: 2095.1008 - val_loss: 254.7990
Epoch 9/50
 - 4s - loss: 2109.3616 - val_loss: 258.7011
Epoch 10/50
 - 4s - loss: 2127.8733 - val_loss: 281.7577
Epoch 11/50
 - 4s - loss: 2143.6779 - val_loss: 251.0481
Epoch 12/50
 - 4s - loss: 2149.6010 - val_loss: 221.1184
Epoch 13/50
 - 4s - loss: 2115.5879 - val_loss: 237.2510
Epoch 14/50
 - 4s - loss: 2173.2023 - val_loss: 242.2371
Epoch 15/50
 - 4s - loss: 2135.3477 - val_loss: 232.5185
Epoch 16/50
 - 4s - loss: 2115.6002 - val_loss: 262.8030
Epoch 17/50
 - 4s - loss: 2157.4539 - val_loss: 282.1891
length of memory (state 0, action 0): 1000, after forget
length of memory (state 0, action 1): 381, after forget
length of memory (state 1, action 0): 1060, before forget
length of memory (state 1, action 0): 1000, after forget
length of memory (state 1, action 1): 368, after forget
time = 71720	action = 0	current_phase = 1	next_phase = 0	reward = 0.440047	array([[  3.1242733, -48.934334 ]], dtype=float32)
time = 71725	action = 0	current_phase = 1	next_phase = 0	reward = 1.000964	array([[  3.3268127, -48.78453  ]], dtype=float32)
time = 71730	action = 0	current_phase = 1	next_phase = 0	reward = 0.443155	array([[  3.3222961, -48.833076 ]], dtype=float32)
time = 71735	action = 0	current_phase = 1	next_phase = 0	reward = 0.715719	array([[  3.2925243, -48.76773  ]], dtype=float32)
time = 71740	action = 0	current_phase = 1	next_phase = 0	reward = 0.717624	array([[  3.3116913, -48.64902  ]], dtype=float32)
time = 71745	action = 0	current_phase = 1	next_phase = 0	reward = 0.724044	array([[  3.2436428, -48.70456  ]], dtype=float32)
time = 71750	action = 0	current_phase = 1	next_phase = 0	reward = 0.729119	array([[  3.3236198, -48.820953 ]], dtype=float32)
time = 71755	action = 0	current_phase = 1	next_phase = 0	reward = 1.001584	array([[  3.308155, -48.684708]], dtype=float32)
time = 71760	action = 0	current_phase = 1	next_phase = 0	reward = 0.714048	array([[  3.3061485, -48.657524 ]], dtype=float32)
time = 71765	action = 0	current_phase = 1	next_phase = 0	reward = 0.725424	array([[  3.2004395, -49.01172  ]], dtype=float32)
time = 71770	action = 0	current_phase = 1	next_phase = 0	reward = 0.723392	array([[  3.1015873, -48.553642 ]], dtype=float32)
time = 71775	action = 0	current_phase = 1	next_phase = 0	reward = 0.717348	array([[  3.3286362, -48.718796 ]], dtype=float32)
time = 71780	action = 0	current_phase = 1	next_phase = 0	reward = 0.714143	array([[  3.27244, -48.81783]], dtype=float32)
time = 71785	action = 0	current_phase = 1	next_phase = 0	reward = 0.438831	array([[  3.193945, -48.54084 ]], dtype=float32)
time = 71790	action = 0	current_phase = 1	next_phase = 0	reward = 1.001780	array([[  3.321144, -48.846558]], dtype=float32)
time = 71795	action = 0	current_phase = 1	next_phase = 0	reward = 0.715844	array([[  3.3050327, -48.63835  ]], dtype=float32)
time = 71800	action = 0	current_phase = 1	next_phase = 0	reward = 0.440756	array([[  3.1923923, -48.552025 ]], dtype=float32)
time = 71805	action = 0	current_phase = 1	next_phase = 0	reward = 1.002709	array([[  3.2060394, -48.956505 ]], dtype=float32)
time = 71810	action = 0	current_phase = 1	next_phase = 0	reward = 0.720236	array([[  3.3184395, -48.777725 ]], dtype=float32)
time = 71815	action = 0	current_phase = 1	next_phase = 0	reward = 0.441551	array([[  3.3262634, -48.761063 ]], dtype=float32)
time = 71820	action = 0	current_phase = 1	next_phase = 0	reward = 0.999874	array([[  3.3288116, -48.699406 ]], dtype=float32)
time = 71825	action = 0	current_phase = 1	next_phase = 0	reward = 0.717233	array([[  3.0507965, -49.011013 ]], dtype=float32)
time = 71830	action = 0	current_phase = 1	next_phase = 0	reward = 0.720147	array([[  3.259016, -48.482742]], dtype=float32)
time = 71835	action = 0	current_phase = 1	next_phase = 0	reward = 0.441255	array([[  3.3293476, -48.807976 ]], dtype=float32)
time = 71840	action = 0	current_phase = 1	next_phase = 0	reward = 0.723084	array([[  3.1334553, -48.916916 ]], dtype=float32)
time = 71845	action = 0	current_phase = 1	next_phase = 0	reward = 1.004694	array([[  3.3154755, -48.657692 ]], dtype=float32)
time = 71850	action = 0	current_phase = 1	next_phase = 0	reward = 0.722699	array([[  3.3147144, -48.8571   ]], dtype=float32)
time = 71855	action = 0	current_phase = 1	next_phase = 0	reward = 0.720246	array([[  3.2397842, -48.741646 ]], dtype=float32)
time = 71860	action = 0	current_phase = 1	next_phase = 0	reward = 0.716840	array([[  3.2943478, -48.642788 ]], dtype=float32)
time = 71865	action = 0	current_phase = 1	next_phase = 0	reward = 0.715128	array([[  3.3072758, -48.64695  ]], dtype=float32)
time = 71870	action = 0	current_phase = 1	next_phase = 0	reward = 0.713731	array([[  3.2980366, -48.59664  ]], dtype=float32)
time = 71875	action = 0	current_phase = 1	next_phase = 0	reward = 0.715938	array([[  3.2611637, -48.758316 ]], dtype=float32)
time = 71880	action = 0	current_phase = 1	next_phase = 0	reward = 0.437799	array([[  3.3337555, -48.798542 ]], dtype=float32)
time = 71885	action = 0	current_phase = 1	next_phase = 0	reward = 0.998522	array([[  3.2804756, -48.93905  ]], dtype=float32)
time = 71890	action = 0	current_phase = 1	next_phase = 0	reward = 0.725237	array([[  2.908678, -48.842293]], dtype=float32)
time = 71895	action = 0	current_phase = 1	next_phase = 0	reward = 0.720259	array([[  3.2758064, -48.51375  ]], dtype=float32)
time = 71900	action = 0	current_phase = 1	next_phase = 0	reward = 0.715562	array([[  3.0821247, -48.41075  ]], dtype=float32)
time = 71905	action = 0	current_phase = 1	next_phase = 0	reward = 0.723782	array([[  3.1436768, -49.008423 ]], dtype=float32)
time = 71910	action = 0	current_phase = 1	next_phase = 0	reward = 0.444774	array([[  3.312252, -48.790462]], dtype=float32)
time = 71915	action = 0	current_phase = 1	next_phase = 0	reward = 1.002077	array([[  3.3140125, -48.738323 ]], dtype=float32)
time = 71920	action = 0	current_phase = 1	next_phase = 0	reward = 0.719164	array([[  3.2747726, -48.736168 ]], dtype=float32)
time = 71925	action = 0	current_phase = 1	next_phase = 0	reward = 0.718158	array([[  3.271021, -48.82348 ]], dtype=float32)
time = 71930	action = 0	current_phase = 1	next_phase = 0	reward = 0.722395	array([[  3.3060188, -48.795357 ]], dtype=float32)
time = 71935	action = 0	current_phase = 1	next_phase = 0	reward = 0.721700	array([[  3.2935123, -48.911232 ]], dtype=float32)
time = 71940	action = 0	current_phase = 1	next_phase = 0	reward = 0.720866	array([[  3.317625, -48.68519 ]], dtype=float32)
time = 71945	action = 0	current_phase = 1	next_phase = 0	reward = 0.730554	array([[  3.1270046, -49.0478   ]], dtype=float32)
time = 71950	action = 0	current_phase = 1	next_phase = 0	reward = 0.724699	array([[  3.2935467, -48.860485 ]], dtype=float32)
time = 71955	action = 0	current_phase = 1	next_phase = 0	reward = 0.438268	array([[  3.3152313, -48.77576  ]], dtype=float32)
time = 71960	action = 0	current_phase = 1	next_phase = 0	reward = 0.998378	array([[  3.3301125, -48.808266 ]], dtype=float32)
time = 71965	action = 0	current_phase = 1	next_phase = 0	reward = 0.714839	array([[  3.3164024, -48.813354 ]], dtype=float32)
time = 71970	action = 0	current_phase = 1	next_phase = 0	reward = 0.725695	array([[  3.1825829, -48.949524 ]], dtype=float32)
time = 71975	action = 0	current_phase = 1	next_phase = 0	reward = 0.727877	array([[  3.205799, -48.79199 ]], dtype=float32)
time = 71980	action = 0	current_phase = 1	next_phase = 0	reward = 0.722519	array([[  3.3246422, -48.724533 ]], dtype=float32)
time = 71985	action = 0	current_phase = 1	next_phase = 0	reward = 0.720234	array([[  3.2685738, -48.705795 ]], dtype=float32)
time = 71990	action = 0	current_phase = 1	next_phase = 0	reward = 0.729298	array([[  3.295847, -48.80802 ]], dtype=float32)
time = 71995	action = 0	current_phase = 1	next_phase = 0	reward = 0.722531	array([[  3.318985, -48.706154]], dtype=float32)
END
finished ['cross.2phases_rou1_switch_rou0.xml']
finished Deeplight
Error: tcpip::Socket::recvAndCheck @ recv: peer shutdown
Quitting (on error).
