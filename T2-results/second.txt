Script started on 2021-07-07 11:50:27+10:00 [TERM="xterm-256color" TTY="/dev/pts/1" COLUMNS="126" LINES="24"]

(base) ]0;soup@soup-virtual-machine: ~/IntelliLight[01;32msoup@soup-virtual-machine[00m:[01;34m~/IntelliLight[00m$ conda activate venv3.5[K6

(venv3.6) ]0;soup@soup-virtual-machine: ~/IntelliLight[01;32msoup@soup-virtual-machine[00m:[01;34m~/IntelliLight[00m$ run [K[K[K[Koyt[K[K[Kpython runexp.py 

/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  _np_qint8 = np.dtype([("qint8", np.int8, 1)])

/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])

/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  _np_qint16 = np.dtype([("qint16", np.int16, 1)])

/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])

/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  _np_qint32 = np.dtype([("qint32", np.int32, 1)])

/home/soup/anaconda3/envs/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  np_resource = np.dtype([("resource", np.ubyte, 1)])

/home/soup/sumo-0.32.0/tools

Using TensorFlow backend.

2021-07-07 11:50:47.026314: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA

__________________________________________________________________________________________________

Layer (type)                    Output Shape         Param #     Connected to                     

==================================================================================================

input_map_feature (InputLayer)  (None, 150, 150, 1)  0                                            

__________________________________________________________________________________________________

conv1 (Conv2D)                  (None, 38, 38, 32)   2048        input_map_feature[0][0]          

__________________________________________________________________________________________________

bn1 (BatchNormalization)        (None, 38, 38, 32)   96          conv1[0][0]                      

__________________________________________________________________________________________________

act1 (Activation)               (None, 38, 38, 32)   0           bn1[0][0]                        

__________________________________________________________________________________________________

max_pooling2d_1 (MaxPooling2D)  (None, 19, 19, 32)   0           act1[0][0]                       

__________________________________________________________________________________________________

dropout_1 (Dropout)             (None, 19, 19, 32)   0           max_pooling2d_1[0][0]            

__________________________________________________________________________________________________

conv2 (Conv2D)                  (None, 10, 10, 16)   8192        dropout_1[0][0]                  

__________________________________________________________________________________________________

bn2 (BatchNormalization)        (None, 10, 10, 16)   48          conv2[0][0]                      

__________________________________________________________________________________________________

act2 (Activation)               (None, 10, 10, 16)   0           bn2[0][0]                        

__________________________________________________________________________________________________

max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 16)     0           act2[0][0]                       

__________________________________________________________________________________________________

dropout_2 (Dropout)             (None, 5, 5, 16)     0           max_pooling2d_2[0][0]            

__________________________________________________________________________________________________

input_cur_phase (InputLayer)    (None, 1)            0                                            

__________________________________________________________________________________________________

flatten_1 (Flatten)             (None, 400)          0           dropout_2[0][0]                  

__________________________________________________________________________________________________

input_next_phase (InputLayer)   (None, 1)            0                                            

__________________________________________________________________________________________________

input_num_of_vehicles (InputLay (None, 12)           0                                            

__________________________________________________________________________________________________

input_queue_length (InputLayer) (None, 12)           0                                            

__________________________________________________________________________________________________

input_waiting_time (InputLayer) (None, 12)           0                                            

__________________________________________________________________________________________________

all_flatten_feature (Concatenat (None, 438)          0           input_cur_phase[0][0]            

                                                                 flatten_1[0][0]                  

                                                                 input_next_phase[0][0]           

                                                                 input_num_of_vehicles[0][0]      

                                                                 input_queue_length[0][0]         

                                                                 input_waiting_time[0][0]         

__________________________________________________________________________________________________

hidden_shared_1 (Dense)         (None, 20)           8780        all_flatten_feature[0][0]        

__________________________________________________________________________________________________

hidden_separate_branch_0_1 (Den (None, 20)           420         hidden_shared_1[0][0]            

__________________________________________________________________________________________________

hidden_separate_branch_1_1 (Den (None, 20)           420         hidden_shared_1[0][0]            

__________________________________________________________________________________________________

q_values_separate_branch_0 (Den (None, 2)            42          hidden_separate_branch_0_1[0][0] 

__________________________________________________________________________________________________

selector_0 (Selector)           (None, 1)            0           input_cur_phase[0][0]            

__________________________________________________________________________________________________

q_values_separate_branch_1 (Den (None, 2)            42          hidden_separate_branch_1_1[0][0] 

__________________________________________________________________________________________________

selector_1 (Selector)           (None, 1)            0           input_cur_phase[0][0]            

__________________________________________________________________________________________________

multiply_0 (Multiply)           (None, 2)            0           q_values_separate_branch_0[0][0] 

                                                                 selector_0[0][0]                 

__________________________________________________________________________________________________

multiply_1 (Multiply)           (None, 2)            0           q_values_separate_branch_1[0][0] 

                                                                 selector_1[0][0]                 

__________________________________________________________________________________________________

add_1 (Add)                     (None, 2)            0           multiply_0[0][0]                 

                                                                 multiply_1[0][0]                 

==================================================================================================

Total params: 20,088

Trainable params: 19,992

Non-trainable params: 96

__________________________________________________________________________________________________

Could not connect to TraCI server at localhost:49359 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 49359 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (4ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (40ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (1ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.241148	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.436842	array([[1.0605273, 0.5609466]], dtype=float32)

time = 43	action = 1	current_phase = 1	next_phase = 0	reward = -1.383084	array([[1.0617688, 0.5633787]], dtype=float32)

time = 51	action = 0	current_phase = 0	next_phase = 1	reward = 0.298886	array([[-0.96808475, -0.17335865]], dtype=float32)

time = 56	action = 1	current_phase = 0	next_phase = 1	reward = -1.611393	array([[-0.97302115, -0.15916142]], dtype=float32)

time = 64	action = 0	current_phase = 1	next_phase = 0	reward = -0.563234	array([[1.0620819 , 0.56289965]], dtype=float32)

time = 69	action = 1	current_phase = 1	next_phase = 0	reward = -1.585063	array([[1.0603971, 0.5643584]], dtype=float32)

time = 77	action = 0	current_phase = 0	next_phase = 1	reward = -0.189993	array([[-0.9689843 , -0.17441389]], dtype=float32)

time = 82	action = 1	current_phase = 0	next_phase = 1	reward = -1.398941	array([[-0.96781206, -0.17413232]], dtype=float32)

time = 90	action = 0	current_phase = 1	next_phase = 0	reward = -1.734078	array([[1.061373 , 0.5663323]], dtype=float32)

time = 95	action = 1	current_phase = 1	next_phase = 0	reward = -1.875039	array([[1.0388786 , 0.57586133]], dtype=float32)

time = 103	action = 0	current_phase = 0	next_phase = 1	reward = -0.293677	array([[-0.980533  , -0.14323832]], dtype=float32)

time = 108	action = 1	current_phase = 0	next_phase = 1	reward = -0.786346	array([[-0.96815515, -0.17319337]], dtype=float32)

time = 116	action = 0	current_phase = 1	next_phase = 0	reward = -1.060231	array([[1.0696381 , 0.56499135]], dtype=float32)

time = 121	action = 1	current_phase = 1	next_phase = 0	reward = -2.062668	array([[1.0384725, 0.5753521]], dtype=float32)

time = 129	action = 0	current_phase = 0	next_phase = 1	reward = -0.396838	array([[-0.9796369 , -0.14278534]], dtype=float32)

time = 134	action = 1	current_phase = 0	next_phase = 1	reward = -1.341688	array([[-0.9685024 , -0.17342351]], dtype=float32)

time = 142	action = 0	current_phase = 1	next_phase = 0	reward = 0.249775	array([[1.060753 , 0.5631924]], dtype=float32)

time = 147	action = 1	current_phase = 1	next_phase = 0	reward = -1.732317	array([[1.0695987, 0.5646446]], dtype=float32)

time = 155	action = 0	current_phase = 0	next_phase = 1	reward = -0.539948	array([[-0.98019785, -0.14384171]], dtype=float32)

time = 160	action = 1	current_phase = 0	next_phase = 1	reward = -1.532650	array([[-0.968106  , -0.17252925]], dtype=float32)

time = 168	action = 0	current_phase = 1	next_phase = 0	reward = -0.170985	array([[1.0611656, 0.5621935]], dtype=float32)

time = 173	action = 1	current_phase = 1	next_phase = 0	reward = -1.804281	array([[1.0618662, 0.5619804]], dtype=float32)

time = 181	action = 0	current_phase = 0	next_phase = 1	reward = -1.706185	array([[-0.9716226 , -0.16576113]], dtype=float32)

time = 186	action = 1	current_phase = 0	next_phase = 1	reward = -1.781931	array([[-0.97081345, -0.16455042]], dtype=float32)

time = 194	action = 0	current_phase = 1	next_phase = 0	reward = -0.238313	array([[1.0617381 , 0.56043917]], dtype=float32)

time = 199	action = 1	current_phase = 1	next_phase = 0	reward = -0.967943	array([[1.0612625, 0.5624091]], dtype=float32)

time = 207	action = 0	current_phase = 0	next_phase = 1	reward = -1.324615	array([[-0.9675047 , -0.15890577]], dtype=float32)

time = 212	action = 1	current_phase = 0	next_phase = 1	reward = -2.025084	array([[-0.9718816 , -0.16516736]], dtype=float32)

time = 220	action = 0	current_phase = 1	next_phase = 0	reward = -0.388162	array([[1.0613319, 0.56156  ]], dtype=float32)

time = 225	action = 1	current_phase = 1	next_phase = 0	reward = -1.321697	array([[1.0604849, 0.5632027]], dtype=float32)

time = 233	action = 0	current_phase = 0	next_phase = 1	reward = 0.159647	array([[-0.96870804, -0.1729069 ]], dtype=float32)

time = 238	action = 1	current_phase = 0	next_phase = 1	reward = -1.894308	array([[-0.9596843 , -0.15165073]], dtype=float32)

time = 246	action = 0	current_phase = 1	next_phase = 0	reward = -0.499073	array([[1.0601983, 0.5621169]], dtype=float32)

time = 251	action = 1	current_phase = 1	next_phase = 0	reward = -1.478030	array([[1.0611603, 0.5639389]], dtype=float32)

time = 259	action = 0	current_phase = 0	next_phase = 1	reward = -0.175046	array([[-0.96877503, -0.1740996 ]], dtype=float32)

time = 264	action = 1	current_phase = 0	next_phase = 1	reward = -0.424494	array([[-0.96837384, -0.172705  ]], dtype=float32)

time = 272	action = 0	current_phase = 1	next_phase = 0	reward = -0.613422	array([[1.0612627, 0.5632694]], dtype=float32)

time = 277	action = 1	current_phase = 1	next_phase = 0	reward = -1.677481	array([[1.0610123, 0.5635408]], dtype=float32)

time = 285	action = 0	current_phase = 0	next_phase = 1	reward = -0.225596	array([[-0.96759516, -0.17445132]], dtype=float32)

time = 290	action = 1	current_phase = 0	next_phase = 1	reward = -1.067538	array([[-0.96753657, -0.1749132 ]], dtype=float32)

time = 298	action = 0	current_phase = 1	next_phase = 0	reward = -1.463868	array([[1.0609052, 0.5656871]], dtype=float32)

time = 303	action = 1	current_phase = 1	next_phase = 0	reward = -1.953733	array([[1.0384855 , 0.57569164]], dtype=float32)

time = 311	action = 0	current_phase = 0	next_phase = 1	reward = -0.330389	array([[-0.98006195, -0.14192317]], dtype=float32)

time = 316	action = 1	current_phase = 0	next_phase = 1	reward = -1.305951	array([[-0.96816134, -0.1726553 ]], dtype=float32)

time = 324	action = 0	current_phase = 1	next_phase = 0	reward = -0.029119	array([[1.0613921, 0.5618713]], dtype=float32)

time = 329	action = 1	current_phase = 1	next_phase = 0	reward = -2.005298	array([[1.0607282, 0.5649228]], dtype=float32)

time = 337	action = 0	current_phase = 0	next_phase = 1	reward = -0.466965	array([[-0.9802538, -0.1436049]], dtype=float32)

time = 342	action = 1	current_phase = 0	next_phase = 1	reward = -1.425501	array([[-0.96842766, -0.17454693]], dtype=float32)

time = 350	action = 0	current_phase = 1	next_phase = 0	reward = 0.343361	array([[1.0603231, 0.5634911]], dtype=float32)

time = 355	action = 1	current_phase = 1	next_phase = 0	reward = -1.370644	array([[1.0693567 , 0.56452495]], dtype=float32)

time = 363	action = 0	current_phase = 0	next_phase = 1	reward = -0.586191	array([[-0.96827996, -0.17351586]], dtype=float32)

time = 368	action = 1	current_phase = 0	next_phase = 1	reward = -1.599333	array([[-0.96727794, -0.17261977]], dtype=float32)

time = 376	action = 0	current_phase = 1	next_phase = 0	reward = -0.181629	array([[1.0613838 , 0.56222856]], dtype=float32)

time = 381	action = 1	current_phase = 1	next_phase = 0	reward = -1.315253	array([[1.0612024, 0.5635092]], dtype=float32)

time = 389	action = 0	current_phase = 0	next_phase = 1	reward = -1.599940	array([[-0.96734583, -0.15903218]], dtype=float32)

time = 394	action = 1	current_phase = 0	next_phase = 1	reward = -1.892467	array([[-0.9713383 , -0.16455069]], dtype=float32)

time = 402	action = 0	current_phase = 1	next_phase = 0	reward = -0.294277	array([[1.0609899, 0.5610641]], dtype=float32)

time = 407	action = 1	current_phase = 1	next_phase = 0	reward = -0.790772	array([[1.0600574, 0.5625472]], dtype=float32)

time = 415	action = 0	current_phase = 0	next_phase = 1	reward = -0.962393	array([[-0.97304314, -0.15860805]], dtype=float32)

time = 420	action = 1	current_phase = 0	next_phase = 1	reward = -2.135806	array([[-0.9673167 , -0.15796627]], dtype=float32)

time = 428	action = 0	current_phase = 1	next_phase = 0	reward = -0.447065	array([[1.0604049, 0.561651 ]], dtype=float32)

time = 433	action = 1	current_phase = 1	next_phase = 0	reward = -1.396884	array([[1.0628712 , 0.56294346]], dtype=float32)

time = 441	action = 0	current_phase = 0	next_phase = 1	reward = 0.323544	array([[-0.9678005 , -0.17354655]], dtype=float32)

time = 446	action = 1	current_phase = 0	next_phase = 1	reward = -1.602773	array([[-0.9727905, -0.1591976]], dtype=float32)

time = 454	action = 0	current_phase = 1	next_phase = 0	reward = -0.560144	array([[1.0627718, 0.5627821]], dtype=float32)

time = 459	action = 1	current_phase = 1	next_phase = 0	reward = -1.599829	array([[1.0610578 , 0.56415915]], dtype=float32)

time = 467	action = 0	current_phase = 0	next_phase = 1	reward = -0.188310	array([[-0.9676189 , -0.17428353]], dtype=float32)

time = 472	action = 1	current_phase = 0	next_phase = 1	reward = -1.342876	array([[-0.96809095, -0.17425682]], dtype=float32)

time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -1.727391	array([[1.0603863, 0.5659003]], dtype=float32)

time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -1.843941	array([[1.0392592 , 0.57607734]], dtype=float32)

time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -0.278707	array([[-0.9812986 , -0.14375976]], dtype=float32)

time = 498	action = 1	current_phase = 0	next_phase = 1	reward = -0.797794	array([[-0.9687903 , -0.17458166]], dtype=float32)

time = 506	action = 0	current_phase = 1	next_phase = 0	reward = -1.063315	array([[1.0699178 , 0.56495154]], dtype=float32)

time = 511	action = 1	current_phase = 1	next_phase = 0	reward = -2.064303	array([[1.0386254 , 0.57502276]], dtype=float32)

time = 519	action = 0	current_phase = 0	next_phase = 1	reward = -0.399149	array([[-0.98009086, -0.14307013]], dtype=float32)

time = 524	action = 1	current_phase = 0	next_phase = 1	reward = -1.342688	array([[-0.9686831 , -0.17370774]], dtype=float32)

time = 532	action = 0	current_phase = 1	next_phase = 0	reward = 0.231387	array([[1.0611955, 0.5627415]], dtype=float32)

time = 537	action = 1	current_phase = 1	next_phase = 0	reward = -1.728931	array([[1.0702872, 0.5643123]], dtype=float32)

time = 545	action = 0	current_phase = 0	next_phase = 1	reward = -0.521285	array([[-0.98025274, -0.14361899]], dtype=float32)

time = 550	action = 1	current_phase = 0	next_phase = 1	reward = -1.511994	array([[-0.9675951 , -0.17375475]], dtype=float32)

time = 558	action = 0	current_phase = 1	next_phase = 0	reward = -0.165020	array([[1.0610781, 0.562157 ]], dtype=float32)

time = 563	action = 1	current_phase = 1	next_phase = 0	reward = -0.235729	array([[1.0609589, 0.5632602]], dtype=float32)

time = 571	action = 0	current_phase = 0	next_phase = 1	reward = -0.644741	array([[-0.96817195, -0.17411248]], dtype=float32)

time = 576	action = 1	current_phase = 0	next_phase = 1	reward = -1.706804	array([[-0.967846  , -0.17378014]], dtype=float32)

time = 584	action = 0	current_phase = 1	next_phase = 0	reward = -0.236316	array([[1.0610672 , 0.56255126]], dtype=float32)

time = 589	action = 1	current_phase = 1	next_phase = 0	reward = -0.992628	array([[1.0620732, 0.5625311]], dtype=float32)

time = 597	action = 0	current_phase = 0	next_phase = 1	reward = -1.323733	array([[-0.9674469 , -0.15950307]], dtype=float32)

time = 602	action = 1	current_phase = 0	next_phase = 1	reward = -2.010824	array([[-0.9709794, -0.1647977]], dtype=float32)

time = 610	action = 0	current_phase = 1	next_phase = 0	reward = -0.371881	array([[1.0602587, 0.5610093]], dtype=float32)

time = 615	action = 1	current_phase = 1	next_phase = 0	reward = -1.324933	array([[1.0609039 , 0.56300443]], dtype=float32)

time = 623	action = 0	current_phase = 0	next_phase = 1	reward = 0.095637	array([[-0.9684188, -0.1730687]], dtype=float32)

time = 628	action = 1	current_phase = 0	next_phase = 1	reward = -1.901537	array([[-0.96773416, -0.15953405]], dtype=float32)

time = 636	action = 0	current_phase = 1	next_phase = 0	reward = -0.501183	array([[1.0593417 , 0.56196016]], dtype=float32)

time = 641	action = 1	current_phase = 1	next_phase = 0	reward = -1.469584	array([[1.0623981, 0.5642922]], dtype=float32)

time = 649	action = 0	current_phase = 0	next_phase = 1	reward = -0.192606	array([[-0.9680902 , -0.17425337]], dtype=float32)

time = 654	action = 1	current_phase = 0	next_phase = 1	reward = -0.606101	array([[-0.968363, -0.173294]], dtype=float32)

time = 662	action = 0	current_phase = 1	next_phase = 0	reward = -0.614366	array([[1.0621191, 0.5634798]], dtype=float32)

time = 667	action = 1	current_phase = 1	next_phase = 0	reward = -1.649262	array([[1.0617332, 0.5633411]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 676.00

Reason: TraCI requested termination.

Performance: 

 Duration: 36299ms

 Real time factor: 18.6231

 UPS: 148.433841

Vehicles: 

 Inserted: 92

 Running: 8

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 2ms answering queries (0.02ms on average).

Could not connect to TraCI server at localhost:58011 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 58011 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (1ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -1.731109	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.985191	array([[-0.9718044 , -0.16345435]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.272966	array([[1.0616846 , 0.56122816]], dtype=float32)

time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -0.820207	array([[1.0620557, 0.5627278]], dtype=float32)

time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -1.119026	array([[-0.97307837, -0.15884933]], dtype=float32)

time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.716720	array([[-0.97130865, -0.16519105]], dtype=float32)

time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.817032	array([[-0.9717203 , -0.16392058]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.260901	array([[1.0610322 , 0.56075466]], dtype=float32)

time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -0.894518	array([[1.061515  , 0.56307006]], dtype=float32)

time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.314827	array([[-0.97319996, -0.15880257]], dtype=float32)

time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -1.688627	array([[-0.97130084, -0.16522571]], dtype=float32)

time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -1.754751	array([[-0.9713723 , -0.16360119]], dtype=float32)

time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.217561	array([[1.060105 , 0.5613769]], dtype=float32)

time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.012570	array([[1.0618936, 0.562878 ]], dtype=float32)

time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.459907	array([[-0.95955485, -0.15106274]], dtype=float32)

time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.665616	array([[-0.97214955, -0.16469815]], dtype=float32)

time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -1.706008	array([[-0.970806  , -0.16347647]], dtype=float32)

time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.192646	array([[1.0605356 , 0.56174195]], dtype=float32)

time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.273034	array([[1.0624278, 0.5623432]], dtype=float32)

time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.606602	array([[-0.96740705, -0.15857194]], dtype=float32)

time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.652795	array([[-0.971462  , -0.16498142]], dtype=float32)

time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -1.651091	array([[-0.9716352 , -0.16435416]], dtype=float32)

time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.178403	array([[1.0615559 , 0.56110793]], dtype=float32)

time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.484792	array([[1.0618025 , 0.56287533]], dtype=float32)

time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.732228	array([[-0.96686596, -0.1577643 ]], dtype=float32)

time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.613691	array([[-0.9717253 , -0.16464192]], dtype=float32)

time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.589023	array([[-0.9707414, -0.1625405]], dtype=float32)

time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -0.164863	array([[1.0616128 , 0.56142807]], dtype=float32)

time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.916452	array([[1.0611451 , 0.56286526]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.719693	array([[-0.97101337, -0.1645346 ]], dtype=float32)

time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.615351	array([[-0.9710753 , -0.16415349]], dtype=float32)

time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -1.569128	array([[-0.97066396, -0.16353452]], dtype=float32)

time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.170984	array([[1.0609449, 0.5611689]], dtype=float32)

time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -0.500347	array([[1.0597217, 0.5633179]], dtype=float32)

time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.616887	array([[-0.9674185 , -0.17291498]], dtype=float32)

time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -0.455900	array([[-0.96773416, -0.17368788]], dtype=float32)

time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.396235	array([[-0.9681446 , -0.17331725]], dtype=float32)

time = 260	action = 0	current_phase = 1	next_phase = 0	reward = 0.328807	array([[1.0610566, 0.5627775]], dtype=float32)

time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.424592	array([[1.0705975, 0.5649128]], dtype=float32)

time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.583686	array([[-0.9673278, -0.1739523]], dtype=float32)

time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.427000	array([[-0.9684205 , -0.17309952]], dtype=float32)

time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.371089	array([[-0.9683458 , -0.17400289]], dtype=float32)

time = 291	action = 0	current_phase = 1	next_phase = 0	reward = 0.317593	array([[1.0614898 , 0.56284297]], dtype=float32)

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.606931	array([[1.0708696 , 0.56485903]], dtype=float32)

time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.560143	array([[-0.967511  , -0.17377035]], dtype=float32)

time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -0.413238	array([[-0.968376  , -0.17318007]], dtype=float32)

time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -1.362590	array([[-0.9677345 , -0.17317279]], dtype=float32)

time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.255096	array([[1.06194   , 0.56286657]], dtype=float32)

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.782502	array([[1.0700809 , 0.56498426]], dtype=float32)

time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.529511	array([[-0.9798138 , -0.14332798]], dtype=float32)

time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -0.383954	array([[-0.96807206, -0.17319766]], dtype=float32)

time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -1.322000	array([[-0.96838504, -0.17358339]], dtype=float32)

time = 353	action = 0	current_phase = 1	next_phase = 0	reward = 0.078227	array([[1.0611346, 0.5620111]], dtype=float32)

time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.892659	array([[1.0627769 , 0.56663924]], dtype=float32)

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.485115	array([[-0.980515  , -0.14318791]], dtype=float32)

time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.327442	array([[-0.96779436, -0.17471957]], dtype=float32)

time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.018164	array([[-0.9689876 , -0.17450717]], dtype=float32)

time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.363888	array([[1.0623474, 0.565006 ]], dtype=float32)

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -2.019126	array([[1.0618024 , 0.56517816]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -0.478193	array([[-0.98000795, -0.1423161 ]], dtype=float32)

time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -0.317730	array([[-0.9682305 , -0.17347401]], dtype=float32)

time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -1.343309	array([[-0.9684589 , -0.17351522]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.280181	array([[1.0608823, 0.5624727]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.115182	array([[1.0615238 , 0.56488574]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.436646	array([[-0.979928  , -0.14281243]], dtype=float32)

time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -0.280943	array([[-0.9688031 , -0.17497836]], dtype=float32)

time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.790034	array([[-0.96822846, -0.1731733 ]], dtype=float32)

time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -1.062604	array([[1.070182 , 0.5646583]], dtype=float32)

time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -2.067543	array([[1.0390708 , 0.57539445]], dtype=float32)

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -0.412680	array([[-0.9793227 , -0.14354599]], dtype=float32)

time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.258017	array([[-0.9685448, -0.173017 ]], dtype=float32)

time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -0.849057	array([[-0.9676553 , -0.17396185]], dtype=float32)

time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -1.260633	array([[1.0698023 , 0.56446487]], dtype=float32)

time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.988607	array([[1.0381877, 0.5753441]], dtype=float32)

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.354334	array([[-0.9804313 , -0.14313516]], dtype=float32)

time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.213758	array([[-0.96855986, -0.17370172]], dtype=float32)

time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -0.979158	array([[-0.96855724, -0.17256486]], dtype=float32)

time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -1.454407	array([[1.062084  , 0.56681347]], dtype=float32)

time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -1.943323	array([[1.0383207, 0.5759834]], dtype=float32)

time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.333446	array([[-0.97999734, -0.1425626 ]], dtype=float32)

time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -0.188081	array([[-0.96816397, -0.17387038]], dtype=float32)

time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -1.355400	array([[-0.9677675 , -0.17331356]], dtype=float32)

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.606984	array([[1.0603995, 0.565589 ]], dtype=float32)

time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.916384	array([[1.0397655, 0.5752095]], dtype=float32)

time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.313854	array([[-0.9807272 , -0.14315224]], dtype=float32)

time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -0.175377	array([[-0.9687606 , -0.17431945]], dtype=float32)

time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -1.550649	array([[-0.9680756, -0.1728899]], dtype=float32)

time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.735772	array([[1.0610063 , 0.56540865]], dtype=float32)

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.851201	array([[1.0404485, 0.5753733]], dtype=float32)

time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.264794	array([[-0.980605  , -0.14293242]], dtype=float32)

time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -0.172373	array([[-0.96780705, -0.17461337]], dtype=float32)

time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -1.063747	array([[-0.9679741 , -0.17341888]], dtype=float32)

time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -1.183051	array([[1.0570039 , 0.56811804]], dtype=float32)

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.754496	array([[1.056982 , 0.5683003]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -0.237852	array([[-0.9609982 , -0.15585965]], dtype=float32)

time = 619	action = 0	current_phase = 0	next_phase = 1	reward = -0.180591	array([[-0.9681942, -0.1739652]], dtype=float32)

time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -0.608551	array([[-0.96862024, -0.17245525]], dtype=float32)

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.614232	array([[1.061707  , 0.56289685]], dtype=float32)

time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.667255	array([[1.0611591, 0.5638461]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.223043	array([[-0.9669575 , -0.17515463]], dtype=float32)

time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 0.354313	array([[-0.96790856, -0.17336261]], dtype=float32)

time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -1.361097	array([[-0.9731525 , -0.15828964]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.592908	array([[1.0617566, 0.5635134]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 35321ms

 Real time factor: 18.9406

 UPS: 154.157583

Vehicles: 

 Inserted: 92

 Running: 8

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 1ms answering queries (0.01ms on average).

Could not connect to TraCI server at localhost:47701 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 47701 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (2ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -1.731109	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.985191	array([[-0.9718044 , -0.16345435]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.272966	array([[1.0616846 , 0.56122816]], dtype=float32)

time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -0.820207	array([[1.0620557, 0.5627278]], dtype=float32)

time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -1.119026	array([[-0.97307837, -0.15884933]], dtype=float32)

time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.716720	array([[-0.97130865, -0.16519105]], dtype=float32)

time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.817032	array([[-0.9717203 , -0.16392058]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.260901	array([[1.0610322 , 0.56075466]], dtype=float32)

time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -0.894518	array([[1.061515  , 0.56307006]], dtype=float32)

time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.314827	array([[-0.97319996, -0.15880257]], dtype=float32)

time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -1.688627	array([[-0.97130084, -0.16522571]], dtype=float32)

time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -1.754751	array([[-0.9713723 , -0.16360119]], dtype=float32)

time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.217561	array([[1.060105 , 0.5613769]], dtype=float32)

time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.012570	array([[1.0618936, 0.562878 ]], dtype=float32)

time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.459907	array([[-0.95955485, -0.15106274]], dtype=float32)

time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.665616	array([[-0.97214955, -0.16469815]], dtype=float32)

time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -1.706008	array([[-0.970806  , -0.16347647]], dtype=float32)

time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.192646	array([[1.0605356 , 0.56174195]], dtype=float32)

time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.273034	array([[1.0624278, 0.5623432]], dtype=float32)

time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.606602	array([[-0.96740705, -0.15857194]], dtype=float32)

time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.652795	array([[-0.971462  , -0.16498142]], dtype=float32)

time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -1.651091	array([[-0.9716352 , -0.16435416]], dtype=float32)

time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.178403	array([[1.0615559 , 0.56110793]], dtype=float32)

time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.484792	array([[1.0618025 , 0.56287533]], dtype=float32)

time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.732228	array([[-0.96686596, -0.1577643 ]], dtype=float32)

time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.613691	array([[-0.9717253 , -0.16464192]], dtype=float32)

time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.589023	array([[-0.9707414, -0.1625405]], dtype=float32)

time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -0.164863	array([[1.0616128 , 0.56142807]], dtype=float32)

time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.916452	array([[1.0611451 , 0.56286526]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.719693	array([[-0.97101337, -0.1645346 ]], dtype=float32)

time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.615351	array([[-0.9710753 , -0.16415349]], dtype=float32)

time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -1.569128	array([[-0.97066396, -0.16353452]], dtype=float32)

time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.170984	array([[1.0609449, 0.5611689]], dtype=float32)

time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -0.500347	array([[1.0597217, 0.5633179]], dtype=float32)

time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.616887	array([[-0.9674185 , -0.17291498]], dtype=float32)

time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -0.455900	array([[-0.96773416, -0.17368788]], dtype=float32)

time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.396235	array([[-0.9681446 , -0.17331725]], dtype=float32)

time = 260	action = 0	current_phase = 1	next_phase = 0	reward = 0.328807	array([[1.0610566, 0.5627775]], dtype=float32)

time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.424592	array([[1.0705975, 0.5649128]], dtype=float32)

time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.583686	array([[-0.9673278, -0.1739523]], dtype=float32)

time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.427000	array([[-0.9684205 , -0.17309952]], dtype=float32)

time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.371089	array([[-0.9683458 , -0.17400289]], dtype=float32)

time = 291	action = 0	current_phase = 1	next_phase = 0	reward = 0.317593	array([[1.0614898 , 0.56284297]], dtype=float32)

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.606931	array([[1.0708696 , 0.56485903]], dtype=float32)

time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.560143	array([[-0.967511  , -0.17377035]], dtype=float32)

time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -0.413238	array([[-0.968376  , -0.17318007]], dtype=float32)

time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -1.362590	array([[-0.9677345 , -0.17317279]], dtype=float32)

time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.255096	array([[1.06194   , 0.56286657]], dtype=float32)

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.782502	array([[1.0700809 , 0.56498426]], dtype=float32)

time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.529511	array([[-0.9798138 , -0.14332798]], dtype=float32)

time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -0.383954	array([[-0.96807206, -0.17319766]], dtype=float32)

time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -1.322000	array([[-0.96838504, -0.17358339]], dtype=float32)

time = 353	action = 0	current_phase = 1	next_phase = 0	reward = 0.078227	array([[1.0611346, 0.5620111]], dtype=float32)

time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.892659	array([[1.0627769 , 0.56663924]], dtype=float32)

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.485115	array([[-0.980515  , -0.14318791]], dtype=float32)

time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.327442	array([[-0.96779436, -0.17471957]], dtype=float32)

time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.018164	array([[-0.9689876 , -0.17450717]], dtype=float32)

time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.363888	array([[1.0623474, 0.565006 ]], dtype=float32)

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -2.019126	array([[1.0618024 , 0.56517816]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -0.478193	array([[-0.98000795, -0.1423161 ]], dtype=float32)

time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -0.317730	array([[-0.9682305 , -0.17347401]], dtype=float32)

time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -1.343309	array([[-0.9684589 , -0.17351522]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.280181	array([[1.0608823, 0.5624727]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.115182	array([[1.0615238 , 0.56488574]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.436646	array([[-0.979928  , -0.14281243]], dtype=float32)

time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -0.280943	array([[-0.9688031 , -0.17497836]], dtype=float32)

time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.790034	array([[-0.96822846, -0.1731733 ]], dtype=float32)

time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -1.062604	array([[1.070182 , 0.5646583]], dtype=float32)

time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -2.067543	array([[1.0390708 , 0.57539445]], dtype=float32)

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -0.412680	array([[-0.9793227 , -0.14354599]], dtype=float32)

time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.258017	array([[-0.9685448, -0.173017 ]], dtype=float32)

time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -0.849057	array([[-0.9676553 , -0.17396185]], dtype=float32)

time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -1.260633	array([[1.0698023 , 0.56446487]], dtype=float32)

time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.988607	array([[1.0381877, 0.5753441]], dtype=float32)

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.354334	array([[-0.9804313 , -0.14313516]], dtype=float32)

time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.213758	array([[-0.96855986, -0.17370172]], dtype=float32)

time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -0.979158	array([[-0.96855724, -0.17256486]], dtype=float32)

time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -1.454407	array([[1.062084  , 0.56681347]], dtype=float32)

time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -1.943323	array([[1.0383207, 0.5759834]], dtype=float32)

time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.333446	array([[-0.97999734, -0.1425626 ]], dtype=float32)

time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -0.188081	array([[-0.96816397, -0.17387038]], dtype=float32)

time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -1.355400	array([[-0.9677675 , -0.17331356]], dtype=float32)

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.606984	array([[1.0603995, 0.565589 ]], dtype=float32)

time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.916384	array([[1.0397655, 0.5752095]], dtype=float32)

time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.313854	array([[-0.9807272 , -0.14315224]], dtype=float32)

time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -0.175377	array([[-0.9687606 , -0.17431945]], dtype=float32)

time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -1.550649	array([[-0.9680756, -0.1728899]], dtype=float32)

time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.735772	array([[1.0610063 , 0.56540865]], dtype=float32)

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.851201	array([[1.0404485, 0.5753733]], dtype=float32)

time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.264794	array([[-0.980605  , -0.14293242]], dtype=float32)

time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -0.172373	array([[-0.96780705, -0.17461337]], dtype=float32)

time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -1.063747	array([[-0.9679741 , -0.17341888]], dtype=float32)

time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -1.183051	array([[1.0570039 , 0.56811804]], dtype=float32)

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.754496	array([[1.056982 , 0.5683003]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -0.237852	array([[-0.9609982 , -0.15585965]], dtype=float32)

time = 619	action = 0	current_phase = 0	next_phase = 1	reward = -0.180591	array([[-0.9681942, -0.1739652]], dtype=float32)

time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -0.608551	array([[-0.96862024, -0.17245525]], dtype=float32)

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.614232	array([[1.061707  , 0.56289685]], dtype=float32)

time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.667255	array([[1.0611591, 0.5638461]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.223043	array([[-0.9669575 , -0.17515463]], dtype=float32)

time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 0.354313	array([[-0.96790856, -0.17336261]], dtype=float32)

time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -1.361097	array([[-0.9731525 , -0.15828964]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.592908	array([[1.0617566, 0.5635134]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 36171ms

 Real time factor: 18.4955

 UPS: 150.534959

Vehicles: 

 Inserted: 92

 Running: 8

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 1ms answering queries (0.01ms on average).

Could not connect to TraCI server at localhost:35669 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 35669 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -1.731109	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.985191	array([[-0.9718044 , -0.16345435]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.272966	array([[1.0616846 , 0.56122816]], dtype=float32)

time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -0.820207	array([[1.0620557, 0.5627278]], dtype=float32)

time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -1.119026	array([[-0.97307837, -0.15884933]], dtype=float32)

time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.716720	array([[-0.97130865, -0.16519105]], dtype=float32)

time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.817032	array([[-0.9717203 , -0.16392058]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.260901	array([[1.0610322 , 0.56075466]], dtype=float32)

time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -0.894518	array([[1.061515  , 0.56307006]], dtype=float32)

time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.314827	array([[-0.97319996, -0.15880257]], dtype=float32)

time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -1.688627	array([[-0.97130084, -0.16522571]], dtype=float32)

time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -1.754751	array([[-0.9713723 , -0.16360119]], dtype=float32)

time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.217561	array([[1.060105 , 0.5613769]], dtype=float32)

time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.012570	array([[1.0618936, 0.562878 ]], dtype=float32)

time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.459907	array([[-0.95955485, -0.15106274]], dtype=float32)

time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.665616	array([[-0.97214955, -0.16469815]], dtype=float32)

time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -1.706008	array([[-0.970806  , -0.16347647]], dtype=float32)

time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.192646	array([[1.0605356 , 0.56174195]], dtype=float32)

time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.273034	array([[1.0624278, 0.5623432]], dtype=float32)

time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.606602	array([[-0.96740705, -0.15857194]], dtype=float32)

time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.652795	array([[-0.971462  , -0.16498142]], dtype=float32)

time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -1.651091	array([[-0.9716352 , -0.16435416]], dtype=float32)

time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.178403	array([[1.0615559 , 0.56110793]], dtype=float32)

time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.484792	array([[1.0618025 , 0.56287533]], dtype=float32)

time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.732228	array([[-0.96686596, -0.1577643 ]], dtype=float32)

time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.613691	array([[-0.9717253 , -0.16464192]], dtype=float32)

time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.589023	array([[-0.9707414, -0.1625405]], dtype=float32)

time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -0.164863	array([[1.0616128 , 0.56142807]], dtype=float32)

time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.916452	array([[1.0611451 , 0.56286526]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.719693	array([[-0.97101337, -0.1645346 ]], dtype=float32)

time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.615351	array([[-0.9710753 , -0.16415349]], dtype=float32)

time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -1.569128	array([[-0.97066396, -0.16353452]], dtype=float32)

time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.170984	array([[1.0609449, 0.5611689]], dtype=float32)

time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -0.500347	array([[1.0597217, 0.5633179]], dtype=float32)

time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.616887	array([[-0.9674185 , -0.17291498]], dtype=float32)

time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -0.455900	array([[-0.96773416, -0.17368788]], dtype=float32)

time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.396235	array([[-0.9681446 , -0.17331725]], dtype=float32)

time = 260	action = 0	current_phase = 1	next_phase = 0	reward = 0.328807	array([[1.0610566, 0.5627775]], dtype=float32)

time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.424592	array([[1.0705975, 0.5649128]], dtype=float32)

time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.583686	array([[-0.9673278, -0.1739523]], dtype=float32)

time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.427000	array([[-0.9684205 , -0.17309952]], dtype=float32)

time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.371089	array([[-0.9683458 , -0.17400289]], dtype=float32)

time = 291	action = 0	current_phase = 1	next_phase = 0	reward = 0.317593	array([[1.0614898 , 0.56284297]], dtype=float32)

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.606931	array([[1.0708696 , 0.56485903]], dtype=float32)

time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.560143	array([[-0.967511  , -0.17377035]], dtype=float32)

time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -0.413238	array([[-0.968376  , -0.17318007]], dtype=float32)

time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -1.362590	array([[-0.9677345 , -0.17317279]], dtype=float32)

time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.255096	array([[1.06194   , 0.56286657]], dtype=float32)

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.782502	array([[1.0700809 , 0.56498426]], dtype=float32)

time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.529511	array([[-0.9798138 , -0.14332798]], dtype=float32)

time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -0.383954	array([[-0.96807206, -0.17319766]], dtype=float32)

time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -1.322000	array([[-0.96838504, -0.17358339]], dtype=float32)

time = 353	action = 0	current_phase = 1	next_phase = 0	reward = 0.078227	array([[1.0611346, 0.5620111]], dtype=float32)

time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.892659	array([[1.0627769 , 0.56663924]], dtype=float32)

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.485115	array([[-0.980515  , -0.14318791]], dtype=float32)

time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.327442	array([[-0.96779436, -0.17471957]], dtype=float32)

time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.018164	array([[-0.9689876 , -0.17450717]], dtype=float32)

time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.363888	array([[1.0623474, 0.565006 ]], dtype=float32)

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -2.019126	array([[1.0618024 , 0.56517816]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -0.478193	array([[-0.98000795, -0.1423161 ]], dtype=float32)

time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -0.317730	array([[-0.9682305 , -0.17347401]], dtype=float32)

time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -1.343309	array([[-0.9684589 , -0.17351522]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.280181	array([[1.0608823, 0.5624727]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.115182	array([[1.0615238 , 0.56488574]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.436646	array([[-0.979928  , -0.14281243]], dtype=float32)

time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -0.280943	array([[-0.9688031 , -0.17497836]], dtype=float32)

time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.790034	array([[-0.96822846, -0.1731733 ]], dtype=float32)

time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -1.062604	array([[1.070182 , 0.5646583]], dtype=float32)

time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -2.067543	array([[1.0390708 , 0.57539445]], dtype=float32)

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -0.412680	array([[-0.9793227 , -0.14354599]], dtype=float32)

time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.258017	array([[-0.9685448, -0.173017 ]], dtype=float32)

time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -0.849057	array([[-0.9676553 , -0.17396185]], dtype=float32)

time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -1.260633	array([[1.0698023 , 0.56446487]], dtype=float32)

time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.988607	array([[1.0381877, 0.5753441]], dtype=float32)

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.354334	array([[-0.9804313 , -0.14313516]], dtype=float32)

time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.213758	array([[-0.96855986, -0.17370172]], dtype=float32)

time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -0.979158	array([[-0.96855724, -0.17256486]], dtype=float32)

time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -1.454407	array([[1.062084  , 0.56681347]], dtype=float32)

time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -1.943323	array([[1.0383207, 0.5759834]], dtype=float32)

time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.333446	array([[-0.97999734, -0.1425626 ]], dtype=float32)

time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -0.188081	array([[-0.96816397, -0.17387038]], dtype=float32)

time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -1.355400	array([[-0.9677675 , -0.17331356]], dtype=float32)

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.606984	array([[1.0603995, 0.565589 ]], dtype=float32)

time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.916384	array([[1.0397655, 0.5752095]], dtype=float32)

time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.313854	array([[-0.9807272 , -0.14315224]], dtype=float32)

time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -0.175377	array([[-0.9687606 , -0.17431945]], dtype=float32)

time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -1.550649	array([[-0.9680756, -0.1728899]], dtype=float32)

time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.735772	array([[1.0610063 , 0.56540865]], dtype=float32)

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.851201	array([[1.0404485, 0.5753733]], dtype=float32)

time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.264794	array([[-0.980605  , -0.14293242]], dtype=float32)

time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -0.172373	array([[-0.96780705, -0.17461337]], dtype=float32)

time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -1.063747	array([[-0.9679741 , -0.17341888]], dtype=float32)

time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -1.183051	array([[1.0570039 , 0.56811804]], dtype=float32)

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.754496	array([[1.056982 , 0.5683003]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -0.237852	array([[-0.9609982 , -0.15585965]], dtype=float32)

time = 619	action = 0	current_phase = 0	next_phase = 1	reward = -0.180591	array([[-0.9681942, -0.1739652]], dtype=float32)

time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -0.608551	array([[-0.96862024, -0.17245525]], dtype=float32)

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.614232	array([[1.061707  , 0.56289685]], dtype=float32)

time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.667255	array([[1.0611591, 0.5638461]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.223043	array([[-0.9669575 , -0.17515463]], dtype=float32)

time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 0.354313	array([[-0.96790856, -0.17336261]], dtype=float32)

time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -1.361097	array([[-0.9731525 , -0.15828964]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.592908	array([[1.0617566, 0.5635134]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 39028ms

 Real time factor: 17.1415

 UPS: 139.515220

Vehicles: 

 Inserted: 92

 Running: 8

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 2ms answering queries (0.02ms on average).

Could not connect to TraCI server at localhost:53157 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 53157 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (2ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -1.731109	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.985191	array([[-0.9718044 , -0.16345435]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.272966	array([[1.0616846 , 0.56122816]], dtype=float32)

time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -0.820207	array([[1.0620557, 0.5627278]], dtype=float32)

time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -1.119026	array([[-0.97307837, -0.15884933]], dtype=float32)

time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.716720	array([[-0.97130865, -0.16519105]], dtype=float32)

time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.817032	array([[-0.9717203 , -0.16392058]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.260901	array([[1.0610322 , 0.56075466]], dtype=float32)

time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -0.894518	array([[1.061515  , 0.56307006]], dtype=float32)

time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.314827	array([[-0.97319996, -0.15880257]], dtype=float32)

time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -1.688627	array([[-0.97130084, -0.16522571]], dtype=float32)

time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -1.754751	array([[-0.9713723 , -0.16360119]], dtype=float32)

time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.217561	array([[1.060105 , 0.5613769]], dtype=float32)

time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.012570	array([[1.0618936, 0.562878 ]], dtype=float32)

time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.459907	array([[-0.95955485, -0.15106274]], dtype=float32)

time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.665616	array([[-0.97214955, -0.16469815]], dtype=float32)

time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -1.706008	array([[-0.970806  , -0.16347647]], dtype=float32)

time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.192646	array([[1.0605356 , 0.56174195]], dtype=float32)

time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.273034	array([[1.0624278, 0.5623432]], dtype=float32)

time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.606602	array([[-0.96740705, -0.15857194]], dtype=float32)

time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.652795	array([[-0.971462  , -0.16498142]], dtype=float32)

time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -1.651091	array([[-0.9716352 , -0.16435416]], dtype=float32)

time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.178403	array([[1.0615559 , 0.56110793]], dtype=float32)

time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.484792	array([[1.0618025 , 0.56287533]], dtype=float32)

time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.732228	array([[-0.96686596, -0.1577643 ]], dtype=float32)

time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.613691	array([[-0.9717253 , -0.16464192]], dtype=float32)

time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.589023	array([[-0.9707414, -0.1625405]], dtype=float32)

time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -0.164863	array([[1.0616128 , 0.56142807]], dtype=float32)

time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.916452	array([[1.0611451 , 0.56286526]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.719693	array([[-0.97101337, -0.1645346 ]], dtype=float32)

time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.615351	array([[-0.9710753 , -0.16415349]], dtype=float32)

time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -1.569128	array([[-0.97066396, -0.16353452]], dtype=float32)

time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.170984	array([[1.0609449, 0.5611689]], dtype=float32)

time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -0.500347	array([[1.0597217, 0.5633179]], dtype=float32)

time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.616887	array([[-0.9674185 , -0.17291498]], dtype=float32)

time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -0.455900	array([[-0.96773416, -0.17368788]], dtype=float32)

time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.396235	array([[-0.9681446 , -0.17331725]], dtype=float32)

time = 260	action = 0	current_phase = 1	next_phase = 0	reward = 0.328807	array([[1.0610566, 0.5627775]], dtype=float32)

time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.424592	array([[1.0705975, 0.5649128]], dtype=float32)

time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.583686	array([[-0.9673278, -0.1739523]], dtype=float32)

time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.427000	array([[-0.9684205 , -0.17309952]], dtype=float32)

time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.371089	array([[-0.9683458 , -0.17400289]], dtype=float32)

time = 291	action = 0	current_phase = 1	next_phase = 0	reward = 0.317593	array([[1.0614898 , 0.56284297]], dtype=float32)

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.606931	array([[1.0708696 , 0.56485903]], dtype=float32)

time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.560143	array([[-0.967511  , -0.17377035]], dtype=float32)

time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -0.413238	array([[-0.968376  , -0.17318007]], dtype=float32)

time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -1.362590	array([[-0.9677345 , -0.17317279]], dtype=float32)

time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.255096	array([[1.06194   , 0.56286657]], dtype=float32)

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.782502	array([[1.0700809 , 0.56498426]], dtype=float32)

time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.529511	array([[-0.9798138 , -0.14332798]], dtype=float32)

time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -0.383954	array([[-0.96807206, -0.17319766]], dtype=float32)

time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -1.322000	array([[-0.96838504, -0.17358339]], dtype=float32)

time = 353	action = 0	current_phase = 1	next_phase = 0	reward = 0.078227	array([[1.0611346, 0.5620111]], dtype=float32)

time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.892659	array([[1.0627769 , 0.56663924]], dtype=float32)

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.485115	array([[-0.980515  , -0.14318791]], dtype=float32)

time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.327442	array([[-0.96779436, -0.17471957]], dtype=float32)

time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.018164	array([[-0.9689876 , -0.17450717]], dtype=float32)

time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.363888	array([[1.0623474, 0.565006 ]], dtype=float32)

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -2.019126	array([[1.0618024 , 0.56517816]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -0.478193	array([[-0.98000795, -0.1423161 ]], dtype=float32)

time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -0.317730	array([[-0.9682305 , -0.17347401]], dtype=float32)

time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -1.343309	array([[-0.9684589 , -0.17351522]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.280181	array([[1.0608823, 0.5624727]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.115182	array([[1.0615238 , 0.56488574]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.436646	array([[-0.979928  , -0.14281243]], dtype=float32)

time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -0.280943	array([[-0.9688031 , -0.17497836]], dtype=float32)

time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.790034	array([[-0.96822846, -0.1731733 ]], dtype=float32)

time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -1.062604	array([[1.070182 , 0.5646583]], dtype=float32)

time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -2.067543	array([[1.0390708 , 0.57539445]], dtype=float32)

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -0.412680	array([[-0.9793227 , -0.14354599]], dtype=float32)

time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.258017	array([[-0.9685448, -0.173017 ]], dtype=float32)

time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -0.849057	array([[-0.9676553 , -0.17396185]], dtype=float32)

time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -1.260633	array([[1.0698023 , 0.56446487]], dtype=float32)

time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.988607	array([[1.0381877, 0.5753441]], dtype=float32)

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.354334	array([[-0.9804313 , -0.14313516]], dtype=float32)

time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.213758	array([[-0.96855986, -0.17370172]], dtype=float32)

time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -0.979158	array([[-0.96855724, -0.17256486]], dtype=float32)

time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -1.454407	array([[1.062084  , 0.56681347]], dtype=float32)

time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -1.943323	array([[1.0383207, 0.5759834]], dtype=float32)

time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.333446	array([[-0.97999734, -0.1425626 ]], dtype=float32)

time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -0.188081	array([[-0.96816397, -0.17387038]], dtype=float32)

time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -1.355400	array([[-0.9677675 , -0.17331356]], dtype=float32)

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.606984	array([[1.0603995, 0.565589 ]], dtype=float32)

time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.916384	array([[1.0397655, 0.5752095]], dtype=float32)

time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.313854	array([[-0.9807272 , -0.14315224]], dtype=float32)

time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -0.175377	array([[-0.9687606 , -0.17431945]], dtype=float32)

time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -1.550649	array([[-0.9680756, -0.1728899]], dtype=float32)

time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.735772	array([[1.0610063 , 0.56540865]], dtype=float32)

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.851201	array([[1.0404485, 0.5753733]], dtype=float32)

time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.264794	array([[-0.980605  , -0.14293242]], dtype=float32)

time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -0.172373	array([[-0.96780705, -0.17461337]], dtype=float32)

time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -1.063747	array([[-0.9679741 , -0.17341888]], dtype=float32)

time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -1.183051	array([[1.0570039 , 0.56811804]], dtype=float32)

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.754496	array([[1.056982 , 0.5683003]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -0.237852	array([[-0.9609982 , -0.15585965]], dtype=float32)

time = 619	action = 0	current_phase = 0	next_phase = 1	reward = -0.180591	array([[-0.9681942, -0.1739652]], dtype=float32)

time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -0.608551	array([[-0.96862024, -0.17245525]], dtype=float32)

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.614232	array([[1.061707  , 0.56289685]], dtype=float32)

time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.667255	array([[1.0611591, 0.5638461]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.223043	array([[-0.9669575 , -0.17515463]], dtype=float32)

time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 0.354313	array([[-0.96790856, -0.17336261]], dtype=float32)

time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -1.361097	array([[-0.9731525 , -0.15828964]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.592908	array([[1.0617566, 0.5635134]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 42423ms

 Real time factor: 15.7697

 UPS: 128.350187

Vehicles: 

 Inserted: 92

 Running: 8

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 2ms answering queries (0.02ms on average).

Could not connect to TraCI server at localhost:60919 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 60919 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (2ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -1.731109	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 35	action = 1	current_phase = 0	next_phase = 1	reward = -1.985191	array([[-0.9718044 , -0.16345435]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.272966	array([[1.0616846 , 0.56122816]], dtype=float32)

time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -0.820207	array([[1.0620557, 0.5627278]], dtype=float32)

time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -1.119026	array([[-0.97307837, -0.15884933]], dtype=float32)

time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.716720	array([[-0.97130865, -0.16519105]], dtype=float32)

time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.817032	array([[-0.9717203 , -0.16392058]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.260901	array([[1.0610322 , 0.56075466]], dtype=float32)

time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -0.894518	array([[1.061515  , 0.56307006]], dtype=float32)

time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.314827	array([[-0.97319996, -0.15880257]], dtype=float32)

time = 92	action = 0	current_phase = 0	next_phase = 1	reward = -1.688627	array([[-0.97130084, -0.16522571]], dtype=float32)

time = 97	action = 1	current_phase = 0	next_phase = 1	reward = -1.754751	array([[-0.9713723 , -0.16360119]], dtype=float32)

time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.217561	array([[1.060105 , 0.5613769]], dtype=float32)

time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.012570	array([[1.0618936, 0.562878 ]], dtype=float32)

time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.459907	array([[-0.95955485, -0.15106274]], dtype=float32)

time = 123	action = 0	current_phase = 0	next_phase = 1	reward = -1.665616	array([[-0.97214955, -0.16469815]], dtype=float32)

time = 128	action = 1	current_phase = 0	next_phase = 1	reward = -1.706008	array([[-0.970806  , -0.16347647]], dtype=float32)

time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.192646	array([[1.0605356 , 0.56174195]], dtype=float32)

time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.273034	array([[1.0624278, 0.5623432]], dtype=float32)

time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.606602	array([[-0.96740705, -0.15857194]], dtype=float32)

time = 154	action = 0	current_phase = 0	next_phase = 1	reward = -1.652795	array([[-0.971462  , -0.16498142]], dtype=float32)

time = 159	action = 1	current_phase = 0	next_phase = 1	reward = -1.651091	array([[-0.9716352 , -0.16435416]], dtype=float32)

time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.178403	array([[1.0615559 , 0.56110793]], dtype=float32)

time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.484792	array([[1.0618025 , 0.56287533]], dtype=float32)

time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.732228	array([[-0.96686596, -0.1577643 ]], dtype=float32)

time = 185	action = 0	current_phase = 0	next_phase = 1	reward = -1.613691	array([[-0.9717253 , -0.16464192]], dtype=float32)

time = 190	action = 1	current_phase = 0	next_phase = 1	reward = -1.589023	array([[-0.9707414, -0.1625405]], dtype=float32)

time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -0.164863	array([[1.0616128 , 0.56142807]], dtype=float32)

time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -1.916452	array([[1.0611451 , 0.56286526]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -1.719693	array([[-0.97101337, -0.1645346 ]], dtype=float32)

time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -1.615351	array([[-0.9710753 , -0.16415349]], dtype=float32)

time = 221	action = 1	current_phase = 0	next_phase = 1	reward = -1.569128	array([[-0.97066396, -0.16353452]], dtype=float32)

time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.170984	array([[1.0609449, 0.5611689]], dtype=float32)

time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -0.500347	array([[1.0597217, 0.5633179]], dtype=float32)

time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.616887	array([[-0.9674185 , -0.17291498]], dtype=float32)

time = 247	action = 0	current_phase = 0	next_phase = 1	reward = -0.455900	array([[-0.96773416, -0.17368788]], dtype=float32)

time = 252	action = 1	current_phase = 0	next_phase = 1	reward = -1.396235	array([[-0.9681446 , -0.17331725]], dtype=float32)

time = 260	action = 0	current_phase = 1	next_phase = 0	reward = 0.328807	array([[1.0610566, 0.5627775]], dtype=float32)

time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.424592	array([[1.0705975, 0.5649128]], dtype=float32)

time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.583686	array([[-0.9673278, -0.1739523]], dtype=float32)

time = 278	action = 0	current_phase = 0	next_phase = 1	reward = -0.427000	array([[-0.9684205 , -0.17309952]], dtype=float32)

time = 283	action = 1	current_phase = 0	next_phase = 1	reward = -1.371089	array([[-0.9683458 , -0.17400289]], dtype=float32)

time = 291	action = 0	current_phase = 1	next_phase = 0	reward = 0.317593	array([[1.0614898 , 0.56284297]], dtype=float32)

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.606931	array([[1.0708696 , 0.56485903]], dtype=float32)

time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.560143	array([[-0.967511  , -0.17377035]], dtype=float32)

time = 309	action = 0	current_phase = 0	next_phase = 1	reward = -0.413238	array([[-0.968376  , -0.17318007]], dtype=float32)

time = 314	action = 1	current_phase = 0	next_phase = 1	reward = -1.362590	array([[-0.9677345 , -0.17317279]], dtype=float32)

time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.255096	array([[1.06194   , 0.56286657]], dtype=float32)

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.782502	array([[1.0700809 , 0.56498426]], dtype=float32)

time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.529511	array([[-0.9798138 , -0.14332798]], dtype=float32)

time = 340	action = 0	current_phase = 0	next_phase = 1	reward = -0.383954	array([[-0.96807206, -0.17319766]], dtype=float32)

time = 345	action = 1	current_phase = 0	next_phase = 1	reward = -1.322000	array([[-0.96838504, -0.17358339]], dtype=float32)

time = 353	action = 0	current_phase = 1	next_phase = 0	reward = 0.078227	array([[1.0611346, 0.5620111]], dtype=float32)

time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.892659	array([[1.0627769 , 0.56663924]], dtype=float32)

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.485115	array([[-0.980515  , -0.14318791]], dtype=float32)

time = 371	action = 0	current_phase = 0	next_phase = 1	reward = -0.327442	array([[-0.96779436, -0.17471957]], dtype=float32)

time = 376	action = 1	current_phase = 0	next_phase = 1	reward = -1.018164	array([[-0.9689876 , -0.17450717]], dtype=float32)

time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.363888	array([[1.0623474, 0.565006 ]], dtype=float32)

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -2.019126	array([[1.0618024 , 0.56517816]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -0.478193	array([[-0.98000795, -0.1423161 ]], dtype=float32)

time = 402	action = 0	current_phase = 0	next_phase = 1	reward = -0.317730	array([[-0.9682305 , -0.17347401]], dtype=float32)

time = 407	action = 1	current_phase = 0	next_phase = 1	reward = -1.343309	array([[-0.9684589 , -0.17351522]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.280181	array([[1.0608823, 0.5624727]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.115182	array([[1.0615238 , 0.56488574]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.436646	array([[-0.979928  , -0.14281243]], dtype=float32)

time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -0.280943	array([[-0.9688031 , -0.17497836]], dtype=float32)

time = 438	action = 1	current_phase = 0	next_phase = 1	reward = -0.790034	array([[-0.96822846, -0.1731733 ]], dtype=float32)

time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -1.062604	array([[1.070182 , 0.5646583]], dtype=float32)

time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -2.067543	array([[1.0390708 , 0.57539445]], dtype=float32)

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -0.412680	array([[-0.9793227 , -0.14354599]], dtype=float32)

time = 464	action = 0	current_phase = 0	next_phase = 1	reward = -0.258017	array([[-0.9685448, -0.173017 ]], dtype=float32)

time = 469	action = 1	current_phase = 0	next_phase = 1	reward = -0.849057	array([[-0.9676553 , -0.17396185]], dtype=float32)

time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -1.260633	array([[1.0698023 , 0.56446487]], dtype=float32)

time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -1.988607	array([[1.0381877, 0.5753441]], dtype=float32)

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.354334	array([[-0.9804313 , -0.14313516]], dtype=float32)

time = 495	action = 0	current_phase = 0	next_phase = 1	reward = -0.213758	array([[-0.96855986, -0.17370172]], dtype=float32)

time = 500	action = 1	current_phase = 0	next_phase = 1	reward = -0.979158	array([[-0.96855724, -0.17256486]], dtype=float32)

time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -1.454407	array([[1.062084  , 0.56681347]], dtype=float32)

time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -1.943323	array([[1.0383207, 0.5759834]], dtype=float32)

time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.333446	array([[-0.97999734, -0.1425626 ]], dtype=float32)

time = 526	action = 0	current_phase = 0	next_phase = 1	reward = -0.188081	array([[-0.96816397, -0.17387038]], dtype=float32)

time = 531	action = 1	current_phase = 0	next_phase = 1	reward = -1.355400	array([[-0.9677675 , -0.17331356]], dtype=float32)

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.606984	array([[1.0603995, 0.565589 ]], dtype=float32)

time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.916384	array([[1.0397655, 0.5752095]], dtype=float32)

time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.313854	array([[-0.9807272 , -0.14315224]], dtype=float32)

time = 557	action = 0	current_phase = 0	next_phase = 1	reward = -0.175377	array([[-0.9687606 , -0.17431945]], dtype=float32)

time = 562	action = 1	current_phase = 0	next_phase = 1	reward = -1.550649	array([[-0.9680756, -0.1728899]], dtype=float32)

time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.735772	array([[1.0610063 , 0.56540865]], dtype=float32)

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.851201	array([[1.0404485, 0.5753733]], dtype=float32)

time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.264794	array([[-0.980605  , -0.14293242]], dtype=float32)

time = 588	action = 0	current_phase = 0	next_phase = 1	reward = -0.172373	array([[-0.96780705, -0.17461337]], dtype=float32)

time = 593	action = 1	current_phase = 0	next_phase = 1	reward = -1.063747	array([[-0.9679741 , -0.17341888]], dtype=float32)

time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -1.183051	array([[1.0570039 , 0.56811804]], dtype=float32)

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.754496	array([[1.056982 , 0.5683003]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -0.237852	array([[-0.9609982 , -0.15585965]], dtype=float32)

time = 619	action = 0	current_phase = 0	next_phase = 1	reward = -0.180591	array([[-0.9681942, -0.1739652]], dtype=float32)

time = 624	action = 1	current_phase = 0	next_phase = 1	reward = -0.608551	array([[-0.96862024, -0.17245525]], dtype=float32)

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -0.614232	array([[1.061707  , 0.56289685]], dtype=float32)

time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.667255	array([[1.0611591, 0.5638461]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.223043	array([[-0.9669575 , -0.17515463]], dtype=float32)

time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 0.354313	array([[-0.96790856, -0.17336261]], dtype=float32)

time = 655	action = 1	current_phase = 0	next_phase = 1	reward = -1.361097	array([[-0.9731525 , -0.15828964]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -0.592908	array([[1.0617566, 0.5635134]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 36737ms

 Real time factor: 18.2105

 UPS: 148.215695

Vehicles: 

 Inserted: 92

 Running: 8

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 1ms answering queries (0.01ms on average).

Could not connect to TraCI server at localhost:49701 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 49701 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -1.731109	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -1.621862	array([[-0.9718044 , -0.16345435]], dtype=float32)

time = 40	action = 1	current_phase = 0	next_phase = 1	reward = -1.708308	array([[-0.970627  , -0.16355117]], dtype=float32)

time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -0.157579	array([[1.0620506 , 0.56044966]], dtype=float32)

time = 53	action = 1	current_phase = 1	next_phase = 0	reward = -0.274290	array([[1.0609069 , 0.56302685]], dtype=float32)

time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -0.654220	array([[-0.96778023, -0.17332068]], dtype=float32)

time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -0.501639	array([[-0.9673895 , -0.17337728]], dtype=float32)

time = 71	action = 0	current_phase = 0	next_phase = 1	reward = -0.354273	array([[-0.96801984, -0.17302942]], dtype=float32)

time = 76	action = 1	current_phase = 0	next_phase = 1	reward = -1.308977	array([[-0.96835303, -0.17337409]], dtype=float32)

time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -0.007460	array([[1.0618528 , 0.56298196]], dtype=float32)

time = 89	action = 1	current_phase = 1	next_phase = 0	reward = -2.005042	array([[1.0602992 , 0.56673706]], dtype=float32)

time = 97	action = 0	current_phase = 0	next_phase = 1	reward = -0.470437	array([[-0.9803413 , -0.14296389]], dtype=float32)

time = 102	action = 0	current_phase = 0	next_phase = 1	reward = -0.319989	array([[-0.9688234 , -0.17318907]], dtype=float32)

time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -0.179987	array([[-0.96794224, -0.17374259]], dtype=float32)

time = 112	action = 1	current_phase = 0	next_phase = 1	reward = -1.478200	array([[-0.9685261 , -0.17297535]], dtype=float32)

time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -1.736138	array([[1.0621047 , 0.56550634]], dtype=float32)

time = 125	action = 1	current_phase = 1	next_phase = 0	reward = -1.856599	array([[1.0393957 , 0.57576954]], dtype=float32)

time = 133	action = 0	current_phase = 0	next_phase = 1	reward = -0.281571	array([[-0.9811785 , -0.14305982]], dtype=float32)

time = 138	action = 0	current_phase = 0	next_phase = 1	reward = -0.160506	array([[-0.9685462 , -0.17404178]], dtype=float32)

time = 143	action = 0	current_phase = 0	next_phase = 1	reward = 0.079443	array([[-0.9687466 , -0.17259441]], dtype=float32)

time = 148	action = 1	current_phase = 0	next_phase = 1	reward = -1.894978	array([[-0.96804494, -0.15863687]], dtype=float32)

time = 156	action = 0	current_phase = 1	next_phase = 0	reward = -0.493131	array([[1.0606091, 0.5614515]], dtype=float32)

time = 161	action = 1	current_phase = 1	next_phase = 0	reward = -1.474119	array([[1.0620427 , 0.56326306]], dtype=float32)

time = 169	action = 0	current_phase = 0	next_phase = 1	reward = -0.183750	array([[-0.968194  , -0.17436048]], dtype=float32)

time = 174	action = 0	current_phase = 0	next_phase = 1	reward = -0.206029	array([[-0.968135  , -0.17309996]], dtype=float32)

time = 179	action = 0	current_phase = 0	next_phase = 1	reward = -1.605720	array([[-0.96801203, -0.15832204]], dtype=float32)

time = 184	action = 1	current_phase = 0	next_phase = 1	reward = -1.891741	array([[-0.9720358 , -0.16443098]], dtype=float32)

time = 192	action = 0	current_phase = 1	next_phase = 0	reward = -0.304299	array([[1.0609677, 0.5611384]], dtype=float32)

time = 197	action = 1	current_phase = 1	next_phase = 0	reward = -0.781404	array([[1.0621991, 0.5625497]], dtype=float32)

time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -0.855509	array([[-0.97255987, -0.15860164]], dtype=float32)

time = 210	action = 0	current_phase = 0	next_phase = 1	reward = -1.730096	array([[-0.96656793, -0.15827519]], dtype=float32)

time = 215	action = 0	current_phase = 0	next_phase = 1	reward = -1.615136	array([[-0.97133034, -0.16282909]], dtype=float32)

time = 220	action = 1	current_phase = 0	next_phase = 1	reward = -1.585017	array([[-0.9713485 , -0.16310713]], dtype=float32)

time = 228	action = 0	current_phase = 1	next_phase = 0	reward = -0.160792	array([[1.0608542 , 0.56081724]], dtype=float32)

time = 233	action = 1	current_phase = 1	next_phase = 0	reward = -1.104756	array([[1.0586684, 0.5639249]], dtype=float32)

time = 241	action = 0	current_phase = 0	next_phase = 1	reward = -1.184998	array([[-0.96235454, -0.16154303]], dtype=float32)

time = 246	action = 0	current_phase = 0	next_phase = 1	reward = -1.049597	array([[-0.9619332 , -0.16163106]], dtype=float32)

time = 251	action = 0	current_phase = 0	next_phase = 1	reward = -0.913456	array([[-0.96323603, -0.16211894]], dtype=float32)

time = 256	action = 1	current_phase = 0	next_phase = 1	reward = -1.346721	array([[-0.96324843, -0.16075468]], dtype=float32)

time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -0.085528	array([[1.0626109, 0.5623367]], dtype=float32)

time = 269	action = 1	current_phase = 1	next_phase = 0	reward = -2.008683	array([[1.0605353, 0.5659324]], dtype=float32)

time = 277	action = 0	current_phase = 0	next_phase = 1	reward = -0.468334	array([[-0.9805039 , -0.14316794]], dtype=float32)

time = 282	action = 0	current_phase = 0	next_phase = 1	reward = -0.312507	array([[-0.9682615 , -0.17286155]], dtype=float32)

time = 287	action = 0	current_phase = 0	next_phase = 1	reward = -0.172511	array([[-0.9682606 , -0.17354342]], dtype=float32)

time = 292	action = 1	current_phase = 0	next_phase = 1	reward = -1.439470	array([[-0.9683533 , -0.17328344]], dtype=float32)

time = 300	action = 0	current_phase = 1	next_phase = 0	reward = -1.731762	array([[1.0614077 , 0.56562936]], dtype=float32)

time = 305	action = 1	current_phase = 1	next_phase = 0	reward = -1.854158	array([[1.0395658 , 0.57565725]], dtype=float32)

time = 313	action = 0	current_phase = 0	next_phase = 1	reward = -0.277836	array([[-0.98081845, -0.14276177]], dtype=float32)

time = 318	action = 0	current_phase = 0	next_phase = 1	reward = -0.161814	array([[-0.9683872 , -0.17425853]], dtype=float32)

time = 323	action = 0	current_phase = 0	next_phase = 1	reward = 0.037296	array([[-0.9684786 , -0.17311674]], dtype=float32)

time = 328	action = 1	current_phase = 0	next_phase = 1	reward = -1.902885	array([[-0.9680341, -0.1586149]], dtype=float32)

time = 336	action = 0	current_phase = 1	next_phase = 0	reward = -0.504194	array([[1.0599326, 0.5620926]], dtype=float32)

time = 341	action = 1	current_phase = 1	next_phase = 0	reward = -1.491144	array([[1.0619724 , 0.56249857]], dtype=float32)

time = 349	action = 0	current_phase = 0	next_phase = 1	reward = -0.172736	array([[-0.96767235, -0.17388219]], dtype=float32)

time = 354	action = 0	current_phase = 0	next_phase = 1	reward = -0.018306	array([[-0.9682977, -0.1736334]], dtype=float32)

time = 359	action = 0	current_phase = 0	next_phase = 1	reward = -1.593409	array([[-0.96754307, -0.15825452]], dtype=float32)

time = 364	action = 1	current_phase = 0	next_phase = 1	reward = -1.885511	array([[-0.9717889 , -0.16505918]], dtype=float32)

time = 372	action = 0	current_phase = 1	next_phase = 0	reward = -0.291073	array([[1.0611503, 0.5614353]], dtype=float32)

time = 377	action = 1	current_phase = 1	next_phase = 0	reward = -0.771843	array([[1.0617367, 0.5620931]], dtype=float32)

time = 385	action = 0	current_phase = 0	next_phase = 1	reward = -0.854828	array([[-0.9722357 , -0.15833285]], dtype=float32)

time = 390	action = 0	current_phase = 0	next_phase = 1	reward = -1.734455	array([[-0.96674603, -0.15824577]], dtype=float32)

time = 395	action = 0	current_phase = 0	next_phase = 1	reward = -1.633661	array([[-0.97211194, -0.16364735]], dtype=float32)

time = 400	action = 1	current_phase = 0	next_phase = 1	reward = -1.618028	array([[-0.97123355, -0.16439329]], dtype=float32)

time = 408	action = 0	current_phase = 1	next_phase = 0	reward = -0.165266	array([[1.0612383, 0.5610291]], dtype=float32)

time = 413	action = 1	current_phase = 1	next_phase = 0	reward = -1.868449	array([[1.0614716, 0.5625743]], dtype=float32)

time = 421	action = 0	current_phase = 0	next_phase = 1	reward = -1.703632	array([[-0.97163045, -0.16539764]], dtype=float32)

time = 426	action = 0	current_phase = 0	next_phase = 1	reward = -1.591070	array([[-0.9713524 , -0.16424541]], dtype=float32)

time = 431	action = 0	current_phase = 0	next_phase = 1	reward = -1.473470	array([[-0.9715927, -0.162767 ]], dtype=float32)

time = 436	action = 1	current_phase = 0	next_phase = 1	reward = -1.377894	array([[-0.9713803 , -0.16290452]], dtype=float32)

time = 444	action = 0	current_phase = 1	next_phase = 0	reward = -0.149082	array([[1.0608045, 0.5614468]], dtype=float32)

time = 449	action = 1	current_phase = 1	next_phase = 0	reward = -2.014721	array([[1.0607712 , 0.56508213]], dtype=float32)

time = 457	action = 0	current_phase = 0	next_phase = 1	reward = -0.472753	array([[-0.97993565, -0.14246334]], dtype=float32)

time = 462	action = 0	current_phase = 0	next_phase = 1	reward = -0.316260	array([[-0.96841633, -0.17337552]], dtype=float32)

time = 467	action = 0	current_phase = 0	next_phase = 1	reward = -0.178720	array([[-0.96899045, -0.1736702 ]], dtype=float32)

time = 472	action = 1	current_phase = 0	next_phase = 1	reward = -1.426304	array([[-0.96859884, -0.17297268]], dtype=float32)

time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -1.726524	array([[1.0616384, 0.5656948]], dtype=float32)

time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -1.854009	array([[1.0397612 , 0.57573384]], dtype=float32)

time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -0.272531	array([[-0.9812511 , -0.14324611]], dtype=float32)

time = 498	action = 0	current_phase = 0	next_phase = 1	reward = -0.161956	array([[-0.9682735 , -0.17387274]], dtype=float32)

time = 503	action = 0	current_phase = 0	next_phase = 1	reward = 0.014525	array([[-0.9682879 , -0.17309454]], dtype=float32)

time = 508	action = 1	current_phase = 0	next_phase = 1	reward = -1.900039	array([[-0.96787596, -0.15763474]], dtype=float32)

time = 516	action = 0	current_phase = 1	next_phase = 0	reward = -0.501049	array([[1.0603361 , 0.56184024]], dtype=float32)

time = 521	action = 1	current_phase = 1	next_phase = 0	reward = -1.489375	array([[1.0616947 , 0.56326133]], dtype=float32)

time = 529	action = 0	current_phase = 0	next_phase = 1	reward = -0.170095	array([[-0.96790195, -0.17472886]], dtype=float32)

time = 534	action = 0	current_phase = 0	next_phase = 1	reward = -0.130569	array([[-0.9679399 , -0.17331897]], dtype=float32)

time = 539	action = 0	current_phase = 0	next_phase = 1	reward = -1.605693	array([[-0.9675365 , -0.15787062]], dtype=float32)

time = 544	action = 1	current_phase = 0	next_phase = 1	reward = -1.906827	array([[-0.9720613, -0.1639924]], dtype=float32)

time = 552	action = 0	current_phase = 1	next_phase = 0	reward = -0.302851	array([[1.0607972, 0.5612534]], dtype=float32)

time = 557	action = 1	current_phase = 1	next_phase = 0	reward = -1.063835	array([[1.061106  , 0.56298757]], dtype=float32)

time = 565	action = 0	current_phase = 0	next_phase = 1	reward = -0.570849	array([[-0.97556853, -0.16822138]], dtype=float32)

time = 570	action = 0	current_phase = 0	next_phase = 1	reward = -1.737067	array([[-0.9672321, -0.1579912]], dtype=float32)

time = 575	action = 0	current_phase = 0	next_phase = 1	reward = -1.617842	array([[-0.97172266, -0.16330415]], dtype=float32)

time = 580	action = 1	current_phase = 0	next_phase = 1	reward = -1.595877	array([[-0.97049505, -0.16424477]], dtype=float32)

time = 588	action = 0	current_phase = 1	next_phase = 0	reward = -0.162762	array([[1.061052 , 0.5609101]], dtype=float32)

time = 593	action = 1	current_phase = 1	next_phase = 0	reward = -1.083407	array([[1.0611885, 0.5622927]], dtype=float32)

time = 601	action = 0	current_phase = 0	next_phase = 1	reward = -1.180775	array([[-0.9771459 , -0.17619556]], dtype=float32)

time = 606	action = 0	current_phase = 0	next_phase = 1	reward = -1.043562	array([[-0.9774232 , -0.17576593]], dtype=float32)

time = 611	action = 0	current_phase = 0	next_phase = 1	reward = -0.914812	array([[-0.9760938 , -0.17578804]], dtype=float32)

time = 616	action = 1	current_phase = 0	next_phase = 1	reward = -1.294324	array([[-0.9758159 , -0.17592558]], dtype=float32)

time = 624	action = 0	current_phase = 1	next_phase = 0	reward = -0.077332	array([[1.0592008, 0.5633256]], dtype=float32)

time = 629	action = 1	current_phase = 1	next_phase = 0	reward = -2.005113	array([[1.0609856, 0.5658302]], dtype=float32)

time = 637	action = 0	current_phase = 0	next_phase = 1	reward = -0.463942	array([[-0.9803866 , -0.14301835]], dtype=float32)

time = 642	action = 0	current_phase = 0	next_phase = 1	reward = -0.308286	array([[-0.96866596, -0.17361139]], dtype=float32)

time = 647	action = 0	current_phase = 0	next_phase = 1	reward = -0.173631	array([[-0.9676078 , -0.17349127]], dtype=float32)

time = 652	action = 1	current_phase = 0	next_phase = 1	reward = -1.495365	array([[-0.9682921 , -0.17338711]], dtype=float32)

time = 660	action = 0	current_phase = 1	next_phase = 0	reward = -1.735706	array([[1.0616428, 0.5650916]], dtype=float32)

time = 665	action = 1	current_phase = 1	next_phase = 0	reward = -1.867899	array([[1.0395225, 0.5759182]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 674.00

Reason: TraCI requested termination.

Performance: 

 Duration: 35787ms

 Real time factor: 18.8337

 UPS: 155.391623

Vehicles: 

 Inserted: 92

 Running: 8

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 1ms answering queries (0.01ms on average).

Could not connect to TraCI server at localhost:59691 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 59691 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -1.731109	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -1.621862	array([[-0.9718044 , -0.16345435]], dtype=float32)

time = 40	action = 0	current_phase = 0	next_phase = 1	reward = -1.495931	array([[-0.970627  , -0.16355117]], dtype=float32)

time = 45	action = 1	current_phase = 0	next_phase = 1	reward = -1.491130	array([[-0.9705789 , -0.16419554]], dtype=float32)

time = 53	action = 0	current_phase = 1	next_phase = 0	reward = 0.079994	array([[1.0605373 , 0.56147194]], dtype=float32)

time = 58	action = 1	current_phase = 1	next_phase = 0	reward = -1.902100	array([[1.0604019, 0.5657813]], dtype=float32)

time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -0.507484	array([[-0.980431  , -0.14317963]], dtype=float32)

time = 71	action = 0	current_phase = 0	next_phase = 1	reward = -0.356808	array([[-0.9675501 , -0.17245802]], dtype=float32)

time = 76	action = 0	current_phase = 0	next_phase = 1	reward = -0.207843	array([[-0.96872795, -0.1733481 ]], dtype=float32)

time = 81	action = 0	current_phase = 0	next_phase = 1	reward = 0.329398	array([[-0.96795434, -0.17385232]], dtype=float32)

time = 86	action = 1	current_phase = 0	next_phase = 1	reward = -1.555993	array([[-0.9738837 , -0.15899412]], dtype=float32)

time = 94	action = 0	current_phase = 1	next_phase = 0	reward = -0.562608	array([[1.0625973, 0.5634643]], dtype=float32)

time = 99	action = 1	current_phase = 1	next_phase = 0	reward = -1.577431	array([[1.0614094 , 0.56307703]], dtype=float32)

time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -0.176747	array([[-0.9678436 , -0.17530921]], dtype=float32)

time = 112	action = 0	current_phase = 0	next_phase = 1	reward = 0.171999	array([[-0.96837884, -0.1745776 ]], dtype=float32)

time = 117	action = 0	current_phase = 0	next_phase = 1	reward = -1.319908	array([[-0.9815364 , -0.16582444]], dtype=float32)

time = 122	action = 0	current_phase = 0	next_phase = 1	reward = -1.688317	array([[-0.9716842 , -0.16538118]], dtype=float32)

time = 127	action = 1	current_phase = 0	next_phase = 1	reward = -1.756988	array([[-0.9714909 , -0.16359049]], dtype=float32)

time = 135	action = 0	current_phase = 1	next_phase = 0	reward = -0.214012	array([[1.0620754, 0.5606545]], dtype=float32)

time = 140	action = 1	current_phase = 1	next_phase = 0	reward = -0.986204	array([[1.0608497, 0.5630221]], dtype=float32)

time = 148	action = 0	current_phase = 0	next_phase = 1	reward = -1.459952	array([[-0.98113304, -0.16646276]], dtype=float32)

time = 153	action = 0	current_phase = 0	next_phase = 1	reward = -1.671179	array([[-0.97147447, -0.16466951]], dtype=float32)

time = 158	action = 0	current_phase = 0	next_phase = 1	reward = -1.554146	array([[-0.9716202, -0.1633977]], dtype=float32)

time = 163	action = 0	current_phase = 0	next_phase = 1	reward = -1.429969	array([[-0.97058594, -0.1644716 ]], dtype=float32)

time = 168	action = 1	current_phase = 0	next_phase = 1	reward = -0.867142	array([[-0.97112834, -0.16381153]], dtype=float32)

time = 176	action = 0	current_phase = 1	next_phase = 0	reward = -1.118831	array([[1.0696316 , 0.56501734]], dtype=float32)

time = 181	action = 1	current_phase = 1	next_phase = 0	reward = -2.050617	array([[1.0379496, 0.5759331]], dtype=float32)

time = 189	action = 0	current_phase = 0	next_phase = 1	reward = -0.399217	array([[-0.9801332 , -0.14266428]], dtype=float32)

time = 194	action = 0	current_phase = 0	next_phase = 1	reward = -0.242309	array([[-0.9678694 , -0.17368856]], dtype=float32)

time = 199	action = 0	current_phase = 0	next_phase = 1	reward = -0.173352	array([[-0.96887624, -0.17163406]], dtype=float32)

time = 204	action = 0	current_phase = 0	next_phase = 1	reward = -0.188335	array([[-0.96876734, -0.17272022]], dtype=float32)

time = 209	action = 1	current_phase = 0	next_phase = 1	reward = -2.015413	array([[-0.96796733, -0.15844145]], dtype=float32)

time = 217	action = 0	current_phase = 1	next_phase = 0	reward = -0.468193	array([[1.0604622, 0.5618853]], dtype=float32)

time = 222	action = 1	current_phase = 1	next_phase = 0	reward = -1.427411	array([[1.0618944, 0.5626472]], dtype=float32)

time = 230	action = 0	current_phase = 0	next_phase = 1	reward = 0.371115	array([[-0.9675247 , -0.17336828]], dtype=float32)

time = 235	action = 0	current_phase = 0	next_phase = 1	reward = -0.782102	array([[-0.9731642 , -0.15912911]], dtype=float32)

time = 240	action = 0	current_phase = 0	next_phase = 1	reward = -1.733206	array([[-0.96696746, -0.15737087]], dtype=float32)

time = 245	action = 0	current_phase = 0	next_phase = 1	reward = -1.626879	array([[-0.97128195, -0.16381907]], dtype=float32)

time = 250	action = 1	current_phase = 0	next_phase = 1	reward = -1.619765	array([[-0.97091323, -0.1638688 ]], dtype=float32)

time = 258	action = 0	current_phase = 1	next_phase = 0	reward = -0.161566	array([[1.0619199, 0.560495 ]], dtype=float32)

time = 263	action = 1	current_phase = 1	next_phase = 0	reward = -1.865771	array([[1.0610213, 0.5629107]], dtype=float32)

time = 271	action = 0	current_phase = 0	next_phase = 1	reward = -1.714290	array([[-0.97129864, -0.1642668 ]], dtype=float32)

time = 276	action = 0	current_phase = 0	next_phase = 1	reward = -1.607680	array([[-0.97152996, -0.16463159]], dtype=float32)

time = 281	action = 0	current_phase = 0	next_phase = 1	reward = -1.499539	array([[-0.9708438 , -0.16386823]], dtype=float32)

time = 286	action = 0	current_phase = 0	next_phase = 1	reward = -1.395034	array([[-0.9717405 , -0.16320431]], dtype=float32)

time = 291	action = 1	current_phase = 0	next_phase = 1	reward = -1.286551	array([[-0.9707131 , -0.16212961]], dtype=float32)

time = 299	action = 0	current_phase = 1	next_phase = 0	reward = -1.601870	array([[1.0610447 , 0.56570023]], dtype=float32)

time = 304	action = 1	current_phase = 1	next_phase = 0	reward = -1.907136	array([[1.0386503, 0.5761287]], dtype=float32)

time = 312	action = 0	current_phase = 0	next_phase = 1	reward = -0.314399	array([[-0.98100054, -0.14187609]], dtype=float32)

time = 317	action = 0	current_phase = 0	next_phase = 1	reward = -0.178390	array([[-0.9679936 , -0.17420086]], dtype=float32)

time = 322	action = 0	current_phase = 0	next_phase = 1	reward = 0.221432	array([[-0.96810955, -0.17351075]], dtype=float32)

time = 327	action = 0	current_phase = 0	next_phase = 1	reward = -1.315200	array([[-0.9732183 , -0.15744294]], dtype=float32)

time = 332	action = 1	current_phase = 0	next_phase = 1	reward = -2.005933	array([[-0.9718565, -0.1653957]], dtype=float32)

time = 340	action = 0	current_phase = 1	next_phase = 0	reward = -0.370809	array([[1.0610162, 0.5612858]], dtype=float32)

time = 345	action = 1	current_phase = 1	next_phase = 0	reward = -1.316347	array([[1.0611639, 0.5631409]], dtype=float32)

time = 353	action = 0	current_phase = 0	next_phase = 1	reward = 0.044147	array([[-0.9682737 , -0.17310649]], dtype=float32)

time = 358	action = 0	current_phase = 0	next_phase = 1	reward = -1.459409	array([[-0.9677159 , -0.15910748]], dtype=float32)

time = 363	action = 0	current_phase = 0	next_phase = 1	reward = -1.653780	array([[-0.97232246, -0.16441554]], dtype=float32)

time = 368	action = 0	current_phase = 0	next_phase = 1	reward = -1.531210	array([[-0.9710122 , -0.16405332]], dtype=float32)

time = 373	action = 1	current_phase = 0	next_phase = 1	reward = -1.413041	array([[-0.97041726, -0.16400564]], dtype=float32)

time = 381	action = 0	current_phase = 1	next_phase = 0	reward = 0.275776	array([[1.0609057 , 0.56142634]], dtype=float32)

time = 386	action = 1	current_phase = 1	next_phase = 0	reward = -1.660513	array([[1.0691477, 0.564814 ]], dtype=float32)

time = 394	action = 0	current_phase = 0	next_phase = 1	reward = -0.550120	array([[-0.9680893 , -0.17340544]], dtype=float32)

time = 399	action = 0	current_phase = 0	next_phase = 1	reward = -0.396855	array([[-0.96760297, -0.17322448]], dtype=float32)

time = 404	action = 0	current_phase = 0	next_phase = 1	reward = -0.250207	array([[-0.96822065, -0.17308873]], dtype=float32)

time = 409	action = 0	current_phase = 0	next_phase = 1	reward = -0.186038	array([[-0.96759415, -0.17313322]], dtype=float32)

time = 414	action = 1	current_phase = 0	next_phase = 1	reward = -0.559333	array([[-0.96843684, -0.1738466 ]], dtype=float32)

time = 422	action = 0	current_phase = 1	next_phase = 0	reward = -0.628092	array([[1.061342  , 0.56337523]], dtype=float32)

time = 427	action = 1	current_phase = 1	next_phase = 0	reward = -1.680397	array([[1.0617272, 0.563461 ]], dtype=float32)

time = 435	action = 0	current_phase = 0	next_phase = 1	reward = -0.228195	array([[-0.9684047 , -0.17470436]], dtype=float32)

time = 440	action = 0	current_phase = 0	next_phase = 1	reward = 0.067573	array([[-0.9678612 , -0.17406553]], dtype=float32)

time = 445	action = 0	current_phase = 0	next_phase = 1	reward = -0.559336	array([[-0.9653489 , -0.16340826]], dtype=float32)

time = 450	action = 0	current_phase = 0	next_phase = 1	reward = -1.735742	array([[-0.96743673, -0.15840662]], dtype=float32)

time = 455	action = 1	current_phase = 0	next_phase = 1	reward = -1.858610	array([[-0.9718656 , -0.16393597]], dtype=float32)

time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -0.282451	array([[1.0616663, 0.5618868]], dtype=float32)

time = 468	action = 1	current_phase = 1	next_phase = 0	reward = -0.778634	array([[1.0616988 , 0.56294113]], dtype=float32)

time = 476	action = 0	current_phase = 0	next_phase = 1	reward = -1.007805	array([[-0.9730793 , -0.15908673]], dtype=float32)

time = 481	action = 0	current_phase = 0	next_phase = 1	reward = -1.707320	array([[-0.9716837 , -0.16531837]], dtype=float32)

time = 486	action = 0	current_phase = 0	next_phase = 1	reward = -1.594713	array([[-0.97155917, -0.16390336]], dtype=float32)

time = 491	action = 0	current_phase = 0	next_phase = 1	reward = -1.487796	array([[-0.9715022 , -0.16331376]], dtype=float32)

time = 496	action = 1	current_phase = 0	next_phase = 1	reward = -1.384770	array([[-0.97074366, -0.16401958]], dtype=float32)

time = 504	action = 0	current_phase = 1	next_phase = 0	reward = -0.136337	array([[1.0597936, 0.5613679]], dtype=float32)

time = 509	action = 1	current_phase = 1	next_phase = 0	reward = -2.013025	array([[1.0604072, 0.5661198]], dtype=float32)

time = 517	action = 0	current_phase = 0	next_phase = 1	reward = -0.469206	array([[-0.98075634, -0.14330493]], dtype=float32)

time = 522	action = 0	current_phase = 0	next_phase = 1	reward = -0.315008	array([[-0.9682566 , -0.17376596]], dtype=float32)

time = 527	action = 0	current_phase = 0	next_phase = 1	reward = -0.173963	array([[-0.9683226 , -0.17421107]], dtype=float32)

time = 532	action = 0	current_phase = 0	next_phase = 1	reward = 0.245299	array([[-0.9683664 , -0.17259184]], dtype=float32)

time = 537	action = 1	current_phase = 0	next_phase = 1	reward = -1.778561	array([[-0.97331154, -0.15915681]], dtype=float32)

time = 545	action = 0	current_phase = 1	next_phase = 0	reward = -0.515221	array([[1.059345 , 0.5623675]], dtype=float32)

time = 550	action = 1	current_phase = 1	next_phase = 0	reward = -1.505748	array([[1.0618714, 0.5626037]], dtype=float32)

time = 558	action = 0	current_phase = 0	next_phase = 1	reward = -0.163513	array([[-0.9682283 , -0.17377481]], dtype=float32)

time = 563	action = 0	current_phase = 0	next_phase = 1	reward = 0.000893	array([[-0.96893644, -0.17323485]], dtype=float32)

time = 568	action = 0	current_phase = 0	next_phase = 1	reward = -1.463178	array([[-0.9676538 , -0.15789115]], dtype=float32)

time = 573	action = 0	current_phase = 0	next_phase = 1	reward = -1.665319	array([[-0.9713485 , -0.16467592]], dtype=float32)

time = 578	action = 1	current_phase = 0	next_phase = 1	reward = -1.705357	array([[-0.97080064, -0.1642884 ]], dtype=float32)

time = 586	action = 0	current_phase = 1	next_phase = 0	reward = -0.194317	array([[1.0614288 , 0.56065214]], dtype=float32)

time = 591	action = 1	current_phase = 1	next_phase = 0	reward = -1.255081	array([[1.0606116, 0.5638   ]], dtype=float32)

time = 599	action = 0	current_phase = 0	next_phase = 1	reward = -1.599303	array([[-0.9676188 , -0.15852891]], dtype=float32)

time = 604	action = 0	current_phase = 0	next_phase = 1	reward = -1.640376	array([[-0.97166103, -0.16531569]], dtype=float32)

time = 609	action = 0	current_phase = 0	next_phase = 1	reward = -1.524462	array([[-0.970786  , -0.16295421]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -1.413869	array([[-0.9698601, -0.1636371]], dtype=float32)

time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -1.031012	array([[-0.97069913, -0.16311571]], dtype=float32)

time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -1.323473	array([[1.0607518 , 0.56540763]], dtype=float32)

time = 632	action = 1	current_phase = 1	next_phase = 0	reward = -2.007661	array([[1.0376823 , 0.57601756]], dtype=float32)

time = 640	action = 0	current_phase = 0	next_phase = 1	reward = -0.359903	array([[-0.98087674, -0.14307407]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.210260	array([[-0.9688234 , -0.17177382]], dtype=float32)

time = 650	action = 0	current_phase = 0	next_phase = 1	reward = 0.361928	array([[-0.96765876, -0.17277077]], dtype=float32)

time = 655	action = 0	current_phase = 0	next_phase = 1	reward = -0.841795	array([[-0.9731322 , -0.15788442]], dtype=float32)

time = 660	action = 1	current_phase = 0	next_phase = 1	reward = -2.118659	array([[-0.9676303 , -0.15828487]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 36746ms

 Real time factor: 18.2061

 UPS: 151.744408

Vehicles: 

 Inserted: 92

 Running: 10

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 4ms answering queries (0.04ms on average).

Could not connect to TraCI server at localhost:36377 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 36377 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (4ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.241148	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.436842	array([[1.0605273, 0.5609466]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.282214	array([[1.0617688, 0.5633787]], dtype=float32)

time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -0.801984	array([[1.0630009, 0.5616622]], dtype=float32)

time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -1.118505	array([[-0.97302115, -0.15916142]], dtype=float32)

time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -2.070484	array([[-0.9718436, -0.1648905]], dtype=float32)

time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.414981	array([[1.0601635, 0.5619509]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.266250	array([[1.0617828, 0.5622121]], dtype=float32)

time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -0.850964	array([[1.0611151, 0.563337 ]], dtype=float32)

time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.207686	array([[-0.97314066, -0.15914747]], dtype=float32)

time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.014163	array([[-0.9721169 , -0.16517934]], dtype=float32)

time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.377084	array([[1.0606918, 0.5617851]], dtype=float32)

time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.222009	array([[1.0626414 , 0.56264246]], dtype=float32)

time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.009937	array([[1.0614806 , 0.56266487]], dtype=float32)

time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.405024	array([[-0.959387  , -0.15127449]], dtype=float32)

time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.951706	array([[-0.9722129, -0.1641387]], dtype=float32)

time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -0.339037	array([[1.0613471, 0.5618478]], dtype=float32)

time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.193666	array([[1.0619515 , 0.56279266]], dtype=float32)

time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.178461	array([[1.0612848, 0.5635407]], dtype=float32)

time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.599404	array([[-0.9679417 , -0.15926652]], dtype=float32)

time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -1.921845	array([[-0.9711615 , -0.16488183]], dtype=float32)

time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.314234	array([[1.0599874 , 0.56189656]], dtype=float32)

time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.176852	array([[1.0614445, 0.5630372]], dtype=float32)

time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.422978	array([[1.0614761, 0.5625372]], dtype=float32)

time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.726860	array([[-0.96736044, -0.15842944]], dtype=float32)

time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -1.829246	array([[-0.9714433, -0.1636824]], dtype=float32)

time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.266238	array([[1.0613371 , 0.56179297]], dtype=float32)

time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -0.155625	array([[1.0616604 , 0.56273764]], dtype=float32)

time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -0.225666	array([[1.060976  , 0.56335986]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.657512	array([[-0.9679843 , -0.17380233]], dtype=float32)

time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.742199	array([[-0.967744  , -0.17264885]], dtype=float32)

time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -0.248010	array([[1.0612397 , 0.56291234]], dtype=float32)

time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.165712	array([[1.0621347 , 0.56226367]], dtype=float32)

time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -0.359931	array([[1.0613531, 0.5630885]], dtype=float32)

time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.620949	array([[-0.96798915, -0.17302175]], dtype=float32)

time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.676884	array([[-0.9679504 , -0.17382544]], dtype=float32)

time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.219107	array([[1.0611892 , 0.56249535]], dtype=float32)

time = 260	action = 0	current_phase = 1	next_phase = 0	reward = 0.384846	array([[1.0609754 , 0.56351763]], dtype=float32)

time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.238629	array([[1.0698005, 0.5653567]], dtype=float32)

time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.586460	array([[-0.96796346, -0.17357218]], dtype=float32)

time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -1.627305	array([[-0.9675813, -0.1733264]], dtype=float32)

time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -0.202611	array([[1.0619893 , 0.56225926]], dtype=float32)

time = 291	action = 0	current_phase = 1	next_phase = 0	reward = 0.329446	array([[1.0607804 , 0.56316483]], dtype=float32)

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.504496	array([[1.0702857 , 0.56446576]], dtype=float32)

time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.562148	array([[-0.9679999 , -0.17331062]], dtype=float32)

time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -1.567012	array([[-0.9680408 , -0.17330478]], dtype=float32)

time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.169494	array([[1.0619901 , 0.56305695]], dtype=float32)

time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.202555	array([[1.0605469 , 0.56297386]], dtype=float32)

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.727527	array([[1.0680348, 0.5634945]], dtype=float32)

time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.524467	array([[-0.9800405 , -0.14333637]], dtype=float32)

time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.521228	array([[-0.96809447, -0.1722692 ]], dtype=float32)

time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.163316	array([[1.0613971, 0.5624069]], dtype=float32)

time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.004041	array([[1.0612129, 0.5621419]], dtype=float32)

time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.894261	array([[1.0613083, 0.5653296]], dtype=float32)

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.489935	array([[-0.9800193 , -0.14319733]], dtype=float32)

time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.454400	array([[-0.9672562 , -0.17360145]], dtype=float32)

time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.183843	array([[1.0606086 , 0.56217426]], dtype=float32)

time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.149358	array([[1.0613581, 0.5629238]], dtype=float32)

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -2.006485	array([[1.0617975, 0.5649792]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -0.462483	array([[-0.9798535 , -0.14250554]], dtype=float32)

time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.418308	array([[-0.9678894 , -0.17379513]], dtype=float32)

time = 410	action = 0	current_phase = 1	next_phase = 0	reward = 0.358152	array([[1.0608277, 0.5636608]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.896995	array([[1.0700282, 0.5644633]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.094500	array([[1.06195   , 0.56550515]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.406224	array([[-0.98058164, -0.14342213]], dtype=float32)

time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.351339	array([[-0.96829134, -0.17396946]], dtype=float32)

time = 441	action = 0	current_phase = 1	next_phase = 0	reward = 0.275543	array([[1.0621498, 0.562966 ]], dtype=float32)

time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -1.173348	array([[1.0702055 , 0.56429774]], dtype=float32)

time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -2.073403	array([[1.039571 , 0.5754585]], dtype=float32)

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -0.415454	array([[-0.9802848 , -0.14265329]], dtype=float32)

time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.355775	array([[-0.968342  , -0.17224194]], dtype=float32)

time = 472	action = 0	current_phase = 1	next_phase = 0	reward = 0.208891	array([[1.0618953 , 0.56288636]], dtype=float32)

time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -1.319690	array([[1.0629127, 0.5659685]], dtype=float32)

time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -2.000517	array([[1.0385668, 0.5755674]], dtype=float32)

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.364359	array([[-0.98038787, -0.1438483 ]], dtype=float32)

time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.301948	array([[-0.9683773 , -0.17256804]], dtype=float32)

time = 503	action = 0	current_phase = 1	next_phase = 0	reward = 0.051314	array([[1.0607693 , 0.56258327]], dtype=float32)

time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -1.459786	array([[1.0624161, 0.5666406]], dtype=float32)

time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -1.968539	array([[1.0392649, 0.575066 ]], dtype=float32)

time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.352927	array([[-0.9806229 , -0.14362419]], dtype=float32)

time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -1.309335	array([[-0.96845216, -0.17373477]], dtype=float32)

time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -0.113060	array([[1.0615649 , 0.56240803]], dtype=float32)

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.600074	array([[1.062132 , 0.5649651]], dtype=float32)

time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.901930	array([[1.0394701 , 0.57557005]], dtype=float32)

time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.293629	array([[-0.98031235, -0.1434156 ]], dtype=float32)

time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -0.764795	array([[-0.96843284, -0.1733118 ]], dtype=float32)

time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -0.849980	array([[1.0700573, 0.5643449]], dtype=float32)

time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.734332	array([[1.0612521 , 0.56513447]], dtype=float32)

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.840401	array([[1.040379  , 0.57513726]], dtype=float32)

time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.269762	array([[-0.98025864, -0.14274053]], dtype=float32)

time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -0.785722	array([[-0.9690328 , -0.17403218]], dtype=float32)

time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -1.064307	array([[1.0694107, 0.5647367]], dtype=float32)

time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -1.707154	array([[1.0383812 , 0.57549626]], dtype=float32)

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.800404	array([[1.0404774, 0.5751138]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -0.250926	array([[-0.9801533 , -0.14225113]], dtype=float32)

time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -0.861974	array([[-0.9682665, -0.1726887]], dtype=float32)

time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -1.315786	array([[1.0688444, 0.5654818]], dtype=float32)

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -1.689937	array([[1.0377684, 0.5752732]], dtype=float32)

time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.760154	array([[1.040428  , 0.57471204]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.213059	array([[-0.9802719 , -0.14171419]], dtype=float32)

time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.013089	array([[-0.9687452 , -0.17236203]], dtype=float32)

time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.457292	array([[1.0621868 , 0.56677496]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -1.656960	array([[1.0386946, 0.5752987]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 33340ms

 Real time factor: 20.066

 UPS: 159.778044

Vehicles: 

 Inserted: 92

 Running: 10

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 0ms answering queries (0.00ms on average).

Could not connect to TraCI server at localhost:34927 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 34927 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (2ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.241148	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.436842	array([[1.0605273, 0.5609466]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.282214	array([[1.0617688, 0.5633787]], dtype=float32)

time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -0.801984	array([[1.0630009, 0.5616622]], dtype=float32)

time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -1.118505	array([[-0.97302115, -0.15916142]], dtype=float32)

time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -2.070484	array([[-0.9718436, -0.1648905]], dtype=float32)

time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.414981	array([[1.0601635, 0.5619509]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.266250	array([[1.0617828, 0.5622121]], dtype=float32)

time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -0.850964	array([[1.0611151, 0.563337 ]], dtype=float32)

time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.207686	array([[-0.97314066, -0.15914747]], dtype=float32)

time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.014163	array([[-0.9721169 , -0.16517934]], dtype=float32)

time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.377084	array([[1.0606918, 0.5617851]], dtype=float32)

time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.222009	array([[1.0626414 , 0.56264246]], dtype=float32)

time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.009937	array([[1.0614806 , 0.56266487]], dtype=float32)

time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.405024	array([[-0.959387  , -0.15127449]], dtype=float32)

time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.951706	array([[-0.9722129, -0.1641387]], dtype=float32)

time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -0.339037	array([[1.0613471, 0.5618478]], dtype=float32)

time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.193666	array([[1.0619515 , 0.56279266]], dtype=float32)

time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.178461	array([[1.0612848, 0.5635407]], dtype=float32)

time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.599404	array([[-0.9679417 , -0.15926652]], dtype=float32)

time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -1.921845	array([[-0.9711615 , -0.16488183]], dtype=float32)

time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.314234	array([[1.0599874 , 0.56189656]], dtype=float32)

time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.176852	array([[1.0614445, 0.5630372]], dtype=float32)

time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.422978	array([[1.0614761, 0.5625372]], dtype=float32)

time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.726860	array([[-0.96736044, -0.15842944]], dtype=float32)

time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -1.829246	array([[-0.9714433, -0.1636824]], dtype=float32)

time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.266238	array([[1.0613371 , 0.56179297]], dtype=float32)

time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -0.155625	array([[1.0616604 , 0.56273764]], dtype=float32)

time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -0.225666	array([[1.060976  , 0.56335986]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.657512	array([[-0.9679843 , -0.17380233]], dtype=float32)

time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.742199	array([[-0.967744  , -0.17264885]], dtype=float32)

time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -0.248010	array([[1.0612397 , 0.56291234]], dtype=float32)

time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.165712	array([[1.0621347 , 0.56226367]], dtype=float32)

time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -0.359931	array([[1.0613531, 0.5630885]], dtype=float32)

time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.620949	array([[-0.96798915, -0.17302175]], dtype=float32)

time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.676884	array([[-0.9679504 , -0.17382544]], dtype=float32)

time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.219107	array([[1.0611892 , 0.56249535]], dtype=float32)

time = 260	action = 0	current_phase = 1	next_phase = 0	reward = 0.384846	array([[1.0609754 , 0.56351763]], dtype=float32)

time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.238629	array([[1.0698005, 0.5653567]], dtype=float32)

time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.586460	array([[-0.96796346, -0.17357218]], dtype=float32)

time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -1.627305	array([[-0.9675813, -0.1733264]], dtype=float32)

time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -0.202611	array([[1.0619893 , 0.56225926]], dtype=float32)

time = 291	action = 0	current_phase = 1	next_phase = 0	reward = 0.329446	array([[1.0607804 , 0.56316483]], dtype=float32)

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.504496	array([[1.0702857 , 0.56446576]], dtype=float32)

time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.562148	array([[-0.9679999 , -0.17331062]], dtype=float32)

time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -1.567012	array([[-0.9680408 , -0.17330478]], dtype=float32)

time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.169494	array([[1.0619901 , 0.56305695]], dtype=float32)

time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.202555	array([[1.0605469 , 0.56297386]], dtype=float32)

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.727527	array([[1.0680348, 0.5634945]], dtype=float32)

time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.524467	array([[-0.9800405 , -0.14333637]], dtype=float32)

time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.521228	array([[-0.96809447, -0.1722692 ]], dtype=float32)

time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.163316	array([[1.0613971, 0.5624069]], dtype=float32)

time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.004041	array([[1.0612129, 0.5621419]], dtype=float32)

time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.894261	array([[1.0613083, 0.5653296]], dtype=float32)

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.489935	array([[-0.9800193 , -0.14319733]], dtype=float32)

time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.454400	array([[-0.9672562 , -0.17360145]], dtype=float32)

time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.183843	array([[1.0606086 , 0.56217426]], dtype=float32)

time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.149358	array([[1.0613581, 0.5629238]], dtype=float32)

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -2.006485	array([[1.0617975, 0.5649792]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -0.462483	array([[-0.9798535 , -0.14250554]], dtype=float32)

time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.418308	array([[-0.9678894 , -0.17379513]], dtype=float32)

time = 410	action = 0	current_phase = 1	next_phase = 0	reward = 0.358152	array([[1.0608277, 0.5636608]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.896995	array([[1.0700282, 0.5644633]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.094500	array([[1.06195   , 0.56550515]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.406224	array([[-0.98058164, -0.14342213]], dtype=float32)

time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.351339	array([[-0.96829134, -0.17396946]], dtype=float32)

time = 441	action = 0	current_phase = 1	next_phase = 0	reward = 0.275543	array([[1.0621498, 0.562966 ]], dtype=float32)

time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -1.173348	array([[1.0702055 , 0.56429774]], dtype=float32)

time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -2.073403	array([[1.039571 , 0.5754585]], dtype=float32)

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -0.415454	array([[-0.9802848 , -0.14265329]], dtype=float32)

time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.355775	array([[-0.968342  , -0.17224194]], dtype=float32)

time = 472	action = 0	current_phase = 1	next_phase = 0	reward = 0.208891	array([[1.0618953 , 0.56288636]], dtype=float32)

time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -1.319690	array([[1.0629127, 0.5659685]], dtype=float32)

time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -2.000517	array([[1.0385668, 0.5755674]], dtype=float32)

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.364359	array([[-0.98038787, -0.1438483 ]], dtype=float32)

time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.301948	array([[-0.9683773 , -0.17256804]], dtype=float32)

time = 503	action = 0	current_phase = 1	next_phase = 0	reward = 0.051314	array([[1.0607693 , 0.56258327]], dtype=float32)

time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -1.459786	array([[1.0624161, 0.5666406]], dtype=float32)

time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -1.968539	array([[1.0392649, 0.575066 ]], dtype=float32)

time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.352927	array([[-0.9806229 , -0.14362419]], dtype=float32)

time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -1.309335	array([[-0.96845216, -0.17373477]], dtype=float32)

time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -0.113060	array([[1.0615649 , 0.56240803]], dtype=float32)

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.600074	array([[1.062132 , 0.5649651]], dtype=float32)

time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.901930	array([[1.0394701 , 0.57557005]], dtype=float32)

time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.293629	array([[-0.98031235, -0.1434156 ]], dtype=float32)

time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -0.764795	array([[-0.96843284, -0.1733118 ]], dtype=float32)

time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -0.849980	array([[1.0700573, 0.5643449]], dtype=float32)

time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.734332	array([[1.0612521 , 0.56513447]], dtype=float32)

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.840401	array([[1.040379  , 0.57513726]], dtype=float32)

time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.269762	array([[-0.98025864, -0.14274053]], dtype=float32)

time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -0.785722	array([[-0.9690328 , -0.17403218]], dtype=float32)

time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -1.064307	array([[1.0694107, 0.5647367]], dtype=float32)

time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -1.707154	array([[1.0383812 , 0.57549626]], dtype=float32)

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.800404	array([[1.0404774, 0.5751138]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -0.250926	array([[-0.9801533 , -0.14225113]], dtype=float32)

time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -0.861974	array([[-0.9682665, -0.1726887]], dtype=float32)

time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -1.315786	array([[1.0688444, 0.5654818]], dtype=float32)

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -1.689937	array([[1.0377684, 0.5752732]], dtype=float32)

time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.760154	array([[1.040428  , 0.57471204]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.213059	array([[-0.9802719 , -0.14171419]], dtype=float32)

time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.013089	array([[-0.9687452 , -0.17236203]], dtype=float32)

time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.457292	array([[1.0621868 , 0.56677496]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -1.656960	array([[1.0386946, 0.5752987]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 41609ms

 Real time factor: 16.0783

 UPS: 128.025187

Vehicles: 

 Inserted: 92

 Running: 10

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 0ms answering queries (0.00ms on average).

Could not connect to TraCI server at localhost:33539 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 33539 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (2ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (1ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.241148	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.436842	array([[1.0605273, 0.5609466]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.282214	array([[1.0617688, 0.5633787]], dtype=float32)

time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -0.801984	array([[1.0630009, 0.5616622]], dtype=float32)

time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -1.118505	array([[-0.97302115, -0.15916142]], dtype=float32)

time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -2.070484	array([[-0.9718436, -0.1648905]], dtype=float32)

time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.414981	array([[1.0601635, 0.5619509]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.266250	array([[1.0617828, 0.5622121]], dtype=float32)

time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -0.850964	array([[1.0611151, 0.563337 ]], dtype=float32)

time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.207686	array([[-0.97314066, -0.15914747]], dtype=float32)

time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.014163	array([[-0.9721169 , -0.16517934]], dtype=float32)

time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.377084	array([[1.0606918, 0.5617851]], dtype=float32)

time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.222009	array([[1.0626414 , 0.56264246]], dtype=float32)

time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.009937	array([[1.0614806 , 0.56266487]], dtype=float32)

time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.405024	array([[-0.959387  , -0.15127449]], dtype=float32)

time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.951706	array([[-0.9722129, -0.1641387]], dtype=float32)

time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -0.339037	array([[1.0613471, 0.5618478]], dtype=float32)

time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.193666	array([[1.0619515 , 0.56279266]], dtype=float32)

time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.178461	array([[1.0612848, 0.5635407]], dtype=float32)

time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.599404	array([[-0.9679417 , -0.15926652]], dtype=float32)

time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -1.921845	array([[-0.9711615 , -0.16488183]], dtype=float32)

time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.314234	array([[1.0599874 , 0.56189656]], dtype=float32)

time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.176852	array([[1.0614445, 0.5630372]], dtype=float32)

time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.422978	array([[1.0614761, 0.5625372]], dtype=float32)

time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.726860	array([[-0.96736044, -0.15842944]], dtype=float32)

time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -1.829246	array([[-0.9714433, -0.1636824]], dtype=float32)

time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.266238	array([[1.0613371 , 0.56179297]], dtype=float32)

time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -0.155625	array([[1.0616604 , 0.56273764]], dtype=float32)

time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -0.225666	array([[1.060976  , 0.56335986]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.657512	array([[-0.9679843 , -0.17380233]], dtype=float32)

time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.742199	array([[-0.967744  , -0.17264885]], dtype=float32)

time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -0.248010	array([[1.0612397 , 0.56291234]], dtype=float32)

time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.165712	array([[1.0621347 , 0.56226367]], dtype=float32)

time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -0.359931	array([[1.0613531, 0.5630885]], dtype=float32)

time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.620949	array([[-0.96798915, -0.17302175]], dtype=float32)

time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.676884	array([[-0.9679504 , -0.17382544]], dtype=float32)

time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.219107	array([[1.0611892 , 0.56249535]], dtype=float32)

time = 260	action = 0	current_phase = 1	next_phase = 0	reward = 0.384846	array([[1.0609754 , 0.56351763]], dtype=float32)

time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.238629	array([[1.0698005, 0.5653567]], dtype=float32)

time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.586460	array([[-0.96796346, -0.17357218]], dtype=float32)

time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -1.627305	array([[-0.9675813, -0.1733264]], dtype=float32)

time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -0.202611	array([[1.0619893 , 0.56225926]], dtype=float32)

time = 291	action = 0	current_phase = 1	next_phase = 0	reward = 0.329446	array([[1.0607804 , 0.56316483]], dtype=float32)

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.504496	array([[1.0702857 , 0.56446576]], dtype=float32)

time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.562148	array([[-0.9679999 , -0.17331062]], dtype=float32)

time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -1.567012	array([[-0.9680408 , -0.17330478]], dtype=float32)

time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.169494	array([[1.0619901 , 0.56305695]], dtype=float32)

time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.202555	array([[1.0605469 , 0.56297386]], dtype=float32)

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.727527	array([[1.0680348, 0.5634945]], dtype=float32)

time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.524467	array([[-0.9800405 , -0.14333637]], dtype=float32)

time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.521228	array([[-0.96809447, -0.1722692 ]], dtype=float32)

time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.163316	array([[1.0613971, 0.5624069]], dtype=float32)

time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.004041	array([[1.0612129, 0.5621419]], dtype=float32)

time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.894261	array([[1.0613083, 0.5653296]], dtype=float32)

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.489935	array([[-0.9800193 , -0.14319733]], dtype=float32)

time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.454400	array([[-0.9672562 , -0.17360145]], dtype=float32)

time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.183843	array([[1.0606086 , 0.56217426]], dtype=float32)

time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.149358	array([[1.0613581, 0.5629238]], dtype=float32)

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -2.006485	array([[1.0617975, 0.5649792]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -0.462483	array([[-0.9798535 , -0.14250554]], dtype=float32)

time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.418308	array([[-0.9678894 , -0.17379513]], dtype=float32)

time = 410	action = 0	current_phase = 1	next_phase = 0	reward = 0.358152	array([[1.0608277, 0.5636608]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.896995	array([[1.0700282, 0.5644633]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.094500	array([[1.06195   , 0.56550515]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.406224	array([[-0.98058164, -0.14342213]], dtype=float32)

time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.351339	array([[-0.96829134, -0.17396946]], dtype=float32)

time = 441	action = 0	current_phase = 1	next_phase = 0	reward = 0.275543	array([[1.0621498, 0.562966 ]], dtype=float32)

time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -1.173348	array([[1.0702055 , 0.56429774]], dtype=float32)

time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -2.073403	array([[1.039571 , 0.5754585]], dtype=float32)

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -0.415454	array([[-0.9802848 , -0.14265329]], dtype=float32)

time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.355775	array([[-0.968342  , -0.17224194]], dtype=float32)

time = 472	action = 0	current_phase = 1	next_phase = 0	reward = 0.208891	array([[1.0618953 , 0.56288636]], dtype=float32)

time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -1.319690	array([[1.0629127, 0.5659685]], dtype=float32)

time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -2.000517	array([[1.0385668, 0.5755674]], dtype=float32)

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.364359	array([[-0.98038787, -0.1438483 ]], dtype=float32)

time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.301948	array([[-0.9683773 , -0.17256804]], dtype=float32)

time = 503	action = 0	current_phase = 1	next_phase = 0	reward = 0.051314	array([[1.0607693 , 0.56258327]], dtype=float32)

time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -1.459786	array([[1.0624161, 0.5666406]], dtype=float32)

time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -1.968539	array([[1.0392649, 0.575066 ]], dtype=float32)

time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.352927	array([[-0.9806229 , -0.14362419]], dtype=float32)

time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -1.309335	array([[-0.96845216, -0.17373477]], dtype=float32)

time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -0.113060	array([[1.0615649 , 0.56240803]], dtype=float32)

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.600074	array([[1.062132 , 0.5649651]], dtype=float32)

time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.901930	array([[1.0394701 , 0.57557005]], dtype=float32)

time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.293629	array([[-0.98031235, -0.1434156 ]], dtype=float32)

time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -0.764795	array([[-0.96843284, -0.1733118 ]], dtype=float32)

time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -0.849980	array([[1.0700573, 0.5643449]], dtype=float32)

time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.734332	array([[1.0612521 , 0.56513447]], dtype=float32)

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.840401	array([[1.040379  , 0.57513726]], dtype=float32)

time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.269762	array([[-0.98025864, -0.14274053]], dtype=float32)

time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -0.785722	array([[-0.9690328 , -0.17403218]], dtype=float32)

time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -1.064307	array([[1.0694107, 0.5647367]], dtype=float32)

time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -1.707154	array([[1.0383812 , 0.57549626]], dtype=float32)

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.800404	array([[1.0404774, 0.5751138]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -0.250926	array([[-0.9801533 , -0.14225113]], dtype=float32)

time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -0.861974	array([[-0.9682665, -0.1726887]], dtype=float32)

time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -1.315786	array([[1.0688444, 0.5654818]], dtype=float32)

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -1.689937	array([[1.0377684, 0.5752732]], dtype=float32)

time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.760154	array([[1.040428  , 0.57471204]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.213059	array([[-0.9802719 , -0.14171419]], dtype=float32)

time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.013089	array([[-0.9687452 , -0.17236203]], dtype=float32)

time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.457292	array([[1.0621868 , 0.56677496]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -1.656960	array([[1.0386946, 0.5752987]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 38886ms

 Real time factor: 17.2041

 UPS: 136.990176

Vehicles: 

 Inserted: 92

 Running: 10

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 1ms answering queries (0.01ms on average).

Could not connect to TraCI server at localhost:58187 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 58187 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (1ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.241148	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.436842	array([[1.0605273, 0.5609466]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.282214	array([[1.0617688, 0.5633787]], dtype=float32)

time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -0.801984	array([[1.0630009, 0.5616622]], dtype=float32)

time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -1.118505	array([[-0.97302115, -0.15916142]], dtype=float32)

time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -2.070484	array([[-0.9718436, -0.1648905]], dtype=float32)

time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.414981	array([[1.0601635, 0.5619509]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.266250	array([[1.0617828, 0.5622121]], dtype=float32)

time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -0.850964	array([[1.0611151, 0.563337 ]], dtype=float32)

time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.207686	array([[-0.97314066, -0.15914747]], dtype=float32)

time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.014163	array([[-0.9721169 , -0.16517934]], dtype=float32)

time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.377084	array([[1.0606918, 0.5617851]], dtype=float32)

time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.222009	array([[1.0626414 , 0.56264246]], dtype=float32)

time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.009937	array([[1.0614806 , 0.56266487]], dtype=float32)

time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.405024	array([[-0.959387  , -0.15127449]], dtype=float32)

time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.951706	array([[-0.9722129, -0.1641387]], dtype=float32)

time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -0.339037	array([[1.0613471, 0.5618478]], dtype=float32)

time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.193666	array([[1.0619515 , 0.56279266]], dtype=float32)

time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.178461	array([[1.0612848, 0.5635407]], dtype=float32)

time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.599404	array([[-0.9679417 , -0.15926652]], dtype=float32)

time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -1.921845	array([[-0.9711615 , -0.16488183]], dtype=float32)

time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.314234	array([[1.0599874 , 0.56189656]], dtype=float32)

time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.176852	array([[1.0614445, 0.5630372]], dtype=float32)

time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.422978	array([[1.0614761, 0.5625372]], dtype=float32)

time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.726860	array([[-0.96736044, -0.15842944]], dtype=float32)

time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -1.829246	array([[-0.9714433, -0.1636824]], dtype=float32)

time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.266238	array([[1.0613371 , 0.56179297]], dtype=float32)

time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -0.155625	array([[1.0616604 , 0.56273764]], dtype=float32)

time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -0.225666	array([[1.060976  , 0.56335986]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.657512	array([[-0.9679843 , -0.17380233]], dtype=float32)

time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.742199	array([[-0.967744  , -0.17264885]], dtype=float32)

time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -0.248010	array([[1.0612397 , 0.56291234]], dtype=float32)

time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.165712	array([[1.0621347 , 0.56226367]], dtype=float32)

time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -0.359931	array([[1.0613531, 0.5630885]], dtype=float32)

time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.620949	array([[-0.96798915, -0.17302175]], dtype=float32)

time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.676884	array([[-0.9679504 , -0.17382544]], dtype=float32)

time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.219107	array([[1.0611892 , 0.56249535]], dtype=float32)

time = 260	action = 0	current_phase = 1	next_phase = 0	reward = 0.384846	array([[1.0609754 , 0.56351763]], dtype=float32)

time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.238629	array([[1.0698005, 0.5653567]], dtype=float32)

time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.586460	array([[-0.96796346, -0.17357218]], dtype=float32)

time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -1.627305	array([[-0.9675813, -0.1733264]], dtype=float32)

time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -0.202611	array([[1.0619893 , 0.56225926]], dtype=float32)

time = 291	action = 0	current_phase = 1	next_phase = 0	reward = 0.329446	array([[1.0607804 , 0.56316483]], dtype=float32)

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.504496	array([[1.0702857 , 0.56446576]], dtype=float32)

time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.562148	array([[-0.9679999 , -0.17331062]], dtype=float32)

time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -1.567012	array([[-0.9680408 , -0.17330478]], dtype=float32)

time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.169494	array([[1.0619901 , 0.56305695]], dtype=float32)

time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.202555	array([[1.0605469 , 0.56297386]], dtype=float32)

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.727527	array([[1.0680348, 0.5634945]], dtype=float32)

time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.524467	array([[-0.9800405 , -0.14333637]], dtype=float32)

time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.521228	array([[-0.96809447, -0.1722692 ]], dtype=float32)

time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.163316	array([[1.0613971, 0.5624069]], dtype=float32)

time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.004041	array([[1.0612129, 0.5621419]], dtype=float32)

time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.894261	array([[1.0613083, 0.5653296]], dtype=float32)

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.489935	array([[-0.9800193 , -0.14319733]], dtype=float32)

time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.454400	array([[-0.9672562 , -0.17360145]], dtype=float32)

time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.183843	array([[1.0606086 , 0.56217426]], dtype=float32)

time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.149358	array([[1.0613581, 0.5629238]], dtype=float32)

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -2.006485	array([[1.0617975, 0.5649792]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -0.462483	array([[-0.9798535 , -0.14250554]], dtype=float32)

time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.418308	array([[-0.9678894 , -0.17379513]], dtype=float32)

time = 410	action = 0	current_phase = 1	next_phase = 0	reward = 0.358152	array([[1.0608277, 0.5636608]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.896995	array([[1.0700282, 0.5644633]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.094500	array([[1.06195   , 0.56550515]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.406224	array([[-0.98058164, -0.14342213]], dtype=float32)

time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.351339	array([[-0.96829134, -0.17396946]], dtype=float32)

time = 441	action = 0	current_phase = 1	next_phase = 0	reward = 0.275543	array([[1.0621498, 0.562966 ]], dtype=float32)

time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -1.173348	array([[1.0702055 , 0.56429774]], dtype=float32)

time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -2.073403	array([[1.039571 , 0.5754585]], dtype=float32)

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -0.415454	array([[-0.9802848 , -0.14265329]], dtype=float32)

time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.355775	array([[-0.968342  , -0.17224194]], dtype=float32)

time = 472	action = 0	current_phase = 1	next_phase = 0	reward = 0.208891	array([[1.0618953 , 0.56288636]], dtype=float32)

time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -1.319690	array([[1.0629127, 0.5659685]], dtype=float32)

time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -2.000517	array([[1.0385668, 0.5755674]], dtype=float32)

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.364359	array([[-0.98038787, -0.1438483 ]], dtype=float32)

time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.301948	array([[-0.9683773 , -0.17256804]], dtype=float32)

time = 503	action = 0	current_phase = 1	next_phase = 0	reward = 0.051314	array([[1.0607693 , 0.56258327]], dtype=float32)

time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -1.459786	array([[1.0624161, 0.5666406]], dtype=float32)

time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -1.968539	array([[1.0392649, 0.575066 ]], dtype=float32)

time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.352927	array([[-0.9806229 , -0.14362419]], dtype=float32)

time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -1.309335	array([[-0.96845216, -0.17373477]], dtype=float32)

time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -0.113060	array([[1.0615649 , 0.56240803]], dtype=float32)

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.600074	array([[1.062132 , 0.5649651]], dtype=float32)

time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.901930	array([[1.0394701 , 0.57557005]], dtype=float32)

time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.293629	array([[-0.98031235, -0.1434156 ]], dtype=float32)

time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -0.764795	array([[-0.96843284, -0.1733118 ]], dtype=float32)

time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -0.849980	array([[1.0700573, 0.5643449]], dtype=float32)

time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.734332	array([[1.0612521 , 0.56513447]], dtype=float32)

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.840401	array([[1.040379  , 0.57513726]], dtype=float32)

time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.269762	array([[-0.98025864, -0.14274053]], dtype=float32)

time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -0.785722	array([[-0.9690328 , -0.17403218]], dtype=float32)

time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -1.064307	array([[1.0694107, 0.5647367]], dtype=float32)

time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -1.707154	array([[1.0383812 , 0.57549626]], dtype=float32)

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.800404	array([[1.0404774, 0.5751138]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -0.250926	array([[-0.9801533 , -0.14225113]], dtype=float32)

time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -0.861974	array([[-0.9682665, -0.1726887]], dtype=float32)

time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -1.315786	array([[1.0688444, 0.5654818]], dtype=float32)

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -1.689937	array([[1.0377684, 0.5752732]], dtype=float32)

time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.760154	array([[1.040428  , 0.57471204]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.213059	array([[-0.9802719 , -0.14171419]], dtype=float32)

time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.013089	array([[-0.9687452 , -0.17236203]], dtype=float32)

time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.457292	array([[1.0621868 , 0.56677496]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -1.656960	array([[1.0386946, 0.5752987]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 45020ms

 Real time factor: 14.8601

 UPS: 118.325189

Vehicles: 

 Inserted: 92

 Running: 10

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 4ms answering queries (0.04ms on average).

Could not connect to TraCI server at localhost:46761 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 46761 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (2ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.241148	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.436842	array([[1.0605273, 0.5609466]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.282214	array([[1.0617688, 0.5633787]], dtype=float32)

time = 48	action = 1	current_phase = 1	next_phase = 0	reward = -0.801984	array([[1.0630009, 0.5616622]], dtype=float32)

time = 56	action = 0	current_phase = 0	next_phase = 1	reward = -1.118505	array([[-0.97302115, -0.15916142]], dtype=float32)

time = 61	action = 1	current_phase = 0	next_phase = 1	reward = -2.070484	array([[-0.9718436, -0.1648905]], dtype=float32)

time = 69	action = 0	current_phase = 1	next_phase = 0	reward = -0.414981	array([[1.0601635, 0.5619509]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.266250	array([[1.0617828, 0.5622121]], dtype=float32)

time = 79	action = 1	current_phase = 1	next_phase = 0	reward = -0.850964	array([[1.0611151, 0.563337 ]], dtype=float32)

time = 87	action = 0	current_phase = 0	next_phase = 1	reward = -1.207686	array([[-0.97314066, -0.15914747]], dtype=float32)

time = 92	action = 1	current_phase = 0	next_phase = 1	reward = -2.014163	array([[-0.9721169 , -0.16517934]], dtype=float32)

time = 100	action = 0	current_phase = 1	next_phase = 0	reward = -0.377084	array([[1.0606918, 0.5617851]], dtype=float32)

time = 105	action = 0	current_phase = 1	next_phase = 0	reward = -0.222009	array([[1.0626414 , 0.56264246]], dtype=float32)

time = 110	action = 1	current_phase = 1	next_phase = 0	reward = -1.009937	array([[1.0614806 , 0.56266487]], dtype=float32)

time = 118	action = 0	current_phase = 0	next_phase = 1	reward = -1.405024	array([[-0.959387  , -0.15127449]], dtype=float32)

time = 123	action = 1	current_phase = 0	next_phase = 1	reward = -1.951706	array([[-0.9722129, -0.1641387]], dtype=float32)

time = 131	action = 0	current_phase = 1	next_phase = 0	reward = -0.339037	array([[1.0613471, 0.5618478]], dtype=float32)

time = 136	action = 0	current_phase = 1	next_phase = 0	reward = -0.193666	array([[1.0619515 , 0.56279266]], dtype=float32)

time = 141	action = 1	current_phase = 1	next_phase = 0	reward = -1.178461	array([[1.0612848, 0.5635407]], dtype=float32)

time = 149	action = 0	current_phase = 0	next_phase = 1	reward = -1.599404	array([[-0.9679417 , -0.15926652]], dtype=float32)

time = 154	action = 1	current_phase = 0	next_phase = 1	reward = -1.921845	array([[-0.9711615 , -0.16488183]], dtype=float32)

time = 162	action = 0	current_phase = 1	next_phase = 0	reward = -0.314234	array([[1.0599874 , 0.56189656]], dtype=float32)

time = 167	action = 0	current_phase = 1	next_phase = 0	reward = -0.176852	array([[1.0614445, 0.5630372]], dtype=float32)

time = 172	action = 1	current_phase = 1	next_phase = 0	reward = -1.422978	array([[1.0614761, 0.5625372]], dtype=float32)

time = 180	action = 0	current_phase = 0	next_phase = 1	reward = -1.726860	array([[-0.96736044, -0.15842944]], dtype=float32)

time = 185	action = 1	current_phase = 0	next_phase = 1	reward = -1.829246	array([[-0.9714433, -0.1636824]], dtype=float32)

time = 193	action = 0	current_phase = 1	next_phase = 0	reward = -0.266238	array([[1.0613371 , 0.56179297]], dtype=float32)

time = 198	action = 0	current_phase = 1	next_phase = 0	reward = -0.155625	array([[1.0616604 , 0.56273764]], dtype=float32)

time = 203	action = 1	current_phase = 1	next_phase = 0	reward = -0.225666	array([[1.060976  , 0.56335986]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -0.657512	array([[-0.9679843 , -0.17380233]], dtype=float32)

time = 216	action = 1	current_phase = 0	next_phase = 1	reward = -1.742199	array([[-0.967744  , -0.17264885]], dtype=float32)

time = 224	action = 0	current_phase = 1	next_phase = 0	reward = -0.248010	array([[1.0612397 , 0.56291234]], dtype=float32)

time = 229	action = 0	current_phase = 1	next_phase = 0	reward = -0.165712	array([[1.0621347 , 0.56226367]], dtype=float32)

time = 234	action = 1	current_phase = 1	next_phase = 0	reward = -0.359931	array([[1.0613531, 0.5630885]], dtype=float32)

time = 242	action = 0	current_phase = 0	next_phase = 1	reward = -0.620949	array([[-0.96798915, -0.17302175]], dtype=float32)

time = 247	action = 1	current_phase = 0	next_phase = 1	reward = -1.676884	array([[-0.9679504 , -0.17382544]], dtype=float32)

time = 255	action = 0	current_phase = 1	next_phase = 0	reward = -0.219107	array([[1.0611892 , 0.56249535]], dtype=float32)

time = 260	action = 0	current_phase = 1	next_phase = 0	reward = 0.384846	array([[1.0609754 , 0.56351763]], dtype=float32)

time = 265	action = 1	current_phase = 1	next_phase = 0	reward = -1.238629	array([[1.0698005, 0.5653567]], dtype=float32)

time = 273	action = 0	current_phase = 0	next_phase = 1	reward = -0.586460	array([[-0.96796346, -0.17357218]], dtype=float32)

time = 278	action = 1	current_phase = 0	next_phase = 1	reward = -1.627305	array([[-0.9675813, -0.1733264]], dtype=float32)

time = 286	action = 0	current_phase = 1	next_phase = 0	reward = -0.202611	array([[1.0619893 , 0.56225926]], dtype=float32)

time = 291	action = 0	current_phase = 1	next_phase = 0	reward = 0.329446	array([[1.0607804 , 0.56316483]], dtype=float32)

time = 296	action = 1	current_phase = 1	next_phase = 0	reward = -1.504496	array([[1.0702857 , 0.56446576]], dtype=float32)

time = 304	action = 0	current_phase = 0	next_phase = 1	reward = -0.562148	array([[-0.9679999 , -0.17331062]], dtype=float32)

time = 309	action = 1	current_phase = 0	next_phase = 1	reward = -1.567012	array([[-0.9680408 , -0.17330478]], dtype=float32)

time = 317	action = 0	current_phase = 1	next_phase = 0	reward = -0.169494	array([[1.0619901 , 0.56305695]], dtype=float32)

time = 322	action = 0	current_phase = 1	next_phase = 0	reward = 0.202555	array([[1.0605469 , 0.56297386]], dtype=float32)

time = 327	action = 1	current_phase = 1	next_phase = 0	reward = -1.727527	array([[1.0680348, 0.5634945]], dtype=float32)

time = 335	action = 0	current_phase = 0	next_phase = 1	reward = -0.524467	array([[-0.9800405 , -0.14333637]], dtype=float32)

time = 340	action = 1	current_phase = 0	next_phase = 1	reward = -1.521228	array([[-0.96809447, -0.1722692 ]], dtype=float32)

time = 348	action = 0	current_phase = 1	next_phase = 0	reward = -0.163316	array([[1.0613971, 0.5624069]], dtype=float32)

time = 353	action = 0	current_phase = 1	next_phase = 0	reward = -0.004041	array([[1.0612129, 0.5621419]], dtype=float32)

time = 358	action = 1	current_phase = 1	next_phase = 0	reward = -1.894261	array([[1.0613083, 0.5653296]], dtype=float32)

time = 366	action = 0	current_phase = 0	next_phase = 1	reward = -0.489935	array([[-0.9800193 , -0.14319733]], dtype=float32)

time = 371	action = 1	current_phase = 0	next_phase = 1	reward = -1.454400	array([[-0.9672562 , -0.17360145]], dtype=float32)

time = 379	action = 0	current_phase = 1	next_phase = 0	reward = -0.183843	array([[1.0606086 , 0.56217426]], dtype=float32)

time = 384	action = 0	current_phase = 1	next_phase = 0	reward = -0.149358	array([[1.0613581, 0.5629238]], dtype=float32)

time = 389	action = 1	current_phase = 1	next_phase = 0	reward = -2.006485	array([[1.0617975, 0.5649792]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -0.462483	array([[-0.9798535 , -0.14250554]], dtype=float32)

time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.418308	array([[-0.9678894 , -0.17379513]], dtype=float32)

time = 410	action = 0	current_phase = 1	next_phase = 0	reward = 0.358152	array([[1.0608277, 0.5636608]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.896995	array([[1.0700282, 0.5644633]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.094500	array([[1.06195   , 0.56550515]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.406224	array([[-0.98058164, -0.14342213]], dtype=float32)

time = 433	action = 1	current_phase = 0	next_phase = 1	reward = -1.351339	array([[-0.96829134, -0.17396946]], dtype=float32)

time = 441	action = 0	current_phase = 1	next_phase = 0	reward = 0.275543	array([[1.0621498, 0.562966 ]], dtype=float32)

time = 446	action = 0	current_phase = 1	next_phase = 0	reward = -1.173348	array([[1.0702055 , 0.56429774]], dtype=float32)

time = 451	action = 1	current_phase = 1	next_phase = 0	reward = -2.073403	array([[1.039571 , 0.5754585]], dtype=float32)

time = 459	action = 0	current_phase = 0	next_phase = 1	reward = -0.415454	array([[-0.9802848 , -0.14265329]], dtype=float32)

time = 464	action = 1	current_phase = 0	next_phase = 1	reward = -1.355775	array([[-0.968342  , -0.17224194]], dtype=float32)

time = 472	action = 0	current_phase = 1	next_phase = 0	reward = 0.208891	array([[1.0618953 , 0.56288636]], dtype=float32)

time = 477	action = 0	current_phase = 1	next_phase = 0	reward = -1.319690	array([[1.0629127, 0.5659685]], dtype=float32)

time = 482	action = 1	current_phase = 1	next_phase = 0	reward = -2.000517	array([[1.0385668, 0.5755674]], dtype=float32)

time = 490	action = 0	current_phase = 0	next_phase = 1	reward = -0.364359	array([[-0.98038787, -0.1438483 ]], dtype=float32)

time = 495	action = 1	current_phase = 0	next_phase = 1	reward = -1.301948	array([[-0.9683773 , -0.17256804]], dtype=float32)

time = 503	action = 0	current_phase = 1	next_phase = 0	reward = 0.051314	array([[1.0607693 , 0.56258327]], dtype=float32)

time = 508	action = 0	current_phase = 1	next_phase = 0	reward = -1.459786	array([[1.0624161, 0.5666406]], dtype=float32)

time = 513	action = 1	current_phase = 1	next_phase = 0	reward = -1.968539	array([[1.0392649, 0.575066 ]], dtype=float32)

time = 521	action = 0	current_phase = 0	next_phase = 1	reward = -0.352927	array([[-0.9806229 , -0.14362419]], dtype=float32)

time = 526	action = 1	current_phase = 0	next_phase = 1	reward = -1.309335	array([[-0.96845216, -0.17373477]], dtype=float32)

time = 534	action = 0	current_phase = 1	next_phase = 0	reward = -0.113060	array([[1.0615649 , 0.56240803]], dtype=float32)

time = 539	action = 0	current_phase = 1	next_phase = 0	reward = -1.600074	array([[1.062132 , 0.5649651]], dtype=float32)

time = 544	action = 1	current_phase = 1	next_phase = 0	reward = -1.901930	array([[1.0394701 , 0.57557005]], dtype=float32)

time = 552	action = 0	current_phase = 0	next_phase = 1	reward = -0.293629	array([[-0.98031235, -0.1434156 ]], dtype=float32)

time = 557	action = 1	current_phase = 0	next_phase = 1	reward = -0.764795	array([[-0.96843284, -0.1733118 ]], dtype=float32)

time = 565	action = 0	current_phase = 1	next_phase = 0	reward = -0.849980	array([[1.0700573, 0.5643449]], dtype=float32)

time = 570	action = 0	current_phase = 1	next_phase = 0	reward = -1.734332	array([[1.0612521 , 0.56513447]], dtype=float32)

time = 575	action = 1	current_phase = 1	next_phase = 0	reward = -1.840401	array([[1.040379  , 0.57513726]], dtype=float32)

time = 583	action = 0	current_phase = 0	next_phase = 1	reward = -0.269762	array([[-0.98025864, -0.14274053]], dtype=float32)

time = 588	action = 1	current_phase = 0	next_phase = 1	reward = -0.785722	array([[-0.9690328 , -0.17403218]], dtype=float32)

time = 596	action = 0	current_phase = 1	next_phase = 0	reward = -1.064307	array([[1.0694107, 0.5647367]], dtype=float32)

time = 601	action = 0	current_phase = 1	next_phase = 0	reward = -1.707154	array([[1.0383812 , 0.57549626]], dtype=float32)

time = 606	action = 1	current_phase = 1	next_phase = 0	reward = -1.800404	array([[1.0404774, 0.5751138]], dtype=float32)

time = 614	action = 0	current_phase = 0	next_phase = 1	reward = -0.250926	array([[-0.9801533 , -0.14225113]], dtype=float32)

time = 619	action = 1	current_phase = 0	next_phase = 1	reward = -0.861974	array([[-0.9682665, -0.1726887]], dtype=float32)

time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -1.315786	array([[1.0688444, 0.5654818]], dtype=float32)

time = 632	action = 0	current_phase = 1	next_phase = 0	reward = -1.689937	array([[1.0377684, 0.5752732]], dtype=float32)

time = 637	action = 1	current_phase = 1	next_phase = 0	reward = -1.760154	array([[1.040428  , 0.57471204]], dtype=float32)

time = 645	action = 0	current_phase = 0	next_phase = 1	reward = -0.213059	array([[-0.9802719 , -0.14171419]], dtype=float32)

time = 650	action = 1	current_phase = 0	next_phase = 1	reward = -1.013089	array([[-0.9687452 , -0.17236203]], dtype=float32)

time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.457292	array([[1.0621868 , 0.56677496]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -1.656960	array([[1.0386946, 0.5752987]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 41373ms

 Real time factor: 16.17

 UPS: 128.755469

Vehicles: 

 Inserted: 92

 Running: 10

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 0ms answering queries (0.00ms on average).

Could not connect to TraCI server at localhost:34741 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 34741 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (1ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (1ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.241148	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.436842	array([[1.0605273, 0.5609466]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.282214	array([[1.0617688, 0.5633787]], dtype=float32)

time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -0.161575	array([[1.0630009, 0.5616622]], dtype=float32)

time = 53	action = 1	current_phase = 1	next_phase = 0	reward = -1.045817	array([[1.0603943, 0.5625997]], dtype=float32)

time = 61	action = 0	current_phase = 0	next_phase = 1	reward = -1.183386	array([[-0.9776049 , -0.17648926]], dtype=float32)

time = 66	action = 1	current_phase = 0	next_phase = 1	reward = -1.774387	array([[-0.97682333, -0.17586054]], dtype=float32)

time = 74	action = 0	current_phase = 1	next_phase = 0	reward = -0.269805	array([[1.0591655, 0.5633476]], dtype=float32)

time = 79	action = 0	current_phase = 1	next_phase = 0	reward = -0.163597	array([[1.0624697, 0.5614399]], dtype=float32)

time = 84	action = 0	current_phase = 1	next_phase = 0	reward = 0.003746	array([[1.0609158, 0.5632754]], dtype=float32)

time = 89	action = 1	current_phase = 1	next_phase = 0	reward = -1.992777	array([[1.0602967, 0.5656537]], dtype=float32)

time = 97	action = 0	current_phase = 0	next_phase = 1	reward = -0.452680	array([[-0.9803741 , -0.14289004]], dtype=float32)

time = 102	action = 1	current_phase = 0	next_phase = 1	reward = -1.400841	array([[-0.9678219, -0.173764 ]], dtype=float32)

time = 110	action = 0	current_phase = 1	next_phase = 0	reward = 0.357276	array([[1.0608463, 0.5635795]], dtype=float32)

time = 115	action = 0	current_phase = 1	next_phase = 0	reward = -0.900328	array([[1.0697707, 0.5646966]], dtype=float32)

time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -1.740182	array([[1.061822  , 0.56472427]], dtype=float32)

time = 125	action = 1	current_phase = 1	next_phase = 0	reward = -1.869040	array([[1.0397378 , 0.57644427]], dtype=float32)

time = 133	action = 0	current_phase = 0	next_phase = 1	reward = -0.285584	array([[-0.98092574, -0.1423086 ]], dtype=float32)

time = 138	action = 1	current_phase = 0	next_phase = 1	reward = -0.789821	array([[-0.96870536, -0.17442866]], dtype=float32)

time = 146	action = 0	current_phase = 1	next_phase = 0	reward = -1.173144	array([[1.069656 , 0.5649685]], dtype=float32)

time = 151	action = 0	current_phase = 1	next_phase = 0	reward = -1.722706	array([[1.0392964, 0.574963 ]], dtype=float32)

time = 156	action = 0	current_phase = 1	next_phase = 0	reward = -1.609937	array([[1.0401347, 0.574952 ]], dtype=float32)

time = 161	action = 1	current_phase = 1	next_phase = 0	reward = -1.573903	array([[1.0418845, 0.5757166]], dtype=float32)

time = 169	action = 0	current_phase = 0	next_phase = 1	reward = -0.174724	array([[-0.9813227 , -0.14190683]], dtype=float32)

time = 174	action = 1	current_phase = 0	next_phase = 1	reward = -0.508246	array([[-0.98747814, -0.16142553]], dtype=float32)

time = 182	action = 0	current_phase = 1	next_phase = 0	reward = -0.616020	array([[1.0609665 , 0.56313187]], dtype=float32)

time = 187	action = 0	current_phase = 1	next_phase = 0	reward = -0.452548	array([[1.0612195, 0.56294  ]], dtype=float32)

time = 192	action = 0	current_phase = 1	next_phase = 0	reward = -0.298022	array([[1.0618333, 0.5623777]], dtype=float32)

time = 197	action = 1	current_phase = 1	next_phase = 0	reward = -0.776520	array([[1.0618998, 0.5626023]], dtype=float32)

time = 205	action = 0	current_phase = 0	next_phase = 1	reward = -0.854543	array([[-0.973346  , -0.15884978]], dtype=float32)

time = 210	action = 1	current_phase = 0	next_phase = 1	reward = -2.122842	array([[-0.96728826, -0.15759581]], dtype=float32)

time = 218	action = 0	current_phase = 1	next_phase = 0	reward = -0.438453	array([[1.0600094, 0.5614658]], dtype=float32)

time = 223	action = 0	current_phase = 1	next_phase = 0	reward = -0.275197	array([[1.0612147 , 0.56343377]], dtype=float32)

time = 228	action = 0	current_phase = 1	next_phase = 0	reward = -0.161934	array([[1.061872 , 0.5622685]], dtype=float32)

time = 233	action = 1	current_phase = 1	next_phase = 0	reward = -1.778364	array([[1.0605502 , 0.56224006]], dtype=float32)

time = 241	action = 0	current_phase = 0	next_phase = 1	reward = -1.700125	array([[-0.9710126 , -0.16403736]], dtype=float32)

time = 246	action = 1	current_phase = 0	next_phase = 1	reward = -1.804818	array([[-0.9715238 , -0.16400138]], dtype=float32)

time = 254	action = 0	current_phase = 1	next_phase = 0	reward = -0.253193	array([[1.0608065, 0.5602974]], dtype=float32)

time = 259	action = 0	current_phase = 1	next_phase = 0	reward = -0.176627	array([[1.0611401, 0.5629339]], dtype=float32)

time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -0.076866	array([[1.0614048 , 0.56312406]], dtype=float32)

time = 269	action = 1	current_phase = 1	next_phase = 0	reward = -2.004716	array([[1.0597861, 0.565972 ]], dtype=float32)

time = 277	action = 0	current_phase = 0	next_phase = 1	reward = -0.471239	array([[-0.97990704, -0.14287554]], dtype=float32)

time = 282	action = 1	current_phase = 0	next_phase = 1	reward = -1.447536	array([[-0.96800417, -0.17287037]], dtype=float32)

time = 290	action = 0	current_phase = 1	next_phase = 0	reward = 0.368834	array([[1.0615469 , 0.56279606]], dtype=float32)

time = 295	action = 0	current_phase = 1	next_phase = 0	reward = -0.678712	array([[1.0693773, 0.5645264]], dtype=float32)

time = 300	action = 0	current_phase = 1	next_phase = 0	reward = -1.722341	array([[1.0609391 , 0.56503093]], dtype=float32)

time = 305	action = 1	current_phase = 1	next_phase = 0	reward = -1.844305	array([[1.0395265, 0.5757685]], dtype=float32)

time = 313	action = 0	current_phase = 0	next_phase = 1	reward = -0.284198	array([[-0.9812784 , -0.14307758]], dtype=float32)

time = 318	action = 1	current_phase = 0	next_phase = 1	reward = -0.799175	array([[-0.96872985, -0.17439279]], dtype=float32)

time = 326	action = 0	current_phase = 1	next_phase = 0	reward = -1.010701	array([[1.0699973 , 0.56439567]], dtype=float32)

time = 331	action = 0	current_phase = 1	next_phase = 0	reward = -1.702978	array([[1.0386137 , 0.57502294]], dtype=float32)

time = 336	action = 0	current_phase = 1	next_phase = 0	reward = -1.588511	array([[1.0397366, 0.5752044]], dtype=float32)

time = 341	action = 1	current_phase = 1	next_phase = 0	reward = -1.544945	array([[1.0411912, 0.5756384]], dtype=float32)

time = 349	action = 0	current_phase = 0	next_phase = 1	reward = -0.187567	array([[-0.9800892 , -0.14226514]], dtype=float32)

time = 354	action = 1	current_phase = 0	next_phase = 1	reward = -0.453812	array([[-0.9692541 , -0.17300165]], dtype=float32)

time = 362	action = 0	current_phase = 1	next_phase = 0	reward = -0.611476	array([[1.0615888 , 0.56295264]], dtype=float32)

time = 367	action = 0	current_phase = 1	next_phase = 0	reward = -0.451870	array([[1.0609854, 0.5633064]], dtype=float32)

time = 372	action = 0	current_phase = 1	next_phase = 0	reward = -0.292243	array([[1.0623834 , 0.56267136]], dtype=float32)

time = 377	action = 1	current_phase = 1	next_phase = 0	reward = -0.775690	array([[1.0627637 , 0.56238735]], dtype=float32)

time = 385	action = 0	current_phase = 0	next_phase = 1	reward = -0.853107	array([[-0.97213936, -0.15874928]], dtype=float32)

time = 390	action = 1	current_phase = 0	next_phase = 1	reward = -2.109717	array([[-0.967696  , -0.15794557]], dtype=float32)

time = 398	action = 0	current_phase = 1	next_phase = 0	reward = -0.436212	array([[1.0605978 , 0.56133133]], dtype=float32)

time = 403	action = 0	current_phase = 1	next_phase = 0	reward = -0.269169	array([[1.0621483, 0.5624354]], dtype=float32)

time = 408	action = 0	current_phase = 1	next_phase = 0	reward = -0.161051	array([[1.062256  , 0.56213516]], dtype=float32)

time = 413	action = 1	current_phase = 1	next_phase = 0	reward = -1.908108	array([[1.060912 , 0.5627109]], dtype=float32)

time = 421	action = 0	current_phase = 0	next_phase = 1	reward = -1.715600	array([[-0.97174805, -0.16490375]], dtype=float32)

time = 426	action = 1	current_phase = 0	next_phase = 1	reward = -1.809576	array([[-0.97113484, -0.16322744]], dtype=float32)

time = 434	action = 0	current_phase = 1	next_phase = 0	reward = -0.256387	array([[1.0602795, 0.5611413]], dtype=float32)

time = 439	action = 0	current_phase = 1	next_phase = 0	reward = -0.179445	array([[1.0622361, 0.5618573]], dtype=float32)

time = 444	action = 0	current_phase = 1	next_phase = 0	reward = -0.079710	array([[1.0613654, 0.5628743]], dtype=float32)

time = 449	action = 1	current_phase = 1	next_phase = 0	reward = -2.000155	array([[1.06048  , 0.5653971]], dtype=float32)

time = 457	action = 0	current_phase = 0	next_phase = 1	reward = -0.457898	array([[-0.9801912 , -0.14304447]], dtype=float32)

time = 462	action = 1	current_phase = 0	next_phase = 1	reward = -1.427158	array([[-0.968035 , -0.1727877]], dtype=float32)

time = 470	action = 0	current_phase = 1	next_phase = 0	reward = 0.337326	array([[1.0607388, 0.5634308]], dtype=float32)

time = 475	action = 0	current_phase = 1	next_phase = 0	reward = -0.905279	array([[1.0695236, 0.5648236]], dtype=float32)

time = 480	action = 0	current_phase = 1	next_phase = 0	reward = -1.742967	array([[1.0616791, 0.5646369]], dtype=float32)

time = 485	action = 1	current_phase = 1	next_phase = 0	reward = -1.870566	array([[1.0396516, 0.5762094]], dtype=float32)

time = 493	action = 0	current_phase = 0	next_phase = 1	reward = -0.284285	array([[-0.9805707 , -0.14314282]], dtype=float32)

time = 498	action = 1	current_phase = 0	next_phase = 1	reward = -0.783390	array([[-0.9688429 , -0.17405273]], dtype=float32)

time = 506	action = 0	current_phase = 1	next_phase = 0	reward = -1.118524	array([[1.0696979, 0.5644417]], dtype=float32)

time = 511	action = 0	current_phase = 1	next_phase = 0	reward = -1.711537	array([[1.0386708, 0.5751496]], dtype=float32)

time = 516	action = 0	current_phase = 1	next_phase = 0	reward = -1.599324	array([[1.0399595, 0.5751374]], dtype=float32)

time = 521	action = 1	current_phase = 1	next_phase = 0	reward = -1.551071	array([[1.0411985, 0.5751589]], dtype=float32)

time = 529	action = 0	current_phase = 0	next_phase = 1	reward = -0.205755	array([[-0.9807732, -0.1418571]], dtype=float32)

time = 534	action = 1	current_phase = 0	next_phase = 1	reward = -0.618834	array([[-0.9688396 , -0.17246592]], dtype=float32)

time = 542	action = 0	current_phase = 1	next_phase = 0	reward = -0.626555	array([[1.0615413 , 0.56265646]], dtype=float32)

time = 547	action = 0	current_phase = 1	next_phase = 0	reward = -0.480872	array([[1.0612687, 0.5635523]], dtype=float32)

time = 552	action = 0	current_phase = 1	next_phase = 0	reward = -0.333321	array([[1.0628127, 0.5625364]], dtype=float32)

time = 557	action = 1	current_phase = 1	next_phase = 0	reward = -1.044225	array([[1.062106  , 0.56232905]], dtype=float32)

time = 565	action = 0	current_phase = 0	next_phase = 1	reward = -0.386381	array([[-0.97531164, -0.1683023 ]], dtype=float32)

time = 570	action = 1	current_phase = 0	next_phase = 1	reward = -2.111783	array([[-0.96733475, -0.15852189]], dtype=float32)

time = 578	action = 0	current_phase = 1	next_phase = 0	reward = -0.430006	array([[1.0602843, 0.5613564]], dtype=float32)

time = 583	action = 0	current_phase = 1	next_phase = 0	reward = -0.272213	array([[1.0616192, 0.5634574]], dtype=float32)

time = 588	action = 0	current_phase = 1	next_phase = 0	reward = -0.161073	array([[1.0625441, 0.5618641]], dtype=float32)

time = 593	action = 1	current_phase = 1	next_phase = 0	reward = -1.847394	array([[1.060007  , 0.56342787]], dtype=float32)

time = 601	action = 0	current_phase = 0	next_phase = 1	reward = -1.707654	array([[-0.97170115, -0.16427602]], dtype=float32)

time = 606	action = 1	current_phase = 0	next_phase = 1	reward = -1.790900	array([[-0.9719088 , -0.16357577]], dtype=float32)

time = 614	action = 0	current_phase = 1	next_phase = 0	reward = -0.233101	array([[1.0620079, 0.5593288]], dtype=float32)

time = 619	action = 0	current_phase = 1	next_phase = 0	reward = -0.174243	array([[1.0617445 , 0.56207865]], dtype=float32)

time = 624	action = 0	current_phase = 1	next_phase = 0	reward = -0.084530	array([[1.060778 , 0.5627389]], dtype=float32)

time = 629	action = 1	current_phase = 1	next_phase = 0	reward = -2.003493	array([[1.0591557, 0.5655929]], dtype=float32)

time = 637	action = 0	current_phase = 0	next_phase = 1	reward = -0.460753	array([[-0.9804076 , -0.14299116]], dtype=float32)

time = 642	action = 1	current_phase = 0	next_phase = 1	reward = -1.427105	array([[-0.96841276, -0.17346215]], dtype=float32)

time = 650	action = 0	current_phase = 1	next_phase = 0	reward = 0.365013	array([[1.0611007, 0.5628699]], dtype=float32)

time = 655	action = 0	current_phase = 1	next_phase = 0	reward = -0.787076	array([[1.0696707, 0.5644875]], dtype=float32)

time = 660	action = 0	current_phase = 1	next_phase = 0	reward = -1.731015	array([[1.0623194 , 0.56484926]], dtype=float32)

time = 665	action = 1	current_phase = 1	next_phase = 0	reward = -1.850689	array([[1.0403695, 0.575562 ]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 674.00

Reason: TraCI requested termination.

Performance: 

 Duration: 41395ms

 Real time factor: 16.2822

 UPS: 133.301123

Vehicles: 

 Inserted: 92

 Running: 8

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 0ms answering queries (0.00ms on average).

Could not connect to TraCI server at localhost:38061 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 38061 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (3ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (0ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[-0.9682462 , -0.17281505]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.97272366, -0.15849422]], dtype=float32)

time = 30	action = 1	current_phase = 0	next_phase = 1	reward = -2.241148	array([[-0.9674337 , -0.15842557]], dtype=float32)

time = 38	action = 0	current_phase = 1	next_phase = 0	reward = -0.436842	array([[1.0605273, 0.5609466]], dtype=float32)

time = 43	action = 0	current_phase = 1	next_phase = 0	reward = -0.282214	array([[1.0617688, 0.5633787]], dtype=float32)

time = 48	action = 0	current_phase = 1	next_phase = 0	reward = -0.161575	array([[1.0630009, 0.5616622]], dtype=float32)

time = 53	action = 0	current_phase = 1	next_phase = 0	reward = 0.137952	array([[1.0603943, 0.5625997]], dtype=float32)

time = 58	action = 1	current_phase = 1	next_phase = 0	reward = -1.899433	array([[1.0623162, 0.5669597]], dtype=float32)

time = 66	action = 0	current_phase = 0	next_phase = 1	reward = -0.507484	array([[-0.9798185 , -0.14314732]], dtype=float32)

time = 71	action = 1	current_phase = 0	next_phase = 1	reward = -1.513392	array([[-0.9683236 , -0.17337093]], dtype=float32)

time = 79	action = 0	current_phase = 1	next_phase = 0	reward = -0.175536	array([[1.0616221 , 0.56228054]], dtype=float32)

time = 84	action = 0	current_phase = 1	next_phase = 0	reward = -0.124511	array([[1.0608013, 0.5630207]], dtype=float32)

time = 89	action = 0	current_phase = 1	next_phase = 0	reward = -1.604739	array([[1.0612093, 0.5658035]], dtype=float32)

time = 94	action = 0	current_phase = 1	next_phase = 0	reward = -1.655100	array([[1.0398384 , 0.57542837]], dtype=float32)

time = 99	action = 1	current_phase = 1	next_phase = 0	reward = -1.664996	array([[1.0397875, 0.5761706]], dtype=float32)

time = 107	action = 0	current_phase = 0	next_phase = 1	reward = -0.177151	array([[-0.9806073 , -0.14338714]], dtype=float32)

time = 112	action = 1	current_phase = 0	next_phase = 1	reward = -1.419760	array([[-0.96859753, -0.17355701]], dtype=float32)

time = 120	action = 0	current_phase = 1	next_phase = 0	reward = -1.732650	array([[1.0611241, 0.5657454]], dtype=float32)

time = 125	action = 0	current_phase = 1	next_phase = 0	reward = -1.621672	array([[1.0394211, 0.5748465]], dtype=float32)

time = 130	action = 0	current_phase = 1	next_phase = 0	reward = -1.510261	array([[1.0410635, 0.5744997]], dtype=float32)

time = 135	action = 0	current_phase = 1	next_phase = 0	reward = -1.403658	array([[1.0406802, 0.5748142]], dtype=float32)

time = 140	action = 1	current_phase = 1	next_phase = 0	reward = -1.040296	array([[1.0430586, 0.5735439]], dtype=float32)

time = 148	action = 0	current_phase = 0	next_phase = 1	reward = -1.459832	array([[-0.98108244, -0.16560322]], dtype=float32)

time = 153	action = 1	current_phase = 0	next_phase = 1	reward = -1.969814	array([[-0.97168064, -0.16394357]], dtype=float32)

time = 161	action = 0	current_phase = 1	next_phase = 0	reward = -0.355154	array([[1.0601351 , 0.56072444]], dtype=float32)

time = 166	action = 0	current_phase = 1	next_phase = 0	reward = -0.204452	array([[1.061402  , 0.56266266]], dtype=float32)

time = 171	action = 0	current_phase = 1	next_phase = 0	reward = 0.315428	array([[1.062682  , 0.56256664]], dtype=float32)

time = 176	action = 0	current_phase = 1	next_phase = 0	reward = -1.116923	array([[1.0702478 , 0.56456476]], dtype=float32)

time = 181	action = 1	current_phase = 1	next_phase = 0	reward = -2.060157	array([[1.0381082, 0.5758447]], dtype=float32)

time = 189	action = 0	current_phase = 0	next_phase = 1	reward = -0.398528	array([[-0.98018706, -0.1425024 ]], dtype=float32)

time = 194	action = 1	current_phase = 0	next_phase = 1	reward = -1.325150	array([[-0.96856016, -0.17287667]], dtype=float32)

time = 202	action = 0	current_phase = 1	next_phase = 0	reward = 0.191830	array([[1.0615312 , 0.56236947]], dtype=float32)

time = 207	action = 0	current_phase = 1	next_phase = 0	reward = -1.320093	array([[1.0679651, 0.5634223]], dtype=float32)

time = 212	action = 0	current_phase = 1	next_phase = 0	reward = -1.692739	array([[1.0391308, 0.5750998]], dtype=float32)

time = 217	action = 0	current_phase = 1	next_phase = 0	reward = -1.567971	array([[1.039637  , 0.57599556]], dtype=float32)

time = 222	action = 1	current_phase = 1	next_phase = 0	reward = -1.474042	array([[1.0400674, 0.5747983]], dtype=float32)

time = 230	action = 0	current_phase = 0	next_phase = 1	reward = 0.331719	array([[-0.98120236, -0.14219582]], dtype=float32)

time = 235	action = 1	current_phase = 0	next_phase = 1	reward = -1.426528	array([[-0.97285545, -0.1586135 ]], dtype=float32)

time = 243	action = 0	current_phase = 1	next_phase = 0	reward = -0.595004	array([[1.06169  , 0.5630335]], dtype=float32)

time = 248	action = 0	current_phase = 1	next_phase = 0	reward = -0.435060	array([[1.0611461, 0.5628507]], dtype=float32)

time = 253	action = 0	current_phase = 1	next_phase = 0	reward = -0.282260	array([[1.0632052 , 0.56194055]], dtype=float32)

time = 258	action = 0	current_phase = 1	next_phase = 0	reward = -0.161758	array([[1.0621672, 0.5625738]], dtype=float32)

time = 263	action = 1	current_phase = 1	next_phase = 0	reward = -1.044019	array([[1.0604136, 0.5628371]], dtype=float32)

time = 271	action = 0	current_phase = 0	next_phase = 1	reward = -1.188236	array([[-0.96195716, -0.1613557 ]], dtype=float32)

time = 276	action = 1	current_phase = 0	next_phase = 1	reward = -1.790120	array([[-0.9620022 , -0.16140544]], dtype=float32)

time = 284	action = 0	current_phase = 1	next_phase = 0	reward = -0.268091	array([[1.0612411 , 0.56080186]], dtype=float32)

time = 289	action = 0	current_phase = 1	next_phase = 0	reward = -0.172127	array([[1.0618434, 0.5624524]], dtype=float32)

time = 294	action = 0	current_phase = 1	next_phase = 0	reward = -0.072797	array([[1.0608513 , 0.56419355]], dtype=float32)

time = 299	action = 0	current_phase = 1	next_phase = 0	reward = -1.596097	array([[1.061246 , 0.5659222]], dtype=float32)

time = 304	action = 1	current_phase = 1	next_phase = 0	reward = -1.899039	array([[1.0393841, 0.5756966]], dtype=float32)

time = 312	action = 0	current_phase = 0	next_phase = 1	reward = -0.309474	array([[-0.9805388 , -0.14233522]], dtype=float32)

time = 317	action = 1	current_phase = 0	next_phase = 1	reward = -0.763534	array([[-0.96799225, -0.1733832 ]], dtype=float32)

time = 325	action = 0	current_phase = 1	next_phase = 0	reward = -0.845237	array([[1.0700681, 0.5642539]], dtype=float32)

time = 330	action = 0	current_phase = 1	next_phase = 0	reward = -1.736939	array([[1.0613146 , 0.56543493]], dtype=float32)

time = 335	action = 0	current_phase = 1	next_phase = 0	reward = -1.619782	array([[1.039511 , 0.5756384]], dtype=float32)

time = 340	action = 0	current_phase = 1	next_phase = 0	reward = -1.507427	array([[1.0410087 , 0.57514226]], dtype=float32)

time = 345	action = 1	current_phase = 1	next_phase = 0	reward = -1.392548	array([[1.0422148 , 0.57409334]], dtype=float32)

time = 353	action = 0	current_phase = 0	next_phase = 1	reward = -0.026486	array([[-0.981565  , -0.14310783]], dtype=float32)

time = 358	action = 1	current_phase = 0	next_phase = 1	reward = -1.899588	array([[-0.9677054 , -0.15895347]], dtype=float32)

time = 366	action = 0	current_phase = 1	next_phase = 0	reward = -0.490009	array([[1.0592774, 0.561538 ]], dtype=float32)

time = 371	action = 0	current_phase = 1	next_phase = 0	reward = -0.335077	array([[1.0628333, 0.5625998]], dtype=float32)

time = 376	action = 0	current_phase = 1	next_phase = 0	reward = -0.191063	array([[1.0617899, 0.5625796]], dtype=float32)

time = 381	action = 0	current_phase = 1	next_phase = 0	reward = 0.300482	array([[1.061805  , 0.56311095]], dtype=float32)

time = 386	action = 1	current_phase = 1	next_phase = 0	reward = -1.665290	array([[1.0693465 , 0.56464565]], dtype=float32)

time = 394	action = 0	current_phase = 0	next_phase = 1	reward = -0.563510	array([[-0.9680178, -0.1732941]], dtype=float32)

time = 399	action = 1	current_phase = 0	next_phase = 1	reward = -1.575760	array([[-0.9682868 , -0.17360023]], dtype=float32)

time = 407	action = 0	current_phase = 1	next_phase = 0	reward = -0.177014	array([[1.0613005 , 0.56150424]], dtype=float32)

time = 412	action = 0	current_phase = 1	next_phase = 0	reward = 0.123209	array([[1.0624685 , 0.56293833]], dtype=float32)

time = 417	action = 0	current_phase = 1	next_phase = 0	reward = -1.324423	array([[1.0615908 , 0.56515384]], dtype=float32)

time = 422	action = 0	current_phase = 1	next_phase = 0	reward = -1.696262	array([[1.0380131 , 0.57624465]], dtype=float32)

time = 427	action = 1	current_phase = 1	next_phase = 0	reward = -1.770415	array([[1.0400139, 0.5753936]], dtype=float32)

time = 435	action = 0	current_phase = 0	next_phase = 1	reward = -0.228435	array([[-0.980627  , -0.14223734]], dtype=float32)

time = 440	action = 1	current_phase = 0	next_phase = 1	reward = -0.949337	array([[-0.9679226 , -0.17200729]], dtype=float32)

time = 448	action = 0	current_phase = 1	next_phase = 0	reward = -1.456029	array([[1.0619179 , 0.56624043]], dtype=float32)

time = 453	action = 0	current_phase = 1	next_phase = 0	reward = -1.654342	array([[1.0386059, 0.5756   ]], dtype=float32)

time = 458	action = 0	current_phase = 1	next_phase = 0	reward = -1.543261	array([[1.0403175, 0.5743153]], dtype=float32)

time = 463	action = 0	current_phase = 1	next_phase = 0	reward = -1.425168	array([[1.0407355, 0.5744608]], dtype=float32)

time = 468	action = 1	current_phase = 1	next_phase = 0	reward = -0.886295	array([[1.0423504, 0.5744573]], dtype=float32)

time = 476	action = 0	current_phase = 0	next_phase = 1	reward = -1.173401	array([[-0.9729791 , -0.15847258]], dtype=float32)

time = 481	action = 1	current_phase = 0	next_phase = 1	reward = -2.067667	array([[-0.9719781 , -0.16568765]], dtype=float32)

time = 489	action = 0	current_phase = 1	next_phase = 0	reward = -0.410968	array([[1.0598394, 0.5612382]], dtype=float32)

time = 494	action = 0	current_phase = 1	next_phase = 0	reward = -0.264089	array([[1.0615369 , 0.56251585]], dtype=float32)

time = 499	action = 0	current_phase = 1	next_phase = 0	reward = -0.168948	array([[1.0630654, 0.5628451]], dtype=float32)

time = 504	action = 0	current_phase = 1	next_phase = 0	reward = -0.000889	array([[1.060729 , 0.5627564]], dtype=float32)

time = 509	action = 1	current_phase = 1	next_phase = 0	reward = -2.002100	array([[1.0611237, 0.5653746]], dtype=float32)

time = 517	action = 0	current_phase = 0	next_phase = 1	reward = -0.459991	array([[-0.9807458 , -0.14315253]], dtype=float32)

time = 522	action = 1	current_phase = 0	next_phase = 1	reward = -1.408602	array([[-0.96834266, -0.17329782]], dtype=float32)

time = 530	action = 0	current_phase = 1	next_phase = 0	reward = 0.347777	array([[1.0602535, 0.5634195]], dtype=float32)

time = 535	action = 0	current_phase = 1	next_phase = 0	reward = -0.848818	array([[1.069722  , 0.56433904]], dtype=float32)

time = 540	action = 0	current_phase = 1	next_phase = 0	reward = -1.735766	array([[1.0619221, 0.565297 ]], dtype=float32)

time = 545	action = 0	current_phase = 1	next_phase = 0	reward = -1.617139	array([[1.0401764, 0.5758941]], dtype=float32)

time = 550	action = 1	current_phase = 1	next_phase = 0	reward = -1.585000	array([[1.04147   , 0.57459545]], dtype=float32)

time = 558	action = 0	current_phase = 0	next_phase = 1	reward = -0.166912	array([[-0.9809982 , -0.14265013]], dtype=float32)

time = 563	action = 1	current_phase = 0	next_phase = 1	reward = -1.851018	array([[-0.96900445, -0.17287903]], dtype=float32)

time = 571	action = 0	current_phase = 1	next_phase = 0	reward = -1.701528	array([[1.0382084 , 0.57549655]], dtype=float32)

time = 576	action = 0	current_phase = 1	next_phase = 0	reward = -1.586983	array([[1.0400255, 0.5748751]], dtype=float32)

time = 581	action = 0	current_phase = 1	next_phase = 0	reward = -1.475408	array([[1.0408791 , 0.57435364]], dtype=float32)

time = 586	action = 0	current_phase = 1	next_phase = 0	reward = -1.371937	array([[1.0421343, 0.5731173]], dtype=float32)

time = 591	action = 1	current_phase = 1	next_phase = 0	reward = -1.331942	array([[1.0438277 , 0.57347465]], dtype=float32)

time = 599	action = 0	current_phase = 0	next_phase = 1	reward = -1.603102	array([[-0.96732354, -0.15723912]], dtype=float32)

time = 604	action = 1	current_phase = 0	next_phase = 1	reward = -1.897859	array([[-0.97161824, -0.16456294]], dtype=float32)

time = 612	action = 0	current_phase = 1	next_phase = 0	reward = -0.294238	array([[1.0604656 , 0.56076854]], dtype=float32)

time = 617	action = 0	current_phase = 1	next_phase = 0	reward = -0.167106	array([[1.061584  , 0.56238264]], dtype=float32)

time = 622	action = 0	current_phase = 1	next_phase = 0	reward = 0.168137	array([[1.0613217 , 0.56271327]], dtype=float32)

time = 627	action = 0	current_phase = 1	next_phase = 0	reward = -1.320350	array([[1.0622829 , 0.56718093]], dtype=float32)

time = 632	action = 1	current_phase = 1	next_phase = 0	reward = -2.009880	array([[1.0388777 , 0.57554466]], dtype=float32)

time = 640	action = 0	current_phase = 0	next_phase = 1	reward = -0.370069	array([[-0.9806241 , -0.14341053]], dtype=float32)

time = 645	action = 1	current_phase = 0	next_phase = 1	reward = -1.313849	array([[-0.9685434 , -0.17288303]], dtype=float32)

time = 653	action = 0	current_phase = 1	next_phase = 0	reward = 0.070319	array([[1.0611888, 0.5623926]], dtype=float32)

time = 658	action = 0	current_phase = 1	next_phase = 0	reward = -1.460574	array([[1.0603113, 0.5657319]], dtype=float32)

time = 663	action = 0	current_phase = 1	next_phase = 0	reward = -1.662426	array([[1.039335  , 0.57496285]], dtype=float32)

Terminal occured. Episode end.

Simulation ended at time: 669.00

Reason: TraCI requested termination.

Performance: 

 Duration: 41322ms

 Real time factor: 16.1899

 UPS: 134.964426

Vehicles: 

 Inserted: 92

 Running: 10

 Waiting: 0



DijkstraRouter answered 92 queries and explored 3.00 edges on average.

DijkstraRouter spent 0ms answering queries (0.00ms on average).

Train on 1113 samples, validate on 478 samples

Epoch 1/500

 - 7s - loss: 0.7764 - val_loss: 0.2628

Epoch 2/500

 - 6s - loss: 0.1726 - val_loss: 0.1165

Epoch 3/500

 - 6s - loss: 0.1044 - val_loss: 0.0832

Epoch 4/500

 - 6s - loss: 0.0840 - val_loss: 0.0712

Epoch 5/500

 - 6s - loss: 0.0732 - val_loss: 0.0679

Epoch 6/500

 - 6s - loss: 0.0668 - val_loss: 0.0649

Epoch 7/500

 - 6s - loss: 0.0606 - val_loss: 0.0571

Epoch 8/500

 - 6s - loss: 0.0577 - val_loss: 0.0568

Epoch 9/500

 - 6s - loss: 0.0543 - val_loss: 0.0552

Epoch 10/500

 - 6s - loss: 0.0512 - val_loss: 0.0507

Epoch 11/500

 - 6s - loss: 0.0498 - val_loss: 0.0524

Epoch 12/500

 - 6s - loss: 0.0474 - val_loss: 0.0510

Epoch 13/500

 - 6s - loss: 0.0440 - val_loss: 0.0520

Epoch 14/500

 - 5s - loss: 0.0450 - val_loss: 0.0500

Epoch 15/500

 - 5s - loss: 0.0425 - val_loss: 0.0499

Epoch 16/500

 - 6s - loss: 0.0406 - val_loss: 0.0504

Epoch 17/500

 - 5s - loss: 0.0406 - val_loss: 0.0539

Epoch 18/500

 - 5s - loss: 0.0389 - val_loss: 0.0501

Epoch 19/500

 - 7s - loss: 0.0359 - val_loss: 0.0520

Epoch 20/500

 - 6s - loss: 0.0350 - val_loss: 0.0502

Epoch 21/500

 - 5s - loss: 0.0325 - val_loss: 0.0479

Epoch 22/500

 - 6s - loss: 0.0351 - val_loss: 0.0485

Epoch 23/500

 - 6s - loss: 0.0320 - val_loss: 0.0477

Epoch 24/500

 - 6s - loss: 0.0326 - val_loss: 0.0476

Epoch 25/500

 - 6s - loss: 0.0320 - val_loss: 0.0483

Epoch 26/500

 - 5s - loss: 0.0309 - val_loss: 0.0470

Epoch 27/500

 - 6s - loss: 0.0315 - val_loss: 0.0479

Epoch 28/500

 - 7s - loss: 0.0283 - val_loss: 0.0465

Epoch 29/500

 - 7s - loss: 0.0303 - val_loss: 0.0493

Epoch 30/500

 - 6s - loss: 0.0279 - val_loss: 0.0471

Epoch 31/500

 - 6s - loss: 0.0283 - val_loss: 0.0502

Epoch 32/500

 - 7s - loss: 0.0268 - val_loss: 0.0497

Epoch 33/500

 - 6s - loss: 0.0278 - val_loss: 0.0458

Epoch 34/500

 - 6s - loss: 0.0269 - val_loss: 0.0494

Epoch 35/500

 - 6s - loss: 0.0268 - val_loss: 0.0502

Epoch 36/500

 - 6s - loss: 0.0261 - val_loss: 0.0497

Epoch 37/500

 - 5s - loss: 0.0237 - val_loss: 0.0495

Epoch 38/500

 - 6s - loss: 0.0242 - val_loss: 0.0491

Epoch 39/500

 - 6s - loss: 0.0234 - val_loss: 0.0484

Epoch 40/500

 - 5s - loss: 0.0255 - val_loss: 0.0497

Epoch 41/500

 - 5s - loss: 0.0240 - val_loss: 0.0510

Epoch 42/500

 - 5s - loss: 0.0231 - val_loss: 0.0501

Epoch 43/500

 - 6s - loss: 0.0240 - val_loss: 0.0457

Epoch 44/500

 - 6s - loss: 0.0241 - val_loss: 0.0467

Epoch 45/500

 - 6s - loss: 0.0243 - val_loss: 0.0471

Epoch 46/500

 - 7s - loss: 0.0233 - val_loss: 0.0459

Epoch 47/500

 - 6s - loss: 0.0236 - val_loss: 0.0450

Epoch 48/500

 - 5s - loss: 0.0226 - val_loss: 0.0474

Epoch 49/500

 - 5s - loss: 0.0230 - val_loss: 0.0467

Epoch 50/500

 - 5s - loss: 0.0217 - val_loss: 0.0461

Epoch 51/500

 - 5s - loss: 0.0215 - val_loss: 0.0474

Epoch 52/500

 - 5s - loss: 0.0200 - val_loss: 0.0462

Epoch 53/500

 - 5s - loss: 0.0207 - val_loss: 0.0486

Epoch 54/500

 - 6s - loss: 0.0218 - val_loss: 0.0453

Epoch 55/500

 - 5s - loss: 0.0193 - val_loss: 0.0462

Epoch 56/500

 - 5s - loss: 0.0201 - val_loss: 0.0481

Epoch 57/500

 - 5s - loss: 0.0200 - val_loss: 0.0481

length of memory (state 0, action 0): 507, after forget

length of memory (state 0, action 1): 303, after forget

length of memory (state 1, action 0): 490, after forget

length of memory (state 1, action 1): 291, after forget

END

Could not connect to TraCI server at localhost:45731 [Errno 111] Connection refused

 Retrying in 1 seconds

Loading configuration... done.

***Starting server on port 45731 ***

Loading net-file from '/home/soup/IntelliLight/data/one_run/cross.net.xml'... done (2ms).

Warning: Missing yellow phase in tlLogic 'node0', program '0' for tl-index 5 when switching to phase 1

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.tls.switch.xml'... done (1ms).

Loading additional-files from '/home/soup/IntelliLight/data/one_run/cross.car.type.xml'... done (0ms).

Loading done.

Simulation started with time: 0.00

time = 20	action = 0	current_phase = 0	next_phase = 1	reward = 0.235105	array([[ 0.28722534, -1.4474537 ]], dtype=float32)

time = 25	action = 0	current_phase = 0	next_phase = 1	reward = -0.788771	array([[-0.8535876, -1.4278731]], dtype=float32)

time = 30	action = 0	current_phase = 0	next_phase = 1	reward = -1.731109	array([[-1.1852498, -1.8825257]], dtype=float32)

time = 35	action = 0	current_phase = 0	next_phase = 1	reward = -1.621862	array([[-1.3674053, -1.6143364]], dtype=float32)

time = 40	action = 0	current_phase = 0	next_phase = 1	reward = -1.495931	array([[-1.3333905, -1.4192835]], dtype=float32)

time = 45	action = 0	current_phase = 0	next_phase = 1	reward = -1.378374	array([[-0.98720646, -1.3080914 ]], dtype=float32)

time = 50	action = 0	current_phase = 0	next_phase = 1	reward = -0.882559	array([[-0.8657313, -1.3708422]], dtype=float32)

time = 55	action = 0	current_phase = 0	next_phase = 1	reward = -2.110557	array([[-1.353886 , -1.5326049]], dtype=float32)

time = 60	action = 0	current_phase = 0	next_phase = 1	reward = -2.614720	array([[-1.4713687, -1.6625874]], dtype=float32)

time = 65	action = 0	current_phase = 0	next_phase = 1	reward = -2.578022	array([[-0.9478561, -1.6551914]], dtype=float32)

time = 70	action = 0	current_phase = 0	next_phase = 1	reward = -2.541727	array([[-0.64671105, -1.4717796 ]], dtype=float32)

time = 75	action = 0	current_phase = 0	next_phase = 1	reward = -2.512061	array([[-0.5300266, -1.4448458]], dtype=float32)

time = 80	action = 0	current_phase = 0	next_phase = 1	reward = -2.012050	array([[-0.6665103, -1.4400759]], dtype=float32)

time = 85	action = 0	current_phase = 0	next_phase = 1	reward = -3.126855	array([[-1.4800835, -1.6244516]], dtype=float32)

time = 90	action = 0	current_phase = 0	next_phase = 1	reward = -3.670187	array([[-1.193253 , -1.8269141]], dtype=float32)

time = 95	action = 1	current_phase = 0	next_phase = 1	reward = -2.061967	array([[-1.5972828, -1.4543945]], dtype=float32)

time = 103	action = 0	current_phase = 1	next_phase = 0	reward = 0.077742	array([[-0.14236185, -1.5656092 ]], dtype=float32)

time = 108	action = 0	current_phase = 1	next_phase = 0	reward = -0.161543	array([[-0.41390896, -1.2760454 ]], dtype=float32)

time = 113	action = 0	current_phase = 1	next_phase = 0	reward = 0.023125	array([[-0.21646908, -1.515525  ]], dtype=float32)

time = 118	action = 0	current_phase = 1	next_phase = 0	reward = -1.462713	array([[-0.86810195, -1.8354398 ]], dtype=float32)

time = 123	action = 0	current_phase = 1	next_phase = 0	reward = -1.672586	array([[-1.2259375, -1.8616766]], dtype=float32)

time = 128	action = 0	current_phase = 1	next_phase = 0	reward = -1.556970	array([[-0.838775 , -1.7008764]], dtype=float32)

time = 133	action = 0	current_phase = 1	next_phase = 0	reward = -1.447358	array([[-1.0362842, -1.5897652]], dtype=float32)

time = 138	action = 0	current_phase = 1	next_phase = 0	reward = -1.364585	array([[-1.288937 , -1.5170356]], dtype=float32)

time = 143	action = 0	current_phase = 1	next_phase = 0	reward = -1.093301	array([[-0.6938348, -1.8151089]], dtype=float32)

time = 148	action = 1	current_phase = 1	next_phase = 0	reward = -1.780068	array([[-1.7169489, -1.564007 ]], dtype=float32)

time = 156	action = 0	current_phase = 0	next_phase = 1	reward = -0.499160	array([[-0.6172545, -1.4716934]], dtype=float32)

time = 161	action = 0	current_phase = 0	next_phase = 1	reward = -0.334786	array([[-0.5093721, -1.4540418]], dtype=float32)

time = 166	action = 0	current_phase = 0	next_phase = 1	reward = -0.195090	array([[-0.22457719, -1.4800287 ]], dtype=float32)

time = 171	action = 0	current_phase = 0	next_phase = 1	reward = 0.273532	array([[-0.55579466, -1.2237252 ]], dtype=float32)

time = 176	action = 0	current_phase = 0	next_phase = 1	reward = -1.118569	array([[-0.5628137, -1.7365127]], dtype=float32)

time = 181	action = 0	current_phase = 0	next_phase = 1	reward = -1.706860	array([[-1.2996106, -1.6078578]], dtype=float32)

time = 186	action = 0	current_phase = 0	next_phase = 1	reward = -1.595431	array([[-0.7327383, -1.786309 ]], dtype=float32)

time = 191	action = 0	current_phase = 0	next_phase = 1	reward = -1.469464	array([[-1.2436372, -1.5343714]], dtype=float32)

time = 196	action = 0	current_phase = 0	next_phase = 1	reward = -1.361784	array([[-0.9116789, -1.2543814]], dtype=float32)

time = 201	action = 0	current_phase = 0	next_phase = 1	reward = -0.941376	array([[-0.72589946, -1.3426766 ]], dtype=float32)

time = 206	action = 0	current_phase = 0	next_phase = 1	reward = -2.356764	array([[-1.3954058, -1.595537 ]], dtype=float32)

time = 211	action = 0	current_phase = 0	next_phase = 1	reward = -2.617845	array([[-1.043331 , -1.7939277]], dtype=float32)

time = 216	action = 0	current_phase = 0	next_phase = 1	reward = -2.590183	array([[-0.8706897, -1.761859 ]], dtype=float32)

time = 221	action = 0	current_phase = 0	next_phase = 1	reward = -2.566892	array([[-0.6333268, -1.4676332]], dtype=float32)

time = 226	action = 0	current_phase = 0	next_phase = 1	reward = -2.536861	array([[-0.66847295, -1.3705232 ]], dtype=float32)

time = 231	action = 0	current_phase = 0	next_phase = 1	reward = -2.073083	array([[-0.7489164, -1.3997774]], dtype=float32)

time = 236	action = 0	current_phase = 0	next_phase = 1	reward = -3.382204	array([[-1.4772325, -1.5937517]], dtype=float32)

time = 241	action = 1	current_phase = 0	next_phase = 1	reward = -2.504562	array([[-1.5848646, -1.5839561]], dtype=float32)

time = 249	action = 0	current_phase = 1	next_phase = 0	reward = 0.259771	array([[-0.40511322, -1.5808167 ]], dtype=float32)

time = 254	action = 0	current_phase = 1	next_phase = 0	reward = -0.251536	array([[-0.15353334, -1.6112328 ]], dtype=float32)

time = 259	action = 0	current_phase = 1	next_phase = 0	reward = -0.177528	array([[-0.36180317, -1.2057768 ]], dtype=float32)

time = 264	action = 0	current_phase = 1	next_phase = 0	reward = -0.192484	array([[-0.4607988, -1.5680809]], dtype=float32)

time = 269	action = 0	current_phase = 1	next_phase = 0	reward = -1.607786	array([[-1.2098525, -1.8542668]], dtype=float32)

time = 274	action = 0	current_phase = 1	next_phase = 0	reward = -1.653662	array([[-0.5738335, -1.8701794]], dtype=float32)

time = 279	action = 0	current_phase = 1	next_phase = 0	reward = -1.534695	array([[-0.76383394, -1.5555172 ]], dtype=float32)

time = 284	action = 0	current_phase = 1	next_phase = 0	reward = -1.423052	array([[-1.3001399, -1.5960045]], dtype=float32)

time = 289	action = 0	current_phase = 1	next_phase = 0	reward = -1.391259	array([[-0.93840635, -1.8026495 ]], dtype=float32)

time = 294	action = 0	current_phase = 1	next_phase = 0	reward = -1.390266	array([[-0.61685437, -1.9548125 ]], dtype=float32)

time = 299	action = 0	current_phase = 1	next_phase = 0	reward = -2.564844	array([[-0.6741386, -2.053373 ]], dtype=float32)

Train on 834 samples, validate on 358 samples

Epoch 1/50

 - 4s - loss: 0.1500 - val_loss: 0.1356

Epoch 2/50

 - 4s - loss: 0.1166 - val_loss: 0.1186

Epoch 3/50

 - 4s - loss: 0.1065 - val_loss: 0.1047

Epoch 4/50

 - 4s - loss: 0.0898 - val_loss: 0.1031

Epoch 5/50

 - 4s - loss: 0.0890 - val_loss: 0.0988

Epoch 6/50

 - 4s - loss: 0.0875 - val_loss: 0.0953

Epoch 7/50

 - 4s - loss: 0.0786 - val_loss: 0.0945

Epoch 8/50

 - 4s - loss: 0.0807 - val_loss: 0.0934

Epoch 9/50

 - 4s - loss: 0.0793 - val_loss: 0.0928

Epoch 10/50

 - 4s - loss: 0.0750 - val_loss: 0.0931

Epoch 11/50

 - 4s - loss: 0.0697 - val_loss: 0.0927

Epoch 12/50

 - 4s - loss: 0.0672 - val_loss: 0.0926

Epoch 13/50

 - 4s - loss: 0.0681 - val_loss: 0.0923

Epoch 14/50

 - 5s - loss: 0.0683 - val_loss: 0.0872

Epoch 15/50

 - 4s - loss: 0.0622 - val_loss: 0.0905

Epoch 16/50

 - 4s - loss: 0.0605 - val_loss: 0.0921

Epoch 17/50

 - 4s - loss: 0.0597 - val_loss: 0.0918

Epoch 18/50

 - 4s - loss: 0.0609 - val_loss: 0.0907

Epoch 19/50

 - 4s - loss: 0.0597 - val_loss: 0.0871

Epoch 20/50

 - 4s - loss: 0.0550 - val_loss: 0.0944

Epoch 21/50

 - 4s - loss: 0.0603 - val_loss: 0.0959

Epoch 22/50

 - 4s - loss: 0.0551 - val_loss: 0.0937

Epoch 23/50

 - 4s - loss: 0.0529 - val_loss: 0.0952

Epoch 24/50

 - 4s - loss: 0.0536 - val_loss: 0.0976

Epoch 25/50

 - 4s - loss: 0.0505 - val_loss: 0.0938

Epoch 26/50

 - 4s - loss: 0.0561 - val_loss: 0.0931

Epoch 27/50

 - 4s - loss: 0.0493 - val_loss: 0.0960

Epoch 28/50

 - 4s - loss: 0.0525 - val_loss: 0.0940

Epoch 29/50

 - 4s - loss: 0.0530 - val_loss: 0.1004

length of memory (state 0, action 0): 539, after forget

length of memory (state 0, action 1): 305, after forget

length of memory (state 1, action 0): 510, after forget

length of memory (state 1, action 1): 292, after forget

time = 304	action = 0	current_phase = 1	next_phase = 0	reward = -2.594361	array([[-0.708346 , -2.0944498]], dtype=float32)

time = 309	action = 0	current_phase = 1	next_phase = 0	reward = -2.555231	array([[-0.60068804, -1.7428313 ]], dtype=float32)

time = 314	action = 0	current_phase = 1	next_phase = 0	reward = -2.518980	array([[-0.46442342, -1.5926363 ]], dtype=float32)

time = 319	action = 0	current_phase = 1	next_phase = 0	reward = -2.274460	array([[-0.51171637, -1.6361264 ]], dtype=float32)

time = 324	action = 0	current_phase = 1	next_phase = 0	reward = -2.715056	array([[-1.5302234, -1.9321907]], dtype=float32)

time = 329	action = 0	current_phase = 1	next_phase = 0	reward = -3.606743	array([[-0.5901933, -2.4888546]], dtype=float32)

time = 334	action = 0	current_phase = 1	next_phase = 0	reward = -3.677302	array([[-1.0408067, -2.1486282]], dtype=float32)

time = 339	action = 0	current_phase = 1	next_phase = 0	reward = -3.687691	array([[-0.6547723, -1.9840695]], dtype=float32)

time = 344	action = 0	current_phase = 1	next_phase = 0	reward = -3.692794	array([[-0.70653844, -1.8059809 ]], dtype=float32)

time = 349	action = 0	current_phase = 1	next_phase = 0	reward = -3.776875	array([[-1.5974408, -1.8300062]], dtype=float32)

time = 354	action = 1	current_phase = 1	next_phase = 0	reward = -0.503339	array([[-2.0294228, -1.8827615]], dtype=float32)

time = 362	action = 0	current_phase = 0	next_phase = 1	reward = -0.616366	array([[-1.0226123, -1.8185343]], dtype=float32)

time = 367	action = 0	current_phase = 0	next_phase = 1	reward = -0.462457	array([[-0.88896126, -1.5942354 ]], dtype=float32)

time = 372	action = 0	current_phase = 0	next_phase = 1	reward = -0.315537	array([[-0.6623388, -1.548285 ]], dtype=float32)

time = 377	action = 0	current_phase = 0	next_phase = 1	reward = -0.178800	array([[-0.5359024, -1.2959774]], dtype=float32)

time = 382	action = 0	current_phase = 0	next_phase = 1	reward = 0.264336	array([[-0.51067793, -2.2846224 ]], dtype=float32)

time = 387	action = 0	current_phase = 0	next_phase = 1	reward = -1.316142	array([[-0.6764664, -1.5430905]], dtype=float32)

time = 392	action = 0	current_phase = 0	next_phase = 1	reward = -1.697325	array([[-0.72580785, -2.1410546 ]], dtype=float32)

time = 397	action = 0	current_phase = 0	next_phase = 1	reward = -1.588503	array([[-1.3655934, -2.0257719]], dtype=float32)

time = 402	action = 1	current_phase = 0	next_phase = 1	reward = -1.511511	array([[-1.787856 , -1.5828283]], dtype=float32)

time = 410	action = 0	current_phase = 1	next_phase = 0	reward = 0.082643	array([[-0.33244145, -1.7818837 ]], dtype=float32)

time = 415	action = 0	current_phase = 1	next_phase = 0	reward = -0.443489	array([[-1.196623 , -1.9443939]], dtype=float32)

time = 420	action = 1	current_phase = 1	next_phase = 0	reward = -2.106592	array([[-2.0732925, -1.7927374]], dtype=float32)

time = 428	action = 0	current_phase = 0	next_phase = 1	reward = -0.425839	array([[-0.86152303, -1.5961648 ]], dtype=float32)

time = 433	action = 0	current_phase = 0	next_phase = 1	reward = -0.270513	array([[-0.54577005, -1.238574  ]], dtype=float32)

time = 438	action = 0	current_phase = 0	next_phase = 1	reward = -0.160179	array([[-0.8469127, -1.52288  ]], dtype=float32)

time = 443	action = 0	current_phase = 0	next_phase = 1	reward = 0.013306	array([[-0.6907627, -2.2690272]], dtype=float32)

time = 448	action = 0	current_phase = 0	next_phase = 1	reward = -1.464909	array([[-1.7864214, -2.0908396]], dtype=float32)

time = 453	action = 0	current_phase = 0	next_phase = 1	reward = -1.665694	array([[-1.2500324, -2.2050004]], dtype=float32)

time = 458	action = 0	current_phase = 0	next_phase = 1	reward = -1.561040	array([[-1.062231 , -1.7715925]], dtype=float32)

time = 463	action = 0	current_phase = 0	next_phase = 1	reward = -1.454720	array([[-1.303455 , -1.5269829]], dtype=float32)

time = 468	action = 0	current_phase = 0	next_phase = 1	reward = -1.370882	array([[-1.0518343, -1.6803976]], dtype=float32)

time = 473	action = 1	current_phase = 0	next_phase = 1	reward = -1.035157	array([[-1.9833148, -1.9755653]], dtype=float32)

time = 481	action = 0	current_phase = 1	next_phase = 0	reward = -1.173779	array([[-0.87332296, -1.7910534 ]], dtype=float32)

time = 486	action = 0	current_phase = 1	next_phase = 0	reward = -1.042743	array([[-0.69573814, -1.8142884 ]], dtype=float32)

time = 491	action = 0	current_phase = 1	next_phase = 0	reward = -0.905388	array([[-0.41309988, -1.6106968 ]], dtype=float32)

time = 496	action = 0	current_phase = 1	next_phase = 0	reward = -0.775159	array([[-0.5869511, -1.6285368]], dtype=float32)

time = 501	action = 0	current_phase = 1	next_phase = 0	reward = -0.287359	array([[-0.41785705, -1.7074256 ]], dtype=float32)

time = 506	action = 1	current_phase = 1	next_phase = 0	reward = -1.475323	array([[-1.7916083, -1.6448343]], dtype=float32)

time = 514	action = 0	current_phase = 0	next_phase = 1	reward = -0.556770	array([[-0.9243994, -1.6704082]], dtype=float32)

time = 519	action = 0	current_phase = 0	next_phase = 1	reward = -0.398576	array([[-0.7395185, -1.6453325]], dtype=float32)

time = 524	action = 0	current_phase = 0	next_phase = 1	reward = -0.242820	array([[-0.7482857, -1.3867782]], dtype=float32)

time = 529	action = 0	current_phase = 0	next_phase = 1	reward = 0.115224	array([[-0.48786297, -1.9210675 ]], dtype=float32)

time = 534	action = 0	current_phase = 0	next_phase = 1	reward = -0.404184	array([[-0.2555834, -1.7826767]], dtype=float32)

time = 539	action = 0	current_phase = 0	next_phase = 1	reward = -1.601724	array([[-1.5276145, -2.1965597]], dtype=float32)

time = 544	action = 0	current_phase = 0	next_phase = 1	reward = -1.643232	array([[-1.8052611, -1.9504448]], dtype=float32)

time = 549	action = 0	current_phase = 0	next_phase = 1	reward = -1.535987	array([[-1.4078171, -1.5945221]], dtype=float32)

time = 554	action = 1	current_phase = 0	next_phase = 1	reward = -1.423442	array([[-1.6951197, -1.627877 ]], dtype=float32)

time = 562	action = 0	current_phase = 1	next_phase = 0	reward = 0.216021	array([[-0.38935447, -1.9907355 ]], dtype=float32)

time = 567	action = 0	current_phase = 1	next_phase = 0	reward = -1.320860	array([[-1.3031868, -2.1174126]], dtype=float32)

time = 572	action = 0	current_phase = 1	next_phase = 0	reward = -1.690692	array([[-0.7241238, -2.4061832]], dtype=float32)

time = 577	action = 0	current_phase = 1	next_phase = 0	reward = -1.575110	array([[-0.65957314, -2.0375261 ]], dtype=float32)

time = 582	action = 0	current_phase = 1	next_phase = 0	reward = -1.458941	array([[-1.1316067, -1.7011735]], dtype=float32)

time = 587	action = 1	current_phase = 1	next_phase = 0	reward = -0.813256	array([[-1.8679298, -1.6768773]], dtype=float32)

time = 595	action = 0	current_phase = 0	next_phase = 1	reward = -0.840119	array([[-1.1297144, -1.5587333]], dtype=float32)

time = 600	action = 1	current_phase = 0	next_phase = 1	reward = -2.115271	array([[-2.0514474, -1.9796842]], dtype=float32)

Train on 837 samples, validate on 359 samples

Epoch 1/50

 - 4s - loss: 0.0848 - val_loss: 0.0993

Epoch 2/50

 - 4s - loss: 0.0836 - val_loss: 0.0917

Epoch 3/50

 - 4s - loss: 0.0806 - val_loss: 0.0973

Epoch 4/50

 - 4s - loss: 0.0707 - val_loss: 0.0887

Epoch 5/50

 - 4s - loss: 0.0690 - val_loss: 0.0937

Epoch 6/50

 - 4s - loss: 0.0639 - val_loss: 0.0817

Epoch 7/50

 - 4s - loss: 0.0678 - val_loss: 0.0880

Epoch 8/50

 - 4s - loss: 0.0616 - val_loss: 0.0864

Epoch 9/50

 - 4s - loss: 0.0587 - val_loss: 0.0878

Epoch 10/50

 - 4s - loss: 0.0528 - val_loss: 0.0862

Epoch 11/50

 - 4s - loss: 0.0573 - val_loss: 0.0806

Epoch 12/50

 - 4s - loss: 0.0590 - val_loss: 0.0898

Epoch 13/50

 - 4s - loss: 0.0562 - val_loss: 0.0835

Epoch 14/50

 - 4s - loss: 0.0567 - val_loss: 0.0837

Epoch 15/50

 - 4s - loss: 0.0540 - val_loss: 0.0848

Epoch 16/50

 - 4s - loss: 0.0510 - val_loss: 0.0832

Epoch 17/50

 - 4s - loss: 0.0513 - val_loss: 0.0829

Epoch 18/50

 - 4s - loss: 0.0527 - val_loss: 0.0835

Epoch 19/50

 - 4s - loss: 0.0513 - val_loss: 0.0804

Epoch 20/50

 - 4s - loss: 0.0540 - val_loss: 0.0822

Epoch 21/50

 - 4s - loss: 0.0525 - val_loss: 0.0866

Epoch 22/50

 - 4s - loss: 0.0483 - val_loss: 0.0897

Epoch 23/50

 - 4s - loss: 0.0475 - val_loss: 0.0880

Epoch 24/50

 - 4s - loss: 0.0442 - val_loss: 0.0843

Epoch 25/50

 - 4s - loss: 0.0461 - val_loss: 0.0879

Epoch 26/50

 - 4s - loss: 0.0498 - val_loss: 0.0850

Epoch 27/50

 - 4s - loss: 0.0417 - val_loss: 0.0832

Epoch 28/50

 - 4s - loss: 0.0446 - val_loss: 0.0837

Epoch 29/50

 - 4s - loss: 0.0406 - val_loss: 0.0848

length of memory (state 0, action 0): 565, after forget

length of memory (state 0, action 1): 309, after forget

length of memory (state 1, action 0): 532, after forget

length of memory (state 1, action 1): 296, after forget

time = 608	action = 0	current_phase = 1	next_phase = 0	reward = -0.436226	array([[-0.71992624, -1.6503061 ]], dtype=float32)

time = 613	action = 0	current_phase = 1	next_phase = 0	reward = -0.277002	array([[-0.4347787, -1.5813438]], dtype=float32)

time = 618	action = 0	current_phase = 1	next_phase = 0	reward = -0.164707	array([[-0.3822472, -1.7280095]], dtype=float32)

time = 623	action = 0	current_phase = 1	next_phase = 0	reward = 0.017978	array([[-0.45252508, -1.9312874 ]], dtype=float32)

time = 628	action = 0	current_phase = 1	next_phase = 0	reward = -1.465260	array([[-1.9876919, -2.1595898]], dtype=float32)

time = 633	action = 0	current_phase = 1	next_phase = 0	reward = -1.672578	array([[-1.7697232, -2.271459 ]], dtype=float32)

time = 638	action = 0	current_phase = 1	next_phase = 0	reward = -1.563238	array([[-1.1201968, -1.7569802]], dtype=float32)

time = 643	action = 1	current_phase = 1	next_phase = 0	reward = -1.465069	array([[-2.1433475, -1.7935336]], dtype=float32)

time = 651	action = 0	current_phase = 0	next_phase = 1	reward = 0.306527	array([[-0.68491143, -1.9294689 ]], dtype=float32)

time = 656	action = 0	current_phase = 0	next_phase = 1	reward = -1.118317	array([[-0.84032464, -1.6670403 ]], dtype=float32)

time = 661	action = 0	current_phase = 0	next_phase = 1	reward = -1.713363	array([[-1.6257844, -2.3686156]], dtype=float32)

time = 666	action = 0	current_phase = 0	next_phase = 1	reward = -1.596807	array([[-1.7795007, -2.095109 ]], dtype=float32)

time = 671	action = 1	current_phase = 0	next_phase = 1	reward = -1.547927	array([[-1.728831 , -1.5071812]], dtype=float32)

time = 679	action = 0	current_phase = 1	next_phase = 0	reward = -0.186020	array([[-0.40136337, -1.669228  ]], dtype=float32)

time = 684	action = 0	current_phase = 1	next_phase = 0	reward = -0.146340	array([[-0.69082016, -1.5372739 ]], dtype=float32)

time = 689	action = 0	current_phase = 1	next_phase = 0	reward = -1.602692	array([[-1.5118493, -2.2754357]], dtype=float32)

time = 694	action = 0	current_phase = 1	next_phase = 0	reward = -1.635250	array([[-1.1543626, -2.432549 ]], dtype=float32)

time = 699	action = 1	current_phase = 1	next_phase = 0	reward = -1.620268	array([[-1.8380716, -1.6800358]], dtype=float32)

time = 707	action = 0	current_phase = 0	next_phase = 1	reward = -0.165491	array([[-0.6172745, -1.474822 ]], dtype=float32)

time = 712	action = 0	current_phase = 0	next_phase = 1	reward = 0.182034	array([[-0.5305001, -2.3824043]], dtype=float32)

time = 717	action = 0	current_phase = 0	next_phase = 1	reward = -1.320925	array([[-0.92324466, -2.4704313 ]], dtype=float32)

time = 722	action = 0	current_phase = 0	next_phase = 1	reward = -1.693397	array([[-0.8924319, -2.2762957]], dtype=float32)

time = 727	action = 0	current_phase = 0	next_phase = 1	reward = -1.583021	array([[-1.5428874, -2.0086205]], dtype=float32)

time = 732	action = 1	current_phase = 0	next_phase = 1	reward = -1.525507	array([[-1.6707915, -1.5524576]], dtype=float32)

time = 740	action = 0	current_phase = 1	next_phase = 0	reward = -0.226385	array([[-0.52138174, -2.078349  ]], dtype=float32)

time = 745	action = 0	current_phase = 1	next_phase = 0	reward = -0.330834	array([[-0.83409715, -2.1331732 ]], dtype=float32)

time = 750	action = 0	current_phase = 1	next_phase = 0	reward = -1.740858	array([[-0.89727515, -2.4441743 ]], dtype=float32)

time = 755	action = 0	current_phase = 1	next_phase = 0	reward = -1.625231	array([[-0.7797394, -2.1807473]], dtype=float32)

time = 760	action = 1	current_phase = 1	next_phase = 0	reward = -1.607403	array([[-2.0221097, -1.9111772]], dtype=float32)

time = 768	action = 0	current_phase = 0	next_phase = 1	reward = -0.164712	array([[-0.57354736, -1.9797921 ]], dtype=float32)

time = 773	action = 0	current_phase = 0	next_phase = 1	reward = 0.079957	array([[-0.6843317, -1.6531293]], dtype=float32)

time = 778	action = 0	current_phase = 0	next_phase = 1	reward = -1.459061	array([[-1.627824 , -2.2894611]], dtype=float32)

time = 783	action = 0	current_phase = 0	next_phase = 1	reward = -1.655981	array([[-1.6980219, -2.2333815]], dtype=float32)

time = 788	action = 0	current_phase = 0	next_phase = 1	reward = -1.545307	array([[-1.709361 , -1.7603395]], dtype=float32)

time = 793	action = 0	current_phase = 0	next_phase = 1	reward = -1.435766	array([[-1.3206475, -1.4765928]], dtype=float32)

time = 798	action = 0	current_phase = 0	next_phase = 1	reward = -1.364690	array([[-1.1690997, -1.9563706]], dtype=float32)

time = 803	action = 1	current_phase = 0	next_phase = 1	reward = -1.857646	array([[-2.0444367, -1.9472313]], dtype=float32)

time = 811	action = 1	current_phase = 1	next_phase = 0	reward = -2.060915	array([[-1.981491 , -1.9133625]], dtype=float32)

time = 819	action = 0	current_phase = 0	next_phase = 1	reward = -0.414919	array([[-0.8593863, -1.607342 ]], dtype=float32)

time = 824	action = 0	current_phase = 0	next_phase = 1	reward = -0.261993	array([[-0.46894974, -1.3022125 ]], dtype=float32)

time = 829	action = 0	current_phase = 0	next_phase = 1	reward = -0.179688	array([[-0.61541975, -1.36759   ]], dtype=float32)

time = 834	action = 0	current_phase = 0	next_phase = 1	reward = -0.142260	array([[-0.76244295, -1.2926717 ]], dtype=float32)

time = 839	action = 0	current_phase = 0	next_phase = 1	reward = -1.597505	array([[-0.7894288, -2.1138   ]], dtype=float32)

time = 844	action = 0	current_phase = 0	next_phase = 1	reward = -1.632792	array([[-1.1849   , -2.0634122]], dtype=float32)

time = 849	action = 1	current_phase = 0	next_phase = 1	reward = -1.631130	array([[-1.6484485, -1.6098254]], dtype=float32)

time = 857	action = 0	current_phase = 1	next_phase = 0	reward = -0.169759	array([[-0.53846323, -1.6313001 ]], dtype=float32)

time = 862	action = 0	current_phase = 1	next_phase = 0	reward = 0.163825	array([[-0.42397708, -2.4125009 ]], dtype=float32)

time = 867	action = 0	current_phase = 1	next_phase = 0	reward = -1.319266	array([[-1.3553395, -2.2726896]], dtype=float32)

time = 872	action = 0	current_phase = 1	next_phase = 0	reward = -1.689997	array([[-1.3806988, -2.3734522]], dtype=float32)

time = 877	action = 0	current_phase = 1	next_phase = 0	reward = -1.567694	array([[-1.3338861, -2.0259774]], dtype=float32)

time = 882	action = 1	current_phase = 1	next_phase = 0	reward = -1.488146	array([[-1.9235713, -1.8454309]], dtype=float32)

time = 890	action = 0	current_phase = 0	next_phase = 1	reward = 0.344626	array([[-0.5612128, -2.0401936]], dtype=float32)

time = 895	action = 0	current_phase = 0	next_phase = 1	reward = -0.902525	array([[-0.7566953, -1.8724461]], dtype=float32)

time = 900	action = 0	current_phase = 0	next_phase = 1	reward = -1.749561	array([[-1.5382128, -2.5335875]], dtype=float32)

time = 905	action = 0	current_phase = 0	next_phase = 1	reward = -1.638624	array([[-1.9482464, -2.1096888]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0596 - val_loss: 0.0456

Epoch 2/50

 - 4s - loss: 0.0546 - val_loss: 0.0456

Epoch 3/50

 - 4s - loss: 0.0515 - val_loss: 0.0462

Epoch 4/50

 - 4s - loss: 0.0498 - val_loss: 0.0464

Epoch 5/50

 - 4s - loss: 0.0478 - val_loss: 0.0500

Epoch 6/50

 - 4s - loss: 0.0459 - val_loss: 0.0492

Epoch 7/50

 - 4s - loss: 0.0469 - val_loss: 0.0505

Epoch 8/50

 - 4s - loss: 0.0467 - val_loss: 0.0520

Epoch 9/50

 - 4s - loss: 0.0419 - val_loss: 0.0517

Epoch 10/50

 - 4s - loss: 0.0415 - val_loss: 0.0507

Epoch 11/50

 - 4s - loss: 0.0430 - val_loss: 0.0532

length of memory (state 0, action 0): 591, after forget

length of memory (state 0, action 1): 313, after forget

length of memory (state 1, action 0): 552, after forget

length of memory (state 1, action 1): 301, after forget

time = 910	action = 0	current_phase = 0	next_phase = 1	reward = -1.524615	array([[-1.2266551, -1.7693769]], dtype=float32)

time = 915	action = 1	current_phase = 0	next_phase = 1	reward = -1.394550	array([[-1.7824217, -1.6329232]], dtype=float32)

time = 923	action = 0	current_phase = 1	next_phase = 0	reward = 0.123865	array([[-0.47546476, -2.0192182 ]], dtype=float32)

time = 928	action = 0	current_phase = 1	next_phase = 0	reward = -1.456058	array([[-2.0143814, -2.0514596]], dtype=float32)

time = 933	action = 1	current_phase = 1	next_phase = 0	reward = -1.936139	array([[-2.600542, -2.029277]], dtype=float32)

time = 941	action = 0	current_phase = 0	next_phase = 1	reward = -0.319452	array([[-0.643323 , -1.5265455]], dtype=float32)

time = 946	action = 0	current_phase = 0	next_phase = 1	reward = -0.178678	array([[-0.68234354, -1.3897021 ]], dtype=float32)

time = 951	action = 0	current_phase = 0	next_phase = 1	reward = 0.249678	array([[-0.57113177, -2.3174493 ]], dtype=float32)

time = 956	action = 0	current_phase = 0	next_phase = 1	reward = -1.173195	array([[-0.87832874, -2.20066   ]], dtype=float32)

time = 961	action = 0	current_phase = 0	next_phase = 1	reward = -1.711687	array([[-1.4384863, -2.4579132]], dtype=float32)

time = 966	action = 1	current_phase = 0	next_phase = 1	reward = -1.804510	array([[-2.1900375, -1.7765062]], dtype=float32)

time = 974	action = 0	current_phase = 1	next_phase = 0	reward = -0.245158	array([[-0.46994096, -1.666785  ]], dtype=float32)

time = 979	action = 0	current_phase = 1	next_phase = 0	reward = -0.182773	array([[-0.29194444, -1.8799106 ]], dtype=float32)

time = 984	action = 0	current_phase = 1	next_phase = 0	reward = -0.149127	array([[-0.5450554, -2.05562  ]], dtype=float32)

time = 989	action = 0	current_phase = 1	next_phase = 0	reward = -1.601763	array([[-0.6556632, -2.6307628]], dtype=float32)

time = 994	action = 0	current_phase = 1	next_phase = 0	reward = -1.644899	array([[-0.78024924, -2.4927344 ]], dtype=float32)

time = 999	action = 0	current_phase = 1	next_phase = 0	reward = -1.535643	array([[-0.83821017, -1.6033155 ]], dtype=float32)

time = 1004	action = 1	current_phase = 1	next_phase = 0	reward = -1.435451	array([[-2.1031506, -1.5698786]], dtype=float32)

time = 1012	action = 0	current_phase = 0	next_phase = 1	reward = 0.194102	array([[-0.6502202, -2.3546772]], dtype=float32)

time = 1017	action = 1	current_phase = 0	next_phase = 1	reward = -1.785942	array([[-1.802749 , -1.7419993]], dtype=float32)

time = 1025	action = 0	current_phase = 1	next_phase = 0	reward = -0.532587	array([[-1.0585009, -1.6314746]], dtype=float32)

time = 1030	action = 0	current_phase = 1	next_phase = 0	reward = -0.373283	array([[-0.4790852, -1.6006474]], dtype=float32)

time = 1035	action = 0	current_phase = 1	next_phase = 0	reward = -0.226052	array([[-0.44247785, -1.5794109 ]], dtype=float32)

time = 1040	action = 0	current_phase = 1	next_phase = 0	reward = 0.371778	array([[-0.38114652, -2.1712055 ]], dtype=float32)

time = 1045	action = 0	current_phase = 1	next_phase = 0	reward = -0.677035	array([[-0.54817235, -2.138698  ]], dtype=float32)

time = 1050	action = 0	current_phase = 1	next_phase = 0	reward = -1.725355	array([[-1.8488982, -1.8512001]], dtype=float32)

time = 1055	action = 0	current_phase = 1	next_phase = 0	reward = -1.610733	array([[-1.6447182, -1.9793715]], dtype=float32)

time = 1060	action = 1	current_phase = 1	next_phase = 0	reward = -1.602962	array([[-2.1161957, -1.9764625]], dtype=float32)

time = 1068	action = 0	current_phase = 0	next_phase = 1	reward = -0.168307	array([[-0.6805452, -1.5796094]], dtype=float32)

time = 1073	action = 0	current_phase = 0	next_phase = 1	reward = 0.117883	array([[-0.6222344, -1.6305487]], dtype=float32)

time = 1078	action = 0	current_phase = 0	next_phase = 1	reward = -1.456548	array([[-1.5369458, -2.7452943]], dtype=float32)

time = 1083	action = 0	current_phase = 0	next_phase = 1	reward = -1.657120	array([[-1.7667301, -2.3941693]], dtype=float32)

time = 1088	action = 1	current_phase = 0	next_phase = 1	reward = -1.706972	array([[-2.0629368, -1.802783 ]], dtype=float32)

time = 1096	action = 0	current_phase = 1	next_phase = 0	reward = -0.196815	array([[-0.45935458, -1.6891122 ]], dtype=float32)

time = 1101	action = 0	current_phase = 1	next_phase = 0	reward = 0.317094	array([[-0.49411213, -2.0054672 ]], dtype=float32)

time = 1106	action = 0	current_phase = 1	next_phase = 0	reward = -1.118019	array([[-0.52584344, -2.5996351 ]], dtype=float32)

time = 1111	action = 1	current_phase = 1	next_phase = 0	reward = -2.058631	array([[-2.4982312, -2.083911 ]], dtype=float32)

time = 1119	action = 0	current_phase = 0	next_phase = 1	reward = -0.396279	array([[-0.83774805, -1.5413715 ]], dtype=float32)

time = 1124	action = 0	current_phase = 0	next_phase = 1	reward = -0.240110	array([[-0.6354414, -1.2238892]], dtype=float32)

time = 1129	action = 0	current_phase = 0	next_phase = 1	reward = -0.179113	array([[-0.709142 , -1.7198238]], dtype=float32)

time = 1134	action = 0	current_phase = 0	next_phase = 1	reward = -0.141376	array([[-0.14779742, -1.8946354 ]], dtype=float32)

time = 1139	action = 0	current_phase = 0	next_phase = 1	reward = -1.603372	array([[-1.7656276, -2.2426877]], dtype=float32)

time = 1144	action = 1	current_phase = 0	next_phase = 1	reward = -1.909559	array([[-2.1772738, -1.8516812]], dtype=float32)

time = 1152	action = 0	current_phase = 1	next_phase = 0	reward = -0.307064	array([[-0.63575554, -1.5838554 ]], dtype=float32)

time = 1157	action = 0	current_phase = 1	next_phase = 0	reward = -0.173716	array([[-0.55669904, -1.5134838 ]], dtype=float32)

time = 1162	action = 0	current_phase = 1	next_phase = 0	reward = 0.195762	array([[-0.63932836, -2.3035178 ]], dtype=float32)

time = 1167	action = 0	current_phase = 1	next_phase = 0	reward = -1.265360	array([[-1.4244728, -2.4519546]], dtype=float32)

time = 1172	action = 0	current_phase = 1	next_phase = 0	reward = -1.686154	array([[-1.2005138, -2.4784572]], dtype=float32)

time = 1177	action = 0	current_phase = 1	next_phase = 0	reward = -1.571742	array([[-1.6017221, -1.6397249]], dtype=float32)

time = 1182	action = 1	current_phase = 1	next_phase = 0	reward = -1.504487	array([[-1.9493569, -1.6288061]], dtype=float32)

time = 1190	action = 0	current_phase = 0	next_phase = 1	reward = 0.355589	array([[-0.3704927, -1.8646016]], dtype=float32)

time = 1195	action = 0	current_phase = 0	next_phase = 1	reward = -0.897187	array([[-1.4212122, -1.7081887]], dtype=float32)

time = 1200	action = 0	current_phase = 0	next_phase = 1	reward = -1.736995	array([[-2.156295 , -2.4119675]], dtype=float32)

time = 1205	action = 0	current_phase = 0	next_phase = 1	reward = -1.625272	array([[-1.8956366, -2.0848262]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0659 - val_loss: 0.0423

Epoch 2/50

 - 4s - loss: 0.0646 - val_loss: 0.0404

Epoch 3/50

 - 4s - loss: 0.0562 - val_loss: 0.0395

Epoch 4/50

 - 4s - loss: 0.0518 - val_loss: 0.0392

Epoch 5/50

 - 4s - loss: 0.0520 - val_loss: 0.0411

Epoch 6/50

 - 4s - loss: 0.0510 - val_loss: 0.0414

Epoch 7/50

 - 4s - loss: 0.0530 - val_loss: 0.0416

Epoch 8/50

 - 4s - loss: 0.0518 - val_loss: 0.0422

Epoch 9/50

 - 4s - loss: 0.0489 - val_loss: 0.0410

Epoch 10/50

 - 4s - loss: 0.0502 - val_loss: 0.0451

Epoch 11/50

 - 4s - loss: 0.0492 - val_loss: 0.0426

Epoch 12/50

 - 4s - loss: 0.0466 - val_loss: 0.0406

Epoch 13/50

 - 4s - loss: 0.0427 - val_loss: 0.0456

Epoch 14/50

 - 4s - loss: 0.0498 - val_loss: 0.0450

length of memory (state 0, action 0): 611, after forget

length of memory (state 0, action 1): 318, after forget

length of memory (state 1, action 0): 576, after forget

length of memory (state 1, action 1): 306, after forget

time = 1210	action = 1	current_phase = 0	next_phase = 1	reward = -1.595998	array([[-1.9001139, -1.7324454]], dtype=float32)

time = 1218	action = 0	current_phase = 1	next_phase = 0	reward = -0.161857	array([[-0.44364816, -1.7589055 ]], dtype=float32)

time = 1223	action = 0	current_phase = 1	next_phase = 0	reward = 0.073818	array([[-0.45246148, -2.4636855 ]], dtype=float32)

time = 1228	action = 0	current_phase = 1	next_phase = 0	reward = -1.461810	array([[-1.4585361, -2.5667763]], dtype=float32)

time = 1233	action = 1	current_phase = 1	next_phase = 0	reward = -1.987881	array([[-2.4661715, -2.3691657]], dtype=float32)

time = 1241	action = 0	current_phase = 0	next_phase = 1	reward = -0.359438	array([[-0.75937426, -1.6001426 ]], dtype=float32)

time = 1246	action = 0	current_phase = 0	next_phase = 1	reward = -0.205557	array([[-0.5726715, -1.2133917]], dtype=float32)

time = 1251	action = 0	current_phase = 0	next_phase = 1	reward = 0.298555	array([[-0.38579887, -2.3863747 ]], dtype=float32)

time = 1256	action = 1	current_phase = 0	next_phase = 1	reward = -1.610244	array([[-2.116413 , -2.0082777]], dtype=float32)

time = 1264	action = 0	current_phase = 1	next_phase = 0	reward = -0.551622	array([[-0.951895 , -1.7341708]], dtype=float32)

time = 1269	action = 0	current_phase = 1	next_phase = 0	reward = -0.397311	array([[-0.91453785, -1.7112436 ]], dtype=float32)

time = 1274	action = 0	current_phase = 1	next_phase = 0	reward = -0.245282	array([[-0.46684837, -1.8228048 ]], dtype=float32)

time = 1279	action = 0	current_phase = 1	next_phase = 0	reward = -0.184267	array([[-0.4142083, -1.8324504]], dtype=float32)

time = 1284	action = 0	current_phase = 1	next_phase = 0	reward = -0.041816	array([[-1.074783 , -1.9503521]], dtype=float32)

time = 1289	action = 0	current_phase = 1	next_phase = 0	reward = -1.594322	array([[-1.4950516, -2.3372746]], dtype=float32)

time = 1294	action = 1	current_phase = 1	next_phase = 0	reward = -1.912723	array([[-2.6346028, -1.9804252]], dtype=float32)

time = 1302	action = 0	current_phase = 0	next_phase = 1	reward = -0.320083	array([[-0.5723295, -1.4816363]], dtype=float32)

time = 1307	action = 0	current_phase = 0	next_phase = 1	reward = -0.182079	array([[-0.67726195, -1.3723624 ]], dtype=float32)

time = 1312	action = 0	current_phase = 0	next_phase = 1	reward = 0.196144	array([[-0.5059463, -2.359549 ]], dtype=float32)

time = 1317	action = 0	current_phase = 0	next_phase = 1	reward = -1.320658	array([[-2.0901103, -2.472929 ]], dtype=float32)

time = 1322	action = 0	current_phase = 0	next_phase = 1	reward = -1.698559	array([[-0.86549723, -2.3408728 ]], dtype=float32)

time = 1327	action = 0	current_phase = 0	next_phase = 1	reward = -1.591394	array([[-1.648336 , -1.8090034]], dtype=float32)

time = 1332	action = 1	current_phase = 0	next_phase = 1	reward = -1.519200	array([[-1.7039446, -1.6376635]], dtype=float32)

time = 1340	action = 0	current_phase = 1	next_phase = 0	reward = 0.378848	array([[-0.39515454, -2.0603004 ]], dtype=float32)

time = 1345	action = 0	current_phase = 1	next_phase = 0	reward = -0.776361	array([[-0.96746534, -1.7279043 ]], dtype=float32)

time = 1350	action = 0	current_phase = 1	next_phase = 0	reward = -1.727319	array([[-1.9883776, -2.4353335]], dtype=float32)

time = 1355	action = 0	current_phase = 1	next_phase = 0	reward = -1.613552	array([[-0.83707595, -2.228825  ]], dtype=float32)

time = 1360	action = 1	current_phase = 1	next_phase = 0	reward = -1.604043	array([[-2.202416 , -1.7689267]], dtype=float32)

time = 1368	action = 0	current_phase = 0	next_phase = 1	reward = -0.169977	array([[-0.5530299, -1.714356 ]], dtype=float32)

time = 1373	action = 0	current_phase = 0	next_phase = 1	reward = 0.071393	array([[-0.60002387, -1.8682492 ]], dtype=float32)

time = 1378	action = 0	current_phase = 0	next_phase = 1	reward = -1.462679	array([[-1.6523329, -2.6663654]], dtype=float32)

time = 1383	action = 0	current_phase = 0	next_phase = 1	reward = -1.664202	array([[-2.2297878, -2.3901143]], dtype=float32)

time = 1388	action = 1	current_phase = 0	next_phase = 1	reward = -1.701048	array([[-2.054415 , -1.7604041]], dtype=float32)

time = 1396	action = 0	current_phase = 1	next_phase = 0	reward = -0.190960	array([[-0.46743003, -1.7764872 ]], dtype=float32)

time = 1401	action = 0	current_phase = 1	next_phase = 0	reward = 0.318218	array([[-0.39594504, -2.5227244 ]], dtype=float32)

time = 1406	action = 0	current_phase = 1	next_phase = 0	reward = -1.063364	array([[-1.9045864, -2.3034935]], dtype=float32)

time = 1411	action = 0	current_phase = 1	next_phase = 0	reward = -1.710194	array([[-2.211569 , -2.4162023]], dtype=float32)

time = 1416	action = 0	current_phase = 1	next_phase = 0	reward = -1.602268	array([[-1.5880159, -2.1208057]], dtype=float32)

time = 1421	action = 1	current_phase = 1	next_phase = 0	reward = -1.564892	array([[-2.339464 , -1.8007892]], dtype=float32)

time = 1429	action = 0	current_phase = 0	next_phase = 1	reward = -0.181778	array([[-0.36292854, -2.0869484 ]], dtype=float32)

time = 1434	action = 0	current_phase = 0	next_phase = 1	reward = -0.154135	array([[-0.33348486, -1.4706674 ]], dtype=float32)

time = 1439	action = 0	current_phase = 0	next_phase = 1	reward = -1.601052	array([[-2.1881354, -2.5839438]], dtype=float32)

time = 1444	action = 0	current_phase = 0	next_phase = 1	reward = -1.641776	array([[-1.9378659, -2.0916934]], dtype=float32)

time = 1449	action = 1	current_phase = 0	next_phase = 1	reward = -1.635607	array([[-2.0345485, -1.6399597]], dtype=float32)

time = 1457	action = 0	current_phase = 1	next_phase = 0	reward = -0.165404	array([[-0.58285165, -1.7068247 ]], dtype=float32)

time = 1462	action = 0	current_phase = 1	next_phase = 0	reward = 0.163636	array([[-0.39257336, -2.4069188 ]], dtype=float32)

time = 1467	action = 0	current_phase = 1	next_phase = 0	reward = -1.320135	array([[-1.0015564, -2.5924704]], dtype=float32)

time = 1472	action = 0	current_phase = 1	next_phase = 0	reward = -1.688575	array([[-1.8407351, -2.4883099]], dtype=float32)

time = 1477	action = 1	current_phase = 1	next_phase = 0	reward = -1.742352	array([[-2.2695432, -2.003293 ]], dtype=float32)

time = 1485	action = 0	current_phase = 0	next_phase = 1	reward = -0.217194	array([[-0.6948776, -1.4243078]], dtype=float32)

time = 1490	action = 0	current_phase = 0	next_phase = 1	reward = 0.363309	array([[-0.34853327, -1.790952  ]], dtype=float32)

time = 1495	action = 0	current_phase = 0	next_phase = 1	reward = -0.842261	array([[-1.4024608, -2.1418538]], dtype=float32)

time = 1500	action = 0	current_phase = 0	next_phase = 1	reward = -1.728797	array([[-2.3796954, -2.5029323]], dtype=float32)

time = 1505	action = 0	current_phase = 0	next_phase = 1	reward = -1.615989	array([[-1.983963 , -2.2236369]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0476 - val_loss: 0.0282

Epoch 2/50

 - 4s - loss: 0.0477 - val_loss: 0.0284

Epoch 3/50

 - 4s - loss: 0.0458 - val_loss: 0.0288

Epoch 4/50

 - 4s - loss: 0.0398 - val_loss: 0.0317

Epoch 5/50

 - 4s - loss: 0.0387 - val_loss: 0.0338

Epoch 6/50

 - 4s - loss: 0.0391 - val_loss: 0.0323

Epoch 7/50

 - 4s - loss: 0.0372 - val_loss: 0.0310

Epoch 8/50

 - 4s - loss: 0.0385 - val_loss: 0.0335

Epoch 9/50

 - 4s - loss: 0.0398 - val_loss: 0.0343

Epoch 10/50

 - 4s - loss: 0.0361 - val_loss: 0.0330

Epoch 11/50

 - 4s - loss: 0.0348 - val_loss: 0.0327

length of memory (state 0, action 0): 633, after forget

length of memory (state 0, action 1): 323, after forget

length of memory (state 1, action 0): 598, after forget

length of memory (state 1, action 1): 311, after forget

time = 1510	action = 1	current_phase = 0	next_phase = 1	reward = -1.599441	array([[-2.0432243, -1.7436719]], dtype=float32)

time = 1518	action = 0	current_phase = 1	next_phase = 0	reward = -0.158409	array([[-0.2638023, -1.8686144]], dtype=float32)

time = 1523	action = 0	current_phase = 1	next_phase = 0	reward = 0.023753	array([[-1.055558, -2.087637]], dtype=float32)

time = 1528	action = 1	current_phase = 1	next_phase = 0	reward = -1.903596	array([[-2.7836335, -2.0542946]], dtype=float32)

time = 1536	action = 0	current_phase = 0	next_phase = 1	reward = -0.502698	array([[-0.73619676, -1.6245959 ]], dtype=float32)

time = 1541	action = 0	current_phase = 0	next_phase = 1	reward = -0.353014	array([[-0.891798 , -1.4215112]], dtype=float32)

time = 1546	action = 0	current_phase = 0	next_phase = 1	reward = -0.205373	array([[-0.6474426, -1.5359507]], dtype=float32)

time = 1551	action = 0	current_phase = 0	next_phase = 1	reward = 0.280544	array([[-0.33711374, -1.8306139 ]], dtype=float32)

time = 1556	action = 1	current_phase = 0	next_phase = 1	reward = -1.663326	array([[-2.0989115, -1.8880296]], dtype=float32)

time = 1564	action = 0	current_phase = 1	next_phase = 0	reward = -0.549247	array([[-0.95172334, -1.7071764 ]], dtype=float32)

time = 1569	action = 0	current_phase = 1	next_phase = 0	reward = -0.394318	array([[-0.37038964, -1.6582125 ]], dtype=float32)

time = 1574	action = 0	current_phase = 1	next_phase = 0	reward = -0.233788	array([[-0.69722915, -1.6486613 ]], dtype=float32)

time = 1579	action = 0	current_phase = 1	next_phase = 0	reward = 0.106314	array([[-0.40559417, -1.738296  ]], dtype=float32)

time = 1584	action = 0	current_phase = 1	next_phase = 0	reward = -0.368921	array([[-0.6449727, -2.3499734]], dtype=float32)

time = 1589	action = 0	current_phase = 1	next_phase = 0	reward = -1.598405	array([[-2.1978993, -2.2958367]], dtype=float32)

time = 1594	action = 1	current_phase = 1	next_phase = 0	reward = -1.903791	array([[-2.3551402, -1.9067341]], dtype=float32)

time = 1602	action = 0	current_phase = 0	next_phase = 1	reward = -0.311197	array([[-0.68399966, -1.52985   ]], dtype=float32)

time = 1607	action = 0	current_phase = 0	next_phase = 1	reward = -0.171941	array([[-0.6902821, -1.4563901]], dtype=float32)

time = 1612	action = 0	current_phase = 0	next_phase = 1	reward = 0.201109	array([[-0.5795816, -2.5988357]], dtype=float32)

time = 1617	action = 0	current_phase = 0	next_phase = 1	reward = -1.319190	array([[-1.9412799, -2.524902 ]], dtype=float32)

time = 1622	action = 0	current_phase = 0	next_phase = 1	reward = -1.690958	array([[-1.8984977, -2.2917514]], dtype=float32)

time = 1627	action = 1	current_phase = 0	next_phase = 1	reward = -1.766699	array([[-2.0659926, -1.7005196]], dtype=float32)

time = 1635	action = 0	current_phase = 1	next_phase = 0	reward = -0.231229	array([[-0.6274854, -1.6486063]], dtype=float32)

time = 1640	action = 0	current_phase = 1	next_phase = 0	reward = 0.374924	array([[-0.44477743, -2.0270839 ]], dtype=float32)

time = 1645	action = 0	current_phase = 1	next_phase = 0	reward = -0.775324	array([[-0.87928355, -2.1299093 ]], dtype=float32)

time = 1650	action = 1	current_phase = 1	next_phase = 0	reward = -2.117629	array([[-2.4828494, -2.1906843]], dtype=float32)

time = 1658	action = 0	current_phase = 0	next_phase = 1	reward = -0.441441	array([[-0.88063663, -1.4765851 ]], dtype=float32)

time = 1663	action = 0	current_phase = 0	next_phase = 1	reward = -0.291730	array([[-0.65668666, -1.1402605 ]], dtype=float32)

time = 1668	action = 0	current_phase = 0	next_phase = 1	reward = -0.166114	array([[-0.6094662, -1.6207218]], dtype=float32)

time = 1673	action = 0	current_phase = 0	next_phase = 1	reward = 0.145759	array([[-0.71552247, -2.125643  ]], dtype=float32)

time = 1678	action = 0	current_phase = 0	next_phase = 1	reward = -1.456511	array([[-1.7239213, -2.3026376]], dtype=float32)

time = 1683	action = 1	current_phase = 0	next_phase = 1	reward = -1.960268	array([[-2.5949643, -1.9558122]], dtype=float32)

time = 1691	action = 0	current_phase = 1	next_phase = 0	reward = -0.343947	array([[-0.6265093, -1.7193329]], dtype=float32)

time = 1696	action = 0	current_phase = 1	next_phase = 0	reward = -0.187612	array([[-0.4550464, -1.7756815]], dtype=float32)

time = 1701	action = 0	current_phase = 1	next_phase = 0	reward = 0.289311	array([[-0.6019101, -1.9959759]], dtype=float32)

time = 1706	action = 0	current_phase = 1	next_phase = 0	reward = -1.010049	array([[-1.5092841, -2.5046496]], dtype=float32)

time = 1711	action = 0	current_phase = 1	next_phase = 0	reward = -1.698707	array([[-1.4644784, -2.507124 ]], dtype=float32)

time = 1716	action = 0	current_phase = 1	next_phase = 0	reward = -1.580930	array([[-1.6469262, -2.0441515]], dtype=float32)

time = 1721	action = 1	current_phase = 1	next_phase = 0	reward = -1.524913	array([[-2.171312, -1.761318]], dtype=float32)

time = 1729	action = 0	current_phase = 0	next_phase = 1	reward = -0.194520	array([[-0.47909456, -1.9728127 ]], dtype=float32)

time = 1734	action = 0	current_phase = 0	next_phase = 1	reward = -0.210684	array([[-0.7203177, -1.4283903]], dtype=float32)

time = 1739	action = 1	current_phase = 0	next_phase = 1	reward = -2.009695	array([[-2.59242  , -2.3015075]], dtype=float32)

time = 1747	action = 0	current_phase = 1	next_phase = 0	reward = -0.466182	array([[-0.6169855, -1.7050405]], dtype=float32)

time = 1752	action = 0	current_phase = 1	next_phase = 0	reward = -0.300714	array([[-0.5644047, -1.6423069]], dtype=float32)

time = 1757	action = 0	current_phase = 1	next_phase = 0	reward = -0.168143	array([[-0.6501234, -1.6805892]], dtype=float32)

time = 1762	action = 0	current_phase = 1	next_phase = 0	reward = 0.241724	array([[-0.5597322, -2.570813 ]], dtype=float32)

time = 1767	action = 0	current_phase = 1	next_phase = 0	reward = -1.315537	array([[-1.6517427, -2.4048982]], dtype=float32)

time = 1772	action = 1	current_phase = 1	next_phase = 0	reward = -2.016069	array([[-2.425012 , -2.1054509]], dtype=float32)

time = 1780	action = 0	current_phase = 0	next_phase = 1	reward = -0.377575	array([[-0.83455026, -1.7093275 ]], dtype=float32)

time = 1785	action = 0	current_phase = 0	next_phase = 1	reward = -0.219907	array([[-0.6577496, -1.3236513]], dtype=float32)

time = 1790	action = 0	current_phase = 0	next_phase = 1	reward = 0.062465	array([[-0.37863868, -1.8538873 ]], dtype=float32)

time = 1795	action = 0	current_phase = 0	next_phase = 1	reward = -0.562362	array([[-1.3315321, -2.0249043]], dtype=float32)

time = 1800	action = 0	current_phase = 0	next_phase = 1	reward = -1.730026	array([[-1.7759334, -2.3666933]], dtype=float32)

time = 1805	action = 1	current_phase = 0	next_phase = 1	reward = -1.842824	array([[-2.231768 , -1.7481472]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1092 - val_loss: 0.0684

Epoch 2/50

 - 4s - loss: 0.0962 - val_loss: 0.0660

Epoch 3/50

 - 4s - loss: 0.0944 - val_loss: 0.0614

Epoch 4/50

 - 4s - loss: 0.0841 - val_loss: 0.0600

Epoch 5/50

 - 4s - loss: 0.0925 - val_loss: 0.0595

Epoch 6/50

 - 4s - loss: 0.0823 - val_loss: 0.0588

Epoch 7/50

 - 4s - loss: 0.0751 - val_loss: 0.0617

Epoch 8/50

 - 4s - loss: 0.0721 - val_loss: 0.0623

Epoch 9/50

 - 4s - loss: 0.0693 - val_loss: 0.0617

Epoch 10/50

 - 4s - loss: 0.0772 - val_loss: 0.0605

Epoch 11/50

 - 4s - loss: 0.0705 - val_loss: 0.0610

Epoch 12/50

 - 4s - loss: 0.0638 - val_loss: 0.0622

Epoch 13/50

 - 4s - loss: 0.0688 - val_loss: 0.0615

Epoch 14/50

 - 4s - loss: 0.0588 - val_loss: 0.0627

Epoch 15/50

 - 4s - loss: 0.0720 - val_loss: 0.0622

Epoch 16/50

 - 4s - loss: 0.0656 - val_loss: 0.0617

length of memory (state 0, action 0): 654, after forget

length of memory (state 0, action 1): 329, after forget

length of memory (state 1, action 0): 620, after forget

length of memory (state 1, action 1): 316, after forget

time = 1813	action = 0	current_phase = 1	next_phase = 0	reward = -0.268562	array([[-0.7666197, -1.734599 ]], dtype=float32)

time = 1818	action = 0	current_phase = 1	next_phase = 0	reward = -0.164580	array([[-0.6340009, -1.8453248]], dtype=float32)

time = 1823	action = 0	current_phase = 1	next_phase = 0	reward = -0.002005	array([[-0.6725882, -3.0079138]], dtype=float32)

time = 1828	action = 1	current_phase = 1	next_phase = 0	reward = -1.898736	array([[-2.845073 , -2.5056026]], dtype=float32)

time = 1836	action = 0	current_phase = 0	next_phase = 1	reward = -0.488980	array([[-0.89158016, -1.6105918 ]], dtype=float32)

time = 1841	action = 0	current_phase = 0	next_phase = 1	reward = -0.338339	array([[-0.7218839, -1.8944942]], dtype=float32)

time = 1846	action = 0	current_phase = 0	next_phase = 1	reward = -0.194088	array([[-0.5952991, -1.7151581]], dtype=float32)

time = 1851	action = 0	current_phase = 0	next_phase = 1	reward = 0.272298	array([[-0.7552948, -2.3598366]], dtype=float32)

time = 1856	action = 1	current_phase = 0	next_phase = 1	reward = -1.562126	array([[-2.833393 , -2.1321802]], dtype=float32)

time = 1864	action = 0	current_phase = 1	next_phase = 0	reward = -0.564654	array([[-1.0392501, -1.8182957]], dtype=float32)

time = 1869	action = 0	current_phase = 1	next_phase = 0	reward = -0.407428	array([[-0.6107819, -1.7507534]], dtype=float32)

time = 1874	action = 0	current_phase = 1	next_phase = 0	reward = -0.243976	array([[-0.76222813, -1.7964958 ]], dtype=float32)

time = 1879	action = 0	current_phase = 1	next_phase = 0	reward = -0.170628	array([[-0.8421803, -2.3319361]], dtype=float32)

time = 1884	action = 0	current_phase = 1	next_phase = 0	reward = -0.074033	array([[-1.8014736, -2.1628182]], dtype=float32)

time = 1889	action = 1	current_phase = 1	next_phase = 0	reward = -2.012954	array([[-2.5409799, -2.3762634]], dtype=float32)

time = 1897	action = 0	current_phase = 0	next_phase = 1	reward = -0.470003	array([[-0.8878086, -1.6008612]], dtype=float32)

time = 1902	action = 0	current_phase = 0	next_phase = 1	reward = -0.321362	array([[-0.5397216, -1.5941854]], dtype=float32)

time = 1907	action = 0	current_phase = 0	next_phase = 1	reward = -0.186677	array([[-0.6447164, -1.5848787]], dtype=float32)

time = 1912	action = 0	current_phase = 0	next_phase = 1	reward = 0.251612	array([[-0.5249219, -2.63301  ]], dtype=float32)

time = 1917	action = 1	current_phase = 0	next_phase = 1	reward = -1.780132	array([[-2.737983 , -2.1971488]], dtype=float32)

time = 1925	action = 0	current_phase = 1	next_phase = 0	reward = -0.521123	array([[-1.1773305, -1.7337425]], dtype=float32)

time = 1930	action = 0	current_phase = 1	next_phase = 0	reward = -0.370035	array([[-0.60464156, -1.7852035 ]], dtype=float32)

time = 1935	action = 0	current_phase = 1	next_phase = 0	reward = -0.222210	array([[-0.6675121, -1.7847667]], dtype=float32)

time = 1940	action = 0	current_phase = 1	next_phase = 0	reward = 0.364865	array([[-0.59450054, -2.080961  ]], dtype=float32)

time = 1945	action = 1	current_phase = 1	next_phase = 0	reward = -1.307889	array([[-2.2307384, -2.1452816]], dtype=float32)

time = 1953	action = 0	current_phase = 0	next_phase = 1	reward = -0.587423	array([[-0.7937784, -1.7275741]], dtype=float32)

time = 1958	action = 0	current_phase = 0	next_phase = 1	reward = -0.428086	array([[-0.6469333, -1.7470201]], dtype=float32)

time = 1963	action = 0	current_phase = 0	next_phase = 1	reward = -0.272207	array([[-0.63783467, -1.3930056 ]], dtype=float32)

time = 1968	action = 0	current_phase = 0	next_phase = 1	reward = -0.170579	array([[-0.6079218, -1.8217851]], dtype=float32)

time = 1973	action = 0	current_phase = 0	next_phase = 1	reward = 0.039578	array([[-1.0166588, -1.8711869]], dtype=float32)

time = 1978	action = 1	current_phase = 0	next_phase = 1	reward = -1.893544	array([[-2.7240098, -2.5128891]], dtype=float32)

time = 1986	action = 0	current_phase = 1	next_phase = 0	reward = -0.499101	array([[-0.95521504, -1.7095972 ]], dtype=float32)

time = 1991	action = 0	current_phase = 1	next_phase = 0	reward = -0.341947	array([[-0.4954698, -1.7494618]], dtype=float32)

time = 1996	action = 0	current_phase = 1	next_phase = 0	reward = -0.197522	array([[-0.58653104, -1.9455783 ]], dtype=float32)

time = 2001	action = 0	current_phase = 1	next_phase = 0	reward = 0.295398	array([[-0.72923434, -2.3249784 ]], dtype=float32)

time = 2006	action = 1	current_phase = 1	next_phase = 0	reward = -1.609980	array([[-2.709612 , -2.1856813]], dtype=float32)

time = 2014	action = 0	current_phase = 0	next_phase = 1	reward = -0.552861	array([[-0.86408556, -1.8256007 ]], dtype=float32)

time = 2019	action = 0	current_phase = 0	next_phase = 1	reward = -0.394682	array([[-0.7458104, -1.6890504]], dtype=float32)

time = 2024	action = 0	current_phase = 0	next_phase = 1	reward = -0.237831	array([[-0.6609595, -1.6932929]], dtype=float32)

time = 2029	action = 0	current_phase = 0	next_phase = 1	reward = -0.185060	array([[-0.68686306, -2.0947118 ]], dtype=float32)

time = 2034	action = 0	current_phase = 0	next_phase = 1	reward = -0.102289	array([[-0.6658622, -2.2332547]], dtype=float32)

time = 2039	action = 1	current_phase = 0	next_phase = 1	reward = -2.002565	array([[-2.779078 , -2.4897919]], dtype=float32)

time = 2047	action = 0	current_phase = 1	next_phase = 0	reward = -0.461241	array([[-0.7815207, -1.68176  ]], dtype=float32)

time = 2052	action = 0	current_phase = 1	next_phase = 0	reward = -0.309725	array([[-0.59578836, -1.7532651 ]], dtype=float32)

time = 2057	action = 0	current_phase = 1	next_phase = 0	reward = -0.177687	array([[-0.51098675, -1.9999197 ]], dtype=float32)

time = 2062	action = 0	current_phase = 1	next_phase = 0	reward = 0.259656	array([[-0.86407715, -2.6128986 ]], dtype=float32)

time = 2067	action = 0	current_phase = 1	next_phase = 0	reward = -1.315780	array([[-1.3104773, -2.7731423]], dtype=float32)

time = 2072	action = 1	current_phase = 1	next_phase = 0	reward = -2.014872	array([[-2.9783008, -2.415292 ]], dtype=float32)

time = 2080	action = 0	current_phase = 0	next_phase = 1	reward = -0.377329	array([[-0.85472846, -1.5900313 ]], dtype=float32)

time = 2085	action = 0	current_phase = 0	next_phase = 1	reward = -0.224332	array([[-0.627864 , -1.6492479]], dtype=float32)

time = 2090	action = 0	current_phase = 0	next_phase = 1	reward = 0.064957	array([[-0.6409515, -2.57816  ]], dtype=float32)

time = 2095	action = 0	current_phase = 0	next_phase = 1	reward = -0.502681	array([[-1.8083088, -2.0931857]], dtype=float32)

time = 2100	action = 1	current_phase = 0	next_phase = 1	reward = -2.113380	array([[-2.7123482, -2.5177946]], dtype=float32)

time = 2108	action = 0	current_phase = 1	next_phase = 0	reward = -0.443302	array([[-1.0206921, -1.7264781]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0724 - val_loss: 0.0400

Epoch 2/50

 - 4s - loss: 0.0623 - val_loss: 0.0409

Epoch 3/50

 - 4s - loss: 0.0639 - val_loss: 0.0430

Epoch 4/50

 - 4s - loss: 0.0578 - val_loss: 0.0427

Epoch 5/50

 - 4s - loss: 0.0587 - val_loss: 0.0412

Epoch 6/50

 - 4s - loss: 0.0584 - val_loss: 0.0415

Epoch 7/50

 - 4s - loss: 0.0523 - val_loss: 0.0440

Epoch 8/50

 - 4s - loss: 0.0555 - val_loss: 0.0438

Epoch 9/50

 - 4s - loss: 0.0521 - val_loss: 0.0456

Epoch 10/50

 - 4s - loss: 0.0522 - val_loss: 0.0463

Epoch 11/50

 - 4s - loss: 0.0509 - val_loss: 0.0466

length of memory (state 0, action 0): 676, after forget

length of memory (state 0, action 1): 334, after forget

length of memory (state 1, action 0): 642, after forget

length of memory (state 1, action 1): 321, after forget

time = 2113	action = 0	current_phase = 1	next_phase = 0	reward = -0.288718	array([[-0.52723384, -1.7222137 ]], dtype=float32)

time = 2118	action = 0	current_phase = 1	next_phase = 0	reward = -0.162882	array([[-0.5655127, -1.9500502]], dtype=float32)

time = 2123	action = 0	current_phase = 1	next_phase = 0	reward = 0.089140	array([[-1.389825 , -2.8955646]], dtype=float32)

time = 2128	action = 1	current_phase = 1	next_phase = 0	reward = -1.895991	array([[-2.8865976, -2.503    ]], dtype=float32)

time = 2136	action = 0	current_phase = 0	next_phase = 1	reward = -0.493242	array([[-0.9985356, -1.4156368]], dtype=float32)

time = 2141	action = 0	current_phase = 0	next_phase = 1	reward = -0.338514	array([[-0.77127784, -1.6728456 ]], dtype=float32)

time = 2146	action = 0	current_phase = 0	next_phase = 1	reward = -0.196167	array([[-0.739917 , -2.0175426]], dtype=float32)

time = 2151	action = 0	current_phase = 0	next_phase = 1	reward = 0.289006	array([[-0.725828 , -2.4529681]], dtype=float32)

time = 2156	action = 1	current_phase = 0	next_phase = 1	reward = -1.604348	array([[-2.6651447, -2.4130044]], dtype=float32)

time = 2164	action = 0	current_phase = 1	next_phase = 0	reward = -0.546503	array([[-0.90559715, -1.8691559 ]], dtype=float32)

time = 2169	action = 0	current_phase = 1	next_phase = 0	reward = -0.394809	array([[-0.543478 , -1.8022935]], dtype=float32)

time = 2174	action = 0	current_phase = 1	next_phase = 0	reward = -0.234375	array([[-0.7780594, -1.8377708]], dtype=float32)

time = 2179	action = 0	current_phase = 1	next_phase = 0	reward = 0.102682	array([[-0.6846662, -2.2203002]], dtype=float32)

time = 2184	action = 0	current_phase = 1	next_phase = 0	reward = -0.426717	array([[-1.2944771, -2.3155458]], dtype=float32)

time = 2189	action = 1	current_phase = 1	next_phase = 0	reward = -2.012134	array([[-2.3538737, -2.3515773]], dtype=float32)

time = 2197	action = 0	current_phase = 0	next_phase = 1	reward = -0.468034	array([[-0.93661976, -1.5448475 ]], dtype=float32)

time = 2202	action = 0	current_phase = 0	next_phase = 1	reward = -0.319679	array([[-0.7155257, -1.3950912]], dtype=float32)

time = 2207	action = 0	current_phase = 0	next_phase = 1	reward = -0.182512	array([[-0.7192716, -1.9802806]], dtype=float32)

time = 2212	action = 0	current_phase = 0	next_phase = 1	reward = 0.202114	array([[-1.0447425, -2.29748  ]], dtype=float32)

time = 2217	action = 1	current_phase = 0	next_phase = 1	reward = -1.782458	array([[-2.505673 , -2.4827437]], dtype=float32)

time = 2225	action = 0	current_phase = 1	next_phase = 0	reward = -0.523907	array([[-1.0754306, -1.8019075]], dtype=float32)

time = 2230	action = 0	current_phase = 1	next_phase = 0	reward = -0.371715	array([[-0.50671333, -1.8018893 ]], dtype=float32)

time = 2235	action = 0	current_phase = 1	next_phase = 0	reward = -0.217344	array([[-0.7100127, -1.8471528]], dtype=float32)

time = 2240	action = 0	current_phase = 1	next_phase = 0	reward = 0.357944	array([[-0.8923055, -2.4092727]], dtype=float32)

time = 2245	action = 1	current_phase = 1	next_phase = 0	reward = -1.364670	array([[-2.5161552, -2.2408288]], dtype=float32)

time = 2253	action = 0	current_phase = 0	next_phase = 1	reward = -0.585692	array([[-1.0882744, -1.4744046]], dtype=float32)

time = 2258	action = 0	current_phase = 0	next_phase = 1	reward = -0.427958	array([[-0.78478354, -1.7018156 ]], dtype=float32)

time = 2263	action = 0	current_phase = 0	next_phase = 1	reward = -0.269634	array([[-0.64801425, -1.4916604 ]], dtype=float32)

time = 2268	action = 0	current_phase = 0	next_phase = 1	reward = -0.163375	array([[-0.57324237, -2.065998  ]], dtype=float32)

time = 2273	action = 0	current_phase = 0	next_phase = 1	reward = -0.057767	array([[-1.793826 , -2.2586305]], dtype=float32)

time = 2278	action = 1	current_phase = 0	next_phase = 1	reward = -1.913883	array([[-2.8928258, -2.45527  ]], dtype=float32)

time = 2286	action = 0	current_phase = 1	next_phase = 0	reward = -0.512732	array([[-0.79003537, -1.9416091 ]], dtype=float32)

time = 2291	action = 0	current_phase = 1	next_phase = 0	reward = -0.358790	array([[-0.4495144, -1.7947633]], dtype=float32)

time = 2296	action = 0	current_phase = 1	next_phase = 0	reward = -0.204873	array([[-0.6875683, -1.8326807]], dtype=float32)

time = 2301	action = 0	current_phase = 1	next_phase = 0	reward = 0.324940	array([[-0.55062115, -2.914664  ]], dtype=float32)

time = 2306	action = 1	current_phase = 1	next_phase = 0	reward = -1.554302	array([[-2.9150262, -2.379779 ]], dtype=float32)

time = 2314	action = 0	current_phase = 0	next_phase = 1	reward = -0.543819	array([[-0.9965838, -1.5887991]], dtype=float32)

time = 2319	action = 0	current_phase = 0	next_phase = 1	reward = -0.391312	array([[-0.76426935, -1.6843331 ]], dtype=float32)

time = 2324	action = 0	current_phase = 0	next_phase = 1	reward = -0.238601	array([[-0.64995277, -1.4853315 ]], dtype=float32)

time = 2329	action = 0	current_phase = 0	next_phase = 1	reward = -0.186646	array([[-0.6530964, -2.148628 ]], dtype=float32)

time = 2334	action = 0	current_phase = 0	next_phase = 1	reward = -0.202970	array([[-1.1323663, -1.8181763]], dtype=float32)

time = 2339	action = 1	current_phase = 0	next_phase = 1	reward = -2.021831	array([[-2.9196708, -2.7422307]], dtype=float32)

time = 2347	action = 0	current_phase = 1	next_phase = 0	reward = -0.470496	array([[-0.73867935, -1.7765076 ]], dtype=float32)

time = 2352	action = 0	current_phase = 1	next_phase = 0	reward = -0.324865	array([[-0.35495687, -1.7663517 ]], dtype=float32)

time = 2357	action = 0	current_phase = 1	next_phase = 0	reward = -0.186316	array([[-0.7604511, -1.7584319]], dtype=float32)

time = 2362	action = 0	current_phase = 1	next_phase = 0	reward = 0.255940	array([[-0.861584, -2.576326]], dtype=float32)

time = 2367	action = 0	current_phase = 1	next_phase = 0	reward = -1.315648	array([[-2.5213833, -2.5749874]], dtype=float32)

time = 2372	action = 1	current_phase = 1	next_phase = 0	reward = -2.011821	array([[-3.0713634, -2.365235 ]], dtype=float32)

time = 2380	action = 0	current_phase = 0	next_phase = 1	reward = -0.375315	array([[-0.8168704, -1.5706259]], dtype=float32)

time = 2385	action = 0	current_phase = 0	next_phase = 1	reward = -0.229980	array([[-0.59159756, -1.6752992 ]], dtype=float32)

time = 2390	action = 0	current_phase = 0	next_phase = 1	reward = 0.363564	array([[-0.47910658, -2.1981246 ]], dtype=float32)

time = 2395	action = 1	current_phase = 0	next_phase = 1	reward = -1.364905	array([[-2.373746 , -2.1391585]], dtype=float32)

time = 2403	action = 0	current_phase = 1	next_phase = 0	reward = -0.595246	array([[-0.9544547, -1.887186 ]], dtype=float32)

time = 2408	action = 0	current_phase = 1	next_phase = 0	reward = -0.447624	array([[-0.87960327, -1.8609711 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0544 - val_loss: 0.0379

Epoch 2/50

 - 4s - loss: 0.0545 - val_loss: 0.0391

Epoch 3/50

 - 4s - loss: 0.0515 - val_loss: 0.0382

Epoch 4/50

 - 4s - loss: 0.0464 - val_loss: 0.0380

Epoch 5/50

 - 4s - loss: 0.0462 - val_loss: 0.0423

Epoch 6/50

 - 4s - loss: 0.0531 - val_loss: 0.0417

Epoch 7/50

 - 4s - loss: 0.0460 - val_loss: 0.0408

Epoch 8/50

 - 4s - loss: 0.0455 - val_loss: 0.0483

Epoch 9/50

 - 4s - loss: 0.0461 - val_loss: 0.0424

Epoch 10/50

 - 4s - loss: 0.0402 - val_loss: 0.0418

Epoch 11/50

 - 4s - loss: 0.0447 - val_loss: 0.0422

length of memory (state 0, action 0): 697, after forget

length of memory (state 0, action 1): 339, after forget

length of memory (state 1, action 0): 665, after forget

length of memory (state 1, action 1): 326, after forget

time = 2413	action = 0	current_phase = 1	next_phase = 0	reward = -0.298077	array([[-0.80152965, -1.8143448 ]], dtype=float32)

time = 2418	action = 0	current_phase = 1	next_phase = 0	reward = -0.166123	array([[-0.7922145, -1.9246916]], dtype=float32)

time = 2423	action = 0	current_phase = 1	next_phase = 0	reward = 0.157750	array([[-0.74283814, -2.610006  ]], dtype=float32)

time = 2428	action = 1	current_phase = 1	next_phase = 0	reward = -1.907389	array([[-3.0681493, -2.4005766]], dtype=float32)

time = 2436	action = 0	current_phase = 0	next_phase = 1	reward = -0.521444	array([[-1.1702106, -1.499409 ]], dtype=float32)

time = 2441	action = 0	current_phase = 0	next_phase = 1	reward = -0.377167	array([[-0.67424035, -1.6918631 ]], dtype=float32)

time = 2446	action = 0	current_phase = 0	next_phase = 1	reward = -0.225997	array([[-0.7230901, -1.6836205]], dtype=float32)

time = 2451	action = 0	current_phase = 0	next_phase = 1	reward = 0.334288	array([[-0.7367677, -2.0915768]], dtype=float32)

time = 2456	action = 1	current_phase = 0	next_phase = 1	reward = -1.497617	array([[-2.3502035, -2.1581883]], dtype=float32)

time = 2464	action = 0	current_phase = 1	next_phase = 0	reward = -0.563795	array([[-1.0850086, -1.8168342]], dtype=float32)

time = 2469	action = 0	current_phase = 1	next_phase = 0	reward = -0.411946	array([[-0.591235 , -1.7579353]], dtype=float32)

time = 2474	action = 0	current_phase = 1	next_phase = 0	reward = -0.255020	array([[-0.42995426, -1.917611  ]], dtype=float32)

time = 2479	action = 0	current_phase = 1	next_phase = 0	reward = -0.171272	array([[-0.57826823, -2.1346822 ]], dtype=float32)

time = 2484	action = 1	current_phase = 1	next_phase = 0	reward = -0.420610	array([[-2.2032466, -2.0378208]], dtype=float32)

time = 2492	action = 0	current_phase = 0	next_phase = 1	reward = -0.611749	array([[-1.0197806, -1.8256156]], dtype=float32)

time = 2497	action = 0	current_phase = 0	next_phase = 1	reward = -0.457011	array([[-0.80796707, -1.7313204 ]], dtype=float32)

time = 2502	action = 0	current_phase = 0	next_phase = 1	reward = -0.308049	array([[-0.7609458, -1.5544527]], dtype=float32)

time = 2507	action = 0	current_phase = 0	next_phase = 1	reward = -0.175685	array([[-0.669158 , -1.9582088]], dtype=float32)

time = 2512	action = 0	current_phase = 0	next_phase = 1	reward = 0.193710	array([[-0.8220942, -2.6958225]], dtype=float32)

time = 2517	action = 1	current_phase = 0	next_phase = 1	reward = -1.780784	array([[-2.9410396, -2.2400775]], dtype=float32)

time = 2525	action = 0	current_phase = 1	next_phase = 0	reward = -0.521405	array([[-1.330465, -1.717897]], dtype=float32)

time = 2530	action = 0	current_phase = 1	next_phase = 0	reward = -0.367706	array([[-0.78583264, -1.8526373 ]], dtype=float32)

time = 2535	action = 0	current_phase = 1	next_phase = 0	reward = -0.217980	array([[-0.8675996, -1.8408533]], dtype=float32)

time = 2540	action = 0	current_phase = 1	next_phase = 0	reward = 0.345217	array([[-0.7879168, -2.034605 ]], dtype=float32)

time = 2545	action = 0	current_phase = 1	next_phase = 0	reward = -0.847688	array([[-2.3847926, -2.4556093]], dtype=float32)

time = 2550	action = 1	current_phase = 1	next_phase = 0	reward = -2.103811	array([[-3.0112693, -2.4217072]], dtype=float32)

time = 2558	action = 0	current_phase = 0	next_phase = 1	reward = -0.431384	array([[-0.9039049, -1.4691328]], dtype=float32)

time = 2563	action = 0	current_phase = 0	next_phase = 1	reward = -0.287447	array([[-0.6261494, -1.5722659]], dtype=float32)

time = 2568	action = 0	current_phase = 0	next_phase = 1	reward = -0.165117	array([[-0.7306571, -2.1473868]], dtype=float32)

time = 2573	action = 0	current_phase = 0	next_phase = 1	reward = -0.038498	array([[-0.7093421, -2.6470158]], dtype=float32)

time = 2578	action = 1	current_phase = 0	next_phase = 1	reward = -1.908563	array([[-2.946041, -2.639185]], dtype=float32)

time = 2586	action = 0	current_phase = 1	next_phase = 0	reward = -0.506447	array([[-0.98136497, -1.7627609 ]], dtype=float32)

time = 2591	action = 0	current_phase = 1	next_phase = 0	reward = -0.351891	array([[-0.69174755, -1.8518963 ]], dtype=float32)

time = 2596	action = 0	current_phase = 1	next_phase = 0	reward = -0.193833	array([[-0.75984216, -1.8669316 ]], dtype=float32)

time = 2601	action = 0	current_phase = 1	next_phase = 0	reward = 0.313079	array([[-0.889927 , -2.1375594]], dtype=float32)

time = 2606	action = 1	current_phase = 1	next_phase = 0	reward = -1.506405	array([[-2.569733 , -2.5014567]], dtype=float32)

time = 2614	action = 0	current_phase = 0	next_phase = 1	reward = -0.555490	array([[-1.0330995, -1.800919 ]], dtype=float32)

time = 2619	action = 0	current_phase = 0	next_phase = 1	reward = -0.392703	array([[-0.6404946, -1.7460165]], dtype=float32)

time = 2624	action = 0	current_phase = 0	next_phase = 1	reward = -0.235706	array([[-0.58784205, -1.6765947 ]], dtype=float32)

time = 2629	action = 0	current_phase = 0	next_phase = 1	reward = -0.171339	array([[-0.55886894, -2.0073974 ]], dtype=float32)

time = 2634	action = 0	current_phase = 0	next_phase = 1	reward = -0.183909	array([[-1.500524 , -2.3043647]], dtype=float32)

time = 2639	action = 1	current_phase = 0	next_phase = 1	reward = -2.016787	array([[-3.1731281, -2.6663027]], dtype=float32)

time = 2647	action = 0	current_phase = 1	next_phase = 0	reward = -0.470840	array([[-0.8444146, -1.7199793]], dtype=float32)

time = 2652	action = 0	current_phase = 1	next_phase = 0	reward = -0.315486	array([[-0.60965955, -1.879979  ]], dtype=float32)

time = 2657	action = 0	current_phase = 1	next_phase = 0	reward = -0.173833	array([[-0.6231499, -2.0623999]], dtype=float32)

time = 2662	action = 0	current_phase = 1	next_phase = 0	reward = 0.264170	array([[-0.7402756, -2.8616948]], dtype=float32)

time = 2667	action = 1	current_phase = 1	next_phase = 0	reward = -1.777346	array([[-2.618163 , -2.5735066]], dtype=float32)

time = 2675	action = 0	current_phase = 0	next_phase = 1	reward = -0.512835	array([[-0.9260036, -1.5643296]], dtype=float32)

time = 2680	action = 0	current_phase = 0	next_phase = 1	reward = -0.349710	array([[-0.53457755, -1.6664371 ]], dtype=float32)

time = 2685	action = 0	current_phase = 0	next_phase = 1	reward = -0.205156	array([[-0.6487029, -1.8889838]], dtype=float32)

time = 2690	action = 0	current_phase = 0	next_phase = 1	reward = 0.344199	array([[-0.70844036, -2.5899527 ]], dtype=float32)

time = 2695	action = 1	current_phase = 0	next_phase = 1	reward = -1.420781	array([[-2.6548924, -2.3731463]], dtype=float32)

time = 2703	action = 0	current_phase = 1	next_phase = 0	reward = -0.597331	array([[-1.0998796, -1.8196664]], dtype=float32)

time = 2708	action = 0	current_phase = 1	next_phase = 0	reward = -0.448838	array([[-0.72699916, -1.8377789 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0548 - val_loss: 0.0314

Epoch 2/50

 - 4s - loss: 0.0485 - val_loss: 0.0335

Epoch 3/50

 - 4s - loss: 0.0490 - val_loss: 0.0315

Epoch 4/50

 - 4s - loss: 0.0480 - val_loss: 0.0339

Epoch 5/50

 - 4s - loss: 0.0444 - val_loss: 0.0338

Epoch 6/50

 - 4s - loss: 0.0448 - val_loss: 0.0321

Epoch 7/50

 - 4s - loss: 0.0431 - val_loss: 0.0323

Epoch 8/50

 - 4s - loss: 0.0416 - val_loss: 0.0324

Epoch 9/50

 - 4s - loss: 0.0402 - val_loss: 0.0340

Epoch 10/50

 - 4s - loss: 0.0429 - val_loss: 0.0329

Epoch 11/50

 - 4s - loss: 0.0436 - val_loss: 0.0356

length of memory (state 0, action 0): 719, after forget

length of memory (state 0, action 1): 344, after forget

length of memory (state 1, action 0): 687, after forget

length of memory (state 1, action 1): 331, after forget

time = 2713	action = 0	current_phase = 1	next_phase = 0	reward = -0.298994	array([[-0.6360842, -1.8131346]], dtype=float32)

time = 2718	action = 0	current_phase = 1	next_phase = 0	reward = -0.165524	array([[-0.5788834, -1.9780984]], dtype=float32)

time = 2723	action = 0	current_phase = 1	next_phase = 0	reward = 0.032114	array([[-0.8918985, -2.4838376]], dtype=float32)

time = 2728	action = 1	current_phase = 1	next_phase = 0	reward = -1.906164	array([[-3.0169096, -2.4524796]], dtype=float32)

time = 2736	action = 0	current_phase = 0	next_phase = 1	reward = -0.501451	array([[-0.96482277, -1.4794269 ]], dtype=float32)

time = 2741	action = 0	current_phase = 0	next_phase = 1	reward = -0.341014	array([[-0.61937803, -1.6900529 ]], dtype=float32)

time = 2746	action = 0	current_phase = 0	next_phase = 1	reward = -0.191256	array([[-0.5843669, -1.776489 ]], dtype=float32)

time = 2751	action = 0	current_phase = 0	next_phase = 1	reward = 0.302940	array([[-0.99043316, -2.260482  ]], dtype=float32)

time = 2756	action = 1	current_phase = 0	next_phase = 1	reward = -1.663281	array([[-2.7969444, -2.4420607]], dtype=float32)

time = 2764	action = 0	current_phase = 1	next_phase = 0	reward = -0.552976	array([[-0.4946577, -1.8070753]], dtype=float32)

time = 2769	action = 0	current_phase = 1	next_phase = 0	reward = -0.399588	array([[-0.7703971, -1.8406811]], dtype=float32)

time = 2774	action = 0	current_phase = 1	next_phase = 0	reward = -0.249233	array([[-0.6053078, -1.8431389]], dtype=float32)

time = 2779	action = 0	current_phase = 1	next_phase = 0	reward = -0.190791	array([[-0.48566818, -2.1090326 ]], dtype=float32)

time = 2784	action = 0	current_phase = 1	next_phase = 0	reward = -0.152060	array([[-1.2894206, -2.0783477]], dtype=float32)

time = 2789	action = 1	current_phase = 1	next_phase = 0	reward = -1.997141	array([[-3.2417562, -2.4325523]], dtype=float32)

time = 2797	action = 0	current_phase = 0	next_phase = 1	reward = -0.456154	array([[-0.8864633, -1.4990654]], dtype=float32)

time = 2802	action = 0	current_phase = 0	next_phase = 1	reward = -0.290657	array([[-0.64524627, -1.5190058 ]], dtype=float32)

time = 2807	action = 0	current_phase = 0	next_phase = 1	reward = -0.163606	array([[-0.6523273, -1.9824902]], dtype=float32)

time = 2812	action = 0	current_phase = 0	next_phase = 1	reward = 0.242943	array([[-1.2385205, -2.3727574]], dtype=float32)

time = 2817	action = 0	current_phase = 0	next_phase = 1	reward = -1.315970	array([[-2.4328759, -2.4546065]], dtype=float32)

time = 2822	action = 1	current_phase = 0	next_phase = 1	reward = -2.003763	array([[-2.6766355, -2.516815 ]], dtype=float32)

time = 2830	action = 0	current_phase = 1	next_phase = 0	reward = -0.365314	array([[-0.67695904, -1.8431915 ]], dtype=float32)

time = 2835	action = 0	current_phase = 1	next_phase = 0	reward = -0.218966	array([[-0.673871 , -1.8401539]], dtype=float32)

time = 2840	action = 0	current_phase = 1	next_phase = 0	reward = 0.357030	array([[-0.6331192, -2.3480897]], dtype=float32)

time = 2845	action = 1	current_phase = 1	next_phase = 0	reward = -1.259032	array([[-2.66771 , -2.232358]], dtype=float32)

time = 2853	action = 0	current_phase = 0	next_phase = 1	reward = -0.579508	array([[-0.78554416, -1.6807619 ]], dtype=float32)

time = 2858	action = 0	current_phase = 0	next_phase = 1	reward = -0.424942	array([[-0.8289632, -1.721696 ]], dtype=float32)

time = 2863	action = 0	current_phase = 0	next_phase = 1	reward = -0.273701	array([[-0.5545146, -1.629115 ]], dtype=float32)

time = 2868	action = 0	current_phase = 0	next_phase = 1	reward = -0.165160	array([[-0.5979662, -2.1727636]], dtype=float32)

time = 2873	action = 0	current_phase = 0	next_phase = 1	reward = -0.059713	array([[-1.6378336, -2.0575364]], dtype=float32)

time = 2878	action = 1	current_phase = 0	next_phase = 1	reward = -1.904769	array([[-3.0555913, -2.6511135]], dtype=float32)

time = 2886	action = 0	current_phase = 1	next_phase = 0	reward = -0.501921	array([[-0.79605514, -1.7024714 ]], dtype=float32)

time = 2891	action = 0	current_phase = 1	next_phase = 0	reward = -0.355690	array([[-0.62701845, -1.826707  ]], dtype=float32)

time = 2896	action = 0	current_phase = 1	next_phase = 0	reward = -0.209389	array([[-0.7898005, -1.8186389]], dtype=float32)

time = 2901	action = 0	current_phase = 1	next_phase = 0	reward = 0.313508	array([[-0.52061784, -2.329854  ]], dtype=float32)

time = 2906	action = 1	current_phase = 1	next_phase = 0	reward = -1.503557	array([[-3.0750082, -2.1782541]], dtype=float32)

time = 2914	action = 0	current_phase = 0	next_phase = 1	reward = -0.556670	array([[-0.8932761, -1.5882925]], dtype=float32)

time = 2919	action = 0	current_phase = 0	next_phase = 1	reward = -0.399650	array([[-0.6956287, -1.6262126]], dtype=float32)

time = 2924	action = 0	current_phase = 0	next_phase = 1	reward = -0.247345	array([[-0.63076276, -1.5819741 ]], dtype=float32)

time = 2929	action = 0	current_phase = 0	next_phase = 1	reward = -0.179885	array([[-0.51253456, -2.0615566 ]], dtype=float32)

time = 2934	action = 0	current_phase = 0	next_phase = 1	reward = -0.095248	array([[-1.3984914, -1.7449521]], dtype=float32)

time = 2939	action = 1	current_phase = 0	next_phase = 1	reward = -2.015111	array([[-3.0308487, -2.5476463]], dtype=float32)

time = 2947	action = 0	current_phase = 1	next_phase = 0	reward = -0.472725	array([[-0.9849765, -1.7965269]], dtype=float32)

time = 2952	action = 0	current_phase = 1	next_phase = 0	reward = -0.318958	array([[-0.5375137, -1.7897513]], dtype=float32)

time = 2957	action = 0	current_phase = 1	next_phase = 0	reward = -0.179515	array([[-0.75549936, -1.8246654 ]], dtype=float32)

time = 2962	action = 0	current_phase = 1	next_phase = 0	reward = 0.271664	array([[-0.83359426, -2.6323686 ]], dtype=float32)

time = 2967	action = 1	current_phase = 1	next_phase = 0	reward = -1.730627	array([[-2.824289 , -2.4744089]], dtype=float32)

time = 2975	action = 0	current_phase = 0	next_phase = 1	reward = -0.528260	array([[-0.9632943, -1.510725 ]], dtype=float32)

time = 2980	action = 0	current_phase = 0	next_phase = 1	reward = -0.369950	array([[-0.36097413, -1.6514143 ]], dtype=float32)

time = 2985	action = 0	current_phase = 0	next_phase = 1	reward = -0.214899	array([[-0.5507433, -1.6239429]], dtype=float32)

time = 2990	action = 0	current_phase = 0	next_phase = 1	reward = 0.358755	array([[-0.65532804, -2.0430467 ]], dtype=float32)

time = 2995	action = 1	current_phase = 0	next_phase = 1	reward = -1.363914	array([[-2.2934995, -2.1159592]], dtype=float32)

time = 3003	action = 0	current_phase = 1	next_phase = 0	reward = -0.596573	array([[-1.1085277, -1.8792953]], dtype=float32)

time = 3008	action = 0	current_phase = 1	next_phase = 0	reward = -0.443804	array([[-0.8110644, -1.8555257]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0487 - val_loss: 0.0264

Epoch 2/50

 - 4s - loss: 0.0447 - val_loss: 0.0264

Epoch 3/50

 - 4s - loss: 0.0441 - val_loss: 0.0277

Epoch 4/50

 - 4s - loss: 0.0412 - val_loss: 0.0269

Epoch 5/50

 - 4s - loss: 0.0446 - val_loss: 0.0255

Epoch 6/50

 - 4s - loss: 0.0412 - val_loss: 0.0246

Epoch 7/50

 - 4s - loss: 0.0390 - val_loss: 0.0291

Epoch 8/50

 - 4s - loss: 0.0396 - val_loss: 0.0318

Epoch 9/50

 - 4s - loss: 0.0412 - val_loss: 0.0292

Epoch 10/50

 - 4s - loss: 0.0343 - val_loss: 0.0311

Epoch 11/50

 - 4s - loss: 0.0368 - val_loss: 0.0284

Epoch 12/50

 - 4s - loss: 0.0359 - val_loss: 0.0289

Epoch 13/50

 - 4s - loss: 0.0391 - val_loss: 0.0279

Epoch 14/50

 - 4s - loss: 0.0359 - val_loss: 0.0297

Epoch 15/50

 - 4s - loss: 0.0385 - val_loss: 0.0305

Epoch 16/50

 - 4s - loss: 0.0323 - val_loss: 0.0304

length of memory (state 0, action 0): 742, after forget

length of memory (state 0, action 1): 349, after forget

length of memory (state 1, action 0): 708, after forget

length of memory (state 1, action 1): 336, after forget

time = 3013	action = 0	current_phase = 1	next_phase = 0	reward = -0.290501	array([[-0.6165706, -1.8362424]], dtype=float32)

time = 3018	action = 0	current_phase = 1	next_phase = 0	reward = -0.167202	array([[-0.5504111, -2.1389437]], dtype=float32)

time = 3023	action = 0	current_phase = 1	next_phase = 0	reward = 0.128634	array([[-1.0254216, -2.3465858]], dtype=float32)

time = 3028	action = 1	current_phase = 1	next_phase = 0	reward = -1.895859	array([[-3.0658014, -2.160356 ]], dtype=float32)

time = 3036	action = 0	current_phase = 0	next_phase = 1	reward = -0.504814	array([[-1.0158106, -1.5463468]], dtype=float32)

time = 3041	action = 0	current_phase = 0	next_phase = 1	reward = -0.354315	array([[-0.7531878, -1.7391002]], dtype=float32)

time = 3046	action = 0	current_phase = 0	next_phase = 1	reward = -0.206307	array([[-0.62151396, -1.9034051 ]], dtype=float32)

time = 3051	action = 0	current_phase = 0	next_phase = 1	reward = 0.304724	array([[-0.90469235, -2.4253201 ]], dtype=float32)

time = 3056	action = 1	current_phase = 0	next_phase = 1	reward = -1.608249	array([[-2.9314895, -2.5926883]], dtype=float32)

time = 3064	action = 0	current_phase = 1	next_phase = 0	reward = -0.564853	array([[-0.59209657, -1.8658942 ]], dtype=float32)

time = 3069	action = 0	current_phase = 1	next_phase = 0	reward = -0.414365	array([[-0.58621013, -1.8295511 ]], dtype=float32)

time = 3074	action = 0	current_phase = 1	next_phase = 0	reward = -0.255626	array([[-0.8132087, -1.8705782]], dtype=float32)

time = 3079	action = 0	current_phase = 1	next_phase = 0	reward = 0.119502	array([[-0.46346462, -2.163992  ]], dtype=float32)

time = 3084	action = 1	current_phase = 1	next_phase = 0	reward = -0.650463	array([[-2.236238 , -1.5740643]], dtype=float32)

time = 3092	action = 0	current_phase = 0	next_phase = 1	reward = -0.619695	array([[-1.149019 , -1.8202776]], dtype=float32)

time = 3097	action = 0	current_phase = 0	next_phase = 1	reward = -0.460606	array([[-0.8937754, -1.7114834]], dtype=float32)

time = 3102	action = 0	current_phase = 0	next_phase = 1	reward = -0.294850	array([[-0.772414, -1.48033 ]], dtype=float32)

time = 3107	action = 0	current_phase = 0	next_phase = 1	reward = -0.165993	array([[-0.75253195, -2.183121  ]], dtype=float32)

time = 3112	action = 0	current_phase = 0	next_phase = 1	reward = 0.233093	array([[-0.8515784, -2.6327653]], dtype=float32)

time = 3117	action = 1	current_phase = 0	next_phase = 1	reward = -1.780473	array([[-2.9545593, -2.4758987]], dtype=float32)

time = 3125	action = 0	current_phase = 1	next_phase = 0	reward = -0.529556	array([[-1.0020821, -1.743986 ]], dtype=float32)

time = 3130	action = 0	current_phase = 1	next_phase = 0	reward = -0.373385	array([[-0.47400683, -1.8497738 ]], dtype=float32)

time = 3135	action = 0	current_phase = 1	next_phase = 0	reward = -0.219273	array([[-0.74868494, -1.9418033 ]], dtype=float32)

time = 3140	action = 0	current_phase = 1	next_phase = 0	reward = 0.061848	array([[-0.9160745, -2.141878 ]], dtype=float32)

time = 3145	action = 0	current_phase = 1	next_phase = 0	reward = -0.508298	array([[-2.2797596, -2.3136768]], dtype=float32)

time = 3150	action = 1	current_phase = 1	next_phase = 0	reward = -2.128508	array([[-3.1005352, -2.5423117]], dtype=float32)

time = 3158	action = 0	current_phase = 0	next_phase = 1	reward = -0.455355	array([[-0.914712 , -1.4922026]], dtype=float32)

time = 3163	action = 0	current_phase = 0	next_phase = 1	reward = -0.309702	array([[-0.6657639, -1.6175302]], dtype=float32)

time = 3168	action = 0	current_phase = 0	next_phase = 1	reward = -0.175306	array([[-0.707128 , -2.1591008]], dtype=float32)

time = 3173	action = 0	current_phase = 0	next_phase = 1	reward = 0.142041	array([[-0.96341544, -2.8294618 ]], dtype=float32)

time = 3178	action = 1	current_phase = 0	next_phase = 1	reward = -1.897752	array([[-2.9238405, -2.6167994]], dtype=float32)

time = 3186	action = 0	current_phase = 1	next_phase = 0	reward = -0.501618	array([[-0.8930405, -1.8137554]], dtype=float32)

time = 3191	action = 0	current_phase = 1	next_phase = 0	reward = -0.353413	array([[-0.6682981, -1.8754897]], dtype=float32)

time = 3196	action = 0	current_phase = 1	next_phase = 0	reward = -0.208358	array([[-0.73340243, -1.9861691 ]], dtype=float32)

time = 3201	action = 0	current_phase = 1	next_phase = 0	reward = 0.340052	array([[-0.8487379, -2.6215382]], dtype=float32)

time = 3206	action = 1	current_phase = 1	next_phase = 0	reward = -1.553006	array([[-2.4722693, -2.2643533]], dtype=float32)

time = 3214	action = 0	current_phase = 0	next_phase = 1	reward = -0.550777	array([[-1.0254555, -1.615537 ]], dtype=float32)

time = 3219	action = 0	current_phase = 0	next_phase = 1	reward = -0.384922	array([[-0.78599197, -1.6991862 ]], dtype=float32)

time = 3224	action = 0	current_phase = 0	next_phase = 1	reward = -0.219581	array([[-0.6599759, -1.893473 ]], dtype=float32)

time = 3229	action = 0	current_phase = 0	next_phase = 1	reward = -0.185335	array([[-0.69310236, -2.1922383 ]], dtype=float32)

time = 3234	action = 0	current_phase = 0	next_phase = 1	reward = -0.149328	array([[-1.6984515, -2.3759313]], dtype=float32)

time = 3239	action = 1	current_phase = 0	next_phase = 1	reward = -2.006241	array([[-3.4112988, -2.7554321]], dtype=float32)

time = 3247	action = 0	current_phase = 1	next_phase = 0	reward = -0.467817	array([[-0.72704786, -1.8354349 ]], dtype=float32)

time = 3252	action = 0	current_phase = 1	next_phase = 0	reward = -0.312313	array([[-0.65722716, -1.766189  ]], dtype=float32)

time = 3257	action = 0	current_phase = 1	next_phase = 0	reward = -0.175864	array([[-0.7884784, -1.8235706]], dtype=float32)

time = 3262	action = 0	current_phase = 1	next_phase = 0	reward = 0.191267	array([[-0.8524612, -2.6182446]], dtype=float32)

time = 3267	action = 1	current_phase = 1	next_phase = 0	reward = -1.733001	array([[-2.9475741, -2.381032 ]], dtype=float32)

time = 3275	action = 0	current_phase = 0	next_phase = 1	reward = -0.537221	array([[-1.0284492, -1.471759 ]], dtype=float32)

time = 3280	action = 0	current_phase = 0	next_phase = 1	reward = -0.376986	array([[-0.6075395, -1.728312 ]], dtype=float32)

time = 3285	action = 0	current_phase = 0	next_phase = 1	reward = -0.223096	array([[-0.75931656, -1.8695564 ]], dtype=float32)

time = 3290	action = 0	current_phase = 0	next_phase = 1	reward = 0.064024	array([[-0.8917855, -2.1480136]], dtype=float32)

time = 3295	action = 1	current_phase = 0	next_phase = 1	reward = -1.026316	array([[-2.2678318, -2.230051 ]], dtype=float32)

time = 3303	action = 0	current_phase = 1	next_phase = 0	reward = -0.593905	array([[-1.189034 , -1.9073833]], dtype=float32)

time = 3308	action = 0	current_phase = 1	next_phase = 0	reward = -0.443573	array([[-0.77566415, -1.9030116 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0870 - val_loss: 0.0434

Epoch 2/50

 - 4s - loss: 0.0754 - val_loss: 0.0417

Epoch 3/50

 - 4s - loss: 0.0791 - val_loss: 0.0425

Epoch 4/50

 - 4s - loss: 0.0642 - val_loss: 0.0412

Epoch 5/50

 - 4s - loss: 0.0626 - val_loss: 0.0418

Epoch 6/50

 - 4s - loss: 0.0711 - val_loss: 0.0431

Epoch 7/50

 - 4s - loss: 0.0656 - val_loss: 0.0408

Epoch 8/50

 - 4s - loss: 0.0684 - val_loss: 0.0406

Epoch 9/50

 - 4s - loss: 0.0646 - val_loss: 0.0411

Epoch 10/50

 - 4s - loss: 0.0634 - val_loss: 0.0416

Epoch 11/50

 - 4s - loss: 0.0585 - val_loss: 0.0423

Epoch 12/50

 - 4s - loss: 0.0592 - val_loss: 0.0422

Epoch 13/50

 - 4s - loss: 0.0557 - val_loss: 0.0405

Epoch 14/50

 - 4s - loss: 0.0547 - val_loss: 0.0409

Epoch 15/50

 - 4s - loss: 0.0571 - val_loss: 0.0445

Epoch 16/50

 - 4s - loss: 0.0567 - val_loss: 0.0429

Epoch 17/50

 - 4s - loss: 0.0560 - val_loss: 0.0454

Epoch 18/50

 - 4s - loss: 0.0508 - val_loss: 0.0453

Epoch 19/50

 - 4s - loss: 0.0510 - val_loss: 0.0489

Epoch 20/50

 - 4s - loss: 0.0551 - val_loss: 0.0505

Epoch 21/50

 - 4s - loss: 0.0511 - val_loss: 0.0469

Epoch 22/50

 - 4s - loss: 0.0537 - val_loss: 0.0474

Epoch 23/50

 - 4s - loss: 0.0507 - val_loss: 0.0468

length of memory (state 0, action 0): 764, after forget

length of memory (state 0, action 1): 354, after forget

length of memory (state 1, action 0): 730, after forget

length of memory (state 1, action 1): 341, after forget

time = 3313	action = 0	current_phase = 1	next_phase = 0	reward = -0.294160	array([[-0.65878403, -1.6189232 ]], dtype=float32)

time = 3318	action = 0	current_phase = 1	next_phase = 0	reward = -0.168350	array([[-1.0599079, -1.7704768]], dtype=float32)

time = 3323	action = 0	current_phase = 1	next_phase = 0	reward = 0.073879	array([[-1.143785 , -2.0512388]], dtype=float32)

time = 3328	action = 1	current_phase = 1	next_phase = 0	reward = -1.900862	array([[-3.1872983, -2.6723807]], dtype=float32)

time = 3336	action = 0	current_phase = 0	next_phase = 1	reward = -0.497535	array([[-1.0279912, -1.5069975]], dtype=float32)

time = 3341	action = 0	current_phase = 0	next_phase = 1	reward = -0.344428	array([[-0.71620333, -1.8236624 ]], dtype=float32)

time = 3346	action = 0	current_phase = 0	next_phase = 1	reward = -0.198262	array([[-0.7737275, -1.8215337]], dtype=float32)

time = 3351	action = 0	current_phase = 0	next_phase = 1	reward = 0.314424	array([[-1.3556677, -2.4589918]], dtype=float32)

time = 3356	action = 1	current_phase = 0	next_phase = 1	reward = -1.506231	array([[-3.03715 , -2.511325]], dtype=float32)

time = 3364	action = 0	current_phase = 1	next_phase = 0	reward = -0.555204	array([[-1.0356216, -1.9266901]], dtype=float32)

time = 3369	action = 0	current_phase = 1	next_phase = 0	reward = -0.397648	array([[-0.5842329, -1.8770385]], dtype=float32)

time = 3374	action = 0	current_phase = 1	next_phase = 0	reward = -0.240425	array([[-0.870527 , -1.8956246]], dtype=float32)

time = 3379	action = 0	current_phase = 1	next_phase = 0	reward = -0.184097	array([[-0.94852793, -2.3265283 ]], dtype=float32)

time = 3384	action = 0	current_phase = 1	next_phase = 0	reward = -0.037497	array([[-2.2632802, -2.5753574]], dtype=float32)

time = 3389	action = 1	current_phase = 1	next_phase = 0	reward = -2.012807	array([[-3.2710023, -2.465887 ]], dtype=float32)

time = 3397	action = 0	current_phase = 0	next_phase = 1	reward = -0.481091	array([[-0.98357004, -1.4928051 ]], dtype=float32)

time = 3402	action = 0	current_phase = 0	next_phase = 1	reward = -0.328167	array([[-0.6548252, -1.7573135]], dtype=float32)

time = 3407	action = 0	current_phase = 0	next_phase = 1	reward = -0.179559	array([[-0.82062656, -1.8824846 ]], dtype=float32)

time = 3412	action = 0	current_phase = 0	next_phase = 1	reward = 0.252301	array([[-1.8055563, -2.5761554]], dtype=float32)

time = 3417	action = 1	current_phase = 0	next_phase = 1	reward = -1.729078	array([[-2.929648 , -2.5356226]], dtype=float32)

time = 3425	action = 0	current_phase = 1	next_phase = 0	reward = -0.527738	array([[-1.2990438, -1.8488612]], dtype=float32)

time = 3430	action = 0	current_phase = 1	next_phase = 0	reward = -0.370092	array([[-0.66939664, -1.8971453 ]], dtype=float32)

time = 3435	action = 0	current_phase = 1	next_phase = 0	reward = -0.219021	array([[-0.93063176, -1.9184613 ]], dtype=float32)

time = 3440	action = 0	current_phase = 1	next_phase = 0	reward = 0.066265	array([[-1.1566675, -2.2121775]], dtype=float32)

time = 3445	action = 1	current_phase = 1	next_phase = 0	reward = -1.083852	array([[-2.3236842, -1.9711223]], dtype=float32)

time = 3453	action = 0	current_phase = 0	next_phase = 1	reward = -0.591539	array([[-1.0365279, -1.6374044]], dtype=float32)

time = 3458	action = 0	current_phase = 0	next_phase = 1	reward = -0.438089	array([[-0.8114193, -1.841182 ]], dtype=float32)

time = 3463	action = 0	current_phase = 0	next_phase = 1	reward = -0.283653	array([[-0.73252296, -1.6015928 ]], dtype=float32)

time = 3468	action = 0	current_phase = 0	next_phase = 1	reward = -0.174714	array([[-0.909041 , -2.2849226]], dtype=float32)

time = 3473	action = 0	current_phase = 0	next_phase = 1	reward = 0.102405	array([[-1.1397734, -2.3075886]], dtype=float32)

time = 3478	action = 1	current_phase = 0	next_phase = 1	reward = -1.897703	array([[-3.1835046, -2.700844 ]], dtype=float32)

time = 3486	action = 0	current_phase = 1	next_phase = 0	reward = -0.501033	array([[-1.0742811, -1.7731683]], dtype=float32)

time = 3491	action = 0	current_phase = 1	next_phase = 0	reward = -0.339669	array([[-0.7515235, -1.895181 ]], dtype=float32)

time = 3496	action = 0	current_phase = 1	next_phase = 0	reward = -0.187758	array([[-0.9394522, -1.8969097]], dtype=float32)

time = 3501	action = 0	current_phase = 1	next_phase = 0	reward = 0.302311	array([[-1.1601305, -2.5400586]], dtype=float32)

time = 3506	action = 1	current_phase = 1	next_phase = 0	reward = -1.610060	array([[-2.808024 , -2.4694176]], dtype=float32)

time = 3514	action = 0	current_phase = 0	next_phase = 1	reward = -0.549149	array([[-1.0134549, -1.6705471]], dtype=float32)

time = 3519	action = 0	current_phase = 0	next_phase = 1	reward = -0.395873	array([[-0.80764884, -1.7981591 ]], dtype=float32)

time = 3524	action = 0	current_phase = 0	next_phase = 1	reward = -0.242494	array([[-0.7587557, -1.7548215]], dtype=float32)

time = 3529	action = 0	current_phase = 0	next_phase = 1	reward = -0.187583	array([[-0.8031562, -2.1972897]], dtype=float32)

time = 3534	action = 1	current_phase = 0	next_phase = 1	reward = -0.505298	array([[-2.0425494, -1.8261541]], dtype=float32)

time = 3542	action = 0	current_phase = 1	next_phase = 0	reward = -0.615388	array([[-1.4083872, -1.9228964]], dtype=float32)

time = 3547	action = 0	current_phase = 1	next_phase = 0	reward = -0.457820	array([[-0.41077286, -1.8532732 ]], dtype=float32)

time = 3552	action = 0	current_phase = 1	next_phase = 0	reward = -0.303246	array([[-0.7566755, -1.5802639]], dtype=float32)

time = 3557	action = 0	current_phase = 1	next_phase = 0	reward = -0.177233	array([[-0.87521756, -1.9539332 ]], dtype=float32)

time = 3562	action = 0	current_phase = 1	next_phase = 0	reward = 0.193898	array([[-1.1917808, -2.7734485]], dtype=float32)

time = 3567	action = 1	current_phase = 1	next_phase = 0	reward = -1.782283	array([[-3.2332728, -2.4808352]], dtype=float32)

time = 3575	action = 0	current_phase = 0	next_phase = 1	reward = -0.522673	array([[-1.2474418, -1.7016394]], dtype=float32)

time = 3580	action = 0	current_phase = 0	next_phase = 1	reward = -0.375586	array([[-0.8190112, -1.8336477]], dtype=float32)

time = 3585	action = 0	current_phase = 0	next_phase = 1	reward = -0.226021	array([[-0.72278315, -1.5605139 ]], dtype=float32)

time = 3590	action = 0	current_phase = 0	next_phase = 1	reward = 0.060691	array([[-0.9833489, -2.4743044]], dtype=float32)

time = 3595	action = 1	current_phase = 0	next_phase = 1	reward = -1.033796	array([[-2.559387, -2.317233]], dtype=float32)

time = 3603	action = 0	current_phase = 1	next_phase = 0	reward = -0.593947	array([[-1.3719088, -1.9128442]], dtype=float32)

time = 3608	action = 0	current_phase = 1	next_phase = 0	reward = -0.442921	array([[-0.81986356, -1.8947372 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0624 - val_loss: 0.0326

Epoch 2/50

 - 4s - loss: 0.0570 - val_loss: 0.0304

Epoch 3/50

 - 4s - loss: 0.0598 - val_loss: 0.0317

Epoch 4/50

 - 4s - loss: 0.0554 - val_loss: 0.0328

Epoch 5/50

 - 4s - loss: 0.0563 - val_loss: 0.0332

Epoch 6/50

 - 4s - loss: 0.0502 - val_loss: 0.0335

Epoch 7/50

 - 4s - loss: 0.0485 - val_loss: 0.0338

Epoch 8/50

 - 4s - loss: 0.0493 - val_loss: 0.0351

Epoch 9/50

 - 4s - loss: 0.0478 - val_loss: 0.0357

Epoch 10/50

 - 4s - loss: 0.0478 - val_loss: 0.0363

Epoch 11/50

 - 4s - loss: 0.0441 - val_loss: 0.0378

Epoch 12/50

 - 4s - loss: 0.0453 - val_loss: 0.0358

length of memory (state 0, action 0): 785, after forget

length of memory (state 0, action 1): 359, after forget

length of memory (state 1, action 0): 753, after forget

length of memory (state 1, action 1): 346, after forget

time = 3613	action = 0	current_phase = 1	next_phase = 0	reward = -0.290780	array([[-0.7752266, -1.6297001]], dtype=float32)

time = 3618	action = 0	current_phase = 1	next_phase = 0	reward = -0.165409	array([[-1.1577616, -1.7779179]], dtype=float32)

time = 3623	action = 0	current_phase = 1	next_phase = 0	reward = 0.048658	array([[-1.3965167, -2.0594103]], dtype=float32)

time = 3628	action = 1	current_phase = 1	next_phase = 0	reward = -1.905386	array([[-3.3147273, -2.7017884]], dtype=float32)

time = 3636	action = 0	current_phase = 0	next_phase = 1	reward = -0.497914	array([[-0.97827405, -1.557058  ]], dtype=float32)

time = 3641	action = 0	current_phase = 0	next_phase = 1	reward = -0.333816	array([[-0.94269043, -1.629093  ]], dtype=float32)

time = 3646	action = 0	current_phase = 0	next_phase = 1	reward = -0.189212	array([[-1.0646832, -2.1607313]], dtype=float32)

time = 3651	action = 0	current_phase = 0	next_phase = 1	reward = 0.303223	array([[-1.5421641, -2.4498487]], dtype=float32)

time = 3656	action = 1	current_phase = 0	next_phase = 1	reward = -1.502959	array([[-2.8942006, -2.355386 ]], dtype=float32)

time = 3664	action = 0	current_phase = 1	next_phase = 0	reward = -0.562717	array([[-1.3234897, -1.9268128]], dtype=float32)

time = 3669	action = 0	current_phase = 1	next_phase = 0	reward = -0.407510	array([[-1.0182644, -1.9531133]], dtype=float32)

time = 3674	action = 0	current_phase = 1	next_phase = 0	reward = -0.249000	array([[-0.8047459, -1.989018 ]], dtype=float32)

time = 3679	action = 0	current_phase = 1	next_phase = 0	reward = -0.174265	array([[-1.0336918, -2.3801112]], dtype=float32)

time = 3684	action = 1	current_phase = 1	next_phase = 0	reward = -0.466883	array([[-2.2271466, -1.5876465]], dtype=float32)

time = 3692	action = 0	current_phase = 0	next_phase = 1	reward = -0.617788	array([[-1.1071248, -1.7479664]], dtype=float32)

time = 3697	action = 0	current_phase = 0	next_phase = 1	reward = -0.467568	array([[-0.9399084, -1.8407696]], dtype=float32)

time = 3702	action = 0	current_phase = 0	next_phase = 1	reward = -0.322116	array([[-0.80789167, -1.6499931 ]], dtype=float32)

time = 3707	action = 0	current_phase = 0	next_phase = 1	reward = -0.184794	array([[-0.96964526, -1.9577814 ]], dtype=float32)

time = 3712	action = 0	current_phase = 0	next_phase = 1	reward = 0.245013	array([[-0.79430306, -2.7878573 ]], dtype=float32)

time = 3717	action = 1	current_phase = 0	next_phase = 1	reward = -1.726890	array([[-2.8097217, -2.4051135]], dtype=float32)

time = 3725	action = 0	current_phase = 1	next_phase = 0	reward = -0.526131	array([[-1.1060501, -1.8333734]], dtype=float32)

time = 3730	action = 0	current_phase = 1	next_phase = 0	reward = -0.368570	array([[-0.6718832, -1.9602056]], dtype=float32)

time = 3735	action = 0	current_phase = 1	next_phase = 0	reward = -0.213675	array([[-0.90883434, -1.9918834 ]], dtype=float32)

time = 3740	action = 0	current_phase = 1	next_phase = 0	reward = 0.353320	array([[-0.9638265, -2.5706077]], dtype=float32)

time = 3745	action = 1	current_phase = 1	next_phase = 0	reward = -1.311457	array([[-2.6380658, -2.304223 ]], dtype=float32)

time = 3753	action = 0	current_phase = 0	next_phase = 1	reward = -0.584598	array([[-1.2447202, -1.5509568]], dtype=float32)

time = 3758	action = 0	current_phase = 0	next_phase = 1	reward = -0.426174	array([[-0.8900505, -1.8430468]], dtype=float32)

time = 3763	action = 0	current_phase = 0	next_phase = 1	reward = -0.273372	array([[-1.006072 , -1.7818682]], dtype=float32)

time = 3768	action = 0	current_phase = 0	next_phase = 1	reward = -0.161644	array([[-1.1052463, -2.086007 ]], dtype=float32)

time = 3773	action = 0	current_phase = 0	next_phase = 1	reward = 0.082713	array([[-1.9680929, -2.4350746]], dtype=float32)

time = 3778	action = 1	current_phase = 0	next_phase = 1	reward = -1.894111	array([[-3.2472603, -2.8788176]], dtype=float32)

time = 3786	action = 0	current_phase = 1	next_phase = 0	reward = -0.490930	array([[-0.98226607, -1.74414   ]], dtype=float32)

time = 3791	action = 0	current_phase = 1	next_phase = 0	reward = -0.331093	array([[-0.7278399, -1.9645022]], dtype=float32)

time = 3796	action = 0	current_phase = 1	next_phase = 0	reward = -0.189615	array([[-0.9451693, -2.004381 ]], dtype=float32)

time = 3801	action = 0	current_phase = 1	next_phase = 0	reward = 0.304390	array([[-0.90903866, -3.052503  ]], dtype=float32)

time = 3806	action = 1	current_phase = 1	next_phase = 0	reward = -1.558184	array([[-3.2117934, -2.4071617]], dtype=float32)

time = 3814	action = 0	current_phase = 0	next_phase = 1	reward = -0.559667	array([[-1.095952 , -1.6227318]], dtype=float32)

time = 3819	action = 0	current_phase = 0	next_phase = 1	reward = -0.407921	array([[-0.91223794, -1.8184575 ]], dtype=float32)

time = 3824	action = 0	current_phase = 0	next_phase = 1	reward = -0.258670	array([[-0.86449224, -1.7777104 ]], dtype=float32)

time = 3829	action = 0	current_phase = 0	next_phase = 1	reward = -0.174848	array([[-0.7258019, -2.4594884]], dtype=float32)

time = 3834	action = 1	current_phase = 0	next_phase = 1	reward = -0.546565	array([[-2.2236166, -1.7941465]], dtype=float32)

time = 3842	action = 0	current_phase = 1	next_phase = 0	reward = -0.612272	array([[-1.2794222, -1.943081 ]], dtype=float32)

time = 3847	action = 0	current_phase = 1	next_phase = 0	reward = -0.446998	array([[-0.45955467, -1.9383136 ]], dtype=float32)

time = 3852	action = 0	current_phase = 1	next_phase = 0	reward = -0.292840	array([[-0.8436662, -1.751916 ]], dtype=float32)

time = 3857	action = 0	current_phase = 1	next_phase = 0	reward = -0.169100	array([[-0.82515955, -2.0712557 ]], dtype=float32)

time = 3862	action = 0	current_phase = 1	next_phase = 0	reward = 0.210321	array([[-1.1387875, -2.8104486]], dtype=float32)

time = 3867	action = 1	current_phase = 1	next_phase = 0	reward = -1.781189	array([[-2.9453201, -2.5824614]], dtype=float32)

time = 3875	action = 0	current_phase = 0	next_phase = 1	reward = -0.534571	array([[-1.0455759, -1.4958874]], dtype=float32)

time = 3880	action = 0	current_phase = 0	next_phase = 1	reward = -0.377916	array([[-0.6333079, -1.8756182]], dtype=float32)

time = 3885	action = 0	current_phase = 0	next_phase = 1	reward = -0.226252	array([[-0.9611376, -2.0879586]], dtype=float32)

time = 3890	action = 0	current_phase = 0	next_phase = 1	reward = 0.364651	array([[-1.457725 , -2.6333668]], dtype=float32)

time = 3895	action = 1	current_phase = 0	next_phase = 1	reward = -1.257853	array([[-2.815321 , -2.1033556]], dtype=float32)

time = 3903	action = 0	current_phase = 1	next_phase = 0	reward = -0.583006	array([[-1.453231 , -1.9746652]], dtype=float32)

time = 3908	action = 0	current_phase = 1	next_phase = 0	reward = -0.436949	array([[-0.7674386, -1.9681369]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0519 - val_loss: 0.0244

Epoch 2/50

 - 4s - loss: 0.0514 - val_loss: 0.0263

Epoch 3/50

 - 4s - loss: 0.0469 - val_loss: 0.0249

Epoch 4/50

 - 4s - loss: 0.0483 - val_loss: 0.0255

Epoch 5/50

 - 4s - loss: 0.0476 - val_loss: 0.0246

Epoch 6/50

 - 4s - loss: 0.0522 - val_loss: 0.0262

Epoch 7/50

 - 4s - loss: 0.0467 - val_loss: 0.0262

Epoch 8/50

 - 4s - loss: 0.0431 - val_loss: 0.0286

Epoch 9/50

 - 4s - loss: 0.0437 - val_loss: 0.0259

Epoch 10/50

 - 4s - loss: 0.0447 - val_loss: 0.0282

Epoch 11/50

 - 4s - loss: 0.0426 - val_loss: 0.0290

length of memory (state 0, action 0): 807, after forget

length of memory (state 0, action 1): 364, after forget

length of memory (state 1, action 0): 775, after forget

length of memory (state 1, action 1): 351, after forget

time = 3913	action = 0	current_phase = 1	next_phase = 0	reward = -0.278810	array([[-0.62825775, -1.7072028 ]], dtype=float32)

time = 3918	action = 0	current_phase = 1	next_phase = 0	reward = -0.161392	array([[-1.0115833, -2.043852 ]], dtype=float32)

time = 3923	action = 0	current_phase = 1	next_phase = 0	reward = 0.060465	array([[-1.786921 , -2.3884506]], dtype=float32)

time = 3928	action = 1	current_phase = 1	next_phase = 0	reward = -1.898900	array([[-3.080179, -2.822353]], dtype=float32)

time = 3936	action = 0	current_phase = 0	next_phase = 1	reward = -0.490207	array([[-0.9350842, -1.4815707]], dtype=float32)

time = 3941	action = 0	current_phase = 0	next_phase = 1	reward = -0.338424	array([[-0.7949875, -1.6965936]], dtype=float32)

time = 3946	action = 0	current_phase = 0	next_phase = 1	reward = -0.190927	array([[-1.0318274, -2.131856 ]], dtype=float32)

time = 3951	action = 0	current_phase = 0	next_phase = 1	reward = 0.296820	array([[-1.6233066, -2.5403438]], dtype=float32)

time = 3956	action = 1	current_phase = 0	next_phase = 1	reward = -1.607575	array([[-2.9267738, -2.209171 ]], dtype=float32)

time = 3964	action = 0	current_phase = 1	next_phase = 0	reward = -0.565970	array([[-1.119952 , -1.9862906]], dtype=float32)

time = 3969	action = 0	current_phase = 1	next_phase = 0	reward = -0.407678	array([[-0.7577914, -1.97602  ]], dtype=float32)

time = 3974	action = 0	current_phase = 1	next_phase = 0	reward = -0.241024	array([[-0.66285515, -1.951608  ]], dtype=float32)

time = 3979	action = 0	current_phase = 1	next_phase = 0	reward = -0.171360	array([[-1.1734536, -2.1627407]], dtype=float32)

time = 3984	action = 1	current_phase = 1	next_phase = 0	reward = -0.484357	array([[-1.7092242, -1.5301276]], dtype=float32)

time = 3992	action = 0	current_phase = 0	next_phase = 1	reward = -0.614892	array([[-1.2176228, -1.845808 ]], dtype=float32)

time = 3997	action = 0	current_phase = 0	next_phase = 1	reward = -0.454414	array([[-0.8699738, -1.863518 ]], dtype=float32)

time = 4002	action = 0	current_phase = 0	next_phase = 1	reward = -0.298476	array([[-0.8316853, -1.5578544]], dtype=float32)

time = 4007	action = 0	current_phase = 0	next_phase = 1	reward = -0.168556	array([[-0.9191917, -2.118812 ]], dtype=float32)

time = 4012	action = 0	current_phase = 0	next_phase = 1	reward = 0.166950	array([[-1.3157227, -2.5201406]], dtype=float32)

time = 4017	action = 1	current_phase = 0	next_phase = 1	reward = -1.780022	array([[-3.5019932, -2.6484437]], dtype=float32)

time = 4025	action = 0	current_phase = 1	next_phase = 0	reward = -0.518281	array([[-0.9494634, -1.8372828]], dtype=float32)

time = 4030	action = 0	current_phase = 1	next_phase = 0	reward = -0.358992	array([[-0.7585995, -1.9743367]], dtype=float32)

time = 4035	action = 0	current_phase = 1	next_phase = 0	reward = -0.204164	array([[-0.91839224, -1.9627886 ]], dtype=float32)

time = 4040	action = 0	current_phase = 1	next_phase = 0	reward = 0.350040	array([[-1.4518046, -2.6094418]], dtype=float32)

time = 4045	action = 1	current_phase = 1	next_phase = 0	reward = -1.317141	array([[-2.6104493, -1.7894472]], dtype=float32)

time = 4053	action = 0	current_phase = 0	next_phase = 1	reward = -0.594408	array([[-1.117239 , -1.6372111]], dtype=float32)

time = 4058	action = 0	current_phase = 0	next_phase = 1	reward = -0.455331	array([[-0.87653667, -1.872691  ]], dtype=float32)

time = 4063	action = 0	current_phase = 0	next_phase = 1	reward = -0.299630	array([[-0.764816 , -1.6170222]], dtype=float32)

time = 4068	action = 0	current_phase = 0	next_phase = 1	reward = -0.169430	array([[-1.5569468, -2.1016295]], dtype=float32)

time = 4073	action = 1	current_phase = 0	next_phase = 1	reward = -1.790968	array([[-1.9732512, -1.8070242]], dtype=float32)

time = 4081	action = 0	current_phase = 1	next_phase = 0	reward = -1.710921	array([[-1.1465544, -2.590607 ]], dtype=float32)

time = 4086	action = 1	current_phase = 1	next_phase = 0	reward = -1.810957	array([[-3.1128736, -2.3809612]], dtype=float32)

time = 4094	action = 0	current_phase = 0	next_phase = 1	reward = -0.252653	array([[-0.72964436, -1.6271924 ]], dtype=float32)

time = 4099	action = 0	current_phase = 0	next_phase = 1	reward = -0.187495	array([[-0.86069095, -2.4688027 ]], dtype=float32)

time = 4104	action = 0	current_phase = 0	next_phase = 1	reward = -0.099767	array([[-1.0846623, -1.8385248]], dtype=float32)

time = 4109	action = 1	current_phase = 0	next_phase = 1	reward = -2.015221	array([[-3.3796067, -2.5476623]], dtype=float32)

time = 4117	action = 0	current_phase = 1	next_phase = 0	reward = -0.468458	array([[-0.8016619, -1.872343 ]], dtype=float32)

time = 4122	action = 0	current_phase = 1	next_phase = 0	reward = -0.308531	array([[-0.70507073, -1.8978893 ]], dtype=float32)

time = 4127	action = 0	current_phase = 1	next_phase = 0	reward = -0.174699	array([[-0.60833204, -2.2299001 ]], dtype=float32)

time = 4132	action = 0	current_phase = 1	next_phase = 0	reward = 0.252843	array([[-1.2921538, -2.9810834]], dtype=float32)

time = 4137	action = 1	current_phase = 1	next_phase = 0	reward = -1.781682	array([[-2.9083226, -2.574868 ]], dtype=float32)

time = 4145	action = 0	current_phase = 0	next_phase = 1	reward = -0.530304	array([[-1.0398386, -1.636753 ]], dtype=float32)

time = 4150	action = 0	current_phase = 0	next_phase = 1	reward = -0.375505	array([[-0.82455903, -1.8936546 ]], dtype=float32)

time = 4155	action = 0	current_phase = 0	next_phase = 1	reward = -0.215471	array([[-0.8789888, -2.170381 ]], dtype=float32)

time = 4160	action = 0	current_phase = 0	next_phase = 1	reward = 0.356142	array([[-1.1750863, -2.6518524]], dtype=float32)

time = 4165	action = 1	current_phase = 0	next_phase = 1	reward = -1.314713	array([[-2.587683, -2.070224]], dtype=float32)

time = 4173	action = 0	current_phase = 1	next_phase = 0	reward = -0.605875	array([[-1.4149299, -1.9251751]], dtype=float32)

time = 4178	action = 0	current_phase = 1	next_phase = 0	reward = -0.457784	array([[-0.9023968, -1.9802918]], dtype=float32)

time = 4183	action = 0	current_phase = 1	next_phase = 0	reward = -0.310765	array([[-0.6091579, -1.6545522]], dtype=float32)

time = 4188	action = 0	current_phase = 1	next_phase = 0	reward = -0.177989	array([[-0.91866165, -2.0386558 ]], dtype=float32)

time = 4193	action = 0	current_phase = 1	next_phase = 0	reward = 0.173880	array([[-1.4655027, -2.6190145]], dtype=float32)

time = 4198	action = 1	current_phase = 1	next_phase = 0	reward = -1.897400	array([[-3.4069748, -2.6487465]], dtype=float32)

time = 4206	action = 0	current_phase = 0	next_phase = 1	reward = -0.505816	array([[-1.0244558, -1.6496984]], dtype=float32)

time = 4211	action = 0	current_phase = 0	next_phase = 1	reward = -0.354540	array([[-0.86746824, -1.8780482 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0690 - val_loss: 0.0276

Epoch 2/50

 - 4s - loss: 0.0601 - val_loss: 0.0286

Epoch 3/50

 - 4s - loss: 0.0562 - val_loss: 0.0307

Epoch 4/50

 - 4s - loss: 0.0549 - val_loss: 0.0308

Epoch 5/50

 - 4s - loss: 0.0525 - val_loss: 0.0317

Epoch 6/50

 - 4s - loss: 0.0566 - val_loss: 0.0317

Epoch 7/50

 - 4s - loss: 0.0539 - val_loss: 0.0329

Epoch 8/50

 - 4s - loss: 0.0471 - val_loss: 0.0327

Epoch 9/50

 - 4s - loss: 0.0461 - val_loss: 0.0361

Epoch 10/50

 - 4s - loss: 0.0507 - val_loss: 0.0387

Epoch 11/50

 - 4s - loss: 0.0463 - val_loss: 0.0367

length of memory (state 0, action 0): 829, after forget

length of memory (state 0, action 1): 369, after forget

length of memory (state 1, action 0): 796, after forget

length of memory (state 1, action 1): 357, after forget

time = 4216	action = 0	current_phase = 0	next_phase = 1	reward = -0.206066	array([[-0.9325239, -1.83071  ]], dtype=float32)

time = 4221	action = 0	current_phase = 0	next_phase = 1	reward = 0.306398	array([[-1.480577, -2.457082]], dtype=float32)

time = 4226	action = 1	current_phase = 0	next_phase = 1	reward = -1.558120	array([[-2.8850732, -2.1329286]], dtype=float32)

time = 4234	action = 0	current_phase = 1	next_phase = 0	reward = -0.565152	array([[-0.90381634, -2.0202365 ]], dtype=float32)

time = 4239	action = 0	current_phase = 1	next_phase = 0	reward = -0.414956	array([[-0.8510301, -2.0154138]], dtype=float32)

time = 4244	action = 0	current_phase = 1	next_phase = 0	reward = -0.264531	array([[-0.7786617, -2.009981 ]], dtype=float32)

time = 4249	action = 0	current_phase = 1	next_phase = 0	reward = -0.188835	array([[-1.2001824, -2.4363725]], dtype=float32)

time = 4254	action = 0	current_phase = 1	next_phase = 0	reward = -0.200270	array([[-2.2046776, -2.4972317]], dtype=float32)

time = 4259	action = 1	current_phase = 1	next_phase = 0	reward = -2.004080	array([[-3.5573716, -2.714546 ]], dtype=float32)

time = 4267	action = 0	current_phase = 0	next_phase = 1	reward = -0.456143	array([[-0.93114084, -1.5139537 ]], dtype=float32)

time = 4272	action = 0	current_phase = 0	next_phase = 1	reward = -0.293804	array([[-0.67009604, -1.8773923 ]], dtype=float32)

time = 4277	action = 0	current_phase = 0	next_phase = 1	reward = -0.169421	array([[-1.2548628, -2.0557914]], dtype=float32)

time = 4282	action = 0	current_phase = 0	next_phase = 1	reward = 0.135013	array([[-1.4681962, -3.009975 ]], dtype=float32)

time = 4287	action = 1	current_phase = 0	next_phase = 1	reward = -1.786620	array([[-3.4357028, -2.3671343]], dtype=float32)

time = 4295	action = 0	current_phase = 1	next_phase = 0	reward = -0.529133	array([[-0.96220636, -1.8955772 ]], dtype=float32)

time = 4300	action = 0	current_phase = 1	next_phase = 0	reward = -0.371982	array([[-0.79785097, -2.009336  ]], dtype=float32)

time = 4305	action = 0	current_phase = 1	next_phase = 0	reward = -0.215146	array([[-0.8647274, -2.0177243]], dtype=float32)

time = 4310	action = 0	current_phase = 1	next_phase = 0	reward = 0.358454	array([[-1.0525426, -2.5931811]], dtype=float32)

time = 4315	action = 1	current_phase = 1	next_phase = 0	reward = -1.306604	array([[-2.6335547, -1.8545052]], dtype=float32)

time = 4323	action = 0	current_phase = 0	next_phase = 1	reward = -0.586475	array([[-1.0177981, -1.6821432]], dtype=float32)

time = 4328	action = 0	current_phase = 0	next_phase = 1	reward = -0.434086	array([[-0.8817335, -1.9000778]], dtype=float32)

time = 4333	action = 0	current_phase = 0	next_phase = 1	reward = -0.272559	array([[-0.826212 , -1.3691661]], dtype=float32)

time = 4338	action = 0	current_phase = 0	next_phase = 1	reward = -0.160891	array([[-0.9752677, -2.3433607]], dtype=float32)

time = 4343	action = 0	current_phase = 0	next_phase = 1	reward = 0.012865	array([[-1.8944647, -2.1424184]], dtype=float32)

time = 4348	action = 1	current_phase = 0	next_phase = 1	reward = -1.898556	array([[-3.2187955, -2.7428975]], dtype=float32)

time = 4356	action = 0	current_phase = 1	next_phase = 0	reward = -0.496670	array([[-0.9104302, -1.8327866]], dtype=float32)

time = 4361	action = 0	current_phase = 1	next_phase = 0	reward = -0.340408	array([[-0.7487651, -2.0135393]], dtype=float32)

time = 4366	action = 0	current_phase = 1	next_phase = 0	reward = -0.198499	array([[-0.90438116, -2.0423188 ]], dtype=float32)

time = 4371	action = 0	current_phase = 1	next_phase = 0	reward = 0.313764	array([[-1.4085817, -2.6524634]], dtype=float32)

time = 4376	action = 1	current_phase = 1	next_phase = 0	reward = -1.552221	array([[-2.821785 , -2.2497532]], dtype=float32)

time = 4384	action = 0	current_phase = 0	next_phase = 1	reward = -0.557356	array([[-1.1622988, -1.5193357]], dtype=float32)

time = 4389	action = 0	current_phase = 0	next_phase = 1	reward = -0.400189	array([[-0.90516096, -1.9058065 ]], dtype=float32)

time = 4394	action = 0	current_phase = 0	next_phase = 1	reward = -0.239431	array([[-0.8223532, -1.6296357]], dtype=float32)

time = 4399	action = 0	current_phase = 0	next_phase = 1	reward = -0.180542	array([[-1.3460453, -2.4343715]], dtype=float32)

time = 4404	action = 1	current_phase = 0	next_phase = 1	reward = -0.432722	array([[-2.1093495, -1.8314141]], dtype=float32)

time = 4412	action = 0	current_phase = 1	next_phase = 0	reward = -0.623968	array([[-0.8366554, -2.0115926]], dtype=float32)

time = 4417	action = 0	current_phase = 1	next_phase = 0	reward = -0.477087	array([[-0.32387567, -1.9720247 ]], dtype=float32)

time = 4422	action = 0	current_phase = 1	next_phase = 0	reward = -0.333413	array([[-0.8710011, -1.9348848]], dtype=float32)

time = 4427	action = 0	current_phase = 1	next_phase = 0	reward = -0.186186	array([[-0.82959676, -2.144363  ]], dtype=float32)

time = 4432	action = 0	current_phase = 1	next_phase = 0	reward = 0.267450	array([[-1.4240977, -2.5667896]], dtype=float32)

time = 4437	action = 1	current_phase = 1	next_phase = 0	reward = -1.781624	array([[-3.0436456, -2.5133479]], dtype=float32)

time = 4445	action = 0	current_phase = 0	next_phase = 1	reward = -0.520648	array([[-1.0352844, -1.6557492]], dtype=float32)

time = 4450	action = 0	current_phase = 0	next_phase = 1	reward = -0.368894	array([[-0.84566486, -1.9083052 ]], dtype=float32)

time = 4455	action = 0	current_phase = 0	next_phase = 1	reward = -0.219983	array([[-0.752762 , -1.7472694]], dtype=float32)

time = 4460	action = 0	current_phase = 0	next_phase = 1	reward = 0.357828	array([[-1.2603449, -2.0731215]], dtype=float32)

time = 4465	action = 1	current_phase = 0	next_phase = 1	reward = -1.365910	array([[-2.5383039, -1.9124473]], dtype=float32)

time = 4473	action = 0	current_phase = 1	next_phase = 0	reward = -0.596855	array([[-0.8408252, -2.0106032]], dtype=float32)

time = 4478	action = 0	current_phase = 1	next_phase = 0	reward = -0.441321	array([[-0.81959844, -2.0027583 ]], dtype=float32)

time = 4483	action = 0	current_phase = 1	next_phase = 0	reward = -0.285237	array([[-0.6401291, -1.6720747]], dtype=float32)

time = 4488	action = 0	current_phase = 1	next_phase = 0	reward = -0.167000	array([[-0.7355348, -2.268526 ]], dtype=float32)

time = 4493	action = 0	current_phase = 1	next_phase = 0	reward = 0.055356	array([[-1.2876222, -2.232881 ]], dtype=float32)

time = 4498	action = 1	current_phase = 1	next_phase = 0	reward = -1.890998	array([[-3.6002407, -2.6868496]], dtype=float32)

time = 4506	action = 0	current_phase = 0	next_phase = 1	reward = -0.489307	array([[-0.9722682, -1.5584714]], dtype=float32)

time = 4511	action = 0	current_phase = 0	next_phase = 1	reward = -0.336685	array([[-0.8771194, -1.715707 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0555 - val_loss: 0.0249

Epoch 2/50

 - 4s - loss: 0.0516 - val_loss: 0.0240

Epoch 3/50

 - 4s - loss: 0.0527 - val_loss: 0.0259

Epoch 4/50

 - 4s - loss: 0.0473 - val_loss: 0.0255

Epoch 5/50

 - 4s - loss: 0.0502 - val_loss: 0.0269

Epoch 6/50

 - 4s - loss: 0.0491 - val_loss: 0.0258

Epoch 7/50

 - 4s - loss: 0.0446 - val_loss: 0.0280

Epoch 8/50

 - 4s - loss: 0.0477 - val_loss: 0.0308

Epoch 9/50

 - 4s - loss: 0.0423 - val_loss: 0.0269

Epoch 10/50

 - 4s - loss: 0.0495 - val_loss: 0.0281

Epoch 11/50

 - 4s - loss: 0.0409 - val_loss: 0.0269

Epoch 12/50

 - 4s - loss: 0.0413 - val_loss: 0.0310

length of memory (state 0, action 0): 850, after forget

length of memory (state 0, action 1): 374, after forget

length of memory (state 1, action 0): 819, after forget

length of memory (state 1, action 1): 362, after forget

time = 4516	action = 0	current_phase = 0	next_phase = 1	reward = -0.189993	array([[-0.75472635, -2.085382  ]], dtype=float32)

time = 4521	action = 0	current_phase = 0	next_phase = 1	reward = 0.300430	array([[-1.1752491, -3.079144 ]], dtype=float32)

time = 4526	action = 1	current_phase = 0	next_phase = 1	reward = -1.609002	array([[-3.0659742, -2.4583867]], dtype=float32)

time = 4534	action = 0	current_phase = 1	next_phase = 0	reward = -0.551929	array([[-1.0954058, -1.935631 ]], dtype=float32)

time = 4539	action = 0	current_phase = 1	next_phase = 0	reward = -0.387859	array([[-0.62290394, -2.0167825 ]], dtype=float32)

time = 4544	action = 0	current_phase = 1	next_phase = 0	reward = -0.231150	array([[-0.8666645, -2.0164542]], dtype=float32)

time = 4549	action = 0	current_phase = 1	next_phase = 0	reward = -0.176203	array([[-1.2472049, -2.5056667]], dtype=float32)

time = 4554	action = 0	current_phase = 1	next_phase = 0	reward = -0.136381	array([[-1.7578034, -2.3160996]], dtype=float32)

time = 4559	action = 1	current_phase = 1	next_phase = 0	reward = -2.018497	array([[-3.2132313, -2.7063963]], dtype=float32)

time = 4567	action = 0	current_phase = 0	next_phase = 1	reward = -0.466871	array([[-0.90323067, -1.5681444 ]], dtype=float32)

time = 4572	action = 0	current_phase = 0	next_phase = 1	reward = -0.303091	array([[-0.73492265, -1.655098  ]], dtype=float32)

time = 4577	action = 0	current_phase = 0	next_phase = 1	reward = -0.171412	array([[-0.97765625, -2.0589821 ]], dtype=float32)

time = 4582	action = 0	current_phase = 0	next_phase = 1	reward = 0.256174	array([[-1.7175343, -2.8466842]], dtype=float32)

time = 4587	action = 1	current_phase = 0	next_phase = 1	reward = -1.774665	array([[-3.0581517, -2.346488 ]], dtype=float32)

time = 4595	action = 0	current_phase = 1	next_phase = 0	reward = -0.509842	array([[-1.064085 , -1.9036028]], dtype=float32)

time = 4600	action = 0	current_phase = 1	next_phase = 0	reward = -0.357097	array([[-0.74482334, -1.9902462 ]], dtype=float32)

time = 4605	action = 0	current_phase = 1	next_phase = 0	reward = -0.214224	array([[-0.88186145, -2.0050504 ]], dtype=float32)

time = 4610	action = 0	current_phase = 1	next_phase = 0	reward = 0.056040	array([[-1.3531584, -2.332015 ]], dtype=float32)

time = 4615	action = 1	current_phase = 1	next_phase = 0	reward = -1.030504	array([[-2.5498986, -2.233147 ]], dtype=float32)

time = 4623	action = 0	current_phase = 0	next_phase = 1	reward = -0.572032	array([[-0.92286915, -1.7588737 ]], dtype=float32)

time = 4628	action = 0	current_phase = 0	next_phase = 1	reward = -0.412129	array([[-0.82514834, -1.9294317 ]], dtype=float32)

time = 4633	action = 0	current_phase = 0	next_phase = 1	reward = -0.251828	array([[-0.8715126, -1.6382093]], dtype=float32)

time = 4638	action = 0	current_phase = 0	next_phase = 1	reward = -0.162552	array([[-0.97850835, -2.2667136 ]], dtype=float32)

time = 4643	action = 1	current_phase = 0	next_phase = 1	reward = -0.281158	array([[-2.2582612, -1.9735875]], dtype=float32)

time = 4651	action = 0	current_phase = 1	next_phase = 0	reward = -0.650369	array([[-1.1851933, -2.029335 ]], dtype=float32)

time = 4656	action = 0	current_phase = 1	next_phase = 0	reward = -0.486849	array([[-0.5877221, -1.8800567]], dtype=float32)

time = 4661	action = 0	current_phase = 1	next_phase = 0	reward = -0.326374	array([[-0.6876801, -1.7708026]], dtype=float32)

time = 4666	action = 0	current_phase = 1	next_phase = 0	reward = -0.180943	array([[-0.9265468, -1.9935254]], dtype=float32)

time = 4671	action = 0	current_phase = 1	next_phase = 0	reward = 0.279170	array([[-1.5921867, -2.5683525]], dtype=float32)

time = 4676	action = 1	current_phase = 1	next_phase = 0	reward = -1.609183	array([[-3.2318087, -2.432013 ]], dtype=float32)

time = 4684	action = 0	current_phase = 0	next_phase = 1	reward = -0.560678	array([[-0.93017215, -1.7114437 ]], dtype=float32)

time = 4689	action = 0	current_phase = 0	next_phase = 1	reward = -0.404746	array([[-0.8242083, -1.9216547]], dtype=float32)

time = 4694	action = 0	current_phase = 0	next_phase = 1	reward = -0.254821	array([[-0.780064 , -2.0036898]], dtype=float32)

time = 4699	action = 0	current_phase = 0	next_phase = 1	reward = -0.173526	array([[-0.970105 , -2.3172321]], dtype=float32)

time = 4704	action = 1	current_phase = 0	next_phase = 1	reward = -0.471004	array([[-2.2907574, -1.759335 ]], dtype=float32)

time = 4712	action = 0	current_phase = 1	next_phase = 0	reward = -0.623405	array([[-0.9140452, -1.9956228]], dtype=float32)

time = 4717	action = 0	current_phase = 1	next_phase = 0	reward = -0.476019	array([[-0.43460733, -1.9983397 ]], dtype=float32)

time = 4722	action = 0	current_phase = 1	next_phase = 0	reward = -0.323404	array([[-0.8494272, -1.9602886]], dtype=float32)

time = 4727	action = 0	current_phase = 1	next_phase = 0	reward = -0.178828	array([[-0.8857106, -2.0625057]], dtype=float32)

time = 4732	action = 0	current_phase = 1	next_phase = 0	reward = 0.247944	array([[-1.6544338, -2.6586363]], dtype=float32)

time = 4737	action = 1	current_phase = 1	next_phase = 0	reward = -1.780371	array([[-3.0914917, -2.582779 ]], dtype=float32)

time = 4745	action = 0	current_phase = 0	next_phase = 1	reward = -0.530254	array([[-0.99307233, -1.6945391 ]], dtype=float32)

time = 4750	action = 0	current_phase = 0	next_phase = 1	reward = -0.369942	array([[-0.6500418, -1.9003377]], dtype=float32)

time = 4755	action = 0	current_phase = 0	next_phase = 1	reward = -0.212454	array([[-0.74293745, -1.6007133 ]], dtype=float32)

time = 4760	action = 0	current_phase = 0	next_phase = 1	reward = 0.347960	array([[-1.2074301, -2.4308684]], dtype=float32)

time = 4765	action = 1	current_phase = 0	next_phase = 1	reward = -1.260965	array([[-2.8751638, -2.2174315]], dtype=float32)

time = 4773	action = 0	current_phase = 1	next_phase = 0	reward = -0.588620	array([[-1.1179543, -2.017951 ]], dtype=float32)

time = 4778	action = 0	current_phase = 1	next_phase = 0	reward = -0.430929	array([[-0.63375324, -2.0194328 ]], dtype=float32)

time = 4783	action = 0	current_phase = 1	next_phase = 0	reward = -0.284931	array([[-0.6970395, -1.6390618]], dtype=float32)

time = 4788	action = 0	current_phase = 1	next_phase = 0	reward = -0.173330	array([[-1.0925355, -1.8899598]], dtype=float32)

time = 4793	action = 0	current_phase = 1	next_phase = 0	reward = 0.074101	array([[-1.554368 , -2.3945231]], dtype=float32)

time = 4798	action = 1	current_phase = 1	next_phase = 0	reward = -1.899999	array([[-3.3831272, -2.7427423]], dtype=float32)

time = 4806	action = 0	current_phase = 0	next_phase = 1	reward = -0.501019	array([[-0.95838964, -1.6725788 ]], dtype=float32)

time = 4811	action = 0	current_phase = 0	next_phase = 1	reward = -0.336304	array([[-0.7606853, -1.9139953]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0521 - val_loss: 0.0434

Epoch 2/50

 - 6s - loss: 0.0473 - val_loss: 0.0436

Epoch 3/50

 - 5s - loss: 0.0488 - val_loss: 0.0448

Epoch 4/50

 - 4s - loss: 0.0427 - val_loss: 0.0460

Epoch 5/50

 - 5s - loss: 0.0455 - val_loss: 0.0462

Epoch 6/50

 - 5s - loss: 0.0412 - val_loss: 0.0442

Epoch 7/50

 - 4s - loss: 0.0405 - val_loss: 0.0453

Epoch 8/50

 - 4s - loss: 0.0429 - val_loss: 0.0438

Epoch 9/50

 - 4s - loss: 0.0391 - val_loss: 0.0478

Epoch 10/50

 - 4s - loss: 0.0433 - val_loss: 0.0449

Epoch 11/50

 - 4s - loss: 0.0358 - val_loss: 0.0461

length of memory (state 0, action 0): 870, after forget

length of memory (state 0, action 1): 379, after forget

length of memory (state 1, action 0): 843, after forget

length of memory (state 1, action 1): 367, after forget

time = 4816	action = 0	current_phase = 0	next_phase = 1	reward = -0.190677	array([[-0.9057835, -1.9004812]], dtype=float32)

time = 4821	action = 0	current_phase = 0	next_phase = 1	reward = 0.297001	array([[-1.1677753, -2.9794443]], dtype=float32)

time = 4826	action = 1	current_phase = 0	next_phase = 1	reward = -1.667067	array([[-3.053767 , -2.4840784]], dtype=float32)

time = 4834	action = 0	current_phase = 1	next_phase = 0	reward = -0.567111	array([[-1.1939342, -2.075902 ]], dtype=float32)

time = 4839	action = 0	current_phase = 1	next_phase = 0	reward = -0.409754	array([[-1.0156244, -2.0663996]], dtype=float32)

time = 4844	action = 0	current_phase = 1	next_phase = 0	reward = -0.257402	array([[-0.93684566, -2.0640602 ]], dtype=float32)

time = 4849	action = 0	current_phase = 1	next_phase = 0	reward = -0.170451	array([[-0.9768232, -2.3675647]], dtype=float32)

time = 4854	action = 1	current_phase = 1	next_phase = 0	reward = -0.486779	array([[-2.4512527, -1.5043594]], dtype=float32)

time = 4862	action = 0	current_phase = 0	next_phase = 1	reward = -0.618786	array([[-1.0808886, -1.7686653]], dtype=float32)

time = 4867	action = 0	current_phase = 0	next_phase = 1	reward = -0.470001	array([[-0.87817305, -1.9206734 ]], dtype=float32)

time = 4872	action = 0	current_phase = 0	next_phase = 1	reward = -0.322221	array([[-0.8356289, -1.6207016]], dtype=float32)

time = 4877	action = 0	current_phase = 0	next_phase = 1	reward = -0.183749	array([[-1.0071188, -2.1958554]], dtype=float32)

time = 4882	action = 0	current_phase = 0	next_phase = 1	reward = 0.234002	array([[-1.3080182, -3.0482576]], dtype=float32)

time = 4887	action = 1	current_phase = 0	next_phase = 1	reward = -1.779162	array([[-3.0535812, -2.8352334]], dtype=float32)

time = 4895	action = 0	current_phase = 1	next_phase = 0	reward = -0.525665	array([[-1.0452292, -1.8514589]], dtype=float32)

time = 4900	action = 0	current_phase = 1	next_phase = 0	reward = -0.380915	array([[-1.0758684, -2.0715675]], dtype=float32)

time = 4905	action = 0	current_phase = 1	next_phase = 0	reward = -0.229823	array([[-1.1523983, -2.125907 ]], dtype=float32)

time = 4910	action = 0	current_phase = 1	next_phase = 0	reward = 0.358050	array([[-1.199509 , -2.6207418]], dtype=float32)

time = 4915	action = 1	current_phase = 1	next_phase = 0	reward = -1.314574	array([[-2.3731828, -1.8869557]], dtype=float32)

time = 4923	action = 0	current_phase = 0	next_phase = 1	reward = -0.588831	array([[-0.98436457, -1.7321836 ]], dtype=float32)

time = 4928	action = 0	current_phase = 0	next_phase = 1	reward = -0.434409	array([[-0.85598147, -1.9334594 ]], dtype=float32)

time = 4933	action = 0	current_phase = 0	next_phase = 1	reward = -0.284650	array([[-1.1143795, -1.6295756]], dtype=float32)

time = 4938	action = 0	current_phase = 0	next_phase = 1	reward = -0.165217	array([[-1.0754563, -2.1658533]], dtype=float32)

time = 4943	action = 0	current_phase = 0	next_phase = 1	reward = -0.034388	array([[-1.3111911, -2.1938026]], dtype=float32)

time = 4948	action = 1	current_phase = 0	next_phase = 1	reward = -1.907291	array([[-3.5340028, -2.90574  ]], dtype=float32)

time = 4956	action = 0	current_phase = 1	next_phase = 0	reward = -0.497873	array([[-1.1154367, -1.8759836]], dtype=float32)

time = 4961	action = 0	current_phase = 1	next_phase = 0	reward = -0.340357	array([[-0.9142816, -1.9773687]], dtype=float32)

time = 4966	action = 0	current_phase = 1	next_phase = 0	reward = -0.194673	array([[-1.0947841, -2.0503654]], dtype=float32)

time = 4971	action = 0	current_phase = 1	next_phase = 0	reward = 0.289638	array([[-1.5893435, -2.9891615]], dtype=float32)

time = 4976	action = 1	current_phase = 1	next_phase = 0	reward = -1.613236	array([[-3.6480076, -2.3296328]], dtype=float32)

time = 4984	action = 0	current_phase = 0	next_phase = 1	reward = -0.561738	array([[-1.1180794, -1.634192 ]], dtype=float32)

time = 4989	action = 0	current_phase = 0	next_phase = 1	reward = -0.406661	array([[-0.9230244, -1.9154061]], dtype=float32)

time = 4994	action = 0	current_phase = 0	next_phase = 1	reward = -0.254599	array([[-0.8653437, -1.7226964]], dtype=float32)

time = 4999	action = 0	current_phase = 0	next_phase = 1	reward = -0.180978	array([[-1.3760189, -2.45126  ]], dtype=float32)

time = 5004	action = 1	current_phase = 0	next_phase = 1	reward = -0.515203	array([[-2.0669894, -1.8631241]], dtype=float32)

time = 5012	action = 0	current_phase = 1	next_phase = 0	reward = -0.622325	array([[-1.3853805, -2.0040848]], dtype=float32)

time = 5017	action = 0	current_phase = 1	next_phase = 0	reward = -0.466322	array([[-0.7203214, -2.0263839]], dtype=float32)

time = 5022	action = 0	current_phase = 1	next_phase = 0	reward = -0.304929	array([[-1.0234175, -1.7000105]], dtype=float32)

time = 5027	action = 0	current_phase = 1	next_phase = 0	reward = -0.170662	array([[-1.1351187, -2.0362046]], dtype=float32)

time = 5032	action = 0	current_phase = 1	next_phase = 0	reward = 0.182707	array([[-1.4381852, -2.4337   ]], dtype=float32)

time = 5037	action = 1	current_phase = 1	next_phase = 0	reward = -1.779587	array([[-3.137494, -2.529562]], dtype=float32)

time = 5045	action = 0	current_phase = 0	next_phase = 1	reward = -0.516113	array([[-1.0915669, -1.7089978]], dtype=float32)

time = 5050	action = 0	current_phase = 0	next_phase = 1	reward = -0.349737	array([[-0.89193505, -1.957154  ]], dtype=float32)

time = 5055	action = 0	current_phase = 0	next_phase = 1	reward = -0.200370	array([[-0.8792061, -1.9246725]], dtype=float32)

time = 5060	action = 0	current_phase = 0	next_phase = 1	reward = 0.333416	array([[-0.7964172, -2.2099097]], dtype=float32)

time = 5065	action = 1	current_phase = 0	next_phase = 1	reward = -1.374256	array([[-2.8787236, -2.2674484]], dtype=float32)

time = 5073	action = 0	current_phase = 1	next_phase = 0	reward = -0.588421	array([[-0.99939597, -2.0328069 ]], dtype=float32)

time = 5078	action = 0	current_phase = 1	next_phase = 0	reward = -0.432185	array([[-1.0210314, -2.0670655]], dtype=float32)

time = 5083	action = 0	current_phase = 1	next_phase = 0	reward = -0.268721	array([[-0.8156558, -1.805219 ]], dtype=float32)

time = 5088	action = 0	current_phase = 1	next_phase = 0	reward = -0.162192	array([[-1.2788061, -2.1878805]], dtype=float32)

time = 5093	action = 1	current_phase = 1	next_phase = 0	reward = -1.064273	array([[-2.464429 , -1.9261024]], dtype=float32)

time = 5101	action = 1	current_phase = 0	next_phase = 1	reward = -2.009414	array([[-2.6714115, -2.3328686]], dtype=float32)

time = 5109	action = 0	current_phase = 1	next_phase = 0	reward = -0.401968	array([[-1.1121031, -2.073153 ]], dtype=float32)

time = 5114	action = 0	current_phase = 1	next_phase = 0	reward = -0.236297	array([[-0.85284615, -2.1322188 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0590 - val_loss: 0.0533

Epoch 2/50

 - 4s - loss: 0.0535 - val_loss: 0.0540

Epoch 3/50

 - 4s - loss: 0.0548 - val_loss: 0.0531

Epoch 4/50

 - 4s - loss: 0.0543 - val_loss: 0.0510

Epoch 5/50

 - 4s - loss: 0.0501 - val_loss: 0.0535

Epoch 6/50

 - 4s - loss: 0.0543 - val_loss: 0.0562

Epoch 7/50

 - 4s - loss: 0.0492 - val_loss: 0.0564

Epoch 8/50

 - 4s - loss: 0.0516 - val_loss: 0.0549

Epoch 9/50

 - 4s - loss: 0.0526 - val_loss: 0.0578

Epoch 10/50

 - 4s - loss: 0.0443 - val_loss: 0.0556

Epoch 11/50

 - 4s - loss: 0.0494 - val_loss: 0.0551

Epoch 12/50

 - 4s - loss: 0.0491 - val_loss: 0.0591

Epoch 13/50

 - 4s - loss: 0.0467 - val_loss: 0.0575

Epoch 14/50

 - 4s - loss: 0.0436 - val_loss: 0.0570

length of memory (state 0, action 0): 890, after forget

length of memory (state 0, action 1): 385, after forget

length of memory (state 1, action 0): 866, after forget

length of memory (state 1, action 1): 372, after forget

time = 5119	action = 0	current_phase = 1	next_phase = 0	reward = -0.171703	array([[-1.0932481, -2.5811195]], dtype=float32)

time = 5124	action = 0	current_phase = 1	next_phase = 0	reward = -0.125698	array([[-0.98747474, -1.5316784 ]], dtype=float32)

time = 5129	action = 0	current_phase = 1	next_phase = 0	reward = -1.604218	array([[-2.1508257, -2.8030243]], dtype=float32)

time = 5134	action = 1	current_phase = 1	next_phase = 0	reward = -1.909493	array([[-3.431641, -2.49467 ]], dtype=float32)

time = 5142	action = 0	current_phase = 0	next_phase = 1	reward = -0.310091	array([[-0.8695283, -1.7525423]], dtype=float32)

time = 5147	action = 0	current_phase = 0	next_phase = 1	reward = -0.177129	array([[-1.01968  , -2.0897152]], dtype=float32)

time = 5152	action = 0	current_phase = 0	next_phase = 1	reward = 0.172955	array([[-1.3216866, -2.916877 ]], dtype=float32)

time = 5157	action = 1	current_phase = 0	next_phase = 1	reward = -1.680865	array([[-3.2965758, -2.5999556]], dtype=float32)

time = 5165	action = 0	current_phase = 1	next_phase = 0	reward = -0.526195	array([[-1.0365882, -1.9342837]], dtype=float32)

time = 5170	action = 0	current_phase = 1	next_phase = 0	reward = -0.361996	array([[-1.1818047, -1.9986718]], dtype=float32)

time = 5175	action = 0	current_phase = 1	next_phase = 0	reward = -0.204495	array([[-1.1361651, -2.148917 ]], dtype=float32)

time = 5180	action = 0	current_phase = 1	next_phase = 0	reward = 0.366673	array([[-1.3654003, -2.7563598]], dtype=float32)

time = 5185	action = 1	current_phase = 1	next_phase = 0	reward = -1.310171	array([[-3.120945, -2.327171]], dtype=float32)

time = 5193	action = 0	current_phase = 0	next_phase = 1	reward = -0.586869	array([[-1.1253872, -1.6980599]], dtype=float32)

time = 5198	action = 0	current_phase = 0	next_phase = 1	reward = -0.436376	array([[-0.97251517, -1.9521149 ]], dtype=float32)

time = 5203	action = 0	current_phase = 0	next_phase = 1	reward = -0.282610	array([[-1.02706  , -1.5127859]], dtype=float32)

time = 5208	action = 0	current_phase = 0	next_phase = 1	reward = -0.162277	array([[-1.7250205, -2.3387363]], dtype=float32)

time = 5213	action = 0	current_phase = 0	next_phase = 1	reward = 0.033809	array([[-2.255532 , -2.5672936]], dtype=float32)

time = 5218	action = 1	current_phase = 0	next_phase = 1	reward = -1.898981	array([[-3.2752783, -2.7545166]], dtype=float32)

time = 5226	action = 0	current_phase = 1	next_phase = 0	reward = -0.499261	array([[-1.1707771, -1.8555946]], dtype=float32)

time = 5231	action = 0	current_phase = 1	next_phase = 0	reward = -0.352891	array([[-0.93924826, -1.9579732 ]], dtype=float32)

time = 5236	action = 0	current_phase = 1	next_phase = 0	reward = -0.210693	array([[-1.0820956, -2.2314951]], dtype=float32)

time = 5241	action = 0	current_phase = 1	next_phase = 0	reward = 0.305559	array([[-1.5929506, -2.6028733]], dtype=float32)

time = 5246	action = 1	current_phase = 1	next_phase = 0	reward = -1.615887	array([[-3.300564 , -2.4753494]], dtype=float32)

time = 5254	action = 0	current_phase = 0	next_phase = 1	reward = -0.562567	array([[-1.2130482, -1.6421605]], dtype=float32)

time = 5259	action = 0	current_phase = 0	next_phase = 1	reward = -0.410248	array([[-0.98358077, -1.9424714 ]], dtype=float32)

time = 5264	action = 0	current_phase = 0	next_phase = 1	reward = -0.248983	array([[-0.9374385, -1.7843337]], dtype=float32)

time = 5269	action = 0	current_phase = 0	next_phase = 1	reward = -0.172819	array([[-1.8832843, -2.283916 ]], dtype=float32)

time = 5274	action = 1	current_phase = 0	next_phase = 1	reward = -0.542443	array([[-2.5094714, -2.072139 ]], dtype=float32)

time = 5282	action = 0	current_phase = 1	next_phase = 0	reward = -0.616318	array([[-1.1029935, -2.045689 ]], dtype=float32)

time = 5287	action = 0	current_phase = 1	next_phase = 0	reward = -0.464359	array([[-0.9738191, -2.0837753]], dtype=float32)

time = 5292	action = 0	current_phase = 1	next_phase = 0	reward = -0.312963	array([[-1.0229638, -2.080062 ]], dtype=float32)

time = 5297	action = 0	current_phase = 1	next_phase = 0	reward = -0.180073	array([[-1.0740646, -2.1252143]], dtype=float32)

time = 5302	action = 0	current_phase = 1	next_phase = 0	reward = 0.224366	array([[-1.3989575, -2.483244 ]], dtype=float32)

time = 5307	action = 1	current_phase = 1	next_phase = 0	reward = -1.787543	array([[-3.403433 , -2.6581385]], dtype=float32)

time = 5315	action = 0	current_phase = 0	next_phase = 1	reward = -0.529533	array([[-1.3175703, -1.4666797]], dtype=float32)

time = 5320	action = 0	current_phase = 0	next_phase = 1	reward = -0.378062	array([[-0.94204605, -1.9628254 ]], dtype=float32)

time = 5325	action = 0	current_phase = 0	next_phase = 1	reward = -0.219326	array([[-1.0041909, -1.7970219]], dtype=float32)

time = 5330	action = 0	current_phase = 0	next_phase = 1	reward = 0.371291	array([[-1.5662075, -1.9596537]], dtype=float32)

time = 5335	action = 1	current_phase = 0	next_phase = 1	reward = -1.299806	array([[-2.8352613, -2.251249 ]], dtype=float32)

time = 5343	action = 0	current_phase = 1	next_phase = 0	reward = -0.579092	array([[-1.175611 , -2.0384002]], dtype=float32)

time = 5348	action = 0	current_phase = 1	next_phase = 0	reward = -0.424144	array([[-0.9574804, -2.06731  ]], dtype=float32)

time = 5353	action = 0	current_phase = 1	next_phase = 0	reward = -0.276913	array([[-0.96617293, -2.0358407 ]], dtype=float32)

time = 5358	action = 0	current_phase = 1	next_phase = 0	reward = -0.166986	array([[-1.3460631, -2.0585206]], dtype=float32)

time = 5363	action = 0	current_phase = 1	next_phase = 0	reward = 0.077421	array([[-2.013204 , -2.5588412]], dtype=float32)

time = 5368	action = 1	current_phase = 1	next_phase = 0	reward = -1.896378	array([[-3.5426526, -2.4673805]], dtype=float32)

time = 5376	action = 0	current_phase = 0	next_phase = 1	reward = -0.504729	array([[-1.0376292, -1.506851 ]], dtype=float32)

time = 5381	action = 0	current_phase = 0	next_phase = 1	reward = -0.357629	array([[-0.95622766, -1.9434631 ]], dtype=float32)

time = 5386	action = 0	current_phase = 0	next_phase = 1	reward = -0.202659	array([[-1.0889388, -2.1670759]], dtype=float32)

time = 5391	action = 0	current_phase = 0	next_phase = 1	reward = 0.313219	array([[-1.1808858, -2.850043 ]], dtype=float32)

time = 5396	action = 1	current_phase = 0	next_phase = 1	reward = -1.556759	array([[-3.165279, -2.580492]], dtype=float32)

time = 5404	action = 0	current_phase = 1	next_phase = 0	reward = -0.554399	array([[-1.1360079, -2.0686924]], dtype=float32)

time = 5409	action = 0	current_phase = 1	next_phase = 0	reward = -0.394638	array([[-1.153924 , -2.1004157]], dtype=float32)

time = 5414	action = 0	current_phase = 1	next_phase = 0	reward = -0.234203	array([[-1.1204917, -2.0939486]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0450 - val_loss: 0.0400

Epoch 2/50

 - 4s - loss: 0.0471 - val_loss: 0.0419

Epoch 3/50

 - 5s - loss: 0.0465 - val_loss: 0.0420

Epoch 4/50

 - 5s - loss: 0.0409 - val_loss: 0.0416

Epoch 5/50

 - 5s - loss: 0.0388 - val_loss: 0.0438

Epoch 6/50

 - 4s - loss: 0.0409 - val_loss: 0.0448

Epoch 7/50

 - 4s - loss: 0.0385 - val_loss: 0.0484

Epoch 8/50

 - 5s - loss: 0.0346 - val_loss: 0.0497

Epoch 9/50

 - 4s - loss: 0.0407 - val_loss: 0.0466

Epoch 10/50

 - 4s - loss: 0.0338 - val_loss: 0.0496

Epoch 11/50

 - 5s - loss: 0.0391 - val_loss: 0.0511

length of memory (state 0, action 0): 910, after forget

length of memory (state 0, action 1): 390, after forget

length of memory (state 1, action 0): 890, after forget

length of memory (state 1, action 1): 377, after forget

time = 5419	action = 0	current_phase = 1	next_phase = 0	reward = -0.175185	array([[-1.4891776, -2.5024593]], dtype=float32)

time = 5424	action = 1	current_phase = 1	next_phase = 0	reward = -0.536615	array([[-2.0271475, -1.6277962]], dtype=float32)

time = 5432	action = 0	current_phase = 0	next_phase = 1	reward = -0.623833	array([[-1.0856271, -1.7007895]], dtype=float32)

time = 5437	action = 0	current_phase = 0	next_phase = 1	reward = -0.459628	array([[-0.89190537, -1.8252413 ]], dtype=float32)

time = 5442	action = 0	current_phase = 0	next_phase = 1	reward = -0.299806	array([[-1.0083609, -1.545623 ]], dtype=float32)

time = 5447	action = 0	current_phase = 0	next_phase = 1	reward = -0.169300	array([[-1.2304176, -2.1601427]], dtype=float32)

time = 5452	action = 0	current_phase = 0	next_phase = 1	reward = 0.248942	array([[-1.2615651, -2.805328 ]], dtype=float32)

time = 5457	action = 1	current_phase = 0	next_phase = 1	reward = -1.680323	array([[-3.300262 , -2.5845187]], dtype=float32)

time = 5465	action = 0	current_phase = 1	next_phase = 0	reward = -0.530239	array([[-1.3550816, -1.9599669]], dtype=float32)

time = 5470	action = 0	current_phase = 1	next_phase = 0	reward = -0.371027	array([[-1.2755413, -2.1350656]], dtype=float32)

time = 5475	action = 0	current_phase = 1	next_phase = 0	reward = -0.224279	array([[-1.2121844, -2.154779 ]], dtype=float32)

time = 5480	action = 0	current_phase = 1	next_phase = 0	reward = 0.068689	array([[-1.3977267, -2.6641407]], dtype=float32)

time = 5485	action = 1	current_phase = 1	next_phase = 0	reward = -1.078987	array([[-2.5867918, -2.167696 ]], dtype=float32)

time = 5493	action = 0	current_phase = 0	next_phase = 1	reward = -0.595419	array([[-1.0715744, -1.6870447]], dtype=float32)

time = 5498	action = 0	current_phase = 0	next_phase = 1	reward = -0.446498	array([[-0.92672455, -1.9194002 ]], dtype=float32)

time = 5503	action = 0	current_phase = 0	next_phase = 1	reward = -0.293574	array([[-1.0187287, -1.6193395]], dtype=float32)

time = 5508	action = 0	current_phase = 0	next_phase = 1	reward = -0.169585	array([[-1.0601904, -2.2256908]], dtype=float32)

time = 5513	action = 0	current_phase = 0	next_phase = 1	reward = 0.155680	array([[-1.7268711, -2.498894 ]], dtype=float32)

time = 5518	action = 1	current_phase = 0	next_phase = 1	reward = -1.896837	array([[-3.5273905, -2.5942214]], dtype=float32)

time = 5526	action = 0	current_phase = 1	next_phase = 0	reward = -0.498433	array([[-1.1863182, -1.8762139]], dtype=float32)

time = 5531	action = 0	current_phase = 1	next_phase = 0	reward = -0.355393	array([[-0.9888871, -2.0280116]], dtype=float32)

time = 5536	action = 0	current_phase = 1	next_phase = 0	reward = -0.203428	array([[-1.1526414, -2.2112827]], dtype=float32)

time = 5541	action = 0	current_phase = 1	next_phase = 0	reward = 0.329895	array([[-1.889361 , -2.6937168]], dtype=float32)

time = 5546	action = 1	current_phase = 1	next_phase = 0	reward = -1.501529	array([[-3.2559402, -2.256721 ]], dtype=float32)

time = 5554	action = 0	current_phase = 0	next_phase = 1	reward = -0.554333	array([[-1.0321983, -1.7063801]], dtype=float32)

time = 5559	action = 0	current_phase = 0	next_phase = 1	reward = -0.397683	array([[-0.8797774, -1.9135743]], dtype=float32)

time = 5564	action = 0	current_phase = 0	next_phase = 1	reward = -0.240970	array([[-0.938389 , -1.6657431]], dtype=float32)

time = 5569	action = 0	current_phase = 0	next_phase = 1	reward = -0.183050	array([[-1.5296993, -2.445919 ]], dtype=float32)

time = 5574	action = 0	current_phase = 0	next_phase = 1	reward = -0.094440	array([[-1.8289179, -1.9341418]], dtype=float32)

time = 5579	action = 1	current_phase = 0	next_phase = 1	reward = -2.013997	array([[-3.493309 , -2.7778833]], dtype=float32)

time = 5587	action = 0	current_phase = 1	next_phase = 0	reward = -0.479286	array([[-1.1905745, -2.0015879]], dtype=float32)

time = 5592	action = 0	current_phase = 1	next_phase = 0	reward = -0.333233	array([[-0.98020005, -2.0858839 ]], dtype=float32)

time = 5597	action = 0	current_phase = 1	next_phase = 0	reward = -0.195032	array([[-1.1766714, -2.167321 ]], dtype=float32)

time = 5602	action = 0	current_phase = 1	next_phase = 0	reward = 0.206336	array([[-1.7053592, -2.9517949]], dtype=float32)

time = 5607	action = 1	current_phase = 1	next_phase = 0	reward = -1.727989	array([[-3.572026 , -2.4837384]], dtype=float32)

time = 5615	action = 0	current_phase = 0	next_phase = 1	reward = -0.519644	array([[-1.0505617, -1.7189544]], dtype=float32)

time = 5620	action = 0	current_phase = 0	next_phase = 1	reward = -0.370649	array([[-0.8894193, -1.7421651]], dtype=float32)

time = 5625	action = 0	current_phase = 0	next_phase = 1	reward = -0.211638	array([[-0.95099497, -1.855694  ]], dtype=float32)

time = 5630	action = 0	current_phase = 0	next_phase = 1	reward = 0.064751	array([[-1.2990566, -2.4237669]], dtype=float32)

time = 5635	action = 1	current_phase = 0	next_phase = 1	reward = -1.032022	array([[-2.3679638, -2.0903206]], dtype=float32)

time = 5643	action = 0	current_phase = 1	next_phase = 0	reward = -0.588844	array([[-1.1228303, -2.0773625]], dtype=float32)

time = 5648	action = 0	current_phase = 1	next_phase = 0	reward = -0.426494	array([[-1.0061687, -2.0943766]], dtype=float32)

time = 5653	action = 0	current_phase = 1	next_phase = 0	reward = -0.264503	array([[-0.9738077, -1.9030327]], dtype=float32)

time = 5658	action = 0	current_phase = 1	next_phase = 0	reward = -0.156235	array([[-1.3500069, -2.158057 ]], dtype=float32)

time = 5663	action = 1	current_phase = 1	next_phase = 0	reward = -0.251980	array([[-1.8790699, -1.6469748]], dtype=float32)

time = 5671	action = 0	current_phase = 0	next_phase = 1	reward = -0.656118	array([[-1.2046535, -1.7983074]], dtype=float32)

time = 5676	action = 0	current_phase = 0	next_phase = 1	reward = -0.503851	array([[-0.9207519, -1.8594197]], dtype=float32)

time = 5681	action = 0	current_phase = 0	next_phase = 1	reward = -0.349489	array([[-0.83898824, -1.738656  ]], dtype=float32)

time = 5686	action = 0	current_phase = 0	next_phase = 1	reward = -0.194002	array([[-0.8898393, -1.9961133]], dtype=float32)

time = 5691	action = 0	current_phase = 0	next_phase = 1	reward = 0.319022	array([[-1.0432491, -2.677244 ]], dtype=float32)

time = 5696	action = 1	current_phase = 0	next_phase = 1	reward = -1.559909	array([[-3.0832148, -2.6488454]], dtype=float32)

time = 5704	action = 0	current_phase = 1	next_phase = 0	reward = -0.565511	array([[-1.2379925, -2.0192657]], dtype=float32)

time = 5709	action = 0	current_phase = 1	next_phase = 0	reward = -0.405059	array([[-1.1424845, -2.1220229]], dtype=float32)

time = 5714	action = 0	current_phase = 1	next_phase = 0	reward = -0.265746	array([[-1.2204545, -2.1287599]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0512 - val_loss: 0.0300

Epoch 2/50

 - 4s - loss: 0.0532 - val_loss: 0.0321

Epoch 3/50

 - 4s - loss: 0.0477 - val_loss: 0.0318

Epoch 4/50

 - 4s - loss: 0.0473 - val_loss: 0.0337

Epoch 5/50

 - 4s - loss: 0.0478 - val_loss: 0.0324

Epoch 6/50

 - 4s - loss: 0.0496 - val_loss: 0.0333

Epoch 7/50

 - 4s - loss: 0.0454 - val_loss: 0.0352

Epoch 8/50

 - 4s - loss: 0.0470 - val_loss: 0.0349

Epoch 9/50

 - 4s - loss: 0.0442 - val_loss: 0.0334

Epoch 10/50

 - 4s - loss: 0.0402 - val_loss: 0.0341

Epoch 11/50

 - 4s - loss: 0.0462 - val_loss: 0.0352

length of memory (state 0, action 0): 934, after forget

length of memory (state 0, action 1): 395, after forget

length of memory (state 1, action 0): 910, after forget

length of memory (state 1, action 1): 382, after forget

time = 5719	action = 0	current_phase = 1	next_phase = 0	reward = -0.177005	array([[-1.4237616, -2.5111098]], dtype=float32)

time = 5724	action = 1	current_phase = 1	next_phase = 0	reward = -0.432513	array([[-2.396419 , -1.6002517]], dtype=float32)

time = 5732	action = 0	current_phase = 0	next_phase = 1	reward = -0.615915	array([[-1.1032116, -1.7525535]], dtype=float32)

time = 5737	action = 0	current_phase = 0	next_phase = 1	reward = -0.454710	array([[-1.0419688, -1.9151772]], dtype=float32)

time = 5742	action = 0	current_phase = 0	next_phase = 1	reward = -0.297913	array([[-0.929198 , -1.7647985]], dtype=float32)

time = 5747	action = 0	current_phase = 0	next_phase = 1	reward = -0.168640	array([[-1.0628546, -1.7168666]], dtype=float32)

time = 5752	action = 0	current_phase = 0	next_phase = 1	reward = 0.113177	array([[-1.0801393, -2.786329 ]], dtype=float32)

time = 5757	action = 1	current_phase = 0	next_phase = 1	reward = -1.782726	array([[-3.6530213, -2.8331366]], dtype=float32)

time = 5765	action = 0	current_phase = 1	next_phase = 0	reward = -0.523694	array([[-1.0623769, -1.9728906]], dtype=float32)

time = 5770	action = 0	current_phase = 1	next_phase = 0	reward = -0.357509	array([[-0.99601185, -2.0945752 ]], dtype=float32)

time = 5775	action = 0	current_phase = 1	next_phase = 0	reward = -0.211015	array([[-1.2433714, -2.1243277]], dtype=float32)

time = 5780	action = 0	current_phase = 1	next_phase = 0	reward = 0.048638	array([[-1.6835755, -2.6674025]], dtype=float32)

time = 5785	action = 1	current_phase = 1	next_phase = 0	reward = -1.087800	array([[-3.11244  , -2.1914716]], dtype=float32)

time = 5793	action = 0	current_phase = 0	next_phase = 1	reward = -0.583123	array([[-1.1236168, -1.7287905]], dtype=float32)

time = 5798	action = 0	current_phase = 0	next_phase = 1	reward = -0.432320	array([[-0.85313135, -2.0051973 ]], dtype=float32)

time = 5803	action = 0	current_phase = 0	next_phase = 1	reward = -0.275853	array([[-0.98912024, -1.4280765 ]], dtype=float32)

time = 5808	action = 0	current_phase = 0	next_phase = 1	reward = -0.164523	array([[-1.8452002, -2.3678002]], dtype=float32)

time = 5813	action = 0	current_phase = 0	next_phase = 1	reward = 0.052628	array([[-2.1357315, -2.5899172]], dtype=float32)

time = 5818	action = 1	current_phase = 0	next_phase = 1	reward = -1.899728	array([[-3.4464662, -2.8272226]], dtype=float32)

time = 5826	action = 0	current_phase = 1	next_phase = 0	reward = -0.495790	array([[-1.0573566, -1.9631474]], dtype=float32)

time = 5831	action = 0	current_phase = 1	next_phase = 0	reward = -0.348277	array([[-0.98257613, -2.0758524 ]], dtype=float32)

time = 5836	action = 0	current_phase = 1	next_phase = 0	reward = -0.204668	array([[-1.2086489, -2.1197112]], dtype=float32)

time = 5841	action = 0	current_phase = 1	next_phase = 0	reward = 0.298689	array([[-1.5736219, -2.6377351]], dtype=float32)

time = 5846	action = 1	current_phase = 1	next_phase = 0	reward = -1.555951	array([[-3.434544 , -2.4667175]], dtype=float32)

time = 5854	action = 0	current_phase = 0	next_phase = 1	reward = -0.553079	array([[-1.124822 , -1.7311504]], dtype=float32)

time = 5859	action = 0	current_phase = 0	next_phase = 1	reward = -0.396042	array([[-1.0117949, -1.9063597]], dtype=float32)

time = 5864	action = 0	current_phase = 0	next_phase = 1	reward = -0.243872	array([[-0.9967435, -1.6964635]], dtype=float32)

time = 5869	action = 0	current_phase = 0	next_phase = 1	reward = -0.191070	array([[-1.707766, -2.113492]], dtype=float32)

time = 5874	action = 1	current_phase = 0	next_phase = 1	reward = -0.512719	array([[-2.2622604, -1.7020855]], dtype=float32)

time = 5882	action = 0	current_phase = 1	next_phase = 0	reward = -0.626422	array([[-1.0808277, -2.0546227]], dtype=float32)

time = 5887	action = 0	current_phase = 1	next_phase = 0	reward = -0.470262	array([[-0.83402973, -2.086171  ]], dtype=float32)

time = 5892	action = 0	current_phase = 1	next_phase = 0	reward = -0.316518	array([[-0.92790926, -1.8763587 ]], dtype=float32)

time = 5897	action = 0	current_phase = 1	next_phase = 0	reward = -0.175410	array([[-1.2419302, -2.158134 ]], dtype=float32)

time = 5902	action = 0	current_phase = 1	next_phase = 0	reward = 0.278848	array([[-1.6343591, -2.6162608]], dtype=float32)

time = 5907	action = 1	current_phase = 1	next_phase = 0	reward = -1.624585	array([[-3.4871078, -2.540775 ]], dtype=float32)

time = 5915	action = 0	current_phase = 0	next_phase = 1	reward = -0.523963	array([[-1.0356169, -1.55213  ]], dtype=float32)

time = 5920	action = 0	current_phase = 0	next_phase = 1	reward = -0.367974	array([[-0.9591359, -1.9533579]], dtype=float32)

time = 5925	action = 0	current_phase = 0	next_phase = 1	reward = -0.218269	array([[-1.0360862, -1.8856375]], dtype=float32)

time = 5930	action = 0	current_phase = 0	next_phase = 1	reward = 0.354376	array([[-1.7022601, -2.3961315]], dtype=float32)

time = 5935	action = 1	current_phase = 0	next_phase = 1	reward = -1.364648	array([[-2.3900502, -1.8770267]], dtype=float32)

time = 5943	action = 0	current_phase = 1	next_phase = 0	reward = -0.592904	array([[-1.084518 , -2.0796542]], dtype=float32)

time = 5948	action = 0	current_phase = 1	next_phase = 0	reward = -0.435149	array([[-0.9605802, -2.0876381]], dtype=float32)

time = 5953	action = 0	current_phase = 1	next_phase = 0	reward = -0.278413	array([[-0.8053134, -1.7348638]], dtype=float32)

time = 5958	action = 0	current_phase = 1	next_phase = 0	reward = -0.163351	array([[-1.3761276, -2.1296942]], dtype=float32)

time = 5963	action = 0	current_phase = 1	next_phase = 0	reward = 0.061461	array([[-2.1722467, -2.2975338]], dtype=float32)

time = 5968	action = 1	current_phase = 1	next_phase = 0	reward = -1.849125	array([[-3.5847893, -2.734957 ]], dtype=float32)

time = 5976	action = 0	current_phase = 0	next_phase = 1	reward = -0.503651	array([[-1.0325673, -1.5448225]], dtype=float32)

time = 5981	action = 0	current_phase = 0	next_phase = 1	reward = -0.354212	array([[-0.84800434, -1.9548085 ]], dtype=float32)

time = 5986	action = 0	current_phase = 0	next_phase = 1	reward = -0.200757	array([[-1.2032553, -2.0782337]], dtype=float32)

time = 5991	action = 0	current_phase = 0	next_phase = 1	reward = 0.300332	array([[-1.5955957, -2.6594925]], dtype=float32)

time = 5996	action = 1	current_phase = 0	next_phase = 1	reward = -1.610335	array([[-3.1296852, -2.5224745]], dtype=float32)

time = 6004	action = 0	current_phase = 1	next_phase = 0	reward = -0.554709	array([[-0.9931264, -2.0601153]], dtype=float32)

time = 6009	action = 0	current_phase = 1	next_phase = 0	reward = -0.395657	array([[-1.1736231, -2.1213357]], dtype=float32)

time = 6014	action = 0	current_phase = 1	next_phase = 0	reward = -0.233914	array([[-1.1523578, -2.046522 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0461 - val_loss: 0.0285

Epoch 2/50

 - 4s - loss: 0.0427 - val_loss: 0.0284

Epoch 3/50

 - 4s - loss: 0.0443 - val_loss: 0.0278

Epoch 4/50

 - 4s - loss: 0.0447 - val_loss: 0.0315

Epoch 5/50

 - 4s - loss: 0.0436 - val_loss: 0.0321

Epoch 6/50

 - 5s - loss: 0.0439 - val_loss: 0.0313

Epoch 7/50

 - 4s - loss: 0.0382 - val_loss: 0.0322

Epoch 8/50

 - 4s - loss: 0.0378 - val_loss: 0.0347

Epoch 9/50

 - 4s - loss: 0.0402 - val_loss: 0.0334

Epoch 10/50

 - 4s - loss: 0.0315 - val_loss: 0.0330

Epoch 11/50

 - 5s - loss: 0.0366 - val_loss: 0.0319

Epoch 12/50

 - 4s - loss: 0.0378 - val_loss: 0.0349

Epoch 13/50

 - 4s - loss: 0.0427 - val_loss: 0.0349

length of memory (state 0, action 0): 956, after forget

length of memory (state 0, action 1): 400, after forget

length of memory (state 1, action 0): 932, after forget

length of memory (state 1, action 1): 387, after forget

time = 6019	action = 0	current_phase = 1	next_phase = 0	reward = -0.176538	array([[-1.4197772, -2.4213202]], dtype=float32)

time = 6024	action = 1	current_phase = 1	next_phase = 0	reward = -0.533746	array([[-2.4062488, -1.5405142]], dtype=float32)

time = 6032	action = 0	current_phase = 0	next_phase = 1	reward = -0.627089	array([[-1.1677018, -1.74558  ]], dtype=float32)

time = 6037	action = 0	current_phase = 0	next_phase = 1	reward = -0.477380	array([[-0.9875879, -1.9150512]], dtype=float32)

time = 6042	action = 0	current_phase = 0	next_phase = 1	reward = -0.328395	array([[-0.9436122, -1.8059536]], dtype=float32)

time = 6047	action = 0	current_phase = 0	next_phase = 1	reward = -0.184785	array([[-1.3393723, -2.060345 ]], dtype=float32)

time = 6052	action = 0	current_phase = 0	next_phase = 1	reward = 0.259724	array([[-1.3105847, -2.9855697]], dtype=float32)

time = 6057	action = 1	current_phase = 0	next_phase = 1	reward = -1.779111	array([[-2.9866877, -2.7199228]], dtype=float32)

time = 6065	action = 0	current_phase = 1	next_phase = 0	reward = -0.528916	array([[-1.0508177, -1.9693391]], dtype=float32)

time = 6070	action = 0	current_phase = 1	next_phase = 0	reward = -0.386488	array([[-1.026595 , -2.0896916]], dtype=float32)

time = 6075	action = 0	current_phase = 1	next_phase = 0	reward = -0.234225	array([[-1.1255878, -2.1332572]], dtype=float32)

time = 6080	action = 0	current_phase = 1	next_phase = 0	reward = 0.071769	array([[-1.3015968, -2.6532438]], dtype=float32)

time = 6085	action = 1	current_phase = 1	next_phase = 0	reward = -1.021813	array([[-2.1520038, -1.4779   ]], dtype=float32)

time = 6093	action = 0	current_phase = 0	next_phase = 1	reward = -0.586164	array([[-1.1286168, -1.7498294]], dtype=float32)

time = 6098	action = 0	current_phase = 0	next_phase = 1	reward = -0.432284	array([[-1.0069696, -1.9658606]], dtype=float32)

time = 6103	action = 0	current_phase = 0	next_phase = 1	reward = -0.274042	array([[-1.1640528, -1.5171983]], dtype=float32)

time = 6108	action = 0	current_phase = 0	next_phase = 1	reward = -0.157834	array([[-1.2446909, -2.2132514]], dtype=float32)

time = 6113	action = 0	current_phase = 0	next_phase = 1	reward = -0.048685	array([[-1.8526531, -2.0588727]], dtype=float32)

time = 6118	action = 1	current_phase = 0	next_phase = 1	reward = -1.906902	array([[-3.625348, -2.946358]], dtype=float32)

time = 6126	action = 0	current_phase = 1	next_phase = 0	reward = -0.503166	array([[-1.0450531, -2.0316138]], dtype=float32)

time = 6131	action = 0	current_phase = 1	next_phase = 0	reward = -0.352546	array([[-0.97511053, -2.0554397 ]], dtype=float32)

time = 6136	action = 0	current_phase = 1	next_phase = 0	reward = -0.197833	array([[-0.94322693, -2.2364888 ]], dtype=float32)

time = 6141	action = 0	current_phase = 1	next_phase = 0	reward = 0.317705	array([[-1.699654 , -2.7472897]], dtype=float32)

time = 6146	action = 1	current_phase = 1	next_phase = 0	reward = -1.605487	array([[-3.3245544, -2.247951 ]], dtype=float32)

time = 6154	action = 0	current_phase = 0	next_phase = 1	reward = -0.552304	array([[-1.1490537, -1.7598122]], dtype=float32)

time = 6159	action = 0	current_phase = 0	next_phase = 1	reward = -0.389780	array([[-1.0211096, -1.9563015]], dtype=float32)

time = 6164	action = 0	current_phase = 0	next_phase = 1	reward = -0.244451	array([[-1.0007001, -1.7184243]], dtype=float32)

time = 6169	action = 0	current_phase = 0	next_phase = 1	reward = -0.190066	array([[-1.6236917, -2.4605281]], dtype=float32)

time = 6174	action = 1	current_phase = 0	next_phase = 1	reward = -0.545215	array([[-2.2621284, -1.7142365]], dtype=float32)

time = 6182	action = 0	current_phase = 1	next_phase = 0	reward = -0.617601	array([[-1.0239159, -2.0673766]], dtype=float32)

time = 6187	action = 0	current_phase = 1	next_phase = 0	reward = -0.462143	array([[-0.8422396, -2.0839007]], dtype=float32)

time = 6192	action = 0	current_phase = 1	next_phase = 0	reward = -0.301318	array([[-0.818612 , -1.7500248]], dtype=float32)

time = 6197	action = 0	current_phase = 1	next_phase = 0	reward = -0.167448	array([[-1.072894, -2.180522]], dtype=float32)

time = 6202	action = 0	current_phase = 1	next_phase = 0	reward = 0.225752	array([[-1.7244586, -2.628216 ]], dtype=float32)

time = 6207	action = 1	current_phase = 1	next_phase = 0	reward = -1.777545	array([[-3.547248 , -2.5335011]], dtype=float32)

time = 6215	action = 0	current_phase = 0	next_phase = 1	reward = -0.517224	array([[-1.0638845, -1.5670168]], dtype=float32)

time = 6220	action = 0	current_phase = 0	next_phase = 1	reward = -0.351555	array([[-0.97520006, -1.9837403 ]], dtype=float32)

time = 6225	action = 0	current_phase = 0	next_phase = 1	reward = -0.200637	array([[-1.0834539, -1.8973583]], dtype=float32)

time = 6230	action = 0	current_phase = 0	next_phase = 1	reward = 0.334250	array([[-1.376531 , -2.9240658]], dtype=float32)

time = 6235	action = 1	current_phase = 0	next_phase = 1	reward = -1.369826	array([[-2.8463917, -2.2506068]], dtype=float32)

time = 6243	action = 0	current_phase = 1	next_phase = 0	reward = -0.585770	array([[-1.0845656, -2.0779297]], dtype=float32)

time = 6248	action = 0	current_phase = 1	next_phase = 0	reward = -0.427890	array([[-1.008313 , -2.0885527]], dtype=float32)

time = 6253	action = 0	current_phase = 1	next_phase = 0	reward = -0.277568	array([[-0.86957467, -1.9503896 ]], dtype=float32)

time = 6258	action = 0	current_phase = 1	next_phase = 0	reward = -0.164007	array([[-1.3773601, -2.1306753]], dtype=float32)

time = 6263	action = 0	current_phase = 1	next_phase = 0	reward = 0.002705	array([[-2.5516002, -2.7196498]], dtype=float32)

time = 6268	action = 1	current_phase = 1	next_phase = 0	reward = -1.900026	array([[-3.8315   , -2.5110023]], dtype=float32)

time = 6276	action = 0	current_phase = 0	next_phase = 1	reward = -0.503415	array([[-1.1187233, -1.7098545]], dtype=float32)

time = 6281	action = 0	current_phase = 0	next_phase = 1	reward = -0.353203	array([[-0.99952054, -1.9320652 ]], dtype=float32)

time = 6286	action = 0	current_phase = 0	next_phase = 1	reward = -0.197077	array([[-1.0744221, -1.9331026]], dtype=float32)

time = 6291	action = 0	current_phase = 0	next_phase = 1	reward = 0.293651	array([[-1.6176616, -2.4441183]], dtype=float32)

time = 6296	action = 1	current_phase = 0	next_phase = 1	reward = -1.608224	array([[-2.9131103, -2.6074321]], dtype=float32)

time = 6304	action = 0	current_phase = 1	next_phase = 0	reward = -0.558796	array([[-0.9325968, -2.0198147]], dtype=float32)

time = 6309	action = 0	current_phase = 1	next_phase = 0	reward = -0.404417	array([[-1.0134525, -2.0833912]], dtype=float32)

time = 6314	action = 0	current_phase = 1	next_phase = 0	reward = -0.245298	array([[-1.0153196, -2.0821722]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0518 - val_loss: 0.0399

Epoch 2/50

 - 4s - loss: 0.0498 - val_loss: 0.0371

Epoch 3/50

 - 4s - loss: 0.0539 - val_loss: 0.0364

Epoch 4/50

 - 4s - loss: 0.0471 - val_loss: 0.0430

Epoch 5/50

 - 4s - loss: 0.0425 - val_loss: 0.0395

Epoch 6/50

 - 4s - loss: 0.0510 - val_loss: 0.0393

Epoch 7/50

 - 5s - loss: 0.0467 - val_loss: 0.0410

Epoch 8/50

 - 4s - loss: 0.0444 - val_loss: 0.0398

Epoch 9/50

 - 4s - loss: 0.0456 - val_loss: 0.0374

Epoch 10/50

 - 4s - loss: 0.0411 - val_loss: 0.0405

Epoch 11/50

 - 4s - loss: 0.0422 - val_loss: 0.0410

Epoch 12/50

 - 4s - loss: 0.0407 - val_loss: 0.0414

Epoch 13/50

 - 5s - loss: 0.0448 - val_loss: 0.0384

length of memory (state 0, action 0): 978, after forget

length of memory (state 0, action 1): 405, after forget

length of memory (state 1, action 0): 954, after forget

length of memory (state 1, action 1): 392, after forget

time = 6319	action = 0	current_phase = 1	next_phase = 0	reward = -0.178559	array([[-1.4808018, -2.5956016]], dtype=float32)

time = 6324	action = 1	current_phase = 1	next_phase = 0	reward = -0.476765	array([[-2.4402828, -1.3393955]], dtype=float32)

time = 6332	action = 0	current_phase = 0	next_phase = 1	reward = -0.615668	array([[-1.4120177, -1.7813531]], dtype=float32)

time = 6337	action = 0	current_phase = 0	next_phase = 1	reward = -0.467362	array([[-1.1446013, -1.9412608]], dtype=float32)

time = 6342	action = 0	current_phase = 0	next_phase = 1	reward = -0.307697	array([[-1.1366897, -1.6724393]], dtype=float32)

time = 6347	action = 0	current_phase = 0	next_phase = 1	reward = -0.171799	array([[-1.562728 , -2.0230968]], dtype=float32)

time = 6352	action = 0	current_phase = 0	next_phase = 1	reward = 0.185094	array([[-1.322239 , -2.8564343]], dtype=float32)

time = 6357	action = 1	current_phase = 0	next_phase = 1	reward = -1.787437	array([[-3.3196146, -2.824067 ]], dtype=float32)

time = 6365	action = 0	current_phase = 1	next_phase = 0	reward = -0.535365	array([[-1.170534 , -2.0059674]], dtype=float32)

time = 6370	action = 0	current_phase = 1	next_phase = 0	reward = -0.386468	array([[-1.1562382, -2.1225276]], dtype=float32)

time = 6375	action = 0	current_phase = 1	next_phase = 0	reward = -0.229441	array([[-1.3336685, -2.179307 ]], dtype=float32)

time = 6380	action = 0	current_phase = 1	next_phase = 0	reward = 0.081118	array([[-1.2482537, -2.5949392]], dtype=float32)

time = 6385	action = 1	current_phase = 1	next_phase = 0	reward = -0.971504	array([[-2.4809928, -2.1706154]], dtype=float32)

time = 6393	action = 0	current_phase = 0	next_phase = 1	reward = -0.594553	array([[-1.3530416, -1.7178279]], dtype=float32)

time = 6398	action = 0	current_phase = 0	next_phase = 1	reward = -0.450632	array([[-1.2676009, -1.7999722]], dtype=float32)

time = 6403	action = 0	current_phase = 0	next_phase = 1	reward = -0.285724	array([[-1.2626609, -1.4228055]], dtype=float32)

time = 6408	action = 0	current_phase = 0	next_phase = 1	reward = -0.159974	array([[-1.3375177, -2.1720483]], dtype=float32)

time = 6413	action = 0	current_phase = 0	next_phase = 1	reward = -0.046940	array([[-1.8705993, -1.9351481]], dtype=float32)

time = 6418	action = 1	current_phase = 0	next_phase = 1	reward = -1.900743	array([[-3.7029178, -2.816644 ]], dtype=float32)

time = 6426	action = 0	current_phase = 1	next_phase = 0	reward = -0.494487	array([[-1.2375492, -1.9366859]], dtype=float32)

time = 6431	action = 0	current_phase = 1	next_phase = 0	reward = -0.338238	array([[-1.1530678, -2.085486 ]], dtype=float32)

time = 6436	action = 0	current_phase = 1	next_phase = 0	reward = -0.191219	array([[-1.4787394, -2.1454434]], dtype=float32)

time = 6441	action = 0	current_phase = 1	next_phase = 0	reward = 0.314442	array([[-1.611994 , -2.8431842]], dtype=float32)

time = 6446	action = 1	current_phase = 1	next_phase = 0	reward = -1.607185	array([[-3.3531764, -2.5076964]], dtype=float32)

time = 6454	action = 0	current_phase = 0	next_phase = 1	reward = -0.553365	array([[-1.275096 , -1.7442884]], dtype=float32)

time = 6459	action = 0	current_phase = 0	next_phase = 1	reward = -0.397812	array([[-1.1782944, -1.9492116]], dtype=float32)

time = 6464	action = 0	current_phase = 0	next_phase = 1	reward = -0.246426	array([[-1.1655768, -1.7725993]], dtype=float32)

time = 6469	action = 0	current_phase = 0	next_phase = 1	reward = -0.175064	array([[-1.6423486, -2.3728178]], dtype=float32)

time = 6474	action = 1	current_phase = 0	next_phase = 1	reward = -0.425846	array([[-2.7898815, -2.1591086]], dtype=float32)

time = 6482	action = 0	current_phase = 1	next_phase = 0	reward = -0.605108	array([[-1.2436881, -2.0326333]], dtype=float32)

time = 6487	action = 0	current_phase = 1	next_phase = 0	reward = -0.447401	array([[-0.8265251, -2.0628402]], dtype=float32)

time = 6492	action = 0	current_phase = 1	next_phase = 0	reward = -0.295602	array([[-1.3091793, -2.0571308]], dtype=float32)

time = 6497	action = 0	current_phase = 1	next_phase = 0	reward = -0.169044	array([[-1.7381257, -1.9124874]], dtype=float32)

time = 6502	action = 0	current_phase = 1	next_phase = 0	reward = 0.123715	array([[-1.6697967, -2.8465664]], dtype=float32)

time = 6507	action = 1	current_phase = 1	next_phase = 0	reward = -1.787415	array([[-3.5919943, -2.730712 ]], dtype=float32)

time = 6515	action = 0	current_phase = 0	next_phase = 1	reward = -0.532124	array([[-1.250542 , -1.5201205]], dtype=float32)

time = 6520	action = 0	current_phase = 0	next_phase = 1	reward = -0.375389	array([[-0.865103 , -2.0285249]], dtype=float32)

time = 6525	action = 0	current_phase = 0	next_phase = 1	reward = -0.226260	array([[-1.3175861, -2.084811 ]], dtype=float32)

time = 6530	action = 0	current_phase = 0	next_phase = 1	reward = 0.076994	array([[-1.7659475, -2.2916622]], dtype=float32)

time = 6535	action = 1	current_phase = 0	next_phase = 1	reward = -0.967863	array([[-2.6273055, -2.3485332]], dtype=float32)

time = 6543	action = 0	current_phase = 1	next_phase = 0	reward = -0.588329	array([[-1.2021266, -2.1011488]], dtype=float32)

time = 6548	action = 0	current_phase = 1	next_phase = 0	reward = -0.435763	array([[-1.2634223, -2.1427317]], dtype=float32)

time = 6553	action = 0	current_phase = 1	next_phase = 0	reward = -0.268187	array([[-1.394724, -2.025546]], dtype=float32)

time = 6558	action = 0	current_phase = 1	next_phase = 0	reward = -0.159208	array([[-1.5460556, -2.055072 ]], dtype=float32)

time = 6563	action = 0	current_phase = 1	next_phase = 0	reward = -0.044129	array([[-1.9247307, -2.0207996]], dtype=float32)

time = 6568	action = 1	current_phase = 1	next_phase = 0	reward = -1.903628	array([[-3.6304028, -2.7029643]], dtype=float32)

time = 6576	action = 0	current_phase = 0	next_phase = 1	reward = -0.482599	array([[-1.2301493, -1.6299067]], dtype=float32)

time = 6581	action = 0	current_phase = 0	next_phase = 1	reward = -0.326792	array([[-1.0751126, -1.7482704]], dtype=float32)

time = 6586	action = 0	current_phase = 0	next_phase = 1	reward = -0.183348	array([[-1.1687235, -1.7736402]], dtype=float32)

time = 6591	action = 0	current_phase = 0	next_phase = 1	reward = 0.285717	array([[-1.5997888, -2.4889197]], dtype=float32)

time = 6596	action = 1	current_phase = 0	next_phase = 1	reward = -1.665115	array([[-2.8916492, -2.548912 ]], dtype=float32)

time = 6604	action = 0	current_phase = 1	next_phase = 0	reward = -0.557215	array([[-1.1922694, -2.0640159]], dtype=float32)

time = 6609	action = 0	current_phase = 1	next_phase = 0	reward = -0.406439	array([[-1.0931865, -2.1006384]], dtype=float32)

time = 6614	action = 0	current_phase = 1	next_phase = 0	reward = -0.248029	array([[-1.2196201, -1.9298223]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0583 - val_loss: 0.0260

Epoch 2/50

 - 4s - loss: 0.0524 - val_loss: 0.0279

Epoch 3/50

 - 4s - loss: 0.0480 - val_loss: 0.0265

Epoch 4/50

 - 4s - loss: 0.0500 - val_loss: 0.0271

Epoch 5/50

 - 4s - loss: 0.0467 - val_loss: 0.0292

Epoch 6/50

 - 4s - loss: 0.0493 - val_loss: 0.0284

Epoch 7/50

 - 5s - loss: 0.0488 - val_loss: 0.0277

Epoch 8/50

 - 5s - loss: 0.0427 - val_loss: 0.0271

Epoch 9/50

 - 4s - loss: 0.0465 - val_loss: 0.0289

Epoch 10/50

 - 4s - loss: 0.0418 - val_loss: 0.0313

Epoch 11/50

 - 4s - loss: 0.0414 - val_loss: 0.0306

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 410, after forget

length of memory (state 1, action 0): 976, after forget

length of memory (state 1, action 1): 397, after forget

time = 6619	action = 0	current_phase = 1	next_phase = 0	reward = 0.114972	array([[-1.144349 , -2.2013788]], dtype=float32)

time = 6624	action = 1	current_phase = 1	next_phase = 0	reward = -0.762977	array([[-2.5836494, -1.7045141]], dtype=float32)

time = 6632	action = 0	current_phase = 0	next_phase = 1	reward = -0.626754	array([[-1.238319, -1.80586 ]], dtype=float32)

time = 6637	action = 0	current_phase = 0	next_phase = 1	reward = -0.481753	array([[-1.09985  , -1.9037682]], dtype=float32)

time = 6642	action = 0	current_phase = 0	next_phase = 1	reward = -0.327600	array([[-1.077012 , -1.6377594]], dtype=float32)

time = 6647	action = 0	current_phase = 0	next_phase = 1	reward = -0.177475	array([[-1.2816854, -2.2489703]], dtype=float32)

time = 6652	action = 0	current_phase = 0	next_phase = 1	reward = 0.235293	array([[-1.7928189, -3.0249093]], dtype=float32)

time = 6657	action = 1	current_phase = 0	next_phase = 1	reward = -1.726349	array([[-3.5046453, -2.6524415]], dtype=float32)

time = 6665	action = 0	current_phase = 1	next_phase = 0	reward = -0.530767	array([[-1.3119869, -1.9396442]], dtype=float32)

time = 6670	action = 0	current_phase = 1	next_phase = 0	reward = -0.374526	array([[-1.0929422, -2.1391337]], dtype=float32)

time = 6675	action = 0	current_phase = 1	next_phase = 0	reward = -0.225296	array([[-1.2296869, -2.2619176]], dtype=float32)

time = 6680	action = 0	current_phase = 1	next_phase = 0	reward = 0.355758	array([[-1.3439772, -2.470312 ]], dtype=float32)

time = 6685	action = 1	current_phase = 1	next_phase = 0	reward = -1.311765	array([[-3.382546 , -2.4242282]], dtype=float32)

time = 6693	action = 0	current_phase = 0	next_phase = 1	reward = -0.587675	array([[-1.2784036, -1.7139529]], dtype=float32)

time = 6698	action = 0	current_phase = 0	next_phase = 1	reward = -0.431759	array([[-1.130373 , -1.9328209]], dtype=float32)

time = 6703	action = 0	current_phase = 0	next_phase = 1	reward = -0.268456	array([[-1.3085014, -1.4438217]], dtype=float32)

time = 6708	action = 0	current_phase = 0	next_phase = 1	reward = -0.164775	array([[-1.107602 , -2.1201894]], dtype=float32)

time = 6713	action = 0	current_phase = 0	next_phase = 1	reward = 0.010045	array([[-2.280332 , -2.8293428]], dtype=float32)

time = 6718	action = 1	current_phase = 0	next_phase = 1	reward = -1.898207	array([[-3.7088487, -2.773582 ]], dtype=float32)

time = 6726	action = 0	current_phase = 1	next_phase = 0	reward = -0.505475	array([[-1.2216372, -2.0144053]], dtype=float32)

time = 6731	action = 0	current_phase = 1	next_phase = 0	reward = -0.352052	array([[-1.1228342, -2.1079547]], dtype=float32)

time = 6736	action = 0	current_phase = 1	next_phase = 0	reward = -0.197254	array([[-1.481581 , -2.1380565]], dtype=float32)

time = 6741	action = 0	current_phase = 1	next_phase = 0	reward = 0.324779	array([[-1.5299037, -2.7075644]], dtype=float32)

time = 6746	action = 1	current_phase = 1	next_phase = 0	reward = -1.602349	array([[-3.2640722, -2.4210997]], dtype=float32)

time = 6754	action = 0	current_phase = 0	next_phase = 1	reward = -0.544110	array([[-1.2755667, -1.705646 ]], dtype=float32)

time = 6759	action = 0	current_phase = 0	next_phase = 1	reward = -0.391461	array([[-1.1178719, -1.9311324]], dtype=float32)

time = 6764	action = 0	current_phase = 0	next_phase = 1	reward = -0.230370	array([[-1.1443835, -1.6327618]], dtype=float32)

time = 6769	action = 0	current_phase = 0	next_phase = 1	reward = -0.187891	array([[-1.8474215, -2.1355128]], dtype=float32)

time = 6774	action = 1	current_phase = 0	next_phase = 1	reward = -0.546883	array([[-2.136062 , -1.3285964]], dtype=float32)

time = 6782	action = 0	current_phase = 1	next_phase = 0	reward = -0.617583	array([[-1.2059686, -2.0595715]], dtype=float32)

time = 6787	action = 0	current_phase = 1	next_phase = 0	reward = -0.460263	array([[-0.91502625, -2.093278  ]], dtype=float32)

time = 6792	action = 0	current_phase = 1	next_phase = 0	reward = -0.306560	array([[-1.3398457, -2.0526302]], dtype=float32)

time = 6797	action = 0	current_phase = 1	next_phase = 0	reward = -0.171669	array([[-1.6475718, -1.948738 ]], dtype=float32)

time = 6802	action = 0	current_phase = 1	next_phase = 0	reward = 0.225916	array([[-1.8527925, -2.717842 ]], dtype=float32)

time = 6807	action = 1	current_phase = 1	next_phase = 0	reward = -1.725862	array([[-3.6178212, -2.6327457]], dtype=float32)

time = 6815	action = 0	current_phase = 0	next_phase = 1	reward = -0.522097	array([[-1.245688 , -1.7448914]], dtype=float32)

time = 6820	action = 0	current_phase = 0	next_phase = 1	reward = -0.361911	array([[-1.1036779, -1.9341954]], dtype=float32)

time = 6825	action = 0	current_phase = 0	next_phase = 1	reward = -0.205885	array([[-1.1990231, -1.798056 ]], dtype=float32)

time = 6830	action = 0	current_phase = 0	next_phase = 1	reward = 0.338809	array([[-1.5525045, -3.0463953]], dtype=float32)

time = 6835	action = 1	current_phase = 0	next_phase = 1	reward = -1.421890	array([[-2.7174313, -2.081543 ]], dtype=float32)

time = 6843	action = 0	current_phase = 1	next_phase = 0	reward = -0.579286	array([[-1.4308739, -2.0901456]], dtype=float32)

time = 6848	action = 0	current_phase = 1	next_phase = 0	reward = -0.420308	array([[-1.2350748, -2.1536157]], dtype=float32)

time = 6853	action = 0	current_phase = 1	next_phase = 0	reward = -0.258609	array([[-1.3637569, -2.0431   ]], dtype=float32)

time = 6858	action = 0	current_phase = 1	next_phase = 0	reward = -0.160496	array([[-1.4889438, -2.0568066]], dtype=float32)

time = 6863	action = 1	current_phase = 1	next_phase = 0	reward = -1.083410	array([[-2.5341198, -1.8705533]], dtype=float32)

time = 6871	action = 0	current_phase = 0	next_phase = 1	reward = -1.180831	array([[-1.4666643, -1.9121724]], dtype=float32)

time = 6876	action = 0	current_phase = 0	next_phase = 1	reward = -1.050772	array([[-1.3507572, -2.0977309]], dtype=float32)

time = 6881	action = 0	current_phase = 0	next_phase = 1	reward = -0.922741	array([[-1.4087027, -1.9812325]], dtype=float32)

time = 6886	action = 0	current_phase = 0	next_phase = 1	reward = -0.793346	array([[-1.8049686, -2.1032314]], dtype=float32)

time = 6891	action = 0	current_phase = 0	next_phase = 1	reward = -0.321424	array([[-1.3291715, -3.1144912]], dtype=float32)

time = 6896	action = 1	current_phase = 0	next_phase = 1	reward = -1.638584	array([[-3.6658392, -2.7936633]], dtype=float32)

time = 6904	action = 0	current_phase = 1	next_phase = 0	reward = -0.554114	array([[-1.2855253, -2.045888 ]], dtype=float32)

time = 6909	action = 0	current_phase = 1	next_phase = 0	reward = -0.414293	array([[-1.2271729, -2.1493664]], dtype=float32)

time = 6914	action = 0	current_phase = 1	next_phase = 0	reward = -0.260759	array([[-1.4565845, -2.110663 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0498 - val_loss: 0.0319

Epoch 2/50

 - 4s - loss: 0.0470 - val_loss: 0.0342

Epoch 3/50

 - 4s - loss: 0.0438 - val_loss: 0.0337

Epoch 4/50

 - 4s - loss: 0.0461 - val_loss: 0.0342

Epoch 5/50

 - 4s - loss: 0.0413 - val_loss: 0.0364

Epoch 6/50

 - 4s - loss: 0.0475 - val_loss: 0.0350

Epoch 7/50

 - 4s - loss: 0.0443 - val_loss: 0.0379

Epoch 8/50

 - 4s - loss: 0.0386 - val_loss: 0.0349

Epoch 9/50

 - 4s - loss: 0.0394 - val_loss: 0.0347

Epoch 10/50

 - 4s - loss: 0.0353 - val_loss: 0.0340

Epoch 11/50

 - 4s - loss: 0.0367 - val_loss: 0.0370

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 415, after forget

length of memory (state 1, action 0): 997, after forget

length of memory (state 1, action 1): 402, after forget

time = 6919	action = 0	current_phase = 1	next_phase = 0	reward = -0.172198	array([[-1.5685617, -2.312193 ]], dtype=float32)

time = 6924	action = 1	current_phase = 1	next_phase = 0	reward = -0.442546	array([[-2.7437057, -1.7750978]], dtype=float32)

time = 6932	action = 0	current_phase = 0	next_phase = 1	reward = -0.614724	array([[-1.3366892, -1.8270794]], dtype=float32)

time = 6937	action = 0	current_phase = 0	next_phase = 1	reward = -0.457545	array([[-1.2069925, -1.9504442]], dtype=float32)

time = 6942	action = 0	current_phase = 0	next_phase = 1	reward = -0.302751	array([[-1.3842443, -1.4997035]], dtype=float32)

time = 6947	action = 0	current_phase = 0	next_phase = 1	reward = -0.175249	array([[-1.4920557, -2.1865935]], dtype=float32)

time = 6952	action = 0	current_phase = 0	next_phase = 1	reward = 0.196158	array([[-1.7278434, -3.0210752]], dtype=float32)

time = 6957	action = 1	current_phase = 0	next_phase = 1	reward = -1.727334	array([[-3.595014, -2.564218]], dtype=float32)

time = 6965	action = 0	current_phase = 1	next_phase = 0	reward = -0.513324	array([[-1.4182217, -2.0563293]], dtype=float32)

time = 6970	action = 0	current_phase = 1	next_phase = 0	reward = -0.349893	array([[-1.3899505, -2.1799839]], dtype=float32)

time = 6975	action = 0	current_phase = 1	next_phase = 0	reward = -0.197454	array([[-1.4667194, -2.243713 ]], dtype=float32)

time = 6980	action = 0	current_phase = 1	next_phase = 0	reward = 0.339162	array([[-1.1643735, -2.9172235]], dtype=float32)

time = 6985	action = 1	current_phase = 1	next_phase = 0	reward = -1.421308	array([[-3.5852103, -2.463066 ]], dtype=float32)

time = 6993	action = 0	current_phase = 0	next_phase = 1	reward = -0.585157	array([[-1.3515562, -1.7237082]], dtype=float32)

time = 6998	action = 0	current_phase = 0	next_phase = 1	reward = -0.430315	array([[-1.2485133, -1.9490153]], dtype=float32)

time = 7003	action = 0	current_phase = 0	next_phase = 1	reward = -0.276499	array([[-1.2828168, -1.7319982]], dtype=float32)

time = 7008	action = 0	current_phase = 0	next_phase = 1	reward = -0.161673	array([[-2.001451 , -2.3206484]], dtype=float32)

time = 7013	action = 0	current_phase = 0	next_phase = 1	reward = 0.014303	array([[-2.2356265, -2.3708298]], dtype=float32)

time = 7018	action = 1	current_phase = 0	next_phase = 1	reward = -1.901366	array([[-4.0255976, -2.7540412]], dtype=float32)

time = 7026	action = 0	current_phase = 1	next_phase = 0	reward = -0.488974	array([[-1.3911686, -1.9015992]], dtype=float32)

time = 7031	action = 0	current_phase = 1	next_phase = 0	reward = -0.334327	array([[-1.2213799, -2.0933793]], dtype=float32)

time = 7036	action = 0	current_phase = 1	next_phase = 0	reward = -0.186320	array([[-1.5594832, -2.134647 ]], dtype=float32)

time = 7041	action = 0	current_phase = 1	next_phase = 0	reward = 0.298241	array([[-1.491345, -2.771478]], dtype=float32)

time = 7046	action = 1	current_phase = 1	next_phase = 0	reward = -1.662162	array([[-3.7605853, -2.6569192]], dtype=float32)

time = 7054	action = 0	current_phase = 0	next_phase = 1	reward = -0.559736	array([[-1.3526804, -1.7211578]], dtype=float32)

time = 7059	action = 0	current_phase = 0	next_phase = 1	reward = -0.410668	array([[-1.239742 , -1.9535077]], dtype=float32)

time = 7064	action = 0	current_phase = 0	next_phase = 1	reward = -0.247419	array([[-1.1541028, -1.7736797]], dtype=float32)

time = 7069	action = 0	current_phase = 0	next_phase = 1	reward = -0.184619	array([[-1.7502776, -2.7010498]], dtype=float32)

time = 7074	action = 1	current_phase = 0	next_phase = 1	reward = -0.553049	array([[-2.3615046, -1.4649032]], dtype=float32)

time = 7082	action = 0	current_phase = 1	next_phase = 0	reward = -0.611774	array([[-1.4186348, -2.0889359]], dtype=float32)

time = 7087	action = 0	current_phase = 1	next_phase = 0	reward = -0.447677	array([[-1.1232847, -2.1573946]], dtype=float32)

time = 7092	action = 0	current_phase = 1	next_phase = 0	reward = -0.287126	array([[-1.5022666, -2.1295822]], dtype=float32)

time = 7097	action = 0	current_phase = 1	next_phase = 0	reward = -0.165480	array([[-1.4713019, -2.0680437]], dtype=float32)

time = 7102	action = 0	current_phase = 1	next_phase = 0	reward = 0.165715	array([[-1.5771712, -2.32009  ]], dtype=float32)

time = 7107	action = 1	current_phase = 1	next_phase = 0	reward = -1.779444	array([[-3.6460288, -2.7853873]], dtype=float32)

time = 7115	action = 0	current_phase = 0	next_phase = 1	reward = -0.518305	array([[-1.2399658, -1.5092396]], dtype=float32)

time = 7120	action = 0	current_phase = 0	next_phase = 1	reward = -0.367880	array([[-1.2406948, -1.9733384]], dtype=float32)

time = 7125	action = 0	current_phase = 0	next_phase = 1	reward = -0.221304	array([[-1.3496978, -2.0478358]], dtype=float32)

time = 7130	action = 0	current_phase = 0	next_phase = 1	reward = 0.362631	array([[-1.5800989, -2.5667262]], dtype=float32)

time = 7135	action = 1	current_phase = 0	next_phase = 1	reward = -1.254518	array([[-2.9827693, -2.1426494]], dtype=float32)

time = 7143	action = 0	current_phase = 1	next_phase = 0	reward = -0.580378	array([[-1.2495357, -2.1293511]], dtype=float32)

time = 7148	action = 0	current_phase = 1	next_phase = 0	reward = -0.420174	array([[-1.3693303, -2.1800318]], dtype=float32)

time = 7153	action = 0	current_phase = 1	next_phase = 0	reward = -0.261433	array([[-1.4515091, -2.0616493]], dtype=float32)

time = 7158	action = 0	current_phase = 1	next_phase = 0	reward = -0.165623	array([[-1.3883317, -2.4131024]], dtype=float32)

time = 7163	action = 0	current_phase = 1	next_phase = 0	reward = -0.002699	array([[-1.9115943, -2.435179 ]], dtype=float32)

time = 7168	action = 1	current_phase = 1	next_phase = 0	reward = -1.902279	array([[-3.7880778, -2.7568777]], dtype=float32)

time = 7176	action = 0	current_phase = 0	next_phase = 1	reward = -0.498366	array([[-1.2536055, -1.5905411]], dtype=float32)

time = 7181	action = 0	current_phase = 0	next_phase = 1	reward = -0.347761	array([[-1.3416427, -1.7682409]], dtype=float32)

time = 7186	action = 0	current_phase = 0	next_phase = 1	reward = -0.201744	array([[-1.3328477, -1.8352056]], dtype=float32)

time = 7191	action = 0	current_phase = 0	next_phase = 1	reward = 0.304704	array([[-1.4669312, -2.6942475]], dtype=float32)

time = 7196	action = 1	current_phase = 0	next_phase = 1	reward = -1.451579	array([[-2.9729307, -2.347571 ]], dtype=float32)

time = 7204	action = 0	current_phase = 1	next_phase = 0	reward = -0.561023	array([[-1.4780418, -2.145859 ]], dtype=float32)

time = 7209	action = 0	current_phase = 1	next_phase = 0	reward = -0.403812	array([[-1.3854648, -2.1755311]], dtype=float32)

time = 7214	action = 0	current_phase = 1	next_phase = 0	reward = -0.251493	array([[-1.5051851, -2.1178226]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0506 - val_loss: 0.0293

Epoch 2/50

 - 4s - loss: 0.0454 - val_loss: 0.0350

Epoch 3/50

 - 4s - loss: 0.0418 - val_loss: 0.0312

Epoch 4/50

 - 4s - loss: 0.0435 - val_loss: 0.0319

Epoch 5/50

 - 4s - loss: 0.0446 - val_loss: 0.0307

Epoch 6/50

 - 4s - loss: 0.0426 - val_loss: 0.0343

Epoch 7/50

 - 4s - loss: 0.0427 - val_loss: 0.0314

Epoch 8/50

 - 4s - loss: 0.0428 - val_loss: 0.0313

Epoch 9/50

 - 4s - loss: 0.0392 - val_loss: 0.0347

Epoch 10/50

 - 4s - loss: 0.0380 - val_loss: 0.0361

Epoch 11/50

 - 5s - loss: 0.0388 - val_loss: 0.0338

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 420, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 407, after forget

time = 7219	action = 0	current_phase = 1	next_phase = 0	reward = -0.166906	array([[-1.5038956, -2.3315344]], dtype=float32)

time = 7224	action = 1	current_phase = 1	next_phase = 0	reward = -0.468201	array([[-2.6364996, -1.7021215]], dtype=float32)

time = 7232	action = 0	current_phase = 0	next_phase = 1	reward = -0.615570	array([[-1.2843926, -1.7615305]], dtype=float32)

time = 7237	action = 0	current_phase = 0	next_phase = 1	reward = -0.462921	array([[-1.1286   , -1.9297478]], dtype=float32)

time = 7242	action = 0	current_phase = 0	next_phase = 1	reward = -0.304517	array([[-1.1067083, -1.67603  ]], dtype=float32)

time = 7247	action = 0	current_phase = 0	next_phase = 1	reward = -0.175326	array([[-1.2660316, -1.9007725]], dtype=float32)

time = 7252	action = 0	current_phase = 0	next_phase = 1	reward = 0.158072	array([[-1.7030315, -2.9503026]], dtype=float32)

time = 7257	action = 1	current_phase = 0	next_phase = 1	reward = -1.783836	array([[-3.8056479, -2.5472364]], dtype=float32)

time = 7265	action = 0	current_phase = 1	next_phase = 0	reward = -0.518676	array([[-1.2801002, -2.042039 ]], dtype=float32)

time = 7270	action = 0	current_phase = 1	next_phase = 0	reward = -0.359195	array([[-1.1924367, -2.217807 ]], dtype=float32)

time = 7275	action = 0	current_phase = 1	next_phase = 0	reward = -0.213839	array([[-1.2732642, -2.2898517]], dtype=float32)

time = 7280	action = 0	current_phase = 1	next_phase = 0	reward = 0.361782	array([[-1.2963165, -2.7659876]], dtype=float32)

time = 7285	action = 1	current_phase = 1	next_phase = 0	reward = -1.310568	array([[-2.9939802, -2.1760874]], dtype=float32)

time = 7293	action = 0	current_phase = 0	next_phase = 1	reward = -0.578348	array([[-1.2721392, -1.6916374]], dtype=float32)

time = 7298	action = 0	current_phase = 0	next_phase = 1	reward = -0.414592	array([[-0.9718975, -2.009814 ]], dtype=float32)

time = 7303	action = 0	current_phase = 0	next_phase = 1	reward = -0.251880	array([[-1.1403441, -1.8348155]], dtype=float32)

time = 7308	action = 0	current_phase = 0	next_phase = 1	reward = -0.161360	array([[-1.4926728, -2.354756 ]], dtype=float32)

time = 7313	action = 1	current_phase = 0	next_phase = 1	reward = -0.237494	array([[-2.0413523, -1.9004388]], dtype=float32)

time = 7321	action = 0	current_phase = 1	next_phase = 0	reward = -0.651321	array([[-1.5272616, -2.1516795]], dtype=float32)

time = 7326	action = 0	current_phase = 1	next_phase = 0	reward = -0.494444	array([[-1.1474152, -2.1654515]], dtype=float32)

time = 7331	action = 0	current_phase = 1	next_phase = 0	reward = -0.334965	array([[-1.7548143, -2.2224126]], dtype=float32)

time = 7336	action = 0	current_phase = 1	next_phase = 0	reward = -0.192847	array([[-1.6441541, -2.086409 ]], dtype=float32)

time = 7341	action = 0	current_phase = 1	next_phase = 0	reward = 0.321274	array([[-1.439083 , -2.4932668]], dtype=float32)

time = 7346	action = 1	current_phase = 1	next_phase = 0	reward = -1.556908	array([[-3.5839076, -2.7033207]], dtype=float32)

time = 7354	action = 0	current_phase = 0	next_phase = 1	reward = -0.552801	array([[-1.2865885, -1.6747265]], dtype=float32)

time = 7359	action = 0	current_phase = 0	next_phase = 1	reward = -0.401279	array([[-1.1640513, -1.9335805]], dtype=float32)

time = 7364	action = 0	current_phase = 0	next_phase = 1	reward = -0.251315	array([[-1.2210857, -1.8192606]], dtype=float32)

time = 7369	action = 0	current_phase = 0	next_phase = 1	reward = -0.175765	array([[-1.419061 , -2.2044947]], dtype=float32)

time = 7374	action = 1	current_phase = 0	next_phase = 1	reward = -0.476963	array([[-2.564208 , -1.6283264]], dtype=float32)

time = 7382	action = 0	current_phase = 1	next_phase = 0	reward = -0.611657	array([[-1.360886, -2.15799 ]], dtype=float32)

time = 7387	action = 0	current_phase = 1	next_phase = 0	reward = -0.455725	array([[-1.1602932, -2.177401 ]], dtype=float32)

time = 7392	action = 0	current_phase = 1	next_phase = 0	reward = -0.296098	array([[-1.3771348, -2.152983 ]], dtype=float32)

time = 7397	action = 0	current_phase = 1	next_phase = 0	reward = -0.168416	array([[-1.6170361, -2.0989408]], dtype=float32)

time = 7402	action = 0	current_phase = 1	next_phase = 0	reward = 0.175906	array([[-1.9480599, -2.6614318]], dtype=float32)

time = 7407	action = 1	current_phase = 1	next_phase = 0	reward = -1.788222	array([[-3.9651313, -2.7168744]], dtype=float32)

time = 7415	action = 0	current_phase = 0	next_phase = 1	reward = -0.535990	array([[-1.1457293, -1.5012033]], dtype=float32)

time = 7420	action = 0	current_phase = 0	next_phase = 1	reward = -0.381011	array([[-1.1262872, -1.9485357]], dtype=float32)

time = 7425	action = 0	current_phase = 0	next_phase = 1	reward = -0.225416	array([[-1.3950744, -2.1142888]], dtype=float32)

time = 7430	action = 0	current_phase = 0	next_phase = 1	reward = -0.229811	array([[-1.4776272, -2.5050406]], dtype=float32)

time = 7435	action = 1	current_phase = 0	next_phase = 1	reward = -0.695655	array([[-2.689714 , -2.1104968]], dtype=float32)

time = 7443	action = 0	current_phase = 1	next_phase = 0	reward = -0.579647	array([[-1.2758112, -2.1623287]], dtype=float32)

time = 7448	action = 0	current_phase = 1	next_phase = 0	reward = -0.429803	array([[-1.2901368, -2.2334645]], dtype=float32)

time = 7453	action = 0	current_phase = 1	next_phase = 0	reward = -0.271114	array([[-1.309716 , -2.0585883]], dtype=float32)

time = 7458	action = 0	current_phase = 1	next_phase = 0	reward = -0.170462	array([[-1.7641711, -2.011011 ]], dtype=float32)

time = 7463	action = 0	current_phase = 1	next_phase = 0	reward = 0.084512	array([[-2.1396496, -2.6385314]], dtype=float32)

time = 7468	action = 1	current_phase = 1	next_phase = 0	reward = -1.894665	array([[-3.7387583, -2.8147552]], dtype=float32)

time = 7476	action = 0	current_phase = 0	next_phase = 1	reward = -0.496535	array([[-1.1317053, -1.4675082]], dtype=float32)

time = 7481	action = 0	current_phase = 0	next_phase = 1	reward = -0.353782	array([[-1.1594622, -1.6961688]], dtype=float32)

time = 7486	action = 0	current_phase = 0	next_phase = 1	reward = -0.207359	array([[-1.3546274, -2.047047 ]], dtype=float32)

time = 7491	action = 0	current_phase = 0	next_phase = 1	reward = 0.307567	array([[-1.6349374, -2.5163405]], dtype=float32)

time = 7496	action = 1	current_phase = 0	next_phase = 1	reward = -1.668084	array([[-3.020558 , -2.4667463]], dtype=float32)

time = 7504	action = 0	current_phase = 1	next_phase = 0	reward = -0.568187	array([[-1.2731751, -2.1418831]], dtype=float32)

time = 7509	action = 0	current_phase = 1	next_phase = 0	reward = -0.405762	array([[-1.2737126, -2.2199233]], dtype=float32)

time = 7514	action = 0	current_phase = 1	next_phase = 0	reward = -0.257894	array([[-1.3894252, -2.1679332]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0475 - val_loss: 0.0289

Epoch 2/50

 - 4s - loss: 0.0493 - val_loss: 0.0315

Epoch 3/50

 - 4s - loss: 0.0534 - val_loss: 0.0310

Epoch 4/50

 - 4s - loss: 0.0422 - val_loss: 0.0323

Epoch 5/50

 - 4s - loss: 0.0432 - val_loss: 0.0312

Epoch 6/50

 - 4s - loss: 0.0422 - val_loss: 0.0360

Epoch 7/50

 - 5s - loss: 0.0420 - val_loss: 0.0344

Epoch 8/50

 - 4s - loss: 0.0408 - val_loss: 0.0357

Epoch 9/50

 - 4s - loss: 0.0393 - val_loss: 0.0333

Epoch 10/50

 - 4s - loss: 0.0373 - val_loss: 0.0394

Epoch 11/50

 - 4s - loss: 0.0392 - val_loss: 0.0361

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 425, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 412, after forget

time = 7519	action = 0	current_phase = 1	next_phase = 0	reward = -0.178090	array([[-1.520639 , -2.4149873]], dtype=float32)

time = 7524	action = 1	current_phase = 1	next_phase = 0	reward = -0.564017	array([[-2.6132848, -1.4630212]], dtype=float32)

time = 7532	action = 0	current_phase = 0	next_phase = 1	reward = -0.613267	array([[-1.268491 , -1.7748338]], dtype=float32)

time = 7537	action = 0	current_phase = 0	next_phase = 1	reward = -0.453415	array([[-1.127187, -1.903026]], dtype=float32)

time = 7542	action = 0	current_phase = 0	next_phase = 1	reward = -0.310052	array([[-1.2048861, -1.5156674]], dtype=float32)

time = 7547	action = 0	current_phase = 0	next_phase = 1	reward = -0.175719	array([[-0.75136864, -2.3538952 ]], dtype=float32)

time = 7552	action = 0	current_phase = 0	next_phase = 1	reward = 0.177955	array([[-1.5958861, -2.3104746]], dtype=float32)

time = 7557	action = 1	current_phase = 0	next_phase = 1	reward = -1.784830	array([[-3.7691066, -2.776852 ]], dtype=float32)

time = 7565	action = 0	current_phase = 1	next_phase = 0	reward = -0.530202	array([[-1.2111948, -2.0775173]], dtype=float32)

time = 7570	action = 0	current_phase = 1	next_phase = 0	reward = -0.375015	array([[-1.295377 , -2.2554965]], dtype=float32)

time = 7575	action = 0	current_phase = 1	next_phase = 0	reward = -0.218984	array([[-1.3171332, -2.2938588]], dtype=float32)

time = 7580	action = 0	current_phase = 1	next_phase = 0	reward = 0.360504	array([[-1.286159, -2.433736]], dtype=float32)

time = 7585	action = 1	current_phase = 1	next_phase = 0	reward = -1.311761	array([[-3.0567358, -2.1383991]], dtype=float32)

time = 7593	action = 0	current_phase = 0	next_phase = 1	reward = -0.593536	array([[-1.2987101, -1.6690279]], dtype=float32)

time = 7598	action = 0	current_phase = 0	next_phase = 1	reward = -0.443331	array([[-1.1460632, -1.9257811]], dtype=float32)

time = 7603	action = 0	current_phase = 0	next_phase = 1	reward = -0.290274	array([[-1.2956733, -1.3824872]], dtype=float32)

time = 7608	action = 0	current_phase = 0	next_phase = 1	reward = -0.168860	array([[-1.7049116, -2.2773614]], dtype=float32)

time = 7613	action = 0	current_phase = 0	next_phase = 1	reward = 0.089232	array([[-1.6325916, -2.3524988]], dtype=float32)

time = 7618	action = 1	current_phase = 0	next_phase = 1	reward = -1.903830	array([[-3.8701422, -2.8454533]], dtype=float32)

time = 7626	action = 0	current_phase = 1	next_phase = 0	reward = -0.500217	array([[-1.2490325, -2.1235867]], dtype=float32)

time = 7631	action = 0	current_phase = 1	next_phase = 0	reward = -0.346391	array([[-1.2129425, -2.2179272]], dtype=float32)

time = 7636	action = 0	current_phase = 1	next_phase = 0	reward = -0.198859	array([[-1.4209433, -2.2506952]], dtype=float32)

time = 7641	action = 0	current_phase = 1	next_phase = 0	reward = 0.326873	array([[-1.916698 , -2.7949615]], dtype=float32)

time = 7646	action = 1	current_phase = 1	next_phase = 0	reward = -1.452099	array([[-3.4492197, -2.519635 ]], dtype=float32)

time = 7654	action = 0	current_phase = 0	next_phase = 1	reward = -0.556165	array([[-1.2920259, -1.6660885]], dtype=float32)

time = 7659	action = 0	current_phase = 0	next_phase = 1	reward = -0.404070	array([[-1.1343197, -1.9198387]], dtype=float32)

time = 7664	action = 0	current_phase = 0	next_phase = 1	reward = -0.253037	array([[-1.2242042, -2.1703217]], dtype=float32)

time = 7669	action = 0	current_phase = 0	next_phase = 1	reward = -0.172629	array([[-1.6440337, -2.2624269]], dtype=float32)

time = 7674	action = 1	current_phase = 0	next_phase = 1	reward = -0.474908	array([[-2.4145553, -1.5135434]], dtype=float32)

time = 7682	action = 0	current_phase = 1	next_phase = 0	reward = -0.611269	array([[-1.2693324, -2.1941988]], dtype=float32)

time = 7687	action = 0	current_phase = 1	next_phase = 0	reward = -0.449189	array([[-1.2893587, -2.2624254]], dtype=float32)

time = 7692	action = 0	current_phase = 1	next_phase = 0	reward = -0.290300	array([[-1.4368339, -2.180661 ]], dtype=float32)

time = 7697	action = 0	current_phase = 1	next_phase = 0	reward = -0.163441	array([[-1.7217519, -2.10061  ]], dtype=float32)

time = 7702	action = 0	current_phase = 1	next_phase = 0	reward = 0.170966	array([[-1.8823736, -2.9204218]], dtype=float32)

time = 7707	action = 1	current_phase = 1	next_phase = 0	reward = -1.736778	array([[-3.74551  , -2.8058274]], dtype=float32)

time = 7715	action = 0	current_phase = 0	next_phase = 1	reward = -0.534909	array([[-1.1620947, -1.4842677]], dtype=float32)

time = 7720	action = 0	current_phase = 0	next_phase = 1	reward = -0.375090	array([[-1.0861595, -1.9397937]], dtype=float32)

time = 7725	action = 0	current_phase = 0	next_phase = 1	reward = -0.219554	array([[-1.1532472, -1.682371 ]], dtype=float32)

time = 7730	action = 0	current_phase = 0	next_phase = 1	reward = 0.368150	array([[-1.5741646, -2.4713573]], dtype=float32)

time = 7735	action = 1	current_phase = 0	next_phase = 1	reward = -1.254879	array([[-2.7617161, -2.2154832]], dtype=float32)

time = 7743	action = 0	current_phase = 1	next_phase = 0	reward = -0.587476	array([[-1.2261748, -2.2085845]], dtype=float32)

time = 7748	action = 0	current_phase = 1	next_phase = 0	reward = -0.437219	array([[-1.3714933, -2.2670581]], dtype=float32)

time = 7753	action = 0	current_phase = 1	next_phase = 0	reward = -0.281685	array([[-1.4500716, -1.8758967]], dtype=float32)

time = 7758	action = 0	current_phase = 1	next_phase = 0	reward = -0.164389	array([[-1.7616177, -2.0814216]], dtype=float32)

time = 7763	action = 0	current_phase = 1	next_phase = 0	reward = 0.094010	array([[-2.168819 , -2.2648287]], dtype=float32)

time = 7768	action = 1	current_phase = 1	next_phase = 0	reward = -1.893285	array([[-3.8012838, -2.7632353]], dtype=float32)

time = 7776	action = 0	current_phase = 0	next_phase = 1	reward = -0.495269	array([[-1.2066634, -1.6133524]], dtype=float32)

time = 7781	action = 0	current_phase = 0	next_phase = 1	reward = -0.338013	array([[-1.014778 , -1.8841224]], dtype=float32)

time = 7786	action = 0	current_phase = 0	next_phase = 1	reward = -0.193355	array([[-1.2436049, -1.8702611]], dtype=float32)

time = 7791	action = 0	current_phase = 0	next_phase = 1	reward = 0.295762	array([[-1.5824058, -2.9890413]], dtype=float32)

time = 7796	action = 1	current_phase = 0	next_phase = 1	reward = -1.611760	array([[-3.1921966, -2.3892045]], dtype=float32)

time = 7804	action = 0	current_phase = 1	next_phase = 0	reward = -0.557858	array([[-1.2286992, -2.173183 ]], dtype=float32)

time = 7809	action = 0	current_phase = 1	next_phase = 0	reward = -0.414200	array([[-1.3916044, -2.2650552]], dtype=float32)

time = 7814	action = 0	current_phase = 1	next_phase = 0	reward = -0.260595	array([[-1.4503593, -2.2458858]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0515 - val_loss: 0.0458

Epoch 2/50

 - 5s - loss: 0.0482 - val_loss: 0.0465

Epoch 3/50

 - 5s - loss: 0.0446 - val_loss: 0.0498

Epoch 4/50

 - 5s - loss: 0.0435 - val_loss: 0.0475

Epoch 5/50

 - 4s - loss: 0.0424 - val_loss: 0.0495

Epoch 6/50

 - 4s - loss: 0.0439 - val_loss: 0.0519

Epoch 7/50

 - 5s - loss: 0.0395 - val_loss: 0.0518

Epoch 8/50

 - 4s - loss: 0.0384 - val_loss: 0.0517

Epoch 9/50

 - 4s - loss: 0.0344 - val_loss: 0.0511

Epoch 10/50

 - 4s - loss: 0.0416 - val_loss: 0.0496

Epoch 11/50

 - 4s - loss: 0.0384 - val_loss: 0.0506

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 430, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 417, after forget

time = 7819	action = 0	current_phase = 1	next_phase = 0	reward = -0.166127	array([[-1.4317976, -2.1918967]], dtype=float32)

time = 7824	action = 1	current_phase = 1	next_phase = 0	reward = -0.409024	array([[-2.4484293, -1.5385598]], dtype=float32)

time = 7832	action = 0	current_phase = 0	next_phase = 1	reward = -0.618442	array([[-1.5739194, -1.9125979]], dtype=float32)

time = 7837	action = 0	current_phase = 0	next_phase = 1	reward = -0.463301	array([[-1.2717175, -1.963742 ]], dtype=float32)

time = 7842	action = 0	current_phase = 0	next_phase = 1	reward = -0.313089	array([[-1.305564 , -1.6006594]], dtype=float32)

time = 7847	action = 0	current_phase = 0	next_phase = 1	reward = -0.173138	array([[-1.6151379, -1.9855428]], dtype=float32)

time = 7852	action = 0	current_phase = 0	next_phase = 1	reward = 0.241420	array([[-1.4026102, -2.858748 ]], dtype=float32)

time = 7857	action = 1	current_phase = 0	next_phase = 1	reward = -1.784253	array([[-3.2986584, -2.7153738]], dtype=float32)

time = 7865	action = 0	current_phase = 1	next_phase = 0	reward = -0.532091	array([[-1.5471556, -2.0589583]], dtype=float32)

time = 7870	action = 0	current_phase = 1	next_phase = 0	reward = -0.370916	array([[-1.4673233, -2.2454255]], dtype=float32)

time = 7875	action = 0	current_phase = 1	next_phase = 0	reward = -0.220366	array([[-1.3501722, -2.322214 ]], dtype=float32)

time = 7880	action = 0	current_phase = 1	next_phase = 0	reward = 0.377888	array([[-1.3675418, -2.372921 ]], dtype=float32)

time = 7885	action = 1	current_phase = 1	next_phase = 0	reward = -1.243435	array([[-3.3168952, -2.439447 ]], dtype=float32)

time = 7893	action = 0	current_phase = 0	next_phase = 1	reward = -0.580419	array([[-1.4815823, -1.6969278]], dtype=float32)

time = 7898	action = 0	current_phase = 0	next_phase = 1	reward = -0.435663	array([[-1.2637419, -1.9779557]], dtype=float32)

time = 7903	action = 0	current_phase = 0	next_phase = 1	reward = -0.275395	array([[-1.4325562, -1.6447072]], dtype=float32)

time = 7908	action = 0	current_phase = 0	next_phase = 1	reward = -0.160528	array([[-1.8150153, -2.231471 ]], dtype=float32)

time = 7913	action = 1	current_phase = 0	next_phase = 1	reward = -1.853915	array([[-2.5067155, -2.2737253]], dtype=float32)

time = 7921	action = 1	current_phase = 1	next_phase = 0	reward = -2.015206	array([[-2.7742617, -2.6370058]], dtype=float32)

time = 7929	action = 0	current_phase = 0	next_phase = 1	reward = -0.399981	array([[-1.2355444, -1.4771308]], dtype=float32)

time = 7934	action = 0	current_phase = 0	next_phase = 1	reward = -0.248210	array([[-1.1274961, -2.4954298]], dtype=float32)

time = 7939	action = 0	current_phase = 0	next_phase = 1	reward = -0.180655	array([[-1.3732733, -1.9680912]], dtype=float32)

time = 7944	action = 1	current_phase = 0	next_phase = 1	reward = -0.601754	array([[-1.7092985, -1.5005964]], dtype=float32)

time = 7952	action = 0	current_phase = 1	next_phase = 0	reward = -0.618628	array([[-1.3196021, -2.1949139]], dtype=float32)

time = 7957	action = 0	current_phase = 1	next_phase = 0	reward = -0.465659	array([[-1.3858103, -2.1704793]], dtype=float32)

time = 7962	action = 0	current_phase = 1	next_phase = 0	reward = -0.316827	array([[-1.6424575, -2.1591952]], dtype=float32)

time = 7967	action = 0	current_phase = 1	next_phase = 0	reward = -0.177781	array([[-1.5585268, -2.214847 ]], dtype=float32)

time = 7972	action = 0	current_phase = 1	next_phase = 0	reward = 0.263816	array([[-1.9141961, -2.7900653]], dtype=float32)

time = 7977	action = 1	current_phase = 1	next_phase = 0	reward = -1.776652	array([[-3.9150283, -2.6924431]], dtype=float32)

time = 7985	action = 0	current_phase = 0	next_phase = 1	reward = -0.518008	array([[-1.3855922, -1.6968987]], dtype=float32)

time = 7990	action = 0	current_phase = 0	next_phase = 1	reward = -0.367811	array([[-1.1916339, -1.989553 ]], dtype=float32)

time = 7995	action = 0	current_phase = 0	next_phase = 1	reward = -0.215940	array([[-1.4246327, -2.1036413]], dtype=float32)

time = 8000	action = 0	current_phase = 0	next_phase = 1	reward = 0.349722	array([[-1.5892053, -2.8597662]], dtype=float32)

time = 8005	action = 1	current_phase = 0	next_phase = 1	reward = -1.366809	array([[-2.7138784, -2.400549 ]], dtype=float32)

time = 8013	action = 0	current_phase = 1	next_phase = 0	reward = -0.585972	array([[-1.344805 , -2.2029262]], dtype=float32)

time = 8018	action = 0	current_phase = 1	next_phase = 0	reward = -0.423667	array([[-1.408008 , -2.2376037]], dtype=float32)

time = 8023	action = 0	current_phase = 1	next_phase = 0	reward = -0.270210	array([[-1.537775 , -2.1628857]], dtype=float32)

time = 8028	action = 0	current_phase = 1	next_phase = 0	reward = -0.160270	array([[-1.786517 , -2.0340147]], dtype=float32)

time = 8033	action = 1	current_phase = 1	next_phase = 0	reward = -1.130564	array([[-2.4799418, -1.7148377]], dtype=float32)

time = 8041	action = 0	current_phase = 0	next_phase = 1	reward = -1.182405	array([[-2.6893852, -2.8964486]], dtype=float32)

time = 8046	action = 0	current_phase = 0	next_phase = 1	reward = -1.053053	array([[-2.1774685, -2.7807357]], dtype=float32)

time = 8051	action = 0	current_phase = 0	next_phase = 1	reward = -0.923957	array([[-1.912915 , -2.2728457]], dtype=float32)

time = 8056	action = 0	current_phase = 0	next_phase = 1	reward = -0.796668	array([[-1.7230006, -2.48778  ]], dtype=float32)

time = 8061	action = 0	current_phase = 0	next_phase = 1	reward = -0.325799	array([[-2.7197092, -3.1484113]], dtype=float32)

time = 8066	action = 1	current_phase = 0	next_phase = 1	reward = -1.639462	array([[-3.8796625, -2.7603607]], dtype=float32)

time = 8074	action = 0	current_phase = 1	next_phase = 0	reward = -0.558054	array([[-1.4590837, -2.1642537]], dtype=float32)

time = 8079	action = 0	current_phase = 1	next_phase = 0	reward = -0.405071	array([[-1.4835399, -2.2451174]], dtype=float32)

time = 8084	action = 0	current_phase = 1	next_phase = 0	reward = -0.249679	array([[-1.5318795, -2.2044005]], dtype=float32)

time = 8089	action = 0	current_phase = 1	next_phase = 0	reward = -0.171345	array([[-1.3325922, -2.365513 ]], dtype=float32)

time = 8094	action = 1	current_phase = 1	next_phase = 0	reward = -0.489787	array([[-2.5558345, -2.2678416]], dtype=float32)

time = 8102	action = 0	current_phase = 0	next_phase = 1	reward = -0.613269	array([[-1.5223598, -1.7101748]], dtype=float32)

time = 8107	action = 0	current_phase = 0	next_phase = 1	reward = -0.457588	array([[-1.2248813, -1.9506016]], dtype=float32)

time = 8112	action = 0	current_phase = 0	next_phase = 1	reward = -0.298275	array([[-1.3191528, -1.5512127]], dtype=float32)

time = 8117	action = 0	current_phase = 0	next_phase = 1	reward = -0.168267	array([[-1.5646892, -2.1080906]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0500 - val_loss: 0.0343

Epoch 2/50

 - 4s - loss: 0.0518 - val_loss: 0.0375

Epoch 3/50

 - 4s - loss: 0.0492 - val_loss: 0.0374

Epoch 4/50

 - 4s - loss: 0.0480 - val_loss: 0.0384

Epoch 5/50

 - 4s - loss: 0.0419 - val_loss: 0.0389

Epoch 6/50

 - 4s - loss: 0.0487 - val_loss: 0.0396

Epoch 7/50

 - 4s - loss: 0.0459 - val_loss: 0.0410

Epoch 8/50

 - 4s - loss: 0.0415 - val_loss: 0.0413

Epoch 9/50

 - 4s - loss: 0.0435 - val_loss: 0.0443

Epoch 10/50

 - 4s - loss: 0.0389 - val_loss: 0.0437

Epoch 11/50

 - 4s - loss: 0.0416 - val_loss: 0.0415

length of memory (state 0, action 0): 1025, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 435, after forget

length of memory (state 1, action 0): 1018, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 423, after forget

time = 8122	action = 0	current_phase = 0	next_phase = 1	reward = 0.154368	array([[-1.9749129, -2.4474652]], dtype=float32)

time = 8127	action = 1	current_phase = 0	next_phase = 1	reward = -1.786923	array([[-3.4262962, -2.8821602]], dtype=float32)

time = 8135	action = 0	current_phase = 1	next_phase = 0	reward = -0.532891	array([[-1.3644717, -2.062233 ]], dtype=float32)

time = 8140	action = 0	current_phase = 1	next_phase = 0	reward = -0.377328	array([[-1.4919745, -2.2543166]], dtype=float32)

time = 8145	action = 0	current_phase = 1	next_phase = 0	reward = -0.234161	array([[-1.2297409, -2.3892715]], dtype=float32)

time = 8150	action = 0	current_phase = 1	next_phase = 0	reward = 0.370620	array([[-1.165029 , -2.5829432]], dtype=float32)

time = 8155	action = 1	current_phase = 1	next_phase = 0	reward = -1.201326	array([[-2.3630903, -1.7009971]], dtype=float32)

time = 8163	action = 0	current_phase = 0	next_phase = 1	reward = -0.600533	array([[-1.3951014, -1.7203794]], dtype=float32)

time = 8168	action = 0	current_phase = 0	next_phase = 1	reward = -0.450699	array([[-1.2866987, -1.9471084]], dtype=float32)

time = 8173	action = 0	current_phase = 0	next_phase = 1	reward = -0.287187	array([[-1.3908926, -1.423825 ]], dtype=float32)

time = 8178	action = 0	current_phase = 0	next_phase = 1	reward = -0.165062	array([[-1.4666628, -2.2212436]], dtype=float32)

time = 8183	action = 0	current_phase = 0	next_phase = 1	reward = 0.000564	array([[-1.7236342, -2.4178874]], dtype=float32)

time = 8188	action = 1	current_phase = 0	next_phase = 1	reward = -1.893169	array([[-3.680618, -2.953954]], dtype=float32)

time = 8196	action = 0	current_phase = 1	next_phase = 0	reward = -0.484688	array([[-1.5258582, -2.0733044]], dtype=float32)

time = 8201	action = 0	current_phase = 1	next_phase = 0	reward = -0.324745	array([[-1.5021418, -2.2014647]], dtype=float32)

time = 8206	action = 0	current_phase = 1	next_phase = 0	reward = -0.177698	array([[-1.6334906, -2.183134 ]], dtype=float32)

time = 8211	action = 0	current_phase = 1	next_phase = 0	reward = 0.288560	array([[-2.1248872, -2.8125873]], dtype=float32)

time = 8216	action = 1	current_phase = 1	next_phase = 0	reward = -1.554928	array([[-3.490136, -2.593513]], dtype=float32)

time = 8224	action = 0	current_phase = 0	next_phase = 1	reward = -0.554204	array([[-1.3814174, -1.7138833]], dtype=float32)

time = 8229	action = 0	current_phase = 0	next_phase = 1	reward = -0.395190	array([[-1.2770255, -1.978781 ]], dtype=float32)

time = 8234	action = 0	current_phase = 0	next_phase = 1	reward = -0.225788	array([[-1.4355228, -2.1347818]], dtype=float32)

time = 8239	action = 0	current_phase = 0	next_phase = 1	reward = -0.183825	array([[-1.6905664, -2.4272876]], dtype=float32)

time = 8244	action = 1	current_phase = 0	next_phase = 1	reward = -0.591649	array([[-1.9900143, -1.3719361]], dtype=float32)

time = 8252	action = 0	current_phase = 1	next_phase = 0	reward = -0.621656	array([[-1.4916502, -2.1354947]], dtype=float32)

time = 8257	action = 0	current_phase = 1	next_phase = 0	reward = -0.478615	array([[-0.9646307, -2.188949 ]], dtype=float32)

time = 8262	action = 0	current_phase = 1	next_phase = 0	reward = -0.325865	array([[-1.6675375, -2.1708136]], dtype=float32)

time = 8267	action = 0	current_phase = 1	next_phase = 0	reward = -0.182777	array([[-1.7651552, -2.0627522]], dtype=float32)

time = 8272	action = 0	current_phase = 1	next_phase = 0	reward = 0.228536	array([[-1.95889  , -2.8083372]], dtype=float32)

time = 8277	action = 1	current_phase = 1	next_phase = 0	reward = -1.784961	array([[-3.6610215, -2.8509555]], dtype=float32)

time = 8285	action = 0	current_phase = 0	next_phase = 1	reward = -0.531379	array([[-1.3929205, -1.7231691]], dtype=float32)

time = 8290	action = 0	current_phase = 0	next_phase = 1	reward = -0.369449	array([[-1.2713817, -1.9945331]], dtype=float32)

time = 8295	action = 0	current_phase = 0	next_phase = 1	reward = -0.216566	array([[-1.3756725, -2.0643408]], dtype=float32)

time = 8300	action = 0	current_phase = 0	next_phase = 1	reward = 0.058446	array([[-0.7099131, -2.1942542]], dtype=float32)

time = 8305	action = 1	current_phase = 0	next_phase = 1	reward = -1.030446	array([[-2.5272937, -1.9672668]], dtype=float32)

time = 8313	action = 0	current_phase = 1	next_phase = 0	reward = -0.586326	array([[-1.9343077, -2.1087053]], dtype=float32)

time = 8318	action = 0	current_phase = 1	next_phase = 0	reward = -0.435478	array([[-1.4311149, -2.2446935]], dtype=float32)

time = 8323	action = 0	current_phase = 1	next_phase = 0	reward = -0.290135	array([[-1.6154082, -2.056437 ]], dtype=float32)

time = 8328	action = 0	current_phase = 1	next_phase = 0	reward = -0.165857	array([[-1.8112618, -2.0423398]], dtype=float32)

time = 8333	action = 0	current_phase = 1	next_phase = 0	reward = 0.154925	array([[-2.0179164, -2.6022642]], dtype=float32)

time = 8338	action = 1	current_phase = 1	next_phase = 0	reward = -1.896476	array([[-3.8245785, -2.8009722]], dtype=float32)

time = 8346	action = 0	current_phase = 0	next_phase = 1	reward = -0.507074	array([[-1.3411827, -1.6856122]], dtype=float32)

time = 8351	action = 0	current_phase = 0	next_phase = 1	reward = -0.360431	array([[-1.3041768, -1.7733705]], dtype=float32)

time = 8356	action = 0	current_phase = 0	next_phase = 1	reward = -0.217434	array([[-1.4589967, -2.176439 ]], dtype=float32)

time = 8361	action = 0	current_phase = 0	next_phase = 1	reward = 0.305445	array([[-1.642909 , -2.7472427]], dtype=float32)

time = 8366	action = 1	current_phase = 0	next_phase = 1	reward = -1.611485	array([[-3.1195233, -2.5465097]], dtype=float32)

time = 8374	action = 0	current_phase = 1	next_phase = 0	reward = -0.566843	array([[-1.4677849, -2.115468 ]], dtype=float32)

time = 8379	action = 0	current_phase = 1	next_phase = 0	reward = -0.419088	array([[-1.473915 , -2.2400434]], dtype=float32)

time = 8384	action = 0	current_phase = 1	next_phase = 0	reward = -0.263829	array([[-1.5926117, -2.197514 ]], dtype=float32)

time = 8389	action = 0	current_phase = 1	next_phase = 0	reward = -0.165390	array([[-1.3991889, -2.438293 ]], dtype=float32)

time = 8394	action = 1	current_phase = 1	next_phase = 0	reward = -0.410183	array([[-2.476437 , -1.3814225]], dtype=float32)

time = 8402	action = 0	current_phase = 0	next_phase = 1	reward = -0.624645	array([[-1.5004293, -1.9392081]], dtype=float32)

time = 8407	action = 0	current_phase = 0	next_phase = 1	reward = -0.465891	array([[-1.2161727, -1.9988127]], dtype=float32)

time = 8412	action = 0	current_phase = 0	next_phase = 1	reward = -0.313514	array([[-1.5238366, -1.787938 ]], dtype=float32)

time = 8417	action = 0	current_phase = 0	next_phase = 1	reward = -0.177554	array([[-1.4683456, -2.1625326]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0592 - val_loss: 0.0308

Epoch 2/50

 - 4s - loss: 0.0522 - val_loss: 0.0314

Epoch 3/50

 - 4s - loss: 0.0551 - val_loss: 0.0340

Epoch 4/50

 - 4s - loss: 0.0538 - val_loss: 0.0309

Epoch 5/50

 - 4s - loss: 0.0495 - val_loss: 0.0336

Epoch 6/50

 - 4s - loss: 0.0533 - val_loss: 0.0323

Epoch 7/50

 - 5s - loss: 0.0512 - val_loss: 0.0331

Epoch 8/50

 - 4s - loss: 0.0469 - val_loss: 0.0306

Epoch 9/50

 - 4s - loss: 0.0420 - val_loss: 0.0331

Epoch 10/50

 - 4s - loss: 0.0441 - val_loss: 0.0338

Epoch 11/50

 - 4s - loss: 0.0458 - val_loss: 0.0339

Epoch 12/50

 - 4s - loss: 0.0424 - val_loss: 0.0329

Epoch 13/50

 - 4s - loss: 0.0427 - val_loss: 0.0330

Epoch 14/50

 - 5s - loss: 0.0460 - val_loss: 0.0334

Epoch 15/50

 - 4s - loss: 0.0439 - val_loss: 0.0340

Epoch 16/50

 - 4s - loss: 0.0419 - val_loss: 0.0335

Epoch 17/50

 - 4s - loss: 0.0393 - val_loss: 0.0378

Epoch 18/50

 - 4s - loss: 0.0437 - val_loss: 0.0355

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 440, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 428, after forget

time = 8422	action = 0	current_phase = 0	next_phase = 1	reward = 0.230908	array([[-1.174892 , -3.0309165]], dtype=float32)

time = 8427	action = 1	current_phase = 0	next_phase = 1	reward = -1.720688	array([[-3.1177282, -2.7747402]], dtype=float32)

time = 8435	action = 0	current_phase = 1	next_phase = 0	reward = -0.510849	array([[-1.6217273, -2.125468 ]], dtype=float32)

time = 8440	action = 0	current_phase = 1	next_phase = 0	reward = -0.361694	array([[-1.5027367, -2.2511857]], dtype=float32)

time = 8445	action = 0	current_phase = 1	next_phase = 0	reward = -0.210879	array([[-1.4344989, -2.2829335]], dtype=float32)

time = 8450	action = 0	current_phase = 1	next_phase = 0	reward = 0.355114	array([[-1.4121358, -2.843012 ]], dtype=float32)

time = 8455	action = 1	current_phase = 1	next_phase = 0	reward = -1.364825	array([[-3.2898638, -2.1838195]], dtype=float32)

time = 8463	action = 0	current_phase = 0	next_phase = 1	reward = -0.585109	array([[-1.4783183, -1.7537546]], dtype=float32)

time = 8468	action = 0	current_phase = 0	next_phase = 1	reward = -0.426766	array([[-1.025442, -2.113275]], dtype=float32)

time = 8473	action = 0	current_phase = 0	next_phase = 1	reward = -0.271412	array([[-1.5527388, -1.7130139]], dtype=float32)

time = 8478	action = 0	current_phase = 0	next_phase = 1	reward = -0.160692	array([[-1.969775 , -2.3780475]], dtype=float32)

time = 8483	action = 1	current_phase = 0	next_phase = 1	reward = -1.969450	array([[-2.4789054, -2.2975457]], dtype=float32)

time = 8491	action = 0	current_phase = 1	next_phase = 0	reward = -1.711012	array([[-2.670255 , -2.8051112]], dtype=float32)

time = 8496	action = 1	current_phase = 1	next_phase = 0	reward = -1.798191	array([[-3.2071967, -2.73965  ]], dtype=float32)

time = 8504	action = 0	current_phase = 0	next_phase = 1	reward = -0.242597	array([[-0.97642916, -1.6549565 ]], dtype=float32)

time = 8509	action = 0	current_phase = 0	next_phase = 1	reward = -0.185566	array([[-1.3529294, -2.549095 ]], dtype=float32)

time = 8514	action = 0	current_phase = 0	next_phase = 1	reward = -0.199535	array([[-1.5065244, -1.5096304]], dtype=float32)

time = 8519	action = 0	current_phase = 0	next_phase = 1	reward = -1.613240	array([[-2.2121942, -3.026106 ]], dtype=float32)

time = 8524	action = 1	current_phase = 0	next_phase = 1	reward = -1.926133	array([[-3.7549946, -2.789376 ]], dtype=float32)

time = 8532	action = 0	current_phase = 1	next_phase = 0	reward = -0.316578	array([[-1.479855 , -2.0962324]], dtype=float32)

time = 8537	action = 0	current_phase = 1	next_phase = 0	reward = -0.173893	array([[-1.733235 , -2.1067953]], dtype=float32)

time = 8542	action = 0	current_phase = 1	next_phase = 0	reward = 0.190257	array([[-1.6016719, -2.9713297]], dtype=float32)

time = 8547	action = 1	current_phase = 1	next_phase = 0	reward = -1.783719	array([[-3.8536863, -2.859629 ]], dtype=float32)

time = 8555	action = 0	current_phase = 0	next_phase = 1	reward = -0.530108	array([[-1.3098397, -1.5410607]], dtype=float32)

time = 8560	action = 0	current_phase = 0	next_phase = 1	reward = -0.387310	array([[-1.2054368, -2.0700045]], dtype=float32)

time = 8565	action = 0	current_phase = 0	next_phase = 1	reward = -0.242061	array([[-1.3286414, -1.9145579]], dtype=float32)

time = 8570	action = 0	current_phase = 0	next_phase = 1	reward = 0.077332	array([[-1.1304731, -2.3135016]], dtype=float32)

time = 8575	action = 1	current_phase = 0	next_phase = 1	reward = -1.017462	array([[-2.4993875, -2.1857579]], dtype=float32)

time = 8583	action = 0	current_phase = 1	next_phase = 0	reward = -0.578620	array([[-1.9994178, -2.1374605]], dtype=float32)

time = 8588	action = 0	current_phase = 1	next_phase = 0	reward = -0.418549	array([[-1.4687856, -2.2520747]], dtype=float32)

time = 8593	action = 0	current_phase = 1	next_phase = 0	reward = -0.258336	array([[-1.6857915, -2.1767335]], dtype=float32)

time = 8598	action = 0	current_phase = 1	next_phase = 0	reward = -0.155653	array([[-1.5934622, -2.1354768]], dtype=float32)

time = 8603	action = 0	current_phase = 1	next_phase = 0	reward = 0.006369	array([[-1.8298736, -1.8833584]], dtype=float32)

time = 8608	action = 1	current_phase = 1	next_phase = 0	reward = -1.901985	array([[-3.8709424, -2.9422622]], dtype=float32)

time = 8616	action = 0	current_phase = 0	next_phase = 1	reward = -0.498836	array([[-1.4048707, -1.7515719]], dtype=float32)

time = 8621	action = 0	current_phase = 0	next_phase = 1	reward = -0.348439	array([[-1.3072071, -2.0291295]], dtype=float32)

time = 8626	action = 0	current_phase = 0	next_phase = 1	reward = -0.202995	array([[-1.5043936, -2.1945934]], dtype=float32)

time = 8631	action = 0	current_phase = 0	next_phase = 1	reward = 0.293917	array([[-1.5692022, -3.095759 ]], dtype=float32)

time = 8636	action = 1	current_phase = 0	next_phase = 1	reward = -1.557609	array([[-3.075388, -2.578434]], dtype=float32)

time = 8644	action = 0	current_phase = 1	next_phase = 0	reward = -0.550277	array([[-1.637084 , -2.1501215]], dtype=float32)

time = 8649	action = 0	current_phase = 1	next_phase = 0	reward = -0.394359	array([[-1.489051 , -2.2488523]], dtype=float32)

time = 8654	action = 0	current_phase = 1	next_phase = 0	reward = -0.244977	array([[-1.543369 , -2.2401247]], dtype=float32)

time = 8659	action = 0	current_phase = 1	next_phase = 0	reward = -0.183572	array([[-1.5090222, -2.5213492]], dtype=float32)

time = 8664	action = 1	current_phase = 1	next_phase = 0	reward = -0.592623	array([[-2.605577 , -1.7848845]], dtype=float32)

time = 8672	action = 0	current_phase = 0	next_phase = 1	reward = -0.614172	array([[-1.6330035, -1.747123 ]], dtype=float32)

time = 8677	action = 0	current_phase = 0	next_phase = 1	reward = -0.459738	array([[-1.3258829, -1.9892247]], dtype=float32)

time = 8682	action = 0	current_phase = 0	next_phase = 1	reward = -0.304907	array([[-1.3324788, -1.7019044]], dtype=float32)

time = 8687	action = 0	current_phase = 0	next_phase = 1	reward = -0.174958	array([[-1.2604779, -2.2859604]], dtype=float32)

time = 8692	action = 0	current_phase = 0	next_phase = 1	reward = 0.252082	array([[-1.8834379, -3.0939395]], dtype=float32)

time = 8697	action = 1	current_phase = 0	next_phase = 1	reward = -1.786370	array([[-3.5125012, -2.708825 ]], dtype=float32)

time = 8705	action = 0	current_phase = 1	next_phase = 0	reward = -0.546065	array([[-1.586039 , -2.1072044]], dtype=float32)

time = 8710	action = 0	current_phase = 1	next_phase = 0	reward = -0.391633	array([[-1.4946682, -2.253446 ]], dtype=float32)

time = 8715	action = 0	current_phase = 1	next_phase = 0	reward = -0.226052	array([[-1.3720405, -2.29648  ]], dtype=float32)

time = 8720	action = 0	current_phase = 1	next_phase = 0	reward = 0.380555	array([[-1.2486486, -2.6376214]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0537 - val_loss: 0.0317

Epoch 2/50

 - 4s - loss: 0.0452 - val_loss: 0.0300

Epoch 3/50

 - 5s - loss: 0.0472 - val_loss: 0.0325

Epoch 4/50

 - 4s - loss: 0.0417 - val_loss: 0.0343

Epoch 5/50

 - 4s - loss: 0.0406 - val_loss: 0.0369

Epoch 6/50

 - 4s - loss: 0.0446 - val_loss: 0.0328

Epoch 7/50

 - 5s - loss: 0.0369 - val_loss: 0.0332

Epoch 8/50

 - 4s - loss: 0.0405 - val_loss: 0.0365

Epoch 9/50

 - 4s - loss: 0.0393 - val_loss: 0.0359

Epoch 10/50

 - 4s - loss: 0.0423 - val_loss: 0.0342

Epoch 11/50

 - 4s - loss: 0.0415 - val_loss: 0.0357

Epoch 12/50

 - 4s - loss: 0.0395 - val_loss: 0.0344

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 446, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 433, after forget

time = 8725	action = 1	current_phase = 1	next_phase = 0	reward = -1.191582	array([[-2.8015776, -2.0727801]], dtype=float32)

time = 8733	action = 0	current_phase = 0	next_phase = 1	reward = -0.588782	array([[-1.4332683, -1.818537 ]], dtype=float32)

time = 8738	action = 0	current_phase = 0	next_phase = 1	reward = -0.441003	array([[-1.313073 , -2.0537689]], dtype=float32)

time = 8743	action = 0	current_phase = 0	next_phase = 1	reward = -0.293928	array([[-1.5071632, -1.5077417]], dtype=float32)

time = 8748	action = 0	current_phase = 0	next_phase = 1	reward = -0.166665	array([[-1.5621434, -2.2301629]], dtype=float32)

time = 8753	action = 0	current_phase = 0	next_phase = 1	reward = 0.072854	array([[-1.8036946, -3.2301536]], dtype=float32)

time = 8758	action = 1	current_phase = 0	next_phase = 1	reward = -1.896541	array([[-3.9423733, -3.091044 ]], dtype=float32)

time = 8766	action = 0	current_phase = 1	next_phase = 0	reward = -0.499542	array([[-1.5453359, -2.0797317]], dtype=float32)

time = 8771	action = 0	current_phase = 1	next_phase = 0	reward = -0.350743	array([[-1.5600461, -2.183492 ]], dtype=float32)

time = 8776	action = 0	current_phase = 1	next_phase = 0	reward = -0.197963	array([[-1.7098025, -2.2387578]], dtype=float32)

time = 8781	action = 0	current_phase = 1	next_phase = 0	reward = 0.317000	array([[-1.6760474, -2.9592743]], dtype=float32)

time = 8786	action = 1	current_phase = 1	next_phase = 0	reward = -1.557284	array([[-4.03686 , -2.646317]], dtype=float32)

time = 8794	action = 0	current_phase = 0	next_phase = 1	reward = -0.558724	array([[-1.4339955, -1.7715583]], dtype=float32)

time = 8799	action = 0	current_phase = 0	next_phase = 1	reward = -0.412192	array([[-1.3154986, -2.0389342]], dtype=float32)

time = 8804	action = 0	current_phase = 0	next_phase = 1	reward = -0.249977	array([[-1.4325749, -1.9280841]], dtype=float32)

time = 8809	action = 0	current_phase = 0	next_phase = 1	reward = -0.171244	array([[-1.6506486, -2.3716345]], dtype=float32)

time = 8814	action = 1	current_phase = 0	next_phase = 1	reward = -0.541273	array([[-2.4734457, -1.5945282]], dtype=float32)

time = 8822	action = 0	current_phase = 1	next_phase = 0	reward = -0.620452	array([[-1.5903578, -2.1565745]], dtype=float32)

time = 8827	action = 0	current_phase = 1	next_phase = 0	reward = -0.457654	array([[-1.7260464, -2.2605035]], dtype=float32)

time = 8832	action = 0	current_phase = 1	next_phase = 0	reward = -0.304331	array([[-1.7465883, -2.212849 ]], dtype=float32)

time = 8837	action = 0	current_phase = 1	next_phase = 0	reward = -0.175447	array([[-1.8090457, -2.1120472]], dtype=float32)

time = 8842	action = 0	current_phase = 1	next_phase = 0	reward = 0.191146	array([[-1.9643112, -2.741464 ]], dtype=float32)

time = 8847	action = 1	current_phase = 1	next_phase = 0	reward = -1.781329	array([[-3.9581983, -2.8423295]], dtype=float32)

time = 8855	action = 0	current_phase = 0	next_phase = 1	reward = -0.513404	array([[-1.4022615, -1.741306 ]], dtype=float32)

time = 8860	action = 0	current_phase = 0	next_phase = 1	reward = -0.364689	array([[-1.3272846, -2.0520535]], dtype=float32)

time = 8865	action = 0	current_phase = 0	next_phase = 1	reward = -0.214819	array([[-1.5421358, -2.174011 ]], dtype=float32)

time = 8870	action = 0	current_phase = 0	next_phase = 1	reward = 0.350522	array([[-1.3188062, -2.7251942]], dtype=float32)

time = 8875	action = 1	current_phase = 0	next_phase = 1	reward = -1.369139	array([[-2.750709, -2.304679]], dtype=float32)

time = 8883	action = 0	current_phase = 1	next_phase = 0	reward = -0.597372	array([[-1.5204397, -2.183582 ]], dtype=float32)

time = 8888	action = 0	current_phase = 1	next_phase = 0	reward = -0.436432	array([[-1.4366931, -2.2460215]], dtype=float32)

time = 8893	action = 0	current_phase = 1	next_phase = 0	reward = -0.281865	array([[-1.7177318, -2.1860597]], dtype=float32)

time = 8898	action = 0	current_phase = 1	next_phase = 0	reward = -0.164561	array([[-1.8814646, -2.0729988]], dtype=float32)

time = 8903	action = 0	current_phase = 1	next_phase = 0	reward = 0.201065	array([[-2.1336591, -2.8721542]], dtype=float32)

time = 8908	action = 1	current_phase = 1	next_phase = 0	reward = -1.888111	array([[-3.809965 , -2.7825217]], dtype=float32)

time = 8916	action = 0	current_phase = 0	next_phase = 1	reward = -0.489200	array([[-1.2568591, -1.5442691]], dtype=float32)

time = 8921	action = 0	current_phase = 0	next_phase = 1	reward = -0.332424	array([[-1.4099337, -1.9176435]], dtype=float32)

time = 8926	action = 0	current_phase = 0	next_phase = 1	reward = -0.183880	array([[-1.5443635, -2.1057153]], dtype=float32)

time = 8931	action = 0	current_phase = 0	next_phase = 1	reward = 0.294297	array([[-1.7234484, -2.8738868]], dtype=float32)

time = 8936	action = 1	current_phase = 0	next_phase = 1	reward = -1.612433	array([[-3.1012053, -2.7286985]], dtype=float32)

time = 8944	action = 0	current_phase = 1	next_phase = 0	reward = -0.555733	array([[-1.6923529, -2.1486988]], dtype=float32)

time = 8949	action = 0	current_phase = 1	next_phase = 0	reward = -0.404830	array([[-1.5302045, -2.2771473]], dtype=float32)

time = 8954	action = 0	current_phase = 1	next_phase = 0	reward = -0.252336	array([[-1.2374313, -2.399305 ]], dtype=float32)

time = 8959	action = 0	current_phase = 1	next_phase = 0	reward = -0.173571	array([[-1.7383243, -2.274213 ]], dtype=float32)

time = 8964	action = 1	current_phase = 1	next_phase = 0	reward = -0.478942	array([[-2.419187 , -1.5506188]], dtype=float32)

time = 8972	action = 0	current_phase = 0	next_phase = 1	reward = -0.621678	array([[-1.4487641, -1.8553634]], dtype=float32)

time = 8977	action = 0	current_phase = 0	next_phase = 1	reward = -0.464129	array([[-1.3128245, -2.0194998]], dtype=float32)

time = 8982	action = 0	current_phase = 0	next_phase = 1	reward = -0.317081	array([[-1.3497005, -1.8385496]], dtype=float32)

time = 8987	action = 0	current_phase = 0	next_phase = 1	reward = -0.178006	array([[-1.4980673, -2.0084548]], dtype=float32)

time = 8992	action = 0	current_phase = 0	next_phase = 1	reward = 0.172339	array([[-1.690843 , -3.3189626]], dtype=float32)

time = 8997	action = 1	current_phase = 0	next_phase = 1	reward = -1.729394	array([[-3.5040667, -2.8971279]], dtype=float32)

time = 9005	action = 0	current_phase = 1	next_phase = 0	reward = -0.531910	array([[-1.6236098, -2.1310139]], dtype=float32)

time = 9010	action = 0	current_phase = 1	next_phase = 0	reward = -0.384745	array([[-1.5427579, -2.2832217]], dtype=float32)

time = 9015	action = 0	current_phase = 1	next_phase = 0	reward = -0.232559	array([[-1.4300028, -2.318663 ]], dtype=float32)

time = 9020	action = 0	current_phase = 1	next_phase = 0	reward = 0.372292	array([[-1.4008666, -2.6919935]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0536 - val_loss: 0.0337

Epoch 2/50

 - 4s - loss: 0.0437 - val_loss: 0.0348

Epoch 3/50

 - 4s - loss: 0.0386 - val_loss: 0.0297

Epoch 4/50

 - 4s - loss: 0.0431 - val_loss: 0.0333

Epoch 5/50

 - 4s - loss: 0.0385 - val_loss: 0.0380

Epoch 6/50

 - 4s - loss: 0.0434 - val_loss: 0.0316

Epoch 7/50

 - 4s - loss: 0.0422 - val_loss: 0.0330

Epoch 8/50

 - 4s - loss: 0.0419 - val_loss: 0.0360

Epoch 9/50

 - 4s - loss: 0.0343 - val_loss: 0.0378

Epoch 10/50

 - 4s - loss: 0.0413 - val_loss: 0.0366

Epoch 11/50

 - 4s - loss: 0.0367 - val_loss: 0.0435

Epoch 12/50

 - 4s - loss: 0.0358 - val_loss: 0.0390

Epoch 13/50

 - 4s - loss: 0.0341 - val_loss: 0.0414

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 451, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 438, after forget

time = 9025	action = 1	current_phase = 1	next_phase = 0	reward = -1.252147	array([[-2.7141058, -1.8624233]], dtype=float32)

time = 9033	action = 0	current_phase = 0	next_phase = 1	reward = -0.593273	array([[-1.4463013, -1.7617775]], dtype=float32)

time = 9038	action = 0	current_phase = 0	next_phase = 1	reward = -0.443258	array([[-1.3076031, -2.055146 ]], dtype=float32)

time = 9043	action = 0	current_phase = 0	next_phase = 1	reward = -0.289620	array([[-1.6313943, -1.8220266]], dtype=float32)

time = 9048	action = 0	current_phase = 0	next_phase = 1	reward = -0.170726	array([[-1.484507 , -2.3109505]], dtype=float32)

time = 9053	action = 0	current_phase = 0	next_phase = 1	reward = 0.058395	array([[-1.7610953, -2.866997 ]], dtype=float32)

time = 9058	action = 1	current_phase = 0	next_phase = 1	reward = -1.901305	array([[-3.929202 , -2.9781857]], dtype=float32)

time = 9066	action = 0	current_phase = 1	next_phase = 0	reward = -0.510134	array([[-1.5257621, -1.9102286]], dtype=float32)

time = 9071	action = 0	current_phase = 1	next_phase = 0	reward = -0.345322	array([[-1.4625639, -2.2238207]], dtype=float32)

time = 9076	action = 0	current_phase = 1	next_phase = 0	reward = -0.196448	array([[-1.3164886, -2.3901472]], dtype=float32)

time = 9081	action = 0	current_phase = 1	next_phase = 0	reward = 0.337341	array([[-1.7471402, -2.8312714]], dtype=float32)

time = 9086	action = 1	current_phase = 1	next_phase = 0	reward = -1.452100	array([[-3.6422942, -2.6442082]], dtype=float32)

time = 9094	action = 0	current_phase = 0	next_phase = 1	reward = -0.549461	array([[-1.432606 , -1.7626247]], dtype=float32)

time = 9099	action = 0	current_phase = 0	next_phase = 1	reward = -0.395348	array([[-1.2860667, -2.0313394]], dtype=float32)

time = 9104	action = 0	current_phase = 0	next_phase = 1	reward = -0.246706	array([[-1.4605283, -2.2516792]], dtype=float32)

time = 9109	action = 0	current_phase = 0	next_phase = 1	reward = -0.175017	array([[-0.9098095, -2.6613858]], dtype=float32)

time = 9114	action = 1	current_phase = 0	next_phase = 1	reward = -0.529317	array([[-2.4889052, -1.7902383]], dtype=float32)

time = 9122	action = 0	current_phase = 1	next_phase = 0	reward = -0.619388	array([[-1.5177138, -2.1639948]], dtype=float32)

time = 9127	action = 0	current_phase = 1	next_phase = 0	reward = -0.457223	array([[-1.2019894, -2.3129377]], dtype=float32)

time = 9132	action = 0	current_phase = 1	next_phase = 0	reward = -0.300988	array([[-1.5573994, -2.270254 ]], dtype=float32)

time = 9137	action = 0	current_phase = 1	next_phase = 0	reward = -0.168938	array([[-1.7810416, -2.1095798]], dtype=float32)

time = 9142	action = 0	current_phase = 1	next_phase = 0	reward = 0.115492	array([[-1.9562246, -3.0773404]], dtype=float32)

time = 9147	action = 1	current_phase = 1	next_phase = 0	reward = -1.789519	array([[-3.9534693, -2.796369 ]], dtype=float32)

time = 9155	action = 0	current_phase = 0	next_phase = 1	reward = -0.529417	array([[-1.4065924, -1.7067808]], dtype=float32)

time = 9160	action = 0	current_phase = 0	next_phase = 1	reward = -0.367641	array([[-1.3180634, -2.110272 ]], dtype=float32)

time = 9165	action = 0	current_phase = 0	next_phase = 1	reward = -0.219493	array([[-1.4370567, -1.9264898]], dtype=float32)

time = 9170	action = 0	current_phase = 0	next_phase = 1	reward = 0.365994	array([[-1.6544018, -2.4424427]], dtype=float32)

time = 9175	action = 1	current_phase = 0	next_phase = 1	reward = -1.310774	array([[-2.781404 , -2.4781077]], dtype=float32)

time = 9183	action = 0	current_phase = 1	next_phase = 0	reward = -0.597112	array([[-1.4281974, -2.2046494]], dtype=float32)

time = 9188	action = 0	current_phase = 1	next_phase = 0	reward = -0.433881	array([[-1.4239435, -2.3140247]], dtype=float32)

time = 9193	action = 0	current_phase = 1	next_phase = 0	reward = -0.273226	array([[-1.4910365, -2.2184634]], dtype=float32)

time = 9198	action = 0	current_phase = 1	next_phase = 0	reward = -0.159858	array([[-1.816949 , -2.0908034]], dtype=float32)

time = 9203	action = 0	current_phase = 1	next_phase = 0	reward = -0.036453	array([[-1.7954404, -3.2557056]], dtype=float32)

time = 9208	action = 1	current_phase = 1	next_phase = 0	reward = -1.902771	array([[-4.006259 , -2.8087776]], dtype=float32)

time = 9216	action = 0	current_phase = 0	next_phase = 1	reward = -0.497288	array([[-1.2701968, -1.522561 ]], dtype=float32)

time = 9221	action = 0	current_phase = 0	next_phase = 1	reward = -0.349376	array([[-1.2948692, -2.0371675]], dtype=float32)

time = 9226	action = 0	current_phase = 0	next_phase = 1	reward = -0.205792	array([[-1.5382273, -2.13838  ]], dtype=float32)

time = 9231	action = 0	current_phase = 0	next_phase = 1	reward = 0.292156	array([[-1.8996489, -2.5953546]], dtype=float32)

time = 9236	action = 1	current_phase = 0	next_phase = 1	reward = -1.662424	array([[-2.9538443, -2.6573317]], dtype=float32)

time = 9244	action = 0	current_phase = 1	next_phase = 0	reward = -0.550218	array([[-1.4918289, -2.185049 ]], dtype=float32)

time = 9249	action = 0	current_phase = 1	next_phase = 0	reward = -0.390393	array([[-1.4356385, -2.3158798]], dtype=float32)

time = 9254	action = 0	current_phase = 1	next_phase = 0	reward = -0.234505	array([[-1.4690729, -2.2346838]], dtype=float32)

time = 9259	action = 0	current_phase = 1	next_phase = 0	reward = -0.176311	array([[-1.4775033, -2.4883647]], dtype=float32)

time = 9264	action = 1	current_phase = 1	next_phase = 0	reward = -0.483396	array([[-2.6608872, -1.9154146]], dtype=float32)

time = 9272	action = 0	current_phase = 0	next_phase = 1	reward = -0.627158	array([[-1.43487 , -1.836451]], dtype=float32)

time = 9277	action = 0	current_phase = 0	next_phase = 1	reward = -0.474723	array([[-1.3114471, -2.0251822]], dtype=float32)

time = 9282	action = 0	current_phase = 0	next_phase = 1	reward = -0.315661	array([[-1.423315 , -1.5145602]], dtype=float32)

time = 9287	action = 0	current_phase = 0	next_phase = 1	reward = -0.180796	array([[-1.4255656, -2.0250537]], dtype=float32)

time = 9292	action = 0	current_phase = 0	next_phase = 1	reward = 0.261707	array([[-1.3599977, -3.1329725]], dtype=float32)

time = 9297	action = 1	current_phase = 0	next_phase = 1	reward = -1.779738	array([[-3.4564862, -2.7913916]], dtype=float32)

time = 9305	action = 0	current_phase = 1	next_phase = 0	reward = -0.524359	array([[-1.4849396, -2.1311173]], dtype=float32)

time = 9310	action = 0	current_phase = 1	next_phase = 0	reward = -0.365390	array([[-1.4075214, -2.3106117]], dtype=float32)

time = 9315	action = 0	current_phase = 1	next_phase = 0	reward = -0.202480	array([[-1.0188777, -2.5778968]], dtype=float32)

time = 9320	action = 0	current_phase = 1	next_phase = 0	reward = 0.345547	array([[-1.4049958, -2.755556 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0589 - val_loss: 0.0358

Epoch 2/50

 - 4s - loss: 0.0563 - val_loss: 0.0371

Epoch 3/50

 - 4s - loss: 0.0536 - val_loss: 0.0356

Epoch 4/50

 - 4s - loss: 0.0503 - val_loss: 0.0359

Epoch 5/50

 - 5s - loss: 0.0543 - val_loss: 0.0361

Epoch 6/50

 - 5s - loss: 0.0485 - val_loss: 0.0357

Epoch 7/50

 - 6s - loss: 0.0461 - val_loss: 0.0354

Epoch 8/50

 - 5s - loss: 0.0447 - val_loss: 0.0366

Epoch 9/50

 - 4s - loss: 0.0509 - val_loss: 0.0364

Epoch 10/50

 - 5s - loss: 0.0429 - val_loss: 0.0374

Epoch 11/50

 - 4s - loss: 0.0486 - val_loss: 0.0383

Epoch 12/50

 - 4s - loss: 0.0477 - val_loss: 0.0389

Epoch 13/50

 - 4s - loss: 0.0435 - val_loss: 0.0391

Epoch 14/50

 - 4s - loss: 0.0487 - val_loss: 0.0384

Epoch 15/50

 - 5s - loss: 0.0437 - val_loss: 0.0386

Epoch 16/50

 - 4s - loss: 0.0413 - val_loss: 0.0384

Epoch 17/50

 - 4s - loss: 0.0420 - val_loss: 0.0395

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 456, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 443, after forget

time = 9325	action = 1	current_phase = 1	next_phase = 0	reward = -1.416806	array([[-3.384694 , -2.1197424]], dtype=float32)

time = 9333	action = 0	current_phase = 0	next_phase = 1	reward = -0.574174	array([[-1.5711007, -1.8172865]], dtype=float32)

time = 9338	action = 0	current_phase = 0	next_phase = 1	reward = -0.413416	array([[-1.4562696, -2.0775645]], dtype=float32)

time = 9343	action = 0	current_phase = 0	next_phase = 1	reward = -0.259637	array([[-1.3665122, -1.4109228]], dtype=float32)

time = 9348	action = 0	current_phase = 0	next_phase = 1	reward = -0.168988	array([[-1.9513294, -2.448014 ]], dtype=float32)

time = 9353	action = 1	current_phase = 0	next_phase = 1	reward = -0.314008	array([[-2.3840926, -1.9733597]], dtype=float32)

time = 9361	action = 0	current_phase = 1	next_phase = 0	reward = -0.659589	array([[-1.7728903, -2.1123846]], dtype=float32)

time = 9366	action = 0	current_phase = 1	next_phase = 0	reward = -0.510616	array([[-1.8126165, -1.9347442]], dtype=float32)

time = 9371	action = 0	current_phase = 1	next_phase = 0	reward = -0.362576	array([[-1.625686 , -2.2429276]], dtype=float32)

time = 9376	action = 0	current_phase = 1	next_phase = 0	reward = -0.211226	array([[-1.5209881, -2.328155 ]], dtype=float32)

time = 9381	action = 0	current_phase = 1	next_phase = 0	reward = 0.359069	array([[-1.6644586, -2.437947 ]], dtype=float32)

time = 9386	action = 1	current_phase = 1	next_phase = 0	reward = -1.492432	array([[-3.5167851, -2.6196637]], dtype=float32)

time = 9394	action = 0	current_phase = 0	next_phase = 1	reward = -0.555301	array([[-1.6095935, -1.7996942]], dtype=float32)

time = 9399	action = 0	current_phase = 0	next_phase = 1	reward = -0.404451	array([[-1.4244627, -2.0370154]], dtype=float32)

time = 9404	action = 0	current_phase = 0	next_phase = 1	reward = -0.260202	array([[-1.5199541, -2.0699112]], dtype=float32)

time = 9409	action = 0	current_phase = 0	next_phase = 1	reward = -0.181707	array([[-1.1599079, -2.23976  ]], dtype=float32)

time = 9414	action = 1	current_phase = 0	next_phase = 1	reward = -0.548866	array([[-2.4179087, -1.9030269]], dtype=float32)

time = 9422	action = 0	current_phase = 1	next_phase = 0	reward = -0.608098	array([[-1.7995888, -2.152362 ]], dtype=float32)

time = 9427	action = 0	current_phase = 1	next_phase = 0	reward = -0.451633	array([[-1.7323252, -2.2651248]], dtype=float32)

time = 9432	action = 0	current_phase = 1	next_phase = 0	reward = -0.309232	array([[-1.6354043, -2.1986194]], dtype=float32)

time = 9437	action = 0	current_phase = 1	next_phase = 0	reward = -0.176252	array([[-1.7182776, -2.1679237]], dtype=float32)

time = 9442	action = 0	current_phase = 1	next_phase = 0	reward = 0.239354	array([[-2.0073175, -2.6952198]], dtype=float32)

time = 9447	action = 1	current_phase = 1	next_phase = 0	reward = -1.776890	array([[-4.197443, -2.726015]], dtype=float32)

time = 9455	action = 0	current_phase = 0	next_phase = 1	reward = -0.513366	array([[-1.4724908, -1.7105644]], dtype=float32)

time = 9460	action = 0	current_phase = 0	next_phase = 1	reward = -0.361833	array([[-1.4397819, -2.0238047]], dtype=float32)

time = 9465	action = 0	current_phase = 0	next_phase = 1	reward = -0.209098	array([[-1.4295863, -1.9809868]], dtype=float32)

time = 9470	action = 0	current_phase = 0	next_phase = 1	reward = 0.355767	array([[-2.0658574, -2.5037005]], dtype=float32)

time = 9475	action = 1	current_phase = 0	next_phase = 1	reward = -1.313232	array([[-2.8078787, -2.5596905]], dtype=float32)

time = 9483	action = 0	current_phase = 1	next_phase = 0	reward = -0.596586	array([[-1.7091386, -2.1628673]], dtype=float32)

time = 9488	action = 0	current_phase = 1	next_phase = 0	reward = -0.444342	array([[-1.5781193, -2.276802 ]], dtype=float32)

time = 9493	action = 0	current_phase = 1	next_phase = 0	reward = -0.292161	array([[-1.7782928, -2.2094853]], dtype=float32)

time = 9498	action = 0	current_phase = 1	next_phase = 0	reward = -0.167939	array([[-1.6072813, -2.3986943]], dtype=float32)

time = 9503	action = 0	current_phase = 1	next_phase = 0	reward = 0.032923	array([[-2.4958549, -2.7446659]], dtype=float32)

time = 9508	action = 1	current_phase = 1	next_phase = 0	reward = -1.900426	array([[-4.1781387, -2.9203854]], dtype=float32)

time = 9516	action = 0	current_phase = 0	next_phase = 1	reward = -0.501241	array([[-1.4026595, -1.6105752]], dtype=float32)

time = 9521	action = 0	current_phase = 0	next_phase = 1	reward = -0.338751	array([[-1.2900797, -2.0473297]], dtype=float32)

time = 9526	action = 0	current_phase = 0	next_phase = 1	reward = -0.186695	array([[-1.4616205, -1.8647895]], dtype=float32)

time = 9531	action = 0	current_phase = 0	next_phase = 1	reward = 0.288399	array([[-2.0476792, -2.7537947]], dtype=float32)

time = 9536	action = 1	current_phase = 0	next_phase = 1	reward = -1.557778	array([[-3.045906 , -2.7879648]], dtype=float32)

time = 9544	action = 0	current_phase = 1	next_phase = 0	reward = -0.564163	array([[-1.751087, -2.160708]], dtype=float32)

time = 9549	action = 0	current_phase = 1	next_phase = 0	reward = -0.407614	array([[-1.5760627, -2.2798522]], dtype=float32)

time = 9554	action = 0	current_phase = 1	next_phase = 0	reward = -0.260974	array([[-1.6981024, -2.2484398]], dtype=float32)

time = 9559	action = 0	current_phase = 1	next_phase = 0	reward = -0.176559	array([[-1.4728274, -2.488271 ]], dtype=float32)

time = 9564	action = 1	current_phase = 1	next_phase = 0	reward = -0.546124	array([[-2.6063085, -1.3779762]], dtype=float32)

time = 9572	action = 0	current_phase = 0	next_phase = 1	reward = -0.617631	array([[-1.576607 , -1.8149195]], dtype=float32)

time = 9577	action = 0	current_phase = 0	next_phase = 1	reward = -0.455686	array([[-1.4290574, -2.0292382]], dtype=float32)

time = 9582	action = 0	current_phase = 0	next_phase = 1	reward = -0.297974	array([[-1.4812416, -1.5165539]], dtype=float32)

time = 9587	action = 0	current_phase = 0	next_phase = 1	reward = -0.174358	array([[-1.2544957, -2.272999 ]], dtype=float32)

time = 9592	action = 0	current_phase = 0	next_phase = 1	reward = 0.196906	array([[-1.8552074, -2.929813 ]], dtype=float32)

time = 9597	action = 1	current_phase = 0	next_phase = 1	reward = -1.783109	array([[-3.7206821, -2.8809283]], dtype=float32)

time = 9605	action = 0	current_phase = 1	next_phase = 0	reward = -0.529788	array([[-1.6783329, -2.092247 ]], dtype=float32)

time = 9610	action = 0	current_phase = 1	next_phase = 0	reward = -0.374597	array([[-1.554249 , -2.2894976]], dtype=float32)

time = 9615	action = 0	current_phase = 1	next_phase = 0	reward = -0.230554	array([[-1.5183685, -2.3422194]], dtype=float32)

time = 9620	action = 0	current_phase = 1	next_phase = 0	reward = 0.080593	array([[-1.4759878, -2.5965357]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0534 - val_loss: 0.0250

Epoch 2/50

 - 4s - loss: 0.0518 - val_loss: 0.0253

Epoch 3/50

 - 4s - loss: 0.0480 - val_loss: 0.0247

Epoch 4/50

 - 4s - loss: 0.0494 - val_loss: 0.0268

Epoch 5/50

 - 4s - loss: 0.0500 - val_loss: 0.0280

Epoch 6/50

 - 4s - loss: 0.0475 - val_loss: 0.0265

Epoch 7/50

 - 4s - loss: 0.0409 - val_loss: 0.0263

Epoch 8/50

 - 4s - loss: 0.0394 - val_loss: 0.0278

Epoch 9/50

 - 4s - loss: 0.0423 - val_loss: 0.0277

Epoch 10/50

 - 4s - loss: 0.0396 - val_loss: 0.0292

Epoch 11/50

 - 4s - loss: 0.0411 - val_loss: 0.0305

Epoch 12/50

 - 4s - loss: 0.0411 - val_loss: 0.0301

Epoch 13/50

 - 4s - loss: 0.0386 - val_loss: 0.0297

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 461, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 448, after forget

time = 9625	action = 1	current_phase = 1	next_phase = 0	reward = -0.971183	array([[-2.6942272, -2.2701406]], dtype=float32)

time = 9633	action = 0	current_phase = 0	next_phase = 1	reward = -0.582922	array([[-1.5974349, -1.7726552]], dtype=float32)

time = 9638	action = 0	current_phase = 0	next_phase = 1	reward = -0.428478	array([[-1.487182 , -1.9788485]], dtype=float32)

time = 9643	action = 0	current_phase = 0	next_phase = 1	reward = -0.281045	array([[-1.3888807, -1.4731879]], dtype=float32)

time = 9648	action = 0	current_phase = 0	next_phase = 1	reward = -0.169033	array([[-1.59971 , -2.180246]], dtype=float32)

time = 9653	action = 0	current_phase = 0	next_phase = 1	reward = 0.035862	array([[-1.8834258, -1.9333103]], dtype=float32)

time = 9658	action = 1	current_phase = 0	next_phase = 1	reward = -1.894488	array([[-4.1990585, -3.0490558]], dtype=float32)

time = 9666	action = 0	current_phase = 1	next_phase = 0	reward = -0.490549	array([[-1.7334241, -2.1067867]], dtype=float32)

time = 9671	action = 0	current_phase = 1	next_phase = 0	reward = -0.338995	array([[-1.5490093, -2.2085867]], dtype=float32)

time = 9676	action = 0	current_phase = 1	next_phase = 0	reward = -0.194211	array([[-1.5311829, -2.3066893]], dtype=float32)

time = 9681	action = 0	current_phase = 1	next_phase = 0	reward = 0.304256	array([[-1.8568752, -2.9542909]], dtype=float32)

time = 9686	action = 1	current_phase = 1	next_phase = 0	reward = -1.607727	array([[-3.9273503, -2.8249717]], dtype=float32)

time = 9694	action = 0	current_phase = 0	next_phase = 1	reward = -0.558089	array([[-1.6168002, -1.7530124]], dtype=float32)

time = 9699	action = 0	current_phase = 0	next_phase = 1	reward = -0.414329	array([[-1.4681684, -1.9853349]], dtype=float32)

time = 9704	action = 0	current_phase = 0	next_phase = 1	reward = -0.271170	array([[-1.370984 , -1.6695771]], dtype=float32)

time = 9709	action = 0	current_phase = 0	next_phase = 1	reward = -0.175516	array([[-1.275241, -2.380586]], dtype=float32)

time = 9714	action = 1	current_phase = 0	next_phase = 1	reward = -0.434910	array([[-2.4492846, -1.7716908]], dtype=float32)

time = 9722	action = 0	current_phase = 1	next_phase = 0	reward = -0.613677	array([[-1.6784656, -2.2071562]], dtype=float32)

time = 9727	action = 0	current_phase = 1	next_phase = 0	reward = -0.458047	array([[-1.4324205, -2.2651715]], dtype=float32)

time = 9732	action = 0	current_phase = 1	next_phase = 0	reward = -0.296592	array([[-1.17923, -2.21966]], dtype=float32)

time = 9737	action = 0	current_phase = 1	next_phase = 0	reward = -0.170580	array([[-1.5001438, -2.2429442]], dtype=float32)

time = 9742	action = 0	current_phase = 1	next_phase = 0	reward = 0.110626	array([[-2.134664 , -3.0088916]], dtype=float32)

time = 9747	action = 1	current_phase = 1	next_phase = 0	reward = -1.792548	array([[-4.193837, -3.006907]], dtype=float32)

time = 9755	action = 0	current_phase = 0	next_phase = 1	reward = -0.536165	array([[-1.4351596, -1.5708561]], dtype=float32)

time = 9760	action = 0	current_phase = 0	next_phase = 1	reward = -0.373873	array([[-1.4799678, -1.9895513]], dtype=float32)

time = 9765	action = 0	current_phase = 0	next_phase = 1	reward = -0.216169	array([[-1.4894115, -1.9538715]], dtype=float32)

time = 9770	action = 0	current_phase = 0	next_phase = 1	reward = 0.361191	array([[-1.4632952, -2.85506  ]], dtype=float32)

time = 9775	action = 1	current_phase = 0	next_phase = 1	reward = -1.360445	array([[-2.652042 , -2.3599527]], dtype=float32)

time = 9783	action = 0	current_phase = 1	next_phase = 0	reward = -0.584368	array([[-1.693534 , -2.1824305]], dtype=float32)

time = 9788	action = 0	current_phase = 1	next_phase = 0	reward = -0.429039	array([[-1.5364692, -2.2634315]], dtype=float32)

time = 9793	action = 0	current_phase = 1	next_phase = 0	reward = -0.279792	array([[-1.7614354, -2.2045736]], dtype=float32)

time = 9798	action = 0	current_phase = 1	next_phase = 0	reward = -0.158710	array([[-1.9024581, -2.1045475]], dtype=float32)

time = 9803	action = 0	current_phase = 1	next_phase = 0	reward = 0.172869	array([[-2.1143265, -2.7014403]], dtype=float32)

time = 9808	action = 1	current_phase = 1	next_phase = 0	reward = -1.887295	array([[-4.094075 , -2.8519964]], dtype=float32)

time = 9816	action = 0	current_phase = 0	next_phase = 1	reward = -0.498022	array([[-1.4515738, -1.5478187]], dtype=float32)

time = 9821	action = 0	current_phase = 0	next_phase = 1	reward = -0.341987	array([[-1.5457094, -1.8681931]], dtype=float32)

time = 9826	action = 0	current_phase = 0	next_phase = 1	reward = -0.196412	array([[-1.5500302, -2.0371006]], dtype=float32)

time = 9831	action = 0	current_phase = 0	next_phase = 1	reward = 0.318097	array([[-1.9586936, -2.703234 ]], dtype=float32)

time = 9836	action = 1	current_phase = 0	next_phase = 1	reward = -1.554799	array([[-2.9912632, -2.8157594]], dtype=float32)

time = 9844	action = 0	current_phase = 1	next_phase = 0	reward = -0.556396	array([[-1.7428094, -2.1808765]], dtype=float32)

time = 9849	action = 0	current_phase = 1	next_phase = 0	reward = -0.397650	array([[-1.5287954, -2.287562 ]], dtype=float32)

time = 9854	action = 0	current_phase = 1	next_phase = 0	reward = -0.252049	array([[-1.4807376, -2.2888885]], dtype=float32)

time = 9859	action = 0	current_phase = 1	next_phase = 0	reward = -0.182566	array([[-1.4354148, -2.4538035]], dtype=float32)

time = 9864	action = 1	current_phase = 1	next_phase = 0	reward = -0.498092	array([[-2.0344625, -1.431219 ]], dtype=float32)

time = 9872	action = 0	current_phase = 0	next_phase = 1	reward = -0.626674	array([[-1.6131457, -1.7646737]], dtype=float32)

time = 9877	action = 0	current_phase = 0	next_phase = 1	reward = -0.478237	array([[-1.4902877, -1.9719043]], dtype=float32)

time = 9882	action = 0	current_phase = 0	next_phase = 1	reward = -0.330023	array([[-1.078737, -1.935353]], dtype=float32)

time = 9887	action = 0	current_phase = 0	next_phase = 1	reward = -0.190581	array([[-1.4854882, -1.8624513]], dtype=float32)

time = 9892	action = 0	current_phase = 0	next_phase = 1	reward = 0.240562	array([[-1.9490252, -3.125285 ]], dtype=float32)

time = 9897	action = 1	current_phase = 0	next_phase = 1	reward = -1.782583	array([[-3.5744712, -2.9205647]], dtype=float32)

time = 9905	action = 0	current_phase = 1	next_phase = 0	reward = -0.531868	array([[-1.6610426, -2.1261492]], dtype=float32)

time = 9910	action = 0	current_phase = 1	next_phase = 0	reward = -0.375807	array([[-1.4904147, -2.2843862]], dtype=float32)

time = 9915	action = 0	current_phase = 1	next_phase = 0	reward = -0.231200	array([[-1.4021673, -2.3175902]], dtype=float32)

time = 9920	action = 0	current_phase = 1	next_phase = 0	reward = 0.367850	array([[-1.2557559, -2.7098837]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0533 - val_loss: 0.0356

Epoch 2/50

 - 4s - loss: 0.0472 - val_loss: 0.0360

Epoch 3/50

 - 4s - loss: 0.0471 - val_loss: 0.0396

Epoch 4/50

 - 4s - loss: 0.0494 - val_loss: 0.0383

Epoch 5/50

 - 4s - loss: 0.0459 - val_loss: 0.0375

Epoch 6/50

 - 4s - loss: 0.0416 - val_loss: 0.0436

Epoch 7/50

 - 4s - loss: 0.0459 - val_loss: 0.0414

Epoch 8/50

 - 4s - loss: 0.0430 - val_loss: 0.0379

Epoch 9/50

 - 4s - loss: 0.0399 - val_loss: 0.0387

Epoch 10/50

 - 4s - loss: 0.0421 - val_loss: 0.0422

Epoch 11/50

 - 4s - loss: 0.0411 - val_loss: 0.0380

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 466, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 453, after forget

time = 9925	action = 1	current_phase = 1	next_phase = 0	reward = -1.305844	array([[-3.1108243, -2.2961605]], dtype=float32)

time = 9933	action = 0	current_phase = 0	next_phase = 1	reward = -0.588821	array([[-1.5947862, -1.8073045]], dtype=float32)

time = 9938	action = 0	current_phase = 0	next_phase = 1	reward = -0.441498	array([[-1.511934 , -2.0092156]], dtype=float32)

time = 9943	action = 1	current_phase = 0	next_phase = 1	reward = -1.398758	array([[-1.4239752, -1.394111 ]], dtype=float32)

time = 9951	action = 0	current_phase = 1	next_phase = 0	reward = 0.311906	array([[-0.37587082, -2.499717  ]], dtype=float32)

time = 9956	action = 0	current_phase = 1	next_phase = 0	reward = -1.006511	array([[-0.18364154, -2.8522508 ]], dtype=float32)

time = 9961	action = 0	current_phase = 1	next_phase = 0	reward = -1.706330	array([[-2.1422138, -3.1330717]], dtype=float32)

time = 9966	action = 0	current_phase = 1	next_phase = 0	reward = -1.595014	array([[-2.6626267, -2.6633995]], dtype=float32)

time = 9971	action = 1	current_phase = 1	next_phase = 0	reward = -1.542106	array([[-3.5325737, -2.6766062]], dtype=float32)

time = 9979	action = 0	current_phase = 0	next_phase = 1	reward = -0.180096	array([[-1.3687389, -1.8531272]], dtype=float32)

time = 9984	action = 1	current_phase = 0	next_phase = 1	reward = -0.549393	array([[-3.3235576, -2.1462138]], dtype=float32)

time = 9992	action = 0	current_phase = 1	next_phase = 0	reward = -0.626175	array([[-1.500354 , -2.2728806]], dtype=float32)

time = 9997	action = 0	current_phase = 1	next_phase = 0	reward = -0.472465	array([[-1.7972704, -2.2040794]], dtype=float32)

time = 10002	action = 0	current_phase = 1	next_phase = 0	reward = -0.310946	array([[-1.6585008, -2.2531707]], dtype=float32)

time = 10007	action = 0	current_phase = 1	next_phase = 0	reward = -0.168710	array([[-1.7188141, -2.2494187]], dtype=float32)

time = 10012	action = 0	current_phase = 1	next_phase = 0	reward = 0.231151	array([[-2.1389494, -3.0691826]], dtype=float32)

time = 10017	action = 1	current_phase = 1	next_phase = 0	reward = -1.782715	array([[-4.2543225, -2.8917263]], dtype=float32)

time = 10025	action = 0	current_phase = 0	next_phase = 1	reward = -0.535241	array([[-1.4474528, -1.5793291]], dtype=float32)

time = 10030	action = 0	current_phase = 0	next_phase = 1	reward = -0.384302	array([[-1.4727876, -2.042681 ]], dtype=float32)

time = 10035	action = 0	current_phase = 0	next_phase = 1	reward = -0.238782	array([[-1.5414524, -2.120709 ]], dtype=float32)

time = 10040	action = 0	current_phase = 0	next_phase = 1	reward = -0.224179	array([[-1.2854788, -2.3204787]], dtype=float32)

time = 10045	action = 0	current_phase = 0	next_phase = 1	reward = -0.225288	array([[-1.9989581, -2.0822077]], dtype=float32)

time = 10050	action = 1	current_phase = 0	next_phase = 1	reward = -2.115303	array([[-4.0175033, -3.202522 ]], dtype=float32)

time = 10058	action = 0	current_phase = 1	next_phase = 0	reward = -0.441494	array([[-1.671033 , -2.1814666]], dtype=float32)

time = 10063	action = 0	current_phase = 1	next_phase = 0	reward = -0.290581	array([[-1.7023796, -2.2155008]], dtype=float32)

time = 10068	action = 0	current_phase = 1	next_phase = 0	reward = -0.167060	array([[-1.8042446, -2.1714795]], dtype=float32)

time = 10073	action = 0	current_phase = 1	next_phase = 0	reward = 0.137940	array([[-1.8596929, -3.1532907]], dtype=float32)

time = 10078	action = 1	current_phase = 1	next_phase = 0	reward = -1.884591	array([[-4.044086 , -2.8954258]], dtype=float32)

time = 10086	action = 0	current_phase = 0	next_phase = 1	reward = -0.483048	array([[-1.4226034, -1.5608739]], dtype=float32)

time = 10091	action = 0	current_phase = 0	next_phase = 1	reward = -0.338466	array([[-1.5568643, -1.8082168]], dtype=float32)

time = 10096	action = 0	current_phase = 0	next_phase = 1	reward = -0.198420	array([[-1.4725678, -1.907813 ]], dtype=float32)

time = 10101	action = 0	current_phase = 0	next_phase = 1	reward = 0.282603	array([[-1.7361283, -2.7420483]], dtype=float32)

time = 10106	action = 1	current_phase = 0	next_phase = 1	reward = -1.613634	array([[-2.9836192, -2.9725366]], dtype=float32)

time = 10114	action = 0	current_phase = 1	next_phase = 0	reward = -0.565494	array([[-1.7451562, -2.2093947]], dtype=float32)

time = 10119	action = 0	current_phase = 1	next_phase = 0	reward = -0.416518	array([[-1.5369599, -2.3202221]], dtype=float32)

time = 10124	action = 0	current_phase = 1	next_phase = 0	reward = -0.265026	array([[-1.5064807, -2.3146608]], dtype=float32)

time = 10129	action = 0	current_phase = 1	next_phase = 0	reward = -0.169463	array([[-1.6500727, -2.285851 ]], dtype=float32)

time = 10134	action = 1	current_phase = 1	next_phase = 0	reward = -0.358035	array([[-2.796296 , -1.7006255]], dtype=float32)

time = 10142	action = 0	current_phase = 0	next_phase = 1	reward = -0.627690	array([[-1.6406019, -1.9756249]], dtype=float32)

time = 10147	action = 0	current_phase = 0	next_phase = 1	reward = -0.470522	array([[-1.5193756, -2.0086415]], dtype=float32)

time = 10152	action = 0	current_phase = 0	next_phase = 1	reward = -0.321362	array([[-1.1770489, -1.9982748]], dtype=float32)

time = 10157	action = 0	current_phase = 0	next_phase = 1	reward = -0.182899	array([[-1.3996215, -1.6680297]], dtype=float32)

time = 10162	action = 0	current_phase = 0	next_phase = 1	reward = 0.190376	array([[-1.9022226, -3.3221667]], dtype=float32)

time = 10167	action = 1	current_phase = 0	next_phase = 1	reward = -1.783034	array([[-3.457409 , -3.2352152]], dtype=float32)

time = 10175	action = 0	current_phase = 1	next_phase = 0	reward = -0.535497	array([[-1.7030665, -2.1052167]], dtype=float32)

time = 10180	action = 0	current_phase = 1	next_phase = 0	reward = -0.381545	array([[-1.5246568, -2.3179367]], dtype=float32)

time = 10185	action = 0	current_phase = 1	next_phase = 0	reward = -0.221501	array([[-1.4169961, -2.3591824]], dtype=float32)

time = 10190	action = 0	current_phase = 1	next_phase = 0	reward = 0.382925	array([[-1.3985933, -2.677425 ]], dtype=float32)

time = 10195	action = 1	current_phase = 1	next_phase = 0	reward = -1.190847	array([[-3.138469 , -1.9165024]], dtype=float32)

time = 10203	action = 0	current_phase = 0	next_phase = 1	reward = -0.588369	array([[-1.6053205, -1.7726728]], dtype=float32)

time = 10208	action = 0	current_phase = 0	next_phase = 1	reward = -0.424948	array([[-1.5007348, -2.011416 ]], dtype=float32)

time = 10213	action = 0	current_phase = 0	next_phase = 1	reward = -0.271066	array([[-1.5737562, -1.5890456]], dtype=float32)

time = 10218	action = 0	current_phase = 0	next_phase = 1	reward = -0.161665	array([[-1.7490809, -2.2537916]], dtype=float32)

time = 10223	action = 1	current_phase = 0	next_phase = 1	reward = -1.065050	array([[-2.2987478, -2.18048  ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0483 - val_loss: 0.0205

Epoch 2/50

 - 4s - loss: 0.0461 - val_loss: 0.0197

Epoch 3/50

 - 4s - loss: 0.0465 - val_loss: 0.0204

Epoch 4/50

 - 4s - loss: 0.0414 - val_loss: 0.0216

Epoch 5/50

 - 4s - loss: 0.0431 - val_loss: 0.0202

Epoch 6/50

 - 4s - loss: 0.0396 - val_loss: 0.0212

Epoch 7/50

 - 5s - loss: 0.0420 - val_loss: 0.0210

Epoch 8/50

 - 4s - loss: 0.0348 - val_loss: 0.0211

Epoch 9/50

 - 4s - loss: 0.0409 - val_loss: 0.0216

Epoch 10/50

 - 5s - loss: 0.0376 - val_loss: 0.0226

Epoch 11/50

 - 4s - loss: 0.0353 - val_loss: 0.0208

Epoch 12/50

 - 4s - loss: 0.0381 - val_loss: 0.0235

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 472, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 459, after forget

time = 10231	action = 0	current_phase = 1	next_phase = 0	reward = -1.180011	array([[-2.0244746, -2.3458967]], dtype=float32)

time = 10236	action = 1	current_phase = 1	next_phase = 0	reward = -1.772138	array([[-2.2668314, -2.151114 ]], dtype=float32)

time = 10244	action = 0	current_phase = 0	next_phase = 1	reward = -0.262723	array([[-1.9368461, -2.1921816]], dtype=float32)

time = 10249	action = 0	current_phase = 0	next_phase = 1	reward = -0.182566	array([[-1.4078574, -2.4211957]], dtype=float32)

time = 10254	action = 0	current_phase = 0	next_phase = 1	reward = -0.143776	array([[-1.1836171, -1.8138239]], dtype=float32)

time = 10259	action = 1	current_phase = 0	next_phase = 1	reward = -2.010897	array([[-3.2049918, -2.9196448]], dtype=float32)

time = 10267	action = 0	current_phase = 1	next_phase = 0	reward = -0.468353	array([[-1.6200026, -2.1912603]], dtype=float32)

time = 10272	action = 0	current_phase = 1	next_phase = 0	reward = -0.309264	array([[-1.7262536, -2.2314692]], dtype=float32)

time = 10277	action = 0	current_phase = 1	next_phase = 0	reward = -0.175662	array([[-1.8716286, -2.1489444]], dtype=float32)

time = 10282	action = 0	current_phase = 1	next_phase = 0	reward = 0.225387	array([[-1.9218782, -3.0415533]], dtype=float32)

time = 10287	action = 1	current_phase = 1	next_phase = 0	reward = -1.778105	array([[-4.1519866, -2.8328776]], dtype=float32)

time = 10295	action = 0	current_phase = 0	next_phase = 1	reward = -0.518524	array([[-1.5532788, -1.5840034]], dtype=float32)

time = 10300	action = 0	current_phase = 0	next_phase = 1	reward = -0.354942	array([[-1.5703331, -2.0177517]], dtype=float32)

time = 10305	action = 0	current_phase = 0	next_phase = 1	reward = -0.205788	array([[-1.3322484, -1.8652152]], dtype=float32)

time = 10310	action = 0	current_phase = 0	next_phase = 1	reward = 0.340598	array([[-1.3354644, -2.5465422]], dtype=float32)

time = 10315	action = 1	current_phase = 0	next_phase = 1	reward = -1.315990	array([[-2.7289608, -2.6555867]], dtype=float32)

time = 10323	action = 0	current_phase = 1	next_phase = 0	reward = -0.589415	array([[-1.7619282, -2.224261 ]], dtype=float32)

time = 10328	action = 0	current_phase = 1	next_phase = 0	reward = -0.437578	array([[-1.5715638, -2.317547 ]], dtype=float32)

time = 10333	action = 0	current_phase = 1	next_phase = 0	reward = -0.279750	array([[-1.6030126, -2.2889297]], dtype=float32)

time = 10338	action = 0	current_phase = 1	next_phase = 0	reward = -0.161802	array([[-1.8430151, -2.1899302]], dtype=float32)

time = 10343	action = 0	current_phase = 1	next_phase = 0	reward = 0.085328	array([[-1.9878895, -2.6558173]], dtype=float32)

time = 10348	action = 1	current_phase = 1	next_phase = 0	reward = -1.898230	array([[-4.308219 , -2.8803797]], dtype=float32)

time = 10356	action = 0	current_phase = 0	next_phase = 1	reward = -0.502298	array([[-1.5106328, -1.5599606]], dtype=float32)

time = 10361	action = 0	current_phase = 0	next_phase = 1	reward = -0.355852	array([[-1.5940772, -1.9651126]], dtype=float32)

time = 10366	action = 0	current_phase = 0	next_phase = 1	reward = -0.200194	array([[-1.5311736, -1.7573594]], dtype=float32)

time = 10371	action = 0	current_phase = 0	next_phase = 1	reward = 0.310392	array([[-1.5242957, -2.8952017]], dtype=float32)

time = 10376	action = 1	current_phase = 0	next_phase = 1	reward = -1.554539	array([[-3.215294 , -2.8780916]], dtype=float32)

time = 10384	action = 0	current_phase = 1	next_phase = 0	reward = -0.550026	array([[-1.7464597, -2.218448 ]], dtype=float32)

time = 10389	action = 0	current_phase = 1	next_phase = 0	reward = -0.398159	array([[-1.5831796, -2.3163993]], dtype=float32)

time = 10394	action = 0	current_phase = 1	next_phase = 0	reward = -0.236708	array([[-1.4879751, -2.2727416]], dtype=float32)

time = 10399	action = 0	current_phase = 1	next_phase = 0	reward = -0.178293	array([[-1.5431216, -2.5739794]], dtype=float32)

time = 10404	action = 1	current_phase = 1	next_phase = 0	reward = -0.582272	array([[-2.5115337, -1.7442523]], dtype=float32)

time = 10412	action = 0	current_phase = 0	next_phase = 1	reward = -0.622791	array([[-1.6989315, -1.8185037]], dtype=float32)

time = 10417	action = 0	current_phase = 0	next_phase = 1	reward = -0.470761	array([[-1.5821224, -2.00389  ]], dtype=float32)

time = 10422	action = 1	current_phase = 0	next_phase = 1	reward = -1.434589	array([[-1.5515946, -1.3992407]], dtype=float32)

time = 10430	action = 0	current_phase = 1	next_phase = 0	reward = 0.068643	array([[-0.63946664, -2.4574082 ]], dtype=float32)

time = 10435	action = 0	current_phase = 1	next_phase = 0	reward = -0.560457	array([[-0.3616276, -2.6759067]], dtype=float32)

time = 10440	action = 0	current_phase = 1	next_phase = 0	reward = -1.733733	array([[-1.6027993, -2.8562925]], dtype=float32)

time = 10445	action = 1	current_phase = 1	next_phase = 0	reward = -1.855517	array([[-3.8727362, -2.7507572]], dtype=float32)

time = 10453	action = 0	current_phase = 0	next_phase = 1	reward = -0.275105	array([[-1.1852487, -1.5427538]], dtype=float32)

time = 10458	action = 0	current_phase = 0	next_phase = 1	reward = -0.160656	array([[-1.3083665, -2.5188816]], dtype=float32)

time = 10463	action = 0	current_phase = 0	next_phase = 1	reward = 0.068844	array([[-2.3106377, -2.7248895]], dtype=float32)

time = 10468	action = 1	current_phase = 0	next_phase = 1	reward = -1.890438	array([[-3.6258917, -3.0768113]], dtype=float32)

time = 10476	action = 0	current_phase = 1	next_phase = 0	reward = -0.483226	array([[-1.5630382, -2.131249 ]], dtype=float32)

time = 10481	action = 0	current_phase = 1	next_phase = 0	reward = -0.331260	array([[-1.6452876, -2.2423036]], dtype=float32)

time = 10486	action = 0	current_phase = 1	next_phase = 0	reward = -0.191024	array([[-1.6109216, -2.3386781]], dtype=float32)

time = 10491	action = 0	current_phase = 1	next_phase = 0	reward = 0.282439	array([[-1.6333542, -3.1805403]], dtype=float32)

time = 10496	action = 1	current_phase = 1	next_phase = 0	reward = -1.608714	array([[-4.2227826, -2.6872518]], dtype=float32)

time = 10504	action = 0	current_phase = 0	next_phase = 1	reward = -0.559409	array([[-1.6667852, -1.7711408]], dtype=float32)

time = 10509	action = 0	current_phase = 0	next_phase = 1	reward = -0.410584	array([[-1.5783505, -2.0115964]], dtype=float32)

time = 10514	action = 0	current_phase = 0	next_phase = 1	reward = -0.248490	array([[-1.632834 , -2.1217518]], dtype=float32)

time = 10519	action = 0	current_phase = 0	next_phase = 1	reward = -0.173602	array([[-1.4882202, -2.3856795]], dtype=float32)

time = 10524	action = 1	current_phase = 0	next_phase = 1	reward = -0.545682	array([[-2.4272492, -1.8231428]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0394 - val_loss: 0.0235

Epoch 2/50

 - 4s - loss: 0.0423 - val_loss: 0.0247

Epoch 3/50

 - 4s - loss: 0.0378 - val_loss: 0.0249

Epoch 4/50

 - 4s - loss: 0.0390 - val_loss: 0.0243

Epoch 5/50

 - 4s - loss: 0.0381 - val_loss: 0.0252

Epoch 6/50

 - 4s - loss: 0.0384 - val_loss: 0.0265

Epoch 7/50

 - 4s - loss: 0.0371 - val_loss: 0.0261

Epoch 8/50

 - 4s - loss: 0.0351 - val_loss: 0.0267

Epoch 9/50

 - 5s - loss: 0.0359 - val_loss: 0.0266

Epoch 10/50

 - 5s - loss: 0.0301 - val_loss: 0.0276

Epoch 11/50

 - 5s - loss: 0.0291 - val_loss: 0.0273

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 478, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 465, after forget

time = 10532	action = 0	current_phase = 1	next_phase = 0	reward = -0.619294	array([[-1.7079941, -2.2199588]], dtype=float32)

time = 10537	action = 0	current_phase = 1	next_phase = 0	reward = -0.474012	array([[-1.6061102, -2.278098 ]], dtype=float32)

time = 10542	action = 0	current_phase = 1	next_phase = 0	reward = -0.317661	array([[-1.6489998, -2.2026036]], dtype=float32)

time = 10547	action = 0	current_phase = 1	next_phase = 0	reward = -0.178460	array([[-1.5474144, -2.2856805]], dtype=float32)

time = 10552	action = 0	current_phase = 1	next_phase = 0	reward = 0.255222	array([[-1.993275 , -2.8316972]], dtype=float32)

time = 10557	action = 1	current_phase = 1	next_phase = 0	reward = -1.727852	array([[-4.3690915, -2.8698144]], dtype=float32)

time = 10565	action = 0	current_phase = 0	next_phase = 1	reward = -0.529809	array([[-1.5662285, -1.7669034]], dtype=float32)

time = 10570	action = 0	current_phase = 0	next_phase = 1	reward = -0.378449	array([[-1.5001752, -2.0582192]], dtype=float32)

time = 10575	action = 0	current_phase = 0	next_phase = 1	reward = -0.216221	array([[-1.2887638, -1.4970332]], dtype=float32)

time = 10580	action = 0	current_phase = 0	next_phase = 1	reward = 0.366569	array([[-1.293254 , -2.7650697]], dtype=float32)

time = 10585	action = 1	current_phase = 0	next_phase = 1	reward = -1.305601	array([[-2.7890277, -2.4690135]], dtype=float32)

time = 10593	action = 0	current_phase = 1	next_phase = 0	reward = -0.589711	array([[-1.7303383, -2.2220693]], dtype=float32)

time = 10598	action = 0	current_phase = 1	next_phase = 0	reward = -0.432259	array([[-1.502469 , -2.3162389]], dtype=float32)

time = 10603	action = 0	current_phase = 1	next_phase = 0	reward = -0.259176	array([[-1.6895788, -2.2159004]], dtype=float32)

time = 10608	action = 0	current_phase = 1	next_phase = 0	reward = -0.158728	array([[-1.8289659, -2.1625023]], dtype=float32)

time = 10613	action = 1	current_phase = 1	next_phase = 0	reward = -0.983288	array([[-2.2767901, -2.1429179]], dtype=float32)

time = 10621	action = 0	current_phase = 0	next_phase = 1	reward = -1.167271	array([[-1.8081957, -2.164391 ]], dtype=float32)

time = 10626	action = 0	current_phase = 0	next_phase = 1	reward = -1.036902	array([[-2.0455718, -2.2224932]], dtype=float32)

time = 10631	action = 0	current_phase = 0	next_phase = 1	reward = -0.910317	array([[-1.5039927, -2.1138318]], dtype=float32)

time = 10636	action = 0	current_phase = 0	next_phase = 1	reward = -0.781538	array([[-1.4919659, -2.2521193]], dtype=float32)

time = 10641	action = 0	current_phase = 0	next_phase = 1	reward = -0.295287	array([[-2.2245297, -3.0358596]], dtype=float32)

time = 10646	action = 1	current_phase = 0	next_phase = 1	reward = -1.529649	array([[-4.0312767, -3.0462573]], dtype=float32)

time = 10654	action = 0	current_phase = 1	next_phase = 0	reward = -0.560656	array([[-1.6142637, -2.2698548]], dtype=float32)

time = 10659	action = 0	current_phase = 1	next_phase = 0	reward = -0.403328	array([[-1.5194252, -2.3164732]], dtype=float32)

time = 10664	action = 0	current_phase = 1	next_phase = 0	reward = -0.255863	array([[-1.5094434, -2.326059 ]], dtype=float32)

time = 10669	action = 0	current_phase = 1	next_phase = 0	reward = -0.177899	array([[-1.4123634, -2.536884 ]], dtype=float32)

time = 10674	action = 1	current_phase = 1	next_phase = 0	reward = -0.539634	array([[-2.5173175, -1.4097126]], dtype=float32)

time = 10682	action = 0	current_phase = 0	next_phase = 1	reward = -0.610756	array([[-1.5917791, -1.8872745]], dtype=float32)

time = 10687	action = 0	current_phase = 0	next_phase = 1	reward = -0.445952	array([[-1.4922374, -2.0483656]], dtype=float32)

time = 10692	action = 0	current_phase = 0	next_phase = 1	reward = -0.289830	array([[-1.4540616, -1.6115639]], dtype=float32)

time = 10697	action = 0	current_phase = 0	next_phase = 1	reward = -0.166451	array([[-1.5993651, -2.2023563]], dtype=float32)

time = 10702	action = 0	current_phase = 0	next_phase = 1	reward = 0.205032	array([[-1.8067964, -2.440425 ]], dtype=float32)

time = 10707	action = 1	current_phase = 0	next_phase = 1	reward = -1.780537	array([[-3.5757785, -3.0212317]], dtype=float32)

time = 10715	action = 0	current_phase = 1	next_phase = 0	reward = -0.511004	array([[-1.6164645, -2.142144 ]], dtype=float32)

time = 10720	action = 0	current_phase = 1	next_phase = 0	reward = -0.351936	array([[-1.5140597, -2.3263104]], dtype=float32)

time = 10725	action = 0	current_phase = 1	next_phase = 0	reward = -0.202918	array([[-1.4916215, -2.3488019]], dtype=float32)

time = 10730	action = 0	current_phase = 1	next_phase = 0	reward = 0.346297	array([[-1.4415663, -2.693084 ]], dtype=float32)

time = 10735	action = 1	current_phase = 1	next_phase = 0	reward = -1.422026	array([[-3.400991 , -2.2635045]], dtype=float32)

time = 10743	action = 0	current_phase = 0	next_phase = 1	reward = -0.583139	array([[-1.6093149, -1.8341849]], dtype=float32)

time = 10748	action = 0	current_phase = 0	next_phase = 1	reward = -0.434490	array([[-1.3507106, -2.0898628]], dtype=float32)

time = 10753	action = 1	current_phase = 0	next_phase = 1	reward = -1.379860	array([[-1.5985075, -1.5678916]], dtype=float32)

time = 10761	action = 0	current_phase = 1	next_phase = 0	reward = 0.307564	array([[-0.47464234, -2.876087  ]], dtype=float32)

time = 10766	action = 0	current_phase = 1	next_phase = 0	reward = -1.061266	array([[-0.6132763, -2.3373106]], dtype=float32)

time = 10771	action = 0	current_phase = 1	next_phase = 0	reward = -1.708384	array([[-2.7715833, -3.120521 ]], dtype=float32)

time = 10776	action = 1	current_phase = 1	next_phase = 0	reward = -1.792686	array([[-3.4848468, -2.7797685]], dtype=float32)

time = 10784	action = 0	current_phase = 0	next_phase = 1	reward = -0.239218	array([[-1.0212157, -1.7192743]], dtype=float32)

time = 10789	action = 0	current_phase = 0	next_phase = 1	reward = -0.191185	array([[-1.0815284, -2.700639 ]], dtype=float32)

time = 10794	action = 0	current_phase = 0	next_phase = 1	reward = -0.152670	array([[-1.669037 , -2.0106502]], dtype=float32)

time = 10799	action = 1	current_phase = 0	next_phase = 1	reward = -2.004947	array([[-3.6634064, -3.14578  ]], dtype=float32)

time = 10807	action = 0	current_phase = 1	next_phase = 0	reward = -0.468417	array([[-1.4780328, -2.1418269]], dtype=float32)

time = 10812	action = 0	current_phase = 1	next_phase = 0	reward = -0.315298	array([[-1.7284448, -2.2381651]], dtype=float32)

time = 10817	action = 0	current_phase = 1	next_phase = 0	reward = -0.180048	array([[-1.7318186, -2.1935434]], dtype=float32)

time = 10822	action = 0	current_phase = 1	next_phase = 0	reward = 0.191688	array([[-1.9859434, -3.0244489]], dtype=float32)

time = 10827	action = 1	current_phase = 1	next_phase = 0	reward = -1.731794	array([[-4.216209, -2.907222]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0593 - val_loss: 0.0319

Epoch 2/50

 - 6s - loss: 0.0578 - val_loss: 0.0315

Epoch 3/50

 - 5s - loss: 0.0571 - val_loss: 0.0343

Epoch 4/50

 - 4s - loss: 0.0541 - val_loss: 0.0327

Epoch 5/50

 - 4s - loss: 0.0449 - val_loss: 0.0325

Epoch 6/50

 - 5s - loss: 0.0467 - val_loss: 0.0318

Epoch 7/50

 - 4s - loss: 0.0436 - val_loss: 0.0342

Epoch 8/50

 - 4s - loss: 0.0469 - val_loss: 0.0336

Epoch 9/50

 - 5s - loss: 0.0440 - val_loss: 0.0330

Epoch 10/50

 - 4s - loss: 0.0391 - val_loss: 0.0347

Epoch 11/50

 - 4s - loss: 0.0477 - val_loss: 0.0342

Epoch 12/50

 - 4s - loss: 0.0396 - val_loss: 0.0349

length of memory (state 0, action 0): 1019, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 483, after forget

length of memory (state 1, action 0): 1024, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 471, after forget

time = 10835	action = 0	current_phase = 0	next_phase = 1	reward = -0.527792	array([[-1.6961797, -1.7948087]], dtype=float32)

time = 10840	action = 0	current_phase = 0	next_phase = 1	reward = -0.385039	array([[-1.559198 , -2.0302396]], dtype=float32)

time = 10845	action = 0	current_phase = 0	next_phase = 1	reward = -0.223896	array([[-1.3179737, -1.4561435]], dtype=float32)

time = 10850	action = 0	current_phase = 0	next_phase = 1	reward = 0.364723	array([[-1.5951198, -2.6007195]], dtype=float32)

time = 10855	action = 1	current_phase = 0	next_phase = 1	reward = -1.360560	array([[-2.6192973, -2.6063557]], dtype=float32)

time = 10863	action = 0	current_phase = 1	next_phase = 0	reward = -0.586747	array([[-1.7596376, -2.255184 ]], dtype=float32)

time = 10868	action = 0	current_phase = 1	next_phase = 0	reward = -0.436023	array([[-1.4717182, -2.364925 ]], dtype=float32)

time = 10873	action = 0	current_phase = 1	next_phase = 0	reward = -0.285539	array([[-1.6519698, -2.2290604]], dtype=float32)

time = 10878	action = 0	current_phase = 1	next_phase = 0	reward = -0.161926	array([[-1.7543485, -2.232222 ]], dtype=float32)

time = 10883	action = 0	current_phase = 1	next_phase = 0	reward = 0.138319	array([[-1.9967482, -2.7151837]], dtype=float32)

time = 10888	action = 1	current_phase = 1	next_phase = 0	reward = -1.892016	array([[-4.17497  , -3.1336992]], dtype=float32)

time = 10896	action = 0	current_phase = 0	next_phase = 1	reward = -0.496598	array([[-1.5056233, -1.5532097]], dtype=float32)

time = 10901	action = 0	current_phase = 0	next_phase = 1	reward = -0.346854	array([[-1.6672202, -1.8161703]], dtype=float32)

time = 10906	action = 0	current_phase = 0	next_phase = 1	reward = -0.200240	array([[-1.5470384, -1.8210343]], dtype=float32)

time = 10911	action = 0	current_phase = 0	next_phase = 1	reward = 0.303961	array([[-1.7608532, -3.0389924]], dtype=float32)

time = 10916	action = 1	current_phase = 0	next_phase = 1	reward = -1.603615	array([[-2.8818126, -2.7370715]], dtype=float32)

time = 10924	action = 0	current_phase = 1	next_phase = 0	reward = -0.550923	array([[-1.7897854, -2.2390685]], dtype=float32)

time = 10929	action = 0	current_phase = 1	next_phase = 0	reward = -0.403639	array([[-1.4850211, -2.357961 ]], dtype=float32)

time = 10934	action = 0	current_phase = 1	next_phase = 0	reward = -0.257379	array([[-1.4848462, -2.3165803]], dtype=float32)

time = 10939	action = 0	current_phase = 1	next_phase = 0	reward = -0.183849	array([[-1.5091842, -2.5274408]], dtype=float32)

time = 10944	action = 1	current_phase = 1	next_phase = 0	reward = -0.603018	array([[-2.622029 , -1.7614315]], dtype=float32)

time = 10952	action = 0	current_phase = 0	next_phase = 1	reward = -0.612172	array([[-1.6899198, -1.828589 ]], dtype=float32)

time = 10957	action = 0	current_phase = 0	next_phase = 1	reward = -0.450159	array([[-1.5704001, -2.0215259]], dtype=float32)

time = 10962	action = 0	current_phase = 0	next_phase = 1	reward = -0.295517	array([[-1.5113897, -1.6192782]], dtype=float32)

time = 10967	action = 0	current_phase = 0	next_phase = 1	reward = -0.169145	array([[-1.5924785, -1.9448546]], dtype=float32)

time = 10972	action = 0	current_phase = 0	next_phase = 1	reward = 0.111542	array([[-2.3084815, -2.8962913]], dtype=float32)

time = 10977	action = 1	current_phase = 0	next_phase = 1	reward = -1.780982	array([[-4.3250465, -3.2368145]], dtype=float32)

time = 10985	action = 0	current_phase = 1	next_phase = 0	reward = -0.522697	array([[-1.6215388, -2.137669 ]], dtype=float32)

time = 10990	action = 0	current_phase = 1	next_phase = 0	reward = -0.368292	array([[-1.4868333, -2.3581367]], dtype=float32)

time = 10995	action = 0	current_phase = 1	next_phase = 0	reward = -0.214565	array([[-1.4124541, -2.3986857]], dtype=float32)

time = 11000	action = 0	current_phase = 1	next_phase = 0	reward = 0.354495	array([[-1.514839, -2.641541]], dtype=float32)

time = 11005	action = 1	current_phase = 1	next_phase = 0	reward = -1.417421	array([[-3.4358227, -2.6333406]], dtype=float32)

time = 11013	action = 0	current_phase = 0	next_phase = 1	reward = -0.585298	array([[-1.6968158, -1.8130068]], dtype=float32)

time = 11018	action = 0	current_phase = 0	next_phase = 1	reward = -0.432678	array([[-1.4931599, -2.1076236]], dtype=float32)

time = 11023	action = 1	current_phase = 0	next_phase = 1	reward = -1.362837	array([[-1.6405612, -1.4799763]], dtype=float32)

time = 11031	action = 0	current_phase = 1	next_phase = 0	reward = 0.313831	array([[-0.07042226, -2.7560198 ]], dtype=float32)

time = 11036	action = 0	current_phase = 1	next_phase = 0	reward = -1.117908	array([[-0.9272709, -2.7203763]], dtype=float32)

time = 11041	action = 1	current_phase = 1	next_phase = 0	reward = -2.062988	array([[-3.7886174, -3.069534 ]], dtype=float32)

time = 11049	action = 0	current_phase = 0	next_phase = 1	reward = -0.403178	array([[-1.4445823, -1.6164228]], dtype=float32)

time = 11054	action = 0	current_phase = 0	next_phase = 1	reward = -0.250347	array([[-1.1727183, -2.0956445]], dtype=float32)

time = 11059	action = 0	current_phase = 0	next_phase = 1	reward = -0.175212	array([[-0.836285, -2.149127]], dtype=float32)

time = 11064	action = 1	current_phase = 0	next_phase = 1	reward = -0.493261	array([[-2.1900027, -2.1714172]], dtype=float32)

time = 11072	action = 0	current_phase = 1	next_phase = 0	reward = -0.613279	array([[-1.8126391, -2.2345123]], dtype=float32)

time = 11077	action = 0	current_phase = 1	next_phase = 0	reward = -0.457117	array([[-1.9318855, -2.2264585]], dtype=float32)

time = 11082	action = 0	current_phase = 1	next_phase = 0	reward = -0.308478	array([[-1.541765, -2.209063]], dtype=float32)

time = 11087	action = 0	current_phase = 1	next_phase = 0	reward = -0.175282	array([[-1.8649014, -2.1606133]], dtype=float32)

time = 11092	action = 0	current_phase = 1	next_phase = 0	reward = 0.180957	array([[-2.1223536, -3.08736  ]], dtype=float32)

time = 11097	action = 1	current_phase = 1	next_phase = 0	reward = -1.790658	array([[-4.422217 , -2.9507766]], dtype=float32)

time = 11105	action = 0	current_phase = 0	next_phase = 1	reward = -0.536643	array([[-1.502527 , -1.5424742]], dtype=float32)

time = 11110	action = 0	current_phase = 0	next_phase = 1	reward = -0.385658	array([[-1.568881 , -2.0272052]], dtype=float32)

time = 11115	action = 0	current_phase = 0	next_phase = 1	reward = -0.237390	array([[-1.6242083, -2.1661544]], dtype=float32)

time = 11120	action = 0	current_phase = 0	next_phase = 1	reward = -0.225600	array([[-1.7977641, -2.1597476]], dtype=float32)

time = 11125	action = 1	current_phase = 0	next_phase = 1	reward = -0.800840	array([[-2.4695714, -2.3080792]], dtype=float32)

time = 11133	action = 0	current_phase = 1	next_phase = 0	reward = -0.588623	array([[-1.8469152, -2.2383156]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0506 - val_loss: 0.0199

Epoch 2/50

 - 4s - loss: 0.0470 - val_loss: 0.0234

Epoch 3/50

 - 5s - loss: 0.0467 - val_loss: 0.0218

Epoch 4/50

 - 7s - loss: 0.0462 - val_loss: 0.0223

Epoch 5/50

 - 4s - loss: 0.0428 - val_loss: 0.0223

Epoch 6/50

 - 4s - loss: 0.0402 - val_loss: 0.0221

Epoch 7/50

 - 4s - loss: 0.0425 - val_loss: 0.0241

Epoch 8/50

 - 4s - loss: 0.0434 - val_loss: 0.0238

Epoch 9/50

 - 4s - loss: 0.0365 - val_loss: 0.0231

Epoch 10/50

 - 4s - loss: 0.0387 - val_loss: 0.0264

Epoch 11/50

 - 4s - loss: 0.0429 - val_loss: 0.0254

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 489, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 476, after forget

time = 11138	action = 0	current_phase = 1	next_phase = 0	reward = -0.438273	array([[-1.6442385, -2.33159  ]], dtype=float32)

time = 11143	action = 0	current_phase = 1	next_phase = 0	reward = -0.294502	array([[-1.7636254, -2.212669 ]], dtype=float32)

time = 11148	action = 0	current_phase = 1	next_phase = 0	reward = -0.170673	array([[-1.9064331, -2.160462 ]], dtype=float32)

time = 11153	action = 0	current_phase = 1	next_phase = 0	reward = 0.085676	array([[-2.0919144, -3.4240816]], dtype=float32)

time = 11158	action = 1	current_phase = 1	next_phase = 0	reward = -1.899349	array([[-4.364111 , -3.0280647]], dtype=float32)

time = 11166	action = 1	current_phase = 0	next_phase = 1	reward = -1.716552	array([[-1.5479698, -1.4746786]], dtype=float32)

time = 11174	action = 0	current_phase = 1	next_phase = 0	reward = -0.239135	array([[-1.0181723, -2.3476658]], dtype=float32)

time = 11179	action = 0	current_phase = 1	next_phase = 0	reward = -0.188337	array([[-0.67045045, -2.1090348 ]], dtype=float32)

time = 11184	action = 0	current_phase = 1	next_phase = 0	reward = -0.206889	array([[-0.15753242, -1.525028  ]], dtype=float32)

time = 11189	action = 0	current_phase = 1	next_phase = 0	reward = -1.607415	array([[-1.3595362, -2.974153 ]], dtype=float32)

time = 11194	action = 1	current_phase = 1	next_phase = 0	reward = -1.906837	array([[-3.9334552, -2.6461697]], dtype=float32)

time = 11202	action = 0	current_phase = 0	next_phase = 1	reward = -0.316542	array([[-1.1053318, -1.4094117]], dtype=float32)

time = 11207	action = 0	current_phase = 0	next_phase = 1	reward = -0.179384	array([[-1.3333333, -2.4359157]], dtype=float32)

time = 11212	action = 0	current_phase = 0	next_phase = 1	reward = 0.200641	array([[-2.2832634, -2.3653302]], dtype=float32)

time = 11217	action = 1	current_phase = 0	next_phase = 1	reward = -1.783784	array([[-3.7612534, -3.2466543]], dtype=float32)

time = 11225	action = 0	current_phase = 1	next_phase = 0	reward = -0.523665	array([[-1.6962696, -2.100308 ]], dtype=float32)

time = 11230	action = 0	current_phase = 1	next_phase = 0	reward = -0.367580	array([[-1.7562169, -2.2542741]], dtype=float32)

time = 11235	action = 0	current_phase = 1	next_phase = 0	reward = -0.219364	array([[-1.4991336, -2.4776945]], dtype=float32)

time = 11240	action = 0	current_phase = 1	next_phase = 0	reward = 0.365685	array([[-1.4952893, -2.5889752]], dtype=float32)

time = 11245	action = 1	current_phase = 1	next_phase = 0	reward = -1.257477	array([[-3.6025524, -2.5578098]], dtype=float32)

time = 11253	action = 0	current_phase = 0	next_phase = 1	reward = -0.595059	array([[-1.7111328, -1.7383132]], dtype=float32)

time = 11258	action = 0	current_phase = 0	next_phase = 1	reward = -0.445269	array([[-1.2661102, -2.028197 ]], dtype=float32)

time = 11263	action = 1	current_phase = 0	next_phase = 1	reward = -1.413405	array([[-1.6811204, -1.5393171]], dtype=float32)

time = 11271	action = 0	current_phase = 1	next_phase = 0	reward = 0.346316	array([[ 0.19849297, -2.676723  ]], dtype=float32)

time = 11276	action = 0	current_phase = 1	next_phase = 0	reward = -1.056076	array([[-0.49908197, -2.962691  ]], dtype=float32)

time = 11281	action = 1	current_phase = 1	next_phase = 0	reward = -2.068451	array([[-4.0648947, -3.0662303]], dtype=float32)

time = 11289	action = 0	current_phase = 0	next_phase = 1	reward = -0.421911	array([[-1.4418242, -1.5592254]], dtype=float32)

time = 11294	action = 0	current_phase = 0	next_phase = 1	reward = -0.271592	array([[-1.2493649, -1.9314878]], dtype=float32)

time = 11299	action = 0	current_phase = 0	next_phase = 1	reward = -0.168902	array([[-1.9293637, -2.1964037]], dtype=float32)

time = 11304	action = 0	current_phase = 0	next_phase = 1	reward = 0.002676	array([[-2.1067312, -2.818031 ]], dtype=float32)

time = 11309	action = 1	current_phase = 0	next_phase = 1	reward = -2.000606	array([[-3.6328344, -3.197051 ]], dtype=float32)

time = 11317	action = 0	current_phase = 1	next_phase = 0	reward = -0.447600	array([[-1.7452894, -2.172166 ]], dtype=float32)

time = 11322	action = 0	current_phase = 1	next_phase = 0	reward = -0.293419	array([[-1.8095664, -2.2410073]], dtype=float32)

time = 11327	action = 0	current_phase = 1	next_phase = 0	reward = -0.169813	array([[-1.9485534, -2.1241858]], dtype=float32)

time = 11332	action = 0	current_phase = 1	next_phase = 0	reward = 0.183097	array([[-2.0217342, -2.8864927]], dtype=float32)

time = 11337	action = 1	current_phase = 1	next_phase = 0	reward = -1.775997	array([[-4.3103256, -2.887622 ]], dtype=float32)

time = 11345	action = 0	current_phase = 0	next_phase = 1	reward = -0.522027	array([[-1.6923892, -1.704213 ]], dtype=float32)

time = 11350	action = 0	current_phase = 0	next_phase = 1	reward = -0.360996	array([[-1.5498204, -1.9454201]], dtype=float32)

time = 11355	action = 0	current_phase = 0	next_phase = 1	reward = -0.205437	array([[-1.606875 , -1.9035355]], dtype=float32)

time = 11360	action = 0	current_phase = 0	next_phase = 1	reward = 0.335407	array([[-1.8008101, -2.5683448]], dtype=float32)

time = 11365	action = 1	current_phase = 0	next_phase = 1	reward = -1.372999	array([[-2.8863  , -2.758727]], dtype=float32)

time = 11373	action = 0	current_phase = 1	next_phase = 0	reward = -0.595138	array([[-1.8163656, -2.2145164]], dtype=float32)

time = 11378	action = 0	current_phase = 1	next_phase = 0	reward = -0.454484	array([[-1.8451538, -2.2839181]], dtype=float32)

time = 11383	action = 0	current_phase = 1	next_phase = 0	reward = -0.305672	array([[-1.8008311, -2.2195182]], dtype=float32)

time = 11388	action = 0	current_phase = 1	next_phase = 0	reward = -0.169822	array([[-1.9569912, -2.1184988]], dtype=float32)

time = 11393	action = 0	current_phase = 1	next_phase = 0	reward = 0.167252	array([[-2.2597787, -2.6484244]], dtype=float32)

time = 11398	action = 1	current_phase = 1	next_phase = 0	reward = -1.891806	array([[-4.3577523, -3.0445993]], dtype=float32)

time = 11406	action = 1	current_phase = 0	next_phase = 1	reward = -1.722772	array([[-1.5164564, -1.4839915]], dtype=float32)

time = 11414	action = 0	current_phase = 1	next_phase = 0	reward = -0.244820	array([[-1.2546012, -2.4163332]], dtype=float32)

time = 11419	action = 0	current_phase = 1	next_phase = 0	reward = -0.175952	array([[-0.52157825, -2.2996194 ]], dtype=float32)

time = 11424	action = 0	current_phase = 1	next_phase = 0	reward = -0.141060	array([[-0.37411493, -1.1321955 ]], dtype=float32)

time = 11429	action = 0	current_phase = 1	next_phase = 0	reward = -1.604477	array([[-0.4940327, -3.202588 ]], dtype=float32)

time = 11434	action = 1	current_phase = 1	next_phase = 0	reward = -1.913684	array([[-3.3819783, -2.8377726]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0590 - val_loss: 0.0229

Epoch 2/50

 - 4s - loss: 0.0586 - val_loss: 0.0250

Epoch 3/50

 - 4s - loss: 0.0639 - val_loss: 0.0246

Epoch 4/50

 - 4s - loss: 0.0523 - val_loss: 0.0263

Epoch 5/50

 - 4s - loss: 0.0529 - val_loss: 0.0281

Epoch 6/50

 - 4s - loss: 0.0544 - val_loss: 0.0274

Epoch 7/50

 - 4s - loss: 0.0506 - val_loss: 0.0271

Epoch 8/50

 - 4s - loss: 0.0489 - val_loss: 0.0264

Epoch 9/50

 - 4s - loss: 0.0506 - val_loss: 0.0311

Epoch 10/50

 - 4s - loss: 0.0500 - val_loss: 0.0284

Epoch 11/50

 - 4s - loss: 0.0504 - val_loss: 0.0274

length of memory (state 0, action 0): 1013, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 495, after forget

length of memory (state 1, action 0): 1027, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 483, after forget

time = 11442	action = 0	current_phase = 0	next_phase = 1	reward = -0.318125	array([[-1.1690369, -1.5019951]], dtype=float32)

time = 11447	action = 0	current_phase = 0	next_phase = 1	reward = -0.179645	array([[-1.4631133, -2.3787038]], dtype=float32)

time = 11452	action = 0	current_phase = 0	next_phase = 1	reward = 0.179879	array([[-1.8822958, -2.6082542]], dtype=float32)

time = 11457	action = 1	current_phase = 0	next_phase = 1	reward = -1.784189	array([[-3.6296694, -3.1465316]], dtype=float32)

time = 11465	action = 0	current_phase = 1	next_phase = 0	reward = -0.527871	array([[-1.75961 , -2.126428]], dtype=float32)

time = 11470	action = 0	current_phase = 1	next_phase = 0	reward = -0.371497	array([[-1.5888855, -2.3426905]], dtype=float32)

time = 11475	action = 0	current_phase = 1	next_phase = 0	reward = -0.210281	array([[-1.4825907, -2.414609 ]], dtype=float32)

time = 11480	action = 0	current_phase = 1	next_phase = 0	reward = 0.355936	array([[-1.6228931, -2.7179186]], dtype=float32)

time = 11485	action = 1	current_phase = 1	next_phase = 0	reward = -1.315723	array([[-3.3731763, -2.4094944]], dtype=float32)

time = 11493	action = 0	current_phase = 0	next_phase = 1	reward = -0.599199	array([[-1.7173772, -1.7387098]], dtype=float32)

time = 11498	action = 0	current_phase = 0	next_phase = 1	reward = -0.436758	array([[-1.5897543, -1.9342837]], dtype=float32)

time = 11503	action = 1	current_phase = 0	next_phase = 1	reward = -1.393811	array([[-1.5478458, -1.2949891]], dtype=float32)

time = 11511	action = 0	current_phase = 1	next_phase = 0	reward = 0.323907	array([[ 0.19779477, -2.7003565 ]], dtype=float32)

time = 11516	action = 0	current_phase = 1	next_phase = 0	reward = -1.007306	array([[-1.5514961, -2.7583704]], dtype=float32)

time = 11521	action = 0	current_phase = 1	next_phase = 0	reward = -1.705352	array([[-1.9338849, -3.2423258]], dtype=float32)

time = 11526	action = 1	current_phase = 1	next_phase = 0	reward = -1.802135	array([[-3.5612006, -2.6676495]], dtype=float32)

time = 11534	action = 0	current_phase = 0	next_phase = 1	reward = -0.248723	array([[-1.3128743, -1.8864985]], dtype=float32)

time = 11539	action = 0	current_phase = 0	next_phase = 1	reward = -0.178997	array([[-0.26089624, -2.6236894 ]], dtype=float32)

time = 11544	action = 1	current_phase = 0	next_phase = 1	reward = -0.553080	array([[-2.5751362, -2.1290271]], dtype=float32)

time = 11552	action = 0	current_phase = 1	next_phase = 0	reward = -0.626195	array([[-1.8657495, -2.2183213]], dtype=float32)

time = 11557	action = 0	current_phase = 1	next_phase = 0	reward = -0.485695	array([[-1.2957689, -2.2061276]], dtype=float32)

time = 11562	action = 0	current_phase = 1	next_phase = 0	reward = -0.338145	array([[-1.8228759, -2.2560894]], dtype=float32)

time = 11567	action = 0	current_phase = 1	next_phase = 0	reward = -0.190094	array([[-1.629359, -2.364734]], dtype=float32)

time = 11572	action = 0	current_phase = 1	next_phase = 0	reward = 0.292969	array([[-2.2749834, -3.2597425]], dtype=float32)

time = 11577	action = 1	current_phase = 1	next_phase = 0	reward = -1.724639	array([[-4.19618 , -2.975181]], dtype=float32)

time = 11585	action = 0	current_phase = 0	next_phase = 1	reward = -0.521687	array([[-1.7385659, -1.7414649]], dtype=float32)

time = 11590	action = 0	current_phase = 0	next_phase = 1	reward = -0.374257	array([[-1.5905335, -1.9327135]], dtype=float32)

time = 11595	action = 0	current_phase = 0	next_phase = 1	reward = -0.217842	array([[-1.567203 , -1.7776504]], dtype=float32)

time = 11600	action = 0	current_phase = 0	next_phase = 1	reward = 0.354067	array([[-1.8045444, -2.5794122]], dtype=float32)

time = 11605	action = 1	current_phase = 0	next_phase = 1	reward = -1.366036	array([[-2.943501 , -2.7188983]], dtype=float32)

time = 11613	action = 0	current_phase = 1	next_phase = 0	reward = -0.589032	array([[-1.8078961, -2.2293973]], dtype=float32)

time = 11618	action = 0	current_phase = 1	next_phase = 0	reward = -0.436049	array([[-1.5771278, -2.3578017]], dtype=float32)

time = 11623	action = 0	current_phase = 1	next_phase = 0	reward = -0.277865	array([[-1.5582331, -2.25018  ]], dtype=float32)

time = 11628	action = 0	current_phase = 1	next_phase = 0	reward = -0.159361	array([[-1.9179127, -2.1717424]], dtype=float32)

time = 11633	action = 0	current_phase = 1	next_phase = 0	reward = 0.025427	array([[-2.0296109, -2.5115244]], dtype=float32)

time = 11638	action = 1	current_phase = 1	next_phase = 0	reward = -1.900095	array([[-4.2918615, -3.0513701]], dtype=float32)

time = 11646	action = 1	current_phase = 0	next_phase = 1	reward = -1.715271	array([[-1.5700114, -1.5057193]], dtype=float32)

time = 11654	action = 0	current_phase = 1	next_phase = 0	reward = -0.247502	array([[-0.6219303, -2.470132 ]], dtype=float32)

time = 11659	action = 0	current_phase = 1	next_phase = 0	reward = -0.173525	array([[-0.5593634, -2.3145223]], dtype=float32)

time = 11664	action = 0	current_phase = 1	next_phase = 0	reward = -0.130751	array([[-0.8251622, -1.0813322]], dtype=float32)

time = 11669	action = 0	current_phase = 1	next_phase = 0	reward = -1.601999	array([[-2.3975089, -2.708658 ]], dtype=float32)

time = 11674	action = 1	current_phase = 1	next_phase = 0	reward = -1.898825	array([[-3.2645926, -2.8300881]], dtype=float32)

time = 11682	action = 0	current_phase = 0	next_phase = 1	reward = -0.300754	array([[-1.365696 , -1.5073481]], dtype=float32)

time = 11687	action = 0	current_phase = 0	next_phase = 1	reward = -0.166585	array([[-1.5304389, -2.2956336]], dtype=float32)

time = 11692	action = 0	current_phase = 0	next_phase = 1	reward = 0.183937	array([[-1.9122562, -2.6477094]], dtype=float32)

time = 11697	action = 1	current_phase = 0	next_phase = 1	reward = -1.780419	array([[-3.840775 , -3.2629464]], dtype=float32)

time = 11705	action = 0	current_phase = 1	next_phase = 0	reward = -0.515571	array([[-1.6884532, -2.1141386]], dtype=float32)

time = 11710	action = 0	current_phase = 1	next_phase = 0	reward = -0.359792	array([[-1.6049079, -2.3128107]], dtype=float32)

time = 11715	action = 0	current_phase = 1	next_phase = 0	reward = -0.210346	array([[-1.4679204, -2.4283726]], dtype=float32)

time = 11720	action = 0	current_phase = 1	next_phase = 0	reward = 0.345824	array([[-1.5993671, -2.7646859]], dtype=float32)

time = 11725	action = 1	current_phase = 1	next_phase = 0	reward = -1.315929	array([[-3.505169, -2.575684]], dtype=float32)

time = 11733	action = 0	current_phase = 0	next_phase = 1	reward = -0.582214	array([[-1.7321441, -1.7384839]], dtype=float32)

time = 11738	action = 0	current_phase = 0	next_phase = 1	reward = -0.432503	array([[-1.5818193, -1.9540501]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0508 - val_loss: 0.0263

Epoch 2/50

 - 4s - loss: 0.0495 - val_loss: 0.0269

Epoch 3/50

 - 4s - loss: 0.0481 - val_loss: 0.0269

Epoch 4/50

 - 4s - loss: 0.0477 - val_loss: 0.0279

Epoch 5/50

 - 4s - loss: 0.0434 - val_loss: 0.0310

Epoch 6/50

 - 4s - loss: 0.0436 - val_loss: 0.0313

Epoch 7/50

 - 4s - loss: 0.0446 - val_loss: 0.0297

Epoch 8/50

 - 4s - loss: 0.0468 - val_loss: 0.0305

Epoch 9/50

 - 4s - loss: 0.0418 - val_loss: 0.0311

Epoch 10/50

 - 4s - loss: 0.0391 - val_loss: 0.0301

Epoch 11/50

 - 4s - loss: 0.0460 - val_loss: 0.0301

length of memory (state 0, action 0): 1016, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 501, after forget

length of memory (state 1, action 0): 1025, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 489, after forget

time = 11743	action = 1	current_phase = 0	next_phase = 1	reward = -1.386488	array([[-1.716281 , -1.5897841]], dtype=float32)

time = 11751	action = 0	current_phase = 1	next_phase = 0	reward = 0.299850	array([[ 0.26395848, -2.5291514 ]], dtype=float32)

time = 11756	action = 0	current_phase = 1	next_phase = 0	reward = -1.064768	array([[-0.36309603, -3.0163872 ]], dtype=float32)

time = 11761	action = 1	current_phase = 1	next_phase = 0	reward = -2.063468	array([[-3.4622161, -3.02863  ]], dtype=float32)

time = 11769	action = 0	current_phase = 0	next_phase = 1	reward = -0.409648	array([[-1.5054795, -1.5951161]], dtype=float32)

time = 11774	action = 0	current_phase = 0	next_phase = 1	reward = -0.256037	array([[-1.3706473, -2.5339575]], dtype=float32)

time = 11779	action = 0	current_phase = 0	next_phase = 1	reward = -0.174218	array([[-1.6522619, -1.9457316]], dtype=float32)

time = 11784	action = 0	current_phase = 0	next_phase = 1	reward = -0.077143	array([[-2.3934913, -2.4538271]], dtype=float32)

time = 11789	action = 1	current_phase = 0	next_phase = 1	reward = -2.002180	array([[-3.641159, -3.148272]], dtype=float32)

time = 11797	action = 0	current_phase = 1	next_phase = 0	reward = -0.457392	array([[-1.7201566, -2.1477995]], dtype=float32)

time = 11802	action = 0	current_phase = 1	next_phase = 0	reward = -0.301733	array([[-1.7677214, -2.2082584]], dtype=float32)

time = 11807	action = 0	current_phase = 1	next_phase = 0	reward = -0.171379	array([[-1.9418702, -2.1367695]], dtype=float32)

time = 11812	action = 0	current_phase = 1	next_phase = 0	reward = 0.174182	array([[-2.2626896, -3.2487123]], dtype=float32)

time = 11817	action = 1	current_phase = 1	next_phase = 0	reward = -1.728742	array([[-4.264903 , -2.9696498]], dtype=float32)

time = 11825	action = 1	current_phase = 0	next_phase = 1	reward = -1.754876	array([[-1.7446344, -1.7310433]], dtype=float32)

time = 11833	action = 0	current_phase = 1	next_phase = 0	reward = -0.276185	array([[-0.5083858, -2.2729964]], dtype=float32)

time = 11838	action = 0	current_phase = 1	next_phase = 0	reward = -0.165021	array([[-0.4028712, -2.5992382]], dtype=float32)

time = 11843	action = 0	current_phase = 1	next_phase = 0	reward = -0.038759	array([[-0.06028888, -3.5896337 ]], dtype=float32)

time = 11848	action = 0	current_phase = 1	next_phase = 0	reward = -1.469457	array([[-0.02062961, -3.1334531 ]], dtype=float32)

time = 11853	action = 0	current_phase = 1	next_phase = 0	reward = -1.678425	array([[-0.889078 , -2.9248745]], dtype=float32)

time = 11858	action = 1	current_phase = 1	next_phase = 0	reward = -1.719239	array([[-3.5443323, -2.779165 ]], dtype=float32)

time = 11866	action = 0	current_phase = 0	next_phase = 1	reward = -0.207349	array([[-1.2349212, -1.5783279]], dtype=float32)

time = 11871	action = 0	current_phase = 0	next_phase = 1	reward = 0.335280	array([[-0.89957577, -2.9300196 ]], dtype=float32)

time = 11876	action = 1	current_phase = 0	next_phase = 1	reward = -1.503164	array([[-3.5262105, -2.7230449]], dtype=float32)

time = 11884	action = 0	current_phase = 1	next_phase = 0	reward = -0.574565	array([[-1.6434201, -2.303304 ]], dtype=float32)

time = 11889	action = 0	current_phase = 1	next_phase = 0	reward = -0.424635	array([[-1.474013 , -2.3443449]], dtype=float32)

time = 11894	action = 0	current_phase = 1	next_phase = 0	reward = -0.259040	array([[-1.698452 , -2.1733618]], dtype=float32)

time = 11899	action = 0	current_phase = 1	next_phase = 0	reward = -0.166555	array([[-1.5523434, -2.626054 ]], dtype=float32)

time = 11904	action = 1	current_phase = 1	next_phase = 0	reward = -0.427083	array([[-2.7905858, -1.6260759]], dtype=float32)

time = 11912	action = 1	current_phase = 0	next_phase = 1	reward = -1.910277	array([[-1.8744192, -1.7585764]], dtype=float32)

time = 11920	action = 0	current_phase = 1	next_phase = 0	reward = -0.363840	array([[-1.7077203, -2.396043 ]], dtype=float32)

time = 11925	action = 0	current_phase = 1	next_phase = 0	reward = -0.216035	array([[-0.6485747, -2.7629437]], dtype=float32)

time = 11930	action = 0	current_phase = 1	next_phase = 0	reward = 0.359150	array([[-0.28453922, -2.4808311 ]], dtype=float32)

time = 11935	action = 0	current_phase = 1	next_phase = 0	reward = -0.843297	array([[-0.77739674, -2.7833438 ]], dtype=float32)

time = 11940	action = 0	current_phase = 1	next_phase = 0	reward = -1.735258	array([[-2.4886477, -2.8121004]], dtype=float32)

time = 11945	action = 1	current_phase = 1	next_phase = 0	reward = -1.863637	array([[-3.9043863, -2.7753978]], dtype=float32)

time = 11953	action = 0	current_phase = 0	next_phase = 1	reward = -0.284928	array([[-1.2197497, -1.5975263]], dtype=float32)

time = 11958	action = 0	current_phase = 0	next_phase = 1	reward = -0.164746	array([[-1.3835138, -2.5446985]], dtype=float32)

time = 11963	action = 0	current_phase = 0	next_phase = 1	reward = 0.059423	array([[-2.619717, -3.000721]], dtype=float32)

time = 11968	action = 1	current_phase = 0	next_phase = 1	reward = -1.901524	array([[-4.065391 , -3.2403646]], dtype=float32)

time = 11976	action = 0	current_phase = 1	next_phase = 0	reward = -0.493563	array([[-1.6715072, -2.114975 ]], dtype=float32)

time = 11981	action = 0	current_phase = 1	next_phase = 0	reward = -0.343022	array([[-1.7701876, -2.2227385]], dtype=float32)

time = 11986	action = 0	current_phase = 1	next_phase = 0	reward = -0.194952	array([[-1.3983173, -2.669525 ]], dtype=float32)

time = 11991	action = 0	current_phase = 1	next_phase = 0	reward = 0.303730	array([[-1.716819 , -3.4237819]], dtype=float32)

time = 11996	action = 1	current_phase = 1	next_phase = 0	reward = -1.614191	array([[-4.303678 , -2.9483154]], dtype=float32)

time = 12004	action = 0	current_phase = 0	next_phase = 1	reward = -0.565278	array([[-1.7421468, -1.7579778]], dtype=float32)

time = 12009	action = 0	current_phase = 0	next_phase = 1	reward = -0.413387	array([[-1.5946753, -1.9608493]], dtype=float32)

time = 12014	action = 0	current_phase = 0	next_phase = 1	reward = -0.262840	array([[-1.4293011, -1.6043392]], dtype=float32)

time = 12019	action = 0	current_phase = 0	next_phase = 1	reward = -0.169020	array([[-2.0457327, -2.4145129]], dtype=float32)

time = 12024	action = 1	current_phase = 0	next_phase = 1	reward = -0.375949	array([[-2.194343 , -1.9329591]], dtype=float32)

time = 12032	action = 0	current_phase = 1	next_phase = 0	reward = -0.617329	array([[-1.7659609, -2.2074218]], dtype=float32)

time = 12037	action = 0	current_phase = 1	next_phase = 0	reward = -0.462517	array([[-1.7246089, -2.3601322]], dtype=float32)

time = 12042	action = 0	current_phase = 1	next_phase = 0	reward = -0.309477	array([[-1.7312543, -2.2828894]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0516 - val_loss: 0.0270

Epoch 2/50

 - 4s - loss: 0.0458 - val_loss: 0.0279

Epoch 3/50

 - 4s - loss: 0.0419 - val_loss: 0.0266

Epoch 4/50

 - 4s - loss: 0.0496 - val_loss: 0.0282

Epoch 5/50

 - 4s - loss: 0.0510 - val_loss: 0.0283

Epoch 6/50

 - 4s - loss: 0.0461 - val_loss: 0.0305

Epoch 7/50

 - 4s - loss: 0.0420 - val_loss: 0.0294

Epoch 8/50

 - 4s - loss: 0.0423 - val_loss: 0.0297

Epoch 9/50

 - 4s - loss: 0.0400 - val_loss: 0.0298

Epoch 10/50

 - 4s - loss: 0.0362 - val_loss: 0.0285

Epoch 11/50

 - 4s - loss: 0.0404 - val_loss: 0.0312

Epoch 12/50

 - 4s - loss: 0.0404 - val_loss: 0.0320

Epoch 13/50

 - 4s - loss: 0.0383 - val_loss: 0.0314

length of memory (state 0, action 0): 1013, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 508, after forget

length of memory (state 1, action 0): 1027, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 495, after forget

time = 12047	action = 0	current_phase = 1	next_phase = 0	reward = -0.174459	array([[-1.8805671, -2.2115633]], dtype=float32)

time = 12052	action = 0	current_phase = 1	next_phase = 0	reward = 0.237358	array([[-1.8077999, -2.9261677]], dtype=float32)

time = 12057	action = 1	current_phase = 1	next_phase = 0	reward = -1.780997	array([[-4.440585 , -2.9976907]], dtype=float32)

time = 12065	action = 0	current_phase = 0	next_phase = 1	reward = -0.524039	array([[-1.6522241, -1.7032402]], dtype=float32)

time = 12070	action = 0	current_phase = 0	next_phase = 1	reward = -0.369225	array([[-1.5618945, -1.9864236]], dtype=float32)

time = 12075	action = 0	current_phase = 0	next_phase = 1	reward = -0.221214	array([[-1.4610673, -1.6009668]], dtype=float32)

time = 12080	action = 0	current_phase = 0	next_phase = 1	reward = 0.364975	array([[-1.7295992, -2.5378609]], dtype=float32)

time = 12085	action = 1	current_phase = 0	next_phase = 1	reward = -1.363244	array([[-2.821036 , -2.6434598]], dtype=float32)

time = 12093	action = 0	current_phase = 1	next_phase = 0	reward = -0.598981	array([[-1.7569426, -2.2855456]], dtype=float32)

time = 12098	action = 0	current_phase = 1	next_phase = 0	reward = -0.443250	array([[-1.6350787, -2.407291 ]], dtype=float32)

time = 12103	action = 0	current_phase = 1	next_phase = 0	reward = -0.287228	array([[-1.7295353, -2.2777545]], dtype=float32)

time = 12108	action = 0	current_phase = 1	next_phase = 0	reward = -0.164765	array([[-1.8171225, -2.2784605]], dtype=float32)

time = 12113	action = 0	current_phase = 1	next_phase = 0	reward = 0.124513	array([[-2.4607584, -3.068209 ]], dtype=float32)

time = 12118	action = 1	current_phase = 1	next_phase = 0	reward = -1.896588	array([[-4.3757286, -3.0470333]], dtype=float32)

time = 12126	action = 0	current_phase = 0	next_phase = 1	reward = -0.499590	array([[-1.5596269, -1.6084443]], dtype=float32)

time = 12131	action = 0	current_phase = 0	next_phase = 1	reward = -0.351195	array([[-1.5230798, -1.8719954]], dtype=float32)

time = 12136	action = 0	current_phase = 0	next_phase = 1	reward = -0.202983	array([[-1.5741993, -1.8046415]], dtype=float32)

time = 12141	action = 0	current_phase = 0	next_phase = 1	reward = 0.324971	array([[-2.186974 , -2.4025369]], dtype=float32)

time = 12146	action = 0	current_phase = 0	next_phase = 1	reward = -1.116715	array([[-3.0278144, -3.0419567]], dtype=float32)

time = 12151	action = 1	current_phase = 0	next_phase = 1	reward = -2.056460	array([[-4.3459835, -3.323925 ]], dtype=float32)

time = 12159	action = 0	current_phase = 1	next_phase = 0	reward = -0.399872	array([[-1.6557897, -2.1829658]], dtype=float32)

time = 12164	action = 0	current_phase = 1	next_phase = 0	reward = -0.249477	array([[-1.4746435, -2.4754395]], dtype=float32)

time = 12169	action = 0	current_phase = 1	next_phase = 0	reward = -0.169481	array([[-1.5386653, -2.6226122]], dtype=float32)

time = 12174	action = 1	current_phase = 1	next_phase = 0	reward = -0.421385	array([[-2.562007 , -1.9172964]], dtype=float32)

time = 12182	action = 0	current_phase = 0	next_phase = 1	reward = -0.618330	array([[-1.82523, -1.82742]], dtype=float32)

time = 12187	action = 0	current_phase = 0	next_phase = 1	reward = -0.463158	array([[-1.5834205, -1.9766877]], dtype=float32)

time = 12192	action = 1	current_phase = 0	next_phase = 1	reward = -1.426808	array([[-1.5820643, -1.4067072]], dtype=float32)

time = 12200	action = 0	current_phase = 1	next_phase = 0	reward = 0.359242	array([[-0.3829573, -2.9108593]], dtype=float32)

time = 12205	action = 0	current_phase = 1	next_phase = 0	reward = -0.897305	array([[-0.3821662, -2.7609317]], dtype=float32)

time = 12210	action = 0	current_phase = 1	next_phase = 0	reward = -1.741007	array([[-2.6293228, -2.8764272]], dtype=float32)

time = 12215	action = 1	current_phase = 1	next_phase = 0	reward = -1.858473	array([[-3.8402498, -2.819621 ]], dtype=float32)

time = 12223	action = 0	current_phase = 0	next_phase = 1	reward = -0.274287	array([[-1.2622167, -1.6142225]], dtype=float32)

time = 12228	action = 0	current_phase = 0	next_phase = 1	reward = -0.165213	array([[-1.2707556, -2.593747 ]], dtype=float32)

time = 12233	action = 0	current_phase = 0	next_phase = 1	reward = 0.020380	array([[-2.0996091, -2.3831239]], dtype=float32)

time = 12238	action = 1	current_phase = 0	next_phase = 1	reward = -1.897798	array([[-3.9534888, -3.2094057]], dtype=float32)

time = 12246	action = 0	current_phase = 1	next_phase = 0	reward = -0.490660	array([[-1.6241791, -2.191648 ]], dtype=float32)

time = 12251	action = 0	current_phase = 1	next_phase = 0	reward = -0.330640	array([[-1.7631226, -2.209978 ]], dtype=float32)

time = 12256	action = 0	current_phase = 1	next_phase = 0	reward = -0.184607	array([[-1.3646843, -2.4908347]], dtype=float32)

time = 12261	action = 0	current_phase = 1	next_phase = 0	reward = 0.320050	array([[-1.925135 , -3.2637255]], dtype=float32)

time = 12266	action = 1	current_phase = 1	next_phase = 0	reward = -1.667703	array([[-4.326294 , -2.8988268]], dtype=float32)

time = 12274	action = 0	current_phase = 0	next_phase = 1	reward = -0.573521	array([[-1.6881541, -1.8287535]], dtype=float32)

time = 12279	action = 0	current_phase = 0	next_phase = 1	reward = -0.420721	array([[-1.5647998, -1.997031 ]], dtype=float32)

time = 12284	action = 0	current_phase = 0	next_phase = 1	reward = -0.262912	array([[-1.340634 , -1.4261832]], dtype=float32)

time = 12289	action = 0	current_phase = 0	next_phase = 1	reward = -0.166783	array([[-2.157865 , -2.3730712]], dtype=float32)

time = 12294	action = 0	current_phase = 0	next_phase = 1	reward = 0.010232	array([[-2.130217 , -2.3158348]], dtype=float32)

time = 12299	action = 1	current_phase = 0	next_phase = 1	reward = -2.011650	array([[-4.3208723, -3.3591824]], dtype=float32)

time = 12307	action = 0	current_phase = 1	next_phase = 0	reward = -0.473163	array([[-1.7341393, -2.281554 ]], dtype=float32)

time = 12312	action = 0	current_phase = 1	next_phase = 0	reward = -0.312951	array([[-1.7255111, -2.255471 ]], dtype=float32)

time = 12317	action = 0	current_phase = 1	next_phase = 0	reward = -0.179994	array([[-1.7506139, -2.3004827]], dtype=float32)

time = 12322	action = 0	current_phase = 1	next_phase = 0	reward = 0.276295	array([[-1.9807175, -3.0703542]], dtype=float32)

time = 12327	action = 1	current_phase = 1	next_phase = 0	reward = -1.785574	array([[-4.3809547, -2.977528 ]], dtype=float32)

time = 12335	action = 0	current_phase = 0	next_phase = 1	reward = -0.528155	array([[-1.6013384, -1.6099324]], dtype=float32)

time = 12340	action = 0	current_phase = 0	next_phase = 1	reward = -0.374980	array([[-1.594977 , -1.9406884]], dtype=float32)

time = 12345	action = 0	current_phase = 0	next_phase = 1	reward = -0.228997	array([[-1.5571307, -1.8397652]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0655 - val_loss: 0.0358

Epoch 2/50

 - 4s - loss: 0.0565 - val_loss: 0.0349

Epoch 3/50

 - 4s - loss: 0.0660 - val_loss: 0.0348

Epoch 4/50

 - 4s - loss: 0.0523 - val_loss: 0.0371

Epoch 5/50

 - 4s - loss: 0.0562 - val_loss: 0.0362

Epoch 6/50

 - 4s - loss: 0.0480 - val_loss: 0.0357

Epoch 7/50

 - 4s - loss: 0.0529 - val_loss: 0.0359

Epoch 8/50

 - 4s - loss: 0.0504 - val_loss: 0.0358

Epoch 9/50

 - 4s - loss: 0.0490 - val_loss: 0.0371

Epoch 10/50

 - 4s - loss: 0.0535 - val_loss: 0.0361

Epoch 11/50

 - 4s - loss: 0.0485 - val_loss: 0.0367

Epoch 12/50

 - 4s - loss: 0.0437 - val_loss: 0.0376

Epoch 13/50

 - 4s - loss: 0.0466 - val_loss: 0.0377

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 513, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 501, after forget

time = 12350	action = 0	current_phase = 0	next_phase = 1	reward = 0.072909	array([[-2.1394687, -2.5995193]], dtype=float32)

time = 12355	action = 1	current_phase = 0	next_phase = 1	reward = -1.021269	array([[-2.770981 , -2.2537112]], dtype=float32)

time = 12363	action = 0	current_phase = 1	next_phase = 0	reward = -0.587619	array([[-1.9332635, -2.2556443]], dtype=float32)

time = 12368	action = 0	current_phase = 1	next_phase = 0	reward = -0.435715	array([[-1.7003994, -2.4069462]], dtype=float32)

time = 12373	action = 0	current_phase = 1	next_phase = 0	reward = -0.275326	array([[-1.8399513, -2.2392776]], dtype=float32)

time = 12378	action = 0	current_phase = 1	next_phase = 0	reward = -0.163240	array([[-2.0098855, -2.1834118]], dtype=float32)

time = 12383	action = 0	current_phase = 1	next_phase = 0	reward = 0.131403	array([[-2.1113865, -2.3638446]], dtype=float32)

time = 12388	action = 1	current_phase = 1	next_phase = 0	reward = -1.892364	array([[-4.383637 , -3.0886734]], dtype=float32)

time = 12396	action = 1	current_phase = 0	next_phase = 1	reward = -1.699757	array([[-1.6438562, -1.6048523]], dtype=float32)

time = 12404	action = 0	current_phase = 1	next_phase = 0	reward = -0.236588	array([[-0.8397606, -2.641954 ]], dtype=float32)

time = 12409	action = 0	current_phase = 1	next_phase = 0	reward = -0.189139	array([[-0.03697139, -2.6061206 ]], dtype=float32)

time = 12414	action = 0	current_phase = 1	next_phase = 0	reward = -0.153749	array([[-0.6364908, -1.2739277]], dtype=float32)

time = 12419	action = 0	current_phase = 1	next_phase = 0	reward = -1.603166	array([[-2.5013242, -2.8235376]], dtype=float32)

time = 12424	action = 1	current_phase = 1	next_phase = 0	reward = -1.906166	array([[-2.788319, -2.759087]], dtype=float32)

time = 12432	action = 0	current_phase = 0	next_phase = 1	reward = -0.305991	array([[-1.5218596, -1.5634236]], dtype=float32)

time = 12437	action = 0	current_phase = 0	next_phase = 1	reward = -0.168891	array([[-1.4246624, -1.9573157]], dtype=float32)

time = 12442	action = 0	current_phase = 0	next_phase = 1	reward = 0.187488	array([[-2.3037317, -2.4026906]], dtype=float32)

time = 12447	action = 1	current_phase = 0	next_phase = 1	reward = -1.783639	array([[-3.6991053, -3.132694 ]], dtype=float32)

time = 12455	action = 0	current_phase = 1	next_phase = 0	reward = -0.528431	array([[-1.764926 , -2.1510823]], dtype=float32)

time = 12460	action = 0	current_phase = 1	next_phase = 0	reward = -0.385887	array([[-1.6185107, -2.4024603]], dtype=float32)

time = 12465	action = 0	current_phase = 1	next_phase = 0	reward = -0.227158	array([[-1.597753 , -2.4565945]], dtype=float32)

time = 12470	action = 0	current_phase = 1	next_phase = 0	reward = 0.369100	array([[-1.7964816, -3.0221212]], dtype=float32)

time = 12475	action = 1	current_phase = 1	next_phase = 0	reward = -1.305566	array([[-3.3635404, -2.4848628]], dtype=float32)

time = 12483	action = 1	current_phase = 0	next_phase = 1	reward = -1.850197	array([[-1.7797588, -1.7679764]], dtype=float32)

time = 12491	action = 0	current_phase = 1	next_phase = 0	reward = -0.322426	array([[-1.8871403, -2.4989874]], dtype=float32)

time = 12496	action = 0	current_phase = 1	next_phase = 0	reward = -0.184477	array([[-0.39891517, -2.6716433 ]], dtype=float32)

time = 12501	action = 0	current_phase = 1	next_phase = 0	reward = 0.299656	array([[ 0.05691871, -2.6144226 ]], dtype=float32)

time = 12506	action = 0	current_phase = 1	next_phase = 0	reward = -1.173094	array([[-1.5377948, -2.8763902]], dtype=float32)

time = 12511	action = 1	current_phase = 1	next_phase = 0	reward = -2.069852	array([[-3.3293657, -3.206739 ]], dtype=float32)

time = 12519	action = 0	current_phase = 0	next_phase = 1	reward = -0.409550	array([[-1.4948812, -1.6659662]], dtype=float32)

time = 12524	action = 0	current_phase = 0	next_phase = 1	reward = -0.261211	array([[-1.4827486, -1.7407165]], dtype=float32)

time = 12529	action = 1	current_phase = 0	next_phase = 1	reward = -0.889522	array([[-2.0485053, -1.970416 ]], dtype=float32)

time = 12537	action = 1	current_phase = 1	next_phase = 0	reward = -1.782662	array([[-2.5839503, -2.570351 ]], dtype=float32)

time = 12545	action = 0	current_phase = 0	next_phase = 1	reward = -0.521574	array([[-1.6660962, -1.7685803]], dtype=float32)

time = 12550	action = 0	current_phase = 0	next_phase = 1	reward = -0.370011	array([[-1.506028 , -1.9260505]], dtype=float32)

time = 12555	action = 0	current_phase = 0	next_phase = 1	reward = -0.215176	array([[-1.6553309, -1.7156   ]], dtype=float32)

time = 12560	action = 0	current_phase = 0	next_phase = 1	reward = 0.349032	array([[-2.064629, -2.452147]], dtype=float32)

time = 12565	action = 1	current_phase = 0	next_phase = 1	reward = -1.418245	array([[-2.9531603, -2.5945003]], dtype=float32)

time = 12573	action = 0	current_phase = 1	next_phase = 0	reward = -0.581837	array([[-1.8940063, -2.2706683]], dtype=float32)

time = 12578	action = 0	current_phase = 1	next_phase = 0	reward = -0.437030	array([[-1.6360822, -2.4465592]], dtype=float32)

time = 12583	action = 0	current_phase = 1	next_phase = 0	reward = -0.277579	array([[-1.83827  , -2.2361534]], dtype=float32)

time = 12588	action = 0	current_phase = 1	next_phase = 0	reward = -0.161379	array([[-2.012074 , -2.1646454]], dtype=float32)

time = 12593	action = 0	current_phase = 1	next_phase = 0	reward = 0.191748	array([[-2.0668066, -2.2877393]], dtype=float32)

time = 12598	action = 1	current_phase = 1	next_phase = 0	reward = -1.900844	array([[-4.236971 , -3.0609138]], dtype=float32)

time = 12606	action = 1	current_phase = 0	next_phase = 1	reward = -1.740249	array([[-1.6910737, -1.6506833]], dtype=float32)

time = 12614	action = 0	current_phase = 1	next_phase = 0	reward = -0.259726	array([[-1.1795206, -2.4990067]], dtype=float32)

time = 12619	action = 0	current_phase = 1	next_phase = 0	reward = -0.168020	array([[-0.29817516, -2.4797697 ]], dtype=float32)

time = 12624	action = 0	current_phase = 1	next_phase = 0	reward = 0.044184	array([[-0.33375093, -1.0984471 ]], dtype=float32)

time = 12629	action = 0	current_phase = 1	next_phase = 0	reward = -1.589716	array([[-0.7544123, -3.2302737]], dtype=float32)

time = 12634	action = 0	current_phase = 1	next_phase = 0	reward = -1.633384	array([[-1.3148016, -2.62795  ]], dtype=float32)

time = 12639	action = 1	current_phase = 1	next_phase = 0	reward = -1.626704	array([[-3.919608 , -2.8479118]], dtype=float32)

time = 12647	action = 0	current_phase = 0	next_phase = 1	reward = -0.165060	array([[-1.2043974, -1.6930356]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0559 - val_loss: 0.0281

Epoch 2/50

 - 4s - loss: 0.0502 - val_loss: 0.0291

Epoch 3/50

 - 4s - loss: 0.0594 - val_loss: 0.0298

Epoch 4/50

 - 4s - loss: 0.0509 - val_loss: 0.0289

Epoch 5/50

 - 4s - loss: 0.0497 - val_loss: 0.0287

Epoch 6/50

 - 4s - loss: 0.0459 - val_loss: 0.0289

Epoch 7/50

 - 4s - loss: 0.0499 - val_loss: 0.0294

Epoch 8/50

 - 4s - loss: 0.0399 - val_loss: 0.0288

Epoch 9/50

 - 4s - loss: 0.0416 - val_loss: 0.0279

Epoch 10/50

 - 4s - loss: 0.0421 - val_loss: 0.0292

Epoch 11/50

 - 4s - loss: 0.0417 - val_loss: 0.0279

Epoch 12/50

 - 4s - loss: 0.0419 - val_loss: 0.0290

Epoch 13/50

 - 4s - loss: 0.0390 - val_loss: 0.0277

Epoch 14/50

 - 4s - loss: 0.0419 - val_loss: 0.0301

Epoch 15/50

 - 4s - loss: 0.0415 - val_loss: 0.0290

Epoch 16/50

 - 4s - loss: 0.0378 - val_loss: 0.0282

Epoch 17/50

 - 4s - loss: 0.0392 - val_loss: 0.0272

Epoch 18/50

 - 4s - loss: 0.0390 - val_loss: 0.0276

Epoch 19/50

 - 4s - loss: 0.0378 - val_loss: 0.0277

Epoch 20/50

 - 4s - loss: 0.0380 - val_loss: 0.0277

Epoch 21/50

 - 4s - loss: 0.0355 - val_loss: 0.0295

Epoch 22/50

 - 4s - loss: 0.0399 - val_loss: 0.0281

Epoch 23/50

 - 4s - loss: 0.0364 - val_loss: 0.0288

Epoch 24/50

 - 4s - loss: 0.0325 - val_loss: 0.0331

Epoch 25/50

 - 4s - loss: 0.0334 - val_loss: 0.0297

Epoch 26/50

 - 4s - loss: 0.0310 - val_loss: 0.0294

Epoch 27/50

 - 4s - loss: 0.0315 - val_loss: 0.0285

length of memory (state 0, action 0): 1011, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 520, after forget

length of memory (state 1, action 0): 1027, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 508, after forget

time = 12652	action = 0	current_phase = 0	next_phase = 1	reward = 0.169293	array([[-1.1789637, -2.7739952]], dtype=float32)

time = 12657	action = 1	current_phase = 0	next_phase = 1	reward = -1.779056	array([[-3.847334 , -3.4699214]], dtype=float32)

time = 12665	action = 0	current_phase = 1	next_phase = 0	reward = -0.515184	array([[-2.0310423, -2.2218645]], dtype=float32)

time = 12670	action = 0	current_phase = 1	next_phase = 0	reward = -0.364980	array([[-1.5995154, -2.4312742]], dtype=float32)

time = 12675	action = 0	current_phase = 1	next_phase = 0	reward = -0.210985	array([[-1.5131662, -2.6392171]], dtype=float32)

time = 12680	action = 0	current_phase = 1	next_phase = 0	reward = 0.341589	array([[-2.027816 , -3.0937524]], dtype=float32)

time = 12685	action = 1	current_phase = 1	next_phase = 0	reward = -1.318871	array([[-3.780236 , -2.8633173]], dtype=float32)

time = 12693	action = 0	current_phase = 0	next_phase = 1	reward = -0.585773	array([[-1.7557456, -1.808049 ]], dtype=float32)

time = 12698	action = 0	current_phase = 0	next_phase = 1	reward = -0.429162	array([[-1.5666623, -1.9767861]], dtype=float32)

time = 12703	action = 1	current_phase = 0	next_phase = 1	reward = -1.367752	array([[-1.7623901, -1.3042865]], dtype=float32)

time = 12711	action = 0	current_phase = 1	next_phase = 0	reward = 0.306908	array([[-0.28359026, -3.0700293 ]], dtype=float32)

time = 12716	action = 0	current_phase = 1	next_phase = 0	reward = -1.118732	array([[-2.7690318, -2.8406308]], dtype=float32)

time = 12721	action = 1	current_phase = 1	next_phase = 0	reward = -2.075244	array([[-3.7635312, -3.1973884]], dtype=float32)

time = 12729	action = 0	current_phase = 0	next_phase = 1	reward = -0.415894	array([[-1.4537244, -1.7203717]], dtype=float32)

time = 12734	action = 0	current_phase = 0	next_phase = 1	reward = -0.251269	array([[-1.3798048, -1.9235523]], dtype=float32)

time = 12739	action = 0	current_phase = 0	next_phase = 1	reward = -0.172057	array([[-1.9841342, -2.137391 ]], dtype=float32)

time = 12744	action = 0	current_phase = 0	next_phase = 1	reward = -0.022604	array([[-2.2733293, -2.457845 ]], dtype=float32)

time = 12749	action = 1	current_phase = 0	next_phase = 1	reward = -2.010668	array([[-4.197206 , -3.2898405]], dtype=float32)

time = 12757	action = 0	current_phase = 1	next_phase = 0	reward = -0.474485	array([[-1.8026155, -2.2556949]], dtype=float32)

time = 12762	action = 0	current_phase = 1	next_phase = 0	reward = -0.322638	array([[-1.8280554, -2.311127 ]], dtype=float32)

time = 12767	action = 0	current_phase = 1	next_phase = 0	reward = -0.178185	array([[-1.6894039, -2.3859305]], dtype=float32)

time = 12772	action = 0	current_phase = 1	next_phase = 0	reward = 0.277184	array([[-1.9636581, -3.2559876]], dtype=float32)

time = 12777	action = 1	current_phase = 1	next_phase = 0	reward = -1.732740	array([[-4.4128685, -3.0481267]], dtype=float32)

time = 12785	action = 1	current_phase = 0	next_phase = 1	reward = -1.777996	array([[-1.6766946, -1.6763299]], dtype=float32)

time = 12793	action = 0	current_phase = 1	next_phase = 0	reward = -0.278938	array([[-0.73249805, -2.220261  ]], dtype=float32)

time = 12798	action = 0	current_phase = 1	next_phase = 0	reward = -0.161256	array([[-1.0230719, -2.6861978]], dtype=float32)

time = 12803	action = 0	current_phase = 1	next_phase = 0	reward = 0.079684	array([[-0.9095981, -2.3705952]], dtype=float32)

time = 12808	action = 0	current_phase = 1	next_phase = 0	reward = -1.461249	array([[-2.6729896, -2.898351 ]], dtype=float32)

time = 12813	action = 0	current_phase = 1	next_phase = 0	reward = -1.668326	array([[-2.3526301, -3.0258281]], dtype=float32)

time = 12818	action = 1	current_phase = 1	next_phase = 0	reward = -1.703512	array([[-3.9016256, -2.860846 ]], dtype=float32)

time = 12826	action = 1	current_phase = 0	next_phase = 1	reward = -1.302985	array([[-1.5666361, -1.53355  ]], dtype=float32)

time = 12834	action = 1	current_phase = 1	next_phase = 0	reward = -0.418485	array([[-2.7520766, -1.7946335]], dtype=float32)

time = 12842	action = 0	current_phase = 0	next_phase = 1	reward = -0.625185	array([[-1.5495973, -2.2310686]], dtype=float32)

time = 12847	action = 0	current_phase = 0	next_phase = 1	reward = -0.472949	array([[-1.7572691, -2.428185 ]], dtype=float32)

time = 12852	action = 0	current_phase = 0	next_phase = 1	reward = -0.321462	array([[-1.3907468, -1.9489613]], dtype=float32)

time = 12857	action = 0	current_phase = 0	next_phase = 1	reward = -0.183858	array([[-1.2926986, -2.6832426]], dtype=float32)

time = 12862	action = 0	current_phase = 0	next_phase = 1	reward = 0.126724	array([[-2.1889632, -3.1106837]], dtype=float32)

time = 12867	action = 1	current_phase = 0	next_phase = 1	reward = -1.789864	array([[-4.016305 , -3.5068116]], dtype=float32)

time = 12875	action = 0	current_phase = 1	next_phase = 0	reward = -0.532790	array([[-1.7888288, -2.187019 ]], dtype=float32)

time = 12880	action = 0	current_phase = 1	next_phase = 0	reward = -0.373567	array([[-1.6005769, -2.4570327]], dtype=float32)

time = 12885	action = 0	current_phase = 1	next_phase = 0	reward = -0.223359	array([[-1.5684068, -2.4560623]], dtype=float32)

time = 12890	action = 0	current_phase = 1	next_phase = 0	reward = 0.368004	array([[-1.6460847, -2.728486 ]], dtype=float32)

time = 12895	action = 1	current_phase = 1	next_phase = 0	reward = -1.305101	array([[-3.4805572, -2.701077 ]], dtype=float32)

time = 12903	action = 1	current_phase = 0	next_phase = 1	reward = -1.865953	array([[-1.8213723, -1.8062327]], dtype=float32)

time = 12911	action = 0	current_phase = 1	next_phase = 0	reward = -0.333108	array([[-1.8739784, -2.5143921]], dtype=float32)

time = 12916	action = 0	current_phase = 1	next_phase = 0	reward = -0.187679	array([[-0.45668042, -2.747947  ]], dtype=float32)

time = 12921	action = 0	current_phase = 1	next_phase = 0	reward = 0.324244	array([[ 0.09596896, -2.7092185 ]], dtype=float32)

time = 12926	action = 0	current_phase = 1	next_phase = 0	reward = -1.116754	array([[-0.7001976, -2.8621683]], dtype=float32)

time = 12931	action = 0	current_phase = 1	next_phase = 0	reward = -1.710602	array([[-3.1465893, -3.2474587]], dtype=float32)

time = 12936	action = 1	current_phase = 1	next_phase = 0	reward = -1.801986	array([[-3.9631557, -2.842054 ]], dtype=float32)

time = 12944	action = 0	current_phase = 0	next_phase = 1	reward = -0.254234	array([[-1.2135379, -1.6780012]], dtype=float32)

time = 12949	action = 0	current_phase = 0	next_phase = 1	reward = -0.179936	array([[-1.187403 , -2.6984706]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0505 - val_loss: 0.0473

Epoch 2/50

 - 4s - loss: 0.0507 - val_loss: 0.0501

Epoch 3/50

 - 4s - loss: 0.0435 - val_loss: 0.0471

Epoch 4/50

 - 4s - loss: 0.0427 - val_loss: 0.0469

Epoch 5/50

 - 4s - loss: 0.0438 - val_loss: 0.0481

Epoch 6/50

 - 4s - loss: 0.0414 - val_loss: 0.0461

Epoch 7/50

 - 4s - loss: 0.0422 - val_loss: 0.0515

Epoch 8/50

 - 4s - loss: 0.0402 - val_loss: 0.0465

Epoch 9/50

 - 4s - loss: 0.0354 - val_loss: 0.0467

Epoch 10/50

 - 4s - loss: 0.0371 - val_loss: 0.0480

Epoch 11/50

 - 4s - loss: 0.0473 - val_loss: 0.0480

Epoch 12/50

 - 4s - loss: 0.0396 - val_loss: 0.0477

Epoch 13/50

 - 4s - loss: 0.0385 - val_loss: 0.0495

Epoch 14/50

 - 4s - loss: 0.0352 - val_loss: 0.0504

Epoch 15/50

 - 4s - loss: 0.0341 - val_loss: 0.0503

Epoch 16/50

 - 4s - loss: 0.0339 - val_loss: 0.0495

length of memory (state 0, action 0): 1014, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 527, after forget

length of memory (state 1, action 0): 1024, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 515, after forget

time = 12954	action = 1	current_phase = 0	next_phase = 1	reward = -0.551131	array([[-2.49356  , -2.1630769]], dtype=float32)

time = 12962	action = 0	current_phase = 1	next_phase = 0	reward = -0.618784	array([[-2.0971549, -2.3669195]], dtype=float32)

time = 12967	action = 0	current_phase = 1	next_phase = 0	reward = -0.455689	array([[-1.0580902, -2.3614192]], dtype=float32)

time = 12972	action = 0	current_phase = 1	next_phase = 0	reward = -0.295559	array([[-1.8339605, -2.3522513]], dtype=float32)

time = 12977	action = 0	current_phase = 1	next_phase = 0	reward = -0.171201	array([[-1.9889039, -2.2610176]], dtype=float32)

time = 12982	action = 0	current_phase = 1	next_phase = 0	reward = 0.106914	array([[-2.421704 , -3.3636167]], dtype=float32)

time = 12987	action = 1	current_phase = 1	next_phase = 0	reward = -1.785405	array([[-4.5171194, -3.2169874]], dtype=float32)

time = 12995	action = 0	current_phase = 0	next_phase = 1	reward = -0.527546	array([[-1.7747763, -1.8284392]], dtype=float32)

time = 13000	action = 0	current_phase = 0	next_phase = 1	reward = -0.378660	array([[-1.6059374, -1.964304 ]], dtype=float32)

time = 13005	action = 1	current_phase = 0	next_phase = 1	reward = -1.323440	array([[-1.6559083, -1.5438175]], dtype=float32)

time = 13013	action = 0	current_phase = 1	next_phase = 0	reward = -0.057590	array([[ 0.2571418, -3.7471542]], dtype=float32)

time = 13018	action = 0	current_phase = 1	next_phase = 0	reward = -1.469120	array([[-0.20619002, -3.313502  ]], dtype=float32)

time = 13023	action = 1	current_phase = 1	next_phase = 0	reward = -1.959689	array([[-3.704783 , -2.9832911]], dtype=float32)

time = 13031	action = 0	current_phase = 0	next_phase = 1	reward = -0.344834	array([[-1.5355529, -1.6866001]], dtype=float32)

time = 13036	action = 0	current_phase = 0	next_phase = 1	reward = -0.195902	array([[-1.5139515, -2.3961544]], dtype=float32)

time = 13041	action = 0	current_phase = 0	next_phase = 1	reward = 0.325041	array([[-1.7241999, -2.850452 ]], dtype=float32)

time = 13046	action = 1	current_phase = 0	next_phase = 1	reward = -1.555595	array([[-3.3006153, -3.0116472]], dtype=float32)

time = 13054	action = 0	current_phase = 1	next_phase = 0	reward = -0.557750	array([[-2.0380964, -2.3640525]], dtype=float32)

time = 13059	action = 0	current_phase = 1	next_phase = 0	reward = -0.408493	array([[-1.5755388, -2.4986181]], dtype=float32)

time = 13064	action = 0	current_phase = 1	next_phase = 0	reward = -0.251096	array([[-1.6488887, -2.4722493]], dtype=float32)

time = 13069	action = 0	current_phase = 1	next_phase = 0	reward = -0.167779	array([[-1.7085202, -2.4603634]], dtype=float32)

time = 13074	action = 1	current_phase = 1	next_phase = 0	reward = -0.463546	array([[-2.804405 , -1.8883522]], dtype=float32)

time = 13082	action = 1	current_phase = 0	next_phase = 1	reward = -1.911321	array([[-1.8642486, -1.8296504]], dtype=float32)

time = 13090	action = 0	current_phase = 1	next_phase = 0	reward = -0.358177	array([[-1.6320997, -2.5387595]], dtype=float32)

time = 13095	action = 0	current_phase = 1	next_phase = 0	reward = -0.201300	array([[-0.9533428, -2.6601677]], dtype=float32)

time = 13100	action = 0	current_phase = 1	next_phase = 0	reward = 0.365433	array([[-0.8112351, -2.6956584]], dtype=float32)

time = 13105	action = 1	current_phase = 1	next_phase = 0	reward = -1.361077	array([[-3.1218944, -2.821675 ]], dtype=float32)

time = 13113	action = 0	current_phase = 0	next_phase = 1	reward = -0.583495	array([[-1.7137003, -1.8386697]], dtype=float32)

time = 13118	action = 0	current_phase = 0	next_phase = 1	reward = -0.426379	array([[-1.5934597, -1.979659 ]], dtype=float32)

time = 13123	action = 1	current_phase = 0	next_phase = 1	reward = -1.366275	array([[-1.7761042, -1.3436626]], dtype=float32)

time = 13131	action = 0	current_phase = 1	next_phase = 0	reward = 0.279856	array([[-0.2188493, -2.915462 ]], dtype=float32)

time = 13136	action = 0	current_phase = 1	next_phase = 0	reward = -1.118399	array([[-1.591238 , -2.9754357]], dtype=float32)

time = 13141	action = 1	current_phase = 1	next_phase = 0	reward = -2.058437	array([[-4.4496713, -3.209489 ]], dtype=float32)

time = 13149	action = 0	current_phase = 0	next_phase = 1	reward = -0.400469	array([[-1.4930979, -1.7570913]], dtype=float32)

time = 13154	action = 0	current_phase = 0	next_phase = 1	reward = -0.254466	array([[-1.5348921, -2.2502766]], dtype=float32)

time = 13159	action = 0	current_phase = 0	next_phase = 1	reward = -0.178372	array([[-1.663198 , -2.2366066]], dtype=float32)

time = 13164	action = 1	current_phase = 0	next_phase = 1	reward = -0.545366	array([[-2.2250586, -2.1029053]], dtype=float32)

time = 13172	action = 1	current_phase = 1	next_phase = 0	reward = -1.931641	array([[-2.275447, -2.218073]], dtype=float32)

time = 13180	action = 0	current_phase = 0	next_phase = 1	reward = -0.379483	array([[-1.3165534, -1.9638029]], dtype=float32)

time = 13185	action = 0	current_phase = 0	next_phase = 1	reward = -0.231748	array([[-1.3719407, -2.0082211]], dtype=float32)

time = 13190	action = 0	current_phase = 0	next_phase = 1	reward = 0.081142	array([[-1.2954261, -3.045803 ]], dtype=float32)

time = 13195	action = 0	current_phase = 0	next_phase = 1	reward = -0.500924	array([[-1.1232431, -2.1007714]], dtype=float32)

time = 13200	action = 0	current_phase = 0	next_phase = 1	reward = -1.733908	array([[-3.024317 , -3.5112839]], dtype=float32)

time = 13205	action = 1	current_phase = 0	next_phase = 1	reward = -1.856821	array([[-4.002809 , -3.3105555]], dtype=float32)

time = 13213	action = 0	current_phase = 1	next_phase = 0	reward = -0.271931	array([[-1.7916397, -2.2440405]], dtype=float32)

time = 13218	action = 0	current_phase = 1	next_phase = 0	reward = -0.161050	array([[-1.8963778, -2.670468 ]], dtype=float32)

time = 13223	action = 0	current_phase = 1	next_phase = 0	reward = 0.087136	array([[-2.1617386, -2.223106 ]], dtype=float32)

time = 13228	action = 1	current_phase = 1	next_phase = 0	reward = -1.899357	array([[-4.21664  , -3.2442372]], dtype=float32)

time = 13236	action = 0	current_phase = 0	next_phase = 1	reward = -0.501665	array([[-0.725057 , -2.0547347]], dtype=float32)

time = 13241	action = 0	current_phase = 0	next_phase = 1	reward = -0.340167	array([[-1.6737314, -1.816302 ]], dtype=float32)

time = 13246	action = 0	current_phase = 0	next_phase = 1	reward = -0.189249	array([[-1.9167795, -2.0031934]], dtype=float32)

time = 13251	action = 0	current_phase = 0	next_phase = 1	reward = 0.298679	array([[-2.4566321, -2.674457 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0565 - val_loss: 0.0420

Epoch 2/50

 - 4s - loss: 0.0631 - val_loss: 0.0459

Epoch 3/50

 - 4s - loss: 0.0693 - val_loss: 0.0445

Epoch 4/50

 - 4s - loss: 0.0531 - val_loss: 0.0418

Epoch 5/50

 - 4s - loss: 0.0527 - val_loss: 0.0425

Epoch 6/50

 - 4s - loss: 0.0431 - val_loss: 0.0458

Epoch 7/50

 - 4s - loss: 0.0436 - val_loss: 0.0462

Epoch 8/50

 - 4s - loss: 0.0473 - val_loss: 0.0467

Epoch 9/50

 - 4s - loss: 0.0466 - val_loss: 0.0501

Epoch 10/50

 - 4s - loss: 0.0444 - val_loss: 0.0477

Epoch 11/50

 - 4s - loss: 0.0443 - val_loss: 0.0529

Epoch 12/50

 - 4s - loss: 0.0444 - val_loss: 0.0484

Epoch 13/50

 - 4s - loss: 0.0415 - val_loss: 0.0500

Epoch 14/50

 - 4s - loss: 0.0394 - val_loss: 0.0531

length of memory (state 0, action 0): 1019, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 534, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 522, after forget

time = 13256	action = 1	current_phase = 0	next_phase = 1	reward = -1.560133	array([[-3.1300025, -2.9949055]], dtype=float32)

time = 13264	action = 0	current_phase = 1	next_phase = 0	reward = -0.567046	array([[-1.746355 , -2.3123543]], dtype=float32)

time = 13269	action = 0	current_phase = 1	next_phase = 0	reward = -0.412860	array([[-1.5370686, -2.4952383]], dtype=float32)

time = 13274	action = 0	current_phase = 1	next_phase = 0	reward = -0.253879	array([[-1.4254541, -2.4086883]], dtype=float32)

time = 13279	action = 0	current_phase = 1	next_phase = 0	reward = -0.169894	array([[-1.6525308, -2.6874754]], dtype=float32)

time = 13284	action = 1	current_phase = 1	next_phase = 0	reward = -0.487660	array([[-2.6588292, -1.8975298]], dtype=float32)

time = 13292	action = 0	current_phase = 0	next_phase = 1	reward = -0.618066	array([[-1.8063046, -1.8685877]], dtype=float32)

time = 13297	action = 0	current_phase = 0	next_phase = 1	reward = -0.462875	array([[-1.5662482, -1.9818066]], dtype=float32)

time = 13302	action = 1	current_phase = 0	next_phase = 1	reward = -1.428748	array([[-1.6281097, -1.4410543]], dtype=float32)

time = 13310	action = 0	current_phase = 1	next_phase = 0	reward = 0.356557	array([[-0.6606086, -2.5624874]], dtype=float32)

time = 13315	action = 0	current_phase = 1	next_phase = 0	reward = -0.845075	array([[-2.15667  , -2.9426646]], dtype=float32)

time = 13320	action = 1	current_phase = 1	next_phase = 0	reward = -2.118945	array([[-3.4310684, -2.985242 ]], dtype=float32)

time = 13328	action = 0	current_phase = 0	next_phase = 1	reward = -0.437209	array([[-1.5009692, -1.7393756]], dtype=float32)

time = 13333	action = 0	current_phase = 0	next_phase = 1	reward = -0.289554	array([[-1.5370659, -1.6823717]], dtype=float32)

time = 13338	action = 0	current_phase = 0	next_phase = 1	reward = -0.173069	array([[-1.8679831, -2.073385 ]], dtype=float32)

time = 13343	action = 0	current_phase = 0	next_phase = 1	reward = 0.067010	array([[-2.232232, -2.663242]], dtype=float32)

time = 13348	action = 1	current_phase = 0	next_phase = 1	reward = -1.892444	array([[-3.8110175, -3.3242102]], dtype=float32)

time = 13356	action = 0	current_phase = 1	next_phase = 0	reward = -0.497317	array([[-1.6340871, -2.1983159]], dtype=float32)

time = 13361	action = 0	current_phase = 1	next_phase = 0	reward = -0.340274	array([[-1.5631907, -2.3662388]], dtype=float32)

time = 13366	action = 0	current_phase = 1	next_phase = 0	reward = -0.197218	array([[-1.5940981, -2.421105 ]], dtype=float32)

time = 13371	action = 0	current_phase = 1	next_phase = 0	reward = 0.308788	array([[-1.9818012, -3.211526 ]], dtype=float32)

time = 13376	action = 1	current_phase = 1	next_phase = 0	reward = -1.612569	array([[-4.39816  , -3.0453446]], dtype=float32)

time = 13384	action = 0	current_phase = 0	next_phase = 1	reward = -0.560844	array([[-1.8692849, -2.0419977]], dtype=float32)

time = 13389	action = 0	current_phase = 0	next_phase = 1	reward = -0.409003	array([[-1.5669992, -1.9785665]], dtype=float32)

time = 13394	action = 1	current_phase = 0	next_phase = 1	reward = -1.349190	array([[-1.5806355, -1.4759125]], dtype=float32)

time = 13402	action = 0	current_phase = 1	next_phase = 0	reward = 0.242404	array([[ 0.17646164, -2.787579  ]], dtype=float32)

time = 13407	action = 0	current_phase = 1	next_phase = 0	reward = -1.316076	array([[-2.442843 , -2.6485279]], dtype=float32)

time = 13412	action = 0	current_phase = 1	next_phase = 0	reward = -1.688285	array([[-2.352276 , -3.1255615]], dtype=float32)

time = 13417	action = 1	current_phase = 1	next_phase = 0	reward = -1.757997	array([[-3.783046 , -2.7101667]], dtype=float32)

time = 13425	action = 0	current_phase = 0	next_phase = 1	reward = -0.215313	array([[-1.3876346, -1.9237453]], dtype=float32)

time = 13430	action = 0	current_phase = 0	next_phase = 1	reward = 0.346181	array([[-0.4182794, -2.6493206]], dtype=float32)

time = 13435	action = 1	current_phase = 0	next_phase = 1	reward = -1.368885	array([[-3.5044222, -2.7715201]], dtype=float32)

time = 13443	action = 0	current_phase = 1	next_phase = 0	reward = -0.589884	array([[-2.062417 , -2.2432082]], dtype=float32)

time = 13448	action = 0	current_phase = 1	next_phase = 0	reward = -0.435222	array([[-1.7439907, -2.3089225]], dtype=float32)

time = 13453	action = 0	current_phase = 1	next_phase = 0	reward = -0.265509	array([[-1.7658389, -2.3219817]], dtype=float32)

time = 13458	action = 0	current_phase = 1	next_phase = 0	reward = -0.156969	array([[-1.7571278, -2.2911813]], dtype=float32)

time = 13463	action = 0	current_phase = 1	next_phase = 0	reward = 0.074335	array([[-1.74344  , -2.4135528]], dtype=float32)

time = 13468	action = 1	current_phase = 1	next_phase = 0	reward = -1.892127	array([[-4.415538 , -3.1035786]], dtype=float32)

time = 13476	action = 0	current_phase = 0	next_phase = 1	reward = -0.488824	array([[-1.6585801, -1.8455228]], dtype=float32)

time = 13481	action = 0	current_phase = 0	next_phase = 1	reward = -0.340508	array([[-1.5130417, -1.9508739]], dtype=float32)

time = 13486	action = 0	current_phase = 0	next_phase = 1	reward = -0.198040	array([[-1.8344337, -1.920336 ]], dtype=float32)

time = 13491	action = 0	current_phase = 0	next_phase = 1	reward = 0.246081	array([[-2.2121935, -2.5586057]], dtype=float32)

time = 13496	action = 1	current_phase = 0	next_phase = 1	reward = -1.666278	array([[-3.21807  , -2.9798703]], dtype=float32)

time = 13504	action = 0	current_phase = 1	next_phase = 0	reward = -0.554923	array([[-1.6942608, -2.3443918]], dtype=float32)

time = 13509	action = 0	current_phase = 1	next_phase = 0	reward = -0.402559	array([[-1.5425304, -2.4948106]], dtype=float32)

time = 13514	action = 0	current_phase = 1	next_phase = 0	reward = -0.253256	array([[-1.483583 , -2.4652169]], dtype=float32)

time = 13519	action = 0	current_phase = 1	next_phase = 0	reward = -0.174018	array([[-1.6067287, -2.6808565]], dtype=float32)

time = 13524	action = 1	current_phase = 1	next_phase = 0	reward = -0.528057	array([[-2.3487704, -1.6761056]], dtype=float32)

time = 13532	action = 0	current_phase = 0	next_phase = 1	reward = -0.609324	array([[-1.7672175, -1.867037 ]], dtype=float32)

time = 13537	action = 0	current_phase = 0	next_phase = 1	reward = -0.448398	array([[-1.5641178, -1.9803016]], dtype=float32)

time = 13542	action = 1	current_phase = 0	next_phase = 1	reward = -1.398203	array([[-1.6403646, -1.4304377]], dtype=float32)

time = 13550	action = 0	current_phase = 1	next_phase = 0	reward = 0.334529	array([[-0.37374526, -2.8206613 ]], dtype=float32)

time = 13555	action = 0	current_phase = 1	next_phase = 0	reward = -0.852159	array([[-1.0405996, -2.7346883]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0674 - val_loss: 0.0291

Epoch 2/50

 - 4s - loss: 0.0605 - val_loss: 0.0282

Epoch 3/50

 - 4s - loss: 0.0531 - val_loss: 0.0303

Epoch 4/50

 - 4s - loss: 0.0519 - val_loss: 0.0310

Epoch 5/50

 - 4s - loss: 0.0514 - val_loss: 0.0312

Epoch 6/50

 - 4s - loss: 0.0430 - val_loss: 0.0306

Epoch 7/50

 - 4s - loss: 0.0488 - val_loss: 0.0298

Epoch 8/50

 - 4s - loss: 0.0471 - val_loss: 0.0285

Epoch 9/50

 - 4s - loss: 0.0459 - val_loss: 0.0286

Epoch 10/50

 - 4s - loss: 0.0429 - val_loss: 0.0303

Epoch 11/50

 - 4s - loss: 0.0466 - val_loss: 0.0341

Epoch 12/50

 - 4s - loss: 0.0435 - val_loss: 0.0300

length of memory (state 0, action 0): 1016, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 541, after forget

length of memory (state 1, action 0): 1024, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 528, after forget

time = 13560	action = 1	current_phase = 1	next_phase = 0	reward = -2.104306	array([[-3.6609738, -2.994875 ]], dtype=float32)

time = 13568	action = 0	current_phase = 0	next_phase = 1	reward = -0.425778	array([[-1.4486842, -1.7574605]], dtype=float32)

time = 13573	action = 1	current_phase = 0	next_phase = 1	reward = -1.379900	array([[-1.6027503, -1.5895698]], dtype=float32)

time = 13581	action = 0	current_phase = 1	next_phase = 0	reward = 0.310459	array([[-0.58008754, -2.5532134 ]], dtype=float32)

time = 13586	action = 1	current_phase = 1	next_phase = 0	reward = -1.609289	array([[-2.8088334, -2.7138767]], dtype=float32)

time = 13594	action = 0	current_phase = 0	next_phase = 1	reward = -0.549563	array([[-1.964599 , -2.2133427]], dtype=float32)

time = 13599	action = 0	current_phase = 0	next_phase = 1	reward = -0.389698	array([[-1.5351872, -1.9726195]], dtype=float32)

time = 13604	action = 1	current_phase = 0	next_phase = 1	reward = -1.321130	array([[-1.5493279, -1.4509873]], dtype=float32)

time = 13612	action = 0	current_phase = 1	next_phase = 0	reward = 0.217583	array([[ 0.26863554, -2.8178399 ]], dtype=float32)

time = 13617	action = 0	current_phase = 1	next_phase = 0	reward = -1.316249	array([[-1.9055566, -3.0704272]], dtype=float32)

time = 13622	action = 1	current_phase = 1	next_phase = 0	reward = -2.028435	array([[-3.8353732, -3.0300639]], dtype=float32)

time = 13630	action = 0	current_phase = 0	next_phase = 1	reward = -0.386598	array([[-1.4587466, -1.7450193]], dtype=float32)

time = 13635	action = 0	current_phase = 0	next_phase = 1	reward = -0.227512	array([[-1.4949528, -2.0835679]], dtype=float32)

time = 13640	action = 0	current_phase = 0	next_phase = 1	reward = 0.083161	array([[-1.9964288, -2.5469863]], dtype=float32)

time = 13645	action = 1	current_phase = 0	next_phase = 1	reward = -1.021150	array([[-2.9395185, -2.6469085]], dtype=float32)

time = 13653	action = 0	current_phase = 1	next_phase = 0	reward = -0.589618	array([[-2.1246667, -2.2065682]], dtype=float32)

time = 13658	action = 0	current_phase = 1	next_phase = 0	reward = -0.430144	array([[-1.8143696, -2.350311 ]], dtype=float32)

time = 13663	action = 0	current_phase = 1	next_phase = 0	reward = -0.275637	array([[-1.721738 , -2.2892525]], dtype=float32)

time = 13668	action = 0	current_phase = 1	next_phase = 0	reward = -0.171417	array([[-1.9848303, -2.2044113]], dtype=float32)

time = 13673	action = 0	current_phase = 1	next_phase = 0	reward = 0.101681	array([[-2.27583  , -2.6880703]], dtype=float32)

time = 13678	action = 1	current_phase = 1	next_phase = 0	reward = -1.892380	array([[-4.5468698, -3.1150904]], dtype=float32)

time = 13686	action = 0	current_phase = 0	next_phase = 1	reward = -0.494880	array([[-1.7708412, -1.8610685]], dtype=float32)

time = 13691	action = 0	current_phase = 0	next_phase = 1	reward = -0.338645	array([[-1.5334141, -1.9764644]], dtype=float32)

time = 13696	action = 0	current_phase = 0	next_phase = 1	reward = -0.190328	array([[-1.8520505, -1.9394491]], dtype=float32)

time = 13701	action = 0	current_phase = 0	next_phase = 1	reward = 0.278700	array([[-2.1533394, -2.7091618]], dtype=float32)

time = 13706	action = 1	current_phase = 0	next_phase = 1	reward = -1.560633	array([[-3.1071427, -3.026091 ]], dtype=float32)

time = 13714	action = 0	current_phase = 1	next_phase = 0	reward = -0.553617	array([[-1.784651, -2.34378 ]], dtype=float32)

time = 13719	action = 0	current_phase = 1	next_phase = 0	reward = -0.397065	array([[-1.5907311, -2.503708 ]], dtype=float32)

time = 13724	action = 0	current_phase = 1	next_phase = 0	reward = -0.244759	array([[-1.5608451, -2.463174 ]], dtype=float32)

time = 13729	action = 0	current_phase = 1	next_phase = 0	reward = -0.184044	array([[-1.7611878, -2.7088034]], dtype=float32)

time = 13734	action = 1	current_phase = 1	next_phase = 0	reward = -0.556648	array([[-2.676282 , -1.9352584]], dtype=float32)

time = 13742	action = 0	current_phase = 0	next_phase = 1	reward = -0.617762	array([[-1.8224492, -1.869757 ]], dtype=float32)

time = 13747	action = 0	current_phase = 0	next_phase = 1	reward = -0.471266	array([[-1.5787146, -1.9788423]], dtype=float32)

time = 13752	action = 1	current_phase = 0	next_phase = 1	reward = -1.453870	array([[-1.7112385, -1.4035465]], dtype=float32)

time = 13760	action = 0	current_phase = 1	next_phase = 0	reward = 0.075583	array([[-0.4330284, -2.6028636]], dtype=float32)

time = 13765	action = 0	current_phase = 1	next_phase = 0	reward = -0.556619	array([[-0.14544226, -2.4847717 ]], dtype=float32)

time = 13770	action = 1	current_phase = 1	next_phase = 0	reward = -2.122794	array([[-3.987412 , -2.8936203]], dtype=float32)

time = 13778	action = 0	current_phase = 0	next_phase = 1	reward = -0.447138	array([[-1.4556218, -1.7673701]], dtype=float32)

time = 13783	action = 0	current_phase = 0	next_phase = 1	reward = -0.302011	array([[-1.5312202, -1.7141948]], dtype=float32)

time = 13788	action = 0	current_phase = 0	next_phase = 1	reward = -0.174144	array([[-1.7906089, -2.1222072]], dtype=float32)

time = 13793	action = 0	current_phase = 0	next_phase = 1	reward = 0.151661	array([[-2.2852364, -2.365346 ]], dtype=float32)

time = 13798	action = 1	current_phase = 0	next_phase = 1	reward = -1.887610	array([[-3.618383 , -3.1510797]], dtype=float32)

time = 13806	action = 0	current_phase = 1	next_phase = 0	reward = -0.489479	array([[-1.7008175, -2.2435064]], dtype=float32)

time = 13811	action = 0	current_phase = 1	next_phase = 0	reward = -0.343375	array([[-1.6507665, -2.3935835]], dtype=float32)

time = 13816	action = 0	current_phase = 1	next_phase = 0	reward = -0.198506	array([[-1.665462, -2.432105]], dtype=float32)

time = 13821	action = 0	current_phase = 1	next_phase = 0	reward = 0.285665	array([[-2.0370314, -2.9797964]], dtype=float32)

time = 13826	action = 1	current_phase = 1	next_phase = 0	reward = -1.663412	array([[-4.4137287, -3.0202017]], dtype=float32)

time = 13834	action = 0	current_phase = 0	next_phase = 1	reward = -0.553978	array([[-1.7822329, -1.8636755]], dtype=float32)

time = 13839	action = 0	current_phase = 0	next_phase = 1	reward = -0.408796	array([[-1.5743939, -1.9807191]], dtype=float32)

time = 13844	action = 1	current_phase = 0	next_phase = 1	reward = -1.353647	array([[-1.4481148, -1.2739488]], dtype=float32)

time = 13852	action = 0	current_phase = 1	next_phase = 0	reward = 0.215221	array([[-0.79699326, -3.2733576 ]], dtype=float32)

time = 13857	action = 0	current_phase = 1	next_phase = 0	reward = -1.320012	array([[-0.09876786, -3.069515  ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0898 - val_loss: 0.0550

Epoch 2/50

 - 4s - loss: 0.0889 - val_loss: 0.0511

Epoch 3/50

 - 4s - loss: 0.0736 - val_loss: 0.0494

Epoch 4/50

 - 4s - loss: 0.0669 - val_loss: 0.0511

Epoch 5/50

 - 4s - loss: 0.0653 - val_loss: 0.0532

Epoch 6/50

 - 4s - loss: 0.0648 - val_loss: 0.0515

Epoch 7/50

 - 4s - loss: 0.0610 - val_loss: 0.0472

Epoch 8/50

 - 4s - loss: 0.0571 - val_loss: 0.0492

Epoch 9/50

 - 4s - loss: 0.0576 - val_loss: 0.0490

Epoch 10/50

 - 4s - loss: 0.0625 - val_loss: 0.0518

Epoch 11/50

 - 4s - loss: 0.0538 - val_loss: 0.0513

Epoch 12/50

 - 4s - loss: 0.0603 - val_loss: 0.0506

Epoch 13/50

 - 4s - loss: 0.0483 - val_loss: 0.0508

Epoch 14/50

 - 4s - loss: 0.0499 - val_loss: 0.0504

Epoch 15/50

 - 4s - loss: 0.0521 - val_loss: 0.0519

Epoch 16/50

 - 4s - loss: 0.0491 - val_loss: 0.0497

Epoch 17/50

 - 4s - loss: 0.0517 - val_loss: 0.0469

Epoch 18/50

 - 4s - loss: 0.0463 - val_loss: 0.0500

Epoch 19/50

 - 4s - loss: 0.0582 - val_loss: 0.0484

Epoch 20/50

 - 4s - loss: 0.0483 - val_loss: 0.0490

Epoch 21/50

 - 4s - loss: 0.0482 - val_loss: 0.0492

Epoch 22/50

 - 4s - loss: 0.0477 - val_loss: 0.0483

Epoch 23/50

 - 4s - loss: 0.0470 - val_loss: 0.0478

Epoch 24/50

 - 4s - loss: 0.0464 - val_loss: 0.0477

Epoch 25/50

 - 4s - loss: 0.0458 - val_loss: 0.0511

Epoch 26/50

 - 4s - loss: 0.0498 - val_loss: 0.0454

Epoch 27/50

 - 4s - loss: 0.0436 - val_loss: 0.0478

Epoch 28/50

 - 4s - loss: 0.0456 - val_loss: 0.0474

Epoch 29/50

 - 4s - loss: 0.0416 - val_loss: 0.0517

Epoch 30/50

 - 4s - loss: 0.0519 - val_loss: 0.0498

Epoch 31/50

 - 4s - loss: 0.0449 - val_loss: 0.0517

Epoch 32/50

 - 4s - loss: 0.0474 - val_loss: 0.0551

Epoch 33/50

 - 4s - loss: 0.0402 - val_loss: 0.0503

Epoch 34/50

 - 4s - loss: 0.0379 - val_loss: 0.0517

Epoch 35/50

 - 4s - loss: 0.0452 - val_loss: 0.0491

Epoch 36/50

 - 4s - loss: 0.0449 - val_loss: 0.0496

length of memory (state 0, action 0): 1018, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 548, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 535, after forget

time = 13862	action = 1	current_phase = 1	next_phase = 0	reward = -2.017126	array([[-3.3595314, -3.019253 ]], dtype=float32)

time = 13870	action = 0	current_phase = 0	next_phase = 1	reward = -0.372886	array([[-1.4972801, -1.7432297]], dtype=float32)

time = 13875	action = 0	current_phase = 0	next_phase = 1	reward = -0.215371	array([[-1.5885141, -1.9111899]], dtype=float32)

time = 13880	action = 0	current_phase = 0	next_phase = 1	reward = 0.361220	array([[-1.929584 , -2.0043213]], dtype=float32)

time = 13885	action = 1	current_phase = 0	next_phase = 1	reward = -1.258076	array([[-3.291304 , -2.9558327]], dtype=float32)

time = 13893	action = 0	current_phase = 1	next_phase = 0	reward = -0.598421	array([[-1.9817092, -2.3254292]], dtype=float32)

time = 13898	action = 0	current_phase = 1	next_phase = 0	reward = -0.457840	array([[-1.8560537, -2.3350854]], dtype=float32)

time = 13903	action = 0	current_phase = 1	next_phase = 0	reward = -0.304017	array([[-1.8591099, -2.3372698]], dtype=float32)

time = 13908	action = 0	current_phase = 1	next_phase = 0	reward = -0.172742	array([[-2.0423062, -2.2132356]], dtype=float32)

time = 13913	action = 0	current_phase = 1	next_phase = 0	reward = 0.223404	array([[-2.569408 , -3.3158736]], dtype=float32)

time = 13918	action = 1	current_phase = 1	next_phase = 0	reward = -1.894924	array([[-4.4548073, -3.0328767]], dtype=float32)

time = 13926	action = 0	current_phase = 0	next_phase = 1	reward = -0.500631	array([[-1.6688461, -1.7507187]], dtype=float32)

time = 13931	action = 0	current_phase = 0	next_phase = 1	reward = -0.353367	array([[-1.8078097, -2.0304937]], dtype=float32)

time = 13936	action = 0	current_phase = 0	next_phase = 1	reward = -0.203346	array([[-2.0008461, -2.0059795]], dtype=float32)

time = 13941	action = 0	current_phase = 0	next_phase = 1	reward = 0.288568	array([[-2.1807587, -2.6023405]], dtype=float32)

time = 13946	action = 1	current_phase = 0	next_phase = 1	reward = -1.610757	array([[-3.073394 , -3.0628517]], dtype=float32)

time = 13954	action = 0	current_phase = 1	next_phase = 0	reward = -0.555106	array([[-1.8448746, -2.3388798]], dtype=float32)

time = 13959	action = 0	current_phase = 1	next_phase = 0	reward = -0.400345	array([[-1.6380706, -2.4774907]], dtype=float32)

time = 13964	action = 0	current_phase = 1	next_phase = 0	reward = -0.250536	array([[-1.6466758, -2.45223  ]], dtype=float32)

time = 13969	action = 0	current_phase = 1	next_phase = 0	reward = -0.186692	array([[-1.6924525, -2.7552273]], dtype=float32)

time = 13974	action = 1	current_phase = 1	next_phase = 0	reward = -0.554301	array([[-2.6092813, -2.0649545]], dtype=float32)

time = 13982	action = 0	current_phase = 0	next_phase = 1	reward = -0.620123	array([[-1.9118633, -1.940552 ]], dtype=float32)

time = 13987	action = 0	current_phase = 0	next_phase = 1	reward = -0.460307	array([[-1.5988165, -1.9665678]], dtype=float32)

time = 13992	action = 1	current_phase = 0	next_phase = 1	reward = -1.399979	array([[-1.7364674, -1.4722055]], dtype=float32)

time = 14000	action = 0	current_phase = 1	next_phase = 0	reward = 0.357589	array([[-1.042217 , -2.7993565]], dtype=float32)

time = 14005	action = 0	current_phase = 1	next_phase = 0	reward = -0.843791	array([[-2.6907196, -2.8861701]], dtype=float32)

time = 14010	action = 1	current_phase = 1	next_phase = 0	reward = -2.115292	array([[-3.6573455, -3.0704641]], dtype=float32)

time = 14018	action = 0	current_phase = 0	next_phase = 1	reward = -0.436800	array([[-1.4758831, -1.7500429]], dtype=float32)

time = 14023	action = 1	current_phase = 0	next_phase = 1	reward = -1.394449	array([[-1.7969167, -1.5148591]], dtype=float32)

time = 14031	action = 0	current_phase = 1	next_phase = 0	reward = 0.328363	array([[-1.400503 , -2.8219078]], dtype=float32)

time = 14036	action = 1	current_phase = 1	next_phase = 0	reward = -1.502028	array([[-3.139983 , -2.3782885]], dtype=float32)

time = 14044	action = 0	current_phase = 0	next_phase = 1	reward = -0.565670	array([[-1.5350634, -1.841304 ]], dtype=float32)

time = 14049	action = 0	current_phase = 0	next_phase = 1	reward = -0.416168	array([[-1.6051152, -1.9607991]], dtype=float32)

time = 14054	action = 1	current_phase = 0	next_phase = 1	reward = -1.356097	array([[-1.707275 , -1.5700132]], dtype=float32)

time = 14062	action = 0	current_phase = 1	next_phase = 0	reward = 0.275977	array([[-1.209723 , -3.2817163]], dtype=float32)

time = 14067	action = 0	current_phase = 1	next_phase = 0	reward = -1.315258	array([[-1.1178231, -3.071884 ]], dtype=float32)

time = 14072	action = 1	current_phase = 1	next_phase = 0	reward = -2.019201	array([[-3.320716 , -2.9895961]], dtype=float32)

time = 14080	action = 0	current_phase = 0	next_phase = 1	reward = -0.392052	array([[-1.4984045, -1.7313645]], dtype=float32)

time = 14085	action = 0	current_phase = 0	next_phase = 1	reward = -0.234199	array([[-1.3982602, -1.9779248]], dtype=float32)

time = 14090	action = 0	current_phase = 0	next_phase = 1	reward = 0.067598	array([[-1.1424054, -2.3411   ]], dtype=float32)

time = 14095	action = 1	current_phase = 0	next_phase = 1	reward = -1.028937	array([[-2.8755276, -2.559145 ]], dtype=float32)

time = 14103	action = 0	current_phase = 1	next_phase = 0	reward = -0.582450	array([[-1.941313 , -2.3468108]], dtype=float32)

time = 14108	action = 0	current_phase = 1	next_phase = 0	reward = -0.423930	array([[-1.8630174, -2.3451197]], dtype=float32)

time = 14113	action = 0	current_phase = 1	next_phase = 0	reward = -0.259394	array([[-1.8195285, -2.317974 ]], dtype=float32)

time = 14118	action = 0	current_phase = 1	next_phase = 0	reward = -0.160577	array([[-2.0126147, -2.2340775]], dtype=float32)

time = 14123	action = 0	current_phase = 1	next_phase = 0	reward = 0.001365	array([[-2.1395621, -2.9498334]], dtype=float32)

time = 14128	action = 1	current_phase = 1	next_phase = 0	reward = -1.892039	array([[-4.616865 , -3.2375433]], dtype=float32)

time = 14136	action = 0	current_phase = 0	next_phase = 1	reward = -0.492163	array([[-1.7366493, -1.8925129]], dtype=float32)

time = 14141	action = 0	current_phase = 0	next_phase = 1	reward = -0.332460	array([[-1.7726218, -2.1581986]], dtype=float32)

time = 14146	action = 0	current_phase = 0	next_phase = 1	reward = -0.186031	array([[-2.0235124, -2.0366392]], dtype=float32)

time = 14151	action = 0	current_phase = 0	next_phase = 1	reward = 0.277750	array([[-2.245592 , -2.3630257]], dtype=float32)

time = 14156	action = 1	current_phase = 0	next_phase = 1	reward = -1.612793	array([[-3.0704036, -3.0029418]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0680 - val_loss: 0.0258

Epoch 2/50

 - 4s - loss: 0.0612 - val_loss: 0.0269

Epoch 3/50

 - 4s - loss: 0.0641 - val_loss: 0.0263

Epoch 4/50

 - 4s - loss: 0.0578 - val_loss: 0.0274

Epoch 5/50

 - 4s - loss: 0.0594 - val_loss: 0.0257

Epoch 6/50

 - 4s - loss: 0.0610 - val_loss: 0.0267

Epoch 7/50

 - 4s - loss: 0.0553 - val_loss: 0.0280

Epoch 8/50

 - 4s - loss: 0.0522 - val_loss: 0.0293

Epoch 9/50

 - 4s - loss: 0.0426 - val_loss: 0.0285

Epoch 10/50

 - 4s - loss: 0.0531 - val_loss: 0.0285

Epoch 11/50

 - 4s - loss: 0.0485 - val_loss: 0.0292

Epoch 12/50

 - 4s - loss: 0.0466 - val_loss: 0.0283

Epoch 13/50

 - 4s - loss: 0.0459 - val_loss: 0.0293

Epoch 14/50

 - 4s - loss: 0.0518 - val_loss: 0.0306

Epoch 15/50

 - 4s - loss: 0.0516 - val_loss: 0.0309

length of memory (state 0, action 0): 1019, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 555, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 542, after forget

time = 14164	action = 0	current_phase = 1	next_phase = 0	reward = -0.556187	array([[-1.8379298, -2.367324 ]], dtype=float32)

time = 14169	action = 0	current_phase = 1	next_phase = 0	reward = -0.403745	array([[-1.659127 , -2.4651542]], dtype=float32)

time = 14174	action = 0	current_phase = 1	next_phase = 0	reward = -0.243687	array([[-1.6826503, -2.3897347]], dtype=float32)

time = 14179	action = 0	current_phase = 1	next_phase = 0	reward = -0.172419	array([[-1.7786889, -2.3851414]], dtype=float32)

time = 14184	action = 1	current_phase = 1	next_phase = 0	reward = -0.470855	array([[-2.799441 , -1.9434355]], dtype=float32)

time = 14192	action = 0	current_phase = 0	next_phase = 1	reward = -0.627358	array([[-2.1083834, -2.1449406]], dtype=float32)

time = 14197	action = 0	current_phase = 0	next_phase = 1	reward = -0.467051	array([[-1.6212585, -1.9624964]], dtype=float32)

time = 14202	action = 1	current_phase = 0	next_phase = 1	reward = -1.427733	array([[-1.7466671, -1.5240332]], dtype=float32)

time = 14210	action = 0	current_phase = 1	next_phase = 0	reward = 0.364612	array([[-1.0973269, -2.7892058]], dtype=float32)

time = 14215	action = 0	current_phase = 1	next_phase = 0	reward = -0.733071	array([[-2.5540478, -2.6704428]], dtype=float32)

time = 14220	action = 1	current_phase = 1	next_phase = 0	reward = -2.119965	array([[-3.7892613, -3.242134 ]], dtype=float32)

time = 14228	action = 0	current_phase = 0	next_phase = 1	reward = -0.447053	array([[-1.5480216, -1.7257328]], dtype=float32)

time = 14233	action = 1	current_phase = 0	next_phase = 1	reward = -1.402160	array([[-1.8401765, -1.4750161]], dtype=float32)

time = 14241	action = 0	current_phase = 1	next_phase = 0	reward = 0.323898	array([[-1.0749156, -3.4256256]], dtype=float32)

time = 14246	action = 0	current_phase = 1	next_phase = 0	reward = -1.007889	array([[-2.06459 , -3.100228]], dtype=float32)

time = 14251	action = 0	current_phase = 1	next_phase = 0	reward = -1.706226	array([[-1.0091622, -3.2512245]], dtype=float32)

time = 14256	action = 1	current_phase = 1	next_phase = 0	reward = -1.801892	array([[-3.7996526, -2.7904437]], dtype=float32)

time = 14264	action = 0	current_phase = 0	next_phase = 1	reward = -0.246573	array([[-1.3902553, -1.6832402]], dtype=float32)

time = 14269	action = 0	current_phase = 0	next_phase = 1	reward = -0.174933	array([[-1.6104791, -2.5660818]], dtype=float32)

time = 14274	action = 1	current_phase = 0	next_phase = 1	reward = -0.541665	array([[-2.2439294, -1.8657392]], dtype=float32)

time = 14282	action = 0	current_phase = 1	next_phase = 0	reward = -0.609300	array([[-1.9275459, -2.363285 ]], dtype=float32)

time = 14287	action = 0	current_phase = 1	next_phase = 0	reward = -0.462868	array([[-0.571588, -2.427661]], dtype=float32)

time = 14292	action = 0	current_phase = 1	next_phase = 0	reward = -0.317902	array([[-1.8500016, -2.358347 ]], dtype=float32)

time = 14297	action = 0	current_phase = 1	next_phase = 0	reward = -0.178813	array([[-1.8969591, -2.336554 ]], dtype=float32)

time = 14302	action = 0	current_phase = 1	next_phase = 0	reward = 0.191172	array([[-2.384745 , -3.3263814]], dtype=float32)

time = 14307	action = 1	current_phase = 1	next_phase = 0	reward = -1.727948	array([[-4.4590473, -3.2179196]], dtype=float32)

time = 14315	action = 0	current_phase = 0	next_phase = 1	reward = -0.526660	array([[-1.8252314, -1.8358434]], dtype=float32)

time = 14320	action = 0	current_phase = 0	next_phase = 1	reward = -0.370862	array([[-1.459591 , -1.9074513]], dtype=float32)

time = 14325	action = 1	current_phase = 0	next_phase = 1	reward = -1.313412	array([[-1.8425266, -1.7682827]], dtype=float32)

time = 14333	action = 0	current_phase = 1	next_phase = 0	reward = 0.074431	array([[-0.3589711, -2.6634648]], dtype=float32)

time = 14338	action = 1	current_phase = 1	next_phase = 0	reward = -1.895916	array([[-3.1680646, -2.9814634]], dtype=float32)

time = 14346	action = 0	current_phase = 0	next_phase = 1	reward = -0.496771	array([[-1.7242992, -1.7720213]], dtype=float32)

time = 14351	action = 0	current_phase = 0	next_phase = 1	reward = -0.345365	array([[-1.8050901, -1.8643748]], dtype=float32)

time = 14356	action = 1	current_phase = 0	next_phase = 1	reward = -1.018581	array([[-2.0470407, -2.0268548]], dtype=float32)

time = 14364	action = 0	current_phase = 1	next_phase = 0	reward = -0.290461	array([[-1.0320413, -1.5932041]], dtype=float32)

time = 14369	action = 0	current_phase = 1	next_phase = 0	reward = -1.597220	array([[-0.30392185, -3.282852  ]], dtype=float32)

time = 14374	action = 1	current_phase = 1	next_phase = 0	reward = -1.917408	array([[-3.3561175, -2.9226184]], dtype=float32)

time = 14382	action = 0	current_phase = 0	next_phase = 1	reward = -0.317028	array([[-1.493524 , -1.6184739]], dtype=float32)

time = 14387	action = 0	current_phase = 0	next_phase = 1	reward = -0.178699	array([[-1.5849458, -2.2461112]], dtype=float32)

time = 14392	action = 0	current_phase = 0	next_phase = 1	reward = 0.181520	array([[-2.1337445, -2.7645218]], dtype=float32)

time = 14397	action = 1	current_phase = 0	next_phase = 1	reward = -1.786481	array([[-3.4652197, -3.3131778]], dtype=float32)

time = 14405	action = 0	current_phase = 1	next_phase = 0	reward = -0.535611	array([[-1.7670038, -2.2180414]], dtype=float32)

time = 14410	action = 0	current_phase = 1	next_phase = 0	reward = -0.389368	array([[-1.6317234, -2.4782717]], dtype=float32)

time = 14415	action = 0	current_phase = 1	next_phase = 0	reward = -0.238759	array([[-1.6147928, -2.5101714]], dtype=float32)

time = 14420	action = 0	current_phase = 1	next_phase = 0	reward = 0.378067	array([[-1.6251353, -2.706418 ]], dtype=float32)

time = 14425	action = 1	current_phase = 1	next_phase = 0	reward = -1.243494	array([[-3.7380579, -2.766274 ]], dtype=float32)

time = 14433	action = 0	current_phase = 0	next_phase = 1	reward = -0.581316	array([[-1.8706981, -1.9290187]], dtype=float32)

time = 14438	action = 0	current_phase = 0	next_phase = 1	reward = -0.426329	array([[-1.6125146, -1.9652714]], dtype=float32)

time = 14443	action = 1	current_phase = 0	next_phase = 1	reward = -1.377105	array([[-1.8939869, -1.4170027]], dtype=float32)

time = 14451	action = 0	current_phase = 1	next_phase = 0	reward = 0.303281	array([[-0.00652078, -2.9803104 ]], dtype=float32)

time = 14456	action = 0	current_phase = 1	next_phase = 0	reward = -1.116708	array([[-0.3403443, -3.2482352]], dtype=float32)

time = 14461	action = 1	current_phase = 1	next_phase = 0	reward = -2.065538	array([[-4.2004743, -3.11428  ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0562 - val_loss: 0.0321

Epoch 2/50

 - 4s - loss: 0.0538 - val_loss: 0.0323

Epoch 3/50

 - 4s - loss: 0.0567 - val_loss: 0.0313

Epoch 4/50

 - 4s - loss: 0.0591 - val_loss: 0.0348

Epoch 5/50

 - 4s - loss: 0.0510 - val_loss: 0.0324

Epoch 6/50

 - 4s - loss: 0.0649 - val_loss: 0.0329

Epoch 7/50

 - 4s - loss: 0.0466 - val_loss: 0.0323

Epoch 8/50

 - 4s - loss: 0.0430 - val_loss: 0.0336

Epoch 9/50

 - 4s - loss: 0.0454 - val_loss: 0.0341

Epoch 10/50

 - 4s - loss: 0.0418 - val_loss: 0.0345

Epoch 11/50

 - 4s - loss: 0.0465 - val_loss: 0.0325

Epoch 12/50

 - 4s - loss: 0.0399 - val_loss: 0.0316

Epoch 13/50

 - 4s - loss: 0.0347 - val_loss: 0.0339

length of memory (state 0, action 0): 1014, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 562, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 550, after forget

time = 14469	action = 0	current_phase = 0	next_phase = 1	reward = -0.396186	array([[-1.569328 , -1.7128536]], dtype=float32)

time = 14474	action = 0	current_phase = 0	next_phase = 1	reward = -0.231375	array([[-1.4059911, -1.7736766]], dtype=float32)

time = 14479	action = 0	current_phase = 0	next_phase = 1	reward = -0.189683	array([[-1.585012 , -2.2392352]], dtype=float32)

time = 14484	action = 1	current_phase = 0	next_phase = 1	reward = -0.597653	array([[-2.2969217, -2.2310889]], dtype=float32)

time = 14492	action = 0	current_phase = 1	next_phase = 0	reward = -0.634384	array([[-2.2115912, -2.226466 ]], dtype=float32)

time = 14497	action = 0	current_phase = 1	next_phase = 0	reward = -0.484136	array([[-1.7417599, -2.4310913]], dtype=float32)

time = 14502	action = 0	current_phase = 1	next_phase = 0	reward = -0.332234	array([[-1.9112606, -2.3369813]], dtype=float32)

time = 14507	action = 0	current_phase = 1	next_phase = 0	reward = -0.188163	array([[-1.8705812, -2.3694448]], dtype=float32)

time = 14512	action = 0	current_phase = 1	next_phase = 0	reward = 0.242649	array([[-2.3881743, -2.9795198]], dtype=float32)

time = 14517	action = 1	current_phase = 1	next_phase = 0	reward = -1.782834	array([[-4.450059 , -3.1301186]], dtype=float32)

time = 14525	action = 1	current_phase = 0	next_phase = 1	reward = -1.787258	array([[-1.8392345, -1.8254149]], dtype=float32)

time = 14533	action = 0	current_phase = 1	next_phase = 0	reward = -0.293201	array([[-0.7298045, -2.409762 ]], dtype=float32)

time = 14538	action = 0	current_phase = 1	next_phase = 0	reward = -0.165499	array([[-0.6746119, -2.7347534]], dtype=float32)

time = 14543	action = 0	current_phase = 1	next_phase = 0	reward = 0.205397	array([[-0.9648957, -3.131993 ]], dtype=float32)

time = 14548	action = 1	current_phase = 1	next_phase = 0	reward = -1.898352	array([[-3.1154041, -2.9898822]], dtype=float32)

time = 14556	action = 1	current_phase = 0	next_phase = 1	reward = -1.723725	array([[-1.7380984, -1.731155 ]], dtype=float32)

time = 14564	action = 0	current_phase = 1	next_phase = 0	reward = -0.247906	array([[-1.2695436, -2.4800665]], dtype=float32)

time = 14569	action = 0	current_phase = 1	next_phase = 0	reward = -0.174372	array([[-0.768379 , -2.7698298]], dtype=float32)

time = 14574	action = 0	current_phase = 1	next_phase = 0	reward = -0.081215	array([[-1.1486514, -1.9194877]], dtype=float32)

time = 14579	action = 0	current_phase = 1	next_phase = 0	reward = -1.596307	array([[-2.6015508, -3.2456121]], dtype=float32)

time = 14584	action = 1	current_phase = 1	next_phase = 0	reward = -1.894401	array([[-3.949531 , -2.9241776]], dtype=float32)

time = 14592	action = 0	current_phase = 0	next_phase = 1	reward = -0.307635	array([[-1.5413551, -1.5987784]], dtype=float32)

time = 14597	action = 0	current_phase = 0	next_phase = 1	reward = -0.172668	array([[-1.3293939, -2.6953032]], dtype=float32)

time = 14602	action = 1	current_phase = 0	next_phase = 1	reward = -1.459440	array([[-2.525523 , -2.4169302]], dtype=float32)

time = 14610	action = 0	current_phase = 1	next_phase = 0	reward = -1.731548	array([[-2.3162334, -3.104576 ]], dtype=float32)

time = 14615	action = 0	current_phase = 1	next_phase = 0	reward = -1.618970	array([[-1.1005707, -2.9016764]], dtype=float32)

time = 14620	action = 1	current_phase = 1	next_phase = 0	reward = -1.606403	array([[-4.0109744, -2.9005003]], dtype=float32)

time = 14628	action = 0	current_phase = 0	next_phase = 1	reward = -0.168691	array([[-2.2300239, -2.3044288]], dtype=float32)

time = 14633	action = 0	current_phase = 0	next_phase = 1	reward = 0.008278	array([[-2.1456041, -2.3100307]], dtype=float32)

time = 14638	action = 1	current_phase = 0	next_phase = 1	reward = -1.892633	array([[-4.1130753, -3.3369799]], dtype=float32)

time = 14646	action = 0	current_phase = 1	next_phase = 0	reward = -0.497218	array([[-1.8257204, -2.2299056]], dtype=float32)

time = 14651	action = 0	current_phase = 1	next_phase = 0	reward = -0.348678	array([[-1.6592884, -2.4755564]], dtype=float32)

time = 14656	action = 0	current_phase = 1	next_phase = 0	reward = -0.202664	array([[-1.7612224, -2.4707258]], dtype=float32)

time = 14661	action = 0	current_phase = 1	next_phase = 0	reward = 0.328200	array([[-2.10594 , -3.159552]], dtype=float32)

time = 14666	action = 1	current_phase = 1	next_phase = 0	reward = -1.506012	array([[-4.690746 , -3.0221832]], dtype=float32)

time = 14674	action = 0	current_phase = 0	next_phase = 1	reward = -0.554547	array([[-1.8455569, -1.8587068]], dtype=float32)

time = 14679	action = 0	current_phase = 0	next_phase = 1	reward = -0.395413	array([[-1.724657 , -1.9191564]], dtype=float32)

time = 14684	action = 1	current_phase = 0	next_phase = 1	reward = -1.340781	array([[-1.9013784, -1.6179143]], dtype=float32)

time = 14692	action = 0	current_phase = 1	next_phase = 0	reward = 0.204994	array([[-1.1363323, -3.0363083]], dtype=float32)

time = 14697	action = 0	current_phase = 1	next_phase = 0	reward = -1.266848	array([[-0.12648712, -3.2896283 ]], dtype=float32)

time = 14702	action = 1	current_phase = 1	next_phase = 0	reward = -2.019318	array([[-3.8610122, -3.0066643]], dtype=float32)

time = 14710	action = 0	current_phase = 0	next_phase = 1	reward = -0.371570	array([[-1.6363466, -1.6515502]], dtype=float32)

time = 14715	action = 0	current_phase = 0	next_phase = 1	reward = -0.216015	array([[-1.7209253, -1.8339562]], dtype=float32)

time = 14720	action = 1	current_phase = 0	next_phase = 1	reward = -1.122462	array([[-2.0737133, -2.0072563]], dtype=float32)

time = 14728	action = 0	current_phase = 1	next_phase = 0	reward = -1.466745	array([[-2.894574 , -2.9465103]], dtype=float32)

time = 14733	action = 0	current_phase = 1	next_phase = 0	reward = -1.672412	array([[ 0.78565943, -3.182031  ]], dtype=float32)

time = 14738	action = 1	current_phase = 1	next_phase = 0	reward = -1.703673	array([[-4.1321106, -2.9238136]], dtype=float32)

time = 14746	action = 0	current_phase = 0	next_phase = 1	reward = -0.200011	array([[-1.8338664, -1.899016 ]], dtype=float32)

time = 14751	action = 0	current_phase = 0	next_phase = 1	reward = 0.300439	array([[-1.9925137, -2.5414171]], dtype=float32)

time = 14756	action = 1	current_phase = 0	next_phase = 1	reward = -1.506376	array([[-3.4456508, -3.2175446]], dtype=float32)

time = 14764	action = 0	current_phase = 1	next_phase = 0	reward = -0.561179	array([[-1.750272 , -2.4669833]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0505 - val_loss: 0.0271

Epoch 2/50

 - 4s - loss: 0.0455 - val_loss: 0.0278

Epoch 3/50

 - 4s - loss: 0.0447 - val_loss: 0.0291

Epoch 4/50

 - 4s - loss: 0.0418 - val_loss: 0.0283

Epoch 5/50

 - 4s - loss: 0.0448 - val_loss: 0.0291

Epoch 6/50

 - 4s - loss: 0.0409 - val_loss: 0.0323

Epoch 7/50

 - 4s - loss: 0.0441 - val_loss: 0.0302

Epoch 8/50

 - 4s - loss: 0.0330 - val_loss: 0.0315

Epoch 9/50

 - 4s - loss: 0.0380 - val_loss: 0.0314

Epoch 10/50

 - 4s - loss: 0.0421 - val_loss: 0.0316

Epoch 11/50

 - 4s - loss: 0.0333 - val_loss: 0.0339

length of memory (state 0, action 0): 1013, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 570, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 557, after forget

time = 14769	action = 0	current_phase = 1	next_phase = 0	reward = -0.404105	array([[-1.6583067, -2.4818923]], dtype=float32)

time = 14774	action = 0	current_phase = 1	next_phase = 0	reward = -0.245250	array([[-1.7496666, -2.4183662]], dtype=float32)

time = 14779	action = 0	current_phase = 1	next_phase = 0	reward = -0.169490	array([[-1.7785177, -2.7417564]], dtype=float32)

time = 14784	action = 1	current_phase = 1	next_phase = 0	reward = -0.486982	array([[-2.692758 , -2.0208123]], dtype=float32)

time = 14792	action = 0	current_phase = 0	next_phase = 1	reward = -0.614881	array([[-1.8360412, -1.9481838]], dtype=float32)

time = 14797	action = 0	current_phase = 0	next_phase = 1	reward = -0.455207	array([[-1.6361032, -1.9938576]], dtype=float32)

time = 14802	action = 1	current_phase = 0	next_phase = 1	reward = -1.404032	array([[-1.9612824, -1.4940078]], dtype=float32)

time = 14810	action = 0	current_phase = 1	next_phase = 0	reward = 0.337304	array([[-1.4165772, -2.6903431]], dtype=float32)

time = 14815	action = 1	current_phase = 1	next_phase = 0	reward = -1.267334	array([[-3.210402 , -3.0230367]], dtype=float32)

time = 14823	action = 0	current_phase = 0	next_phase = 1	reward = -0.583403	array([[-1.781794 , -1.9380014]], dtype=float32)

time = 14828	action = 0	current_phase = 0	next_phase = 1	reward = -0.433054	array([[-1.5939527, -1.9950445]], dtype=float32)

time = 14833	action = 1	current_phase = 0	next_phase = 1	reward = -1.388039	array([[-1.9477788, -1.5027273]], dtype=float32)

time = 14841	action = 0	current_phase = 1	next_phase = 0	reward = 0.308342	array([[-1.9371626, -2.982655 ]], dtype=float32)

time = 14846	action = 1	current_phase = 1	next_phase = 0	reward = -1.556489	array([[-3.0882933, -3.0031505]], dtype=float32)

time = 14854	action = 0	current_phase = 0	next_phase = 1	reward = -0.552423	array([[-1.7706767, -1.9256352]], dtype=float32)

time = 14859	action = 0	current_phase = 0	next_phase = 1	reward = -0.399365	array([[-1.5662601, -1.9933677]], dtype=float32)

time = 14864	action = 1	current_phase = 0	next_phase = 1	reward = -1.340551	array([[-1.8413509, -1.6579636]], dtype=float32)

time = 14872	action = 0	current_phase = 1	next_phase = 0	reward = 0.182660	array([[-1.0980197, -2.971204 ]], dtype=float32)

time = 14877	action = 0	current_phase = 1	next_phase = 0	reward = -1.319467	array([[-2.2461483, -3.1015792]], dtype=float32)

time = 14882	action = 1	current_phase = 1	next_phase = 0	reward = -2.010609	array([[-3.9836438, -3.06748  ]], dtype=float32)

time = 14890	action = 0	current_phase = 0	next_phase = 1	reward = -0.354886	array([[-1.545987 , -1.7182757]], dtype=float32)

time = 14895	action = 0	current_phase = 0	next_phase = 1	reward = -0.208686	array([[-1.8316568, -1.90712  ]], dtype=float32)

time = 14900	action = 0	current_phase = 0	next_phase = 1	reward = 0.357163	array([[-1.8607745, -2.0201666]], dtype=float32)

time = 14905	action = 1	current_phase = 0	next_phase = 1	reward = -1.361078	array([[-3.2025008, -2.9177928]], dtype=float32)

time = 14913	action = 0	current_phase = 1	next_phase = 0	reward = -0.593520	array([[-2.0632493, -2.260556 ]], dtype=float32)

time = 14918	action = 0	current_phase = 1	next_phase = 0	reward = -0.440275	array([[-1.8909394, -2.3472683]], dtype=float32)

time = 14923	action = 0	current_phase = 1	next_phase = 0	reward = -0.284907	array([[-1.919531 , -2.2837138]], dtype=float32)

time = 14928	action = 0	current_phase = 1	next_phase = 0	reward = -0.164608	array([[-2.040876 , -2.1916282]], dtype=float32)

time = 14933	action = 0	current_phase = 1	next_phase = 0	reward = 0.079208	array([[-2.345197 , -2.7840059]], dtype=float32)

time = 14938	action = 1	current_phase = 1	next_phase = 0	reward = -1.897199	array([[-4.6250887, -3.2562904]], dtype=float32)

time = 14946	action = 0	current_phase = 0	next_phase = 1	reward = -0.502617	array([[-1.7166674, -1.7585596]], dtype=float32)

time = 14951	action = 0	current_phase = 0	next_phase = 1	reward = -0.332241	array([[-1.6953435, -1.8908837]], dtype=float32)

time = 14956	action = 1	current_phase = 0	next_phase = 1	reward = -1.305561	array([[-1.9674312, -1.9500179]], dtype=float32)

time = 14964	action = 0	current_phase = 1	next_phase = 0	reward = -0.087628	array([[-1.2137074, -1.6921635]], dtype=float32)

time = 14969	action = 0	current_phase = 1	next_phase = 0	reward = -1.598322	array([[-0.10703647, -3.2784817 ]], dtype=float32)

time = 14974	action = 1	current_phase = 1	next_phase = 0	reward = -1.902109	array([[-3.9149876, -2.9839268]], dtype=float32)

time = 14982	action = 0	current_phase = 0	next_phase = 1	reward = -0.301468	array([[-1.6101146, -1.694989 ]], dtype=float32)

time = 14987	action = 0	current_phase = 0	next_phase = 1	reward = -0.173342	array([[-1.7750634, -2.2155883]], dtype=float32)

time = 14992	action = 0	current_phase = 0	next_phase = 1	reward = 0.191766	array([[-1.2752253, -2.7305672]], dtype=float32)

time = 14997	action = 1	current_phase = 0	next_phase = 1	reward = -1.777021	array([[-3.9617574, -3.2871368]], dtype=float32)

time = 15005	action = 0	current_phase = 1	next_phase = 0	reward = -0.514508	array([[-1.8632098, -2.2024217]], dtype=float32)

time = 15010	action = 0	current_phase = 1	next_phase = 0	reward = -0.373567	array([[-1.7099783, -2.449228 ]], dtype=float32)

time = 15015	action = 0	current_phase = 1	next_phase = 0	reward = -0.222076	array([[-1.6632447, -2.4770274]], dtype=float32)

time = 15020	action = 0	current_phase = 1	next_phase = 0	reward = 0.350691	array([[-2.0034072, -2.9068837]], dtype=float32)

time = 15025	action = 1	current_phase = 1	next_phase = 0	reward = -1.261833	array([[-3.7118797, -2.8109524]], dtype=float32)

time = 15033	action = 0	current_phase = 0	next_phase = 1	reward = -0.583446	array([[-1.8315665, -1.9192739]], dtype=float32)

time = 15038	action = 0	current_phase = 0	next_phase = 1	reward = -0.416897	array([[-1.6460636, -1.9821794]], dtype=float32)

time = 15043	action = 1	current_phase = 0	next_phase = 1	reward = -1.346999	array([[-1.8923851, -1.5426842]], dtype=float32)

time = 15051	action = 0	current_phase = 1	next_phase = 0	reward = 0.268710	array([[-1.5526075, -3.009791 ]], dtype=float32)

time = 15056	action = 1	current_phase = 1	next_phase = 0	reward = -1.660674	array([[-2.9300869, -2.859172 ]], dtype=float32)

time = 15064	action = 0	current_phase = 0	next_phase = 1	reward = -0.551545	array([[-1.8501974, -2.0014157]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0766 - val_loss: 0.0383

Epoch 2/50

 - 4s - loss: 0.0700 - val_loss: 0.0403

Epoch 3/50

 - 4s - loss: 0.0500 - val_loss: 0.0378

Epoch 4/50

 - 4s - loss: 0.0620 - val_loss: 0.0372

Epoch 5/50

 - 4s - loss: 0.0594 - val_loss: 0.0375

Epoch 6/50

 - 4s - loss: 0.0541 - val_loss: 0.0380

Epoch 7/50

 - 4s - loss: 0.0511 - val_loss: 0.0383

Epoch 8/50

 - 4s - loss: 0.0505 - val_loss: 0.0409

Epoch 9/50

 - 4s - loss: 0.0631 - val_loss: 0.0394

Epoch 10/50

 - 4s - loss: 0.0515 - val_loss: 0.0400

Epoch 11/50

 - 4s - loss: 0.0563 - val_loss: 0.0400

Epoch 12/50

 - 4s - loss: 0.0491 - val_loss: 0.0414

Epoch 13/50

 - 4s - loss: 0.0463 - val_loss: 0.0394

Epoch 14/50

 - 4s - loss: 0.0507 - val_loss: 0.0404

length of memory (state 0, action 0): 1017, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 577, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 565, after forget

time = 15069	action = 0	current_phase = 0	next_phase = 1	reward = -0.397084	array([[-1.5564378, -1.9931936]], dtype=float32)

time = 15074	action = 1	current_phase = 0	next_phase = 1	reward = -1.324642	array([[-1.732348 , -1.5531278]], dtype=float32)

time = 15082	action = 0	current_phase = 1	next_phase = 0	reward = 0.182542	array([[-1.8275511, -3.0948346]], dtype=float32)

time = 15087	action = 0	current_phase = 1	next_phase = 0	reward = -1.321200	array([[-1.6278752, -3.0553174]], dtype=float32)

time = 15092	action = 1	current_phase = 1	next_phase = 0	reward = -2.026147	array([[-4.1557717, -2.9467533]], dtype=float32)

time = 15100	action = 0	current_phase = 0	next_phase = 1	reward = -0.382092	array([[-1.526205 , -1.7371151]], dtype=float32)

time = 15105	action = 0	current_phase = 0	next_phase = 1	reward = -0.219322	array([[-1.8922337, -2.0946326]], dtype=float32)

time = 15110	action = 0	current_phase = 0	next_phase = 1	reward = 0.371098	array([[-1.7548105, -2.3561854]], dtype=float32)

time = 15115	action = 1	current_phase = 0	next_phase = 1	reward = -1.302931	array([[-3.4792438, -2.9906127]], dtype=float32)

time = 15123	action = 0	current_phase = 1	next_phase = 0	reward = -0.584924	array([[-1.9515243, -2.2915142]], dtype=float32)

time = 15128	action = 0	current_phase = 1	next_phase = 0	reward = -0.430156	array([[-1.908456 , -2.3263946]], dtype=float32)

time = 15133	action = 0	current_phase = 1	next_phase = 0	reward = -0.279115	array([[-1.8843628, -2.2728364]], dtype=float32)

time = 15138	action = 0	current_phase = 1	next_phase = 0	reward = -0.164262	array([[-2.053694 , -2.1921227]], dtype=float32)

time = 15143	action = 0	current_phase = 1	next_phase = 0	reward = 0.025934	array([[-2.5195088, -2.9271567]], dtype=float32)

time = 15148	action = 1	current_phase = 1	next_phase = 0	reward = -1.901671	array([[-4.6484456, -3.3011804]], dtype=float32)

time = 15156	action = 0	current_phase = 0	next_phase = 1	reward = -0.498284	array([[-1.7121621, -1.859971 ]], dtype=float32)

time = 15161	action = 0	current_phase = 0	next_phase = 1	reward = -0.342561	array([[-1.7342868, -1.9022214]], dtype=float32)

time = 15166	action = 1	current_phase = 0	next_phase = 1	reward = -1.311282	array([[-1.9092016, -1.839257 ]], dtype=float32)

time = 15174	action = 1	current_phase = 1	next_phase = 0	reward = -0.522100	array([[-2.5327253, -1.7042464]], dtype=float32)

time = 15182	action = 0	current_phase = 0	next_phase = 1	reward = -0.610306	array([[-2.333518 , -2.5542624]], dtype=float32)

time = 15187	action = 0	current_phase = 0	next_phase = 1	reward = -0.459563	array([[-1.5772703, -2.0065293]], dtype=float32)

time = 15192	action = 1	current_phase = 0	next_phase = 1	reward = -1.425022	array([[-1.8093655, -1.5936038]], dtype=float32)

time = 15200	action = 0	current_phase = 1	next_phase = 0	reward = 0.361180	array([[-0.7161956, -2.6323843]], dtype=float32)

time = 15205	action = 1	current_phase = 1	next_phase = 0	reward = -1.365579	array([[-3.4811409, -2.9549177]], dtype=float32)

time = 15213	action = 0	current_phase = 0	next_phase = 1	reward = -0.590646	array([[-1.7390312, -1.9357345]], dtype=float32)

time = 15218	action = 0	current_phase = 0	next_phase = 1	reward = -0.430124	array([[-1.5703319, -2.0064764]], dtype=float32)

time = 15223	action = 1	current_phase = 0	next_phase = 1	reward = -1.374680	array([[-1.8856698, -1.5540326]], dtype=float32)

time = 15231	action = 0	current_phase = 1	next_phase = 0	reward = 0.305768	array([[-1.756863 , -3.0667424]], dtype=float32)

time = 15236	action = 1	current_phase = 1	next_phase = 0	reward = -1.450627	array([[-3.2484684, -3.065623 ]], dtype=float32)

time = 15244	action = 0	current_phase = 0	next_phase = 1	reward = -0.554214	array([[-1.74593  , -1.9175231]], dtype=float32)

time = 15249	action = 0	current_phase = 0	next_phase = 1	reward = -0.394298	array([[-1.6053604, -1.9945219]], dtype=float32)

time = 15254	action = 1	current_phase = 0	next_phase = 1	reward = -1.332551	array([[-1.7654859, -1.6038473]], dtype=float32)

time = 15262	action = 0	current_phase = 1	next_phase = 0	reward = 0.173602	array([[-1.6944678, -2.9538026]], dtype=float32)

time = 15267	action = 1	current_phase = 1	next_phase = 0	reward = -1.786308	array([[-3.1851938, -2.904777 ]], dtype=float32)

time = 15275	action = 0	current_phase = 0	next_phase = 1	reward = -0.530017	array([[-1.7622943, -1.9253554]], dtype=float32)

time = 15280	action = 0	current_phase = 0	next_phase = 1	reward = -0.370171	array([[-1.6532636, -1.9311023]], dtype=float32)

time = 15285	action = 1	current_phase = 0	next_phase = 1	reward = -1.308212	array([[-1.8286812, -1.7464383]], dtype=float32)

time = 15293	action = 0	current_phase = 1	next_phase = 0	reward = 0.022100	array([[-1.8579926, -2.8293757]], dtype=float32)

time = 15298	action = 1	current_phase = 1	next_phase = 0	reward = -1.897931	array([[-3.8188107, -3.0052571]], dtype=float32)

time = 15306	action = 0	current_phase = 0	next_phase = 1	reward = -0.489883	array([[-1.9095777, -2.051836 ]], dtype=float32)

time = 15311	action = 0	current_phase = 0	next_phase = 1	reward = -0.338462	array([[-1.8251238, -1.8937745]], dtype=float32)

time = 15316	action = 1	current_phase = 0	next_phase = 1	reward = -1.307494	array([[-1.8162823, -1.6798904]], dtype=float32)

time = 15324	action = 1	current_phase = 1	next_phase = 0	reward = -0.477695	array([[-2.1367204, -1.9956449]], dtype=float32)

time = 15332	action = 0	current_phase = 0	next_phase = 1	reward = -0.613187	array([[-1.6612395, -2.049574 ]], dtype=float32)

time = 15337	action = 0	current_phase = 0	next_phase = 1	reward = -0.454482	array([[-1.6949294, -2.063151 ]], dtype=float32)

time = 15342	action = 1	current_phase = 0	next_phase = 1	reward = -1.407136	array([[-1.7630653, -1.6351037]], dtype=float32)

time = 15350	action = 0	current_phase = 1	next_phase = 0	reward = 0.357682	array([[-1.145936 , -2.6743784]], dtype=float32)

time = 15355	action = 0	current_phase = 1	next_phase = 0	reward = -0.841207	array([[-1.239059 , -3.0552542]], dtype=float32)

time = 15360	action = 1	current_phase = 1	next_phase = 0	reward = -2.120915	array([[-4.4628468, -3.1500566]], dtype=float32)

time = 15368	action = 0	current_phase = 0	next_phase = 1	reward = -0.443870	array([[-1.46087 , -1.775939]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0765 - val_loss: 0.0580

Epoch 2/50

 - 4s - loss: 0.0711 - val_loss: 0.0549

Epoch 3/50

 - 4s - loss: 0.0660 - val_loss: 0.0551

Epoch 4/50

 - 4s - loss: 0.0614 - val_loss: 0.0539

Epoch 5/50

 - 4s - loss: 0.0622 - val_loss: 0.0554

Epoch 6/50

 - 4s - loss: 0.0704 - val_loss: 0.0571

Epoch 7/50

 - 4s - loss: 0.0596 - val_loss: 0.0565

Epoch 8/50

 - 4s - loss: 0.0517 - val_loss: 0.0581

Epoch 9/50

 - 4s - loss: 0.0578 - val_loss: 0.0577

Epoch 10/50

 - 4s - loss: 0.0564 - val_loss: 0.0579

Epoch 11/50

 - 4s - loss: 0.0589 - val_loss: 0.0594

Epoch 12/50

 - 4s - loss: 0.0568 - val_loss: 0.0596

Epoch 13/50

 - 4s - loss: 0.0551 - val_loss: 0.0603

Epoch 14/50

 - 4s - loss: 0.0471 - val_loss: 0.0598

length of memory (state 0, action 0): 1019, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 586, after forget

length of memory (state 1, action 0): 1013, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 574, after forget

time = 15373	action = 0	current_phase = 0	next_phase = 1	reward = -0.297475	array([[-1.776146 , -2.0947504]], dtype=float32)

time = 15378	action = 0	current_phase = 0	next_phase = 1	reward = -0.172710	array([[-2.0937285, -2.358767 ]], dtype=float32)

time = 15383	action = 0	current_phase = 0	next_phase = 1	reward = 0.085554	array([[-2.9593444, -3.180361 ]], dtype=float32)

time = 15388	action = 1	current_phase = 0	next_phase = 1	reward = -1.903755	array([[-3.9022522, -3.3176732]], dtype=float32)

time = 15396	action = 0	current_phase = 1	next_phase = 0	reward = -0.506171	array([[-1.8647287, -2.2692263]], dtype=float32)

time = 15401	action = 0	current_phase = 1	next_phase = 0	reward = -0.358883	array([[-1.6026638, -2.506512 ]], dtype=float32)

time = 15406	action = 0	current_phase = 1	next_phase = 0	reward = -0.211709	array([[-1.7201319, -2.4988537]], dtype=float32)

time = 15411	action = 0	current_phase = 1	next_phase = 0	reward = 0.331901	array([[-1.9960582, -3.1159847]], dtype=float32)

time = 15416	action = 1	current_phase = 1	next_phase = 0	reward = -1.500055	array([[-4.7335253, -3.0610762]], dtype=float32)

time = 15424	action = 0	current_phase = 0	next_phase = 1	reward = -0.553486	array([[-1.877164 , -1.9647276]], dtype=float32)

time = 15429	action = 0	current_phase = 0	next_phase = 1	reward = -0.408748	array([[-1.7198027, -2.0849907]], dtype=float32)

time = 15434	action = 1	current_phase = 0	next_phase = 1	reward = -1.347609	array([[-1.9056772, -1.8820043]], dtype=float32)

time = 15442	action = 0	current_phase = 1	next_phase = 0	reward = 0.184205	array([[-1.7169144, -2.942695 ]], dtype=float32)

time = 15447	action = 0	current_phase = 1	next_phase = 0	reward = -1.319639	array([[-2.4641798, -3.1315057]], dtype=float32)

time = 15452	action = 1	current_phase = 1	next_phase = 0	reward = -2.008779	array([[-4.3926244, -3.1562927]], dtype=float32)

time = 15460	action = 0	current_phase = 0	next_phase = 1	reward = -0.375970	array([[-1.6919155, -1.757101 ]], dtype=float32)

time = 15465	action = 0	current_phase = 0	next_phase = 1	reward = -0.223988	array([[-1.8525465, -2.504872 ]], dtype=float32)

time = 15470	action = 0	current_phase = 0	next_phase = 1	reward = 0.050665	array([[-2.048688 , -2.3349535]], dtype=float32)

time = 15475	action = 1	current_phase = 0	next_phase = 1	reward = -1.035981	array([[-3.1157475, -3.0839531]], dtype=float32)

time = 15483	action = 1	current_phase = 1	next_phase = 0	reward = -1.860085	array([[-2.3224404, -2.137679 ]], dtype=float32)

time = 15491	action = 1	current_phase = 0	next_phase = 1	reward = -1.477427	array([[-2.8550339, -2.581385 ]], dtype=float32)

time = 15499	action = 0	current_phase = 1	next_phase = 0	reward = -0.178459	array([[-1.8647921, -2.807265 ]], dtype=float32)

time = 15504	action = 1	current_phase = 1	next_phase = 0	reward = -0.476940	array([[-2.2109392, -1.9025614]], dtype=float32)

time = 15512	action = 0	current_phase = 0	next_phase = 1	reward = -0.624397	array([[-1.8606671, -1.9858693]], dtype=float32)

time = 15517	action = 0	current_phase = 0	next_phase = 1	reward = -0.473267	array([[-1.7159685, -2.0866418]], dtype=float32)

time = 15522	action = 0	current_phase = 0	next_phase = 1	reward = -0.320371	array([[-1.8865967, -1.9774988]], dtype=float32)

time = 15527	action = 0	current_phase = 0	next_phase = 1	reward = -0.183485	array([[-2.0292091, -2.0974386]], dtype=float32)

time = 15532	action = 0	current_phase = 0	next_phase = 1	reward = 0.197787	array([[-2.0311646, -3.5139225]], dtype=float32)

time = 15537	action = 1	current_phase = 0	next_phase = 1	reward = -1.787362	array([[-4.54906  , -3.3666835]], dtype=float32)

time = 15545	action = 0	current_phase = 1	next_phase = 0	reward = -0.533723	array([[-1.8166292, -2.2577708]], dtype=float32)

time = 15550	action = 0	current_phase = 1	next_phase = 0	reward = -0.378076	array([[-1.7252469, -2.4808147]], dtype=float32)

time = 15555	action = 0	current_phase = 1	next_phase = 0	reward = -0.225102	array([[-1.6065247, -2.5117705]], dtype=float32)

time = 15560	action = 0	current_phase = 1	next_phase = 0	reward = 0.375085	array([[-1.780782, -2.671779]], dtype=float32)

time = 15565	action = 1	current_phase = 1	next_phase = 0	reward = -1.299881	array([[-3.5584388, -2.6014931]], dtype=float32)

time = 15573	action = 0	current_phase = 0	next_phase = 1	reward = -0.593532	array([[-1.8799187, -1.9721897]], dtype=float32)

time = 15578	action = 0	current_phase = 0	next_phase = 1	reward = -0.433418	array([[-1.7046614, -2.0961723]], dtype=float32)

time = 15583	action = 0	current_phase = 0	next_phase = 1	reward = -0.280932	array([[-1.8725104, -1.996164 ]], dtype=float32)

time = 15588	action = 0	current_phase = 0	next_phase = 1	reward = -0.164445	array([[-2.1366968, -2.3582532]], dtype=float32)

time = 15593	action = 0	current_phase = 0	next_phase = 1	reward = 0.003470	array([[-2.3236914, -2.6256976]], dtype=float32)

time = 15598	action = 1	current_phase = 0	next_phase = 1	reward = -1.899733	array([[-4.583158 , -3.4214113]], dtype=float32)

time = 15606	action = 0	current_phase = 1	next_phase = 0	reward = -0.494978	array([[-1.8525355, -2.2618346]], dtype=float32)

time = 15611	action = 0	current_phase = 1	next_phase = 0	reward = -0.344698	array([[-1.7567034, -2.436091 ]], dtype=float32)

time = 15616	action = 0	current_phase = 1	next_phase = 0	reward = -0.195498	array([[-1.940819 , -2.3731189]], dtype=float32)

time = 15621	action = 0	current_phase = 1	next_phase = 0	reward = 0.296845	array([[-2.0220313, -3.250325 ]], dtype=float32)

time = 15626	action = 1	current_phase = 1	next_phase = 0	reward = -1.612358	array([[-4.797997 , -3.0924032]], dtype=float32)

time = 15634	action = 0	current_phase = 0	next_phase = 1	reward = -0.559687	array([[-1.8814054, -1.9632859]], dtype=float32)

time = 15639	action = 0	current_phase = 0	next_phase = 1	reward = -0.400344	array([[-1.7230679, -2.0783277]], dtype=float32)

time = 15644	action = 0	current_phase = 0	next_phase = 1	reward = -0.236409	array([[-2.017672 , -2.3802402]], dtype=float32)

time = 15649	action = 0	current_phase = 0	next_phase = 1	reward = -0.172910	array([[-2.144651 , -2.6196852]], dtype=float32)

time = 15654	action = 0	current_phase = 0	next_phase = 1	reward = -0.139156	array([[-2.3463326, -2.3729587]], dtype=float32)

time = 15659	action = 1	current_phase = 0	next_phase = 1	reward = -2.005110	array([[-4.405965, -3.512989]], dtype=float32)

time = 15667	action = 0	current_phase = 1	next_phase = 0	reward = -0.456094	array([[-1.872464 , -2.2776306]], dtype=float32)

time = 15672	action = 0	current_phase = 1	next_phase = 0	reward = -0.308269	array([[-1.91184  , -2.3270264]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0502 - val_loss: 0.0517

Epoch 2/50

 - 4s - loss: 0.0493 - val_loss: 0.0499

Epoch 3/50

 - 4s - loss: 0.0428 - val_loss: 0.0548

Epoch 4/50

 - 4s - loss: 0.0489 - val_loss: 0.0559

Epoch 5/50

 - 4s - loss: 0.0425 - val_loss: 0.0539

Epoch 6/50

 - 4s - loss: 0.0412 - val_loss: 0.0527

Epoch 7/50

 - 4s - loss: 0.0416 - val_loss: 0.0513

Epoch 8/50

 - 4s - loss: 0.0408 - val_loss: 0.0521

Epoch 9/50

 - 4s - loss: 0.0420 - val_loss: 0.0539

Epoch 10/50

 - 4s - loss: 0.0402 - val_loss: 0.0536

Epoch 11/50

 - 4s - loss: 0.0419 - val_loss: 0.0574

Epoch 12/50

 - 4s - loss: 0.0369 - val_loss: 0.0574

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 593, after forget

length of memory (state 1, action 0): 1017, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 580, after forget

time = 15677	action = 0	current_phase = 1	next_phase = 0	reward = -0.171627	array([[-1.9392259, -2.4014997]], dtype=float32)

time = 15682	action = 0	current_phase = 1	next_phase = 0	reward = 0.249802	array([[-2.1315353, -3.243286 ]], dtype=float32)

time = 15687	action = 1	current_phase = 1	next_phase = 0	reward = -1.779183	array([[-4.7780647, -3.0701818]], dtype=float32)

time = 15695	action = 0	current_phase = 0	next_phase = 1	reward = -0.527345	array([[-1.8260614, -2.0466237]], dtype=float32)

time = 15700	action = 0	current_phase = 0	next_phase = 1	reward = -0.372679	array([[-1.772492 , -2.0591643]], dtype=float32)

time = 15705	action = 0	current_phase = 0	next_phase = 1	reward = -0.222328	array([[-1.8210527, -1.9766893]], dtype=float32)

time = 15710	action = 0	current_phase = 0	next_phase = 1	reward = 0.370918	array([[-1.7489874, -2.705005 ]], dtype=float32)

time = 15715	action = 1	current_phase = 0	next_phase = 1	reward = -1.255422	array([[-3.0082827, -2.9123626]], dtype=float32)

time = 15723	action = 0	current_phase = 1	next_phase = 0	reward = -0.597131	array([[-1.9795351, -2.3772967]], dtype=float32)

time = 15728	action = 0	current_phase = 1	next_phase = 0	reward = -0.445290	array([[-1.9944687, -2.3385878]], dtype=float32)

time = 15733	action = 0	current_phase = 1	next_phase = 0	reward = -0.282804	array([[-1.8516176, -2.3405988]], dtype=float32)

time = 15738	action = 0	current_phase = 1	next_phase = 0	reward = -0.159790	array([[-2.1492958, -2.1976347]], dtype=float32)

time = 15743	action = 0	current_phase = 1	next_phase = 0	reward = 0.071764	array([[-2.2614298, -2.7616487]], dtype=float32)

time = 15748	action = 1	current_phase = 1	next_phase = 0	reward = -1.894846	array([[-4.720648 , -3.2935147]], dtype=float32)

time = 15756	action = 0	current_phase = 0	next_phase = 1	reward = -0.486510	array([[-1.734193 , -1.9021268]], dtype=float32)

time = 15761	action = 0	current_phase = 0	next_phase = 1	reward = -0.328046	array([[-1.7853527, -2.017898 ]], dtype=float32)

time = 15766	action = 0	current_phase = 0	next_phase = 1	reward = -0.191690	array([[-1.9211712, -2.1391869]], dtype=float32)

time = 15771	action = 0	current_phase = 0	next_phase = 1	reward = 0.240318	array([[-2.0829852, -2.7849205]], dtype=float32)

time = 15776	action = 1	current_phase = 0	next_phase = 1	reward = -1.606602	array([[-3.440638 , -3.2639008]], dtype=float32)

time = 15784	action = 0	current_phase = 1	next_phase = 0	reward = -0.555019	array([[-1.9347763, -2.3877368]], dtype=float32)

time = 15789	action = 0	current_phase = 1	next_phase = 0	reward = -0.402523	array([[-1.7169414, -2.5112665]], dtype=float32)

time = 15794	action = 0	current_phase = 1	next_phase = 0	reward = -0.249763	array([[-1.733127 , -2.5078003]], dtype=float32)

time = 15799	action = 0	current_phase = 1	next_phase = 0	reward = -0.171850	array([[-1.789199, -2.832887]], dtype=float32)

time = 15804	action = 1	current_phase = 1	next_phase = 0	reward = -0.473754	array([[-2.4067762, -1.8929129]], dtype=float32)

time = 15812	action = 0	current_phase = 0	next_phase = 1	reward = -0.625084	array([[-1.8488214, -2.0459244]], dtype=float32)

time = 15817	action = 0	current_phase = 0	next_phase = 1	reward = -0.481443	array([[-1.6752849, -2.1730917]], dtype=float32)

time = 15822	action = 0	current_phase = 0	next_phase = 1	reward = -0.327602	array([[-1.8737799, -2.1283495]], dtype=float32)

time = 15827	action = 0	current_phase = 0	next_phase = 1	reward = -0.185075	array([[-1.9122654, -2.186329 ]], dtype=float32)

time = 15832	action = 0	current_phase = 0	next_phase = 1	reward = 0.184738	array([[-2.402509, -3.075175]], dtype=float32)

time = 15837	action = 1	current_phase = 0	next_phase = 1	reward = -1.784069	array([[-4.4670777, -3.2412653]], dtype=float32)

time = 15845	action = 0	current_phase = 1	next_phase = 0	reward = -0.526793	array([[-1.7835326, -2.3162067]], dtype=float32)

time = 15850	action = 0	current_phase = 1	next_phase = 0	reward = -0.374960	array([[-1.7091503, -2.5071974]], dtype=float32)

time = 15855	action = 0	current_phase = 1	next_phase = 0	reward = -0.216473	array([[-1.6028184, -2.506403 ]], dtype=float32)

time = 15860	action = 0	current_phase = 1	next_phase = 0	reward = 0.063732	array([[-1.7951945, -2.6648116]], dtype=float32)

time = 15865	action = 1	current_phase = 1	next_phase = 0	reward = -1.133179	array([[-3.5523028, -2.6020238]], dtype=float32)

time = 15873	action = 0	current_phase = 0	next_phase = 1	reward = -0.579200	array([[-1.8065108, -2.0231688]], dtype=float32)

time = 15878	action = 0	current_phase = 0	next_phase = 1	reward = -0.422490	array([[-1.6795784, -2.160109 ]], dtype=float32)

time = 15883	action = 0	current_phase = 0	next_phase = 1	reward = -0.282229	array([[-1.8431886, -2.1788208]], dtype=float32)

time = 15888	action = 0	current_phase = 0	next_phase = 1	reward = -0.162955	array([[-2.1413548, -2.5272527]], dtype=float32)

time = 15893	action = 1	current_phase = 0	next_phase = 1	reward = -1.123839	array([[-2.7108989, -2.6697483]], dtype=float32)

time = 15901	action = 0	current_phase = 1	next_phase = 0	reward = -1.177874	array([[-2.568065 , -2.6972911]], dtype=float32)

time = 15906	action = 0	current_phase = 1	next_phase = 0	reward = -1.045751	array([[-2.3628497, -2.890624 ]], dtype=float32)

time = 15911	action = 0	current_phase = 1	next_phase = 0	reward = -0.916279	array([[-1.7126162, -2.5086277]], dtype=float32)

time = 15916	action = 0	current_phase = 1	next_phase = 0	reward = -0.792479	array([[-1.6793028, -2.4978478]], dtype=float32)

time = 15921	action = 0	current_phase = 1	next_phase = 0	reward = -0.320495	array([[-2.5832093, -3.0207186]], dtype=float32)

time = 15926	action = 1	current_phase = 1	next_phase = 0	reward = -1.586313	array([[-5.0041757, -3.1375544]], dtype=float32)

time = 15934	action = 0	current_phase = 0	next_phase = 1	reward = -0.550834	array([[-1.7883116, -1.9737029]], dtype=float32)

time = 15939	action = 0	current_phase = 0	next_phase = 1	reward = -0.390408	array([[-1.7692395, -2.0250762]], dtype=float32)

time = 15944	action = 0	current_phase = 0	next_phase = 1	reward = -0.229835	array([[-1.9141359, -2.1182406]], dtype=float32)

time = 15949	action = 0	current_phase = 0	next_phase = 1	reward = -0.189100	array([[-1.8223019, -2.5950255]], dtype=float32)

time = 15954	action = 0	current_phase = 0	next_phase = 1	reward = -0.205679	array([[-2.1884923, -2.2550018]], dtype=float32)

time = 15959	action = 1	current_phase = 0	next_phase = 1	reward = -2.010462	array([[-4.5663333, -3.3166819]], dtype=float32)

time = 15967	action = 0	current_phase = 1	next_phase = 0	reward = -0.459684	array([[-1.8372483, -2.2993984]], dtype=float32)

time = 15972	action = 0	current_phase = 1	next_phase = 0	reward = -0.304936	array([[-1.8574897, -2.412309 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0595 - val_loss: 0.0236

Epoch 2/50

 - 4s - loss: 0.0670 - val_loss: 0.0233

Epoch 3/50

 - 4s - loss: 0.0638 - val_loss: 0.0262

Epoch 4/50

 - 4s - loss: 0.0529 - val_loss: 0.0246

Epoch 5/50

 - 4s - loss: 0.0498 - val_loss: 0.0249

Epoch 6/50

 - 4s - loss: 0.0532 - val_loss: 0.0236

Epoch 7/50

 - 4s - loss: 0.0544 - val_loss: 0.0277

Epoch 8/50

 - 4s - loss: 0.0489 - val_loss: 0.0239

Epoch 9/50

 - 4s - loss: 0.0422 - val_loss: 0.0259

Epoch 10/50

 - 4s - loss: 0.0491 - val_loss: 0.0258

Epoch 11/50

 - 4s - loss: 0.0452 - val_loss: 0.0301

Epoch 12/50

 - 4s - loss: 0.0438 - val_loss: 0.0280

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 598, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 585, after forget

time = 15977	action = 0	current_phase = 1	next_phase = 0	reward = -0.171145	array([[-2.102491 , -2.3304071]], dtype=float32)

time = 15982	action = 0	current_phase = 1	next_phase = 0	reward = 0.162666	array([[-2.3640325, -3.1631536]], dtype=float32)

time = 15987	action = 1	current_phase = 1	next_phase = 0	reward = -1.785129	array([[-4.6175013, -3.2377274]], dtype=float32)

time = 15995	action = 0	current_phase = 0	next_phase = 1	reward = -0.522140	array([[-1.7902689, -2.0014973]], dtype=float32)

time = 16000	action = 0	current_phase = 0	next_phase = 1	reward = -0.360099	array([[-1.7705379, -2.0236044]], dtype=float32)

time = 16005	action = 0	current_phase = 0	next_phase = 1	reward = -0.219488	array([[-1.8641952, -2.2250338]], dtype=float32)

time = 16010	action = 0	current_phase = 0	next_phase = 1	reward = 0.348145	array([[-1.9475396, -2.3058271]], dtype=float32)

time = 16015	action = 0	current_phase = 0	next_phase = 1	reward = -0.900814	array([[-2.6317527, -2.8523865]], dtype=float32)

time = 16020	action = 1	current_phase = 0	next_phase = 1	reward = -2.109506	array([[-4.417921 , -3.3582098]], dtype=float32)

time = 16028	action = 0	current_phase = 1	next_phase = 0	reward = -0.432090	array([[-1.9109001, -2.3568265]], dtype=float32)

time = 16033	action = 0	current_phase = 1	next_phase = 0	reward = -0.279275	array([[-1.9657881, -2.4463139]], dtype=float32)

time = 16038	action = 0	current_phase = 1	next_phase = 0	reward = -0.159444	array([[-2.1663477, -2.2344916]], dtype=float32)

time = 16043	action = 0	current_phase = 1	next_phase = 0	reward = 0.010134	array([[-2.743253 , -3.3774464]], dtype=float32)

time = 16048	action = 1	current_phase = 1	next_phase = 0	reward = -1.898801	array([[-4.7449   , -3.2443662]], dtype=float32)

time = 16056	action = 0	current_phase = 0	next_phase = 1	reward = -0.486493	array([[-1.8020087, -2.0848265]], dtype=float32)

time = 16061	action = 0	current_phase = 0	next_phase = 1	reward = -0.330938	array([[-1.7747104, -2.0318975]], dtype=float32)

time = 16066	action = 0	current_phase = 0	next_phase = 1	reward = -0.191790	array([[-1.9181478, -2.2554913]], dtype=float32)

time = 16071	action = 0	current_phase = 0	next_phase = 1	reward = 0.278773	array([[-2.0969548, -2.4979825]], dtype=float32)

time = 16076	action = 0	current_phase = 0	next_phase = 1	reward = -1.063871	array([[-3.035667 , -3.0482688]], dtype=float32)

time = 16081	action = 1	current_phase = 0	next_phase = 1	reward = -2.060253	array([[-4.339313, -3.386408]], dtype=float32)

time = 16089	action = 0	current_phase = 1	next_phase = 0	reward = -0.408493	array([[-1.8646245, -2.3838873]], dtype=float32)

time = 16094	action = 0	current_phase = 1	next_phase = 0	reward = -0.263653	array([[-1.8244262, -2.5401156]], dtype=float32)

time = 16099	action = 0	current_phase = 1	next_phase = 0	reward = -0.174585	array([[-1.7932472, -2.5565493]], dtype=float32)

time = 16104	action = 1	current_phase = 1	next_phase = 0	reward = -0.488601	array([[-2.6287944, -2.061612 ]], dtype=float32)

time = 16112	action = 0	current_phase = 0	next_phase = 1	reward = -0.618488	array([[-1.781058 , -2.0606837]], dtype=float32)

time = 16117	action = 0	current_phase = 0	next_phase = 1	reward = -0.461977	array([[-1.7644082, -2.0266159]], dtype=float32)

time = 16122	action = 0	current_phase = 0	next_phase = 1	reward = -0.301939	array([[-1.8924413, -2.1872606]], dtype=float32)

time = 16127	action = 0	current_phase = 0	next_phase = 1	reward = -0.168523	array([[-1.9991158, -2.3687713]], dtype=float32)

time = 16132	action = 0	current_phase = 0	next_phase = 1	reward = 0.176237	array([[-2.3964412, -2.9867833]], dtype=float32)

time = 16137	action = 1	current_phase = 0	next_phase = 1	reward = -1.780587	array([[-4.4974494, -3.2677531]], dtype=float32)

time = 16145	action = 0	current_phase = 1	next_phase = 0	reward = -0.522306	array([[-1.9139681, -2.3396344]], dtype=float32)

time = 16150	action = 0	current_phase = 1	next_phase = 0	reward = -0.368624	array([[-1.704438, -2.5583  ]], dtype=float32)

time = 16155	action = 0	current_phase = 1	next_phase = 0	reward = -0.214944	array([[-1.7280118, -2.5572848]], dtype=float32)

time = 16160	action = 0	current_phase = 1	next_phase = 0	reward = 0.358793	array([[-1.7757869, -2.814926 ]], dtype=float32)

time = 16165	action = 1	current_phase = 1	next_phase = 0	reward = -1.309798	array([[-3.9252768, -2.722137 ]], dtype=float32)

time = 16173	action = 0	current_phase = 0	next_phase = 1	reward = -0.594831	array([[-1.8033828, -2.0232878]], dtype=float32)

time = 16178	action = 0	current_phase = 0	next_phase = 1	reward = -0.443570	array([[-1.7016039, -2.153983 ]], dtype=float32)

time = 16183	action = 0	current_phase = 0	next_phase = 1	reward = -0.291885	array([[-1.8404363, -2.2273843]], dtype=float32)

time = 16188	action = 0	current_phase = 0	next_phase = 1	reward = -0.169637	array([[-2.1673322, -2.4702642]], dtype=float32)

time = 16193	action = 0	current_phase = 0	next_phase = 1	reward = 0.094968	array([[-1.9906926, -2.3684778]], dtype=float32)

time = 16198	action = 1	current_phase = 0	next_phase = 1	reward = -1.896688	array([[-4.6750283, -3.2675135]], dtype=float32)

time = 16206	action = 0	current_phase = 1	next_phase = 0	reward = -0.495818	array([[-1.870681 , -2.2642772]], dtype=float32)

time = 16211	action = 0	current_phase = 1	next_phase = 0	reward = -0.346296	array([[-1.9313958, -2.4593   ]], dtype=float32)

time = 16216	action = 0	current_phase = 1	next_phase = 0	reward = -0.196400	array([[-1.7547092, -2.556244 ]], dtype=float32)

time = 16221	action = 0	current_phase = 1	next_phase = 0	reward = 0.315195	array([[-2.2180705, -3.2268422]], dtype=float32)

time = 16226	action = 1	current_phase = 1	next_phase = 0	reward = -1.558761	array([[-4.87869 , -3.099356]], dtype=float32)

time = 16234	action = 0	current_phase = 0	next_phase = 1	reward = -0.557216	array([[-1.7716249, -2.0103712]], dtype=float32)

time = 16239	action = 0	current_phase = 0	next_phase = 1	reward = -0.400181	array([[-1.7258887, -2.1074252]], dtype=float32)

time = 16244	action = 0	current_phase = 0	next_phase = 1	reward = -0.261531	array([[-1.8492403, -2.1220903]], dtype=float32)

time = 16249	action = 0	current_phase = 0	next_phase = 1	reward = -0.178093	array([[-2.0102816, -2.3898025]], dtype=float32)

time = 16254	action = 0	current_phase = 0	next_phase = 1	reward = -0.021440	array([[-2.1768758, -2.3232148]], dtype=float32)

time = 16259	action = 1	current_phase = 0	next_phase = 1	reward = -2.001415	array([[-4.5457506, -3.3186796]], dtype=float32)

time = 16267	action = 0	current_phase = 1	next_phase = 0	reward = -0.468804	array([[-1.9056413, -2.3772454]], dtype=float32)

time = 16272	action = 0	current_phase = 1	next_phase = 0	reward = -0.307012	array([[-1.972595 , -2.4396353]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0471 - val_loss: 0.0385

Epoch 2/50

 - 4s - loss: 0.0519 - val_loss: 0.0364

Epoch 3/50

 - 4s - loss: 0.0451 - val_loss: 0.0444

Epoch 4/50

 - 4s - loss: 0.0412 - val_loss: 0.0406

Epoch 5/50

 - 4s - loss: 0.0436 - val_loss: 0.0434

Epoch 6/50

 - 4s - loss: 0.0361 - val_loss: 0.0480

Epoch 7/50

 - 4s - loss: 0.0452 - val_loss: 0.0503

Epoch 8/50

 - 4s - loss: 0.0396 - val_loss: 0.0474

Epoch 9/50

 - 4s - loss: 0.0320 - val_loss: 0.0462

Epoch 10/50

 - 4s - loss: 0.0402 - val_loss: 0.0453

Epoch 11/50

 - 4s - loss: 0.0446 - val_loss: 0.0478

Epoch 12/50

 - 4s - loss: 0.0399 - val_loss: 0.0523

length of memory (state 0, action 0): 1025, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 603, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 590, after forget

time = 16277	action = 0	current_phase = 1	next_phase = 0	reward = -0.171244	array([[-2.1053271, -2.2783866]], dtype=float32)

time = 16282	action = 0	current_phase = 1	next_phase = 0	reward = 0.161877	array([[-2.3219264, -3.2896874]], dtype=float32)

time = 16287	action = 1	current_phase = 1	next_phase = 0	reward = -1.781535	array([[-4.8220987, -3.17975  ]], dtype=float32)

time = 16295	action = 0	current_phase = 0	next_phase = 1	reward = -0.516726	array([[-1.8501943, -2.0894265]], dtype=float32)

time = 16300	action = 0	current_phase = 0	next_phase = 1	reward = -0.365239	array([[-1.7960886, -2.0478747]], dtype=float32)

time = 16305	action = 0	current_phase = 0	next_phase = 1	reward = -0.223013	array([[-1.7917424, -2.196124 ]], dtype=float32)

time = 16310	action = 0	current_phase = 0	next_phase = 1	reward = 0.357724	array([[-1.8631879, -2.4932933]], dtype=float32)

time = 16315	action = 0	current_phase = 0	next_phase = 1	reward = -0.787156	array([[-2.829416, -2.936864]], dtype=float32)

time = 16320	action = 1	current_phase = 0	next_phase = 1	reward = -2.120414	array([[-4.5986986, -3.4226475]], dtype=float32)

time = 16328	action = 0	current_phase = 1	next_phase = 0	reward = -0.443245	array([[-1.8495142, -2.3613954]], dtype=float32)

time = 16333	action = 0	current_phase = 1	next_phase = 0	reward = -0.291411	array([[-1.9218619, -2.4879303]], dtype=float32)

time = 16338	action = 0	current_phase = 1	next_phase = 0	reward = -0.167669	array([[-2.020447 , -2.2379045]], dtype=float32)

time = 16343	action = 0	current_phase = 1	next_phase = 0	reward = 0.133789	array([[-2.5517468, -2.857285 ]], dtype=float32)

time = 16348	action = 1	current_phase = 1	next_phase = 0	reward = -1.890968	array([[-4.8456497, -3.1449614]], dtype=float32)

time = 16356	action = 0	current_phase = 0	next_phase = 1	reward = -0.497104	array([[-1.7978594, -2.0289636]], dtype=float32)

time = 16361	action = 0	current_phase = 0	next_phase = 1	reward = -0.335245	array([[-1.7660646, -2.1629078]], dtype=float32)

time = 16366	action = 0	current_phase = 0	next_phase = 1	reward = -0.185115	array([[-1.8926834, -2.3018694]], dtype=float32)

time = 16371	action = 0	current_phase = 0	next_phase = 1	reward = 0.305693	array([[-2.135895 , -2.9734578]], dtype=float32)

time = 16376	action = 0	current_phase = 0	next_phase = 1	reward = -1.115400	array([[-3.0485787, -3.1905024]], dtype=float32)

time = 16381	action = 1	current_phase = 0	next_phase = 1	reward = -2.055768	array([[-4.339227 , -3.4237795]], dtype=float32)

time = 16389	action = 0	current_phase = 1	next_phase = 0	reward = -0.395893	array([[-1.793776 , -2.3939242]], dtype=float32)

time = 16394	action = 0	current_phase = 1	next_phase = 0	reward = -0.229438	array([[-1.6651669, -2.6288798]], dtype=float32)

time = 16399	action = 0	current_phase = 1	next_phase = 0	reward = 0.112329	array([[-1.9190006, -2.4337714]], dtype=float32)

time = 16404	action = 1	current_phase = 1	next_phase = 0	reward = -0.809987	array([[-3.0089557, -2.2947218]], dtype=float32)

time = 16412	action = 0	current_phase = 0	next_phase = 1	reward = -0.618061	array([[-1.8557909, -2.118026 ]], dtype=float32)

time = 16417	action = 0	current_phase = 0	next_phase = 1	reward = -0.456856	array([[-1.7962871, -2.0434911]], dtype=float32)

time = 16422	action = 0	current_phase = 0	next_phase = 1	reward = -0.311212	array([[-1.7073267, -2.4131446]], dtype=float32)

time = 16427	action = 0	current_phase = 0	next_phase = 1	reward = -0.180117	array([[-1.9630659, -2.3872738]], dtype=float32)

time = 16432	action = 0	current_phase = 0	next_phase = 1	reward = 0.234441	array([[-2.5860915, -2.9955924]], dtype=float32)

time = 16437	action = 1	current_phase = 0	next_phase = 1	reward = -1.784073	array([[-3.996252 , -3.1433733]], dtype=float32)

time = 16445	action = 0	current_phase = 1	next_phase = 0	reward = -0.524550	array([[-1.8148806, -2.3714776]], dtype=float32)

time = 16450	action = 0	current_phase = 1	next_phase = 0	reward = -0.360822	array([[-1.6788464, -2.5898812]], dtype=float32)

time = 16455	action = 0	current_phase = 1	next_phase = 0	reward = -0.206612	array([[-1.6172976, -2.533663 ]], dtype=float32)

time = 16460	action = 0	current_phase = 1	next_phase = 0	reward = 0.354358	array([[-1.7675445, -2.9288113]], dtype=float32)

time = 16465	action = 1	current_phase = 1	next_phase = 0	reward = -1.365544	array([[-3.839773 , -2.6497967]], dtype=float32)

time = 16473	action = 0	current_phase = 0	next_phase = 1	reward = -0.588970	array([[-1.8285269, -2.049947 ]], dtype=float32)

time = 16478	action = 0	current_phase = 0	next_phase = 1	reward = -0.437931	array([[-1.7412117, -2.2330656]], dtype=float32)

time = 16483	action = 0	current_phase = 0	next_phase = 1	reward = -0.284841	array([[-1.8720981, -2.3062537]], dtype=float32)

time = 16488	action = 0	current_phase = 0	next_phase = 1	reward = -0.164597	array([[-1.9672006, -2.4031224]], dtype=float32)

time = 16493	action = 0	current_phase = 0	next_phase = 1	reward = 0.076627	array([[-2.5122268, -3.1401124]], dtype=float32)

time = 16498	action = 1	current_phase = 0	next_phase = 1	reward = -1.896658	array([[-4.5771685, -3.3766406]], dtype=float32)

time = 16506	action = 0	current_phase = 1	next_phase = 0	reward = -0.492863	array([[-1.8259907, -2.3794076]], dtype=float32)

time = 16511	action = 0	current_phase = 1	next_phase = 0	reward = -0.346793	array([[-1.8087163, -2.5662677]], dtype=float32)

time = 16516	action = 0	current_phase = 1	next_phase = 0	reward = -0.203137	array([[-1.9003818, -2.4885247]], dtype=float32)

time = 16521	action = 0	current_phase = 1	next_phase = 0	reward = 0.315368	array([[-2.0687885, -3.3901672]], dtype=float32)

time = 16526	action = 1	current_phase = 1	next_phase = 0	reward = -1.502833	array([[-4.767736, -3.132977]], dtype=float32)

time = 16534	action = 0	current_phase = 0	next_phase = 1	reward = -0.540012	array([[-1.7998738, -2.0408983]], dtype=float32)

time = 16539	action = 0	current_phase = 0	next_phase = 1	reward = -0.380628	array([[-1.7970567, -2.0447848]], dtype=float32)

time = 16544	action = 0	current_phase = 0	next_phase = 1	reward = -0.221225	array([[-1.9167687, -2.340242 ]], dtype=float32)

time = 16549	action = 0	current_phase = 0	next_phase = 1	reward = 0.087450	array([[-1.9387294, -2.6083844]], dtype=float32)

time = 16554	action = 1	current_phase = 0	next_phase = 1	reward = -0.836248	array([[-3.0819924, -2.8280108]], dtype=float32)

time = 16562	action = 0	current_phase = 1	next_phase = 0	reward = -0.625424	array([[-1.9405572, -2.4870431]], dtype=float32)

time = 16567	action = 0	current_phase = 1	next_phase = 0	reward = -0.464813	array([[-1.9195108, -2.496507 ]], dtype=float32)

time = 16572	action = 0	current_phase = 1	next_phase = 0	reward = -0.304157	array([[-1.9657803, -2.4200642]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0611 - val_loss: 0.0152

Epoch 2/50

 - 4s - loss: 0.0592 - val_loss: 0.0149

Epoch 3/50

 - 4s - loss: 0.0522 - val_loss: 0.0163

Epoch 4/50

 - 4s - loss: 0.0600 - val_loss: 0.0160

Epoch 5/50

 - 4s - loss: 0.0494 - val_loss: 0.0172

Epoch 6/50

 - 4s - loss: 0.0504 - val_loss: 0.0175

Epoch 7/50

 - 4s - loss: 0.0566 - val_loss: 0.0176

Epoch 8/50

 - 4s - loss: 0.0432 - val_loss: 0.0201

Epoch 9/50

 - 4s - loss: 0.0568 - val_loss: 0.0192

Epoch 10/50

 - 4s - loss: 0.0550 - val_loss: 0.0184

Epoch 11/50

 - 4s - loss: 0.0459 - val_loss: 0.0199

Epoch 12/50

 - 4s - loss: 0.0479 - val_loss: 0.0206

length of memory (state 0, action 0): 1024, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 608, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 595, after forget

time = 16577	action = 0	current_phase = 1	next_phase = 0	reward = -0.168131	array([[-2.1651225, -2.260148 ]], dtype=float32)

time = 16582	action = 0	current_phase = 1	next_phase = 0	reward = 0.238834	array([[-2.581654 , -3.2729256]], dtype=float32)

time = 16587	action = 1	current_phase = 1	next_phase = 0	reward = -1.782081	array([[-4.8182254, -3.1690502]], dtype=float32)

time = 16595	action = 0	current_phase = 0	next_phase = 1	reward = -0.520719	array([[-1.7816604, -2.065504 ]], dtype=float32)

time = 16600	action = 0	current_phase = 0	next_phase = 1	reward = -0.362273	array([[-1.7708292, -2.1183708]], dtype=float32)

time = 16605	action = 0	current_phase = 0	next_phase = 1	reward = -0.219260	array([[-1.7895919, -2.0889792]], dtype=float32)

time = 16610	action = 0	current_phase = 0	next_phase = 1	reward = 0.368139	array([[-1.905947 , -2.6732445]], dtype=float32)

time = 16615	action = 1	current_phase = 0	next_phase = 1	reward = -1.300199	array([[-3.0937705, -2.9235644]], dtype=float32)

time = 16623	action = 0	current_phase = 1	next_phase = 0	reward = -0.589448	array([[-2.0200243, -2.4326425]], dtype=float32)

time = 16628	action = 0	current_phase = 1	next_phase = 0	reward = -0.433045	array([[-1.8680757, -2.4710722]], dtype=float32)

time = 16633	action = 0	current_phase = 1	next_phase = 0	reward = -0.270882	array([[-1.9798971, -2.443626 ]], dtype=float32)

time = 16638	action = 0	current_phase = 1	next_phase = 0	reward = -0.162078	array([[-2.0876887, -2.2780237]], dtype=float32)

time = 16643	action = 0	current_phase = 1	next_phase = 0	reward = 0.005394	array([[-2.684322 , -3.0120792]], dtype=float32)

time = 16648	action = 1	current_phase = 1	next_phase = 0	reward = -1.906512	array([[-4.7614756, -3.2802713]], dtype=float32)

time = 16656	action = 0	current_phase = 0	next_phase = 1	reward = -0.497089	array([[-1.7949622, -2.0706775]], dtype=float32)

time = 16661	action = 0	current_phase = 0	next_phase = 1	reward = -0.339636	array([[-1.8329288, -2.088225 ]], dtype=float32)

time = 16666	action = 0	current_phase = 0	next_phase = 1	reward = -0.199203	array([[-1.8759676, -2.3075974]], dtype=float32)

time = 16671	action = 0	current_phase = 0	next_phase = 1	reward = 0.285644	array([[-2.137776 , -2.5385873]], dtype=float32)

time = 16676	action = 0	current_phase = 0	next_phase = 1	reward = -1.009958	array([[-2.9395142, -3.0846107]], dtype=float32)

time = 16681	action = 1	current_phase = 0	next_phase = 1	reward = -2.059559	array([[-4.3375673, -3.402025 ]], dtype=float32)

time = 16689	action = 0	current_phase = 1	next_phase = 0	reward = -0.402894	array([[-1.788763 , -2.4810314]], dtype=float32)

time = 16694	action = 0	current_phase = 1	next_phase = 0	reward = -0.244482	array([[-1.7636987, -2.592586 ]], dtype=float32)

time = 16699	action = 0	current_phase = 1	next_phase = 0	reward = -0.171239	array([[-1.8910631, -2.5938237]], dtype=float32)

time = 16704	action = 1	current_phase = 1	next_phase = 0	reward = -0.469939	array([[-2.3849368, -1.9472133]], dtype=float32)

time = 16712	action = 0	current_phase = 0	next_phase = 1	reward = -0.612549	array([[-1.8019927, -2.097678 ]], dtype=float32)

time = 16717	action = 0	current_phase = 0	next_phase = 1	reward = -0.441814	array([[-1.7790153, -2.0673912]], dtype=float32)

time = 16722	action = 0	current_phase = 0	next_phase = 1	reward = -0.283340	array([[-1.7999074, -2.246658 ]], dtype=float32)

time = 16727	action = 0	current_phase = 0	next_phase = 1	reward = -0.165130	array([[-1.9187529, -2.3118486]], dtype=float32)

time = 16732	action = 0	current_phase = 0	next_phase = 1	reward = 0.175098	array([[-2.4797673, -3.023703 ]], dtype=float32)

time = 16737	action = 1	current_phase = 0	next_phase = 1	reward = -1.785848	array([[-4.450355 , -3.2914708]], dtype=float32)

time = 16745	action = 0	current_phase = 1	next_phase = 0	reward = -0.525710	array([[-1.8849379, -2.3444989]], dtype=float32)

time = 16750	action = 0	current_phase = 1	next_phase = 0	reward = -0.376600	array([[-1.7093724, -2.554279 ]], dtype=float32)

time = 16755	action = 0	current_phase = 1	next_phase = 0	reward = -0.222850	array([[-1.6780248, -2.5555592]], dtype=float32)

time = 16760	action = 0	current_phase = 1	next_phase = 0	reward = 0.366843	array([[-1.6294632, -3.025199 ]], dtype=float32)

time = 16765	action = 1	current_phase = 1	next_phase = 0	reward = -1.411215	array([[-3.954299, -2.66748 ]], dtype=float32)

time = 16773	action = 0	current_phase = 0	next_phase = 1	reward = -0.585421	array([[-1.797982 , -2.0718677]], dtype=float32)

time = 16778	action = 0	current_phase = 0	next_phase = 1	reward = -0.435376	array([[-1.7185776, -2.2776332]], dtype=float32)

time = 16783	action = 0	current_phase = 0	next_phase = 1	reward = -0.287323	array([[-1.8049343, -2.3758926]], dtype=float32)

time = 16788	action = 0	current_phase = 0	next_phase = 1	reward = -0.163535	array([[-2.0591156, -2.5270746]], dtype=float32)

time = 16793	action = 0	current_phase = 0	next_phase = 1	reward = 0.071925	array([[-2.5054734, -3.2376533]], dtype=float32)

time = 16798	action = 1	current_phase = 0	next_phase = 1	reward = -1.894864	array([[-4.6502233, -3.3186734]], dtype=float32)

time = 16806	action = 0	current_phase = 1	next_phase = 0	reward = -0.490996	array([[-1.8860661, -2.3658264]], dtype=float32)

time = 16811	action = 0	current_phase = 1	next_phase = 0	reward = -0.336411	array([[-1.854356 , -2.5142338]], dtype=float32)

time = 16816	action = 0	current_phase = 1	next_phase = 0	reward = -0.193388	array([[-1.7450355, -2.5531287]], dtype=float32)

time = 16821	action = 0	current_phase = 1	next_phase = 0	reward = 0.330537	array([[-2.1271012, -3.3257644]], dtype=float32)

time = 16826	action = 1	current_phase = 1	next_phase = 0	reward = -1.557029	array([[-4.82005  , -3.0838199]], dtype=float32)

time = 16834	action = 0	current_phase = 0	next_phase = 1	reward = -0.555749	array([[-1.7811577, -2.068221 ]], dtype=float32)

time = 16839	action = 0	current_phase = 0	next_phase = 1	reward = -0.409420	array([[-1.779268 , -2.0695577]], dtype=float32)

time = 16844	action = 0	current_phase = 0	next_phase = 1	reward = -0.263585	array([[-1.8939773, -2.6757767]], dtype=float32)

time = 16849	action = 0	current_phase = 0	next_phase = 1	reward = -0.177098	array([[-1.9975187, -2.469603 ]], dtype=float32)

time = 16854	action = 1	current_phase = 0	next_phase = 1	reward = -0.540691	array([[-2.200265 , -2.1801786]], dtype=float32)

time = 16862	action = 0	current_phase = 1	next_phase = 0	reward = -0.620962	array([[-1.9899418, -2.4521632]], dtype=float32)

time = 16867	action = 0	current_phase = 1	next_phase = 0	reward = -0.468679	array([[-1.8279339, -2.5672312]], dtype=float32)

time = 16872	action = 0	current_phase = 1	next_phase = 0	reward = -0.316120	array([[-1.9788821, -2.4309635]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0698 - val_loss: 0.0413

Epoch 2/50

 - 6s - loss: 0.0503 - val_loss: 0.0407

Epoch 3/50

 - 4s - loss: 0.0457 - val_loss: 0.0430

Epoch 4/50

 - 4s - loss: 0.0499 - val_loss: 0.0385

Epoch 5/50

 - 4s - loss: 0.0403 - val_loss: 0.0390

Epoch 6/50

 - 5s - loss: 0.0406 - val_loss: 0.0482

Epoch 7/50

 - 4s - loss: 0.0486 - val_loss: 0.0453

Epoch 8/50

 - 4s - loss: 0.0540 - val_loss: 0.0433

Epoch 9/50

 - 4s - loss: 0.0531 - val_loss: 0.0474

Epoch 10/50

 - 4s - loss: 0.0446 - val_loss: 0.0452

Epoch 11/50

 - 4s - loss: 0.0407 - val_loss: 0.0481

Epoch 12/50

 - 4s - loss: 0.0385 - val_loss: 0.0413

Epoch 13/50

 - 4s - loss: 0.0388 - val_loss: 0.0434

Epoch 14/50

 - 4s - loss: 0.0417 - val_loss: 0.0453

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 613, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 600, after forget

time = 16877	action = 0	current_phase = 1	next_phase = 0	reward = -0.180906	array([[-1.9048367, -2.4888253]], dtype=float32)

time = 16882	action = 0	current_phase = 1	next_phase = 0	reward = 0.260101	array([[-2.3020709, -3.2169003]], dtype=float32)

time = 16887	action = 1	current_phase = 1	next_phase = 0	reward = -1.788699	array([[-4.9916596, -3.2231255]], dtype=float32)

time = 16895	action = 0	current_phase = 0	next_phase = 1	reward = -0.544399	array([[-1.8917174, -2.1189513]], dtype=float32)

time = 16900	action = 0	current_phase = 0	next_phase = 1	reward = -0.397811	array([[-1.8904121, -2.1402364]], dtype=float32)

time = 16905	action = 0	current_phase = 0	next_phase = 1	reward = -0.240642	array([[-1.9326279, -2.3711705]], dtype=float32)

time = 16910	action = 0	current_phase = 0	next_phase = 1	reward = -0.207501	array([[-1.7184947, -2.8427372]], dtype=float32)

time = 16915	action = 1	current_phase = 0	next_phase = 1	reward = -0.742023	array([[-2.2925692, -2.1130939]], dtype=float32)

time = 16923	action = 0	current_phase = 1	next_phase = 0	reward = -0.584698	array([[-2.0636184, -2.3958435]], dtype=float32)

time = 16928	action = 0	current_phase = 1	next_phase = 0	reward = -0.426536	array([[-2.0359445, -2.4053507]], dtype=float32)

time = 16933	action = 0	current_phase = 1	next_phase = 0	reward = -0.279368	array([[-2.0451605, -2.436545 ]], dtype=float32)

time = 16938	action = 0	current_phase = 1	next_phase = 0	reward = -0.160131	array([[-1.9667759, -2.5247965]], dtype=float32)

time = 16943	action = 0	current_phase = 1	next_phase = 0	reward = 0.025370	array([[-2.4031715, -3.1152186]], dtype=float32)

time = 16948	action = 1	current_phase = 1	next_phase = 0	reward = -1.898980	array([[-4.816579 , -3.3306136]], dtype=float32)

time = 16956	action = 0	current_phase = 0	next_phase = 1	reward = -0.483180	array([[-1.9071815, -2.1282454]], dtype=float32)

time = 16961	action = 0	current_phase = 0	next_phase = 1	reward = -0.325404	array([[-1.8442453, -2.2609324]], dtype=float32)

time = 16966	action = 0	current_phase = 0	next_phase = 1	reward = -0.189670	array([[-1.96054 , -2.358756]], dtype=float32)

time = 16971	action = 0	current_phase = 0	next_phase = 1	reward = 0.291597	array([[-1.9905739, -2.826372 ]], dtype=float32)

time = 16976	action = 1	current_phase = 0	next_phase = 1	reward = -1.557264	array([[-3.0993528, -3.091813 ]], dtype=float32)

time = 16984	action = 0	current_phase = 1	next_phase = 0	reward = -0.553047	array([[-2.0292401, -2.4763632]], dtype=float32)

time = 16989	action = 0	current_phase = 1	next_phase = 0	reward = -0.402730	array([[-1.7788095, -2.5891666]], dtype=float32)

time = 16994	action = 0	current_phase = 1	next_phase = 0	reward = -0.253160	array([[-1.6900234, -2.540842 ]], dtype=float32)

time = 16999	action = 0	current_phase = 1	next_phase = 0	reward = -0.176124	array([[-1.7548199, -2.388709 ]], dtype=float32)

time = 17004	action = 1	current_phase = 1	next_phase = 0	reward = -0.478069	array([[-2.585594 , -1.8372576]], dtype=float32)

time = 17012	action = 0	current_phase = 0	next_phase = 1	reward = -0.614632	array([[-1.9183899, -2.1304562]], dtype=float32)

time = 17017	action = 0	current_phase = 0	next_phase = 1	reward = -0.458532	array([[-1.863302 , -2.2232127]], dtype=float32)

time = 17022	action = 0	current_phase = 0	next_phase = 1	reward = -0.305254	array([[-1.7769597, -2.5270388]], dtype=float32)

time = 17027	action = 0	current_phase = 0	next_phase = 1	reward = -0.168387	array([[-1.9583098, -2.3596265]], dtype=float32)

time = 17032	action = 0	current_phase = 0	next_phase = 1	reward = 0.123068	array([[-2.3400598, -3.2101214]], dtype=float32)

time = 17037	action = 1	current_phase = 0	next_phase = 1	reward = -1.786030	array([[-4.4706206, -3.5415795]], dtype=float32)

time = 17045	action = 0	current_phase = 1	next_phase = 0	reward = -0.527374	array([[-1.8783512, -2.3770027]], dtype=float32)

time = 17050	action = 0	current_phase = 1	next_phase = 0	reward = -0.368726	array([[-1.7745769, -2.5904036]], dtype=float32)

time = 17055	action = 0	current_phase = 1	next_phase = 0	reward = -0.210532	array([[-1.5737777, -2.5479112]], dtype=float32)

time = 17060	action = 0	current_phase = 1	next_phase = 0	reward = 0.351875	array([[-1.7376187, -2.804284 ]], dtype=float32)

time = 17065	action = 1	current_phase = 1	next_phase = 0	reward = -1.364304	array([[-3.8131115, -2.6370344]], dtype=float32)

time = 17073	action = 0	current_phase = 0	next_phase = 1	reward = -0.584321	array([[-1.938148 , -2.1247437]], dtype=float32)

time = 17078	action = 0	current_phase = 0	next_phase = 1	reward = -0.430360	array([[-1.8171587, -2.3623488]], dtype=float32)

time = 17083	action = 0	current_phase = 0	next_phase = 1	reward = -0.271586	array([[-1.801744 , -2.5808387]], dtype=float32)

time = 17088	action = 0	current_phase = 0	next_phase = 1	reward = -0.169000	array([[-2.013266 , -2.4268262]], dtype=float32)

time = 17093	action = 1	current_phase = 0	next_phase = 1	reward = -1.896416	array([[-2.8799858, -2.869882 ]], dtype=float32)

time = 17101	action = 1	current_phase = 1	next_phase = 0	reward = -2.063001	array([[-4.355615, -3.38307 ]], dtype=float32)

time = 17109	action = 0	current_phase = 0	next_phase = 1	reward = -0.413102	array([[-1.8101785, -1.8957559]], dtype=float32)

time = 17114	action = 0	current_phase = 0	next_phase = 1	reward = -0.264208	array([[-1.8417743, -2.6234226]], dtype=float32)

time = 17119	action = 0	current_phase = 0	next_phase = 1	reward = -0.166257	array([[-1.9619417, -2.8909984]], dtype=float32)

time = 17124	action = 0	current_phase = 0	next_phase = 1	reward = -0.005696	array([[-2.3632998, -2.5434425]], dtype=float32)

time = 17129	action = 0	current_phase = 0	next_phase = 1	reward = -1.593392	array([[-3.0580423, -3.2066762]], dtype=float32)

time = 17134	action = 1	current_phase = 0	next_phase = 1	reward = -1.898465	array([[-4.2224064, -3.4783356]], dtype=float32)

time = 17142	action = 0	current_phase = 1	next_phase = 0	reward = -0.303667	array([[-1.9533603, -2.4809284]], dtype=float32)

time = 17147	action = 0	current_phase = 1	next_phase = 0	reward = -0.169837	array([[-2.0392015, -2.4871812]], dtype=float32)

time = 17152	action = 0	current_phase = 1	next_phase = 0	reward = 0.189286	array([[-1.9014201, -2.833908 ]], dtype=float32)

time = 17157	action = 1	current_phase = 1	next_phase = 0	reward = -1.789288	array([[-4.6525445, -3.2197042]], dtype=float32)

time = 17165	action = 0	current_phase = 0	next_phase = 1	reward = -0.538807	array([[-1.8587004, -2.074502 ]], dtype=float32)

time = 17170	action = 0	current_phase = 0	next_phase = 1	reward = -0.386874	array([[-1.8987517, -2.1159842]], dtype=float32)

time = 17175	action = 0	current_phase = 0	next_phase = 1	reward = -0.237334	array([[-1.7979614, -2.5583587]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0467 - val_loss: 0.0281

Epoch 2/50

 - 5s - loss: 0.0528 - val_loss: 0.0302

Epoch 3/50

 - 4s - loss: 0.0482 - val_loss: 0.0284

Epoch 4/50

 - 4s - loss: 0.0470 - val_loss: 0.0313

Epoch 5/50

 - 4s - loss: 0.0391 - val_loss: 0.0325

Epoch 6/50

 - 4s - loss: 0.0393 - val_loss: 0.0302

Epoch 7/50

 - 4s - loss: 0.0298 - val_loss: 0.0327

Epoch 8/50

 - 5s - loss: 0.0376 - val_loss: 0.0337

Epoch 9/50

 - 4s - loss: 0.0326 - val_loss: 0.0303

Epoch 10/50

 - 5s - loss: 0.0403 - val_loss: 0.0339

Epoch 11/50

 - 4s - loss: 0.0420 - val_loss: 0.0343

length of memory (state 0, action 0): 1025, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 618, after forget

length of memory (state 1, action 0): 1018, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 606, after forget

time = 17180	action = 0	current_phase = 0	next_phase = 1	reward = 0.083249	array([[-1.9166938, -2.4800243]], dtype=float32)

time = 17185	action = 1	current_phase = 0	next_phase = 1	reward = -0.910988	array([[-3.0012896, -2.5429068]], dtype=float32)

time = 17193	action = 0	current_phase = 1	next_phase = 0	reward = -0.586885	array([[-2.0891817, -2.406912 ]], dtype=float32)

time = 17198	action = 0	current_phase = 1	next_phase = 0	reward = -0.432655	array([[-2.0415447, -2.434327 ]], dtype=float32)

time = 17203	action = 0	current_phase = 1	next_phase = 0	reward = -0.277481	array([[-1.9124408, -2.4216857]], dtype=float32)

time = 17208	action = 0	current_phase = 1	next_phase = 0	reward = -0.162854	array([[-2.1432254, -2.2920334]], dtype=float32)

time = 17213	action = 0	current_phase = 1	next_phase = 0	reward = 0.203897	array([[-2.4039109, -2.4645193]], dtype=float32)

time = 17218	action = 1	current_phase = 1	next_phase = 0	reward = -1.898193	array([[-4.8962417, -3.2205396]], dtype=float32)

time = 17226	action = 0	current_phase = 0	next_phase = 1	reward = -0.503956	array([[-1.9122103, -2.111851 ]], dtype=float32)

time = 17231	action = 0	current_phase = 0	next_phase = 1	reward = -0.343926	array([[-1.9077932, -2.164036 ]], dtype=float32)

time = 17236	action = 0	current_phase = 0	next_phase = 1	reward = -0.191414	array([[-1.9313257, -2.3915372]], dtype=float32)

time = 17241	action = 0	current_phase = 0	next_phase = 1	reward = 0.314354	array([[-2.2121098, -2.725682 ]], dtype=float32)

time = 17246	action = 0	current_phase = 0	next_phase = 1	reward = -1.118903	array([[-2.9782293, -3.1875198]], dtype=float32)

time = 17251	action = 1	current_phase = 0	next_phase = 1	reward = -2.074911	array([[-4.42168 , -3.478962]], dtype=float32)

time = 17259	action = 0	current_phase = 1	next_phase = 0	reward = -0.413066	array([[-1.8820314, -2.4885387]], dtype=float32)

time = 17264	action = 0	current_phase = 1	next_phase = 0	reward = -0.252081	array([[-1.7861497, -2.4884913]], dtype=float32)

time = 17269	action = 0	current_phase = 1	next_phase = 0	reward = -0.170793	array([[-1.8084009, -2.5420794]], dtype=float32)

time = 17274	action = 1	current_phase = 1	next_phase = 0	reward = -0.480385	array([[-2.4102094, -2.0347552]], dtype=float32)

time = 17282	action = 0	current_phase = 0	next_phase = 1	reward = -0.616324	array([[-1.9158924, -2.164641 ]], dtype=float32)

time = 17287	action = 0	current_phase = 0	next_phase = 1	reward = -0.463848	array([[-1.8931066, -2.1488338]], dtype=float32)

time = 17292	action = 0	current_phase = 0	next_phase = 1	reward = -0.305075	array([[-1.7715504, -2.5535123]], dtype=float32)

time = 17297	action = 0	current_phase = 0	next_phase = 1	reward = -0.174682	array([[-1.8965867, -2.435317 ]], dtype=float32)

time = 17302	action = 0	current_phase = 0	next_phase = 1	reward = 0.190765	array([[-2.4318001, -2.9030006]], dtype=float32)

time = 17307	action = 1	current_phase = 0	next_phase = 1	reward = -1.779003	array([[-4.5604925, -3.357047 ]], dtype=float32)

time = 17315	action = 0	current_phase = 1	next_phase = 0	reward = -0.517960	array([[-1.9145768, -2.3846126]], dtype=float32)

time = 17320	action = 0	current_phase = 1	next_phase = 0	reward = -0.359269	array([[-1.793016 , -2.5955017]], dtype=float32)

time = 17325	action = 0	current_phase = 1	next_phase = 0	reward = -0.205159	array([[-1.7473011, -2.5316005]], dtype=float32)

time = 17330	action = 0	current_phase = 1	next_phase = 0	reward = 0.353036	array([[-1.7991741, -2.8987534]], dtype=float32)

time = 17335	action = 1	current_phase = 1	next_phase = 0	reward = -1.416741	array([[-3.9161513, -2.7460232]], dtype=float32)

time = 17343	action = 0	current_phase = 0	next_phase = 1	reward = -0.577382	array([[-1.9170607, -2.1517663]], dtype=float32)

time = 17348	action = 0	current_phase = 0	next_phase = 1	reward = -0.427847	array([[-1.8556843, -2.287037 ]], dtype=float32)

time = 17353	action = 0	current_phase = 0	next_phase = 1	reward = -0.270153	array([[-1.80112  , -2.5402696]], dtype=float32)

time = 17358	action = 0	current_phase = 0	next_phase = 1	reward = -0.166436	array([[-2.0061495, -2.4683368]], dtype=float32)

time = 17363	action = 1	current_phase = 0	next_phase = 1	reward = -1.077648	array([[-3.20477  , -2.8420668]], dtype=float32)

time = 17371	action = 1	current_phase = 1	next_phase = 0	reward = -1.997889	array([[-4.1729074, -3.3847067]], dtype=float32)

time = 17379	action = 0	current_phase = 0	next_phase = 1	reward = -0.391025	array([[-1.8545527, -2.2377038]], dtype=float32)

time = 17384	action = 0	current_phase = 0	next_phase = 1	reward = -0.239972	array([[-1.8409184, -2.585606 ]], dtype=float32)

time = 17389	action = 0	current_phase = 0	next_phase = 1	reward = -0.179455	array([[-0.913405 , -3.2888708]], dtype=float32)

time = 17394	action = 0	current_phase = 0	next_phase = 1	reward = -0.194470	array([[-2.0503035, -2.0715482]], dtype=float32)

time = 17399	action = 0	current_phase = 0	next_phase = 1	reward = -1.607989	array([[-2.9177935, -3.2777445]], dtype=float32)

time = 17404	action = 1	current_phase = 0	next_phase = 1	reward = -1.914131	array([[-4.329542 , -3.4063714]], dtype=float32)

time = 17412	action = 0	current_phase = 1	next_phase = 0	reward = -0.318370	array([[-1.9110267, -2.3888602]], dtype=float32)

time = 17417	action = 0	current_phase = 1	next_phase = 0	reward = -0.181854	array([[-2.065968, -2.468217]], dtype=float32)

time = 17422	action = 0	current_phase = 1	next_phase = 0	reward = 0.238890	array([[-2.17193  , -2.9552097]], dtype=float32)

time = 17427	action = 1	current_phase = 1	next_phase = 0	reward = -1.729413	array([[-4.690723, -3.163003]], dtype=float32)

time = 17435	action = 0	current_phase = 0	next_phase = 1	reward = -0.531047	array([[-1.8901807, -2.1113858]], dtype=float32)

time = 17440	action = 0	current_phase = 0	next_phase = 1	reward = -0.381590	array([[-1.8950608, -2.1437104]], dtype=float32)

time = 17445	action = 0	current_phase = 0	next_phase = 1	reward = -0.241833	array([[-1.8473263, -2.395002 ]], dtype=float32)

time = 17450	action = 0	current_phase = 0	next_phase = 1	reward = 0.081481	array([[-1.9011774, -2.4970393]], dtype=float32)

time = 17455	action = 1	current_phase = 0	next_phase = 1	reward = -1.014719	array([[-2.6773484, -2.4564722]], dtype=float32)

time = 17463	action = 0	current_phase = 1	next_phase = 0	reward = -0.591411	array([[-2.0864942, -2.4583247]], dtype=float32)

time = 17468	action = 0	current_phase = 1	next_phase = 0	reward = -0.431107	array([[-1.9811234, -2.475285 ]], dtype=float32)

time = 17473	action = 0	current_phase = 1	next_phase = 0	reward = -0.273900	array([[-1.9871445, -2.4095776]], dtype=float32)

time = 17478	action = 0	current_phase = 1	next_phase = 0	reward = -0.161404	array([[-2.1665401, -2.258742 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0414 - val_loss: 0.0378

Epoch 2/50

 - 5s - loss: 0.0514 - val_loss: 0.0365

Epoch 3/50

 - 5s - loss: 0.0405 - val_loss: 0.0371

Epoch 4/50

 - 4s - loss: 0.0424 - val_loss: 0.0387

Epoch 5/50

 - 5s - loss: 0.0354 - val_loss: 0.0412

Epoch 6/50

 - 5s - loss: 0.0321 - val_loss: 0.0397

Epoch 7/50

 - 5s - loss: 0.0357 - val_loss: 0.0395

Epoch 8/50

 - 5s - loss: 0.0401 - val_loss: 0.0398

Epoch 9/50

 - 5s - loss: 0.0297 - val_loss: 0.0422

Epoch 10/50

 - 4s - loss: 0.0506 - val_loss: 0.0374

Epoch 11/50

 - 4s - loss: 0.0371 - val_loss: 0.0436

Epoch 12/50

 - 4s - loss: 0.0326 - val_loss: 0.0415

length of memory (state 0, action 0): 1024, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 624, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 611, after forget

time = 17483	action = 0	current_phase = 1	next_phase = 0	reward = 0.093941	array([[-2.310708 , -2.8447433]], dtype=float32)

time = 17488	action = 1	current_phase = 1	next_phase = 0	reward = -1.894979	array([[-4.8811154, -3.293143 ]], dtype=float32)

time = 17496	action = 0	current_phase = 0	next_phase = 1	reward = -0.484110	array([[-1.8693457, -2.096858 ]], dtype=float32)

time = 17501	action = 0	current_phase = 0	next_phase = 1	reward = -0.322906	array([[-1.8593435, -2.1911695]], dtype=float32)

time = 17506	action = 0	current_phase = 0	next_phase = 1	reward = -0.179395	array([[-1.874449 , -2.4204905]], dtype=float32)

time = 17511	action = 0	current_phase = 0	next_phase = 1	reward = 0.273203	array([[-2.154912 , -3.0271132]], dtype=float32)

time = 17516	action = 1	current_phase = 0	next_phase = 1	reward = -1.610856	array([[-3.2589366, -3.1268978]], dtype=float32)

time = 17524	action = 0	current_phase = 1	next_phase = 0	reward = -0.558657	array([[-1.9530014, -2.480689 ]], dtype=float32)

time = 17529	action = 0	current_phase = 1	next_phase = 0	reward = -0.395574	array([[-1.6973702, -2.6138916]], dtype=float32)

time = 17534	action = 0	current_phase = 1	next_phase = 0	reward = -0.244009	array([[-1.5636914, -2.5473292]], dtype=float32)

time = 17539	action = 0	current_phase = 1	next_phase = 0	reward = -0.176724	array([[-1.6362448, -2.7714672]], dtype=float32)

time = 17544	action = 1	current_phase = 1	next_phase = 0	reward = -0.430509	array([[-2.59403  , -1.8088415]], dtype=float32)

time = 17552	action = 0	current_phase = 0	next_phase = 1	reward = -0.617368	array([[-1.947091 , -2.1457512]], dtype=float32)

time = 17557	action = 0	current_phase = 0	next_phase = 1	reward = -0.455039	array([[-1.8727052, -2.132557 ]], dtype=float32)

time = 17562	action = 0	current_phase = 0	next_phase = 1	reward = -0.298613	array([[-1.7863712, -2.4745731]], dtype=float32)

time = 17567	action = 0	current_phase = 0	next_phase = 1	reward = -0.166178	array([[-1.9606713, -2.399885 ]], dtype=float32)

time = 17572	action = 0	current_phase = 0	next_phase = 1	reward = 0.181689	array([[-2.4930704, -3.0874329]], dtype=float32)

time = 17577	action = 1	current_phase = 0	next_phase = 1	reward = -1.782841	array([[-4.491691 , -3.4686306]], dtype=float32)

time = 17585	action = 0	current_phase = 1	next_phase = 0	reward = -0.526106	array([[-1.8230168, -2.3837502]], dtype=float32)

time = 17590	action = 0	current_phase = 1	next_phase = 0	reward = -0.381359	array([[-1.7004609, -2.6200461]], dtype=float32)

time = 17595	action = 0	current_phase = 1	next_phase = 0	reward = -0.225485	array([[-1.683296 , -2.6269958]], dtype=float32)

time = 17600	action = 0	current_phase = 1	next_phase = 0	reward = 0.069660	array([[-1.6357   , -2.9548678]], dtype=float32)

time = 17605	action = 1	current_phase = 1	next_phase = 0	reward = -0.978958	array([[-3.7151034, -2.579999 ]], dtype=float32)

time = 17613	action = 0	current_phase = 0	next_phase = 1	reward = -0.597124	array([[-1.9082797, -2.12314  ]], dtype=float32)

time = 17618	action = 0	current_phase = 0	next_phase = 1	reward = -0.450437	array([[-1.8777174, -2.115814 ]], dtype=float32)

time = 17623	action = 0	current_phase = 0	next_phase = 1	reward = -0.299282	array([[-1.9016757, -2.4214256]], dtype=float32)

time = 17628	action = 0	current_phase = 0	next_phase = 1	reward = -0.174080	array([[-2.0674562, -2.620748 ]], dtype=float32)

time = 17633	action = 0	current_phase = 0	next_phase = 1	reward = 0.010056	array([[-2.8810558, -3.2772434]], dtype=float32)

time = 17638	action = 1	current_phase = 0	next_phase = 1	reward = -1.895589	array([[-4.696288 , -3.3898144]], dtype=float32)

time = 17646	action = 0	current_phase = 1	next_phase = 0	reward = -0.485845	array([[-1.8987345, -2.4564292]], dtype=float32)

time = 17651	action = 0	current_phase = 1	next_phase = 0	reward = -0.323848	array([[-1.7328932, -2.5657372]], dtype=float32)

time = 17656	action = 0	current_phase = 1	next_phase = 0	reward = -0.181243	array([[-1.8570974, -2.413511 ]], dtype=float32)

time = 17661	action = 0	current_phase = 1	next_phase = 0	reward = 0.306164	array([[-2.3175914, -3.1931398]], dtype=float32)

time = 17666	action = 1	current_phase = 1	next_phase = 0	reward = -1.661876	array([[-4.7405543, -3.092957 ]], dtype=float32)

time = 17674	action = 0	current_phase = 0	next_phase = 1	reward = -0.555206	array([[-1.8781695, -2.1163468]], dtype=float32)

time = 17679	action = 0	current_phase = 0	next_phase = 1	reward = -0.401656	array([[-1.876462 , -2.1144314]], dtype=float32)

time = 17684	action = 0	current_phase = 0	next_phase = 1	reward = -0.248541	array([[-1.8532736, -2.4450595]], dtype=float32)

time = 17689	action = 0	current_phase = 0	next_phase = 1	reward = -0.193586	array([[-1.9455321, -2.4844997]], dtype=float32)

time = 17694	action = 1	current_phase = 0	next_phase = 1	reward = -0.631592	array([[-2.5590897, -2.4532473]], dtype=float32)

time = 17702	action = 0	current_phase = 1	next_phase = 0	reward = -0.614890	array([[-1.9465504, -2.468439 ]], dtype=float32)

time = 17707	action = 0	current_phase = 1	next_phase = 0	reward = -0.461886	array([[-1.9596509, -2.4714196]], dtype=float32)

time = 17712	action = 0	current_phase = 1	next_phase = 0	reward = -0.303591	array([[-1.9050952, -2.4832022]], dtype=float32)

time = 17717	action = 0	current_phase = 1	next_phase = 0	reward = -0.174203	array([[-2.0820293, -2.296156 ]], dtype=float32)

time = 17722	action = 0	current_phase = 1	next_phase = 0	reward = 0.252945	array([[-2.4443274, -3.3031163]], dtype=float32)

time = 17727	action = 1	current_phase = 1	next_phase = 0	reward = -1.722002	array([[-4.9499307, -3.2450137]], dtype=float32)

time = 17735	action = 0	current_phase = 0	next_phase = 1	reward = -0.514781	array([[-1.8524665, -2.066129 ]], dtype=float32)

time = 17740	action = 0	current_phase = 0	next_phase = 1	reward = -0.356866	array([[-1.8518035, -2.1767457]], dtype=float32)

time = 17745	action = 0	current_phase = 0	next_phase = 1	reward = -0.214129	array([[-1.8134507, -2.4830005]], dtype=float32)

time = 17750	action = 0	current_phase = 0	next_phase = 1	reward = 0.345218	array([[-1.9093721, -2.5595157]], dtype=float32)

time = 17755	action = 0	current_phase = 0	next_phase = 1	reward = -0.848628	array([[-2.8619149, -2.8776517]], dtype=float32)

time = 17760	action = 1	current_phase = 0	next_phase = 1	reward = -2.107785	array([[-4.576977 , -3.5711462]], dtype=float32)

time = 17768	action = 0	current_phase = 1	next_phase = 0	reward = -0.433825	array([[-1.9587448, -2.4508755]], dtype=float32)

time = 17773	action = 0	current_phase = 1	next_phase = 0	reward = -0.282035	array([[-1.93902  , -2.4854894]], dtype=float32)

time = 17778	action = 0	current_phase = 1	next_phase = 0	reward = -0.161279	array([[-2.1103008, -2.281596 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0432 - val_loss: 0.0234

Epoch 2/50

 - 4s - loss: 0.0396 - val_loss: 0.0214

Epoch 3/50

 - 4s - loss: 0.0461 - val_loss: 0.0223

Epoch 4/50

 - 5s - loss: 0.0412 - val_loss: 0.0224

Epoch 5/50

 - 4s - loss: 0.0488 - val_loss: 0.0246

Epoch 6/50

 - 4s - loss: 0.0338 - val_loss: 0.0247

Epoch 7/50

 - 4s - loss: 0.0372 - val_loss: 0.0242

Epoch 8/50

 - 4s - loss: 0.0406 - val_loss: 0.0249

Epoch 9/50

 - 4s - loss: 0.0418 - val_loss: 0.0247

Epoch 10/50

 - 6s - loss: 0.0327 - val_loss: 0.0251

Epoch 11/50

 - 4s - loss: 0.0402 - val_loss: 0.0242

Epoch 12/50

 - 4s - loss: 0.0337 - val_loss: 0.0240

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 629, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 616, after forget

time = 17783	action = 0	current_phase = 1	next_phase = 0	reward = 0.073766	array([[-2.2372267, -2.9475818]], dtype=float32)

time = 17788	action = 1	current_phase = 1	next_phase = 0	reward = -1.903179	array([[-4.7000923, -3.2385178]], dtype=float32)

time = 17796	action = 0	current_phase = 0	next_phase = 1	reward = -0.503293	array([[-2.0051842, -2.3149111]], dtype=float32)

time = 17801	action = 0	current_phase = 0	next_phase = 1	reward = -0.351638	array([[-1.9509796, -2.1437418]], dtype=float32)

time = 17806	action = 0	current_phase = 0	next_phase = 1	reward = -0.199298	array([[-1.94021 , -2.451004]], dtype=float32)

time = 17811	action = 0	current_phase = 0	next_phase = 1	reward = 0.287143	array([[-2.2061718, -2.796077 ]], dtype=float32)

time = 17816	action = 1	current_phase = 0	next_phase = 1	reward = -1.660494	array([[-3.1560435, -3.1291215]], dtype=float32)

time = 17824	action = 0	current_phase = 1	next_phase = 0	reward = -0.556447	array([[-2.0398805, -2.43385  ]], dtype=float32)

time = 17829	action = 0	current_phase = 1	next_phase = 0	reward = -0.393045	array([[-1.7604306, -2.6002588]], dtype=float32)

time = 17834	action = 0	current_phase = 1	next_phase = 0	reward = -0.231844	array([[-1.7832026, -2.57273  ]], dtype=float32)

time = 17839	action = 0	current_phase = 1	next_phase = 0	reward = 0.108054	array([[-1.7032096, -2.770628 ]], dtype=float32)

time = 17844	action = 1	current_phase = 1	next_phase = 0	reward = -0.804786	array([[-2.8393095, -2.0307631]], dtype=float32)

time = 17852	action = 0	current_phase = 0	next_phase = 1	reward = -0.620768	array([[-2.009945, -2.227345]], dtype=float32)

time = 17857	action = 0	current_phase = 0	next_phase = 1	reward = -0.475539	array([[-1.9337583, -2.165429 ]], dtype=float32)

time = 17862	action = 0	current_phase = 0	next_phase = 1	reward = -0.322243	array([[-1.8971771, -2.4460344]], dtype=float32)

time = 17867	action = 0	current_phase = 0	next_phase = 1	reward = -0.177166	array([[-2.0040023, -2.3741436]], dtype=float32)

time = 17872	action = 0	current_phase = 0	next_phase = 1	reward = 0.243386	array([[-2.5425286, -3.2086184]], dtype=float32)

time = 17877	action = 1	current_phase = 0	next_phase = 1	reward = -1.672942	array([[-4.357868, -3.405379]], dtype=float32)

time = 17885	action = 0	current_phase = 1	next_phase = 0	reward = -0.529162	array([[-1.9441156, -2.4130046]], dtype=float32)

time = 17890	action = 0	current_phase = 1	next_phase = 0	reward = -0.376736	array([[-1.7503223, -2.607501 ]], dtype=float32)

time = 17895	action = 0	current_phase = 1	next_phase = 0	reward = -0.220719	array([[-1.6259856, -2.5758238]], dtype=float32)

time = 17900	action = 0	current_phase = 1	next_phase = 0	reward = 0.368554	array([[-1.7223573, -2.844439 ]], dtype=float32)

time = 17905	action = 1	current_phase = 1	next_phase = 0	reward = -1.257274	array([[-3.286812 , -2.4317987]], dtype=float32)

time = 17913	action = 0	current_phase = 0	next_phase = 1	reward = -0.594641	array([[-1.9357104, -2.1475267]], dtype=float32)

time = 17918	action = 0	current_phase = 0	next_phase = 1	reward = -0.437359	array([[-1.9239818, -2.1924953]], dtype=float32)

time = 17923	action = 0	current_phase = 0	next_phase = 1	reward = -0.284934	array([[-1.9467323, -2.4101553]], dtype=float32)

time = 17928	action = 0	current_phase = 0	next_phase = 1	reward = -0.162953	array([[-2.002543 , -2.4031897]], dtype=float32)

time = 17933	action = 1	current_phase = 0	next_phase = 1	reward = -1.878561	array([[-3.0186908, -2.9505851]], dtype=float32)

time = 17941	action = 1	current_phase = 1	next_phase = 0	reward = -2.050796	array([[-4.6969957, -3.3479788]], dtype=float32)

time = 17949	action = 0	current_phase = 0	next_phase = 1	reward = -0.393183	array([[-1.8145438, -1.9032822]], dtype=float32)

time = 17954	action = 0	current_phase = 0	next_phase = 1	reward = -0.237361	array([[-1.8123264, -2.6024113]], dtype=float32)

time = 17959	action = 0	current_phase = 0	next_phase = 1	reward = -0.186368	array([[-1.9754286, -2.38754  ]], dtype=float32)

time = 17964	action = 1	current_phase = 0	next_phase = 1	reward = -0.561304	array([[-2.5940402, -2.5607276]], dtype=float32)

time = 17972	action = 1	current_phase = 1	next_phase = 0	reward = -1.916339	array([[-2.5549922, -2.4609933]], dtype=float32)

time = 17980	action = 0	current_phase = 0	next_phase = 1	reward = -0.377042	array([[-1.8605973, -2.5717235]], dtype=float32)

time = 17985	action = 0	current_phase = 0	next_phase = 1	reward = -0.230543	array([[-2.2236397, -2.8267903]], dtype=float32)

time = 17990	action = 0	current_phase = 0	next_phase = 1	reward = 0.058315	array([[-1.4484605, -3.602683 ]], dtype=float32)

time = 17995	action = 0	current_phase = 0	next_phase = 1	reward = -0.509673	array([[-1.7546421, -2.1604402]], dtype=float32)

time = 18000	action = 1	current_phase = 0	next_phase = 1	reward = -2.101191	array([[-3.8773887, -3.6714618]], dtype=float32)

time = 18008	action = 0	current_phase = 1	next_phase = 0	reward = -0.418950	array([[-2.0308797, -2.4435582]], dtype=float32)

time = 18013	action = 0	current_phase = 1	next_phase = 0	reward = -0.267391	array([[-2.0236027, -2.4824855]], dtype=float32)

time = 18018	action = 0	current_phase = 1	next_phase = 0	reward = -0.159245	array([[-2.0701652, -2.5631042]], dtype=float32)

time = 18023	action = 0	current_phase = 1	next_phase = 0	reward = 0.065692	array([[-1.597821 , -1.7286168]], dtype=float32)

time = 18028	action = 1	current_phase = 1	next_phase = 0	reward = -1.894302	array([[-4.7068114, -3.2738373]], dtype=float32)

time = 18036	action = 0	current_phase = 0	next_phase = 1	reward = -0.490010	array([[-2.0089676, -2.3260503]], dtype=float32)

time = 18041	action = 0	current_phase = 0	next_phase = 1	reward = -0.336966	array([[-1.953591, -2.151772]], dtype=float32)

time = 18046	action = 0	current_phase = 0	next_phase = 1	reward = -0.189778	array([[-1.9983925, -2.369898 ]], dtype=float32)

time = 18051	action = 0	current_phase = 0	next_phase = 1	reward = 0.310305	array([[-2.3004997, -2.8412771]], dtype=float32)

time = 18056	action = 1	current_phase = 0	next_phase = 1	reward = -1.605902	array([[-3.158295 , -3.1529417]], dtype=float32)

time = 18064	action = 0	current_phase = 1	next_phase = 0	reward = -0.551549	array([[-2.019277 , -2.4879107]], dtype=float32)

time = 18069	action = 0	current_phase = 1	next_phase = 0	reward = -0.398145	array([[-1.7835855, -2.5710568]], dtype=float32)

time = 18074	action = 0	current_phase = 1	next_phase = 0	reward = -0.243242	array([[-1.6917117, -2.5877435]], dtype=float32)

time = 18079	action = 0	current_phase = 1	next_phase = 0	reward = -0.178053	array([[-1.6736372, -2.8352442]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0577 - val_loss: 0.0425

Epoch 2/50

 - 4s - loss: 0.0548 - val_loss: 0.0452

Epoch 3/50

 - 4s - loss: 0.0490 - val_loss: 0.0481

Epoch 4/50

 - 4s - loss: 0.0577 - val_loss: 0.0428

Epoch 5/50

 - 4s - loss: 0.0460 - val_loss: 0.0424

Epoch 6/50

 - 4s - loss: 0.0461 - val_loss: 0.0442

Epoch 7/50

 - 4s - loss: 0.0508 - val_loss: 0.0463

Epoch 8/50

 - 4s - loss: 0.0445 - val_loss: 0.0531

Epoch 9/50

 - 4s - loss: 0.0403 - val_loss: 0.0590

Epoch 10/50

 - 4s - loss: 0.0381 - val_loss: 0.0530

Epoch 11/50

 - 4s - loss: 0.0425 - val_loss: 0.0537

Epoch 12/50

 - 4s - loss: 0.0423 - val_loss: 0.0426

Epoch 13/50

 - 4s - loss: 0.0332 - val_loss: 0.0532

Epoch 14/50

 - 4s - loss: 0.0392 - val_loss: 0.0532

Epoch 15/50

 - 4s - loss: 0.0380 - val_loss: 0.0526

length of memory (state 0, action 0): 1024, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 635, after forget

length of memory (state 1, action 0): 1017, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 622, after forget

time = 18084	action = 1	current_phase = 1	next_phase = 0	reward = -0.481894	array([[-3.1295588, -1.9715269]], dtype=float32)

time = 18092	action = 0	current_phase = 0	next_phase = 1	reward = -0.619163	array([[-1.9763718, -2.1727545]], dtype=float32)

time = 18097	action = 0	current_phase = 0	next_phase = 1	reward = -0.470634	array([[-1.8997853, -2.1548588]], dtype=float32)

time = 18102	action = 0	current_phase = 0	next_phase = 1	reward = -0.310002	array([[-1.8214854, -2.5263352]], dtype=float32)

time = 18107	action = 0	current_phase = 0	next_phase = 1	reward = -0.174667	array([[-2.0080898, -2.3936799]], dtype=float32)

time = 18112	action = 0	current_phase = 0	next_phase = 1	reward = 0.257133	array([[-2.6173444, -3.2995155]], dtype=float32)

time = 18117	action = 1	current_phase = 0	next_phase = 1	reward = -1.734994	array([[-4.486232, -3.284396]], dtype=float32)

time = 18125	action = 0	current_phase = 1	next_phase = 0	reward = -0.537255	array([[-1.9283265, -2.4377682]], dtype=float32)

time = 18130	action = 0	current_phase = 1	next_phase = 0	reward = -0.382118	array([[-1.7399104, -2.633896 ]], dtype=float32)

time = 18135	action = 0	current_phase = 1	next_phase = 0	reward = -0.224749	array([[-1.6654809, -2.5909166]], dtype=float32)

time = 18140	action = 0	current_phase = 1	next_phase = 0	reward = 0.380060	array([[-1.5891731, -2.9145439]], dtype=float32)

time = 18145	action = 1	current_phase = 1	next_phase = 0	reward = -1.246024	array([[-3.6981769, -2.5630565]], dtype=float32)

time = 18153	action = 0	current_phase = 0	next_phase = 1	reward = -0.599272	array([[-1.9111212, -2.1430495]], dtype=float32)

time = 18158	action = 0	current_phase = 0	next_phase = 1	reward = -0.445801	array([[-1.9002475, -2.1423757]], dtype=float32)

time = 18163	action = 0	current_phase = 0	next_phase = 1	reward = -0.287925	array([[-1.8138446, -2.574447 ]], dtype=float32)

time = 18168	action = 0	current_phase = 0	next_phase = 1	reward = -0.162699	array([[-2.1732125, -2.5025287]], dtype=float32)

time = 18173	action = 0	current_phase = 0	next_phase = 1	reward = 0.136582	array([[-2.408152 , -3.1717052]], dtype=float32)

time = 18178	action = 1	current_phase = 0	next_phase = 1	reward = -1.892475	array([[-4.621975 , -3.3295949]], dtype=float32)

time = 18186	action = 0	current_phase = 1	next_phase = 0	reward = -0.499664	array([[-2.0043552, -2.4995477]], dtype=float32)

time = 18191	action = 0	current_phase = 1	next_phase = 0	reward = -0.340647	array([[-1.8231153, -2.6198826]], dtype=float32)

time = 18196	action = 0	current_phase = 1	next_phase = 0	reward = -0.192781	array([[-1.8839626, -2.5093951]], dtype=float32)

time = 18201	action = 0	current_phase = 1	next_phase = 0	reward = 0.306309	array([[-2.1451824, -3.3021185]], dtype=float32)

time = 18206	action = 1	current_phase = 1	next_phase = 0	reward = -1.558798	array([[-4.82808  , -3.1384516]], dtype=float32)

time = 18214	action = 0	current_phase = 0	next_phase = 1	reward = -0.563071	array([[-1.9073337, -2.141345 ]], dtype=float32)

time = 18219	action = 0	current_phase = 0	next_phase = 1	reward = -0.408637	array([[-1.9007729, -2.1397252]], dtype=float32)

time = 18224	action = 0	current_phase = 0	next_phase = 1	reward = -0.248986	array([[-1.8091378, -2.5826917]], dtype=float32)

time = 18229	action = 0	current_phase = 0	next_phase = 1	reward = -0.174474	array([[-2.0264144, -2.5060554]], dtype=float32)

time = 18234	action = 1	current_phase = 0	next_phase = 1	reward = -0.544066	array([[-2.3486218, -2.0982904]], dtype=float32)

time = 18242	action = 0	current_phase = 1	next_phase = 0	reward = -0.622678	array([[-2.02845  , -2.4428499]], dtype=float32)

time = 18247	action = 0	current_phase = 1	next_phase = 0	reward = -0.453240	array([[-2.0125391, -2.5414872]], dtype=float32)

time = 18252	action = 0	current_phase = 1	next_phase = 0	reward = -0.293335	array([[-2.0187743, -2.4573164]], dtype=float32)

time = 18257	action = 0	current_phase = 1	next_phase = 0	reward = -0.165185	array([[-2.1422217, -2.3092866]], dtype=float32)

time = 18262	action = 0	current_phase = 1	next_phase = 0	reward = 0.176453	array([[-2.2840662, -3.089305 ]], dtype=float32)

time = 18267	action = 1	current_phase = 1	next_phase = 0	reward = -1.781957	array([[-4.900892 , -3.3501291]], dtype=float32)

time = 18275	action = 0	current_phase = 0	next_phase = 1	reward = -0.516147	array([[-1.9179004, -2.1659825]], dtype=float32)

time = 18280	action = 0	current_phase = 0	next_phase = 1	reward = -0.360099	array([[-1.8981293, -2.165213 ]], dtype=float32)

time = 18285	action = 0	current_phase = 0	next_phase = 1	reward = -0.210548	array([[-1.9950374, -2.3444219]], dtype=float32)

time = 18290	action = 0	current_phase = 0	next_phase = 1	reward = 0.350022	array([[-2.1622462, -2.7118757]], dtype=float32)

time = 18295	action = 1	current_phase = 0	next_phase = 1	reward = -1.362782	array([[-2.9790726, -2.8379245]], dtype=float32)

time = 18303	action = 0	current_phase = 1	next_phase = 0	reward = -0.595819	array([[-2.0422013, -2.4434087]], dtype=float32)

time = 18308	action = 0	current_phase = 1	next_phase = 0	reward = -0.447676	array([[-1.9407179, -2.5509183]], dtype=float32)

time = 18313	action = 0	current_phase = 1	next_phase = 0	reward = -0.286830	array([[-2.0024402, -2.498714 ]], dtype=float32)

time = 18318	action = 0	current_phase = 1	next_phase = 0	reward = -0.170741	array([[-2.1201928, -2.2923162]], dtype=float32)

time = 18323	action = 0	current_phase = 1	next_phase = 0	reward = 0.176420	array([[-2.5199234, -2.8846326]], dtype=float32)

time = 18328	action = 1	current_phase = 1	next_phase = 0	reward = -1.890081	array([[-4.7963867, -3.3412545]], dtype=float32)

time = 18336	action = 0	current_phase = 0	next_phase = 1	reward = -0.488845	array([[-1.8693659, -2.076532 ]], dtype=float32)

time = 18341	action = 0	current_phase = 0	next_phase = 1	reward = -0.332981	array([[-1.889964 , -2.1815903]], dtype=float32)

time = 18346	action = 0	current_phase = 0	next_phase = 1	reward = -0.193862	array([[-2.023593 , -2.3577414]], dtype=float32)

time = 18351	action = 0	current_phase = 0	next_phase = 1	reward = 0.294282	array([[-2.3834343, -2.9204874]], dtype=float32)

time = 18356	action = 0	current_phase = 0	next_phase = 1	reward = -1.009602	array([[-3.0600724, -3.1805677]], dtype=float32)

time = 18361	action = 1	current_phase = 0	next_phase = 1	reward = -2.056954	array([[-4.565118 , -3.5137897]], dtype=float32)

time = 18369	action = 0	current_phase = 1	next_phase = 0	reward = -0.405172	array([[-1.7664748, -2.6218443]], dtype=float32)

time = 18374	action = 0	current_phase = 1	next_phase = 0	reward = -0.254295	array([[-1.7879134, -2.6089213]], dtype=float32)

time = 18379	action = 0	current_phase = 1	next_phase = 0	reward = -0.174687	array([[-1.6799073, -2.9139826]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0483 - val_loss: 0.0427

Epoch 2/50

 - 4s - loss: 0.0490 - val_loss: 0.0477

Epoch 3/50

 - 4s - loss: 0.0504 - val_loss: 0.0494

Epoch 4/50

 - 4s - loss: 0.0500 - val_loss: 0.0458

Epoch 5/50

 - 4s - loss: 0.0442 - val_loss: 0.0439

Epoch 6/50

 - 4s - loss: 0.0503 - val_loss: 0.0463

Epoch 7/50

 - 4s - loss: 0.0422 - val_loss: 0.0493

Epoch 8/50

 - 5s - loss: 0.0506 - val_loss: 0.0541

Epoch 9/50

 - 5s - loss: 0.0413 - val_loss: 0.0501

Epoch 10/50

 - 4s - loss: 0.0505 - val_loss: 0.0531

Epoch 11/50

 - 5s - loss: 0.0347 - val_loss: 0.0533

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 640, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 627, after forget

time = 18384	action = 1	current_phase = 1	next_phase = 0	reward = -0.544567	array([[-2.6580963, -2.2023928]], dtype=float32)

time = 18392	action = 0	current_phase = 0	next_phase = 1	reward = -0.631533	array([[-1.9544951, -2.1280522]], dtype=float32)

time = 18397	action = 0	current_phase = 0	next_phase = 1	reward = -0.486496	array([[-1.9315568, -2.1109936]], dtype=float32)

time = 18402	action = 0	current_phase = 0	next_phase = 1	reward = -0.340145	array([[-1.9172295, -2.3478522]], dtype=float32)

time = 18407	action = 0	current_phase = 0	next_phase = 1	reward = -0.195078	array([[-2.044242 , -2.3198814]], dtype=float32)

time = 18412	action = 0	current_phase = 0	next_phase = 1	reward = 0.259346	array([[-2.677958, -3.342422]], dtype=float32)

time = 18417	action = 1	current_phase = 0	next_phase = 1	reward = -1.779809	array([[-4.2782493, -3.218245 ]], dtype=float32)

time = 18425	action = 0	current_phase = 1	next_phase = 0	reward = -0.526882	array([[-1.8632764, -2.4509113]], dtype=float32)

time = 18430	action = 0	current_phase = 1	next_phase = 0	reward = -0.371682	array([[-1.6983082, -2.6605818]], dtype=float32)

time = 18435	action = 0	current_phase = 1	next_phase = 0	reward = -0.226585	array([[-1.6605905, -2.6308715]], dtype=float32)

time = 18440	action = 0	current_phase = 1	next_phase = 0	reward = 0.352413	array([[-1.6499277, -2.8649035]], dtype=float32)

time = 18445	action = 1	current_phase = 1	next_phase = 0	reward = -1.360780	array([[-3.689691 , -2.7207716]], dtype=float32)

time = 18453	action = 0	current_phase = 0	next_phase = 1	reward = -0.595121	array([[-1.9491738, -2.1202266]], dtype=float32)

time = 18458	action = 0	current_phase = 0	next_phase = 1	reward = -0.441705	array([[-1.9148378, -2.2128243]], dtype=float32)

time = 18463	action = 0	current_phase = 0	next_phase = 1	reward = -0.285235	array([[-1.8501414, -2.532295 ]], dtype=float32)

time = 18468	action = 0	current_phase = 0	next_phase = 1	reward = -0.165189	array([[-2.0839698, -2.380556 ]], dtype=float32)

time = 18473	action = 0	current_phase = 0	next_phase = 1	reward = 0.065116	array([[-2.9028726, -3.104009 ]], dtype=float32)

time = 18478	action = 1	current_phase = 0	next_phase = 1	reward = -1.892942	array([[-4.7918687, -3.3440008]], dtype=float32)

time = 18486	action = 0	current_phase = 1	next_phase = 0	reward = -0.493627	array([[-1.8762746, -2.4735727]], dtype=float32)

time = 18491	action = 0	current_phase = 1	next_phase = 0	reward = -0.342725	array([[-1.8810042, -2.5753381]], dtype=float32)

time = 18496	action = 0	current_phase = 1	next_phase = 0	reward = -0.192889	array([[-1.853097 , -2.4995432]], dtype=float32)

time = 18501	action = 0	current_phase = 1	next_phase = 0	reward = 0.292706	array([[-2.1693892, -3.267708 ]], dtype=float32)

time = 18506	action = 1	current_phase = 1	next_phase = 0	reward = -1.608404	array([[-4.8009176, -3.2048666]], dtype=float32)

time = 18514	action = 0	current_phase = 0	next_phase = 1	reward = -0.547165	array([[-1.952688 , -2.1016834]], dtype=float32)

time = 18519	action = 0	current_phase = 0	next_phase = 1	reward = -0.391393	array([[-1.9316161, -2.1101649]], dtype=float32)

time = 18524	action = 0	current_phase = 0	next_phase = 1	reward = -0.229867	array([[-1.8229903, -2.5731678]], dtype=float32)

time = 18529	action = 0	current_phase = 0	next_phase = 1	reward = -0.184105	array([[-2.054348 , -2.4051316]], dtype=float32)

time = 18534	action = 1	current_phase = 0	next_phase = 1	reward = -0.541508	array([[-2.4555151, -2.0613294]], dtype=float32)

time = 18542	action = 0	current_phase = 1	next_phase = 0	reward = -0.623503	array([[-1.9893633, -2.452342 ]], dtype=float32)

time = 18547	action = 0	current_phase = 1	next_phase = 0	reward = -0.472814	array([[-1.9365399, -2.5555127]], dtype=float32)

time = 18552	action = 0	current_phase = 1	next_phase = 0	reward = -0.309852	array([[-1.963923 , -2.4527435]], dtype=float32)

time = 18557	action = 0	current_phase = 1	next_phase = 0	reward = -0.172925	array([[-2.0064201, -2.430306 ]], dtype=float32)

time = 18562	action = 0	current_phase = 1	next_phase = 0	reward = 0.182589	array([[-2.3355722, -3.0201802]], dtype=float32)

time = 18567	action = 1	current_phase = 1	next_phase = 0	reward = -1.783672	array([[-4.9200664, -3.380039 ]], dtype=float32)

time = 18575	action = 0	current_phase = 0	next_phase = 1	reward = -0.527480	array([[-1.9857348, -2.176214 ]], dtype=float32)

time = 18580	action = 0	current_phase = 0	next_phase = 1	reward = -0.374207	array([[-1.9283483, -2.12185  ]], dtype=float32)

time = 18585	action = 0	current_phase = 0	next_phase = 1	reward = -0.216885	array([[-1.8669732, -2.515772 ]], dtype=float32)

time = 18590	action = 0	current_phase = 0	next_phase = 1	reward = 0.360830	array([[-2.0582285, -2.3395622]], dtype=float32)

time = 18595	action = 1	current_phase = 0	next_phase = 1	reward = -1.362499	array([[-3.1949348, -2.8896494]], dtype=float32)

time = 18603	action = 0	current_phase = 1	next_phase = 0	reward = -0.586683	array([[-1.9925584, -2.4383385]], dtype=float32)

time = 18608	action = 0	current_phase = 1	next_phase = 0	reward = -0.433873	array([[-1.9695964, -2.4588983]], dtype=float32)

time = 18613	action = 0	current_phase = 1	next_phase = 0	reward = -0.289351	array([[-1.9589443, -2.5096843]], dtype=float32)

time = 18618	action = 0	current_phase = 1	next_phase = 0	reward = -0.164425	array([[-2.1088154, -2.3130178]], dtype=float32)

time = 18623	action = 0	current_phase = 1	next_phase = 0	reward = -0.039612	array([[-2.5848083, -2.9883807]], dtype=float32)

time = 18628	action = 1	current_phase = 1	next_phase = 0	reward = -1.901002	array([[-4.8729606, -3.4010093]], dtype=float32)

time = 18636	action = 0	current_phase = 0	next_phase = 1	reward = -0.502027	array([[-1.9614315, -2.1691082]], dtype=float32)

time = 18641	action = 0	current_phase = 0	next_phase = 1	reward = -0.341282	array([[-1.9354519, -2.1121125]], dtype=float32)

time = 18646	action = 0	current_phase = 0	next_phase = 1	reward = -0.189507	array([[-1.9885837, -2.3972168]], dtype=float32)

time = 18651	action = 0	current_phase = 0	next_phase = 1	reward = 0.286586	array([[-2.2064805, -2.768004 ]], dtype=float32)

time = 18656	action = 1	current_phase = 0	next_phase = 1	reward = -1.611217	array([[-3.1479032, -3.1117654]], dtype=float32)

time = 18664	action = 0	current_phase = 1	next_phase = 0	reward = -0.554460	array([[-1.9782566, -2.47008  ]], dtype=float32)

time = 18669	action = 0	current_phase = 1	next_phase = 0	reward = -0.398385	array([[-1.711455, -2.656616]], dtype=float32)

time = 18674	action = 0	current_phase = 1	next_phase = 0	reward = -0.245906	array([[-1.6702452, -2.6151273]], dtype=float32)

time = 18679	action = 0	current_phase = 1	next_phase = 0	reward = -0.178923	array([[-1.663008 , -2.8607914]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0796 - val_loss: 0.0499

Epoch 2/50

 - 4s - loss: 0.0640 - val_loss: 0.0477

Epoch 3/50

 - 4s - loss: 0.0452 - val_loss: 0.0482

Epoch 4/50

 - 5s - loss: 0.0584 - val_loss: 0.0465

Epoch 5/50

 - 4s - loss: 0.0475 - val_loss: 0.0484

Epoch 6/50

 - 4s - loss: 0.0452 - val_loss: 0.0507

Epoch 7/50

 - 5s - loss: 0.0715 - val_loss: 0.0488

Epoch 8/50

 - 5s - loss: 0.0536 - val_loss: 0.0478

Epoch 9/50

 - 5s - loss: 0.0456 - val_loss: 0.0448

Epoch 10/50

 - 4s - loss: 0.0490 - val_loss: 0.0446

Epoch 11/50

 - 4s - loss: 0.0380 - val_loss: 0.0544

Epoch 12/50

 - 4s - loss: 0.0455 - val_loss: 0.0495

Epoch 13/50

 - 4s - loss: 0.0526 - val_loss: 0.0523

Epoch 14/50

 - 4s - loss: 0.0506 - val_loss: 0.0509

Epoch 15/50

 - 4s - loss: 0.0433 - val_loss: 0.0477

Epoch 16/50

 - 4s - loss: 0.0450 - val_loss: 0.0485

Epoch 17/50

 - 5s - loss: 0.0333 - val_loss: 0.0496

Epoch 18/50

 - 4s - loss: 0.0419 - val_loss: 0.0518

Epoch 19/50

 - 5s - loss: 0.0367 - val_loss: 0.0571

Epoch 20/50

 - 5s - loss: 0.0351 - val_loss: 0.0539

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 645, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 632, after forget

time = 18684	action = 1	current_phase = 1	next_phase = 0	reward = -0.584803	array([[-2.711019 , -2.0106988]], dtype=float32)

time = 18692	action = 0	current_phase = 0	next_phase = 1	reward = -0.617498	array([[-2.0588343, -2.1822932]], dtype=float32)

time = 18697	action = 0	current_phase = 0	next_phase = 1	reward = -0.461312	array([[-1.9405258, -2.151419 ]], dtype=float32)

time = 18702	action = 0	current_phase = 0	next_phase = 1	reward = -0.302159	array([[-1.8424197, -2.692359 ]], dtype=float32)

time = 18707	action = 0	current_phase = 0	next_phase = 1	reward = -0.168040	array([[-2.0842876, -2.437929 ]], dtype=float32)

time = 18712	action = 0	current_phase = 0	next_phase = 1	reward = 0.118560	array([[-2.2445655, -3.1298428]], dtype=float32)

time = 18717	action = 1	current_phase = 0	next_phase = 1	reward = -1.786362	array([[-4.736754 , -3.4700992]], dtype=float32)

time = 18725	action = 0	current_phase = 1	next_phase = 0	reward = -0.531587	array([[-1.935371 , -2.4479876]], dtype=float32)

time = 18730	action = 0	current_phase = 1	next_phase = 0	reward = -0.375579	array([[-1.7754436, -2.663452 ]], dtype=float32)

time = 18735	action = 0	current_phase = 1	next_phase = 0	reward = -0.230913	array([[-1.6528846, -2.5989115]], dtype=float32)

time = 18740	action = 0	current_phase = 1	next_phase = 0	reward = 0.368683	array([[-1.7366326, -2.8423893]], dtype=float32)

time = 18745	action = 1	current_phase = 1	next_phase = 0	reward = -1.250073	array([[-3.8051772, -2.7321277]], dtype=float32)

time = 18753	action = 0	current_phase = 0	next_phase = 1	reward = -0.586162	array([[-2.064959 , -2.1897228]], dtype=float32)

time = 18758	action = 0	current_phase = 0	next_phase = 1	reward = -0.426314	array([[-1.9291874, -2.203168 ]], dtype=float32)

time = 18763	action = 0	current_phase = 0	next_phase = 1	reward = -0.268187	array([[-1.8799187, -2.676537 ]], dtype=float32)

time = 18768	action = 0	current_phase = 0	next_phase = 1	reward = -0.165367	array([[-2.0892336, -2.4669065]], dtype=float32)

time = 18773	action = 0	current_phase = 0	next_phase = 1	reward = -0.067051	array([[-3.0013263, -3.2883987]], dtype=float32)

time = 18778	action = 1	current_phase = 0	next_phase = 1	reward = -1.898130	array([[-4.7797403, -3.440813 ]], dtype=float32)

time = 18786	action = 0	current_phase = 1	next_phase = 0	reward = -0.487369	array([[-2.0146103, -2.5399792]], dtype=float32)

time = 18791	action = 0	current_phase = 1	next_phase = 0	reward = -0.336162	array([[-1.8999686, -2.5527744]], dtype=float32)

time = 18796	action = 0	current_phase = 1	next_phase = 0	reward = -0.199245	array([[-2.0046217, -2.4636424]], dtype=float32)

time = 18801	action = 0	current_phase = 1	next_phase = 0	reward = 0.276042	array([[-2.3073306, -3.2495656]], dtype=float32)

time = 18806	action = 1	current_phase = 1	next_phase = 0	reward = -1.609057	array([[-4.7813754, -3.200856 ]], dtype=float32)

time = 18814	action = 0	current_phase = 0	next_phase = 1	reward = -0.553951	array([[-1.9356291, -2.14645  ]], dtype=float32)

time = 18819	action = 0	current_phase = 0	next_phase = 1	reward = -0.406909	array([[-1.9370781, -2.1493723]], dtype=float32)

time = 18824	action = 0	current_phase = 0	next_phase = 1	reward = -0.253686	array([[-1.8717188, -2.693354 ]], dtype=float32)

time = 18829	action = 0	current_phase = 0	next_phase = 1	reward = -0.166848	array([[-2.0563428, -2.4469113]], dtype=float32)

time = 18834	action = 1	current_phase = 0	next_phase = 1	reward = -0.363334	array([[-2.527856 , -2.2831283]], dtype=float32)

time = 18842	action = 0	current_phase = 1	next_phase = 0	reward = -0.625638	array([[-2.081961 , -2.4399648]], dtype=float32)

time = 18847	action = 0	current_phase = 1	next_phase = 0	reward = -0.458179	array([[-2.043271, -2.540772]], dtype=float32)

time = 18852	action = 0	current_phase = 1	next_phase = 0	reward = -0.306580	array([[-1.9821237, -2.4106774]], dtype=float32)

time = 18857	action = 0	current_phase = 1	next_phase = 0	reward = -0.177378	array([[-2.1793466, -2.3272986]], dtype=float32)

time = 18862	action = 0	current_phase = 1	next_phase = 0	reward = 0.186345	array([[-2.349204 , -3.1429017]], dtype=float32)

time = 18867	action = 1	current_phase = 1	next_phase = 0	reward = -1.784527	array([[-4.8914723, -3.3965638]], dtype=float32)

time = 18875	action = 0	current_phase = 0	next_phase = 1	reward = -0.533977	array([[-1.9870341, -2.1684897]], dtype=float32)

time = 18880	action = 0	current_phase = 0	next_phase = 1	reward = -0.372068	array([[-1.9320924, -2.1640484]], dtype=float32)

time = 18885	action = 0	current_phase = 0	next_phase = 1	reward = -0.231988	array([[-1.9990779, -2.6500897]], dtype=float32)

time = 18890	action = 0	current_phase = 0	next_phase = 1	reward = -0.233916	array([[-2.0359921, -2.451781 ]], dtype=float32)

time = 18895	action = 1	current_phase = 0	next_phase = 1	reward = -0.751120	array([[-2.820309, -2.622644]], dtype=float32)

time = 18903	action = 0	current_phase = 1	next_phase = 0	reward = -0.591637	array([[-2.0753136, -2.44556  ]], dtype=float32)

time = 18908	action = 0	current_phase = 1	next_phase = 0	reward = -0.442661	array([[-2.0496056, -2.446786 ]], dtype=float32)

time = 18913	action = 0	current_phase = 1	next_phase = 0	reward = -0.292016	array([[-1.959918 , -2.4634554]], dtype=float32)

time = 18918	action = 0	current_phase = 1	next_phase = 0	reward = -0.165953	array([[-2.1640744, -2.29534  ]], dtype=float32)

time = 18923	action = 0	current_phase = 1	next_phase = 0	reward = 0.028994	array([[-2.7094853, -3.093783 ]], dtype=float32)

time = 18928	action = 1	current_phase = 1	next_phase = 0	reward = -1.904228	array([[-4.856181 , -3.3869078]], dtype=float32)

time = 18936	action = 0	current_phase = 0	next_phase = 1	reward = -0.492758	array([[-1.9505905, -2.1288626]], dtype=float32)

time = 18941	action = 0	current_phase = 0	next_phase = 1	reward = -0.329857	array([[-1.9308056, -2.1830184]], dtype=float32)

time = 18946	action = 0	current_phase = 0	next_phase = 1	reward = -0.189206	array([[-2.0292203, -2.472077 ]], dtype=float32)

time = 18951	action = 0	current_phase = 0	next_phase = 1	reward = 0.296199	array([[-2.2374458, -2.699573 ]], dtype=float32)

time = 18956	action = 0	current_phase = 0	next_phase = 1	reward = -1.118987	array([[-3.1568227, -3.232262 ]], dtype=float32)

time = 18961	action = 1	current_phase = 0	next_phase = 1	reward = -2.070223	array([[-4.574879 , -3.4995728]], dtype=float32)

time = 18969	action = 0	current_phase = 1	next_phase = 0	reward = -0.406675	array([[-1.8491887, -2.5714915]], dtype=float32)

time = 18974	action = 0	current_phase = 1	next_phase = 0	reward = -0.249576	array([[-1.6638196, -2.5951242]], dtype=float32)

time = 18979	action = 0	current_phase = 1	next_phase = 0	reward = -0.166879	array([[-2.0129967, -2.379855 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0505 - val_loss: 0.0443

Epoch 2/50

 - 5s - loss: 0.0493 - val_loss: 0.0461

Epoch 3/50

 - 6s - loss: 0.0450 - val_loss: 0.0441

Epoch 4/50

 - 5s - loss: 0.0378 - val_loss: 0.0489

Epoch 5/50

 - 5s - loss: 0.0378 - val_loss: 0.0442

Epoch 6/50

 - 4s - loss: 0.0401 - val_loss: 0.0448

Epoch 7/50

 - 4s - loss: 0.0328 - val_loss: 0.0468

Epoch 8/50

 - 4s - loss: 0.0496 - val_loss: 0.0445

Epoch 9/50

 - 4s - loss: 0.0369 - val_loss: 0.0465

Epoch 10/50

 - 4s - loss: 0.0349 - val_loss: 0.0432

Epoch 11/50

 - 4s - loss: 0.0397 - val_loss: 0.0470

Epoch 12/50

 - 4s - loss: 0.0302 - val_loss: 0.0470

Epoch 13/50

 - 4s - loss: 0.0373 - val_loss: 0.0481

Epoch 14/50

 - 4s - loss: 0.0352 - val_loss: 0.0489

Epoch 15/50

 - 6s - loss: 0.0451 - val_loss: 0.0507

Epoch 16/50

 - 5s - loss: 0.0300 - val_loss: 0.0491

Epoch 17/50

 - 6s - loss: 0.0308 - val_loss: 0.0491

Epoch 18/50

 - 4s - loss: 0.0320 - val_loss: 0.0463

Epoch 19/50

 - 4s - loss: 0.0383 - val_loss: 0.0489

Epoch 20/50

 - 4s - loss: 0.0340 - val_loss: 0.0450

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 650, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 637, after forget

time = 18984	action = 1	current_phase = 1	next_phase = 0	reward = -0.362281	array([[-2.6279705, -2.1165493]], dtype=float32)

time = 18992	action = 0	current_phase = 0	next_phase = 1	reward = -0.628667	array([[-2.1652763, -2.202564 ]], dtype=float32)

time = 18997	action = 0	current_phase = 0	next_phase = 1	reward = -0.482502	array([[-1.9677656, -2.1313381]], dtype=float32)

time = 19002	action = 0	current_phase = 0	next_phase = 1	reward = -0.326345	array([[-1.9126364, -2.6533198]], dtype=float32)

time = 19007	action = 0	current_phase = 0	next_phase = 1	reward = -0.181362	array([[-2.1394382, -2.398498 ]], dtype=float32)

time = 19012	action = 0	current_phase = 0	next_phase = 1	reward = 0.249313	array([[-2.4964948, -3.4393306]], dtype=float32)

time = 19017	action = 1	current_phase = 0	next_phase = 1	reward = -1.724384	array([[-4.0002604, -3.1262288]], dtype=float32)

time = 19025	action = 0	current_phase = 1	next_phase = 0	reward = -0.519454	array([[-1.9376581, -2.4789531]], dtype=float32)

time = 19030	action = 0	current_phase = 1	next_phase = 0	reward = -0.364726	array([[-1.7610977, -2.6765885]], dtype=float32)

time = 19035	action = 0	current_phase = 1	next_phase = 0	reward = -0.212131	array([[-1.6514251, -2.631396 ]], dtype=float32)

time = 19040	action = 0	current_phase = 1	next_phase = 0	reward = 0.366271	array([[-1.7334576, -2.922426 ]], dtype=float32)

time = 19045	action = 1	current_phase = 1	next_phase = 0	reward = -1.311674	array([[-3.9412513, -2.8911932]], dtype=float32)

time = 19053	action = 0	current_phase = 0	next_phase = 1	reward = -0.595169	array([[-2.0737925, -2.1615381]], dtype=float32)

time = 19058	action = 0	current_phase = 0	next_phase = 1	reward = -0.445149	array([[-1.9649246, -2.1413116]], dtype=float32)

time = 19063	action = 0	current_phase = 0	next_phase = 1	reward = -0.285822	array([[-1.971429 , -2.6737752]], dtype=float32)

time = 19068	action = 0	current_phase = 0	next_phase = 1	reward = -0.163012	array([[-2.1638038, -2.432342 ]], dtype=float32)

time = 19073	action = 0	current_phase = 0	next_phase = 1	reward = -0.046295	array([[-3.1186109, -3.3333964]], dtype=float32)

time = 19078	action = 1	current_phase = 0	next_phase = 1	reward = -1.909778	array([[-4.8487916, -3.3985395]], dtype=float32)

time = 19086	action = 0	current_phase = 1	next_phase = 0	reward = -0.505978	array([[-1.9927356, -2.5549018]], dtype=float32)

time = 19091	action = 0	current_phase = 1	next_phase = 0	reward = -0.340685	array([[-1.6691823, -2.6589322]], dtype=float32)

time = 19096	action = 0	current_phase = 1	next_phase = 0	reward = -0.195472	array([[-1.771532, -2.582009]], dtype=float32)

time = 19101	action = 0	current_phase = 1	next_phase = 0	reward = 0.321293	array([[-2.1989932, -3.2670794]], dtype=float32)

time = 19106	action = 1	current_phase = 1	next_phase = 0	reward = -1.504533	array([[-4.7896976, -3.1909046]], dtype=float32)

time = 19114	action = 0	current_phase = 0	next_phase = 1	reward = -0.560700	array([[-1.986161 , -2.1237607]], dtype=float32)

time = 19119	action = 0	current_phase = 0	next_phase = 1	reward = -0.412644	array([[-1.964062 , -2.1851764]], dtype=float32)

time = 19124	action = 0	current_phase = 0	next_phase = 1	reward = -0.253219	array([[-1.9262519, -2.716731 ]], dtype=float32)

time = 19129	action = 0	current_phase = 0	next_phase = 1	reward = -0.180562	array([[-2.1254334, -2.4379802]], dtype=float32)

time = 19134	action = 1	current_phase = 0	next_phase = 1	reward = -0.566149	array([[-2.7150764, -2.3854947]], dtype=float32)

time = 19142	action = 0	current_phase = 1	next_phase = 0	reward = -0.611339	array([[-2.0654945, -2.455296 ]], dtype=float32)

time = 19147	action = 0	current_phase = 1	next_phase = 0	reward = -0.448162	array([[-1.9596941, -2.6128266]], dtype=float32)

time = 19152	action = 0	current_phase = 1	next_phase = 0	reward = -0.286681	array([[-1.9495273, -2.4779   ]], dtype=float32)

time = 19157	action = 0	current_phase = 1	next_phase = 0	reward = -0.164001	array([[-2.0747755, -2.3483722]], dtype=float32)

time = 19162	action = 0	current_phase = 1	next_phase = 0	reward = 0.242563	array([[-2.3016262, -3.1154058]], dtype=float32)

time = 19167	action = 1	current_phase = 1	next_phase = 0	reward = -1.777190	array([[-4.9073057, -3.3658907]], dtype=float32)

time = 19175	action = 1	current_phase = 0	next_phase = 1	reward = -1.748888	array([[-2.086232, -2.063058]], dtype=float32)

time = 19183	action = 0	current_phase = 1	next_phase = 0	reward = -0.264419	array([[-1.707721, -2.703149]], dtype=float32)

time = 19188	action = 0	current_phase = 1	next_phase = 0	reward = -0.162349	array([[-1.0976185, -2.77436  ]], dtype=float32)

time = 19193	action = 0	current_phase = 1	next_phase = 0	reward = 0.006135	array([[-2.2903683, -2.6718585]], dtype=float32)

time = 19198	action = 1	current_phase = 1	next_phase = 0	reward = -1.904905	array([[-3.857723 , -3.3686633]], dtype=float32)

time = 19206	action = 0	current_phase = 0	next_phase = 1	reward = -0.507822	array([[-2.0707457, -2.1621325]], dtype=float32)

time = 19211	action = 0	current_phase = 0	next_phase = 1	reward = -0.353407	array([[-1.9863206, -2.1436372]], dtype=float32)

time = 19216	action = 0	current_phase = 0	next_phase = 1	reward = -0.198582	array([[-2.134084 , -2.4030843]], dtype=float32)

time = 19221	action = 0	current_phase = 0	next_phase = 1	reward = 0.309256	array([[-2.2042356, -2.8298087]], dtype=float32)

time = 19226	action = 1	current_phase = 0	next_phase = 1	reward = -1.557426	array([[-3.2675407, -3.243637 ]], dtype=float32)

time = 19234	action = 0	current_phase = 1	next_phase = 0	reward = -0.552168	array([[-2.0494328, -2.498691 ]], dtype=float32)

time = 19239	action = 0	current_phase = 1	next_phase = 0	reward = -0.391429	array([[-1.8026776, -2.686795 ]], dtype=float32)

time = 19244	action = 0	current_phase = 1	next_phase = 0	reward = -0.239412	array([[-1.7515469, -2.5442944]], dtype=float32)

time = 19249	action = 0	current_phase = 1	next_phase = 0	reward = -0.182563	array([[-1.7723482, -2.8697076]], dtype=float32)

time = 19254	action = 1	current_phase = 1	next_phase = 0	reward = -0.482398	array([[-2.232558 , -1.9578996]], dtype=float32)

time = 19262	action = 0	current_phase = 0	next_phase = 1	reward = -0.622048	array([[-2.2096605, -2.2201433]], dtype=float32)

time = 19267	action = 0	current_phase = 0	next_phase = 1	reward = -0.479263	array([[-2.0385277, -2.178236 ]], dtype=float32)

time = 19272	action = 0	current_phase = 0	next_phase = 1	reward = -0.324874	array([[-2.025761, -2.401599]], dtype=float32)

time = 19277	action = 0	current_phase = 0	next_phase = 1	reward = -0.180044	array([[-2.1358473, -2.3884397]], dtype=float32)

time = 19282	action = 0	current_phase = 0	next_phase = 1	reward = 0.192393	array([[-2.5600047, -3.3707995]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0594 - val_loss: 0.0339

Epoch 2/50

 - 5s - loss: 0.0664 - val_loss: 0.0381

Epoch 3/50

 - 5s - loss: 0.0515 - val_loss: 0.0360

Epoch 4/50

 - 5s - loss: 0.0480 - val_loss: 0.0359

Epoch 5/50

 - 4s - loss: 0.0503 - val_loss: 0.0371

Epoch 6/50

 - 4s - loss: 0.0445 - val_loss: 0.0348

Epoch 7/50

 - 4s - loss: 0.0484 - val_loss: 0.0317

Epoch 8/50

 - 4s - loss: 0.0454 - val_loss: 0.0327

Epoch 9/50

 - 4s - loss: 0.0388 - val_loss: 0.0383

Epoch 10/50

 - 4s - loss: 0.0471 - val_loss: 0.0425

Epoch 11/50

 - 4s - loss: 0.0447 - val_loss: 0.0414

Epoch 12/50

 - 4s - loss: 0.0509 - val_loss: 0.0410

Epoch 13/50

 - 4s - loss: 0.0461 - val_loss: 0.0421

Epoch 14/50

 - 4s - loss: 0.0406 - val_loss: 0.0416

Epoch 15/50

 - 4s - loss: 0.0441 - val_loss: 0.0388

Epoch 16/50

 - 4s - loss: 0.0358 - val_loss: 0.0403

Epoch 17/50

 - 4s - loss: 0.0402 - val_loss: 0.0400

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 655, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 643, after forget

time = 19287	action = 1	current_phase = 0	next_phase = 1	reward = -1.776303	array([[-4.806354 , -3.3383515]], dtype=float32)

time = 19295	action = 0	current_phase = 1	next_phase = 0	reward = -0.517569	array([[-1.9975122, -2.4772594]], dtype=float32)

time = 19300	action = 0	current_phase = 1	next_phase = 0	reward = -0.361177	array([[-1.8010776, -2.6276178]], dtype=float32)

time = 19305	action = 0	current_phase = 1	next_phase = 0	reward = -0.205780	array([[-1.6641915, -2.5946848]], dtype=float32)

time = 19310	action = 0	current_phase = 1	next_phase = 0	reward = 0.352497	array([[-1.783497 , -2.9101222]], dtype=float32)

time = 19315	action = 1	current_phase = 1	next_phase = 0	reward = -1.367242	array([[-4.077532 , -2.9250982]], dtype=float32)

time = 19323	action = 0	current_phase = 0	next_phase = 1	reward = -0.586071	array([[-2.1507053, -2.1800938]], dtype=float32)

time = 19328	action = 0	current_phase = 0	next_phase = 1	reward = -0.430601	array([[-1.9458067, -2.1336582]], dtype=float32)

time = 19333	action = 0	current_phase = 0	next_phase = 1	reward = -0.273104	array([[-1.9497408, -2.7192543]], dtype=float32)

time = 19338	action = 0	current_phase = 0	next_phase = 1	reward = -0.165694	array([[-2.1189685, -2.4201741]], dtype=float32)

time = 19343	action = 0	current_phase = 0	next_phase = 1	reward = -0.004597	array([[-3.253871 , -3.4390812]], dtype=float32)

time = 19348	action = 1	current_phase = 0	next_phase = 1	reward = -1.899557	array([[-4.811466 , -3.4357064]], dtype=float32)

time = 19356	action = 0	current_phase = 1	next_phase = 0	reward = -0.494685	array([[-2.0678487, -2.5573142]], dtype=float32)

time = 19361	action = 0	current_phase = 1	next_phase = 0	reward = -0.346850	array([[-1.88456  , -2.6705346]], dtype=float32)

time = 19366	action = 0	current_phase = 1	next_phase = 0	reward = -0.204509	array([[-2.056879 , -2.4234147]], dtype=float32)

time = 19371	action = 0	current_phase = 1	next_phase = 0	reward = 0.319857	array([[-2.3454602, -3.2931821]], dtype=float32)

time = 19376	action = 1	current_phase = 1	next_phase = 0	reward = -1.608945	array([[-4.822027 , -3.1320724]], dtype=float32)

time = 19384	action = 0	current_phase = 0	next_phase = 1	reward = -0.561847	array([[-2.0497088, -2.143866 ]], dtype=float32)

time = 19389	action = 0	current_phase = 0	next_phase = 1	reward = -0.410033	array([[-1.9457335, -2.1101582]], dtype=float32)

time = 19394	action = 0	current_phase = 0	next_phase = 1	reward = -0.251687	array([[-1.9482507, -2.7336109]], dtype=float32)

time = 19399	action = 0	current_phase = 0	next_phase = 1	reward = -0.183884	array([[-2.1079688, -2.4322917]], dtype=float32)

time = 19404	action = 1	current_phase = 0	next_phase = 1	reward = -0.473356	array([[-2.819713 , -2.1888337]], dtype=float32)

time = 19412	action = 0	current_phase = 1	next_phase = 0	reward = -0.616087	array([[-2.1715286, -2.432801 ]], dtype=float32)

time = 19417	action = 0	current_phase = 1	next_phase = 0	reward = -0.464990	array([[-1.9056865, -2.638282 ]], dtype=float32)

time = 19422	action = 0	current_phase = 1	next_phase = 0	reward = -0.315837	array([[-1.9790603, -2.4241266]], dtype=float32)

time = 19427	action = 0	current_phase = 1	next_phase = 0	reward = -0.180687	array([[-2.1521664, -2.3526769]], dtype=float32)

time = 19432	action = 0	current_phase = 1	next_phase = 0	reward = 0.290321	array([[-2.3317282, -3.1146927]], dtype=float32)

time = 19437	action = 1	current_phase = 1	next_phase = 0	reward = -1.782793	array([[-5.014091 , -3.2687922]], dtype=float32)

time = 19445	action = 0	current_phase = 0	next_phase = 1	reward = -0.530041	array([[-2.0596864, -2.3777118]], dtype=float32)

time = 19450	action = 0	current_phase = 0	next_phase = 1	reward = -0.371151	array([[-1.9463938, -2.112046 ]], dtype=float32)

time = 19455	action = 0	current_phase = 0	next_phase = 1	reward = -0.221613	array([[-2.036774 , -2.4727314]], dtype=float32)

time = 19460	action = 0	current_phase = 0	next_phase = 1	reward = 0.364172	array([[-2.0614877, -2.5290363]], dtype=float32)

time = 19465	action = 1	current_phase = 0	next_phase = 1	reward = -1.309566	array([[-3.3219526, -2.8572185]], dtype=float32)

time = 19473	action = 0	current_phase = 1	next_phase = 0	reward = -0.596463	array([[-2.183051 , -2.4245071]], dtype=float32)

time = 19478	action = 0	current_phase = 1	next_phase = 0	reward = -0.451058	array([[-2.0748966, -2.4512873]], dtype=float32)

time = 19483	action = 0	current_phase = 1	next_phase = 0	reward = -0.306930	array([[-2.062361 , -2.4601116]], dtype=float32)

time = 19488	action = 0	current_phase = 1	next_phase = 0	reward = -0.178012	array([[-2.212327 , -2.3208783]], dtype=float32)

time = 19493	action = 0	current_phase = 1	next_phase = 0	reward = 0.025085	array([[-2.8055153, -3.034211 ]], dtype=float32)

time = 19498	action = 1	current_phase = 1	next_phase = 0	reward = -1.901334	array([[-4.9209723, -3.3954408]], dtype=float32)

time = 19506	action = 0	current_phase = 0	next_phase = 1	reward = -0.489304	array([[-2.0300374, -2.4176912]], dtype=float32)

time = 19511	action = 0	current_phase = 0	next_phase = 1	reward = -0.329274	array([[-1.9448625, -2.1335616]], dtype=float32)

time = 19516	action = 0	current_phase = 0	next_phase = 1	reward = -0.182627	array([[-2.0499458, -2.5307112]], dtype=float32)

time = 19521	action = 0	current_phase = 0	next_phase = 1	reward = 0.281865	array([[-2.2769387, -2.926266 ]], dtype=float32)

time = 19526	action = 1	current_phase = 0	next_phase = 1	reward = -1.663543	array([[-3.380457 , -3.2157753]], dtype=float32)

time = 19534	action = 0	current_phase = 1	next_phase = 0	reward = -0.554593	array([[-2.054506 , -2.4621754]], dtype=float32)

time = 19539	action = 0	current_phase = 1	next_phase = 0	reward = -0.399297	array([[-1.818431 , -2.6375566]], dtype=float32)

time = 19544	action = 0	current_phase = 1	next_phase = 0	reward = -0.249805	array([[-1.6933205, -2.574641 ]], dtype=float32)

time = 19549	action = 0	current_phase = 1	next_phase = 0	reward = -0.171586	array([[-1.8268241, -2.8552303]], dtype=float32)

time = 19554	action = 1	current_phase = 1	next_phase = 0	reward = -0.473598	array([[-2.3977213, -1.9377909]], dtype=float32)

time = 19562	action = 1	current_phase = 0	next_phase = 1	reward = -1.901748	array([[-2.2035816, -2.2008448]], dtype=float32)

time = 19570	action = 0	current_phase = 1	next_phase = 0	reward = -0.362042	array([[-1.8107516, -2.5559974]], dtype=float32)

time = 19575	action = 0	current_phase = 1	next_phase = 0	reward = -0.206570	array([[-1.8485906, -2.6725602]], dtype=float32)

time = 19580	action = 0	current_phase = 1	next_phase = 0	reward = 0.351966	array([[-1.4941107, -2.8249123]], dtype=float32)

time = 19585	action = 1	current_phase = 1	next_phase = 0	reward = -1.367413	array([[-3.9159267, -3.0690923]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0563 - val_loss: 0.0271

Epoch 2/50

 - 4s - loss: 0.0688 - val_loss: 0.0283

Epoch 3/50

 - 4s - loss: 0.0465 - val_loss: 0.0285

Epoch 4/50

 - 4s - loss: 0.0553 - val_loss: 0.0266

Epoch 5/50

 - 5s - loss: 0.0523 - val_loss: 0.0305

Epoch 6/50

 - 4s - loss: 0.0478 - val_loss: 0.0298

Epoch 7/50

 - 4s - loss: 0.0419 - val_loss: 0.0291

Epoch 8/50

 - 4s - loss: 0.0453 - val_loss: 0.0290

Epoch 9/50

 - 4s - loss: 0.0474 - val_loss: 0.0299

Epoch 10/50

 - 4s - loss: 0.0483 - val_loss: 0.0306

Epoch 11/50

 - 4s - loss: 0.0417 - val_loss: 0.0329

Epoch 12/50

 - 4s - loss: 0.0360 - val_loss: 0.0320

Epoch 13/50

 - 4s - loss: 0.0435 - val_loss: 0.0335

Epoch 14/50

 - 4s - loss: 0.0397 - val_loss: 0.0321

length of memory (state 0, action 0): 1017, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 661, after forget

length of memory (state 1, action 0): 1025, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 649, after forget

time = 19593	action = 0	current_phase = 0	next_phase = 1	reward = -0.597040	array([[-1.9021508, -2.1567173]], dtype=float32)

time = 19598	action = 0	current_phase = 0	next_phase = 1	reward = -0.449792	array([[-1.8651252, -2.1587195]], dtype=float32)

time = 19603	action = 0	current_phase = 0	next_phase = 1	reward = -0.294406	array([[-1.8847228, -2.7411835]], dtype=float32)

time = 19608	action = 0	current_phase = 0	next_phase = 1	reward = -0.164510	array([[-2.1375058, -2.4896457]], dtype=float32)

time = 19613	action = 0	current_phase = 0	next_phase = 1	reward = 0.200525	array([[-2.5710144, -3.3079884]], dtype=float32)

time = 19618	action = 1	current_phase = 0	next_phase = 1	reward = -1.890455	array([[-4.378002 , -3.2669528]], dtype=float32)

time = 19626	action = 0	current_phase = 1	next_phase = 0	reward = -0.490519	array([[-2.0303314, -2.616477 ]], dtype=float32)

time = 19631	action = 0	current_phase = 1	next_phase = 0	reward = -0.330941	array([[-1.7208183, -2.6601388]], dtype=float32)

time = 19636	action = 0	current_phase = 1	next_phase = 0	reward = -0.189735	array([[-1.6279298, -2.5714378]], dtype=float32)

time = 19641	action = 0	current_phase = 1	next_phase = 0	reward = 0.318735	array([[-2.02269  , -3.1992562]], dtype=float32)

time = 19646	action = 1	current_phase = 1	next_phase = 0	reward = -1.613703	array([[-4.5745907, -3.0802233]], dtype=float32)

time = 19654	action = 0	current_phase = 0	next_phase = 1	reward = -0.575231	array([[-2.0007768, -2.2257812]], dtype=float32)

time = 19659	action = 0	current_phase = 0	next_phase = 1	reward = -0.421708	array([[-1.8631374, -2.1553912]], dtype=float32)

time = 19664	action = 0	current_phase = 0	next_phase = 1	reward = -0.274604	array([[-1.875988 , -2.8136172]], dtype=float32)

time = 19669	action = 0	current_phase = 0	next_phase = 1	reward = -0.172089	array([[-2.0773513, -2.484211 ]], dtype=float32)

time = 19674	action = 1	current_phase = 0	next_phase = 1	reward = -0.473331	array([[-2.6643932, -2.2913692]], dtype=float32)

time = 19682	action = 0	current_phase = 1	next_phase = 0	reward = -0.623950	array([[-2.0009634, -2.4522653]], dtype=float32)

time = 19687	action = 0	current_phase = 1	next_phase = 0	reward = -0.462386	array([[-1.7774218, -2.7969966]], dtype=float32)

time = 19692	action = 0	current_phase = 1	next_phase = 0	reward = -0.301100	array([[-1.8898216, -2.5351155]], dtype=float32)

time = 19697	action = 0	current_phase = 1	next_phase = 0	reward = -0.169286	array([[-1.9508165, -2.3717952]], dtype=float32)

time = 19702	action = 0	current_phase = 1	next_phase = 0	reward = 0.112068	array([[-2.140229, -3.090843]], dtype=float32)

time = 19707	action = 1	current_phase = 1	next_phase = 0	reward = -1.783187	array([[-4.789922 , -3.2839723]], dtype=float32)

time = 19715	action = 0	current_phase = 0	next_phase = 1	reward = -0.512088	array([[-2.1653721, -2.5764542]], dtype=float32)

time = 19720	action = 0	current_phase = 0	next_phase = 1	reward = -0.354272	array([[-1.8656452, -2.1662831]], dtype=float32)

time = 19725	action = 0	current_phase = 0	next_phase = 1	reward = -0.207432	array([[-1.8414854, -2.725224 ]], dtype=float32)

time = 19730	action = 0	current_phase = 0	next_phase = 1	reward = 0.029566	array([[-2.0961297, -2.6500766]], dtype=float32)

time = 19735	action = 1	current_phase = 0	next_phase = 1	reward = -1.146557	array([[-2.869785 , -2.7415893]], dtype=float32)

time = 19743	action = 0	current_phase = 1	next_phase = 0	reward = -0.584961	array([[-2.0694468, -2.4731371]], dtype=float32)

time = 19748	action = 0	current_phase = 1	next_phase = 0	reward = -0.426316	array([[-1.7963525, -2.627665 ]], dtype=float32)

time = 19753	action = 0	current_phase = 1	next_phase = 0	reward = -0.267009	array([[-1.9204098, -2.4478621]], dtype=float32)

time = 19758	action = 0	current_phase = 1	next_phase = 0	reward = -0.159652	array([[-1.8841243, -2.4118073]], dtype=float32)

time = 19763	action = 0	current_phase = 1	next_phase = 0	reward = 0.079335	array([[-2.404039 , -3.0377343]], dtype=float32)

time = 19768	action = 1	current_phase = 1	next_phase = 0	reward = -1.893017	array([[-4.906678 , -3.3632514]], dtype=float32)

time = 19776	action = 0	current_phase = 0	next_phase = 1	reward = -0.492677	array([[-1.9291707, -2.4849513]], dtype=float32)

time = 19781	action = 0	current_phase = 0	next_phase = 1	reward = -0.343224	array([[-1.8772  , -2.165146]], dtype=float32)

time = 19786	action = 0	current_phase = 0	next_phase = 1	reward = -0.192028	array([[-1.9489397, -2.6260614]], dtype=float32)

time = 19791	action = 0	current_phase = 0	next_phase = 1	reward = 0.288065	array([[-2.2080429, -3.2984483]], dtype=float32)

time = 19796	action = 1	current_phase = 0	next_phase = 1	reward = -1.557190	array([[-3.4779222, -3.2443488]], dtype=float32)

time = 19804	action = 0	current_phase = 1	next_phase = 0	reward = -0.554079	array([[-1.9818678, -2.4808989]], dtype=float32)

time = 19809	action = 0	current_phase = 1	next_phase = 0	reward = -0.390597	array([[-1.7387582, -2.6691408]], dtype=float32)

time = 19814	action = 0	current_phase = 1	next_phase = 0	reward = -0.242436	array([[-1.5674838, -2.5911393]], dtype=float32)

time = 19819	action = 0	current_phase = 1	next_phase = 0	reward = -0.182405	array([[-1.682073, -2.930029]], dtype=float32)

time = 19824	action = 1	current_phase = 1	next_phase = 0	reward = -0.489937	array([[-2.0793107, -1.9347235]], dtype=float32)

time = 19832	action = 0	current_phase = 0	next_phase = 1	reward = -0.623599	array([[-2.1250749, -2.2895586]], dtype=float32)

time = 19837	action = 0	current_phase = 0	next_phase = 1	reward = -0.466764	array([[-1.8662912, -2.2129354]], dtype=float32)

time = 19842	action = 0	current_phase = 0	next_phase = 1	reward = -0.310192	array([[-1.9696226, -2.3818066]], dtype=float32)

time = 19847	action = 0	current_phase = 0	next_phase = 1	reward = -0.176110	array([[-2.0801566, -2.446087 ]], dtype=float32)

time = 19852	action = 0	current_phase = 0	next_phase = 1	reward = 0.252018	array([[-2.4148564, -3.3382993]], dtype=float32)

time = 19857	action = 1	current_phase = 0	next_phase = 1	reward = -1.780644	array([[-4.5887723, -3.239547 ]], dtype=float32)

time = 19865	action = 0	current_phase = 1	next_phase = 0	reward = -0.511050	array([[-1.8716376, -2.514594 ]], dtype=float32)

time = 19870	action = 0	current_phase = 1	next_phase = 0	reward = -0.353774	array([[-1.7260133, -2.6627476]], dtype=float32)

time = 19875	action = 0	current_phase = 1	next_phase = 0	reward = -0.205736	array([[-1.5640732, -2.5939426]], dtype=float32)

time = 19880	action = 0	current_phase = 1	next_phase = 0	reward = 0.340772	array([[-1.6699138, -2.9718268]], dtype=float32)

time = 19885	action = 1	current_phase = 1	next_phase = 0	reward = -1.367789	array([[-4.457162 , -2.9886153]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0650 - val_loss: 0.0588

Epoch 2/50

 - 4s - loss: 0.0470 - val_loss: 0.0541

Epoch 3/50

 - 4s - loss: 0.0425 - val_loss: 0.0533

Epoch 4/50

 - 4s - loss: 0.0440 - val_loss: 0.0602

Epoch 5/50

 - 4s - loss: 0.0416 - val_loss: 0.0581

Epoch 6/50

 - 4s - loss: 0.0432 - val_loss: 0.0622

Epoch 7/50

 - 4s - loss: 0.0406 - val_loss: 0.0573

Epoch 8/50

 - 4s - loss: 0.0301 - val_loss: 0.0576

Epoch 9/50

 - 4s - loss: 0.0347 - val_loss: 0.0564

Epoch 10/50

 - 4s - loss: 0.0317 - val_loss: 0.0596

Epoch 11/50

 - 4s - loss: 0.0309 - val_loss: 0.0577

Epoch 12/50

 - 4s - loss: 0.0355 - val_loss: 0.0558

Epoch 13/50

 - 4s - loss: 0.0351 - val_loss: 0.0586

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 666, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 654, after forget

time = 19893	action = 0	current_phase = 0	next_phase = 1	reward = -0.576447	array([[-2.137023 , -2.3014903]], dtype=float32)

time = 19898	action = 0	current_phase = 0	next_phase = 1	reward = -0.414629	array([[-1.9466803, -2.2177925]], dtype=float32)

time = 19903	action = 0	current_phase = 0	next_phase = 1	reward = -0.261155	array([[-1.907065 , -2.8343835]], dtype=float32)

time = 19908	action = 0	current_phase = 0	next_phase = 1	reward = -0.169797	array([[-2.1052575, -2.5191326]], dtype=float32)

time = 19913	action = 1	current_phase = 0	next_phase = 1	reward = -1.091490	array([[-2.915047 , -2.6613834]], dtype=float32)

time = 19921	action = 1	current_phase = 1	next_phase = 0	reward = -2.006172	array([[-2.805079 , -2.7548306]], dtype=float32)

time = 19929	action = 0	current_phase = 0	next_phase = 1	reward = -0.404648	array([[-1.9144075, -2.7446513]], dtype=float32)

time = 19934	action = 0	current_phase = 0	next_phase = 1	reward = -0.239039	array([[-2.4937923, -3.0217555]], dtype=float32)

time = 19939	action = 0	current_phase = 0	next_phase = 1	reward = -0.178081	array([[-1.7012132, -3.6144965]], dtype=float32)

time = 19944	action = 0	current_phase = 0	next_phase = 1	reward = -0.143705	array([[-1.1281193, -2.2642484]], dtype=float32)

time = 19949	action = 0	current_phase = 0	next_phase = 1	reward = -1.602106	array([[-2.9650779, -3.1546948]], dtype=float32)

time = 19954	action = 0	current_phase = 0	next_phase = 1	reward = -1.642830	array([[-3.3767788, -3.4475381]], dtype=float32)

time = 19959	action = 1	current_phase = 0	next_phase = 1	reward = -1.653141	array([[-4.0969596, -3.1044269]], dtype=float32)

time = 19967	action = 0	current_phase = 1	next_phase = 0	reward = -0.178369	array([[-1.9466201, -2.5409267]], dtype=float32)

time = 19972	action = 0	current_phase = 1	next_phase = 0	reward = 0.248169	array([[-2.2853985, -3.44564  ]], dtype=float32)

time = 19977	action = 1	current_phase = 1	next_phase = 0	reward = -1.773683	array([[-4.627196 , -3.2868285]], dtype=float32)

time = 19985	action = 0	current_phase = 0	next_phase = 1	reward = -0.516270	array([[-2.0239532, -2.4768991]], dtype=float32)

time = 19990	action = 0	current_phase = 0	next_phase = 1	reward = -0.366152	array([[-1.9512377, -2.2088737]], dtype=float32)

time = 19995	action = 0	current_phase = 0	next_phase = 1	reward = -0.225104	array([[-1.9184787, -2.8141809]], dtype=float32)

time = 20000	action = 0	current_phase = 0	next_phase = 1	reward = 0.362893	array([[-2.1101685, -2.7457843]], dtype=float32)

time = 20005	action = 1	current_phase = 0	next_phase = 1	reward = -1.359553	array([[-3.199714 , -2.9330568]], dtype=float32)

time = 20013	action = 0	current_phase = 1	next_phase = 0	reward = -0.586176	array([[-2.079852 , -2.5015442]], dtype=float32)

time = 20018	action = 0	current_phase = 1	next_phase = 0	reward = -0.445625	array([[-2.0028198, -2.5210176]], dtype=float32)

time = 20023	action = 0	current_phase = 1	next_phase = 0	reward = -0.292229	array([[-1.9455452, -2.4879308]], dtype=float32)

time = 20028	action = 0	current_phase = 1	next_phase = 0	reward = -0.167856	array([[-2.1145482, -2.4217172]], dtype=float32)

time = 20033	action = 0	current_phase = 1	next_phase = 0	reward = 0.142344	array([[-2.8122458, -3.1742878]], dtype=float32)

time = 20038	action = 1	current_phase = 1	next_phase = 0	reward = -1.895327	array([[-4.9105186, -3.4570034]], dtype=float32)

time = 20046	action = 0	current_phase = 0	next_phase = 1	reward = -0.502590	array([[-1.9964278, -2.5922575]], dtype=float32)

time = 20051	action = 0	current_phase = 0	next_phase = 1	reward = -0.354985	array([[-1.9449693, -2.2300153]], dtype=float32)

time = 20056	action = 0	current_phase = 0	next_phase = 1	reward = -0.203936	array([[-2.062968, -2.554562]], dtype=float32)

time = 20061	action = 0	current_phase = 0	next_phase = 1	reward = 0.340159	array([[-2.290469 , -2.9186473]], dtype=float32)

time = 20066	action = 1	current_phase = 0	next_phase = 1	reward = -1.449724	array([[-3.4271543, -3.1329408]], dtype=float32)

time = 20074	action = 0	current_phase = 1	next_phase = 0	reward = -0.557114	array([[-1.969863 , -2.4923656]], dtype=float32)

time = 20079	action = 0	current_phase = 1	next_phase = 0	reward = -0.399535	array([[-1.7685618, -2.693004 ]], dtype=float32)

time = 20084	action = 0	current_phase = 1	next_phase = 0	reward = -0.252469	array([[-1.7539996, -2.6018167]], dtype=float32)

time = 20089	action = 0	current_phase = 1	next_phase = 0	reward = -0.165718	array([[-2.0037694, -2.4867415]], dtype=float32)

time = 20094	action = 1	current_phase = 1	next_phase = 0	reward = -0.401844	array([[-2.4941587, -2.2745137]], dtype=float32)

time = 20102	action = 0	current_phase = 0	next_phase = 1	reward = -0.616524	array([[-2.1285653, -2.3008487]], dtype=float32)

time = 20107	action = 0	current_phase = 0	next_phase = 1	reward = -0.464291	array([[-1.9515554, -2.4592586]], dtype=float32)

time = 20112	action = 0	current_phase = 0	next_phase = 1	reward = -0.325106	array([[-1.943645 , -2.7531345]], dtype=float32)

time = 20117	action = 0	current_phase = 0	next_phase = 1	reward = -0.184612	array([[-2.1246214, -2.5535247]], dtype=float32)

time = 20122	action = 0	current_phase = 0	next_phase = 1	reward = 0.171644	array([[-2.4506273, -3.7257836]], dtype=float32)

time = 20127	action = 1	current_phase = 0	next_phase = 1	reward = -1.781910	array([[-4.5384264, -3.3930783]], dtype=float32)

time = 20135	action = 0	current_phase = 1	next_phase = 0	reward = -0.523358	array([[-1.9495595, -2.5153906]], dtype=float32)

time = 20140	action = 0	current_phase = 1	next_phase = 0	reward = -0.380776	array([[-1.756886, -2.691819]], dtype=float32)

time = 20145	action = 0	current_phase = 1	next_phase = 0	reward = -0.230458	array([[-1.6639677, -2.664887 ]], dtype=float32)

time = 20150	action = 0	current_phase = 1	next_phase = 0	reward = 0.367015	array([[-1.8201582, -2.9707115]], dtype=float32)

time = 20155	action = 1	current_phase = 1	next_phase = 0	reward = -1.307997	array([[-3.6090822, -2.8100984]], dtype=float32)

time = 20163	action = 0	current_phase = 0	next_phase = 1	reward = -0.592217	array([[-1.9885144, -2.2393417]], dtype=float32)

time = 20168	action = 0	current_phase = 0	next_phase = 1	reward = -0.429327	array([[-1.9463878, -2.333121 ]], dtype=float32)

time = 20173	action = 0	current_phase = 0	next_phase = 1	reward = -0.273956	array([[-1.9334586, -2.7819836]], dtype=float32)

time = 20178	action = 0	current_phase = 0	next_phase = 1	reward = -0.164615	array([[-2.1625824, -2.516758 ]], dtype=float32)

time = 20183	action = 0	current_phase = 0	next_phase = 1	reward = -0.055509	array([[-2.9711397, -2.9764626]], dtype=float32)

time = 20188	action = 1	current_phase = 0	next_phase = 1	reward = -1.899008	array([[-4.8668637, -3.3830686]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0477 - val_loss: 0.0375

Epoch 2/50

 - 4s - loss: 0.0394 - val_loss: 0.0404

Epoch 3/50

 - 4s - loss: 0.0393 - val_loss: 0.0376

Epoch 4/50

 - 4s - loss: 0.0456 - val_loss: 0.0379

Epoch 5/50

 - 4s - loss: 0.0410 - val_loss: 0.0382

Epoch 6/50

 - 4s - loss: 0.0650 - val_loss: 0.0400

Epoch 7/50

 - 4s - loss: 0.0564 - val_loss: 0.0401

Epoch 8/50

 - 4s - loss: 0.0418 - val_loss: 0.0404

Epoch 9/50

 - 4s - loss: 0.0365 - val_loss: 0.0378

Epoch 10/50

 - 4s - loss: 0.0325 - val_loss: 0.0378

Epoch 11/50

 - 4s - loss: 0.0472 - val_loss: 0.0389

length of memory (state 0, action 0): 1028, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 672, after forget

length of memory (state 1, action 0): 1015, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 659, after forget

time = 20196	action = 0	current_phase = 1	next_phase = 0	reward = -0.490975	array([[-2.0298696, -2.6555982]], dtype=float32)

time = 20201	action = 0	current_phase = 1	next_phase = 0	reward = -0.338613	array([[-1.9277358, -2.6660237]], dtype=float32)

time = 20206	action = 0	current_phase = 1	next_phase = 0	reward = -0.190080	array([[-2.0107937, -2.4858408]], dtype=float32)

time = 20211	action = 0	current_phase = 1	next_phase = 0	reward = 0.289795	array([[-2.25568 , -3.425858]], dtype=float32)

time = 20216	action = 1	current_phase = 1	next_phase = 0	reward = -1.662699	array([[-4.8330107, -3.187859 ]], dtype=float32)

time = 20224	action = 0	current_phase = 0	next_phase = 1	reward = -0.565023	array([[-2.036349 , -2.3146832]], dtype=float32)

time = 20229	action = 0	current_phase = 0	next_phase = 1	reward = -0.422887	array([[-2.0368567, -2.3206055]], dtype=float32)

time = 20234	action = 0	current_phase = 0	next_phase = 1	reward = -0.265827	array([[-2.2155142, -3.0867689]], dtype=float32)

time = 20239	action = 0	current_phase = 0	next_phase = 1	reward = -0.167689	array([[-2.0745661, -3.094501 ]], dtype=float32)

time = 20244	action = 1	current_phase = 0	next_phase = 1	reward = -0.481652	array([[-2.6186907, -2.5106306]], dtype=float32)

time = 20252	action = 0	current_phase = 1	next_phase = 0	reward = -0.610142	array([[-2.0880854, -2.5138793]], dtype=float32)

time = 20257	action = 0	current_phase = 1	next_phase = 0	reward = -0.460126	array([[-1.9634976, -2.5802326]], dtype=float32)

time = 20262	action = 0	current_phase = 1	next_phase = 0	reward = -0.304629	array([[-1.9384308, -2.5136266]], dtype=float32)

time = 20267	action = 0	current_phase = 1	next_phase = 0	reward = -0.171143	array([[-2.0692368, -2.4625916]], dtype=float32)

time = 20272	action = 0	current_phase = 1	next_phase = 0	reward = 0.193251	array([[-2.4973273, -3.3819685]], dtype=float32)

time = 20277	action = 1	current_phase = 1	next_phase = 0	reward = -1.725587	array([[-4.937498, -3.462246]], dtype=float32)

time = 20285	action = 0	current_phase = 0	next_phase = 1	reward = -0.513544	array([[-2.1057475, -2.615559 ]], dtype=float32)

time = 20290	action = 0	current_phase = 0	next_phase = 1	reward = -0.362863	array([[-2.036843 , -2.3207088]], dtype=float32)

time = 20295	action = 0	current_phase = 0	next_phase = 1	reward = -0.211008	array([[-2.0372925, -2.9652634]], dtype=float32)

time = 20300	action = 0	current_phase = 0	next_phase = 1	reward = 0.340980	array([[-2.2817113, -2.8919659]], dtype=float32)

time = 20305	action = 1	current_phase = 0	next_phase = 1	reward = -1.318185	array([[-3.3007965, -3.1902068]], dtype=float32)

time = 20313	action = 0	current_phase = 1	next_phase = 0	reward = -0.592122	array([[-2.1511652, -2.5010228]], dtype=float32)

time = 20318	action = 0	current_phase = 1	next_phase = 0	reward = -0.442046	array([[-1.9854621, -2.554028 ]], dtype=float32)

time = 20323	action = 0	current_phase = 1	next_phase = 0	reward = -0.286696	array([[-1.8683667, -2.4940357]], dtype=float32)

time = 20328	action = 0	current_phase = 1	next_phase = 0	reward = -0.170592	array([[-2.1220102, -2.412437 ]], dtype=float32)

time = 20333	action = 0	current_phase = 1	next_phase = 0	reward = 0.188534	array([[-2.639175 , -3.1986861]], dtype=float32)

time = 20338	action = 1	current_phase = 1	next_phase = 0	reward = -1.894364	array([[-4.943266, -3.454259]], dtype=float32)

time = 20346	action = 0	current_phase = 0	next_phase = 1	reward = -0.486718	array([[-2.1083872, -2.6690648]], dtype=float32)

time = 20351	action = 0	current_phase = 0	next_phase = 1	reward = -0.327921	array([[-2.0406866, -2.3262806]], dtype=float32)

time = 20356	action = 0	current_phase = 0	next_phase = 1	reward = -0.190224	array([[-2.1676962, -2.741095 ]], dtype=float32)

time = 20361	action = 0	current_phase = 0	next_phase = 1	reward = 0.270196	array([[-2.2819028, -3.3085854]], dtype=float32)

time = 20366	action = 1	current_phase = 0	next_phase = 1	reward = -1.665478	array([[-3.4286542, -3.222256 ]], dtype=float32)

time = 20374	action = 0	current_phase = 1	next_phase = 0	reward = -0.562753	array([[-1.9723512, -2.4437861]], dtype=float32)

time = 20379	action = 0	current_phase = 1	next_phase = 0	reward = -0.415522	array([[-1.8036581, -2.6897335]], dtype=float32)

time = 20384	action = 0	current_phase = 1	next_phase = 0	reward = -0.261777	array([[-1.7655447, -2.5580535]], dtype=float32)

time = 20389	action = 0	current_phase = 1	next_phase = 0	reward = -0.181329	array([[-1.8688878, -2.90799  ]], dtype=float32)

time = 20394	action = 1	current_phase = 1	next_phase = 0	reward = -0.515908	array([[-2.4506965, -2.1231256]], dtype=float32)

time = 20402	action = 0	current_phase = 0	next_phase = 1	reward = -0.621073	array([[-2.147512 , -2.3829858]], dtype=float32)

time = 20407	action = 0	current_phase = 0	next_phase = 1	reward = -0.459846	array([[-2.0320573, -2.3301928]], dtype=float32)

time = 20412	action = 0	current_phase = 0	next_phase = 1	reward = -0.305204	array([[-2.0777102, -2.703054 ]], dtype=float32)

time = 20417	action = 0	current_phase = 0	next_phase = 1	reward = -0.170184	array([[-2.28843  , -2.6117778]], dtype=float32)

time = 20422	action = 0	current_phase = 0	next_phase = 1	reward = 0.177785	array([[-2.6259978, -3.4636674]], dtype=float32)

time = 20427	action = 1	current_phase = 0	next_phase = 1	reward = -1.786578	array([[-4.8078146, -3.437867 ]], dtype=float32)

time = 20435	action = 0	current_phase = 1	next_phase = 0	reward = -0.532259	array([[-1.9622778, -2.5207825]], dtype=float32)

time = 20440	action = 0	current_phase = 1	next_phase = 0	reward = -0.383786	array([[-1.7857044, -2.681911 ]], dtype=float32)

time = 20445	action = 0	current_phase = 1	next_phase = 0	reward = -0.236660	array([[-1.6601322, -2.7039232]], dtype=float32)

time = 20450	action = 0	current_phase = 1	next_phase = 0	reward = 0.380642	array([[-1.8288527, -3.0585527]], dtype=float32)

time = 20455	action = 1	current_phase = 1	next_phase = 0	reward = -1.293664	array([[-3.6090572, -2.7793884]], dtype=float32)

time = 20463	action = 0	current_phase = 0	next_phase = 1	reward = -0.586532	array([[-2.0930908, -2.3490717]], dtype=float32)

time = 20468	action = 0	current_phase = 0	next_phase = 1	reward = -0.428514	array([[-2.0356264, -2.3144963]], dtype=float32)

time = 20473	action = 0	current_phase = 0	next_phase = 1	reward = -0.266740	array([[-1.9770484, -2.8744087]], dtype=float32)

time = 20478	action = 0	current_phase = 0	next_phase = 1	reward = -0.163991	array([[-2.2607236, -2.608622 ]], dtype=float32)

time = 20483	action = 0	current_phase = 0	next_phase = 1	reward = 0.059005	array([[-3.426684 , -3.5971644]], dtype=float32)

time = 20488	action = 1	current_phase = 0	next_phase = 1	reward = -1.906993	array([[-4.9076743, -3.4768257]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0479 - val_loss: 0.0293

Epoch 2/50

 - 4s - loss: 0.0495 - val_loss: 0.0267

Epoch 3/50

 - 4s - loss: 0.0629 - val_loss: 0.0309

Epoch 4/50

 - 4s - loss: 0.0533 - val_loss: 0.0272

Epoch 5/50

 - 4s - loss: 0.0417 - val_loss: 0.0299

Epoch 6/50

 - 4s - loss: 0.0542 - val_loss: 0.0288

Epoch 7/50

 - 4s - loss: 0.0508 - val_loss: 0.0307

Epoch 8/50

 - 4s - loss: 0.0367 - val_loss: 0.0286

Epoch 9/50

 - 4s - loss: 0.0479 - val_loss: 0.0272

Epoch 10/50

 - 4s - loss: 0.0398 - val_loss: 0.0277

Epoch 11/50

 - 4s - loss: 0.0475 - val_loss: 0.0271

Epoch 12/50

 - 4s - loss: 0.0450 - val_loss: 0.0283

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 677, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 664, after forget

time = 20496	action = 0	current_phase = 1	next_phase = 0	reward = -0.514016	array([[-2.0559816, -2.6972327]], dtype=float32)

time = 20501	action = 0	current_phase = 1	next_phase = 0	reward = -0.367837	array([[-1.8074474, -2.6273146]], dtype=float32)

time = 20506	action = 0	current_phase = 1	next_phase = 0	reward = -0.217033	array([[-1.7038293, -2.62844  ]], dtype=float32)

time = 20511	action = 0	current_phase = 1	next_phase = 0	reward = 0.345646	array([[-2.0705736, -3.2201562]], dtype=float32)

time = 20516	action = 1	current_phase = 1	next_phase = 0	reward = -1.492666	array([[-3.939536 , -2.9136734]], dtype=float32)

time = 20524	action = 0	current_phase = 0	next_phase = 1	reward = -0.542116	array([[-2.065305 , -2.3577666]], dtype=float32)

time = 20529	action = 0	current_phase = 0	next_phase = 1	reward = -0.388479	array([[-1.974913 , -2.3169906]], dtype=float32)

time = 20534	action = 0	current_phase = 0	next_phase = 1	reward = -0.238951	array([[-2.077346 , -3.0086734]], dtype=float32)

time = 20539	action = 0	current_phase = 0	next_phase = 1	reward = -0.187428	array([[-2.1152394, -2.64522  ]], dtype=float32)

time = 20544	action = 1	current_phase = 0	next_phase = 1	reward = -0.547889	array([[-2.733569, -2.480467]], dtype=float32)

time = 20552	action = 0	current_phase = 1	next_phase = 0	reward = -0.614512	array([[-2.02588 , -2.547192]], dtype=float32)

time = 20557	action = 0	current_phase = 1	next_phase = 0	reward = -0.455146	array([[-1.9876994, -2.766903 ]], dtype=float32)

time = 20562	action = 0	current_phase = 1	next_phase = 0	reward = -0.300737	array([[-1.9070392, -2.5092707]], dtype=float32)

time = 20567	action = 0	current_phase = 1	next_phase = 0	reward = -0.172954	array([[-2.1438403, -2.4678292]], dtype=float32)

time = 20572	action = 0	current_phase = 1	next_phase = 0	reward = 0.194306	array([[-2.3412368, -3.2987328]], dtype=float32)

time = 20577	action = 1	current_phase = 1	next_phase = 0	reward = -1.780796	array([[-5.0314445, -3.388597 ]], dtype=float32)

time = 20585	action = 0	current_phase = 0	next_phase = 1	reward = -0.518958	array([[-2.0590956, -2.6237092]], dtype=float32)

time = 20590	action = 0	current_phase = 0	next_phase = 1	reward = -0.358895	array([[-1.9743688, -2.3142498]], dtype=float32)

time = 20595	action = 0	current_phase = 0	next_phase = 1	reward = -0.213628	array([[-1.9140937, -2.8848937]], dtype=float32)

time = 20600	action = 0	current_phase = 0	next_phase = 1	reward = 0.350949	array([[-2.014389, -2.780975]], dtype=float32)

time = 20605	action = 1	current_phase = 0	next_phase = 1	reward = -1.368715	array([[-3.2560978, -3.0250347]], dtype=float32)

time = 20613	action = 0	current_phase = 1	next_phase = 0	reward = -0.595516	array([[-2.073319 , -2.5297818]], dtype=float32)

time = 20618	action = 0	current_phase = 1	next_phase = 0	reward = -0.440433	array([[-2.0095005, -2.540945 ]], dtype=float32)

time = 20623	action = 0	current_phase = 1	next_phase = 0	reward = -0.288189	array([[-1.9595642, -2.5547976]], dtype=float32)

time = 20628	action = 0	current_phase = 1	next_phase = 0	reward = -0.162992	array([[-2.1727896, -2.485969 ]], dtype=float32)

time = 20633	action = 0	current_phase = 1	next_phase = 0	reward = 0.088017	array([[-2.8398204, -2.9827685]], dtype=float32)

time = 20638	action = 1	current_phase = 1	next_phase = 0	reward = -1.897097	array([[-4.9106493, -3.4423323]], dtype=float32)

time = 20646	action = 0	current_phase = 0	next_phase = 1	reward = -0.496876	array([[-2.0317526, -2.637476 ]], dtype=float32)

time = 20651	action = 0	current_phase = 0	next_phase = 1	reward = -0.344119	array([[-1.9731454, -2.320524 ]], dtype=float32)

time = 20656	action = 0	current_phase = 0	next_phase = 1	reward = -0.193371	array([[-1.9391775, -2.8952794]], dtype=float32)

time = 20661	action = 0	current_phase = 0	next_phase = 1	reward = 0.283471	array([[-2.2321994, -3.1567228]], dtype=float32)

time = 20666	action = 1	current_phase = 0	next_phase = 1	reward = -1.666894	array([[-3.490847, -3.147233]], dtype=float32)

time = 20674	action = 0	current_phase = 1	next_phase = 0	reward = -0.565720	array([[-1.9629937, -2.5096025]], dtype=float32)

time = 20679	action = 0	current_phase = 1	next_phase = 0	reward = -0.412713	array([[-1.7428726, -2.7245612]], dtype=float32)

time = 20684	action = 0	current_phase = 1	next_phase = 0	reward = -0.260752	array([[-1.6242217, -2.6475134]], dtype=float32)

time = 20689	action = 0	current_phase = 1	next_phase = 0	reward = -0.170340	array([[-1.8758696, -2.950882 ]], dtype=float32)

time = 20694	action = 1	current_phase = 1	next_phase = 0	reward = -0.430623	array([[-2.3708084, -2.270237 ]], dtype=float32)

time = 20702	action = 0	current_phase = 0	next_phase = 1	reward = -0.612330	array([[-2.2170935, -2.4320614]], dtype=float32)

time = 20707	action = 0	current_phase = 0	next_phase = 1	reward = -0.456638	array([[-1.980297 , -2.3286326]], dtype=float32)

time = 20712	action = 0	current_phase = 0	next_phase = 1	reward = -0.296610	array([[-1.9950603, -2.606365 ]], dtype=float32)

time = 20717	action = 0	current_phase = 0	next_phase = 1	reward = -0.169933	array([[-2.159396 , -2.5672634]], dtype=float32)

time = 20722	action = 0	current_phase = 0	next_phase = 1	reward = 0.110933	array([[-2.469915 , -3.6096158]], dtype=float32)

time = 20727	action = 1	current_phase = 0	next_phase = 1	reward = -1.791578	array([[-4.9287133, -3.3886955]], dtype=float32)

time = 20735	action = 0	current_phase = 1	next_phase = 0	reward = -0.540978	array([[-1.9325242, -2.5298629]], dtype=float32)

time = 20740	action = 0	current_phase = 1	next_phase = 0	reward = -0.382923	array([[-1.7001548, -2.6989121]], dtype=float32)

time = 20745	action = 0	current_phase = 1	next_phase = 0	reward = -0.235114	array([[-1.6177672, -2.6554909]], dtype=float32)

time = 20750	action = 0	current_phase = 1	next_phase = 0	reward = 0.075125	array([[-1.8014275, -2.9764247]], dtype=float32)

time = 20755	action = 1	current_phase = 1	next_phase = 0	reward = -1.073136	array([[-3.193267 , -2.3954396]], dtype=float32)

time = 20763	action = 0	current_phase = 0	next_phase = 1	reward = -0.592699	array([[-2.1111674, -2.381104 ]], dtype=float32)

time = 20768	action = 0	current_phase = 0	next_phase = 1	reward = -0.448843	array([[-1.9769162, -2.3131766]], dtype=float32)

time = 20773	action = 0	current_phase = 0	next_phase = 1	reward = -0.307757	array([[-2.0463305, -2.6936104]], dtype=float32)

time = 20778	action = 0	current_phase = 0	next_phase = 1	reward = -0.175456	array([[-2.3418872, -2.7399788]], dtype=float32)

time = 20783	action = 0	current_phase = 0	next_phase = 1	reward = 0.105302	array([[-2.512516 , -3.4083278]], dtype=float32)

time = 20788	action = 1	current_phase = 0	next_phase = 1	reward = -1.893825	array([[-4.951448 , -3.4448888]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0657 - val_loss: 0.0155

Epoch 2/50

 - 4s - loss: 0.0647 - val_loss: 0.0150

Epoch 3/50

 - 4s - loss: 0.0433 - val_loss: 0.0162

Epoch 4/50

 - 4s - loss: 0.0431 - val_loss: 0.0184

Epoch 5/50

 - 4s - loss: 0.0376 - val_loss: 0.0158

Epoch 6/50

 - 4s - loss: 0.0416 - val_loss: 0.0168

Epoch 7/50

 - 4s - loss: 0.0435 - val_loss: 0.0182

Epoch 8/50

 - 4s - loss: 0.0500 - val_loss: 0.0163

Epoch 9/50

 - 4s - loss: 0.0445 - val_loss: 0.0178

Epoch 10/50

 - 4s - loss: 0.0416 - val_loss: 0.0158

Epoch 11/50

 - 4s - loss: 0.0407 - val_loss: 0.0171

Epoch 12/50

 - 4s - loss: 0.0422 - val_loss: 0.0171

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 682, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 669, after forget

time = 20796	action = 0	current_phase = 1	next_phase = 0	reward = -0.490129	array([[-2.0274436, -2.6607132]], dtype=float32)

time = 20801	action = 0	current_phase = 1	next_phase = 0	reward = -0.334395	array([[-1.7620022, -2.7051036]], dtype=float32)

time = 20806	action = 0	current_phase = 1	next_phase = 0	reward = -0.189538	array([[-2.0020087, -2.478008 ]], dtype=float32)

time = 20811	action = 0	current_phase = 1	next_phase = 0	reward = 0.316562	array([[-2.2555256, -3.3126256]], dtype=float32)

time = 20816	action = 1	current_phase = 1	next_phase = 0	reward = -1.561623	array([[-4.803214 , -3.2478337]], dtype=float32)

time = 20824	action = 0	current_phase = 0	next_phase = 1	reward = -0.572985	array([[-2.056803 , -2.3097875]], dtype=float32)

time = 20829	action = 0	current_phase = 0	next_phase = 1	reward = -0.416564	array([[-1.9971682, -2.289729 ]], dtype=float32)

time = 20834	action = 0	current_phase = 0	next_phase = 1	reward = -0.258675	array([[-1.934558, -2.896759]], dtype=float32)

time = 20839	action = 0	current_phase = 0	next_phase = 1	reward = -0.174963	array([[-2.1325629, -2.6242583]], dtype=float32)

time = 20844	action = 1	current_phase = 0	next_phase = 1	reward = -0.431885	array([[-2.856902, -2.43149 ]], dtype=float32)

time = 20852	action = 0	current_phase = 1	next_phase = 0	reward = -0.616702	array([[-2.0461285, -2.5419106]], dtype=float32)

time = 20857	action = 0	current_phase = 1	next_phase = 0	reward = -0.459384	array([[-1.8627112, -2.8603659]], dtype=float32)

time = 20862	action = 0	current_phase = 1	next_phase = 0	reward = -0.308353	array([[-1.9490831, -2.516949 ]], dtype=float32)

time = 20867	action = 0	current_phase = 1	next_phase = 0	reward = -0.181644	array([[-2.0755558, -2.5301816]], dtype=float32)

time = 20872	action = 0	current_phase = 1	next_phase = 0	reward = 0.230168	array([[-2.3497007, -3.3769963]], dtype=float32)

time = 20877	action = 1	current_phase = 1	next_phase = 0	reward = -1.729519	array([[-5.023544 , -3.3487597]], dtype=float32)

time = 20885	action = 0	current_phase = 0	next_phase = 1	reward = -0.526015	array([[-2.0249033, -2.6555402]], dtype=float32)

time = 20890	action = 0	current_phase = 0	next_phase = 1	reward = -0.376567	array([[-1.9957634, -2.29218  ]], dtype=float32)

time = 20895	action = 0	current_phase = 0	next_phase = 1	reward = -0.229526	array([[-2.0072255, -2.93969  ]], dtype=float32)

time = 20900	action = 0	current_phase = 0	next_phase = 1	reward = 0.063263	array([[-2.1050472, -2.559591 ]], dtype=float32)

time = 20905	action = 1	current_phase = 0	next_phase = 1	reward = -1.080785	array([[-3.211897, -2.470247]], dtype=float32)

time = 20913	action = 0	current_phase = 1	next_phase = 0	reward = -0.580084	array([[-2.121451, -2.503379]], dtype=float32)

time = 20918	action = 0	current_phase = 1	next_phase = 0	reward = -0.414832	array([[-1.9371967, -2.576821 ]], dtype=float32)

time = 20923	action = 0	current_phase = 1	next_phase = 0	reward = -0.261193	array([[-1.8834946, -2.5043738]], dtype=float32)

time = 20928	action = 0	current_phase = 1	next_phase = 0	reward = -0.164538	array([[-1.8864698, -2.549647 ]], dtype=float32)

time = 20933	action = 0	current_phase = 1	next_phase = 0	reward = -0.053121	array([[-2.6725276, -2.7085824]], dtype=float32)

time = 20938	action = 1	current_phase = 1	next_phase = 0	reward = -1.894730	array([[-4.965952 , -3.4452233]], dtype=float32)

time = 20946	action = 0	current_phase = 0	next_phase = 1	reward = -0.485256	array([[-1.9798174, -2.580664 ]], dtype=float32)

time = 20951	action = 0	current_phase = 0	next_phase = 1	reward = -0.330951	array([[-2.0016584, -2.293908 ]], dtype=float32)

time = 20956	action = 0	current_phase = 0	next_phase = 1	reward = -0.188982	array([[-2.088068 , -2.6089666]], dtype=float32)

time = 20961	action = 0	current_phase = 0	next_phase = 1	reward = 0.306681	array([[-2.3797483, -3.1513956]], dtype=float32)

time = 20966	action = 1	current_phase = 0	next_phase = 1	reward = -1.661869	array([[-3.5553827, -3.0630872]], dtype=float32)

time = 20974	action = 0	current_phase = 1	next_phase = 0	reward = -0.560626	array([[-1.9547863, -2.528459 ]], dtype=float32)

time = 20979	action = 0	current_phase = 1	next_phase = 0	reward = -0.408847	array([[-1.7200136, -2.720036 ]], dtype=float32)

time = 20984	action = 0	current_phase = 1	next_phase = 0	reward = -0.251404	array([[-1.6632457, -2.6728272]], dtype=float32)

time = 20989	action = 0	current_phase = 1	next_phase = 0	reward = -0.173515	array([[-1.824394 , -2.9663408]], dtype=float32)

time = 20994	action = 1	current_phase = 1	next_phase = 0	reward = -0.540888	array([[-2.1885395, -2.0162706]], dtype=float32)

time = 21002	action = 0	current_phase = 0	next_phase = 1	reward = -0.616639	array([[-2.1216311, -2.3456433]], dtype=float32)

time = 21007	action = 0	current_phase = 0	next_phase = 1	reward = -0.461469	array([[-2.0058734, -2.2995927]], dtype=float32)

time = 21012	action = 0	current_phase = 0	next_phase = 1	reward = -0.310492	array([[-1.9956495, -2.7417488]], dtype=float32)

time = 21017	action = 0	current_phase = 0	next_phase = 1	reward = -0.172243	array([[-2.1366231, -2.5191512]], dtype=float32)

time = 21022	action = 0	current_phase = 0	next_phase = 1	reward = 0.136808	array([[-2.430349, -3.843468]], dtype=float32)

time = 21027	action = 1	current_phase = 0	next_phase = 1	reward = -1.789628	array([[-5.058339 , -3.3011417]], dtype=float32)

time = 21035	action = 0	current_phase = 1	next_phase = 0	reward = -0.535315	array([[-1.911052 , -2.5383408]], dtype=float32)

time = 21040	action = 0	current_phase = 1	next_phase = 0	reward = -0.379417	array([[-1.6218009, -2.6702468]], dtype=float32)

time = 21045	action = 0	current_phase = 1	next_phase = 0	reward = -0.225699	array([[-1.6380646, -2.676733 ]], dtype=float32)

time = 21050	action = 0	current_phase = 1	next_phase = 0	reward = 0.082320	array([[-1.7653906, -3.0146124]], dtype=float32)

time = 21055	action = 1	current_phase = 1	next_phase = 0	reward = -0.965116	array([[-3.4167628, -2.4257596]], dtype=float32)

time = 21063	action = 0	current_phase = 0	next_phase = 1	reward = -0.580161	array([[-2.1119604, -2.3401203]], dtype=float32)

time = 21068	action = 0	current_phase = 0	next_phase = 1	reward = -0.427730	array([[-1.9964012, -2.2998557]], dtype=float32)

time = 21073	action = 0	current_phase = 0	next_phase = 1	reward = -0.285998	array([[-1.9324973, -2.8899817]], dtype=float32)

time = 21078	action = 0	current_phase = 0	next_phase = 1	reward = -0.167255	array([[-2.1707215, -2.5710387]], dtype=float32)

time = 21083	action = 0	current_phase = 0	next_phase = 1	reward = 0.021811	array([[-3.0593848, -3.2931912]], dtype=float32)

time = 21088	action = 1	current_phase = 0	next_phase = 1	reward = -1.896662	array([[-4.9776616, -3.4120383]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0533 - val_loss: 0.0217

Epoch 2/50

 - 4s - loss: 0.0429 - val_loss: 0.0219

Epoch 3/50

 - 4s - loss: 0.0400 - val_loss: 0.0219

Epoch 4/50

 - 5s - loss: 0.0454 - val_loss: 0.0252

Epoch 5/50

 - 6s - loss: 0.0533 - val_loss: 0.0234

Epoch 6/50

 - 4s - loss: 0.0397 - val_loss: 0.0246

Epoch 7/50

 - 4s - loss: 0.0389 - val_loss: 0.0230

Epoch 8/50

 - 4s - loss: 0.0432 - val_loss: 0.0233

Epoch 9/50

 - 4s - loss: 0.0448 - val_loss: 0.0239

Epoch 10/50

 - 4s - loss: 0.0345 - val_loss: 0.0229

Epoch 11/50

 - 4s - loss: 0.0412 - val_loss: 0.0249

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 687, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 674, after forget

time = 21096	action = 0	current_phase = 1	next_phase = 0	reward = -0.490186	array([[-2.0699072, -2.7266202]], dtype=float32)

time = 21101	action = 0	current_phase = 1	next_phase = 0	reward = -0.333771	array([[-2.0129197, -2.719245 ]], dtype=float32)

time = 21106	action = 0	current_phase = 1	next_phase = 0	reward = -0.182659	array([[-2.0122087, -2.562218 ]], dtype=float32)

time = 21111	action = 0	current_phase = 1	next_phase = 0	reward = 0.299703	array([[-2.3308465, -3.3689728]], dtype=float32)

time = 21116	action = 1	current_phase = 1	next_phase = 0	reward = -1.666267	array([[-4.8667855, -3.1827586]], dtype=float32)

time = 21124	action = 0	current_phase = 0	next_phase = 1	reward = -0.562010	array([[-2.0252545, -2.3335154]], dtype=float32)

time = 21129	action = 0	current_phase = 0	next_phase = 1	reward = -0.411843	array([[-2.01296  , -2.3297703]], dtype=float32)

time = 21134	action = 0	current_phase = 0	next_phase = 1	reward = -0.259846	array([[-1.9724168, -2.9508832]], dtype=float32)

time = 21139	action = 0	current_phase = 0	next_phase = 1	reward = -0.175845	array([[-2.154897 , -2.8424835]], dtype=float32)

time = 21144	action = 1	current_phase = 0	next_phase = 1	reward = -0.519635	array([[-2.954127 , -2.0877802]], dtype=float32)

time = 21152	action = 0	current_phase = 1	next_phase = 0	reward = -0.614567	array([[-2.050149 , -2.5667944]], dtype=float32)

time = 21157	action = 0	current_phase = 1	next_phase = 0	reward = -0.454447	array([[-1.9427894, -2.8623495]], dtype=float32)

time = 21162	action = 0	current_phase = 1	next_phase = 0	reward = -0.296725	array([[-1.9703133, -2.5315914]], dtype=float32)

time = 21167	action = 0	current_phase = 1	next_phase = 0	reward = -0.168304	array([[-2.1534085, -2.4876823]], dtype=float32)

time = 21172	action = 0	current_phase = 1	next_phase = 0	reward = 0.232426	array([[-2.5652952, -3.3074765]], dtype=float32)

time = 21177	action = 1	current_phase = 1	next_phase = 0	reward = -1.727511	array([[-5.0356364, -3.375545 ]], dtype=float32)

time = 21185	action = 0	current_phase = 0	next_phase = 1	reward = -0.525923	array([[-2.0599604, -2.707117 ]], dtype=float32)

time = 21190	action = 0	current_phase = 0	next_phase = 1	reward = -0.374309	array([[-2.0015547, -2.3801825]], dtype=float32)

time = 21195	action = 0	current_phase = 0	next_phase = 1	reward = -0.217970	array([[-2.0197387, -2.944403 ]], dtype=float32)

time = 21200	action = 0	current_phase = 0	next_phase = 1	reward = 0.054733	array([[-2.1043258, -2.784029 ]], dtype=float32)

time = 21205	action = 1	current_phase = 0	next_phase = 1	reward = -1.088493	array([[-3.259488, -2.917576]], dtype=float32)

time = 21213	action = 0	current_phase = 1	next_phase = 0	reward = -0.585233	array([[-2.2183192, -2.4982677]], dtype=float32)

time = 21218	action = 0	current_phase = 1	next_phase = 0	reward = -0.431063	array([[-2.0108833, -2.5630162]], dtype=float32)

time = 21223	action = 0	current_phase = 1	next_phase = 0	reward = -0.277072	array([[-1.9724323, -2.5496583]], dtype=float32)

time = 21228	action = 0	current_phase = 1	next_phase = 0	reward = -0.167453	array([[-2.154999 , -2.4729252]], dtype=float32)

time = 21233	action = 0	current_phase = 1	next_phase = 0	reward = 0.146798	array([[-2.6886609, -2.9951437]], dtype=float32)

time = 21238	action = 1	current_phase = 1	next_phase = 0	reward = -1.901703	array([[-5.1149383, -3.3967292]], dtype=float32)

time = 21246	action = 0	current_phase = 0	next_phase = 1	reward = -0.508038	array([[-2.038076 , -2.7244647]], dtype=float32)

time = 21251	action = 0	current_phase = 0	next_phase = 1	reward = -0.353695	array([[-2.026898 , -2.3522704]], dtype=float32)

time = 21256	action = 0	current_phase = 0	next_phase = 1	reward = -0.210577	array([[-2.002881 , -2.9108908]], dtype=float32)

time = 21261	action = 0	current_phase = 0	next_phase = 1	reward = 0.327486	array([[-2.3641496, -2.9358938]], dtype=float32)

time = 21266	action = 1	current_phase = 0	next_phase = 1	reward = -1.557587	array([[-3.6168358, -3.2992933]], dtype=float32)

time = 21274	action = 0	current_phase = 1	next_phase = 0	reward = -0.571009	array([[-1.7767247, -2.2531493]], dtype=float32)

time = 21279	action = 0	current_phase = 1	next_phase = 0	reward = -0.419898	array([[-1.7893538, -2.74982  ]], dtype=float32)

time = 21284	action = 0	current_phase = 1	next_phase = 0	reward = -0.263760	array([[-1.7279289, -2.6495776]], dtype=float32)

time = 21289	action = 0	current_phase = 1	next_phase = 0	reward = -0.181962	array([[-1.9293181, -2.7607937]], dtype=float32)

time = 21294	action = 1	current_phase = 1	next_phase = 0	reward = -0.485605	array([[-2.091889 , -2.0033722]], dtype=float32)

time = 21302	action = 0	current_phase = 0	next_phase = 1	reward = -0.619038	array([[-2.3369558, -2.4853375]], dtype=float32)

time = 21307	action = 0	current_phase = 0	next_phase = 1	reward = -0.468910	array([[-2.016857 , -2.3519723]], dtype=float32)

time = 21312	action = 0	current_phase = 0	next_phase = 1	reward = -0.320021	array([[-2.0072663, -2.6987767]], dtype=float32)

time = 21317	action = 0	current_phase = 0	next_phase = 1	reward = -0.182021	array([[-2.1347501, -2.826285 ]], dtype=float32)

time = 21322	action = 0	current_phase = 0	next_phase = 1	reward = 0.232706	array([[-2.6531768, -3.5300338]], dtype=float32)

time = 21327	action = 1	current_phase = 0	next_phase = 1	reward = -1.782824	array([[-4.657488 , -3.2602544]], dtype=float32)

time = 21335	action = 0	current_phase = 1	next_phase = 0	reward = -0.523300	array([[-1.9514899, -2.5476294]], dtype=float32)

time = 21340	action = 0	current_phase = 1	next_phase = 0	reward = -0.361775	array([[-1.7440476, -2.7284386]], dtype=float32)

time = 21345	action = 0	current_phase = 1	next_phase = 0	reward = -0.213082	array([[-1.6663531, -2.680293 ]], dtype=float32)

time = 21350	action = 0	current_phase = 1	next_phase = 0	reward = 0.340762	array([[-1.8763417, -3.0597887]], dtype=float32)

time = 21355	action = 1	current_phase = 1	next_phase = 0	reward = -1.369981	array([[-3.976425, -2.901543]], dtype=float32)

time = 21363	action = 0	current_phase = 0	next_phase = 1	reward = -0.582992	array([[-2.086396 , -2.3834765]], dtype=float32)

time = 21368	action = 0	current_phase = 0	next_phase = 1	reward = -0.426365	array([[-2.0124826, -2.3362768]], dtype=float32)

time = 21373	action = 0	current_phase = 0	next_phase = 1	reward = -0.280123	array([[-1.9928395, -2.9098775]], dtype=float32)

time = 21378	action = 0	current_phase = 0	next_phase = 1	reward = -0.168761	array([[-2.1440237, -2.5963078]], dtype=float32)

time = 21383	action = 0	current_phase = 0	next_phase = 1	reward = 0.112377	array([[-2.8289046, -3.5960352]], dtype=float32)

time = 21388	action = 1	current_phase = 0	next_phase = 1	reward = -1.903359	array([[-4.959612, -3.391221]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0648 - val_loss: 0.0182

Epoch 2/50

 - 4s - loss: 0.0644 - val_loss: 0.0170

Epoch 3/50

 - 4s - loss: 0.0656 - val_loss: 0.0179

Epoch 4/50

 - 4s - loss: 0.0677 - val_loss: 0.0186

Epoch 5/50

 - 4s - loss: 0.0504 - val_loss: 0.0188

Epoch 6/50

 - 4s - loss: 0.0519 - val_loss: 0.0197

Epoch 7/50

 - 4s - loss: 0.0583 - val_loss: 0.0191

Epoch 8/50

 - 4s - loss: 0.0506 - val_loss: 0.0201

Epoch 9/50

 - 4s - loss: 0.0392 - val_loss: 0.0197

Epoch 10/50

 - 4s - loss: 0.0353 - val_loss: 0.0207

Epoch 11/50

 - 4s - loss: 0.0403 - val_loss: 0.0196

Epoch 12/50

 - 4s - loss: 0.0392 - val_loss: 0.0206

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 692, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 679, after forget

time = 21396	action = 0	current_phase = 1	next_phase = 0	reward = -0.504326	array([[-2.0758266, -2.7014832]], dtype=float32)

time = 21401	action = 0	current_phase = 1	next_phase = 0	reward = -0.350590	array([[-1.7004972, -2.748818 ]], dtype=float32)

time = 21406	action = 0	current_phase = 1	next_phase = 0	reward = -0.204733	array([[-2.0142434, -2.5893078]], dtype=float32)

time = 21411	action = 0	current_phase = 1	next_phase = 0	reward = 0.332684	array([[-2.0693169, -3.2789571]], dtype=float32)

time = 21416	action = 1	current_phase = 1	next_phase = 0	reward = -1.502114	array([[-4.8641486, -3.2706397]], dtype=float32)

time = 21424	action = 0	current_phase = 0	next_phase = 1	reward = -0.556441	array([[-2.0803847, -2.3727667]], dtype=float32)

time = 21429	action = 0	current_phase = 0	next_phase = 1	reward = -0.396912	array([[-2.0825152, -2.3818111]], dtype=float32)

time = 21434	action = 0	current_phase = 0	next_phase = 1	reward = -0.238246	array([[-2.0703564, -3.0636694]], dtype=float32)

time = 21439	action = 0	current_phase = 0	next_phase = 1	reward = -0.179510	array([[-2.3148916, -2.9555879]], dtype=float32)

time = 21444	action = 1	current_phase = 0	next_phase = 1	reward = -0.540260	array([[-3.070669 , -2.1686037]], dtype=float32)

time = 21452	action = 0	current_phase = 1	next_phase = 0	reward = -0.623953	array([[-2.1243932, -2.54439  ]], dtype=float32)

time = 21457	action = 0	current_phase = 1	next_phase = 0	reward = -0.469561	array([[-2.1054413, -2.7807052]], dtype=float32)

time = 21462	action = 0	current_phase = 1	next_phase = 0	reward = -0.315126	array([[-2.0461667, -2.5415568]], dtype=float32)

time = 21467	action = 0	current_phase = 1	next_phase = 0	reward = -0.176822	array([[-2.1180656, -2.533913 ]], dtype=float32)

time = 21472	action = 0	current_phase = 1	next_phase = 0	reward = 0.261859	array([[-2.3345256, -3.3379145]], dtype=float32)

time = 21477	action = 1	current_phase = 1	next_phase = 0	reward = -1.779169	array([[-5.094804, -3.474356]], dtype=float32)

time = 21485	action = 0	current_phase = 0	next_phase = 1	reward = -0.524071	array([[-2.2291276, -2.792996 ]], dtype=float32)

time = 21490	action = 0	current_phase = 0	next_phase = 1	reward = -0.369804	array([[-2.0840816, -2.3834217]], dtype=float32)

time = 21495	action = 0	current_phase = 0	next_phase = 1	reward = -0.218442	array([[-2.0295975, -3.0313113]], dtype=float32)

time = 21500	action = 0	current_phase = 0	next_phase = 1	reward = 0.347712	array([[-2.157555 , -2.8373497]], dtype=float32)

time = 21505	action = 1	current_phase = 0	next_phase = 1	reward = -1.420099	array([[-3.5206776, -3.1293762]], dtype=float32)

time = 21513	action = 0	current_phase = 1	next_phase = 0	reward = -0.587125	array([[-2.2896988, -2.4819565]], dtype=float32)

time = 21518	action = 0	current_phase = 1	next_phase = 0	reward = -0.429981	array([[-2.0789604, -2.55939  ]], dtype=float32)

time = 21523	action = 0	current_phase = 1	next_phase = 0	reward = -0.270361	array([[-2.060605 , -2.5473542]], dtype=float32)

time = 21528	action = 0	current_phase = 1	next_phase = 0	reward = -0.163704	array([[-2.1382248, -2.5453713]], dtype=float32)

time = 21533	action = 0	current_phase = 1	next_phase = 0	reward = 0.049465	array([[-2.6941133, -3.1620338]], dtype=float32)

time = 21538	action = 1	current_phase = 1	next_phase = 0	reward = -1.897130	array([[-5.0282006, -3.5443432]], dtype=float32)

time = 21546	action = 0	current_phase = 0	next_phase = 1	reward = -0.492559	array([[-2.1825097, -2.776978 ]], dtype=float32)

time = 21551	action = 0	current_phase = 0	next_phase = 1	reward = -0.331575	array([[-2.0951343, -2.3850706]], dtype=float32)

time = 21556	action = 0	current_phase = 0	next_phase = 1	reward = -0.189021	array([[-2.0817323, -2.9755392]], dtype=float32)

time = 21561	action = 0	current_phase = 0	next_phase = 1	reward = 0.286493	array([[-2.4515376, -3.1365182]], dtype=float32)

time = 21566	action = 1	current_phase = 0	next_phase = 1	reward = -1.610593	array([[-3.6806118, -3.2198727]], dtype=float32)

time = 21574	action = 0	current_phase = 1	next_phase = 0	reward = -0.554266	array([[-2.0640402, -2.5277884]], dtype=float32)

time = 21579	action = 0	current_phase = 1	next_phase = 0	reward = -0.411765	array([[-1.8511906, -2.7511735]], dtype=float32)

time = 21584	action = 0	current_phase = 1	next_phase = 0	reward = -0.271599	array([[-1.8495741, -2.6049662]], dtype=float32)

time = 21589	action = 0	current_phase = 1	next_phase = 0	reward = 0.113124	array([[-2.0178654, -2.9560492]], dtype=float32)

time = 21594	action = 1	current_phase = 1	next_phase = 0	reward = -0.697672	array([[-2.834863 , -2.4234319]], dtype=float32)

time = 21602	action = 0	current_phase = 0	next_phase = 1	reward = -0.628884	array([[-2.2560196, -2.4663396]], dtype=float32)

time = 21607	action = 0	current_phase = 0	next_phase = 1	reward = -0.477487	array([[-2.078571 , -2.4612868]], dtype=float32)

time = 21612	action = 0	current_phase = 0	next_phase = 1	reward = -0.327408	array([[-2.1750116, -2.7509506]], dtype=float32)

time = 21617	action = 0	current_phase = 0	next_phase = 1	reward = -0.184393	array([[-2.3177361, -2.8552685]], dtype=float32)

time = 21622	action = 0	current_phase = 0	next_phase = 1	reward = 0.279665	array([[-2.4428208, -3.6458442]], dtype=float32)

time = 21627	action = 1	current_phase = 0	next_phase = 1	reward = -1.727252	array([[-4.6288924, -3.4870918]], dtype=float32)

time = 21635	action = 0	current_phase = 1	next_phase = 0	reward = -0.522504	array([[-1.965647 , -2.6465793]], dtype=float32)

time = 21640	action = 0	current_phase = 1	next_phase = 0	reward = -0.364992	array([[-1.8148842, -2.762033 ]], dtype=float32)

time = 21645	action = 0	current_phase = 1	next_phase = 0	reward = -0.218270	array([[-1.7153761, -2.709067 ]], dtype=float32)

time = 21650	action = 0	current_phase = 1	next_phase = 0	reward = 0.339646	array([[-1.9400125, -3.1038458]], dtype=float32)

time = 21655	action = 1	current_phase = 1	next_phase = 0	reward = -1.370770	array([[-3.990149, -2.910571]], dtype=float32)

time = 21663	action = 0	current_phase = 0	next_phase = 1	reward = -0.588868	array([[-2.1685088, -2.424879 ]], dtype=float32)

time = 21668	action = 0	current_phase = 0	next_phase = 1	reward = -0.423903	array([[-2.082819 , -2.3859866]], dtype=float32)

time = 21673	action = 0	current_phase = 0	next_phase = 1	reward = -0.261164	array([[-2.0719674, -3.0301971]], dtype=float32)

time = 21678	action = 0	current_phase = 0	next_phase = 1	reward = -0.160432	array([[-2.1297817, -2.7704587]], dtype=float32)

time = 21683	action = 0	current_phase = 0	next_phase = 1	reward = 0.004951	array([[-2.980408 , -3.3988676]], dtype=float32)

time = 21688	action = 1	current_phase = 0	next_phase = 1	reward = -1.898874	array([[-5.082843 , -3.5944278]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0337 - val_loss: 0.0310

Epoch 2/50

 - 4s - loss: 0.0404 - val_loss: 0.0320

Epoch 3/50

 - 4s - loss: 0.0351 - val_loss: 0.0331

Epoch 4/50

 - 4s - loss: 0.0477 - val_loss: 0.0294

Epoch 5/50

 - 4s - loss: 0.0268 - val_loss: 0.0372

Epoch 6/50

 - 4s - loss: 0.0297 - val_loss: 0.0334

Epoch 7/50

 - 4s - loss: 0.0352 - val_loss: 0.0338

Epoch 8/50

 - 4s - loss: 0.0332 - val_loss: 0.0374

Epoch 9/50

 - 4s - loss: 0.0325 - val_loss: 0.0351

Epoch 10/50

 - 4s - loss: 0.0379 - val_loss: 0.0322

Epoch 11/50

 - 4s - loss: 0.0279 - val_loss: 0.0356

Epoch 12/50

 - 4s - loss: 0.0305 - val_loss: 0.0329

Epoch 13/50

 - 4s - loss: 0.0297 - val_loss: 0.0342

Epoch 14/50

 - 4s - loss: 0.0291 - val_loss: 0.0373

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 697, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 684, after forget

time = 21696	action = 0	current_phase = 1	next_phase = 0	reward = -0.499633	array([[-2.0344286, -2.7428684]], dtype=float32)

time = 21701	action = 0	current_phase = 1	next_phase = 0	reward = -0.352314	array([[-1.9608923, -2.6215677]], dtype=float32)

time = 21706	action = 0	current_phase = 1	next_phase = 0	reward = -0.204310	array([[-1.9636925, -2.6295152]], dtype=float32)

time = 21711	action = 0	current_phase = 1	next_phase = 0	reward = 0.291158	array([[-2.3655622, -3.4032083]], dtype=float32)

time = 21716	action = 1	current_phase = 1	next_phase = 0	reward = -1.609871	array([[-4.891934 , -3.2552996]], dtype=float32)

time = 21724	action = 0	current_phase = 0	next_phase = 1	reward = -0.564077	array([[-2.1037145, -2.3891578]], dtype=float32)

time = 21729	action = 0	current_phase = 0	next_phase = 1	reward = -0.407190	array([[-2.0448084, -2.416102 ]], dtype=float32)

time = 21734	action = 0	current_phase = 0	next_phase = 1	reward = -0.245927	array([[-2.0264676, -3.0697763]], dtype=float32)

time = 21739	action = 0	current_phase = 0	next_phase = 1	reward = -0.178778	array([[-2.163994 , -2.7729533]], dtype=float32)

time = 21744	action = 1	current_phase = 0	next_phase = 1	reward = -0.554084	array([[-2.9760783, -2.0877492]], dtype=float32)

time = 21752	action = 0	current_phase = 1	next_phase = 0	reward = -0.616204	array([[-2.0942967, -2.6056423]], dtype=float32)

time = 21757	action = 0	current_phase = 1	next_phase = 0	reward = -0.458005	array([[-1.9174237, -2.899929 ]], dtype=float32)

time = 21762	action = 0	current_phase = 1	next_phase = 0	reward = -0.312056	array([[-2.0137393, -2.5642252]], dtype=float32)

time = 21767	action = 0	current_phase = 1	next_phase = 0	reward = -0.174016	array([[-2.055334, -2.627449]], dtype=float32)

time = 21772	action = 0	current_phase = 1	next_phase = 0	reward = 0.227752	array([[-2.4754694, -3.425407 ]], dtype=float32)

time = 21777	action = 1	current_phase = 1	next_phase = 0	reward = -1.778764	array([[-5.0688634, -3.4633217]], dtype=float32)

time = 21785	action = 0	current_phase = 0	next_phase = 1	reward = -0.526351	array([[-2.1753955, -2.8298476]], dtype=float32)

time = 21790	action = 0	current_phase = 0	next_phase = 1	reward = -0.376959	array([[-2.0446813, -2.4072685]], dtype=float32)

time = 21795	action = 0	current_phase = 0	next_phase = 1	reward = -0.222992	array([[-2.0392942, -2.9527137]], dtype=float32)

time = 21800	action = 0	current_phase = 0	next_phase = 1	reward = 0.063255	array([[-2.146777 , -2.8609653]], dtype=float32)

time = 21805	action = 1	current_phase = 0	next_phase = 1	reward = -1.082333	array([[-3.351742, -2.639111]], dtype=float32)

time = 21813	action = 0	current_phase = 1	next_phase = 0	reward = -0.590193	array([[-2.1381998, -2.5245638]], dtype=float32)

time = 21818	action = 0	current_phase = 1	next_phase = 0	reward = -0.435358	array([[-2.0672393, -2.5970588]], dtype=float32)

time = 21823	action = 0	current_phase = 1	next_phase = 0	reward = -0.281608	array([[-2.030999 , -2.6077032]], dtype=float32)

time = 21828	action = 0	current_phase = 1	next_phase = 0	reward = -0.168025	array([[-2.2257087, -2.645588 ]], dtype=float32)

time = 21833	action = 0	current_phase = 1	next_phase = 0	reward = -0.006369	array([[-2.783758 , -3.1893344]], dtype=float32)

time = 21838	action = 1	current_phase = 1	next_phase = 0	reward = -1.900761	array([[-5.083036, -3.566433]], dtype=float32)

time = 21846	action = 0	current_phase = 0	next_phase = 1	reward = -0.493615	array([[-2.1648   , -2.7260394]], dtype=float32)

time = 21851	action = 0	current_phase = 0	next_phase = 1	reward = -0.340961	array([[-2.0734334, -2.3838873]], dtype=float32)

time = 21856	action = 0	current_phase = 0	next_phase = 1	reward = -0.195889	array([[-2.1624832, -2.7792964]], dtype=float32)

time = 21861	action = 0	current_phase = 0	next_phase = 1	reward = 0.303150	array([[-2.334307 , -3.3089786]], dtype=float32)

time = 21866	action = 1	current_phase = 0	next_phase = 1	reward = -1.608872	array([[-3.6158228, -3.2441556]], dtype=float32)

time = 21874	action = 0	current_phase = 1	next_phase = 0	reward = -0.556267	array([[-2.0521946, -2.5857625]], dtype=float32)

time = 21879	action = 0	current_phase = 1	next_phase = 0	reward = -0.402444	array([[-1.7985857, -2.7709002]], dtype=float32)

time = 21884	action = 0	current_phase = 1	next_phase = 0	reward = -0.239289	array([[-1.8019187, -2.6561227]], dtype=float32)

time = 21889	action = 0	current_phase = 1	next_phase = 0	reward = -0.175703	array([[-2.0005713, -3.0361214]], dtype=float32)

time = 21894	action = 1	current_phase = 1	next_phase = 0	reward = -0.583874	array([[-2.650826 , -2.1503818]], dtype=float32)

time = 21902	action = 0	current_phase = 0	next_phase = 1	reward = -0.620189	array([[-2.305154, -2.523083]], dtype=float32)

time = 21907	action = 0	current_phase = 0	next_phase = 1	reward = -0.455588	array([[-2.0473206, -2.4198432]], dtype=float32)

time = 21912	action = 0	current_phase = 0	next_phase = 1	reward = -0.294146	array([[-2.128856 , -2.7574568]], dtype=float32)

time = 21917	action = 0	current_phase = 0	next_phase = 1	reward = -0.168606	array([[-2.3913827, -2.847513 ]], dtype=float32)

time = 21922	action = 0	current_phase = 0	next_phase = 1	reward = 0.086355	array([[-2.695296 , -4.0234494]], dtype=float32)

time = 21927	action = 1	current_phase = 0	next_phase = 1	reward = -1.786739	array([[-5.1045694, -3.476358 ]], dtype=float32)

time = 21935	action = 0	current_phase = 1	next_phase = 0	reward = -0.522724	array([[-1.9367644, -2.559957 ]], dtype=float32)

time = 21940	action = 0	current_phase = 1	next_phase = 0	reward = -0.364868	array([[-1.8137747, -2.7765703]], dtype=float32)

time = 21945	action = 0	current_phase = 1	next_phase = 0	reward = -0.211744	array([[-1.7071923, -2.7414308]], dtype=float32)

time = 21950	action = 0	current_phase = 1	next_phase = 0	reward = 0.363406	array([[-1.905028 , -2.9054146]], dtype=float32)

time = 21955	action = 1	current_phase = 1	next_phase = 0	reward = -1.256700	array([[-3.902012 , -2.9428248]], dtype=float32)

time = 21963	action = 0	current_phase = 0	next_phase = 1	reward = -0.593343	array([[-2.1004834, -2.4342306]], dtype=float32)

time = 21968	action = 0	current_phase = 0	next_phase = 1	reward = -0.442292	array([[-2.045134 , -2.4095435]], dtype=float32)

time = 21973	action = 0	current_phase = 0	next_phase = 1	reward = -0.290853	array([[-2.0539095, -2.9277537]], dtype=float32)

time = 21978	action = 0	current_phase = 0	next_phase = 1	reward = -0.161173	array([[-2.2493627, -2.786489 ]], dtype=float32)

time = 21983	action = 0	current_phase = 0	next_phase = 1	reward = 0.133364	array([[-2.5477188, -3.6808014]], dtype=float32)

time = 21988	action = 1	current_phase = 0	next_phase = 1	reward = -1.889897	array([[-5.045616 , -3.4891481]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0718 - val_loss: 0.0549

Epoch 2/50

 - 4s - loss: 0.0604 - val_loss: 0.0543

Epoch 3/50

 - 4s - loss: 0.0735 - val_loss: 0.0499

Epoch 4/50

 - 4s - loss: 0.0616 - val_loss: 0.0527

Epoch 5/50

 - 4s - loss: 0.0477 - val_loss: 0.0480

Epoch 6/50

 - 4s - loss: 0.0541 - val_loss: 0.0468

Epoch 7/50

 - 4s - loss: 0.0565 - val_loss: 0.0524

Epoch 8/50

 - 4s - loss: 0.0672 - val_loss: 0.0499

Epoch 9/50

 - 4s - loss: 0.0405 - val_loss: 0.0547

Epoch 10/50

 - 4s - loss: 0.0740 - val_loss: 0.0502

Epoch 11/50

 - 4s - loss: 0.0362 - val_loss: 0.0531

Epoch 12/50

 - 4s - loss: 0.0480 - val_loss: 0.0581

Epoch 13/50

 - 4s - loss: 0.0612 - val_loss: 0.0540

Epoch 14/50

 - 4s - loss: 0.0327 - val_loss: 0.0554

Epoch 15/50

 - 4s - loss: 0.0469 - val_loss: 0.0504

Epoch 16/50

 - 4s - loss: 0.0544 - val_loss: 0.0606

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 702, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 689, after forget

time = 21996	action = 0	current_phase = 1	next_phase = 0	reward = -0.485275	array([[-1.9166673, -2.7890167]], dtype=float32)

time = 22001	action = 0	current_phase = 1	next_phase = 0	reward = -0.325195	array([[-1.8083102, -2.7594635]], dtype=float32)

time = 22006	action = 0	current_phase = 1	next_phase = 0	reward = -0.183392	array([[-2.0917118, -2.5620022]], dtype=float32)

time = 22011	action = 0	current_phase = 1	next_phase = 0	reward = 0.293706	array([[-2.279857, -3.473495]], dtype=float32)

time = 22016	action = 1	current_phase = 1	next_phase = 0	reward = -1.557856	array([[-4.8441463, -3.3117082]], dtype=float32)

time = 22024	action = 0	current_phase = 0	next_phase = 1	reward = -0.561799	array([[-2.1470478, -2.5344448]], dtype=float32)

time = 22029	action = 0	current_phase = 0	next_phase = 1	reward = -0.399083	array([[-2.0041096, -2.4564779]], dtype=float32)

time = 22034	action = 0	current_phase = 0	next_phase = 1	reward = -0.250094	array([[-1.9401883, -3.0482938]], dtype=float32)

time = 22039	action = 0	current_phase = 0	next_phase = 1	reward = -0.181149	array([[-2.1173472, -2.8540595]], dtype=float32)

time = 22044	action = 1	current_phase = 0	next_phase = 1	reward = -0.578955	array([[-2.9245076, -2.0798519]], dtype=float32)

time = 22052	action = 0	current_phase = 1	next_phase = 0	reward = -0.623362	array([[-2.1050866, -2.5906692]], dtype=float32)

time = 22057	action = 0	current_phase = 1	next_phase = 0	reward = -0.467067	array([[-1.8908204, -2.9263382]], dtype=float32)

time = 22062	action = 0	current_phase = 1	next_phase = 0	reward = -0.321215	array([[-1.9440542, -2.6233587]], dtype=float32)

time = 22067	action = 0	current_phase = 1	next_phase = 0	reward = -0.178124	array([[-2.0995402, -2.5671546]], dtype=float32)

time = 22072	action = 0	current_phase = 1	next_phase = 0	reward = 0.240394	array([[-2.094922 , -3.1751149]], dtype=float32)

time = 22077	action = 1	current_phase = 1	next_phase = 0	reward = -1.780725	array([[-5.099512 , -3.4415538]], dtype=float32)

time = 22085	action = 0	current_phase = 0	next_phase = 1	reward = -0.521345	array([[-2.1037881, -2.863661 ]], dtype=float32)

time = 22090	action = 0	current_phase = 0	next_phase = 1	reward = -0.364655	array([[-2.00217  , -2.4594412]], dtype=float32)

time = 22095	action = 0	current_phase = 0	next_phase = 1	reward = -0.212795	array([[-1.9541105, -3.0178642]], dtype=float32)

time = 22100	action = 0	current_phase = 0	next_phase = 1	reward = 0.356442	array([[-2.0505292, -2.9486675]], dtype=float32)

time = 22105	action = 1	current_phase = 0	next_phase = 1	reward = -1.356679	array([[-3.4501517, -3.0710373]], dtype=float32)

time = 22113	action = 0	current_phase = 1	next_phase = 0	reward = -0.591928	array([[-2.1321247, -2.5849478]], dtype=float32)

time = 22118	action = 0	current_phase = 1	next_phase = 0	reward = -0.441403	array([[-1.9741676, -2.6362963]], dtype=float32)

time = 22123	action = 0	current_phase = 1	next_phase = 0	reward = -0.284223	array([[-1.9426743, -2.5927746]], dtype=float32)

time = 22128	action = 0	current_phase = 1	next_phase = 0	reward = -0.165091	array([[-2.1663225, -2.5735555]], dtype=float32)

time = 22133	action = 0	current_phase = 1	next_phase = 0	reward = 0.065933	array([[-2.6660159, -3.2466717]], dtype=float32)

time = 22138	action = 1	current_phase = 1	next_phase = 0	reward = -1.895737	array([[-5.059042 , -3.5533168]], dtype=float32)

time = 22146	action = 0	current_phase = 0	next_phase = 1	reward = -0.495353	array([[-2.0953515, -2.864554 ]], dtype=float32)

time = 22151	action = 0	current_phase = 0	next_phase = 1	reward = -0.332446	array([[-2.0070817, -2.4563913]], dtype=float32)

time = 22156	action = 0	current_phase = 0	next_phase = 1	reward = -0.188509	array([[-2.0519826, -2.9338093]], dtype=float32)

time = 22161	action = 0	current_phase = 0	next_phase = 1	reward = 0.311725	array([[-2.2884681, -3.5263941]], dtype=float32)

time = 22166	action = 1	current_phase = 0	next_phase = 1	reward = -1.553630	array([[-3.6550255, -3.1852033]], dtype=float32)

time = 22174	action = 0	current_phase = 1	next_phase = 0	reward = -0.557798	array([[-1.9880669, -2.6032977]], dtype=float32)

time = 22179	action = 0	current_phase = 1	next_phase = 0	reward = -0.398236	array([[-1.6978022, -2.8045926]], dtype=float32)

time = 22184	action = 0	current_phase = 1	next_phase = 0	reward = -0.246082	array([[-1.8062272, -2.7438016]], dtype=float32)

time = 22189	action = 0	current_phase = 1	next_phase = 0	reward = 0.115181	array([[-2.0216465, -2.7809694]], dtype=float32)

time = 22194	action = 1	current_phase = 1	next_phase = 0	reward = -0.748526	array([[-2.917572 , -2.3284767]], dtype=float32)

time = 22202	action = 0	current_phase = 0	next_phase = 1	reward = -0.614633	array([[-2.334714 , -2.6164625]], dtype=float32)

time = 22207	action = 0	current_phase = 0	next_phase = 1	reward = -0.455697	array([[-2.0077205, -2.459963 ]], dtype=float32)

time = 22212	action = 0	current_phase = 0	next_phase = 1	reward = -0.298831	array([[-1.9664396, -2.9986517]], dtype=float32)

time = 22217	action = 0	current_phase = 0	next_phase = 1	reward = -0.169890	array([[-2.1506555, -2.7931168]], dtype=float32)

time = 22222	action = 0	current_phase = 0	next_phase = 1	reward = 0.178297	array([[-2.3845954, -3.9761362]], dtype=float32)

time = 22227	action = 1	current_phase = 0	next_phase = 1	reward = -1.784544	array([[-4.992897 , -3.4230568]], dtype=float32)

time = 22235	action = 0	current_phase = 1	next_phase = 0	reward = -0.534901	array([[-1.8708851, -2.6118522]], dtype=float32)

time = 22240	action = 0	current_phase = 1	next_phase = 0	reward = -0.373594	array([[-1.6914481, -2.80308  ]], dtype=float32)

time = 22245	action = 0	current_phase = 1	next_phase = 0	reward = -0.211931	array([[-1.5851105, -2.7333994]], dtype=float32)

time = 22250	action = 0	current_phase = 1	next_phase = 0	reward = 0.357634	array([[-1.7755771, -3.0824752]], dtype=float32)

time = 22255	action = 1	current_phase = 1	next_phase = 0	reward = -1.311508	array([[-4.047759 , -3.0231616]], dtype=float32)

time = 22263	action = 0	current_phase = 0	next_phase = 1	reward = -0.582083	array([[-2.163164 , -2.5335176]], dtype=float32)

time = 22268	action = 0	current_phase = 0	next_phase = 1	reward = -0.427722	array([[-2.0069647, -2.4545207]], dtype=float32)

time = 22273	action = 0	current_phase = 0	next_phase = 1	reward = -0.285108	array([[-1.9506265, -3.045593 ]], dtype=float32)

time = 22278	action = 0	current_phase = 0	next_phase = 1	reward = -0.163457	array([[-2.21671  , -2.8531647]], dtype=float32)

time = 22283	action = 0	current_phase = 0	next_phase = 1	reward = 0.076851	array([[-2.6416166, -3.7457266]], dtype=float32)

time = 22288	action = 1	current_phase = 0	next_phase = 1	reward = -1.896317	array([[-5.0812774, -3.597251 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1302 - val_loss: 0.0259

Epoch 2/50

 - 4s - loss: 0.0673 - val_loss: 0.0278

Epoch 3/50

 - 4s - loss: 0.0879 - val_loss: 0.0277

Epoch 4/50

 - 4s - loss: 0.0695 - val_loss: 0.0283

Epoch 5/50

 - 4s - loss: 0.0633 - val_loss: 0.0309

Epoch 6/50

 - 4s - loss: 0.0515 - val_loss: 0.0297

Epoch 7/50

 - 4s - loss: 0.0501 - val_loss: 0.0322

Epoch 8/50

 - 4s - loss: 0.0457 - val_loss: 0.0321

Epoch 9/50

 - 4s - loss: 0.0614 - val_loss: 0.0315

Epoch 10/50

 - 4s - loss: 0.0621 - val_loss: 0.0310

Epoch 11/50

 - 4s - loss: 0.0622 - val_loss: 0.0331

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 707, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 694, after forget

time = 22296	action = 0	current_phase = 1	next_phase = 0	reward = -0.500800	array([[-2.015533, -2.779774]], dtype=float32)

time = 22301	action = 0	current_phase = 1	next_phase = 0	reward = -0.351815	array([[-1.905981 , -2.7211254]], dtype=float32)

time = 22306	action = 0	current_phase = 1	next_phase = 0	reward = -0.206750	array([[-2.046393 , -2.5722837]], dtype=float32)

time = 22311	action = 0	current_phase = 1	next_phase = 0	reward = 0.320041	array([[-2.3088264, -3.4246633]], dtype=float32)

time = 22316	action = 1	current_phase = 1	next_phase = 0	reward = -1.555960	array([[-4.7712536, -3.197949 ]], dtype=float32)

time = 22324	action = 0	current_phase = 0	next_phase = 1	reward = -0.562704	array([[-2.2636826, -2.5958648]], dtype=float32)

time = 22329	action = 0	current_phase = 0	next_phase = 1	reward = -0.405015	array([[-2.0549812, -2.4891157]], dtype=float32)

time = 22334	action = 0	current_phase = 0	next_phase = 1	reward = -0.248557	array([[-2.0433471, -3.0909567]], dtype=float32)

time = 22339	action = 0	current_phase = 0	next_phase = 1	reward = -0.181274	array([[-2.4212778, -2.869331 ]], dtype=float32)

time = 22344	action = 1	current_phase = 0	next_phase = 1	reward = -0.583486	array([[-3.1705956, -2.192954 ]], dtype=float32)

time = 22352	action = 0	current_phase = 1	next_phase = 0	reward = -0.623458	array([[-2.0717764, -2.6540222]], dtype=float32)

time = 22357	action = 0	current_phase = 1	next_phase = 0	reward = -0.465932	array([[-2.0481935, -2.9046104]], dtype=float32)

time = 22362	action = 0	current_phase = 1	next_phase = 0	reward = -0.315533	array([[-2.071281 , -2.6397417]], dtype=float32)

time = 22367	action = 0	current_phase = 1	next_phase = 0	reward = -0.178759	array([[-1.9447389, -3.0335088]], dtype=float32)

time = 22372	action = 0	current_phase = 1	next_phase = 0	reward = 0.205546	array([[-2.5780466, -3.39422  ]], dtype=float32)

time = 22377	action = 1	current_phase = 1	next_phase = 0	reward = -1.784735	array([[-5.02036 , -3.450304]], dtype=float32)

time = 22385	action = 0	current_phase = 0	next_phase = 1	reward = -0.528252	array([[-2.2360756, -2.8474038]], dtype=float32)

time = 22390	action = 0	current_phase = 0	next_phase = 1	reward = -0.372347	array([[-2.053619, -2.496358]], dtype=float32)

time = 22395	action = 0	current_phase = 0	next_phase = 1	reward = -0.218417	array([[-2.0403829, -3.0690732]], dtype=float32)

time = 22400	action = 0	current_phase = 0	next_phase = 1	reward = 0.379413	array([[-2.090174, -3.185515]], dtype=float32)

time = 22405	action = 1	current_phase = 0	next_phase = 1	reward = -1.246199	array([[-3.7414515, -3.0915747]], dtype=float32)

time = 22413	action = 0	current_phase = 1	next_phase = 0	reward = -0.586565	array([[-2.1464753, -2.6207924]], dtype=float32)

time = 22418	action = 0	current_phase = 1	next_phase = 0	reward = -0.431336	array([[-2.0532653, -2.6696339]], dtype=float32)

time = 22423	action = 0	current_phase = 1	next_phase = 0	reward = -0.284943	array([[-1.9634193, -2.5698712]], dtype=float32)

time = 22428	action = 0	current_phase = 1	next_phase = 0	reward = -0.169937	array([[-2.226708, -2.608268]], dtype=float32)

time = 22433	action = 0	current_phase = 1	next_phase = 0	reward = 0.136347	array([[-2.669994, -3.19056 ]], dtype=float32)

time = 22438	action = 1	current_phase = 1	next_phase = 0	reward = -1.889171	array([[-5.031748 , -3.5293968]], dtype=float32)

time = 22446	action = 0	current_phase = 0	next_phase = 1	reward = -0.498408	array([[-2.1277366, -2.812063 ]], dtype=float32)

time = 22451	action = 0	current_phase = 0	next_phase = 1	reward = -0.349457	array([[-2.0757468, -2.4804673]], dtype=float32)

time = 22456	action = 0	current_phase = 0	next_phase = 1	reward = -0.201599	array([[-2.1778   , -2.7934954]], dtype=float32)

time = 22461	action = 0	current_phase = 0	next_phase = 1	reward = 0.316589	array([[-2.559684 , -3.6234407]], dtype=float32)

time = 22466	action = 1	current_phase = 0	next_phase = 1	reward = -1.559756	array([[-3.5607455, -3.2380583]], dtype=float32)

time = 22474	action = 0	current_phase = 1	next_phase = 0	reward = -0.560246	array([[-1.8746061, -2.444557 ]], dtype=float32)

time = 22479	action = 0	current_phase = 1	next_phase = 0	reward = -0.410504	array([[-1.8286611, -2.8439007]], dtype=float32)

time = 22484	action = 0	current_phase = 1	next_phase = 0	reward = -0.253071	array([[-1.7286607, -2.7336917]], dtype=float32)

time = 22489	action = 0	current_phase = 1	next_phase = 0	reward = -0.173475	array([[-1.9152143, -3.0240657]], dtype=float32)

time = 22494	action = 1	current_phase = 1	next_phase = 0	reward = -0.524906	array([[-2.2395995, -2.2069693]], dtype=float32)

time = 22502	action = 0	current_phase = 0	next_phase = 1	reward = -0.617655	array([[-2.3919697, -2.6611607]], dtype=float32)

time = 22507	action = 0	current_phase = 0	next_phase = 1	reward = -0.455259	array([[-2.0593607, -2.4936142]], dtype=float32)

time = 22512	action = 0	current_phase = 0	next_phase = 1	reward = -0.302125	array([[-2.115123, -2.890313]], dtype=float32)

time = 22517	action = 0	current_phase = 0	next_phase = 1	reward = -0.173190	array([[-2.2923384, -2.797042 ]], dtype=float32)

time = 22522	action = 0	current_phase = 0	next_phase = 1	reward = 0.101326	array([[-2.4154942, -4.0432897]], dtype=float32)

time = 22527	action = 1	current_phase = 0	next_phase = 1	reward = -1.783715	array([[-5.1834693, -3.3810687]], dtype=float32)

time = 22535	action = 0	current_phase = 1	next_phase = 0	reward = -0.528128	array([[-1.9557415, -2.5926456]], dtype=float32)

time = 22540	action = 0	current_phase = 1	next_phase = 0	reward = -0.375091	array([[-1.7997062, -2.8331106]], dtype=float32)

time = 22545	action = 0	current_phase = 1	next_phase = 0	reward = -0.227090	array([[-1.6909121, -2.7610638]], dtype=float32)

time = 22550	action = 0	current_phase = 1	next_phase = 0	reward = 0.354106	array([[-1.8579497, -3.0988364]], dtype=float32)

time = 22555	action = 1	current_phase = 1	next_phase = 0	reward = -1.364742	array([[-3.857649 , -2.9746363]], dtype=float32)

time = 22563	action = 0	current_phase = 0	next_phase = 1	reward = -0.601189	array([[-2.3433852, -2.639267 ]], dtype=float32)

time = 22568	action = 0	current_phase = 0	next_phase = 1	reward = -0.443643	array([[-2.0620344, -2.4910405]], dtype=float32)

time = 22573	action = 0	current_phase = 0	next_phase = 1	reward = -0.287095	array([[-2.020168 , -3.0717883]], dtype=float32)

time = 22578	action = 0	current_phase = 0	next_phase = 1	reward = -0.165245	array([[-2.4059916, -2.8239253]], dtype=float32)

time = 22583	action = 0	current_phase = 0	next_phase = 1	reward = 0.068833	array([[-2.5977647, -4.07694  ]], dtype=float32)

time = 22588	action = 1	current_phase = 0	next_phase = 1	reward = -1.893113	array([[-5.179945 , -3.5509806]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0390 - val_loss: 0.0196

Epoch 2/50

 - 4s - loss: 0.0368 - val_loss: 0.0202

Epoch 3/50

 - 5s - loss: 0.0400 - val_loss: 0.0216

Epoch 4/50

 - 4s - loss: 0.0309 - val_loss: 0.0209

Epoch 5/50

 - 4s - loss: 0.0426 - val_loss: 0.0214

Epoch 6/50

 - 4s - loss: 0.0349 - val_loss: 0.0209

Epoch 7/50

 - 4s - loss: 0.0295 - val_loss: 0.0194

Epoch 8/50

 - 4s - loss: 0.0344 - val_loss: 0.0204

Epoch 9/50

 - 5s - loss: 0.0306 - val_loss: 0.0217

Epoch 10/50

 - 4s - loss: 0.0346 - val_loss: 0.0232

Epoch 11/50

 - 5s - loss: 0.0276 - val_loss: 0.0233

Epoch 12/50

 - 4s - loss: 0.0244 - val_loss: 0.0232

Epoch 13/50

 - 4s - loss: 0.0387 - val_loss: 0.0250

Epoch 14/50

 - 4s - loss: 0.0273 - val_loss: 0.0219

Epoch 15/50

 - 4s - loss: 0.0365 - val_loss: 0.0223

Epoch 16/50

 - 4s - loss: 0.0266 - val_loss: 0.0228

Epoch 17/50

 - 4s - loss: 0.0244 - val_loss: 0.0251

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 712, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 699, after forget

time = 22596	action = 0	current_phase = 1	next_phase = 0	reward = -0.499142	array([[-1.9372596, -2.8296642]], dtype=float32)

time = 22601	action = 0	current_phase = 1	next_phase = 0	reward = -0.347700	array([[-1.6797861, -2.9399195]], dtype=float32)

time = 22606	action = 0	current_phase = 1	next_phase = 0	reward = -0.206173	array([[-1.6971139, -2.791544 ]], dtype=float32)

time = 22611	action = 0	current_phase = 1	next_phase = 0	reward = 0.306968	array([[-2.2297993, -3.3082814]], dtype=float32)

time = 22616	action = 1	current_phase = 1	next_phase = 0	reward = -1.504780	array([[-4.5275855, -3.1664844]], dtype=float32)

time = 22624	action = 0	current_phase = 0	next_phase = 1	reward = -0.573535	array([[-2.215808 , -2.5915923]], dtype=float32)

time = 22629	action = 0	current_phase = 0	next_phase = 1	reward = -0.416253	array([[-2.0556006, -2.5043335]], dtype=float32)

time = 22634	action = 0	current_phase = 0	next_phase = 1	reward = -0.263841	array([[-2.0629056, -3.067976 ]], dtype=float32)

time = 22639	action = 0	current_phase = 0	next_phase = 1	reward = -0.178224	array([[-2.233727, -2.793767]], dtype=float32)

time = 22644	action = 1	current_phase = 0	next_phase = 1	reward = -0.452644	array([[-3.1638122, -2.3708403]], dtype=float32)

time = 22652	action = 0	current_phase = 1	next_phase = 0	reward = -0.617226	array([[-2.1013966, -2.6466064]], dtype=float32)

time = 22657	action = 0	current_phase = 1	next_phase = 0	reward = -0.454495	array([[-1.7010624, -3.0313482]], dtype=float32)

time = 22662	action = 0	current_phase = 1	next_phase = 0	reward = -0.298005	array([[-1.7495414, -2.7397504]], dtype=float32)

time = 22667	action = 0	current_phase = 1	next_phase = 0	reward = -0.167495	array([[-2.0032015, -2.713749 ]], dtype=float32)

time = 22672	action = 0	current_phase = 1	next_phase = 0	reward = 0.186665	array([[-2.2395625, -3.3844266]], dtype=float32)

time = 22677	action = 1	current_phase = 1	next_phase = 0	reward = -1.732566	array([[-4.8928633, -3.5107417]], dtype=float32)

time = 22685	action = 0	current_phase = 0	next_phase = 1	reward = -0.525907	array([[-2.2470477, -2.8968809]], dtype=float32)

time = 22690	action = 0	current_phase = 0	next_phase = 1	reward = -0.370122	array([[-2.0564785, -2.5010772]], dtype=float32)

time = 22695	action = 0	current_phase = 0	next_phase = 1	reward = -0.211064	array([[-2.0675306, -3.053096 ]], dtype=float32)

time = 22700	action = 0	current_phase = 0	next_phase = 1	reward = 0.353942	array([[-2.2643452, -3.0762198]], dtype=float32)

time = 22705	action = 1	current_phase = 0	next_phase = 1	reward = -1.365522	array([[-3.591892 , -2.9945302]], dtype=float32)

time = 22713	action = 0	current_phase = 1	next_phase = 0	reward = -0.579786	array([[-2.2229338, -2.58106  ]], dtype=float32)

time = 22718	action = 0	current_phase = 1	next_phase = 0	reward = -0.423646	array([[-1.8051181, -2.7890449]], dtype=float32)

time = 22723	action = 0	current_phase = 1	next_phase = 0	reward = -0.275732	array([[-1.8759094, -2.636992 ]], dtype=float32)

time = 22728	action = 0	current_phase = 1	next_phase = 0	reward = -0.160385	array([[-2.0558999, -2.676928 ]], dtype=float32)

time = 22733	action = 0	current_phase = 1	next_phase = 0	reward = 0.085005	array([[-2.3348706, -2.465612 ]], dtype=float32)

time = 22738	action = 1	current_phase = 1	next_phase = 0	reward = -1.900805	array([[-4.8993516, -3.5357518]], dtype=float32)

time = 22746	action = 0	current_phase = 0	next_phase = 1	reward = -0.493586	array([[-2.1508214, -2.9079804]], dtype=float32)

time = 22751	action = 0	current_phase = 0	next_phase = 1	reward = -0.335551	array([[-2.0727677, -2.4933367]], dtype=float32)

time = 22756	action = 0	current_phase = 0	next_phase = 1	reward = -0.189240	array([[-2.246966, -2.77527 ]], dtype=float32)

time = 22761	action = 0	current_phase = 0	next_phase = 1	reward = 0.287507	array([[-2.329343, -3.155961]], dtype=float32)

time = 22766	action = 1	current_phase = 0	next_phase = 1	reward = -1.609798	array([[-3.6838837, -3.2961664]], dtype=float32)

time = 22774	action = 0	current_phase = 1	next_phase = 0	reward = -0.554885	array([[-1.9762169, -2.6578407]], dtype=float32)

time = 22779	action = 0	current_phase = 1	next_phase = 0	reward = -0.400273	array([[-1.7028186, -2.8653884]], dtype=float32)

time = 22784	action = 0	current_phase = 1	next_phase = 0	reward = -0.244902	array([[-1.6857845, -2.7872   ]], dtype=float32)

time = 22789	action = 0	current_phase = 1	next_phase = 0	reward = -0.179235	array([[-1.8299046, -3.1466513]], dtype=float32)

time = 22794	action = 1	current_phase = 1	next_phase = 0	reward = -0.588614	array([[-2.3262532, -2.192603 ]], dtype=float32)

time = 22802	action = 0	current_phase = 0	next_phase = 1	reward = -0.603455	array([[-2.3731081, -2.6721163]], dtype=float32)

time = 22807	action = 0	current_phase = 0	next_phase = 1	reward = -0.448784	array([[-2.0994742, -2.5220773]], dtype=float32)

time = 22812	action = 0	current_phase = 0	next_phase = 1	reward = -0.291305	array([[-2.134712 , -2.9301062]], dtype=float32)

time = 22817	action = 0	current_phase = 0	next_phase = 1	reward = -0.165405	array([[-2.2537336, -2.7333796]], dtype=float32)

time = 22822	action = 0	current_phase = 0	next_phase = 1	reward = 0.188231	array([[-2.4735768, -4.0474777]], dtype=float32)

time = 22827	action = 1	current_phase = 0	next_phase = 1	reward = -1.729881	array([[-5.1942687, -3.4351375]], dtype=float32)

time = 22835	action = 0	current_phase = 1	next_phase = 0	reward = -0.530475	array([[-1.8876764, -2.7047725]], dtype=float32)

time = 22840	action = 0	current_phase = 1	next_phase = 0	reward = -0.381863	array([[-1.688654, -2.850265]], dtype=float32)

time = 22845	action = 0	current_phase = 1	next_phase = 0	reward = -0.229375	array([[-1.6277468, -2.7989845]], dtype=float32)

time = 22850	action = 0	current_phase = 1	next_phase = 0	reward = 0.073656	array([[-1.7229654, -3.2915578]], dtype=float32)

time = 22855	action = 1	current_phase = 1	next_phase = 0	reward = -0.972961	array([[-3.3196836, -2.604827 ]], dtype=float32)

time = 22863	action = 0	current_phase = 0	next_phase = 1	reward = -0.593196	array([[-2.2523744, -2.6041024]], dtype=float32)

time = 22868	action = 0	current_phase = 0	next_phase = 1	reward = -0.456646	array([[-2.057091, -2.50186 ]], dtype=float32)

time = 22873	action = 0	current_phase = 0	next_phase = 1	reward = -0.304677	array([[-2.1023362, -2.9930503]], dtype=float32)

time = 22878	action = 0	current_phase = 0	next_phase = 1	reward = -0.174951	array([[-2.4000313, -2.7961311]], dtype=float32)

time = 22883	action = 0	current_phase = 0	next_phase = 1	reward = 0.106795	array([[-2.6323714, -3.936277 ]], dtype=float32)

time = 22888	action = 1	current_phase = 0	next_phase = 1	reward = -1.896176	array([[-5.229858, -3.53715 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 6s - loss: 0.0563 - val_loss: 0.0351

Epoch 2/50

 - 6s - loss: 0.0545 - val_loss: 0.0513

Epoch 3/50

 - 5s - loss: 0.0436 - val_loss: 0.0454

Epoch 4/50

 - 5s - loss: 0.0537 - val_loss: 0.0385

Epoch 5/50

 - 5s - loss: 0.0443 - val_loss: 0.0410

Epoch 6/50

 - 5s - loss: 0.0373 - val_loss: 0.0350

Epoch 7/50

 - 5s - loss: 0.0384 - val_loss: 0.0345

Epoch 8/50

 - 4s - loss: 0.0409 - val_loss: 0.0371

Epoch 9/50

 - 6s - loss: 0.0405 - val_loss: 0.0426

Epoch 10/50

 - 4s - loss: 0.0315 - val_loss: 0.0419

Epoch 11/50

 - 5s - loss: 0.0304 - val_loss: 0.0380

Epoch 12/50

 - 4s - loss: 0.0346 - val_loss: 0.0400

Epoch 13/50

 - 4s - loss: 0.0334 - val_loss: 0.0380

Epoch 14/50

 - 4s - loss: 0.0333 - val_loss: 0.0378

Epoch 15/50

 - 5s - loss: 0.0314 - val_loss: 0.0370

Epoch 16/50

 - 4s - loss: 0.0462 - val_loss: 0.0405

Epoch 17/50

 - 5s - loss: 0.0272 - val_loss: 0.0410

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 717, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 704, after forget

time = 22896	action = 0	current_phase = 1	next_phase = 0	reward = -0.503181	array([[-1.8794755, -2.8289557]], dtype=float32)

time = 22901	action = 0	current_phase = 1	next_phase = 0	reward = -0.345413	array([[-1.8431019, -2.7420378]], dtype=float32)

time = 22906	action = 0	current_phase = 1	next_phase = 0	reward = -0.191011	array([[-1.9461967, -2.6568313]], dtype=float32)

time = 22911	action = 0	current_phase = 1	next_phase = 0	reward = 0.322712	array([[-2.2825987, -3.4784107]], dtype=float32)

time = 22916	action = 1	current_phase = 1	next_phase = 0	reward = -1.605453	array([[-4.785191 , -3.2986069]], dtype=float32)

time = 22924	action = 0	current_phase = 0	next_phase = 1	reward = -0.550798	array([[-2.217039 , -2.5163763]], dtype=float32)

time = 22929	action = 0	current_phase = 0	next_phase = 1	reward = -0.394394	array([[-2.124303 , -2.4876592]], dtype=float32)

time = 22934	action = 0	current_phase = 0	next_phase = 1	reward = -0.242004	array([[-2.1170454, -3.0672429]], dtype=float32)

time = 22939	action = 0	current_phase = 0	next_phase = 1	reward = -0.188987	array([[-2.1163151, -3.1244395]], dtype=float32)

time = 22944	action = 1	current_phase = 0	next_phase = 1	reward = -0.556037	array([[-3.0875523, -2.3730583]], dtype=float32)

time = 22952	action = 0	current_phase = 1	next_phase = 0	reward = -0.621970	array([[-2.0385842, -2.6685243]], dtype=float32)

time = 22957	action = 0	current_phase = 1	next_phase = 0	reward = -0.467812	array([[-1.7958181, -2.9878197]], dtype=float32)

time = 22962	action = 0	current_phase = 1	next_phase = 0	reward = -0.320443	array([[-1.8678201, -2.591895 ]], dtype=float32)

time = 22967	action = 0	current_phase = 1	next_phase = 0	reward = -0.181060	array([[-2.0654519, -2.566969 ]], dtype=float32)

time = 22972	action = 0	current_phase = 1	next_phase = 0	reward = 0.125347	array([[-2.3268008, -3.5019045]], dtype=float32)

time = 22977	action = 1	current_phase = 1	next_phase = 0	reward = -1.783414	array([[-5.0051203, -3.6231527]], dtype=float32)

time = 22985	action = 0	current_phase = 0	next_phase = 1	reward = -0.529836	array([[-2.2018092, -3.023972 ]], dtype=float32)

time = 22990	action = 0	current_phase = 0	next_phase = 1	reward = -0.376516	array([[-2.123907 , -2.4890382]], dtype=float32)

time = 22995	action = 0	current_phase = 0	next_phase = 1	reward = -0.222606	array([[-2.0972946, -3.0178912]], dtype=float32)

time = 23000	action = 0	current_phase = 0	next_phase = 1	reward = 0.359051	array([[-2.2513387, -2.8912795]], dtype=float32)

time = 23005	action = 1	current_phase = 0	next_phase = 1	reward = -1.310232	array([[-3.792665 , -2.8009236]], dtype=float32)

time = 23013	action = 0	current_phase = 1	next_phase = 0	reward = -0.588763	array([[-2.1748316, -2.613133 ]], dtype=float32)

time = 23018	action = 0	current_phase = 1	next_phase = 0	reward = -0.438928	array([[-1.9508635, -2.6814637]], dtype=float32)

time = 23023	action = 0	current_phase = 1	next_phase = 0	reward = -0.292248	array([[-1.885893 , -2.6875958]], dtype=float32)

time = 23028	action = 0	current_phase = 1	next_phase = 0	reward = -0.168677	array([[-2.1026545, -2.6240292]], dtype=float32)

time = 23033	action = 0	current_phase = 1	next_phase = 0	reward = 0.110198	array([[-2.3831425, -2.7865696]], dtype=float32)

time = 23038	action = 1	current_phase = 1	next_phase = 0	reward = -1.891446	array([[-5.0168214, -3.6271467]], dtype=float32)

time = 23046	action = 0	current_phase = 0	next_phase = 1	reward = -0.495893	array([[-2.19177  , -2.8995085]], dtype=float32)

time = 23051	action = 0	current_phase = 0	next_phase = 1	reward = -0.351200	array([[-2.1248083, -2.5011203]], dtype=float32)

time = 23056	action = 0	current_phase = 0	next_phase = 1	reward = -0.201098	array([[-2.135807 , -3.0370326]], dtype=float32)

time = 23061	action = 0	current_phase = 0	next_phase = 1	reward = 0.276557	array([[-2.3412147, -3.6030521]], dtype=float32)

time = 23066	action = 1	current_phase = 0	next_phase = 1	reward = -1.659032	array([[-3.8742409, -3.0321872]], dtype=float32)

time = 23074	action = 0	current_phase = 1	next_phase = 0	reward = -0.549785	array([[-1.9382592, -2.6659312]], dtype=float32)

time = 23079	action = 0	current_phase = 1	next_phase = 0	reward = -0.390757	array([[-1.7116215, -2.8818383]], dtype=float32)

time = 23084	action = 0	current_phase = 1	next_phase = 0	reward = -0.234214	array([[-1.7014945, -2.7534723]], dtype=float32)

time = 23089	action = 0	current_phase = 1	next_phase = 0	reward = -0.184695	array([[-1.807322, -3.051302]], dtype=float32)

time = 23094	action = 0	current_phase = 1	next_phase = 0	reward = -0.150451	array([[-2.012931, -2.252143]], dtype=float32)

time = 23099	action = 1	current_phase = 1	next_phase = 0	reward = -2.017158	array([[-5.009563 , -3.6019878]], dtype=float32)

time = 23107	action = 0	current_phase = 0	next_phase = 1	reward = -0.475105	array([[-2.121081 , -2.7060304]], dtype=float32)

time = 23112	action = 0	current_phase = 0	next_phase = 1	reward = -0.311587	array([[-2.142634 , -2.7003918]], dtype=float32)

time = 23117	action = 0	current_phase = 0	next_phase = 1	reward = -0.177492	array([[-2.2248404, -2.9775019]], dtype=float32)

time = 23122	action = 0	current_phase = 0	next_phase = 1	reward = 0.200380	array([[-2.7762074, -3.7246969]], dtype=float32)

time = 23127	action = 1	current_phase = 0	next_phase = 1	reward = -1.789530	array([[-4.721186 , -3.2500813]], dtype=float32)

time = 23135	action = 0	current_phase = 1	next_phase = 0	reward = -0.535720	array([[-1.902943 , -2.6264362]], dtype=float32)

time = 23140	action = 0	current_phase = 1	next_phase = 0	reward = -0.383617	array([[-1.701768 , -2.8902826]], dtype=float32)

time = 23145	action = 0	current_phase = 1	next_phase = 0	reward = -0.228043	array([[-1.6493361, -2.7962427]], dtype=float32)

time = 23150	action = 0	current_phase = 1	next_phase = 0	reward = 0.079260	array([[-1.790859 , -3.0780506]], dtype=float32)

time = 23155	action = 1	current_phase = 1	next_phase = 0	reward = -1.073522	array([[-3.0398493, -2.6830072]], dtype=float32)

time = 23163	action = 0	current_phase = 0	next_phase = 1	reward = -0.585851	array([[-2.2866879, -2.559407 ]], dtype=float32)

time = 23168	action = 0	current_phase = 0	next_phase = 1	reward = -0.424587	array([[-2.1277506, -2.4888365]], dtype=float32)

time = 23173	action = 0	current_phase = 0	next_phase = 1	reward = -0.271911	array([[-2.1759663, -2.9322948]], dtype=float32)

time = 23178	action = 0	current_phase = 0	next_phase = 1	reward = -0.165018	array([[-2.4842517, -2.9390438]], dtype=float32)

time = 23183	action = 0	current_phase = 0	next_phase = 1	reward = 0.053573	array([[-3.4166577, -3.7315445]], dtype=float32)

time = 23188	action = 1	current_phase = 0	next_phase = 1	reward = -1.895174	array([[-5.2743864, -3.3446991]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0558 - val_loss: 0.0361

Epoch 2/50

 - 4s - loss: 0.0374 - val_loss: 0.0322

Epoch 3/50

 - 4s - loss: 0.0485 - val_loss: 0.0351

Epoch 4/50

 - 5s - loss: 0.0408 - val_loss: 0.0356

Epoch 5/50

 - 6s - loss: 0.0390 - val_loss: 0.0318

Epoch 6/50

 - 8s - loss: 0.0300 - val_loss: 0.0299

Epoch 7/50

 - 7s - loss: 0.0323 - val_loss: 0.0348

Epoch 8/50

 - 7s - loss: 0.0648 - val_loss: 0.0421

Epoch 9/50

 - 6s - loss: 0.0290 - val_loss: 0.0370

Epoch 10/50

 - 7s - loss: 0.0334 - val_loss: 0.0331

Epoch 11/50

 - 6s - loss: 0.0371 - val_loss: 0.0335

Epoch 12/50

 - 6s - loss: 0.0385 - val_loss: 0.0378

Epoch 13/50

 - 5s - loss: 0.0346 - val_loss: 0.0353

Epoch 14/50

 - 5s - loss: 0.0328 - val_loss: 0.0339

Epoch 15/50

 - 4s - loss: 0.0401 - val_loss: 0.0384

Epoch 16/50

 - 5s - loss: 0.0252 - val_loss: 0.0508

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 722, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 709, after forget

time = 23196	action = 0	current_phase = 1	next_phase = 0	reward = -0.484288	array([[-1.9362235, -2.808253 ]], dtype=float32)

time = 23201	action = 0	current_phase = 1	next_phase = 0	reward = -0.320811	array([[-1.8873278, -2.8583698]], dtype=float32)

time = 23206	action = 0	current_phase = 1	next_phase = 0	reward = -0.181559	array([[-1.9706314, -2.6184585]], dtype=float32)

time = 23211	action = 0	current_phase = 1	next_phase = 0	reward = 0.276889	array([[-2.2378054, -3.5049193]], dtype=float32)

time = 23216	action = 1	current_phase = 1	next_phase = 0	reward = -1.608698	array([[-4.6842394, -3.353641 ]], dtype=float32)

time = 23224	action = 0	current_phase = 0	next_phase = 1	reward = -0.549871	array([[-2.1244533, -2.484785 ]], dtype=float32)

time = 23229	action = 0	current_phase = 0	next_phase = 1	reward = -0.393333	array([[-2.1177375, -2.4867544]], dtype=float32)

time = 23234	action = 0	current_phase = 0	next_phase = 1	reward = -0.245105	array([[-2.1527648, -3.0759978]], dtype=float32)

time = 23239	action = 0	current_phase = 0	next_phase = 1	reward = 0.114892	array([[-2.1384382, -3.1488736]], dtype=float32)

time = 23244	action = 1	current_phase = 0	next_phase = 1	reward = -0.650676	array([[-3.5403442, -2.6378634]], dtype=float32)

time = 23252	action = 0	current_phase = 1	next_phase = 0	reward = -0.622828	array([[-2.109702 , -2.6353343]], dtype=float32)

time = 23257	action = 0	current_phase = 1	next_phase = 0	reward = -0.466044	array([[-1.82493  , -3.0040367]], dtype=float32)

time = 23262	action = 0	current_phase = 1	next_phase = 0	reward = -0.321424	array([[-1.8175219, -2.6359506]], dtype=float32)

time = 23267	action = 0	current_phase = 1	next_phase = 0	reward = -0.185231	array([[-1.9205368, -2.755569 ]], dtype=float32)

time = 23272	action = 0	current_phase = 1	next_phase = 0	reward = 0.243381	array([[-2.3149369, -3.530575 ]], dtype=float32)

time = 23277	action = 1	current_phase = 1	next_phase = 0	reward = -1.778155	array([[-4.8908496, -3.5686023]], dtype=float32)

time = 23285	action = 0	current_phase = 0	next_phase = 1	reward = -0.525463	array([[-2.1899107, -2.9837182]], dtype=float32)

time = 23290	action = 0	current_phase = 0	next_phase = 1	reward = -0.361243	array([[-2.1176636, -2.4856296]], dtype=float32)

time = 23295	action = 0	current_phase = 0	next_phase = 1	reward = -0.207976	array([[-2.1343594, -3.050631 ]], dtype=float32)

time = 23300	action = 0	current_phase = 0	next_phase = 1	reward = 0.041034	array([[-2.2291243, -3.0721042]], dtype=float32)

time = 23305	action = 1	current_phase = 0	next_phase = 1	reward = -1.194695	array([[-3.8070261, -2.9491227]], dtype=float32)

time = 23313	action = 0	current_phase = 1	next_phase = 0	reward = -0.583506	array([[-2.0384536, -2.6598938]], dtype=float32)

time = 23318	action = 0	current_phase = 1	next_phase = 0	reward = -0.422971	array([[-1.9007558, -2.725216 ]], dtype=float32)

time = 23323	action = 0	current_phase = 1	next_phase = 0	reward = -0.267893	array([[-1.8785697, -2.628849 ]], dtype=float32)

time = 23328	action = 0	current_phase = 1	next_phase = 0	reward = -0.157511	array([[-2.0578127, -2.5832176]], dtype=float32)

time = 23333	action = 0	current_phase = 1	next_phase = 0	reward = 0.074041	array([[-2.7296379, -3.2601302]], dtype=float32)

time = 23338	action = 1	current_phase = 1	next_phase = 0	reward = -1.895929	array([[-4.9496746, -3.6590686]], dtype=float32)

time = 23346	action = 0	current_phase = 0	next_phase = 1	reward = -0.489293	array([[-2.172274, -2.926437]], dtype=float32)

time = 23351	action = 0	current_phase = 0	next_phase = 1	reward = -0.332411	array([[-2.1279957, -2.5565715]], dtype=float32)

time = 23356	action = 0	current_phase = 0	next_phase = 1	reward = -0.187888	array([[-2.2874548, -2.8682034]], dtype=float32)

time = 23361	action = 0	current_phase = 0	next_phase = 1	reward = 0.292059	array([[-2.4922297, -3.8406453]], dtype=float32)

time = 23366	action = 1	current_phase = 0	next_phase = 1	reward = -1.609918	array([[-4.0080676, -3.1830556]], dtype=float32)

time = 23374	action = 0	current_phase = 1	next_phase = 0	reward = -0.550462	array([[-1.9341635, -2.6784475]], dtype=float32)

time = 23379	action = 0	current_phase = 1	next_phase = 0	reward = -0.390114	array([[-1.7119491, -2.9244313]], dtype=float32)

time = 23384	action = 0	current_phase = 1	next_phase = 0	reward = -0.233965	array([[-1.6213628, -2.835668 ]], dtype=float32)

time = 23389	action = 0	current_phase = 1	next_phase = 0	reward = -0.183781	array([[-1.7826277, -3.127187 ]], dtype=float32)

time = 23394	action = 0	current_phase = 1	next_phase = 0	reward = -0.144485	array([[-2.264068 , -2.3888366]], dtype=float32)

time = 23399	action = 1	current_phase = 1	next_phase = 0	reward = -2.016531	array([[-4.867561 , -3.6418235]], dtype=float32)

time = 23407	action = 0	current_phase = 0	next_phase = 1	reward = -0.482562	array([[-2.1272547, -2.80397  ]], dtype=float32)

time = 23412	action = 0	current_phase = 0	next_phase = 1	reward = -0.325045	array([[-2.1690142, -2.7068024]], dtype=float32)

time = 23417	action = 0	current_phase = 0	next_phase = 1	reward = -0.181538	array([[-2.2609773, -2.825427 ]], dtype=float32)

time = 23422	action = 0	current_phase = 0	next_phase = 1	reward = 0.263355	array([[-2.631771 , -3.9581957]], dtype=float32)

time = 23427	action = 1	current_phase = 0	next_phase = 1	reward = -1.730019	array([[-4.014613 , -3.1063545]], dtype=float32)

time = 23435	action = 0	current_phase = 1	next_phase = 0	reward = -0.528845	array([[-1.8710612, -2.6372902]], dtype=float32)

time = 23440	action = 0	current_phase = 1	next_phase = 0	reward = -0.370325	array([[-1.6947566, -2.9154773]], dtype=float32)

time = 23445	action = 0	current_phase = 1	next_phase = 0	reward = -0.213913	array([[-1.6240711, -2.837491 ]], dtype=float32)

time = 23450	action = 0	current_phase = 1	next_phase = 0	reward = 0.366791	array([[-1.7905778, -3.206308 ]], dtype=float32)

time = 23455	action = 1	current_phase = 1	next_phase = 0	reward = -1.307005	array([[-3.5065646, -3.0296113]], dtype=float32)

time = 23463	action = 0	current_phase = 0	next_phase = 1	reward = -0.596392	array([[-2.2992847, -2.5925035]], dtype=float32)

time = 23468	action = 0	current_phase = 0	next_phase = 1	reward = -0.443477	array([[-2.118002 , -2.4853256]], dtype=float32)

time = 23473	action = 0	current_phase = 0	next_phase = 1	reward = -0.287529	array([[-2.153236 , -3.0099454]], dtype=float32)

time = 23478	action = 0	current_phase = 0	next_phase = 1	reward = -0.163613	array([[-2.342377 , -2.8097196]], dtype=float32)

time = 23483	action = 0	current_phase = 0	next_phase = 1	reward = 0.149892	array([[-2.6716497, -3.955917 ]], dtype=float32)

time = 23488	action = 1	current_phase = 0	next_phase = 1	reward = -1.895714	array([[-5.275447 , -3.3887541]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0608 - val_loss: 0.0247

Epoch 2/50

 - 5s - loss: 0.0471 - val_loss: 0.0254

Epoch 3/50

 - 4s - loss: 0.0580 - val_loss: 0.0251

Epoch 4/50

 - 5s - loss: 0.0482 - val_loss: 0.0241

Epoch 5/50

 - 4s - loss: 0.0443 - val_loss: 0.0248

Epoch 6/50

 - 5s - loss: 0.0383 - val_loss: 0.0247

Epoch 7/50

 - 5s - loss: 0.0423 - val_loss: 0.0256

Epoch 8/50

 - 5s - loss: 0.0431 - val_loss: 0.0264

Epoch 9/50

 - 4s - loss: 0.0438 - val_loss: 0.0267

Epoch 10/50

 - 5s - loss: 0.0381 - val_loss: 0.0269

Epoch 11/50

 - 5s - loss: 0.0361 - val_loss: 0.0273

Epoch 12/50

 - 4s - loss: 0.0266 - val_loss: 0.0275

Epoch 13/50

 - 5s - loss: 0.0299 - val_loss: 0.0263

Epoch 14/50

 - 5s - loss: 0.0329 - val_loss: 0.0275

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 727, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 714, after forget

time = 23496	action = 0	current_phase = 1	next_phase = 0	reward = -0.491662	array([[-1.8176112, -2.9200277]], dtype=float32)

time = 23501	action = 0	current_phase = 1	next_phase = 0	reward = -0.336939	array([[-1.8641884, -2.8004363]], dtype=float32)

time = 23506	action = 0	current_phase = 1	next_phase = 0	reward = -0.193496	array([[-1.9025689, -2.8085923]], dtype=float32)

time = 23511	action = 0	current_phase = 1	next_phase = 0	reward = 0.330881	array([[-2.347851, -3.52399 ]], dtype=float32)

time = 23516	action = 1	current_phase = 1	next_phase = 0	reward = -1.506602	array([[-4.700053 , -3.3351169]], dtype=float32)

time = 23524	action = 0	current_phase = 0	next_phase = 1	reward = -0.558234	array([[-2.1496491, -2.4867024]], dtype=float32)

time = 23529	action = 0	current_phase = 0	next_phase = 1	reward = -0.404636	array([[-2.1223416, -2.500574 ]], dtype=float32)

time = 23534	action = 0	current_phase = 0	next_phase = 1	reward = -0.253561	array([[-2.093104 , -3.0600433]], dtype=float32)

time = 23539	action = 0	current_phase = 0	next_phase = 1	reward = -0.187192	array([[-2.1091635, -3.1233778]], dtype=float32)

time = 23544	action = 1	current_phase = 0	next_phase = 1	reward = -0.537958	array([[-3.2956817, -2.178912 ]], dtype=float32)

time = 23552	action = 0	current_phase = 1	next_phase = 0	reward = -0.625822	array([[-2.0646386, -2.7160454]], dtype=float32)

time = 23557	action = 0	current_phase = 1	next_phase = 0	reward = -0.475974	array([[-1.7114938, -3.179356 ]], dtype=float32)

time = 23562	action = 0	current_phase = 1	next_phase = 0	reward = -0.312496	array([[-1.9814155, -2.734726 ]], dtype=float32)

time = 23567	action = 0	current_phase = 1	next_phase = 0	reward = -0.174394	array([[-1.9888806, -2.7590935]], dtype=float32)

time = 23572	action = 0	current_phase = 1	next_phase = 0	reward = 0.257391	array([[-2.3584087, -3.603357 ]], dtype=float32)

time = 23577	action = 1	current_phase = 1	next_phase = 0	reward = -1.783848	array([[-5.067555 , -3.5543911]], dtype=float32)

time = 23585	action = 0	current_phase = 0	next_phase = 1	reward = -0.534561	array([[-2.2085824, -2.991161 ]], dtype=float32)

time = 23590	action = 0	current_phase = 0	next_phase = 1	reward = -0.377011	array([[-2.125324, -2.490477]], dtype=float32)

time = 23595	action = 0	current_phase = 0	next_phase = 1	reward = -0.222677	array([[-2.0904918, -3.0609248]], dtype=float32)

time = 23600	action = 0	current_phase = 0	next_phase = 1	reward = 0.359242	array([[-2.0627606, -3.2412398]], dtype=float32)

time = 23605	action = 1	current_phase = 0	next_phase = 1	reward = -1.299145	array([[-3.9393651, -2.8503013]], dtype=float32)

time = 23613	action = 0	current_phase = 1	next_phase = 0	reward = -0.580941	array([[-2.1138144, -2.6999488]], dtype=float32)

time = 23618	action = 0	current_phase = 1	next_phase = 0	reward = -0.429049	array([[-1.9902914, -2.7360754]], dtype=float32)

time = 23623	action = 0	current_phase = 1	next_phase = 0	reward = -0.265037	array([[-1.936444, -2.66332 ]], dtype=float32)

time = 23628	action = 0	current_phase = 1	next_phase = 0	reward = -0.159671	array([[-2.0455675, -2.79815  ]], dtype=float32)

time = 23633	action = 0	current_phase = 1	next_phase = 0	reward = 0.052346	array([[-2.3142953, -2.5590742]], dtype=float32)

time = 23638	action = 1	current_phase = 1	next_phase = 0	reward = -1.895701	array([[-4.988868 , -3.6421914]], dtype=float32)

time = 23646	action = 0	current_phase = 0	next_phase = 1	reward = -0.503553	array([[-2.163095 , -2.8793287]], dtype=float32)

time = 23651	action = 0	current_phase = 0	next_phase = 1	reward = -0.359266	array([[-2.1357884, -2.4749649]], dtype=float32)

time = 23656	action = 0	current_phase = 0	next_phase = 1	reward = -0.210420	array([[-2.1425529, -2.9249485]], dtype=float32)

time = 23661	action = 0	current_phase = 0	next_phase = 1	reward = 0.324469	array([[-2.2970371, -3.439884 ]], dtype=float32)

time = 23666	action = 1	current_phase = 0	next_phase = 1	reward = -1.445748	array([[-3.8131995, -3.1359959]], dtype=float32)

time = 23674	action = 0	current_phase = 1	next_phase = 0	reward = -0.547821	array([[-1.9536115, -2.6773195]], dtype=float32)

time = 23679	action = 0	current_phase = 1	next_phase = 0	reward = -0.381718	array([[-1.7449853, -2.967661 ]], dtype=float32)

time = 23684	action = 0	current_phase = 1	next_phase = 0	reward = -0.228472	array([[-1.7205032, -2.8933983]], dtype=float32)

time = 23689	action = 0	current_phase = 1	next_phase = 0	reward = 0.103529	array([[-1.897289 , -3.2604358]], dtype=float32)

time = 23694	action = 1	current_phase = 1	next_phase = 0	reward = -0.820359	array([[-2.7695284, -2.6047142]], dtype=float32)

time = 23702	action = 0	current_phase = 0	next_phase = 1	reward = -0.612477	array([[-2.3928566, -2.6658435]], dtype=float32)

time = 23707	action = 0	current_phase = 0	next_phase = 1	reward = -0.452228	array([[-2.1247587, -2.492925 ]], dtype=float32)

time = 23712	action = 0	current_phase = 0	next_phase = 1	reward = -0.298511	array([[-2.158917 , -2.8810296]], dtype=float32)

time = 23717	action = 0	current_phase = 0	next_phase = 1	reward = -0.169234	array([[-2.2421763, -2.7431405]], dtype=float32)

time = 23722	action = 0	current_phase = 0	next_phase = 1	reward = 0.109380	array([[-2.6356413, -3.943665 ]], dtype=float32)

time = 23727	action = 1	current_phase = 0	next_phase = 1	reward = -1.785780	array([[-5.428275 , -3.4026568]], dtype=float32)

time = 23735	action = 0	current_phase = 1	next_phase = 0	reward = -0.525000	array([[-1.9423925, -2.682728 ]], dtype=float32)

time = 23740	action = 0	current_phase = 1	next_phase = 0	reward = -0.368665	array([[-1.7472978, -2.9717197]], dtype=float32)

time = 23745	action = 0	current_phase = 1	next_phase = 0	reward = -0.211409	array([[-1.6856396, -2.8919034]], dtype=float32)

time = 23750	action = 0	current_phase = 1	next_phase = 0	reward = 0.341342	array([[-2.0731373, -3.397908 ]], dtype=float32)

time = 23755	action = 1	current_phase = 1	next_phase = 0	reward = -1.420568	array([[-3.792062 , -3.2030103]], dtype=float32)

time = 23763	action = 0	current_phase = 0	next_phase = 1	reward = -0.586826	array([[-2.3034956, -2.6119564]], dtype=float32)

time = 23768	action = 0	current_phase = 0	next_phase = 1	reward = -0.428150	array([[-2.1238027, -2.494754 ]], dtype=float32)

time = 23773	action = 0	current_phase = 0	next_phase = 1	reward = -0.270212	array([[-2.0981257, -3.0516527]], dtype=float32)

time = 23778	action = 0	current_phase = 0	next_phase = 1	reward = -0.166965	array([[-2.2576375, -2.7884588]], dtype=float32)

time = 23783	action = 0	current_phase = 0	next_phase = 1	reward = -0.009153	array([[-2.9823093, -3.5587826]], dtype=float32)

time = 23788	action = 1	current_phase = 0	next_phase = 1	reward = -1.895953	array([[-5.4070244, -3.433974 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0416 - val_loss: 0.0758

Epoch 2/50

 - 5s - loss: 0.0465 - val_loss: 0.0754

Epoch 3/50

 - 4s - loss: 0.0476 - val_loss: 0.0628

Epoch 4/50

 - 5s - loss: 0.0596 - val_loss: 0.0625

Epoch 5/50

 - 6s - loss: 0.0431 - val_loss: 0.0618

Epoch 6/50

 - 4s - loss: 0.0572 - val_loss: 0.0624

Epoch 7/50

 - 5s - loss: 0.0414 - val_loss: 0.0603

Epoch 8/50

 - 4s - loss: 0.0394 - val_loss: 0.0561

Epoch 9/50

 - 5s - loss: 0.0400 - val_loss: 0.0657

Epoch 10/50

 - 5s - loss: 0.0380 - val_loss: 0.0608

Epoch 11/50

 - 5s - loss: 0.0431 - val_loss: 0.0520

Epoch 12/50

 - 5s - loss: 0.0472 - val_loss: 0.0592

Epoch 13/50

 - 4s - loss: 0.0447 - val_loss: 0.0584

Epoch 14/50

 - 4s - loss: 0.0343 - val_loss: 0.0721

Epoch 15/50

 - 5s - loss: 0.0357 - val_loss: 0.0615

Epoch 16/50

 - 4s - loss: 0.0397 - val_loss: 0.0574

Epoch 17/50

 - 4s - loss: 0.0344 - val_loss: 0.0707

Epoch 18/50

 - 5s - loss: 0.0431 - val_loss: 0.0641

Epoch 19/50

 - 5s - loss: 0.0492 - val_loss: 0.0623

Epoch 20/50

 - 5s - loss: 0.0341 - val_loss: 0.0655

Epoch 21/50

 - 5s - loss: 0.0389 - val_loss: 0.0669

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 732, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 719, after forget

time = 23796	action = 0	current_phase = 1	next_phase = 0	reward = -0.494337	array([[-1.9577432, -2.9292023]], dtype=float32)

time = 23801	action = 0	current_phase = 1	next_phase = 0	reward = -0.339566	array([[-1.9770174, -2.8683457]], dtype=float32)

time = 23806	action = 0	current_phase = 1	next_phase = 0	reward = -0.184476	array([[-2.0488772, -2.7533884]], dtype=float32)

time = 23811	action = 0	current_phase = 1	next_phase = 0	reward = 0.299547	array([[-2.4253023, -3.5835042]], dtype=float32)

time = 23816	action = 1	current_phase = 1	next_phase = 0	reward = -1.610605	array([[-4.8179708, -3.4058123]], dtype=float32)

time = 23824	action = 0	current_phase = 0	next_phase = 1	reward = -0.568018	array([[-2.1980371, -2.6185586]], dtype=float32)

time = 23829	action = 0	current_phase = 0	next_phase = 1	reward = -0.430388	array([[-2.0692775, -2.5321016]], dtype=float32)

time = 23834	action = 0	current_phase = 0	next_phase = 1	reward = -0.280959	array([[-2.0610857, -3.0419126]], dtype=float32)

time = 23839	action = 0	current_phase = 0	next_phase = 1	reward = -0.175286	array([[-2.061213 , -3.0621445]], dtype=float32)

time = 23844	action = 1	current_phase = 0	next_phase = 1	reward = -0.475385	array([[-3.0468643, -2.3318434]], dtype=float32)

time = 23852	action = 0	current_phase = 1	next_phase = 0	reward = -0.613385	array([[-2.0018172, -2.8182032]], dtype=float32)

time = 23857	action = 0	current_phase = 1	next_phase = 0	reward = -0.465630	array([[-1.8928237, -3.154309 ]], dtype=float32)

time = 23862	action = 0	current_phase = 1	next_phase = 0	reward = -0.318787	array([[-1.952601, -2.783749]], dtype=float32)

time = 23867	action = 0	current_phase = 1	next_phase = 0	reward = -0.180744	array([[-2.0211594, -2.7816083]], dtype=float32)

time = 23872	action = 0	current_phase = 1	next_phase = 0	reward = 0.260228	array([[-2.6000483, -3.5999138]], dtype=float32)

time = 23877	action = 1	current_phase = 1	next_phase = 0	reward = -1.734349	array([[-4.742653, -3.486172]], dtype=float32)

time = 23885	action = 0	current_phase = 0	next_phase = 1	reward = -0.538517	array([[-2.1174839, -2.8966393]], dtype=float32)

time = 23890	action = 0	current_phase = 0	next_phase = 1	reward = -0.379808	array([[-2.06897 , -2.529222]], dtype=float32)

time = 23895	action = 0	current_phase = 0	next_phase = 1	reward = -0.231099	array([[-2.052555 , -3.0500379]], dtype=float32)

time = 23900	action = 0	current_phase = 0	next_phase = 1	reward = 0.066062	array([[-2.0202675, -3.2282984]], dtype=float32)

time = 23905	action = 1	current_phase = 0	next_phase = 1	reward = -0.969187	array([[-3.7095473, -2.4394794]], dtype=float32)

time = 23913	action = 0	current_phase = 1	next_phase = 0	reward = -0.588631	array([[-2.125236 , -2.7707531]], dtype=float32)

time = 23918	action = 0	current_phase = 1	next_phase = 0	reward = -0.436151	array([[-2.0247374, -2.792148 ]], dtype=float32)

time = 23923	action = 0	current_phase = 1	next_phase = 0	reward = -0.282566	array([[-1.965883 , -2.7170002]], dtype=float32)

time = 23928	action = 0	current_phase = 1	next_phase = 0	reward = -0.170320	array([[-2.1485164, -2.8965018]], dtype=float32)

time = 23933	action = 0	current_phase = 1	next_phase = 0	reward = -0.063959	array([[-2.578407, -2.911912]], dtype=float32)

time = 23938	action = 1	current_phase = 1	next_phase = 0	reward = -1.905038	array([[-5.0616517, -3.675751 ]], dtype=float32)

time = 23946	action = 0	current_phase = 0	next_phase = 1	reward = -0.501228	array([[-2.1200233, -3.0138686]], dtype=float32)

time = 23951	action = 0	current_phase = 0	next_phase = 1	reward = -0.346689	array([[-2.072302 , -2.5326447]], dtype=float32)

time = 23956	action = 0	current_phase = 0	next_phase = 1	reward = -0.193569	array([[-2.0545642, -3.0453327]], dtype=float32)

time = 23961	action = 0	current_phase = 0	next_phase = 1	reward = 0.307881	array([[-2.3211093, -3.719388 ]], dtype=float32)

time = 23966	action = 1	current_phase = 0	next_phase = 1	reward = -1.611549	array([[-3.9802158, -3.2010355]], dtype=float32)

time = 23974	action = 0	current_phase = 1	next_phase = 0	reward = -0.557084	array([[-1.9856577, -2.7250896]], dtype=float32)

time = 23979	action = 0	current_phase = 1	next_phase = 0	reward = -0.398232	array([[-1.7500445, -3.0043163]], dtype=float32)

time = 23984	action = 0	current_phase = 1	next_phase = 0	reward = -0.252910	array([[-1.76955  , -2.8962088]], dtype=float32)

time = 23989	action = 0	current_phase = 1	next_phase = 0	reward = 0.104044	array([[-1.9087789, -3.2124157]], dtype=float32)

time = 23994	action = 1	current_phase = 1	next_phase = 0	reward = -0.803076	array([[-2.7925713, -2.4043026]], dtype=float32)

time = 24002	action = 0	current_phase = 0	next_phase = 1	reward = -0.622128	array([[-2.3514132, -2.7403703]], dtype=float32)

time = 24007	action = 0	current_phase = 0	next_phase = 1	reward = -0.464753	array([[-2.0759795, -2.5577075]], dtype=float32)

time = 24012	action = 0	current_phase = 0	next_phase = 1	reward = -0.304814	array([[-2.1414838, -2.7982156]], dtype=float32)

time = 24017	action = 0	current_phase = 0	next_phase = 1	reward = -0.175463	array([[-2.190992 , -2.8181705]], dtype=float32)

time = 24022	action = 0	current_phase = 0	next_phase = 1	reward = 0.196950	array([[-2.505188, -4.205575]], dtype=float32)

time = 24027	action = 1	current_phase = 0	next_phase = 1	reward = -1.778819	array([[-5.3893247, -3.3669624]], dtype=float32)

time = 24035	action = 0	current_phase = 1	next_phase = 0	reward = -0.522462	array([[-1.9396528, -2.8230495]], dtype=float32)

time = 24040	action = 0	current_phase = 1	next_phase = 0	reward = -0.374968	array([[-1.7953737, -3.0286002]], dtype=float32)

time = 24045	action = 0	current_phase = 1	next_phase = 0	reward = -0.218694	array([[-1.7270248, -2.942007 ]], dtype=float32)

time = 24050	action = 0	current_phase = 1	next_phase = 0	reward = 0.345320	array([[-1.800333, -3.403923]], dtype=float32)

time = 24055	action = 1	current_phase = 1	next_phase = 0	reward = -1.318412	array([[-3.6963015, -3.1393886]], dtype=float32)

time = 24063	action = 0	current_phase = 0	next_phase = 1	reward = -0.588765	array([[-2.1419182, -2.5831318]], dtype=float32)

time = 24068	action = 0	current_phase = 0	next_phase = 1	reward = -0.431421	array([[-2.0687764, -2.527058 ]], dtype=float32)

time = 24073	action = 0	current_phase = 0	next_phase = 1	reward = -0.282227	array([[-2.0673335, -3.0252414]], dtype=float32)

time = 24078	action = 0	current_phase = 0	next_phase = 1	reward = -0.167657	array([[-2.245675, -2.829429]], dtype=float32)

time = 24083	action = 0	current_phase = 0	next_phase = 1	reward = 0.029825	array([[-2.5578992, -4.2580323]], dtype=float32)

time = 24088	action = 1	current_phase = 0	next_phase = 1	reward = -1.898396	array([[-5.4390116, -3.4386542]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0704 - val_loss: 0.0237

Epoch 2/50

 - 5s - loss: 0.0546 - val_loss: 0.0254

Epoch 3/50

 - 5s - loss: 0.0540 - val_loss: 0.0272

Epoch 4/50

 - 5s - loss: 0.0693 - val_loss: 0.0263

Epoch 5/50

 - 5s - loss: 0.0363 - val_loss: 0.0269

Epoch 6/50

 - 4s - loss: 0.0454 - val_loss: 0.0277

Epoch 7/50

 - 4s - loss: 0.0384 - val_loss: 0.0273

Epoch 8/50

 - 4s - loss: 0.0519 - val_loss: 0.0268

Epoch 9/50

 - 4s - loss: 0.0339 - val_loss: 0.0286

Epoch 10/50

 - 5s - loss: 0.0296 - val_loss: 0.0315

Epoch 11/50

 - 5s - loss: 0.0372 - val_loss: 0.0306

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 737, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 724, after forget

time = 24096	action = 0	current_phase = 1	next_phase = 0	reward = -0.490812	array([[-1.9767277, -2.9850497]], dtype=float32)

time = 24101	action = 0	current_phase = 1	next_phase = 0	reward = -0.339302	array([[-2.0337012, -2.9501944]], dtype=float32)

time = 24106	action = 0	current_phase = 1	next_phase = 0	reward = -0.195942	array([[-2.0418394, -2.8930016]], dtype=float32)

time = 24111	action = 0	current_phase = 1	next_phase = 0	reward = 0.300588	array([[-2.4266021, -3.571417 ]], dtype=float32)

time = 24116	action = 1	current_phase = 1	next_phase = 0	reward = -1.555698	array([[-4.7946267, -3.2318225]], dtype=float32)

time = 24124	action = 0	current_phase = 0	next_phase = 1	reward = -0.551623	array([[-2.2095501, -2.581496 ]], dtype=float32)

time = 24129	action = 0	current_phase = 0	next_phase = 1	reward = -0.401463	array([[-2.0954208, -2.5042396]], dtype=float32)

time = 24134	action = 0	current_phase = 0	next_phase = 1	reward = -0.244540	array([[-2.05571 , -3.014529]], dtype=float32)

time = 24139	action = 0	current_phase = 0	next_phase = 1	reward = -0.185205	array([[-2.0154393, -3.183821 ]], dtype=float32)

time = 24144	action = 1	current_phase = 0	next_phase = 1	reward = -0.559519	array([[-2.8958616, -2.0435662]], dtype=float32)

time = 24152	action = 0	current_phase = 1	next_phase = 0	reward = -0.610745	array([[-2.0887702, -2.7887707]], dtype=float32)

time = 24157	action = 0	current_phase = 1	next_phase = 0	reward = -0.454544	array([[-1.9371238, -3.1653209]], dtype=float32)

time = 24162	action = 0	current_phase = 1	next_phase = 0	reward = -0.301884	array([[-1.9843006, -2.7715762]], dtype=float32)

time = 24167	action = 0	current_phase = 1	next_phase = 0	reward = -0.167600	array([[-2.2203224, -2.751989 ]], dtype=float32)

time = 24172	action = 0	current_phase = 1	next_phase = 0	reward = 0.233847	array([[-2.5591831, -3.5829275]], dtype=float32)

time = 24177	action = 1	current_phase = 1	next_phase = 0	reward = -1.782217	array([[-5.078653, -3.541286]], dtype=float32)

time = 24185	action = 0	current_phase = 0	next_phase = 1	reward = -0.533061	array([[-2.1667166, -2.990627 ]], dtype=float32)

time = 24190	action = 0	current_phase = 0	next_phase = 1	reward = -0.385363	array([[-2.0954275, -2.506191 ]], dtype=float32)

time = 24195	action = 0	current_phase = 0	next_phase = 1	reward = -0.232485	array([[-2.0595367, -3.005094 ]], dtype=float32)

time = 24200	action = 0	current_phase = 0	next_phase = 1	reward = 0.058395	array([[-1.9790292, -3.4754534]], dtype=float32)

time = 24205	action = 1	current_phase = 0	next_phase = 1	reward = -1.083782	array([[-3.6057372, -2.5867798]], dtype=float32)

time = 24213	action = 0	current_phase = 1	next_phase = 0	reward = -0.589452	array([[-2.2073467, -2.7432406]], dtype=float32)

time = 24218	action = 0	current_phase = 1	next_phase = 0	reward = -0.428659	array([[-2.052574 , -2.7839599]], dtype=float32)

time = 24223	action = 0	current_phase = 1	next_phase = 0	reward = -0.270576	array([[-2.0176213, -2.7439172]], dtype=float32)

time = 24228	action = 0	current_phase = 1	next_phase = 0	reward = -0.157985	array([[-2.2113478, -2.7584865]], dtype=float32)

time = 24233	action = 0	current_phase = 1	next_phase = 0	reward = 0.024666	array([[-2.394103 , -2.5468044]], dtype=float32)

time = 24238	action = 1	current_phase = 1	next_phase = 0	reward = -1.900255	array([[-5.082019 , -3.6210396]], dtype=float32)

time = 24246	action = 0	current_phase = 0	next_phase = 1	reward = -0.495381	array([[-2.1523952, -2.9864888]], dtype=float32)

time = 24251	action = 0	current_phase = 0	next_phase = 1	reward = -0.336813	array([[-2.085769 , -2.5686574]], dtype=float32)

time = 24256	action = 0	current_phase = 0	next_phase = 1	reward = -0.190394	array([[-2.086708 , -2.9612975]], dtype=float32)

time = 24261	action = 0	current_phase = 0	next_phase = 1	reward = 0.290777	array([[-2.1780636, -3.9401762]], dtype=float32)

time = 24266	action = 1	current_phase = 0	next_phase = 1	reward = -1.665011	array([[-3.912008 , -3.0390913]], dtype=float32)

time = 24274	action = 0	current_phase = 1	next_phase = 0	reward = -0.568773	array([[-2.057794 , -2.7832954]], dtype=float32)

time = 24279	action = 0	current_phase = 1	next_phase = 0	reward = -0.427876	array([[-1.7852151, -3.0416672]], dtype=float32)

time = 24284	action = 0	current_phase = 1	next_phase = 0	reward = -0.262321	array([[-1.7950213, -2.9139173]], dtype=float32)

time = 24289	action = 0	current_phase = 1	next_phase = 0	reward = -0.169566	array([[-2.0019293, -3.085574 ]], dtype=float32)

time = 24294	action = 0	current_phase = 1	next_phase = 0	reward = 0.040288	array([[-2.170521 , -2.2827766]], dtype=float32)

time = 24299	action = 1	current_phase = 1	next_phase = 0	reward = -2.011969	array([[-5.0661054, -3.6214914]], dtype=float32)

time = 24307	action = 0	current_phase = 0	next_phase = 1	reward = -0.476071	array([[-2.162465 , -2.8884635]], dtype=float32)

time = 24312	action = 0	current_phase = 0	next_phase = 1	reward = -0.323020	array([[-2.0822656, -2.6943579]], dtype=float32)

time = 24317	action = 0	current_phase = 0	next_phase = 1	reward = -0.181304	array([[-2.1653218, -2.7383437]], dtype=float32)

time = 24322	action = 0	current_phase = 0	next_phase = 1	reward = 0.260038	array([[-2.3418605, -4.001119 ]], dtype=float32)

time = 24327	action = 1	current_phase = 0	next_phase = 1	reward = -1.779243	array([[-3.7886095, -3.0118873]], dtype=float32)

time = 24335	action = 0	current_phase = 1	next_phase = 0	reward = -0.521167	array([[-2.0096583, -2.738554 ]], dtype=float32)

time = 24340	action = 0	current_phase = 1	next_phase = 0	reward = -0.365197	array([[-1.8024778, -3.0194225]], dtype=float32)

time = 24345	action = 0	current_phase = 1	next_phase = 0	reward = -0.216079	array([[-1.741231 , -2.9479172]], dtype=float32)

time = 24350	action = 0	current_phase = 1	next_phase = 0	reward = 0.364535	array([[-1.9467161, -3.2222824]], dtype=float32)

time = 24355	action = 1	current_phase = 1	next_phase = 0	reward = -1.306564	array([[-3.7633748, -2.997953 ]], dtype=float32)

time = 24363	action = 0	current_phase = 0	next_phase = 1	reward = -0.586351	array([[-2.2321632, -2.6094246]], dtype=float32)

time = 24368	action = 0	current_phase = 0	next_phase = 1	reward = -0.430682	array([[-2.0972846, -2.5058122]], dtype=float32)

time = 24373	action = 0	current_phase = 0	next_phase = 1	reward = -0.283821	array([[-2.0608861, -3.0110962]], dtype=float32)

time = 24378	action = 0	current_phase = 0	next_phase = 1	reward = -0.166889	array([[-2.2297876, -2.6840603]], dtype=float32)

time = 24383	action = 0	current_phase = 0	next_phase = 1	reward = -0.041929	array([[-3.015599 , -4.3584857]], dtype=float32)

time = 24388	action = 1	current_phase = 0	next_phase = 1	reward = -1.895310	array([[-5.496979 , -3.3662846]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0518 - val_loss: 0.0309

Epoch 2/50

 - 4s - loss: 0.0822 - val_loss: 0.0342

Epoch 3/50

 - 5s - loss: 0.0570 - val_loss: 0.0300

Epoch 4/50

 - 5s - loss: 0.0508 - val_loss: 0.0379

Epoch 5/50

 - 5s - loss: 0.0557 - val_loss: 0.0389

Epoch 6/50

 - 4s - loss: 0.0469 - val_loss: 0.0398

Epoch 7/50

 - 5s - loss: 0.0639 - val_loss: 0.0357

Epoch 8/50

 - 4s - loss: 0.0617 - val_loss: 0.0376

Epoch 9/50

 - 5s - loss: 0.0415 - val_loss: 0.0397

Epoch 10/50

 - 4s - loss: 0.0375 - val_loss: 0.0412

Epoch 11/50

 - 4s - loss: 0.0419 - val_loss: 0.0372

Epoch 12/50

 - 5s - loss: 0.0545 - val_loss: 0.0403

Epoch 13/50

 - 5s - loss: 0.0513 - val_loss: 0.0351

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 742, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 729, after forget

time = 24396	action = 0	current_phase = 1	next_phase = 0	reward = -0.484434	array([[-2.0414908, -2.9641852]], dtype=float32)

time = 24401	action = 0	current_phase = 1	next_phase = 0	reward = -0.324330	array([[-2.068223 , -2.8150356]], dtype=float32)

time = 24406	action = 0	current_phase = 1	next_phase = 0	reward = -0.182675	array([[-2.2619953, -2.763706 ]], dtype=float32)

time = 24411	action = 0	current_phase = 1	next_phase = 0	reward = 0.276081	array([[-2.3887892, -3.6606228]], dtype=float32)

time = 24416	action = 1	current_phase = 1	next_phase = 0	reward = -1.611845	array([[-4.7884717, -3.3070207]], dtype=float32)

time = 24424	action = 0	current_phase = 0	next_phase = 1	reward = -0.554612	array([[-2.1708412, -2.6116953]], dtype=float32)

time = 24429	action = 0	current_phase = 0	next_phase = 1	reward = -0.394720	array([[-2.058271, -2.535242]], dtype=float32)

time = 24434	action = 0	current_phase = 0	next_phase = 1	reward = -0.248412	array([[-1.999751 , -3.0825248]], dtype=float32)

time = 24439	action = 0	current_phase = 0	next_phase = 1	reward = -0.197853	array([[-1.9303524, -3.3350658]], dtype=float32)

time = 24444	action = 1	current_phase = 0	next_phase = 1	reward = -0.580757	array([[-3.1981196, -2.2234378]], dtype=float32)

time = 24452	action = 0	current_phase = 1	next_phase = 0	reward = -0.624550	array([[-2.1238751, -2.7923985]], dtype=float32)

time = 24457	action = 0	current_phase = 1	next_phase = 0	reward = -0.469748	array([[-1.9603511, -3.1669269]], dtype=float32)

time = 24462	action = 0	current_phase = 1	next_phase = 0	reward = -0.314735	array([[-2.0569408, -2.7764664]], dtype=float32)

time = 24467	action = 0	current_phase = 1	next_phase = 0	reward = -0.172765	array([[-2.3006608, -2.7746718]], dtype=float32)

time = 24472	action = 0	current_phase = 1	next_phase = 0	reward = 0.243837	array([[-2.637687 , -3.5748732]], dtype=float32)

time = 24477	action = 1	current_phase = 1	next_phase = 0	reward = -1.778573	array([[-5.134498 , -3.5661798]], dtype=float32)

time = 24485	action = 0	current_phase = 0	next_phase = 1	reward = -0.518087	array([[-2.1927803, -3.0276546]], dtype=float32)

time = 24490	action = 0	current_phase = 0	next_phase = 1	reward = -0.367045	array([[-2.0582452, -2.536429 ]], dtype=float32)

time = 24495	action = 0	current_phase = 0	next_phase = 1	reward = -0.221283	array([[-1.9982439, -3.0852575]], dtype=float32)

time = 24500	action = 0	current_phase = 0	next_phase = 1	reward = 0.351000	array([[-2.0392544, -3.0950646]], dtype=float32)

time = 24505	action = 1	current_phase = 0	next_phase = 1	reward = -1.367633	array([[-3.618738 , -3.0973206]], dtype=float32)

time = 24513	action = 0	current_phase = 1	next_phase = 0	reward = -0.589798	array([[-2.1062942, -2.8017602]], dtype=float32)

time = 24518	action = 0	current_phase = 1	next_phase = 0	reward = -0.437701	array([[-2.039213 , -2.8362863]], dtype=float32)

time = 24523	action = 0	current_phase = 1	next_phase = 0	reward = -0.284406	array([[-2.0425935, -2.7467144]], dtype=float32)

time = 24528	action = 0	current_phase = 1	next_phase = 0	reward = -0.162833	array([[-2.2921367, -2.7724144]], dtype=float32)

time = 24533	action = 0	current_phase = 1	next_phase = 0	reward = 0.122758	array([[-2.7680523, -3.2414532]], dtype=float32)

time = 24538	action = 1	current_phase = 1	next_phase = 0	reward = -1.894099	array([[-5.1805406, -3.603976 ]], dtype=float32)

time = 24546	action = 0	current_phase = 0	next_phase = 1	reward = -0.492818	array([[-2.166931 , -2.9950309]], dtype=float32)

time = 24551	action = 0	current_phase = 0	next_phase = 1	reward = -0.333799	array([[-2.0690858, -2.5457668]], dtype=float32)

time = 24556	action = 0	current_phase = 0	next_phase = 1	reward = -0.192070	array([[-2.06238  , -2.9533205]], dtype=float32)

time = 24561	action = 0	current_phase = 0	next_phase = 1	reward = 0.289830	array([[-2.272102 , -3.7859335]], dtype=float32)

time = 24566	action = 1	current_phase = 0	next_phase = 1	reward = -1.554855	array([[-3.6589804, -3.1878176]], dtype=float32)

time = 24574	action = 0	current_phase = 1	next_phase = 0	reward = -0.548612	array([[-1.9572511, -2.67216  ]], dtype=float32)

time = 24579	action = 0	current_phase = 1	next_phase = 0	reward = -0.401000	array([[-1.8546623, -3.0080454]], dtype=float32)

time = 24584	action = 0	current_phase = 1	next_phase = 0	reward = -0.240967	array([[-1.771914, -2.938905]], dtype=float32)

time = 24589	action = 0	current_phase = 1	next_phase = 0	reward = -0.172329	array([[-1.9813153, -3.241774 ]], dtype=float32)

time = 24594	action = 0	current_phase = 1	next_phase = 0	reward = -0.130854	array([[-2.2554557, -2.2818074]], dtype=float32)

time = 24599	action = 1	current_phase = 1	next_phase = 0	reward = -2.008123	array([[-4.97179  , -3.6484437]], dtype=float32)

time = 24607	action = 0	current_phase = 0	next_phase = 1	reward = -0.457155	array([[-2.144776 , -2.8321314]], dtype=float32)

time = 24612	action = 0	current_phase = 0	next_phase = 1	reward = -0.297429	array([[-2.015143, -2.978197]], dtype=float32)

time = 24617	action = 0	current_phase = 0	next_phase = 1	reward = -0.165979	array([[-2.3303802, -2.920631 ]], dtype=float32)

time = 24622	action = 0	current_phase = 0	next_phase = 1	reward = 0.172199	array([[-2.6183712, -4.0232334]], dtype=float32)

time = 24627	action = 1	current_phase = 0	next_phase = 1	reward = -1.783198	array([[-5.0780964, -3.4944568]], dtype=float32)

time = 24635	action = 0	current_phase = 1	next_phase = 0	reward = -0.525503	array([[-2.0449617, -2.7817132]], dtype=float32)

time = 24640	action = 0	current_phase = 1	next_phase = 0	reward = -0.359612	array([[-1.8154992, -3.0075617]], dtype=float32)

time = 24645	action = 0	current_phase = 1	next_phase = 0	reward = -0.202177	array([[-1.7659882, -2.9330947]], dtype=float32)

time = 24650	action = 0	current_phase = 1	next_phase = 0	reward = 0.355859	array([[-1.9068153, -3.4396896]], dtype=float32)

time = 24655	action = 1	current_phase = 1	next_phase = 0	reward = -1.361147	array([[-3.9969351, -3.2402902]], dtype=float32)

time = 24663	action = 0	current_phase = 0	next_phase = 1	reward = -0.584999	array([[-2.2554324, -2.6836634]], dtype=float32)

time = 24668	action = 0	current_phase = 0	next_phase = 1	reward = -0.431506	array([[-2.0605752, -2.5413241]], dtype=float32)

time = 24673	action = 0	current_phase = 0	next_phase = 1	reward = -0.281025	array([[-2.005846 , -3.0784097]], dtype=float32)

time = 24678	action = 0	current_phase = 0	next_phase = 1	reward = -0.164367	array([[-2.1475122, -2.7827678]], dtype=float32)

time = 24683	action = 0	current_phase = 0	next_phase = 1	reward = 0.035737	array([[-2.862716 , -3.5237536]], dtype=float32)

time = 24688	action = 1	current_phase = 0	next_phase = 1	reward = -1.899248	array([[-5.5092206, -3.515275 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0770 - val_loss: 0.0190

Epoch 2/50

 - 5s - loss: 0.0611 - val_loss: 0.0192

Epoch 3/50

 - 5s - loss: 0.0602 - val_loss: 0.0176

Epoch 4/50

 - 4s - loss: 0.0525 - val_loss: 0.0241

Epoch 5/50

 - 4s - loss: 0.0777 - val_loss: 0.0224

Epoch 6/50

 - 4s - loss: 0.0548 - val_loss: 0.0237

Epoch 7/50

 - 4s - loss: 0.0527 - val_loss: 0.0285

Epoch 8/50

 - 4s - loss: 0.0658 - val_loss: 0.0225

Epoch 9/50

 - 4s - loss: 0.0435 - val_loss: 0.0227

Epoch 10/50

 - 4s - loss: 0.0507 - val_loss: 0.0215

Epoch 11/50

 - 4s - loss: 0.0621 - val_loss: 0.0220

Epoch 12/50

 - 4s - loss: 0.0490 - val_loss: 0.0207

Epoch 13/50

 - 4s - loss: 0.0404 - val_loss: 0.0201

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 747, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 734, after forget

time = 24696	action = 0	current_phase = 1	next_phase = 0	reward = -0.490747	array([[-2.0714383, -3.0200472]], dtype=float32)

time = 24701	action = 0	current_phase = 1	next_phase = 0	reward = -0.342626	array([[-2.1090734, -2.8240755]], dtype=float32)

time = 24706	action = 0	current_phase = 1	next_phase = 0	reward = -0.199014	array([[-2.2567222, -2.8661458]], dtype=float32)

time = 24711	action = 0	current_phase = 1	next_phase = 0	reward = 0.299367	array([[-2.3925881, -3.6369696]], dtype=float32)

time = 24716	action = 1	current_phase = 1	next_phase = 0	reward = -1.609366	array([[-4.9013104, -3.3377497]], dtype=float32)

time = 24724	action = 0	current_phase = 0	next_phase = 1	reward = -0.562335	array([[-2.161836 , -2.5559556]], dtype=float32)

time = 24729	action = 0	current_phase = 0	next_phase = 1	reward = -0.412219	array([[-2.0648892, -2.4964602]], dtype=float32)

time = 24734	action = 0	current_phase = 0	next_phase = 1	reward = -0.259760	array([[-2.0149367, -3.0795195]], dtype=float32)

time = 24739	action = 0	current_phase = 0	next_phase = 1	reward = -0.170863	array([[-1.9276359, -3.4078531]], dtype=float32)

time = 24744	action = 1	current_phase = 0	next_phase = 1	reward = -0.370228	array([[-3.010281, -2.049146]], dtype=float32)

time = 24752	action = 0	current_phase = 1	next_phase = 0	reward = -0.623388	array([[-2.2692642, -2.79756  ]], dtype=float32)

time = 24757	action = 0	current_phase = 1	next_phase = 0	reward = -0.471647	array([[-2.013619 , -3.2290323]], dtype=float32)

time = 24762	action = 0	current_phase = 1	next_phase = 0	reward = -0.318229	array([[-2.082528 , -2.7979658]], dtype=float32)

time = 24767	action = 0	current_phase = 1	next_phase = 0	reward = -0.180109	array([[-2.1460266, -2.916582 ]], dtype=float32)

time = 24772	action = 0	current_phase = 1	next_phase = 0	reward = 0.199215	array([[-2.3477664, -3.6707945]], dtype=float32)

time = 24777	action = 1	current_phase = 1	next_phase = 0	reward = -1.731300	array([[-4.9156327, -3.6406207]], dtype=float32)

time = 24785	action = 0	current_phase = 0	next_phase = 1	reward = -0.530753	array([[-2.1663415, -2.9754434]], dtype=float32)

time = 24790	action = 0	current_phase = 0	next_phase = 1	reward = -0.375428	array([[-2.0650082, -2.4942534]], dtype=float32)

time = 24795	action = 0	current_phase = 0	next_phase = 1	reward = -0.220393	array([[-2.0081666, -3.0796087]], dtype=float32)

time = 24800	action = 0	current_phase = 0	next_phase = 1	reward = 0.064070	array([[-2.0260773, -3.400402 ]], dtype=float32)

time = 24805	action = 1	current_phase = 0	next_phase = 1	reward = -1.072858	array([[-3.4502013, -2.8625312]], dtype=float32)

time = 24813	action = 0	current_phase = 1	next_phase = 0	reward = -0.579503	array([[-2.236498, -2.807973]], dtype=float32)

time = 24818	action = 0	current_phase = 1	next_phase = 0	reward = -0.422545	array([[-2.1134534, -2.852051 ]], dtype=float32)

time = 24823	action = 0	current_phase = 1	next_phase = 0	reward = -0.268985	array([[-2.0861049, -2.7873433]], dtype=float32)

time = 24828	action = 0	current_phase = 1	next_phase = 0	reward = -0.167385	array([[-2.2160287, -2.9156718]], dtype=float32)

time = 24833	action = 0	current_phase = 1	next_phase = 0	reward = 0.064669	array([[-2.2082787, -2.2893898]], dtype=float32)

time = 24838	action = 1	current_phase = 1	next_phase = 0	reward = -1.895697	array([[-5.1389084, -3.6379523]], dtype=float32)

time = 24846	action = 0	current_phase = 0	next_phase = 1	reward = -0.494092	array([[-2.1883204, -2.9259343]], dtype=float32)

time = 24851	action = 0	current_phase = 0	next_phase = 1	reward = -0.340023	array([[-2.080595 , -2.4916902]], dtype=float32)

time = 24856	action = 0	current_phase = 0	next_phase = 1	reward = -0.191446	array([[-2.025781 , -3.0240312]], dtype=float32)

time = 24861	action = 0	current_phase = 0	next_phase = 1	reward = 0.298143	array([[-2.2344806, -3.732771 ]], dtype=float32)

time = 24866	action = 1	current_phase = 0	next_phase = 1	reward = -1.557225	array([[-3.8797061, -3.084281 ]], dtype=float32)

time = 24874	action = 0	current_phase = 1	next_phase = 0	reward = -0.563911	array([[-2.0737014, -2.7781022]], dtype=float32)

time = 24879	action = 0	current_phase = 1	next_phase = 0	reward = -0.407489	array([[-1.8950514, -3.0585668]], dtype=float32)

time = 24884	action = 0	current_phase = 1	next_phase = 0	reward = -0.253946	array([[-1.8117108, -2.9468083]], dtype=float32)

time = 24889	action = 0	current_phase = 1	next_phase = 0	reward = -0.172225	array([[-2.0235982, -3.3321893]], dtype=float32)

time = 24894	action = 0	current_phase = 1	next_phase = 0	reward = -0.132905	array([[-1.9681839, -2.2526786]], dtype=float32)

time = 24899	action = 1	current_phase = 1	next_phase = 0	reward = -2.014995	array([[-4.9113073, -3.6934123]], dtype=float32)

time = 24907	action = 0	current_phase = 0	next_phase = 1	reward = -0.477346	array([[-2.1215055, -2.7114115]], dtype=float32)

time = 24912	action = 0	current_phase = 0	next_phase = 1	reward = -0.318045	array([[-2.0404615, -2.880391 ]], dtype=float32)

time = 24917	action = 0	current_phase = 0	next_phase = 1	reward = -0.182438	array([[-2.1225345, -2.9594066]], dtype=float32)

time = 24922	action = 0	current_phase = 0	next_phase = 1	reward = 0.189509	array([[-2.230573, -3.977943]], dtype=float32)

time = 24927	action = 1	current_phase = 0	next_phase = 1	reward = -1.776206	array([[-4.9369593, -3.4628043]], dtype=float32)

time = 24935	action = 0	current_phase = 1	next_phase = 0	reward = -0.516455	array([[-2.064493 , -2.7779095]], dtype=float32)

time = 24940	action = 0	current_phase = 1	next_phase = 0	reward = -0.348348	array([[-1.8825314, -3.031678 ]], dtype=float32)

time = 24945	action = 0	current_phase = 1	next_phase = 0	reward = -0.200150	array([[-1.8519393, -2.9544482]], dtype=float32)

time = 24950	action = 0	current_phase = 1	next_phase = 0	reward = 0.341949	array([[-1.9993988, -3.36703  ]], dtype=float32)

time = 24955	action = 1	current_phase = 1	next_phase = 0	reward = -1.369170	array([[-3.8929443, -3.2249713]], dtype=float32)

time = 24963	action = 0	current_phase = 0	next_phase = 1	reward = -0.584747	array([[-2.219182 , -2.6033866]], dtype=float32)

time = 24968	action = 0	current_phase = 0	next_phase = 1	reward = -0.432212	array([[-2.0653667, -2.4891498]], dtype=float32)

time = 24973	action = 0	current_phase = 0	next_phase = 1	reward = -0.280457	array([[-2.0319889, -3.0047839]], dtype=float32)

time = 24978	action = 0	current_phase = 0	next_phase = 1	reward = -0.159211	array([[-2.1666143, -2.683239 ]], dtype=float32)

time = 24983	action = 0	current_phase = 0	next_phase = 1	reward = 0.012572	array([[-2.9865227, -4.183039 ]], dtype=float32)

time = 24988	action = 1	current_phase = 0	next_phase = 1	reward = -1.898831	array([[-5.4740734, -3.449673 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0387 - val_loss: 0.0334

Epoch 2/50

 - 4s - loss: 0.0557 - val_loss: 0.0302

Epoch 3/50

 - 4s - loss: 0.0542 - val_loss: 0.0356

Epoch 4/50

 - 4s - loss: 0.0475 - val_loss: 0.0351

Epoch 5/50

 - 4s - loss: 0.0566 - val_loss: 0.0379

Epoch 6/50

 - 4s - loss: 0.0415 - val_loss: 0.0343

Epoch 7/50

 - 4s - loss: 0.0631 - val_loss: 0.0329

Epoch 8/50

 - 5s - loss: 0.0615 - val_loss: 0.0366

Epoch 9/50

 - 5s - loss: 0.0526 - val_loss: 0.0408

Epoch 10/50

 - 5s - loss: 0.0351 - val_loss: 0.0358

Epoch 11/50

 - 6s - loss: 0.0377 - val_loss: 0.0336

Epoch 12/50

 - 5s - loss: 0.0537 - val_loss: 0.0397

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 752, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 739, after forget

time = 24996	action = 0	current_phase = 1	next_phase = 0	reward = -0.492805	array([[-1.9815397, -3.0657861]], dtype=float32)

time = 25001	action = 0	current_phase = 1	next_phase = 0	reward = -0.326079	array([[-2.0125148, -2.8993065]], dtype=float32)

time = 25006	action = 0	current_phase = 1	next_phase = 0	reward = -0.182748	array([[-2.203639 , -2.8780584]], dtype=float32)

time = 25011	action = 0	current_phase = 1	next_phase = 0	reward = 0.278081	array([[-2.339568 , -3.6828568]], dtype=float32)

time = 25016	action = 1	current_phase = 1	next_phase = 0	reward = -1.555053	array([[-4.851982 , -3.4078166]], dtype=float32)

time = 25024	action = 0	current_phase = 0	next_phase = 1	reward = -0.540396	array([[-2.1414065, -2.5665894]], dtype=float32)

time = 25029	action = 0	current_phase = 0	next_phase = 1	reward = -0.383883	array([[-2.0540228, -2.511548 ]], dtype=float32)

time = 25034	action = 0	current_phase = 0	next_phase = 1	reward = -0.227055	array([[-1.9736729, -3.0867243]], dtype=float32)

time = 25039	action = 0	current_phase = 0	next_phase = 1	reward = -0.190721	array([[-2.0520709, -3.1672804]], dtype=float32)

time = 25044	action = 1	current_phase = 0	next_phase = 1	reward = -0.549833	array([[-3.0452943, -2.2388508]], dtype=float32)

time = 25052	action = 0	current_phase = 1	next_phase = 0	reward = -0.620785	array([[-2.06012 , -2.876297]], dtype=float32)

time = 25057	action = 0	current_phase = 1	next_phase = 0	reward = -0.462188	array([[-2.0556123, -3.1486945]], dtype=float32)

time = 25062	action = 0	current_phase = 1	next_phase = 0	reward = -0.307440	array([[-1.9744403, -2.787591 ]], dtype=float32)

time = 25067	action = 0	current_phase = 1	next_phase = 0	reward = -0.175401	array([[-2.296814 , -2.8723154]], dtype=float32)

time = 25072	action = 0	current_phase = 1	next_phase = 0	reward = 0.198967	array([[-2.472486 , -3.5166686]], dtype=float32)

time = 25077	action = 1	current_phase = 1	next_phase = 0	reward = -1.731391	array([[-5.1058865, -3.6400242]], dtype=float32)

time = 25085	action = 0	current_phase = 0	next_phase = 1	reward = -0.519477	array([[-2.118619, -2.940683]], dtype=float32)

time = 25090	action = 0	current_phase = 0	next_phase = 1	reward = -0.362679	array([[-2.05407  , -2.5131662]], dtype=float32)

time = 25095	action = 0	current_phase = 0	next_phase = 1	reward = -0.214350	array([[-1.9544196, -3.0878525]], dtype=float32)

time = 25100	action = 0	current_phase = 0	next_phase = 1	reward = 0.343670	array([[-1.8784878, -3.3518255]], dtype=float32)

time = 25105	action = 1	current_phase = 0	next_phase = 1	reward = -1.422485	array([[-3.9003541, -3.0455801]], dtype=float32)

time = 25113	action = 0	current_phase = 1	next_phase = 0	reward = -0.588733	array([[-2.060887 , -2.8775842]], dtype=float32)

time = 25118	action = 0	current_phase = 1	next_phase = 0	reward = -0.431181	array([[-2.0561824, -2.877389 ]], dtype=float32)

time = 25123	action = 0	current_phase = 1	next_phase = 0	reward = -0.277798	array([[-1.9993796, -2.8079295]], dtype=float32)

time = 25128	action = 0	current_phase = 1	next_phase = 0	reward = -0.161790	array([[-2.2734005, -2.8719056]], dtype=float32)

time = 25133	action = 0	current_phase = 1	next_phase = 0	reward = 0.143694	array([[-2.8399777, -3.433902 ]], dtype=float32)

time = 25138	action = 1	current_phase = 1	next_phase = 0	reward = -1.844872	array([[-5.091357, -3.621198]], dtype=float32)

time = 25146	action = 0	current_phase = 0	next_phase = 1	reward = -0.492010	array([[-2.145351, -2.979456]], dtype=float32)

time = 25151	action = 0	current_phase = 0	next_phase = 1	reward = -0.330079	array([[-2.058439 , -2.5109303]], dtype=float32)

time = 25156	action = 0	current_phase = 0	next_phase = 1	reward = -0.185935	array([[-2.0289314, -2.869881 ]], dtype=float32)

time = 25161	action = 0	current_phase = 0	next_phase = 1	reward = 0.304740	array([[-2.1793098, -3.7323043]], dtype=float32)

time = 25166	action = 1	current_phase = 0	next_phase = 1	reward = -1.661683	array([[-3.837869 , -3.2031991]], dtype=float32)

time = 25174	action = 0	current_phase = 1	next_phase = 0	reward = -0.550856	array([[-1.9906406, -2.8143134]], dtype=float32)

time = 25179	action = 0	current_phase = 1	next_phase = 0	reward = -0.395430	array([[-1.8058033, -3.0468519]], dtype=float32)

time = 25184	action = 0	current_phase = 1	next_phase = 0	reward = -0.243391	array([[-1.727807 , -2.9464393]], dtype=float32)

time = 25189	action = 0	current_phase = 1	next_phase = 0	reward = -0.187512	array([[-1.9926004, -3.4052577]], dtype=float32)

time = 25194	action = 1	current_phase = 1	next_phase = 0	reward = -0.611217	array([[-2.4525354, -2.3514605]], dtype=float32)

time = 25202	action = 0	current_phase = 0	next_phase = 1	reward = -0.625787	array([[-2.2722435, -2.664378 ]], dtype=float32)

time = 25207	action = 0	current_phase = 0	next_phase = 1	reward = -0.479651	array([[-2.1139956, -2.5514896]], dtype=float32)

time = 25212	action = 0	current_phase = 0	next_phase = 1	reward = -0.333214	array([[-1.957107 , -3.0829232]], dtype=float32)

time = 25217	action = 0	current_phase = 0	next_phase = 1	reward = -0.193431	array([[-2.080408 , -2.7360358]], dtype=float32)

time = 25222	action = 0	current_phase = 0	next_phase = 1	reward = 0.262406	array([[-2.492783 , -4.2312927]], dtype=float32)

time = 25227	action = 1	current_phase = 0	next_phase = 1	reward = -1.725960	array([[-4.7522173, -3.265195 ]], dtype=float32)

time = 25235	action = 0	current_phase = 1	next_phase = 0	reward = -0.528138	array([[-1.955852 , -2.8292983]], dtype=float32)

time = 25240	action = 0	current_phase = 1	next_phase = 0	reward = -0.382330	array([[-1.8064828, -3.0464287]], dtype=float32)

time = 25245	action = 0	current_phase = 1	next_phase = 0	reward = -0.226746	array([[-1.7485285, -2.968123 ]], dtype=float32)

time = 25250	action = 0	current_phase = 1	next_phase = 0	reward = 0.380825	array([[-1.9548476, -3.3817654]], dtype=float32)

time = 25255	action = 1	current_phase = 1	next_phase = 0	reward = -1.289954	array([[-3.7934592, -3.1291127]], dtype=float32)

time = 25263	action = 0	current_phase = 0	next_phase = 1	reward = -0.579792	array([[-2.1841738, -2.6018832]], dtype=float32)

time = 25268	action = 0	current_phase = 0	next_phase = 1	reward = -0.422887	array([[-2.0523763, -2.557143 ]], dtype=float32)

time = 25273	action = 0	current_phase = 0	next_phase = 1	reward = -0.269231	array([[-1.9679645, -3.0708468]], dtype=float32)

time = 25278	action = 0	current_phase = 0	next_phase = 1	reward = -0.164271	array([[-2.1945865, -2.7486997]], dtype=float32)

time = 25283	action = 1	current_phase = 0	next_phase = 1	reward = -1.079572	array([[-2.994476 , -2.7530906]], dtype=float32)

time = 25291	action = 0	current_phase = 1	next_phase = 0	reward = -1.177887	array([[-2.6933486, -3.024926 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0706 - val_loss: 0.0263

Epoch 2/50

 - 5s - loss: 0.0550 - val_loss: 0.0258

Epoch 3/50

 - 5s - loss: 0.0476 - val_loss: 0.0263

Epoch 4/50

 - 4s - loss: 0.0620 - val_loss: 0.0267

Epoch 5/50

 - 5s - loss: 0.0450 - val_loss: 0.0270

Epoch 6/50

 - 4s - loss: 0.0634 - val_loss: 0.0288

Epoch 7/50

 - 5s - loss: 0.0626 - val_loss: 0.0262

Epoch 8/50

 - 5s - loss: 0.0395 - val_loss: 0.0267

Epoch 9/50

 - 5s - loss: 0.0723 - val_loss: 0.0287

Epoch 10/50

 - 5s - loss: 0.0472 - val_loss: 0.0288

Epoch 11/50

 - 4s - loss: 0.0383 - val_loss: 0.0309

Epoch 12/50

 - 5s - loss: 0.0688 - val_loss: 0.0287

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 757, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 744, after forget

time = 25296	action = 0	current_phase = 1	next_phase = 0	reward = -1.044946	array([[-2.3228393, -3.4335208]], dtype=float32)

time = 25301	action = 0	current_phase = 1	next_phase = 0	reward = -0.914064	array([[-2.8453135, -2.918104 ]], dtype=float32)

time = 25306	action = 0	current_phase = 1	next_phase = 0	reward = -0.788062	array([[-2.2351098, -3.0200384]], dtype=float32)

time = 25311	action = 0	current_phase = 1	next_phase = 0	reward = -0.308125	array([[-3.285506 , -3.4668818]], dtype=float32)

time = 25316	action = 1	current_phase = 1	next_phase = 0	reward = -1.578424	array([[-5.165038 , -3.4761493]], dtype=float32)

time = 25324	action = 0	current_phase = 0	next_phase = 1	reward = -0.553344	array([[-2.139784, -2.404211]], dtype=float32)

time = 25329	action = 0	current_phase = 0	next_phase = 1	reward = -0.394029	array([[-2.090467 , -2.5406268]], dtype=float32)

time = 25334	action = 0	current_phase = 0	next_phase = 1	reward = -0.231325	array([[-2.0060344, -3.1279225]], dtype=float32)

time = 25339	action = 0	current_phase = 0	next_phase = 1	reward = -0.192693	array([[-2.0621798, -3.2807553]], dtype=float32)

time = 25344	action = 1	current_phase = 0	next_phase = 1	reward = -0.601153	array([[-3.1565442, -2.2156415]], dtype=float32)

time = 25352	action = 0	current_phase = 1	next_phase = 0	reward = -0.616527	array([[-2.123285 , -2.8811681]], dtype=float32)

time = 25357	action = 0	current_phase = 1	next_phase = 0	reward = -0.472546	array([[-2.0852163, -3.1570923]], dtype=float32)

time = 25362	action = 0	current_phase = 1	next_phase = 0	reward = -0.325511	array([[-2.0510006, -2.826172 ]], dtype=float32)

time = 25367	action = 0	current_phase = 1	next_phase = 0	reward = -0.185280	array([[-2.295886 , -2.9169896]], dtype=float32)

time = 25372	action = 0	current_phase = 1	next_phase = 0	reward = 0.234852	array([[-2.5489697, -3.6492383]], dtype=float32)

time = 25377	action = 1	current_phase = 1	next_phase = 0	reward = -1.726383	array([[-5.231897 , -3.5651565]], dtype=float32)

time = 25385	action = 0	current_phase = 0	next_phase = 1	reward = -0.530133	array([[-2.2377455, -3.015865 ]], dtype=float32)

time = 25390	action = 0	current_phase = 0	next_phase = 1	reward = -0.380724	array([[-2.0901556, -2.533704 ]], dtype=float32)

time = 25395	action = 0	current_phase = 0	next_phase = 1	reward = -0.234999	array([[-2.007182 , -3.1288216]], dtype=float32)

time = 25400	action = 0	current_phase = 0	next_phase = 1	reward = 0.072932	array([[-1.977109 , -3.3281302]], dtype=float32)

time = 25405	action = 1	current_phase = 0	next_phase = 1	reward = -1.020968	array([[-3.6301036, -2.680719 ]], dtype=float32)

time = 25413	action = 0	current_phase = 1	next_phase = 0	reward = -0.578778	array([[-2.1507204, -2.8703208]], dtype=float32)

time = 25418	action = 0	current_phase = 1	next_phase = 0	reward = -0.420587	array([[-1.9874066, -2.9771142]], dtype=float32)

time = 25423	action = 0	current_phase = 1	next_phase = 0	reward = -0.264804	array([[-2.0508068, -2.8131802]], dtype=float32)

time = 25428	action = 0	current_phase = 1	next_phase = 0	reward = -0.159899	array([[-2.23406  , -2.8951797]], dtype=float32)

time = 25433	action = 0	current_phase = 1	next_phase = 0	reward = -0.005065	array([[-2.5977695, -2.8778605]], dtype=float32)

time = 25438	action = 1	current_phase = 1	next_phase = 0	reward = -1.902591	array([[-5.1124187, -3.629025 ]], dtype=float32)

time = 25446	action = 0	current_phase = 0	next_phase = 1	reward = -0.504677	array([[-2.1389813, -2.9756463]], dtype=float32)

time = 25451	action = 0	current_phase = 0	next_phase = 1	reward = -0.358987	array([[-2.0860376, -2.5517805]], dtype=float32)

time = 25456	action = 0	current_phase = 0	next_phase = 1	reward = -0.215733	array([[-2.0099854, -3.1199162]], dtype=float32)

time = 25461	action = 0	current_phase = 0	next_phase = 1	reward = 0.308908	array([[-2.1335378, -3.93197  ]], dtype=float32)

time = 25466	action = 1	current_phase = 0	next_phase = 1	reward = -1.610905	array([[-3.938442 , -3.2269201]], dtype=float32)

time = 25474	action = 0	current_phase = 1	next_phase = 0	reward = -0.575408	array([[-2.0990796, -2.8693871]], dtype=float32)

time = 25479	action = 0	current_phase = 1	next_phase = 0	reward = -0.432702	array([[-1.8733824, -3.063719 ]], dtype=float32)

time = 25484	action = 0	current_phase = 1	next_phase = 0	reward = -0.287006	array([[-1.9948902, -2.835383 ]], dtype=float32)

time = 25489	action = 0	current_phase = 1	next_phase = 0	reward = -0.172897	array([[-2.036842 , -3.3707144]], dtype=float32)

time = 25494	action = 1	current_phase = 1	next_phase = 0	reward = -0.420653	array([[-2.5759556, -2.5207334]], dtype=float32)

time = 25502	action = 0	current_phase = 0	next_phase = 1	reward = -0.625834	array([[-2.3986135, -2.7768033]], dtype=float32)

time = 25507	action = 0	current_phase = 0	next_phase = 1	reward = -0.485652	array([[-2.132977 , -2.6801462]], dtype=float32)

time = 25512	action = 0	current_phase = 0	next_phase = 1	reward = -0.335811	array([[-2.0220437, -3.0899925]], dtype=float32)

time = 25517	action = 0	current_phase = 0	next_phase = 1	reward = -0.184877	array([[-2.0696354, -2.9524844]], dtype=float32)

time = 25522	action = 0	current_phase = 0	next_phase = 1	reward = 0.265668	array([[-2.2279742, -3.7862134]], dtype=float32)

time = 25527	action = 1	current_phase = 0	next_phase = 1	reward = -1.673810	array([[-4.886356 , -3.2190251]], dtype=float32)

time = 25535	action = 0	current_phase = 1	next_phase = 0	reward = -0.525955	array([[-2.011081 , -2.8733187]], dtype=float32)

time = 25540	action = 0	current_phase = 1	next_phase = 0	reward = -0.372535	array([[-1.8724128, -3.0621507]], dtype=float32)

time = 25545	action = 0	current_phase = 1	next_phase = 0	reward = -0.223510	array([[-1.7689523, -2.9749649]], dtype=float32)

time = 25550	action = 0	current_phase = 1	next_phase = 0	reward = 0.367308	array([[-1.9793105, -3.3166206]], dtype=float32)

time = 25555	action = 1	current_phase = 1	next_phase = 0	reward = -1.354486	array([[-3.6636083, -2.9758766]], dtype=float32)

time = 25563	action = 0	current_phase = 0	next_phase = 1	reward = -0.583104	array([[-2.2103126, -2.6283634]], dtype=float32)

time = 25568	action = 0	current_phase = 0	next_phase = 1	reward = -0.423811	array([[-2.0766072, -2.6940207]], dtype=float32)

time = 25573	action = 0	current_phase = 0	next_phase = 1	reward = -0.269212	array([[-2.0290942, -3.0711243]], dtype=float32)

time = 25578	action = 0	current_phase = 0	next_phase = 1	reward = -0.170382	array([[-2.1974657, -2.8372967]], dtype=float32)

time = 25583	action = 0	current_phase = 0	next_phase = 1	reward = -0.018384	array([[-2.8305914, -4.1525507]], dtype=float32)

time = 25588	action = 1	current_phase = 0	next_phase = 1	reward = -1.898547	array([[-5.5206857, -3.490294 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0717 - val_loss: 0.0324

Epoch 2/50

 - 5s - loss: 0.0569 - val_loss: 0.0329

Epoch 3/50

 - 5s - loss: 0.0494 - val_loss: 0.0322

Epoch 4/50

 - 4s - loss: 0.0426 - val_loss: 0.0344

Epoch 5/50

 - 4s - loss: 0.0495 - val_loss: 0.0343

Epoch 6/50

 - 4s - loss: 0.0417 - val_loss: 0.0369

Epoch 7/50

 - 4s - loss: 0.0482 - val_loss: 0.0357

Epoch 8/50

 - 5s - loss: 0.0406 - val_loss: 0.0357

Epoch 9/50

 - 4s - loss: 0.0418 - val_loss: 0.0348

Epoch 10/50

 - 4s - loss: 0.0339 - val_loss: 0.0344

Epoch 11/50

 - 4s - loss: 0.0375 - val_loss: 0.0358

Epoch 12/50

 - 4s - loss: 0.0538 - val_loss: 0.0389

Epoch 13/50

 - 4s - loss: 0.0326 - val_loss: 0.0368

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 762, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 749, after forget

time = 25596	action = 0	current_phase = 1	next_phase = 0	reward = -0.488982	array([[-2.03566  , -3.1863883]], dtype=float32)

time = 25601	action = 0	current_phase = 1	next_phase = 0	reward = -0.341168	array([[-2.0164292, -2.9537477]], dtype=float32)

time = 25606	action = 0	current_phase = 1	next_phase = 0	reward = -0.198641	array([[-2.0872965, -3.0612118]], dtype=float32)

time = 25611	action = 0	current_phase = 1	next_phase = 0	reward = 0.287916	array([[-2.4633982, -3.8432302]], dtype=float32)

time = 25616	action = 1	current_phase = 1	next_phase = 0	reward = -1.665495	array([[-4.91058  , -3.4265156]], dtype=float32)

time = 25624	action = 0	current_phase = 0	next_phase = 1	reward = -0.557504	array([[-2.2560866, -2.628481 ]], dtype=float32)

time = 25629	action = 0	current_phase = 0	next_phase = 1	reward = -0.402957	array([[-2.0867414, -2.506485 ]], dtype=float32)

time = 25634	action = 0	current_phase = 0	next_phase = 1	reward = -0.250820	array([[-2.026167 , -3.1311502]], dtype=float32)

time = 25639	action = 0	current_phase = 0	next_phase = 1	reward = -0.182195	array([[-1.9699416, -3.3855438]], dtype=float32)

time = 25644	action = 1	current_phase = 0	next_phase = 1	reward = -0.603083	array([[-3.111681 , -2.5098903]], dtype=float32)

time = 25652	action = 0	current_phase = 1	next_phase = 0	reward = -0.615684	array([[-2.0360372, -2.9461167]], dtype=float32)

time = 25657	action = 0	current_phase = 1	next_phase = 0	reward = -0.456631	array([[-2.0607388, -3.204467 ]], dtype=float32)

time = 25662	action = 0	current_phase = 1	next_phase = 0	reward = -0.304188	array([[-1.9748235, -2.8944411]], dtype=float32)

time = 25667	action = 0	current_phase = 1	next_phase = 0	reward = -0.167186	array([[-2.166481, -3.011127]], dtype=float32)

time = 25672	action = 0	current_phase = 1	next_phase = 0	reward = 0.180826	array([[-2.8228898, -3.570275 ]], dtype=float32)

time = 25677	action = 1	current_phase = 1	next_phase = 0	reward = -1.780382	array([[-5.1237507, -3.666602 ]], dtype=float32)

time = 25685	action = 0	current_phase = 0	next_phase = 1	reward = -0.519703	array([[-2.1699266, -2.8555062]], dtype=float32)

time = 25690	action = 0	current_phase = 0	next_phase = 1	reward = -0.367664	array([[-2.086738 , -2.4996948]], dtype=float32)

time = 25695	action = 0	current_phase = 0	next_phase = 1	reward = -0.219473	array([[-2.0279896, -3.1259327]], dtype=float32)

time = 25700	action = 0	current_phase = 0	next_phase = 1	reward = 0.370709	array([[-2.0148792, -3.2040741]], dtype=float32)

time = 25705	action = 1	current_phase = 0	next_phase = 1	reward = -1.304413	array([[-3.694836, -2.977634]], dtype=float32)

time = 25713	action = 0	current_phase = 1	next_phase = 0	reward = -0.592073	array([[-2.129518 , -2.8977094]], dtype=float32)

time = 25718	action = 0	current_phase = 1	next_phase = 0	reward = -0.434485	array([[-2.0066886, -2.952668 ]], dtype=float32)

time = 25723	action = 0	current_phase = 1	next_phase = 0	reward = -0.273317	array([[-1.9878384, -2.9024322]], dtype=float32)

time = 25728	action = 0	current_phase = 1	next_phase = 0	reward = -0.157545	array([[-2.2721024, -3.2179415]], dtype=float32)

time = 25733	action = 0	current_phase = 1	next_phase = 0	reward = 0.080352	array([[-2.9312527, -3.3784368]], dtype=float32)

time = 25738	action = 1	current_phase = 1	next_phase = 0	reward = -1.894672	array([[-5.1402817, -3.6740222]], dtype=float32)

time = 25746	action = 0	current_phase = 0	next_phase = 1	reward = -0.489021	array([[-2.2304618, -2.808589 ]], dtype=float32)

time = 25751	action = 0	current_phase = 0	next_phase = 1	reward = -0.340580	array([[-2.0862772, -2.5064485]], dtype=float32)

time = 25756	action = 0	current_phase = 0	next_phase = 1	reward = -0.192661	array([[-2.081728 , -2.9663472]], dtype=float32)

time = 25761	action = 0	current_phase = 0	next_phase = 1	reward = 0.310929	array([[-2.3244338, -3.7423167]], dtype=float32)

time = 25766	action = 1	current_phase = 0	next_phase = 1	reward = -1.558377	array([[-3.7791057, -3.1978915]], dtype=float32)

time = 25774	action = 0	current_phase = 1	next_phase = 0	reward = -0.559779	array([[-1.9763933, -2.903005 ]], dtype=float32)

time = 25779	action = 0	current_phase = 1	next_phase = 0	reward = -0.410463	array([[-1.7762296, -3.1159427]], dtype=float32)

time = 25784	action = 0	current_phase = 1	next_phase = 0	reward = -0.254215	array([[-1.6958846, -3.047796 ]], dtype=float32)

time = 25789	action = 0	current_phase = 1	next_phase = 0	reward = -0.174437	array([[-1.8977153, -3.39525  ]], dtype=float32)

time = 25794	action = 0	current_phase = 1	next_phase = 0	reward = -0.018361	array([[-2.3531804, -2.4248018]], dtype=float32)

time = 25799	action = 1	current_phase = 1	next_phase = 0	reward = -2.006397	array([[-5.1456413, -3.670557 ]], dtype=float32)

time = 25807	action = 0	current_phase = 0	next_phase = 1	reward = -0.457080	array([[-2.159373 , -2.7582903]], dtype=float32)

time = 25812	action = 0	current_phase = 0	next_phase = 1	reward = -0.299619	array([[-2.0363972, -2.9797125]], dtype=float32)

time = 25817	action = 0	current_phase = 0	next_phase = 1	reward = -0.168897	array([[-2.4595666, -2.784842 ]], dtype=float32)

time = 25822	action = 0	current_phase = 0	next_phase = 1	reward = 0.179417	array([[-2.4643562, -4.0941167]], dtype=float32)

time = 25827	action = 1	current_phase = 0	next_phase = 1	reward = -1.782256	array([[-5.000592 , -3.4665365]], dtype=float32)

time = 25835	action = 0	current_phase = 1	next_phase = 0	reward = -0.521860	array([[-1.9943689, -2.9254692]], dtype=float32)

time = 25840	action = 0	current_phase = 1	next_phase = 0	reward = -0.369824	array([[-1.7672446, -3.1134653]], dtype=float32)

time = 25845	action = 0	current_phase = 1	next_phase = 0	reward = -0.218638	array([[-1.6928825, -3.0457277]], dtype=float32)

time = 25850	action = 0	current_phase = 1	next_phase = 0	reward = 0.360434	array([[-2.0224652, -3.522814 ]], dtype=float32)

time = 25855	action = 1	current_phase = 1	next_phase = 0	reward = -1.410643	array([[-3.8870997, -3.1931145]], dtype=float32)

time = 25863	action = 0	current_phase = 0	next_phase = 1	reward = -0.572286	array([[-2.3119326, -2.6706712]], dtype=float32)

time = 25868	action = 0	current_phase = 0	next_phase = 1	reward = -0.418401	array([[-2.0909135, -2.5014536]], dtype=float32)

time = 25873	action = 0	current_phase = 0	next_phase = 1	reward = -0.260538	array([[-2.036829 , -3.1331904]], dtype=float32)

time = 25878	action = 0	current_phase = 0	next_phase = 1	reward = -0.162549	array([[-2.2083979, -2.6848092]], dtype=float32)

time = 25883	action = 1	current_phase = 0	next_phase = 1	reward = -1.123920	array([[-2.867173 , -2.7861016]], dtype=float32)

time = 25891	action = 0	current_phase = 1	next_phase = 0	reward = -1.188882	array([[-3.0497472, -3.3004289]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0310 - val_loss: 0.0229

Epoch 2/50

 - 4s - loss: 0.0493 - val_loss: 0.0270

Epoch 3/50

 - 4s - loss: 0.0403 - val_loss: 0.0251

Epoch 4/50

 - 4s - loss: 0.0350 - val_loss: 0.0238

Epoch 5/50

 - 4s - loss: 0.0342 - val_loss: 0.0243

Epoch 6/50

 - 6s - loss: 0.0419 - val_loss: 0.0208

Epoch 7/50

 - 5s - loss: 0.0355 - val_loss: 0.0225

Epoch 8/50

 - 6s - loss: 0.0309 - val_loss: 0.0247

Epoch 9/50

 - 4s - loss: 0.0289 - val_loss: 0.0255

Epoch 10/50

 - 4s - loss: 0.0371 - val_loss: 0.0290

Epoch 11/50

 - 4s - loss: 0.0381 - val_loss: 0.0295

Epoch 12/50

 - 5s - loss: 0.0450 - val_loss: 0.0281

Epoch 13/50

 - 4s - loss: 0.0286 - val_loss: 0.0294

Epoch 14/50

 - 4s - loss: 0.0315 - val_loss: 0.0325

Epoch 15/50

 - 4s - loss: 0.0401 - val_loss: 0.0305

Epoch 16/50

 - 4s - loss: 0.0326 - val_loss: 0.0283

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 767, after forget

length of memory (state 1, action 0): 1024, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 754, after forget

time = 25896	action = 0	current_phase = 1	next_phase = 0	reward = -1.058654	array([[-2.437382, -3.446719]], dtype=float32)

time = 25901	action = 0	current_phase = 1	next_phase = 0	reward = -0.927519	array([[-2.7362087, -3.070466 ]], dtype=float32)

time = 25906	action = 0	current_phase = 1	next_phase = 0	reward = -0.800252	array([[-2.1775932, -3.0980694]], dtype=float32)

time = 25911	action = 0	current_phase = 1	next_phase = 0	reward = -0.288876	array([[-3.0043476, -3.3926897]], dtype=float32)

time = 25916	action = 1	current_phase = 1	next_phase = 0	reward = -1.587151	array([[-5.2330017, -3.5034862]], dtype=float32)

time = 25924	action = 0	current_phase = 0	next_phase = 1	reward = -0.551651	array([[-2.113394 , -2.3876088]], dtype=float32)

time = 25929	action = 0	current_phase = 0	next_phase = 1	reward = -0.406229	array([[-2.0361326, -2.4943192]], dtype=float32)

time = 25934	action = 0	current_phase = 0	next_phase = 1	reward = -0.254442	array([[-2.03328  , -3.0826523]], dtype=float32)

time = 25939	action = 0	current_phase = 0	next_phase = 1	reward = -0.178371	array([[-2.0535262, -3.150777 ]], dtype=float32)

time = 25944	action = 1	current_phase = 0	next_phase = 1	reward = -0.498940	array([[-2.9454968, -2.3008199]], dtype=float32)

time = 25952	action = 0	current_phase = 1	next_phase = 0	reward = -0.616989	array([[-2.1335714, -2.951728 ]], dtype=float32)

time = 25957	action = 0	current_phase = 1	next_phase = 0	reward = -0.461001	array([[-2.103003 , -3.1895897]], dtype=float32)

time = 25962	action = 0	current_phase = 1	next_phase = 0	reward = -0.297260	array([[-2.1043673, -2.939349 ]], dtype=float32)

time = 25967	action = 0	current_phase = 1	next_phase = 0	reward = -0.165785	array([[-2.3429425, -2.9801528]], dtype=float32)

time = 25972	action = 0	current_phase = 1	next_phase = 0	reward = 0.119515	array([[-3.0820482, -3.5452085]], dtype=float32)

time = 25977	action = 1	current_phase = 1	next_phase = 0	reward = -1.787566	array([[-5.2158685, -3.6512702]], dtype=float32)

time = 25985	action = 0	current_phase = 0	next_phase = 1	reward = -0.525571	array([[-2.1743953, -2.910996 ]], dtype=float32)

time = 25990	action = 0	current_phase = 0	next_phase = 1	reward = -0.370559	array([[-2.034607, -2.507769]], dtype=float32)

time = 25995	action = 0	current_phase = 0	next_phase = 1	reward = -0.215754	array([[-2.0012398, -3.081576 ]], dtype=float32)

time = 26000	action = 0	current_phase = 0	next_phase = 1	reward = 0.355199	array([[-2.029815 , -3.2046325]], dtype=float32)

time = 26005	action = 1	current_phase = 0	next_phase = 1	reward = -1.362900	array([[-3.9377398, -3.034318 ]], dtype=float32)

time = 26013	action = 0	current_phase = 1	next_phase = 0	reward = -0.582380	array([[-2.2105055, -2.9080942]], dtype=float32)

time = 26018	action = 0	current_phase = 1	next_phase = 0	reward = -0.423679	array([[-2.0564582, -2.995194 ]], dtype=float32)

time = 26023	action = 0	current_phase = 1	next_phase = 0	reward = -0.268228	array([[-2.1024108, -2.9415088]], dtype=float32)

time = 26028	action = 0	current_phase = 1	next_phase = 0	reward = -0.160383	array([[-2.3039546, -3.0924988]], dtype=float32)

time = 26033	action = 1	current_phase = 1	next_phase = 0	reward = -0.288419	array([[-2.7378716, -2.6026196]], dtype=float32)

time = 26041	action = 0	current_phase = 0	next_phase = 1	reward = -0.644117	array([[-2.2835832, -2.651849 ]], dtype=float32)

time = 26046	action = 0	current_phase = 0	next_phase = 1	reward = -0.490511	array([[-2.1096535, -2.857178 ]], dtype=float32)

time = 26051	action = 0	current_phase = 0	next_phase = 1	reward = -0.335568	array([[-2.0129943, -2.9195883]], dtype=float32)

time = 26056	action = 0	current_phase = 0	next_phase = 1	reward = -0.181869	array([[-2.1020875, -2.7325754]], dtype=float32)

time = 26061	action = 0	current_phase = 0	next_phase = 1	reward = 0.276225	array([[-2.34863  , -3.4212914]], dtype=float32)

time = 26066	action = 1	current_phase = 0	next_phase = 1	reward = -1.555306	array([[-4.860089 , -3.3944886]], dtype=float32)

time = 26074	action = 0	current_phase = 1	next_phase = 0	reward = -0.551563	array([[-2.0687406, -2.974379 ]], dtype=float32)

time = 26079	action = 0	current_phase = 1	next_phase = 0	reward = -0.396171	array([[-1.8831286, -3.1237714]], dtype=float32)

time = 26084	action = 0	current_phase = 1	next_phase = 0	reward = -0.232384	array([[-1.7862638, -3.0377796]], dtype=float32)

time = 26089	action = 0	current_phase = 1	next_phase = 0	reward = -0.194127	array([[-1.9901193, -3.4301527]], dtype=float32)

time = 26094	action = 0	current_phase = 1	next_phase = 0	reward = -0.101661	array([[-2.1886125, -2.3917384]], dtype=float32)

time = 26099	action = 1	current_phase = 1	next_phase = 0	reward = -2.008187	array([[-5.1248517, -3.6585426]], dtype=float32)

time = 26107	action = 0	current_phase = 0	next_phase = 1	reward = -0.466240	array([[-2.1484835, -2.7939975]], dtype=float32)

time = 26112	action = 0	current_phase = 0	next_phase = 1	reward = -0.303751	array([[-2.0250516, -2.8436322]], dtype=float32)

time = 26117	action = 0	current_phase = 0	next_phase = 1	reward = -0.168686	array([[-2.2276835, -2.69515  ]], dtype=float32)

time = 26122	action = 0	current_phase = 0	next_phase = 1	reward = 0.174816	array([[-2.5363708, -4.024744 ]], dtype=float32)

time = 26127	action = 1	current_phase = 0	next_phase = 1	reward = -1.784882	array([[-4.9474783, -3.4107034]], dtype=float32)

time = 26135	action = 0	current_phase = 1	next_phase = 0	reward = -0.533085	array([[-2.061705, -2.90391 ]], dtype=float32)

time = 26140	action = 0	current_phase = 1	next_phase = 0	reward = -0.373442	array([[-1.8794142, -3.121499 ]], dtype=float32)

time = 26145	action = 0	current_phase = 1	next_phase = 0	reward = -0.223137	array([[-1.7858979, -3.0511353]], dtype=float32)

time = 26150	action = 0	current_phase = 1	next_phase = 0	reward = 0.378176	array([[-2.063224, -3.479992]], dtype=float32)

time = 26155	action = 1	current_phase = 1	next_phase = 0	reward = -1.300981	array([[-3.760406 , -3.0047774]], dtype=float32)

time = 26163	action = 0	current_phase = 0	next_phase = 1	reward = -0.592538	array([[-2.3000515, -2.7032351]], dtype=float32)

time = 26168	action = 0	current_phase = 0	next_phase = 1	reward = -0.442364	array([[-2.0969193, -2.539391 ]], dtype=float32)

time = 26173	action = 0	current_phase = 0	next_phase = 1	reward = -0.288838	array([[-2.031367 , -3.0564718]], dtype=float32)

time = 26178	action = 0	current_phase = 0	next_phase = 1	reward = -0.167458	array([[-2.282201 , -2.6681862]], dtype=float32)

time = 26183	action = 0	current_phase = 0	next_phase = 1	reward = 0.083906	array([[-2.772446 , -3.9566007]], dtype=float32)

time = 26188	action = 1	current_phase = 0	next_phase = 1	reward = -1.894161	array([[-5.5159154, -3.396745 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1051 - val_loss: 0.0337

Epoch 2/50

 - 5s - loss: 0.0549 - val_loss: 0.0411

Epoch 3/50

 - 4s - loss: 0.0502 - val_loss: 0.0499

Epoch 4/50

 - 4s - loss: 0.0447 - val_loss: 0.0398

Epoch 5/50

 - 4s - loss: 0.0601 - val_loss: 0.0417

Epoch 6/50

 - 4s - loss: 0.0538 - val_loss: 0.0302

Epoch 7/50

 - 4s - loss: 0.0430 - val_loss: 0.0396

Epoch 8/50

 - 4s - loss: 0.0458 - val_loss: 0.0455

Epoch 9/50

 - 5s - loss: 0.0454 - val_loss: 0.0425

Epoch 10/50

 - 4s - loss: 0.0447 - val_loss: 0.0383

Epoch 11/50

 - 4s - loss: 0.0564 - val_loss: 0.0440

Epoch 12/50

 - 4s - loss: 0.0544 - val_loss: 0.0398

Epoch 13/50

 - 5s - loss: 0.0498 - val_loss: 0.0408

Epoch 14/50

 - 5s - loss: 0.0333 - val_loss: 0.0345

Epoch 15/50

 - 5s - loss: 0.0361 - val_loss: 0.0314

Epoch 16/50

 - 5s - loss: 0.0285 - val_loss: 0.0336

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 772, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 759, after forget

time = 26196	action = 0	current_phase = 1	next_phase = 0	reward = -0.500328	array([[-2.1000528, -3.118155 ]], dtype=float32)

time = 26201	action = 0	current_phase = 1	next_phase = 0	reward = -0.352519	array([[-2.0403352, -2.96332  ]], dtype=float32)

time = 26206	action = 0	current_phase = 1	next_phase = 0	reward = -0.207042	array([[-2.1688573, -3.011236 ]], dtype=float32)

time = 26211	action = 0	current_phase = 1	next_phase = 0	reward = 0.319532	array([[-2.544375 , -3.6179516]], dtype=float32)

time = 26216	action = 1	current_phase = 1	next_phase = 0	reward = -1.502366	array([[-4.9329844, -3.3752542]], dtype=float32)

time = 26224	action = 0	current_phase = 0	next_phase = 1	reward = -0.553768	array([[-2.2594001, -2.6532128]], dtype=float32)

time = 26229	action = 0	current_phase = 0	next_phase = 1	reward = -0.401741	array([[-2.047731 , -2.5167835]], dtype=float32)

time = 26234	action = 0	current_phase = 0	next_phase = 1	reward = -0.253222	array([[-2.0057776, -3.0925095]], dtype=float32)

time = 26239	action = 0	current_phase = 0	next_phase = 1	reward = -0.173096	array([[-2.0291748, -3.3420067]], dtype=float32)

time = 26244	action = 1	current_phase = 0	next_phase = 1	reward = -0.477431	array([[-3.299294 , -2.1226583]], dtype=float32)

time = 26252	action = 0	current_phase = 1	next_phase = 0	reward = -0.622633	array([[-2.0993376, -2.9329336]], dtype=float32)

time = 26257	action = 0	current_phase = 1	next_phase = 0	reward = -0.466659	array([[-2.0610259, -3.190488 ]], dtype=float32)

time = 26262	action = 0	current_phase = 1	next_phase = 0	reward = -0.299897	array([[-1.9987371, -2.8812099]], dtype=float32)

time = 26267	action = 0	current_phase = 1	next_phase = 0	reward = -0.172447	array([[-2.3073163, -2.9253998]], dtype=float32)

time = 26272	action = 0	current_phase = 1	next_phase = 0	reward = 0.240551	array([[-2.5695374, -3.5487385]], dtype=float32)

time = 26277	action = 1	current_phase = 1	next_phase = 0	reward = -1.734830	array([[-5.2543063, -3.5615544]], dtype=float32)

time = 26285	action = 0	current_phase = 0	next_phase = 1	reward = -0.544788	array([[-2.2480001, -3.0062501]], dtype=float32)

time = 26290	action = 0	current_phase = 0	next_phase = 1	reward = -0.385715	array([[-2.049619 , -2.4957492]], dtype=float32)

time = 26295	action = 0	current_phase = 0	next_phase = 1	reward = -0.225398	array([[-2.0036051, -3.0900962]], dtype=float32)

time = 26300	action = 0	current_phase = 0	next_phase = 1	reward = 0.077034	array([[-1.9650109, -3.436542 ]], dtype=float32)

time = 26305	action = 1	current_phase = 0	next_phase = 1	reward = -1.075132	array([[-3.589836 , -2.5257714]], dtype=float32)

time = 26313	action = 0	current_phase = 1	next_phase = 0	reward = -0.592567	array([[-2.1508524, -2.9079156]], dtype=float32)

time = 26318	action = 0	current_phase = 1	next_phase = 0	reward = -0.440319	array([[-2.0429564, -2.967532 ]], dtype=float32)

time = 26323	action = 0	current_phase = 1	next_phase = 0	reward = -0.285113	array([[-2.0203745, -2.8987126]], dtype=float32)

time = 26328	action = 0	current_phase = 1	next_phase = 0	reward = -0.172667	array([[-2.3050427, -2.9658272]], dtype=float32)

time = 26333	action = 0	current_phase = 1	next_phase = 0	reward = 0.126909	array([[-2.8204055, -2.9857607]], dtype=float32)

time = 26338	action = 1	current_phase = 1	next_phase = 0	reward = -1.898322	array([[-5.0905514, -3.6491027]], dtype=float32)

time = 26346	action = 0	current_phase = 0	next_phase = 1	reward = -0.500975	array([[-2.1736426, -2.9457507]], dtype=float32)

time = 26351	action = 0	current_phase = 0	next_phase = 1	reward = -0.349988	array([[-2.0469792, -2.5256276]], dtype=float32)

time = 26356	action = 0	current_phase = 0	next_phase = 1	reward = -0.209996	array([[-2.0120623, -3.0925484]], dtype=float32)

time = 26361	action = 0	current_phase = 0	next_phase = 1	reward = 0.272824	array([[-2.132962 , -3.5908327]], dtype=float32)

time = 26366	action = 1	current_phase = 0	next_phase = 1	reward = -1.665519	array([[-3.9896169, -3.1330488]], dtype=float32)

time = 26374	action = 0	current_phase = 1	next_phase = 0	reward = -0.564399	array([[-2.0681007, -2.9305995]], dtype=float32)

time = 26379	action = 0	current_phase = 1	next_phase = 0	reward = -0.414649	array([[-1.8482394, -3.1174853]], dtype=float32)

time = 26384	action = 0	current_phase = 1	next_phase = 0	reward = -0.266870	array([[-1.8541162, -2.9257903]], dtype=float32)

time = 26389	action = 0	current_phase = 1	next_phase = 0	reward = -0.179789	array([[-1.972168 , -3.3904881]], dtype=float32)

time = 26394	action = 0	current_phase = 1	next_phase = 0	reward = -0.071073	array([[-2.2787693, -2.418126 ]], dtype=float32)

time = 26399	action = 1	current_phase = 1	next_phase = 0	reward = -2.002873	array([[-5.211781 , -3.6185794]], dtype=float32)

time = 26407	action = 0	current_phase = 0	next_phase = 1	reward = -0.458665	array([[-2.1647918, -2.7978222]], dtype=float32)

time = 26412	action = 0	current_phase = 0	next_phase = 1	reward = -0.305035	array([[-2.0234594, -2.9185786]], dtype=float32)

time = 26417	action = 0	current_phase = 0	next_phase = 1	reward = -0.178318	array([[-2.1525288, -2.731268 ]], dtype=float32)

time = 26422	action = 0	current_phase = 0	next_phase = 1	reward = 0.212798	array([[-2.5212657, -4.1607523]], dtype=float32)

time = 26427	action = 1	current_phase = 0	next_phase = 1	reward = -1.787505	array([[-4.155524 , -3.1804435]], dtype=float32)

time = 26435	action = 0	current_phase = 1	next_phase = 0	reward = -0.538140	array([[-1.969774, -2.895245]], dtype=float32)

time = 26440	action = 0	current_phase = 1	next_phase = 0	reward = -0.386610	array([[-1.8332171, -3.1184466]], dtype=float32)

time = 26445	action = 0	current_phase = 1	next_phase = 0	reward = -0.244208	array([[-1.7676225, -3.0707946]], dtype=float32)

time = 26450	action = 0	current_phase = 1	next_phase = 0	reward = 0.089157	array([[-1.8856368, -3.343964 ]], dtype=float32)

time = 26455	action = 1	current_phase = 1	next_phase = 0	reward = -1.009636	array([[-3.0399275, -2.4686022]], dtype=float32)

time = 26463	action = 0	current_phase = 0	next_phase = 1	reward = -0.589269	array([[-2.3092608, -2.7023864]], dtype=float32)

time = 26468	action = 0	current_phase = 0	next_phase = 1	reward = -0.426042	array([[-2.0502372, -2.4925613]], dtype=float32)

time = 26473	action = 0	current_phase = 0	next_phase = 1	reward = -0.276191	array([[-2.0759535, -3.0948966]], dtype=float32)

time = 26478	action = 0	current_phase = 0	next_phase = 1	reward = -0.163458	array([[-2.3010764, -2.7587688]], dtype=float32)

time = 26483	action = 0	current_phase = 0	next_phase = 1	reward = -0.053367	array([[-2.7243924, -3.8171692]], dtype=float32)

time = 26488	action = 1	current_phase = 0	next_phase = 1	reward = -1.903204	array([[-5.6383843, -3.5129898]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0718 - val_loss: 0.0162

Epoch 2/50

 - 4s - loss: 0.0476 - val_loss: 0.0136

Epoch 3/50

 - 4s - loss: 0.0562 - val_loss: 0.0149

Epoch 4/50

 - 5s - loss: 0.0552 - val_loss: 0.0188

Epoch 5/50

 - 5s - loss: 0.0381 - val_loss: 0.0168

Epoch 6/50

 - 4s - loss: 0.0433 - val_loss: 0.0130

Epoch 7/50

 - 5s - loss: 0.0447 - val_loss: 0.0169

Epoch 8/50

 - 5s - loss: 0.0386 - val_loss: 0.0163

Epoch 9/50

 - 4s - loss: 0.0338 - val_loss: 0.0173

Epoch 10/50

 - 6s - loss: 0.0383 - val_loss: 0.0177

Epoch 11/50

 - 5s - loss: 0.0371 - val_loss: 0.0153

Epoch 12/50

 - 4s - loss: 0.0377 - val_loss: 0.0125

Epoch 13/50

 - 5s - loss: 0.0587 - val_loss: 0.0172

Epoch 14/50

 - 5s - loss: 0.0334 - val_loss: 0.0146

Epoch 15/50

 - 4s - loss: 0.0685 - val_loss: 0.0210

Epoch 16/50

 - 5s - loss: 0.0366 - val_loss: 0.0175

Epoch 17/50

 - 4s - loss: 0.0389 - val_loss: 0.0259

Epoch 18/50

 - 4s - loss: 0.0342 - val_loss: 0.0178

Epoch 19/50

 - 5s - loss: 0.0314 - val_loss: 0.0222

Epoch 20/50

 - 4s - loss: 0.0355 - val_loss: 0.0235

Epoch 21/50

 - 4s - loss: 0.0328 - val_loss: 0.0247

Epoch 22/50

 - 4s - loss: 0.0457 - val_loss: 0.0171

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 777, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 764, after forget

time = 26496	action = 0	current_phase = 1	next_phase = 0	reward = -0.499765	array([[-2.117265, -3.199179]], dtype=float32)

time = 26501	action = 0	current_phase = 1	next_phase = 0	reward = -0.340691	array([[-1.9547025, -3.1291542]], dtype=float32)

time = 26506	action = 0	current_phase = 1	next_phase = 0	reward = -0.187548	array([[-2.0864422, -3.0701973]], dtype=float32)

time = 26511	action = 0	current_phase = 1	next_phase = 0	reward = 0.338092	array([[-2.6138163, -3.583311 ]], dtype=float32)

time = 26516	action = 1	current_phase = 1	next_phase = 0	reward = -1.451419	array([[-4.989806 , -3.3628683]], dtype=float32)

time = 26524	action = 0	current_phase = 0	next_phase = 1	reward = -0.572054	array([[-2.2037764, -2.639834 ]], dtype=float32)

time = 26529	action = 0	current_phase = 0	next_phase = 1	reward = -0.416768	array([[-2.039567 , -2.4895782]], dtype=float32)

time = 26534	action = 0	current_phase = 0	next_phase = 1	reward = -0.268083	array([[-1.9917481, -3.06004  ]], dtype=float32)

time = 26539	action = 0	current_phase = 0	next_phase = 1	reward = -0.174880	array([[-2.0585108, -3.1512938]], dtype=float32)

time = 26544	action = 1	current_phase = 0	next_phase = 1	reward = -0.509771	array([[-3.3523018, -2.0952845]], dtype=float32)

time = 26552	action = 0	current_phase = 1	next_phase = 0	reward = -0.610836	array([[-2.2972775, -2.9053452]], dtype=float32)

time = 26557	action = 0	current_phase = 1	next_phase = 0	reward = -0.443107	array([[-2.0046186, -3.3056703]], dtype=float32)

time = 26562	action = 0	current_phase = 1	next_phase = 0	reward = -0.283338	array([[-2.1466959, -2.969334 ]], dtype=float32)

time = 26567	action = 0	current_phase = 1	next_phase = 0	reward = -0.163624	array([[-2.4049735, -2.9781976]], dtype=float32)

time = 26572	action = 0	current_phase = 1	next_phase = 0	reward = 0.229111	array([[-2.1485233, -3.5116513]], dtype=float32)

time = 26577	action = 1	current_phase = 1	next_phase = 0	reward = -1.777737	array([[-5.2909203, -3.5899355]], dtype=float32)

time = 26585	action = 0	current_phase = 0	next_phase = 1	reward = -0.522576	array([[-2.180664 , -2.8912058]], dtype=float32)

time = 26590	action = 0	current_phase = 0	next_phase = 1	reward = -0.367740	array([[-2.0381846, -2.4960923]], dtype=float32)

time = 26595	action = 0	current_phase = 0	next_phase = 1	reward = -0.213086	array([[-1.9870982, -3.0664506]], dtype=float32)

time = 26600	action = 0	current_phase = 0	next_phase = 1	reward = 0.343170	array([[-2.0167453, -3.2310147]], dtype=float32)

time = 26605	action = 1	current_phase = 0	next_phase = 1	reward = -1.369137	array([[-4.0015807, -3.0771313]], dtype=float32)

time = 26613	action = 0	current_phase = 1	next_phase = 0	reward = -0.588909	array([[-2.2716272, -2.9180338]], dtype=float32)

time = 26618	action = 0	current_phase = 1	next_phase = 0	reward = -0.436744	array([[-2.133548 , -2.9821522]], dtype=float32)

time = 26623	action = 0	current_phase = 1	next_phase = 0	reward = -0.290792	array([[-2.1505666, -2.9637508]], dtype=float32)

time = 26628	action = 0	current_phase = 1	next_phase = 0	reward = -0.162628	array([[-2.421142 , -3.0098965]], dtype=float32)

time = 26633	action = 0	current_phase = 1	next_phase = 0	reward = 0.066660	array([[-3.1052663, -3.482376 ]], dtype=float32)

time = 26638	action = 1	current_phase = 1	next_phase = 0	reward = -1.899341	array([[-5.361723, -3.649175]], dtype=float32)

time = 26646	action = 0	current_phase = 0	next_phase = 1	reward = -0.497953	array([[-2.1637821, -2.8550806]], dtype=float32)

time = 26651	action = 0	current_phase = 0	next_phase = 1	reward = -0.341738	array([[-2.0376127, -2.5118303]], dtype=float32)

time = 26656	action = 0	current_phase = 0	next_phase = 1	reward = -0.189971	array([[-2.0042088, -3.028275 ]], dtype=float32)

time = 26661	action = 0	current_phase = 0	next_phase = 1	reward = 0.316000	array([[-2.3731444, -3.9556317]], dtype=float32)

time = 26666	action = 1	current_phase = 0	next_phase = 1	reward = -1.610586	array([[-4.053025 , -3.1436362]], dtype=float32)

time = 26674	action = 0	current_phase = 1	next_phase = 0	reward = -0.553588	array([[-2.134297 , -2.9425843]], dtype=float32)

time = 26679	action = 0	current_phase = 1	next_phase = 0	reward = -0.399719	array([[-1.9476882, -3.1318703]], dtype=float32)

time = 26684	action = 0	current_phase = 1	next_phase = 0	reward = -0.241013	array([[-2.066848 , -2.9002483]], dtype=float32)

time = 26689	action = 0	current_phase = 1	next_phase = 0	reward = -0.184552	array([[-2.3753576, -3.3017218]], dtype=float32)

time = 26694	action = 0	current_phase = 1	next_phase = 0	reward = -0.066293	array([[-2.3299682, -2.4663515]], dtype=float32)

time = 26699	action = 1	current_phase = 1	next_phase = 0	reward = -2.006675	array([[-5.180415 , -3.6793268]], dtype=float32)

time = 26707	action = 0	current_phase = 0	next_phase = 1	reward = -0.464985	array([[-2.1151674, -2.6990905]], dtype=float32)

time = 26712	action = 0	current_phase = 0	next_phase = 1	reward = -0.306501	array([[-2.0106533, -2.7932396]], dtype=float32)

time = 26717	action = 0	current_phase = 0	next_phase = 1	reward = -0.172364	array([[-2.1694157, -2.6697316]], dtype=float32)

time = 26722	action = 0	current_phase = 0	next_phase = 1	reward = 0.189072	array([[-2.4218438, -4.139732 ]], dtype=float32)

time = 26727	action = 1	current_phase = 0	next_phase = 1	reward = -1.726958	array([[-4.9556823, -3.428771 ]], dtype=float32)

time = 26735	action = 0	current_phase = 1	next_phase = 0	reward = -0.520951	array([[-2.0952978, -2.8930922]], dtype=float32)

time = 26740	action = 0	current_phase = 1	next_phase = 0	reward = -0.375933	array([[-1.9401622, -3.1384637]], dtype=float32)

time = 26745	action = 0	current_phase = 1	next_phase = 0	reward = -0.222145	array([[-1.8373399, -3.042657 ]], dtype=float32)

time = 26750	action = 0	current_phase = 1	next_phase = 0	reward = 0.348725	array([[-2.16287  , -3.4306622]], dtype=float32)

time = 26755	action = 1	current_phase = 1	next_phase = 0	reward = -1.316697	array([[-4.0014496, -3.153208 ]], dtype=float32)

time = 26763	action = 0	current_phase = 0	next_phase = 1	reward = -0.596712	array([[-2.228956 , -2.6898608]], dtype=float32)

time = 26768	action = 0	current_phase = 0	next_phase = 1	reward = -0.441422	array([[-2.0438135, -2.4997401]], dtype=float32)

time = 26773	action = 0	current_phase = 0	next_phase = 1	reward = -0.272480	array([[-2.0876365, -3.0717854]], dtype=float32)

time = 26778	action = 0	current_phase = 0	next_phase = 1	reward = -0.163279	array([[-2.3537133, -2.663042 ]], dtype=float32)

time = 26783	action = 0	current_phase = 0	next_phase = 1	reward = 0.045076	array([[-3.322464 , -3.8513913]], dtype=float32)

time = 26788	action = 1	current_phase = 0	next_phase = 1	reward = -1.899307	array([[-5.66403  , -3.5039368]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0594 - val_loss: 0.0742

Epoch 2/50

 - 4s - loss: 0.0697 - val_loss: 0.0784

Epoch 3/50

 - 4s - loss: 0.0711 - val_loss: 0.0721

Epoch 4/50

 - 4s - loss: 0.0393 - val_loss: 0.0758

Epoch 5/50

 - 4s - loss: 0.0487 - val_loss: 0.0760

Epoch 6/50

 - 4s - loss: 0.0509 - val_loss: 0.0762

Epoch 7/50

 - 4s - loss: 0.0704 - val_loss: 0.0765

Epoch 8/50

 - 4s - loss: 0.0477 - val_loss: 0.0763

Epoch 9/50

 - 4s - loss: 0.0408 - val_loss: 0.0752

Epoch 10/50

 - 4s - loss: 0.0345 - val_loss: 0.0771

Epoch 11/50

 - 4s - loss: 0.0405 - val_loss: 0.0735

Epoch 12/50

 - 4s - loss: 0.0473 - val_loss: 0.0746

Epoch 13/50

 - 5s - loss: 0.0670 - val_loss: 0.0755

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 782, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 769, after forget

time = 26796	action = 0	current_phase = 1	next_phase = 0	reward = -0.501373	array([[-2.171484 , -3.2111144]], dtype=float32)

time = 26801	action = 0	current_phase = 1	next_phase = 0	reward = -0.349045	array([[-2.0235524, -3.0345218]], dtype=float32)

time = 26806	action = 0	current_phase = 1	next_phase = 0	reward = -0.194495	array([[-2.0958598, -3.0714893]], dtype=float32)

time = 26811	action = 0	current_phase = 1	next_phase = 0	reward = 0.331214	array([[-2.5959177, -3.6942868]], dtype=float32)

time = 26816	action = 1	current_phase = 1	next_phase = 0	reward = -1.501707	array([[-5.0468836, -3.353058 ]], dtype=float32)

time = 26824	action = 0	current_phase = 0	next_phase = 1	reward = -0.566686	array([[-2.2157772, -2.722137 ]], dtype=float32)

time = 26829	action = 0	current_phase = 0	next_phase = 1	reward = -0.422589	array([[-1.992841, -2.517708]], dtype=float32)

time = 26834	action = 0	current_phase = 0	next_phase = 1	reward = -0.266221	array([[-1.9248601, -3.0871816]], dtype=float32)

time = 26839	action = 0	current_phase = 0	next_phase = 1	reward = -0.179492	array([[-2.075413, -3.134528]], dtype=float32)

time = 26844	action = 1	current_phase = 0	next_phase = 1	reward = -0.537168	array([[-3.3531728, -2.1770394]], dtype=float32)

time = 26852	action = 0	current_phase = 1	next_phase = 0	reward = -0.622905	array([[-2.1936023, -2.964114 ]], dtype=float32)

time = 26857	action = 0	current_phase = 1	next_phase = 0	reward = -0.472708	array([[-2.1363835, -3.2897305]], dtype=float32)

time = 26862	action = 0	current_phase = 1	next_phase = 0	reward = -0.331393	array([[-2.1014557, -2.9711704]], dtype=float32)

time = 26867	action = 0	current_phase = 1	next_phase = 0	reward = -0.192192	array([[-2.3206332, -2.9515905]], dtype=float32)

time = 26872	action = 0	current_phase = 1	next_phase = 0	reward = 0.299643	array([[-2.77451  , -3.6434095]], dtype=float32)

time = 26877	action = 1	current_phase = 1	next_phase = 0	reward = -1.725214	array([[-5.083666 , -3.5280473]], dtype=float32)

time = 26885	action = 0	current_phase = 0	next_phase = 1	reward = -0.519365	array([[-2.2080705, -2.96768  ]], dtype=float32)

time = 26890	action = 0	current_phase = 0	next_phase = 1	reward = -0.370183	array([[-1.9922633, -2.5186622]], dtype=float32)

time = 26895	action = 0	current_phase = 0	next_phase = 1	reward = -0.219637	array([[-1.9248618, -3.0874908]], dtype=float32)

time = 26900	action = 0	current_phase = 0	next_phase = 1	reward = 0.350958	array([[-1.945728 , -3.3705547]], dtype=float32)

time = 26905	action = 1	current_phase = 0	next_phase = 1	reward = -1.368113	array([[-3.9672606, -3.1520343]], dtype=float32)

time = 26913	action = 0	current_phase = 1	next_phase = 0	reward = -0.592496	array([[-2.271245 , -2.9245772]], dtype=float32)

time = 26918	action = 0	current_phase = 1	next_phase = 0	reward = -0.439699	array([[-2.0859284, -2.9940412]], dtype=float32)

time = 26923	action = 0	current_phase = 1	next_phase = 0	reward = -0.278682	array([[-2.0987592, -2.949328 ]], dtype=float32)

time = 26928	action = 0	current_phase = 1	next_phase = 0	reward = -0.163897	array([[-2.3117452, -3.0704012]], dtype=float32)

time = 26933	action = 0	current_phase = 1	next_phase = 0	reward = -0.000995	array([[-2.3909376, -2.4752116]], dtype=float32)

time = 26938	action = 1	current_phase = 1	next_phase = 0	reward = -1.899821	array([[-5.3072815, -3.64324  ]], dtype=float32)

time = 26946	action = 0	current_phase = 0	next_phase = 1	reward = -0.492979	array([[-2.1340692, -2.9292865]], dtype=float32)

time = 26951	action = 0	current_phase = 0	next_phase = 1	reward = -0.344341	array([[-1.9849249, -2.5653098]], dtype=float32)

time = 26956	action = 0	current_phase = 0	next_phase = 1	reward = -0.191655	array([[-1.9390557, -3.0650713]], dtype=float32)

time = 26961	action = 0	current_phase = 0	next_phase = 1	reward = 0.285994	array([[-2.258141 , -3.7736444]], dtype=float32)

time = 26966	action = 1	current_phase = 0	next_phase = 1	reward = -1.607760	array([[-3.8386817, -3.163657 ]], dtype=float32)

time = 26974	action = 0	current_phase = 1	next_phase = 0	reward = -0.549273	array([[-2.0014198, -2.876214 ]], dtype=float32)

time = 26979	action = 0	current_phase = 1	next_phase = 0	reward = -0.402594	array([[-1.8737439, -3.1481807]], dtype=float32)

time = 26984	action = 0	current_phase = 1	next_phase = 0	reward = -0.260723	array([[-1.7599567, -3.019152 ]], dtype=float32)

time = 26989	action = 0	current_phase = 1	next_phase = 0	reward = -0.188186	array([[-2.1220942, -3.487316 ]], dtype=float32)

time = 26994	action = 1	current_phase = 1	next_phase = 0	reward = -0.605439	array([[-2.3794138, -2.3029442]], dtype=float32)

time = 27002	action = 0	current_phase = 0	next_phase = 1	reward = -0.607115	array([[-2.2624342, -2.8276916]], dtype=float32)

time = 27007	action = 0	current_phase = 0	next_phase = 1	reward = -0.447022	array([[-2.0242553, -2.6230552]], dtype=float32)

time = 27012	action = 0	current_phase = 0	next_phase = 1	reward = -0.291980	array([[-1.9298061, -3.083438 ]], dtype=float32)

time = 27017	action = 0	current_phase = 0	next_phase = 1	reward = -0.167855	array([[-2.1907973, -2.7176669]], dtype=float32)

time = 27022	action = 0	current_phase = 0	next_phase = 1	reward = 0.173536	array([[-2.4584506, -4.2246256]], dtype=float32)

time = 27027	action = 1	current_phase = 0	next_phase = 1	reward = -1.787239	array([[-5.4964867, -3.5485928]], dtype=float32)

time = 27035	action = 0	current_phase = 1	next_phase = 0	reward = -0.532496	array([[-2.0651379, -2.96849  ]], dtype=float32)

time = 27040	action = 0	current_phase = 1	next_phase = 0	reward = -0.379453	array([[-1.8733548, -3.1447074]], dtype=float32)

time = 27045	action = 0	current_phase = 1	next_phase = 0	reward = -0.224075	array([[-1.7890937, -3.0412698]], dtype=float32)

time = 27050	action = 0	current_phase = 1	next_phase = 0	reward = 0.382423	array([[-2.097875 , -3.4503255]], dtype=float32)

time = 27055	action = 1	current_phase = 1	next_phase = 0	reward = -1.240588	array([[-3.8287718, -3.0210798]], dtype=float32)

time = 27063	action = 0	current_phase = 0	next_phase = 1	reward = -0.596594	array([[-2.222993, -2.737541]], dtype=float32)

time = 27068	action = 0	current_phase = 0	next_phase = 1	reward = -0.437111	array([[-1.9866396, -2.5860183]], dtype=float32)

time = 27073	action = 0	current_phase = 0	next_phase = 1	reward = -0.282650	array([[-2.0010397, -3.081339 ]], dtype=float32)

time = 27078	action = 0	current_phase = 0	next_phase = 1	reward = -0.163779	array([[-2.2527494, -2.727875 ]], dtype=float32)

time = 27083	action = 0	current_phase = 0	next_phase = 1	reward = 0.034308	array([[-2.3493729, -3.485489 ]], dtype=float32)

time = 27088	action = 1	current_phase = 0	next_phase = 1	reward = -1.905311	array([[-5.6824956, -3.4898574]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0420 - val_loss: 0.0098

Epoch 2/50

 - 4s - loss: 0.0313 - val_loss: 0.0102

Epoch 3/50

 - 4s - loss: 0.0417 - val_loss: 0.0095

Epoch 4/50

 - 4s - loss: 0.0390 - val_loss: 0.0110

Epoch 5/50

 - 5s - loss: 0.0296 - val_loss: 0.0100

Epoch 6/50

 - 5s - loss: 0.0395 - val_loss: 0.0091

Epoch 7/50

 - 5s - loss: 0.0401 - val_loss: 0.0102

Epoch 8/50

 - 5s - loss: 0.0382 - val_loss: 0.0094

Epoch 9/50

 - 5s - loss: 0.0348 - val_loss: 0.0101

Epoch 10/50

 - 4s - loss: 0.0286 - val_loss: 0.0101

Epoch 11/50

 - 4s - loss: 0.0328 - val_loss: 0.0115

Epoch 12/50

 - 4s - loss: 0.0365 - val_loss: 0.0097

Epoch 13/50

 - 4s - loss: 0.0342 - val_loss: 0.0102

Epoch 14/50

 - 4s - loss: 0.0256 - val_loss: 0.0103

Epoch 15/50

 - 4s - loss: 0.0255 - val_loss: 0.0117

Epoch 16/50

 - 4s - loss: 0.0391 - val_loss: 0.0103

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 787, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 774, after forget

time = 27096	action = 0	current_phase = 1	next_phase = 0	reward = -0.499884	array([[-2.0359445, -3.1108902]], dtype=float32)

time = 27101	action = 0	current_phase = 1	next_phase = 0	reward = -0.343800	array([[-1.9933022, -3.0278494]], dtype=float32)

time = 27106	action = 0	current_phase = 1	next_phase = 0	reward = -0.196704	array([[-2.0701513, -3.0995023]], dtype=float32)

time = 27111	action = 0	current_phase = 1	next_phase = 0	reward = 0.297782	array([[-2.5645177, -3.6969774]], dtype=float32)

time = 27116	action = 1	current_phase = 1	next_phase = 0	reward = -1.559874	array([[-5.141885, -3.341702]], dtype=float32)

time = 27124	action = 0	current_phase = 0	next_phase = 1	reward = -0.563836	array([[-2.2409182, -2.7621174]], dtype=float32)

time = 27129	action = 0	current_phase = 0	next_phase = 1	reward = -0.409421	array([[-2.0342536, -2.5818903]], dtype=float32)

time = 27134	action = 0	current_phase = 0	next_phase = 1	reward = -0.246701	array([[-1.9398087, -3.1373158]], dtype=float32)

time = 27139	action = 0	current_phase = 0	next_phase = 1	reward = -0.172701	array([[-2.019675, -3.258038]], dtype=float32)

time = 27144	action = 1	current_phase = 0	next_phase = 1	reward = -0.484912	array([[-3.2718034, -2.1498597]], dtype=float32)

time = 27152	action = 0	current_phase = 1	next_phase = 0	reward = -0.612397	array([[-2.1594882, -2.9545436]], dtype=float32)

time = 27157	action = 0	current_phase = 1	next_phase = 0	reward = -0.456219	array([[-2.056988 , -3.2649448]], dtype=float32)

time = 27162	action = 0	current_phase = 1	next_phase = 0	reward = -0.297015	array([[-2.0908432, -2.9612272]], dtype=float32)

time = 27167	action = 0	current_phase = 1	next_phase = 0	reward = -0.166415	array([[-2.3373797, -2.987116 ]], dtype=float32)

time = 27172	action = 0	current_phase = 1	next_phase = 0	reward = 0.246278	array([[-2.5631902, -3.7062163]], dtype=float32)

time = 27177	action = 1	current_phase = 1	next_phase = 0	reward = -1.732856	array([[-5.40121  , -3.5730739]], dtype=float32)

time = 27185	action = 0	current_phase = 0	next_phase = 1	reward = -0.537847	array([[-2.1887221, -2.9583452]], dtype=float32)

time = 27190	action = 0	current_phase = 0	next_phase = 1	reward = -0.376910	array([[-2.0292807, -2.6078413]], dtype=float32)

time = 27195	action = 0	current_phase = 0	next_phase = 1	reward = -0.216925	array([[-1.9335243, -3.1522384]], dtype=float32)

time = 27200	action = 0	current_phase = 0	next_phase = 1	reward = 0.367477	array([[-2.0432444, -3.3686066]], dtype=float32)

time = 27205	action = 1	current_phase = 0	next_phase = 1	reward = -1.306712	array([[-3.9950852, -3.0739906]], dtype=float32)

time = 27213	action = 0	current_phase = 1	next_phase = 0	reward = -0.580051	array([[-2.1216435, -2.9623263]], dtype=float32)

time = 27218	action = 0	current_phase = 1	next_phase = 0	reward = -0.427345	array([[-2.085529, -2.979499]], dtype=float32)

time = 27223	action = 0	current_phase = 1	next_phase = 0	reward = -0.269117	array([[-2.0920477, -2.9564884]], dtype=float32)

time = 27228	action = 0	current_phase = 1	next_phase = 0	reward = -0.165493	array([[-2.308742 , -3.1277475]], dtype=float32)

time = 27233	action = 1	current_phase = 1	next_phase = 0	reward = -0.984937	array([[-2.5984554, -2.3483953]], dtype=float32)

time = 27241	action = 0	current_phase = 0	next_phase = 1	reward = -1.171156	array([[-2.3444471, -2.8431702]], dtype=float32)

time = 27246	action = 0	current_phase = 0	next_phase = 1	reward = -1.041299	array([[-2.524847 , -3.0129821]], dtype=float32)

time = 27251	action = 0	current_phase = 0	next_phase = 1	reward = -0.921521	array([[-2.295134, -3.123155]], dtype=float32)

time = 27256	action = 0	current_phase = 0	next_phase = 1	reward = -0.797773	array([[-2.6983218, -2.8066945]], dtype=float32)

time = 27261	action = 0	current_phase = 0	next_phase = 1	reward = -0.282735	array([[-3.269866 , -3.8589854]], dtype=float32)

time = 27266	action = 1	current_phase = 0	next_phase = 1	reward = -1.579965	array([[-5.6094275, -3.2100873]], dtype=float32)

time = 27274	action = 0	current_phase = 1	next_phase = 0	reward = -0.567063	array([[-1.8904438, -2.8862548]], dtype=float32)

time = 27279	action = 0	current_phase = 1	next_phase = 0	reward = -0.413853	array([[-1.8491945, -3.1292293]], dtype=float32)

time = 27284	action = 0	current_phase = 1	next_phase = 0	reward = -0.252294	array([[-1.8155153, -3.0934095]], dtype=float32)

time = 27289	action = 0	current_phase = 1	next_phase = 0	reward = -0.168291	array([[-2.052958 , -3.4632454]], dtype=float32)

time = 27294	action = 0	current_phase = 1	next_phase = 0	reward = 0.006561	array([[-2.2596586, -2.3675697]], dtype=float32)

time = 27299	action = 1	current_phase = 1	next_phase = 0	reward = -2.003095	array([[-5.3133154, -3.6281345]], dtype=float32)

time = 27307	action = 0	current_phase = 0	next_phase = 1	reward = -0.451527	array([[-2.1339934, -2.8440628]], dtype=float32)

time = 27312	action = 0	current_phase = 0	next_phase = 1	reward = -0.291230	array([[-1.9782692, -2.862804 ]], dtype=float32)

time = 27317	action = 0	current_phase = 0	next_phase = 1	reward = -0.166058	array([[-2.1876082, -2.7619848]], dtype=float32)

time = 27322	action = 0	current_phase = 0	next_phase = 1	reward = 0.127767	array([[-2.5400639, -3.9353032]], dtype=float32)

time = 27327	action = 1	current_phase = 0	next_phase = 1	reward = -1.789255	array([[-5.363315 , -3.5175917]], dtype=float32)

time = 27335	action = 0	current_phase = 1	next_phase = 0	reward = -0.538596	array([[-2.0133204, -2.885618 ]], dtype=float32)

time = 27340	action = 0	current_phase = 1	next_phase = 0	reward = -0.379496	array([[-1.850317 , -3.1275032]], dtype=float32)

time = 27345	action = 0	current_phase = 1	next_phase = 0	reward = -0.221951	array([[-1.7726786, -3.0220568]], dtype=float32)

time = 27350	action = 0	current_phase = 1	next_phase = 0	reward = 0.364597	array([[-2.063518 , -3.5247664]], dtype=float32)

time = 27355	action = 1	current_phase = 1	next_phase = 0	reward = -1.197556	array([[-3.9999182, -3.0376954]], dtype=float32)

time = 27363	action = 0	current_phase = 0	next_phase = 1	reward = -0.589156	array([[-2.3057723, -2.8302693]], dtype=float32)

time = 27368	action = 0	current_phase = 0	next_phase = 1	reward = -0.444135	array([[-2.0295148, -2.6101513]], dtype=float32)

time = 27373	action = 0	current_phase = 0	next_phase = 1	reward = -0.293462	array([[-2.000973 , -3.0991507]], dtype=float32)

time = 27378	action = 0	current_phase = 0	next_phase = 1	reward = -0.171039	array([[-2.4319506, -2.8371954]], dtype=float32)

time = 27383	action = 0	current_phase = 0	next_phase = 1	reward = 0.071061	array([[-2.451796 , -3.9310284]], dtype=float32)

time = 27388	action = 1	current_phase = 0	next_phase = 1	reward = -1.895599	array([[-5.683088 , -3.5046113]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0716 - val_loss: 0.0136

Epoch 2/50

 - 5s - loss: 0.0791 - val_loss: 0.0173

Epoch 3/50

 - 5s - loss: 0.0460 - val_loss: 0.0159

Epoch 4/50

 - 5s - loss: 0.0736 - val_loss: 0.0174

Epoch 5/50

 - 5s - loss: 0.0448 - val_loss: 0.0151

Epoch 6/50

 - 4s - loss: 0.0387 - val_loss: 0.0202

Epoch 7/50

 - 4s - loss: 0.0413 - val_loss: 0.0212

Epoch 8/50

 - 5s - loss: 0.0460 - val_loss: 0.0160

Epoch 9/50

 - 5s - loss: 0.0479 - val_loss: 0.0160

Epoch 10/50

 - 4s - loss: 0.0273 - val_loss: 0.0178

Epoch 11/50

 - 5s - loss: 0.0510 - val_loss: 0.0152

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 792, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 779, after forget

time = 27396	action = 0	current_phase = 1	next_phase = 0	reward = -0.491319	array([[-2.123179, -3.136546]], dtype=float32)

time = 27401	action = 0	current_phase = 1	next_phase = 0	reward = -0.333698	array([[-1.98053  , -3.0750618]], dtype=float32)

time = 27406	action = 0	current_phase = 1	next_phase = 0	reward = -0.183685	array([[-2.1716084, -3.1066117]], dtype=float32)

time = 27411	action = 0	current_phase = 1	next_phase = 0	reward = 0.310757	array([[-2.5260468, -3.7148988]], dtype=float32)

time = 27416	action = 1	current_phase = 1	next_phase = 0	reward = -1.504108	array([[-5.2176404, -3.39084  ]], dtype=float32)

time = 27424	action = 0	current_phase = 0	next_phase = 1	reward = -0.559947	array([[-2.1447947, -2.740508 ]], dtype=float32)

time = 27429	action = 0	current_phase = 0	next_phase = 1	reward = -0.408303	array([[-1.9839857, -2.6128445]], dtype=float32)

time = 27434	action = 0	current_phase = 0	next_phase = 1	reward = -0.252193	array([[-1.9488851, -3.1955676]], dtype=float32)

time = 27439	action = 0	current_phase = 0	next_phase = 1	reward = -0.181099	array([[-1.8890413, -3.70059  ]], dtype=float32)

time = 27444	action = 1	current_phase = 0	next_phase = 1	reward = -0.449490	array([[-3.3411894, -2.2634144]], dtype=float32)

time = 27452	action = 0	current_phase = 1	next_phase = 0	reward = -0.619198	array([[-2.2374787, -2.9368002]], dtype=float32)

time = 27457	action = 0	current_phase = 1	next_phase = 0	reward = -0.461096	array([[-2.0708573, -3.2571003]], dtype=float32)

time = 27462	action = 0	current_phase = 1	next_phase = 0	reward = -0.303481	array([[-2.134456 , -2.9478333]], dtype=float32)

time = 27467	action = 0	current_phase = 1	next_phase = 0	reward = -0.168579	array([[-2.2991412, -3.0366745]], dtype=float32)

time = 27472	action = 0	current_phase = 1	next_phase = 0	reward = 0.190248	array([[-2.5373948, -3.585314 ]], dtype=float32)

time = 27477	action = 1	current_phase = 1	next_phase = 0	reward = -1.783501	array([[-5.449042 , -3.6220152]], dtype=float32)

time = 27485	action = 0	current_phase = 0	next_phase = 1	reward = -0.527129	array([[-2.1638222, -3.0281496]], dtype=float32)

time = 27490	action = 0	current_phase = 0	next_phase = 1	reward = -0.366199	array([[-1.9826964, -2.6269991]], dtype=float32)

time = 27495	action = 0	current_phase = 0	next_phase = 1	reward = -0.222709	array([[-1.9440254, -3.1952622]], dtype=float32)

time = 27500	action = 0	current_phase = 0	next_phase = 1	reward = 0.065948	array([[-2.035237 , -3.4064038]], dtype=float32)

time = 27505	action = 1	current_phase = 0	next_phase = 1	reward = -1.029078	array([[-3.394103, -2.689716]], dtype=float32)

time = 27513	action = 0	current_phase = 1	next_phase = 0	reward = -0.591075	array([[-2.2428102, -2.9323754]], dtype=float32)

time = 27518	action = 0	current_phase = 1	next_phase = 0	reward = -0.435783	array([[-2.1392255, -2.972811 ]], dtype=float32)

time = 27523	action = 0	current_phase = 1	next_phase = 0	reward = -0.277312	array([[-2.1376317, -2.9503016]], dtype=float32)

time = 27528	action = 0	current_phase = 1	next_phase = 0	reward = -0.160768	array([[-2.394335, -3.027354]], dtype=float32)

time = 27533	action = 0	current_phase = 1	next_phase = 0	reward = 0.017634	array([[-2.9852507, -3.5070288]], dtype=float32)

time = 27538	action = 1	current_phase = 1	next_phase = 0	reward = -1.895768	array([[-5.34496  , -3.6517255]], dtype=float32)

time = 27546	action = 0	current_phase = 0	next_phase = 1	reward = -0.492893	array([[-2.1195154, -2.9903529]], dtype=float32)

time = 27551	action = 0	current_phase = 0	next_phase = 1	reward = -0.349685	array([[-1.9917192, -2.602997 ]], dtype=float32)

time = 27556	action = 0	current_phase = 0	next_phase = 1	reward = -0.203143	array([[-2.03673  , -3.0236773]], dtype=float32)

time = 27561	action = 0	current_phase = 0	next_phase = 1	reward = 0.295532	array([[-2.3207572, -4.0530953]], dtype=float32)

time = 27566	action = 1	current_phase = 0	next_phase = 1	reward = -1.610145	array([[-4.0657225, -3.1543357]], dtype=float32)

time = 27574	action = 0	current_phase = 1	next_phase = 0	reward = -0.546709	array([[-2.064524 , -2.8847165]], dtype=float32)

time = 27579	action = 0	current_phase = 1	next_phase = 0	reward = -0.389451	array([[-1.9765261, -3.092145 ]], dtype=float32)

time = 27584	action = 0	current_phase = 1	next_phase = 0	reward = -0.244224	array([[-1.8233215, -3.0340402]], dtype=float32)

time = 27589	action = 0	current_phase = 1	next_phase = 0	reward = -0.181730	array([[-1.9895165, -3.4425623]], dtype=float32)

time = 27594	action = 1	current_phase = 1	next_phase = 0	reward = -0.437154	array([[-2.433251 , -2.3701818]], dtype=float32)

time = 27602	action = 0	current_phase = 0	next_phase = 1	reward = -0.613534	array([[-2.3088355, -2.9171274]], dtype=float32)

time = 27607	action = 0	current_phase = 0	next_phase = 1	reward = -0.461726	array([[-1.9986908, -2.6199605]], dtype=float32)

time = 27612	action = 0	current_phase = 0	next_phase = 1	reward = -0.307610	array([[-2.05073  , -3.0091755]], dtype=float32)

time = 27617	action = 0	current_phase = 0	next_phase = 1	reward = -0.171749	array([[-2.2893593, -2.8454397]], dtype=float32)

time = 27622	action = 0	current_phase = 0	next_phase = 1	reward = 0.189205	array([[-2.533566, -4.234926]], dtype=float32)

time = 27627	action = 1	current_phase = 0	next_phase = 1	reward = -1.730571	array([[-5.5986404, -3.4571671]], dtype=float32)

time = 27635	action = 0	current_phase = 1	next_phase = 0	reward = -0.520824	array([[-2.0593312, -2.938609 ]], dtype=float32)

time = 27640	action = 0	current_phase = 1	next_phase = 0	reward = -0.365768	array([[-1.901324 , -3.1244311]], dtype=float32)

time = 27645	action = 0	current_phase = 1	next_phase = 0	reward = -0.221368	array([[-2.0944445, -3.048592 ]], dtype=float32)

time = 27650	action = 0	current_phase = 1	next_phase = 0	reward = 0.340657	array([[-2.206453 , -3.6120584]], dtype=float32)

time = 27655	action = 1	current_phase = 1	next_phase = 0	reward = -1.423077	array([[-4.0548024, -3.1418562]], dtype=float32)

time = 27663	action = 0	current_phase = 0	next_phase = 1	reward = -0.589768	array([[-2.2769587, -2.875315 ]], dtype=float32)

time = 27668	action = 0	current_phase = 0	next_phase = 1	reward = -0.438326	array([[-1.9842699, -2.6223586]], dtype=float32)

time = 27673	action = 0	current_phase = 0	next_phase = 1	reward = -0.281709	array([[-1.9653682, -3.1760647]], dtype=float32)

time = 27678	action = 0	current_phase = 0	next_phase = 1	reward = -0.165149	array([[-2.4439943, -2.878847 ]], dtype=float32)

time = 27683	action = 0	current_phase = 0	next_phase = 1	reward = 0.019893	array([[-2.900753, -4.318247]], dtype=float32)

time = 27688	action = 1	current_phase = 0	next_phase = 1	reward = -1.889889	array([[-5.674015 , -3.5342176]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0263 - val_loss: 0.0233

Epoch 2/50

 - 5s - loss: 0.0280 - val_loss: 0.0232

Epoch 3/50

 - 5s - loss: 0.0359 - val_loss: 0.0230

Epoch 4/50

 - 5s - loss: 0.0329 - val_loss: 0.0235

Epoch 5/50

 - 5s - loss: 0.0245 - val_loss: 0.0248

Epoch 6/50

 - 4s - loss: 0.0260 - val_loss: 0.0238

Epoch 7/50

 - 5s - loss: 0.0316 - val_loss: 0.0226

Epoch 8/50

 - 5s - loss: 0.0310 - val_loss: 0.0220

Epoch 9/50

 - 5s - loss: 0.0353 - val_loss: 0.0219

Epoch 10/50

 - 4s - loss: 0.0275 - val_loss: 0.0218

Epoch 11/50

 - 5s - loss: 0.0287 - val_loss: 0.0231

Epoch 12/50

 - 5s - loss: 0.0320 - val_loss: 0.0238

Epoch 13/50

 - 4s - loss: 0.0289 - val_loss: 0.0236

Epoch 14/50

 - 4s - loss: 0.0248 - val_loss: 0.0243

Epoch 15/50

 - 4s - loss: 0.0317 - val_loss: 0.0234

Epoch 16/50

 - 5s - loss: 0.0232 - val_loss: 0.0250

Epoch 17/50

 - 5s - loss: 0.0286 - val_loss: 0.0238

Epoch 18/50

 - 4s - loss: 0.0215 - val_loss: 0.0234

Epoch 19/50

 - 5s - loss: 0.0294 - val_loss: 0.0239

Epoch 20/50

 - 5s - loss: 0.0399 - val_loss: 0.0236

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 797, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 784, after forget

time = 27696	action = 0	current_phase = 1	next_phase = 0	reward = -0.484433	array([[-2.1358562, -3.1277976]], dtype=float32)

time = 27701	action = 0	current_phase = 1	next_phase = 0	reward = -0.334012	array([[-1.9556847, -3.0694647]], dtype=float32)

time = 27706	action = 0	current_phase = 1	next_phase = 0	reward = -0.197768	array([[-2.1536508, -3.0895917]], dtype=float32)

time = 27711	action = 0	current_phase = 1	next_phase = 0	reward = 0.324209	array([[-2.4681869, -3.7379072]], dtype=float32)

time = 27716	action = 1	current_phase = 1	next_phase = 0	reward = -1.555110	array([[-5.251547 , -3.4399025]], dtype=float32)

time = 27724	action = 0	current_phase = 0	next_phase = 1	reward = -0.544854	array([[-2.1492794, -2.7508254]], dtype=float32)

time = 27729	action = 0	current_phase = 0	next_phase = 1	reward = -0.374257	array([[-1.9925797, -2.6091504]], dtype=float32)

time = 27734	action = 0	current_phase = 0	next_phase = 1	reward = -0.217950	array([[-1.9447591, -3.211165 ]], dtype=float32)

time = 27739	action = 0	current_phase = 0	next_phase = 1	reward = -0.196977	array([[-1.9144793, -3.6519365]], dtype=float32)

time = 27744	action = 1	current_phase = 0	next_phase = 1	reward = -0.554612	array([[-3.0344648, -2.2189548]], dtype=float32)

time = 27752	action = 0	current_phase = 1	next_phase = 0	reward = -0.613293	array([[-2.2220907, -2.9417632]], dtype=float32)

time = 27757	action = 0	current_phase = 1	next_phase = 0	reward = -0.463179	array([[-2.1795087, -3.1974764]], dtype=float32)

time = 27762	action = 0	current_phase = 1	next_phase = 0	reward = -0.309507	array([[-2.0562832, -2.884646 ]], dtype=float32)

time = 27767	action = 0	current_phase = 1	next_phase = 0	reward = -0.175009	array([[-2.3545058, -3.023415 ]], dtype=float32)

time = 27772	action = 0	current_phase = 1	next_phase = 0	reward = 0.177739	array([[-2.584804 , -3.6836658]], dtype=float32)

time = 27777	action = 1	current_phase = 1	next_phase = 0	reward = -1.790865	array([[-5.342073, -3.596852]], dtype=float32)

time = 27785	action = 0	current_phase = 0	next_phase = 1	reward = -0.542345	array([[-2.143507 , -2.9868104]], dtype=float32)

time = 27790	action = 0	current_phase = 0	next_phase = 1	reward = -0.390065	array([[-1.9921623, -2.6125746]], dtype=float32)

time = 27795	action = 0	current_phase = 0	next_phase = 1	reward = -0.235889	array([[-1.9432958, -3.2176194]], dtype=float32)

time = 27800	action = 0	current_phase = 0	next_phase = 1	reward = 0.075107	array([[-2.0032706, -3.3435621]], dtype=float32)

time = 27805	action = 1	current_phase = 0	next_phase = 1	reward = -1.024003	array([[-3.6662617, -2.4414966]], dtype=float32)

time = 27813	action = 0	current_phase = 1	next_phase = 0	reward = -0.590777	array([[-2.194452 , -2.9489074]], dtype=float32)

time = 27818	action = 0	current_phase = 1	next_phase = 0	reward = -0.432986	array([[-2.126276 , -2.9700687]], dtype=float32)

time = 27823	action = 0	current_phase = 1	next_phase = 0	reward = -0.272767	array([[-2.102525, -2.950249]], dtype=float32)

time = 27828	action = 0	current_phase = 1	next_phase = 0	reward = -0.164106	array([[-2.275909, -3.028345]], dtype=float32)

time = 27833	action = 0	current_phase = 1	next_phase = 0	reward = 0.055289	array([[-2.961201 , -3.4675438]], dtype=float32)

time = 27838	action = 1	current_phase = 1	next_phase = 0	reward = -1.895626	array([[-5.34767  , -3.6176744]], dtype=float32)

time = 27846	action = 0	current_phase = 0	next_phase = 1	reward = -0.492656	array([[-2.129658 , -2.9121804]], dtype=float32)

time = 27851	action = 0	current_phase = 0	next_phase = 1	reward = -0.329253	array([[-2.0025134, -2.5965023]], dtype=float32)

time = 27856	action = 0	current_phase = 0	next_phase = 1	reward = -0.180995	array([[-2.017768 , -3.0414019]], dtype=float32)

time = 27861	action = 0	current_phase = 0	next_phase = 1	reward = 0.301022	array([[-2.3590298, -3.7876487]], dtype=float32)

time = 27866	action = 1	current_phase = 0	next_phase = 1	reward = -1.665574	array([[-4.0434456, -3.1301472]], dtype=float32)

time = 27874	action = 0	current_phase = 1	next_phase = 0	reward = -0.558958	array([[-1.9361427, -2.7706184]], dtype=float32)

time = 27879	action = 0	current_phase = 1	next_phase = 0	reward = -0.404970	array([[-1.8873267, -3.1229286]], dtype=float32)

time = 27884	action = 0	current_phase = 1	next_phase = 0	reward = -0.252673	array([[-1.8474705, -3.0682223]], dtype=float32)

time = 27889	action = 0	current_phase = 1	next_phase = 0	reward = -0.169475	array([[-2.0604024, -3.5072653]], dtype=float32)

time = 27894	action = 1	current_phase = 1	next_phase = 0	reward = -0.416706	array([[-2.4494853, -2.282396 ]], dtype=float32)

time = 27902	action = 0	current_phase = 0	next_phase = 1	reward = -0.613773	array([[-2.3017635, -2.9066775]], dtype=float32)

time = 27907	action = 0	current_phase = 0	next_phase = 1	reward = -0.454551	array([[-2.001401 , -2.6413043]], dtype=float32)

time = 27912	action = 0	current_phase = 0	next_phase = 1	reward = -0.297879	array([[-2.0937095, -2.8739767]], dtype=float32)

time = 27917	action = 0	current_phase = 0	next_phase = 1	reward = -0.165061	array([[-2.276827 , -2.8499103]], dtype=float32)

time = 27922	action = 0	current_phase = 0	next_phase = 1	reward = 0.109600	array([[-2.5641963, -4.2214885]], dtype=float32)

time = 27927	action = 1	current_phase = 0	next_phase = 1	reward = -1.784213	array([[-5.7384653, -3.4058845]], dtype=float32)

time = 27935	action = 0	current_phase = 1	next_phase = 0	reward = -0.520849	array([[-2.0667439, -2.9157848]], dtype=float32)

time = 27940	action = 0	current_phase = 1	next_phase = 0	reward = -0.362865	array([[-1.8859389, -3.114506 ]], dtype=float32)

time = 27945	action = 0	current_phase = 1	next_phase = 0	reward = -0.208051	array([[-1.8037713, -3.035343 ]], dtype=float32)

time = 27950	action = 0	current_phase = 1	next_phase = 0	reward = 0.349169	array([[-2.0634801, -3.4357796]], dtype=float32)

time = 27955	action = 1	current_phase = 1	next_phase = 0	reward = -1.256814	array([[-3.8186598, -3.0766735]], dtype=float32)

time = 27963	action = 0	current_phase = 0	next_phase = 1	reward = -0.583017	array([[-2.1940374, -2.8071995]], dtype=float32)

time = 27968	action = 0	current_phase = 0	next_phase = 1	reward = -0.424958	array([[-1.9928526, -2.6092272]], dtype=float32)

time = 27973	action = 0	current_phase = 0	next_phase = 1	reward = -0.270540	array([[-2.063927 , -3.1928499]], dtype=float32)

time = 27978	action = 0	current_phase = 0	next_phase = 1	reward = -0.165276	array([[-2.48533  , -2.9030836]], dtype=float32)

time = 27983	action = 0	current_phase = 0	next_phase = 1	reward = -0.061856	array([[-2.9157984, -4.3227987]], dtype=float32)

time = 27988	action = 1	current_phase = 0	next_phase = 1	reward = -1.900904	array([[-5.686681 , -3.5308661]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0354 - val_loss: 0.0468

Epoch 2/50

 - 4s - loss: 0.0307 - val_loss: 0.0524

Epoch 3/50

 - 4s - loss: 0.0377 - val_loss: 0.0528

Epoch 4/50

 - 5s - loss: 0.0291 - val_loss: 0.0503

Epoch 5/50

 - 4s - loss: 0.0468 - val_loss: 0.0486

Epoch 6/50

 - 4s - loss: 0.0405 - val_loss: 0.0512

Epoch 7/50

 - 5s - loss: 0.0290 - val_loss: 0.0550

Epoch 8/50

 - 5s - loss: 0.0336 - val_loss: 0.0524

Epoch 9/50

 - 5s - loss: 0.0273 - val_loss: 0.0557

Epoch 10/50

 - 6s - loss: 0.0291 - val_loss: 0.0525

Epoch 11/50

 - 6s - loss: 0.0197 - val_loss: 0.0552

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 802, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 789, after forget

time = 27996	action = 0	current_phase = 1	next_phase = 0	reward = -0.494503	array([[-2.099519 , -3.1650186]], dtype=float32)

time = 28001	action = 0	current_phase = 1	next_phase = 0	reward = -0.330760	array([[-1.9995742, -3.0349598]], dtype=float32)

time = 28006	action = 0	current_phase = 1	next_phase = 0	reward = -0.186051	array([[-2.1667912, -3.0427148]], dtype=float32)

time = 28011	action = 0	current_phase = 1	next_phase = 0	reward = 0.318071	array([[-2.345438 , -3.7008758]], dtype=float32)

time = 28016	action = 1	current_phase = 1	next_phase = 0	reward = -1.607463	array([[-5.040187 , -3.2618804]], dtype=float32)

time = 28024	action = 0	current_phase = 0	next_phase = 1	reward = -0.554806	array([[-2.2068784, -2.7340603]], dtype=float32)

time = 28029	action = 0	current_phase = 0	next_phase = 1	reward = -0.400685	array([[-2.0460021, -2.587684 ]], dtype=float32)

time = 28034	action = 0	current_phase = 0	next_phase = 1	reward = -0.246683	array([[-1.9790381, -3.1804495]], dtype=float32)

time = 28039	action = 0	current_phase = 0	next_phase = 1	reward = -0.181327	array([[-2.097668 , -3.2286801]], dtype=float32)

time = 28044	action = 1	current_phase = 0	next_phase = 1	reward = -0.558368	array([[-3.3294415, -2.2399035]], dtype=float32)

time = 28052	action = 0	current_phase = 1	next_phase = 0	reward = -0.623795	array([[-2.2099042, -2.9149058]], dtype=float32)

time = 28057	action = 0	current_phase = 1	next_phase = 0	reward = -0.466443	array([[-2.2115352, -3.1409485]], dtype=float32)

time = 28062	action = 0	current_phase = 1	next_phase = 0	reward = -0.312391	array([[-2.0524766, -2.988402 ]], dtype=float32)

time = 28067	action = 0	current_phase = 1	next_phase = 0	reward = -0.180193	array([[-2.2967288, -2.9595113]], dtype=float32)

time = 28072	action = 0	current_phase = 1	next_phase = 0	reward = 0.200108	array([[-2.524644 , -3.7235518]], dtype=float32)

time = 28077	action = 1	current_phase = 1	next_phase = 0	reward = -1.783008	array([[-5.4717326, -3.5612302]], dtype=float32)

time = 28085	action = 0	current_phase = 0	next_phase = 1	reward = -0.532568	array([[-2.2346275, -3.0501077]], dtype=float32)

time = 28090	action = 0	current_phase = 0	next_phase = 1	reward = -0.382017	array([[-2.0414536, -2.5897536]], dtype=float32)

time = 28095	action = 0	current_phase = 0	next_phase = 1	reward = -0.235087	array([[-1.9789878, -3.1798224]], dtype=float32)

time = 28100	action = 0	current_phase = 0	next_phase = 1	reward = 0.054283	array([[-1.9682138, -3.6041753]], dtype=float32)

time = 28105	action = 1	current_phase = 0	next_phase = 1	reward = -1.086125	array([[-3.708716 , -2.4877167]], dtype=float32)

time = 28113	action = 0	current_phase = 1	next_phase = 0	reward = -0.592915	array([[-2.235388 , -2.9047673]], dtype=float32)

time = 28118	action = 0	current_phase = 1	next_phase = 0	reward = -0.430533	array([[-2.1527677, -2.935477 ]], dtype=float32)

time = 28123	action = 0	current_phase = 1	next_phase = 0	reward = -0.267179	array([[-2.1494973, -2.9343748]], dtype=float32)

time = 28128	action = 0	current_phase = 1	next_phase = 0	reward = -0.158472	array([[-2.3011353, -3.0791733]], dtype=float32)

time = 28133	action = 0	current_phase = 1	next_phase = 0	reward = -0.031468	array([[-2.5937743, -3.6194403]], dtype=float32)

time = 28138	action = 1	current_phase = 1	next_phase = 0	reward = -1.902532	array([[-5.3639674, -3.604502 ]], dtype=float32)

time = 28146	action = 0	current_phase = 0	next_phase = 1	reward = -0.501599	array([[-2.1536274, -2.825677 ]], dtype=float32)

time = 28151	action = 0	current_phase = 0	next_phase = 1	reward = -0.347518	array([[-2.0314734, -2.6496515]], dtype=float32)

time = 28156	action = 0	current_phase = 0	next_phase = 1	reward = -0.195864	array([[-2.024429 , -3.0828323]], dtype=float32)

time = 28161	action = 0	current_phase = 0	next_phase = 1	reward = 0.301715	array([[-2.3417568, -3.7064257]], dtype=float32)

time = 28166	action = 1	current_phase = 0	next_phase = 1	reward = -1.551187	array([[-4.0819535, -3.1740031]], dtype=float32)

time = 28174	action = 0	current_phase = 1	next_phase = 0	reward = -0.542509	array([[-2.1107473, -2.8635967]], dtype=float32)

time = 28179	action = 0	current_phase = 1	next_phase = 0	reward = -0.380015	array([[-1.9416306, -3.0785093]], dtype=float32)

time = 28184	action = 0	current_phase = 1	next_phase = 0	reward = -0.225613	array([[-1.869005 , -2.9871125]], dtype=float32)

time = 28189	action = 0	current_phase = 1	next_phase = 0	reward = -0.184379	array([[-2.1187842, -3.4753335]], dtype=float32)

time = 28194	action = 1	current_phase = 1	next_phase = 0	reward = -0.544480	array([[-2.5808823, -2.434019 ]], dtype=float32)

time = 28202	action = 0	current_phase = 0	next_phase = 1	reward = -0.620124	array([[-2.2889187, -2.8192058]], dtype=float32)

time = 28207	action = 0	current_phase = 0	next_phase = 1	reward = -0.459520	array([[-2.0587268, -2.6028485]], dtype=float32)

time = 28212	action = 0	current_phase = 0	next_phase = 1	reward = -0.295310	array([[-2.0001369, -3.1409686]], dtype=float32)

time = 28217	action = 0	current_phase = 0	next_phase = 1	reward = -0.163695	array([[-2.4512177, -2.811308 ]], dtype=float32)

time = 28222	action = 0	current_phase = 0	next_phase = 1	reward = 0.130673	array([[-2.8307042, -4.0744615]], dtype=float32)

time = 28227	action = 1	current_phase = 0	next_phase = 1	reward = -1.781190	array([[-5.764744 , -3.5441606]], dtype=float32)

time = 28235	action = 0	current_phase = 1	next_phase = 0	reward = -0.507305	array([[-2.0872712, -2.9121473]], dtype=float32)

time = 28240	action = 0	current_phase = 1	next_phase = 0	reward = -0.333624	array([[-1.9423206, -3.0772247]], dtype=float32)

time = 28245	action = 0	current_phase = 1	next_phase = 0	reward = -0.186394	array([[-1.9175503, -3.028457 ]], dtype=float32)

time = 28250	action = 0	current_phase = 1	next_phase = 0	reward = 0.342797	array([[-2.2962365, -3.564548 ]], dtype=float32)

time = 28255	action = 1	current_phase = 1	next_phase = 0	reward = -1.319542	array([[-4.7409477, -3.214498 ]], dtype=float32)

time = 28263	action = 0	current_phase = 0	next_phase = 1	reward = -0.581666	array([[-2.2864223, -2.8115623]], dtype=float32)

time = 28268	action = 0	current_phase = 0	next_phase = 1	reward = -0.434455	array([[-2.0423524, -2.6130962]], dtype=float32)

time = 28273	action = 0	current_phase = 0	next_phase = 1	reward = -0.271911	array([[-2.4245286, -3.2302604]], dtype=float32)

time = 28278	action = 0	current_phase = 0	next_phase = 1	reward = -0.162667	array([[-2.281645 , -2.7936945]], dtype=float32)

time = 28283	action = 0	current_phase = 0	next_phase = 1	reward = -0.001232	array([[-2.8320918, -3.9792686]], dtype=float32)

time = 28288	action = 1	current_phase = 0	next_phase = 1	reward = -1.893746	array([[-5.7480927, -3.5349298]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0862 - val_loss: 0.1200

Epoch 2/50

 - 4s - loss: 0.0803 - val_loss: 0.1144

Epoch 3/50

 - 5s - loss: 0.0457 - val_loss: 0.1052

Epoch 4/50

 - 5s - loss: 0.0629 - val_loss: 0.1029

Epoch 5/50

 - 6s - loss: 0.0423 - val_loss: 0.1090

Epoch 6/50

 - 5s - loss: 0.0707 - val_loss: 0.1142

Epoch 7/50

 - 5s - loss: 0.0398 - val_loss: 0.1134

Epoch 8/50

 - 5s - loss: 0.0435 - val_loss: 0.1308

Epoch 9/50

 - 5s - loss: 0.0423 - val_loss: 0.1379

Epoch 10/50

 - 5s - loss: 0.0492 - val_loss: 0.1407

Epoch 11/50

 - 4s - loss: 0.0421 - val_loss: 0.1358

Epoch 12/50

 - 4s - loss: 0.0364 - val_loss: 0.1339

Epoch 13/50

 - 5s - loss: 0.0762 - val_loss: 0.1376

Epoch 14/50

 - 4s - loss: 0.0677 - val_loss: 0.1401

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 807, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 794, after forget

time = 28296	action = 0	current_phase = 1	next_phase = 0	reward = -0.488620	array([[-2.2049382, -3.1510856]], dtype=float32)

time = 28301	action = 0	current_phase = 1	next_phase = 0	reward = -0.336593	array([[-2.1197925, -2.9596927]], dtype=float32)

time = 28306	action = 0	current_phase = 1	next_phase = 0	reward = -0.184226	array([[-2.347361 , -2.9881186]], dtype=float32)

time = 28311	action = 0	current_phase = 1	next_phase = 0	reward = 0.305526	array([[-2.5097046, -3.725487 ]], dtype=float32)

time = 28316	action = 1	current_phase = 1	next_phase = 0	reward = -1.605553	array([[-5.268889 , -3.4029033]], dtype=float32)

time = 28324	action = 0	current_phase = 0	next_phase = 1	reward = -0.549998	array([[-2.195351, -2.657146]], dtype=float32)

time = 28329	action = 0	current_phase = 0	next_phase = 1	reward = -0.402168	array([[-2.0487983, -2.5375147]], dtype=float32)

time = 28334	action = 0	current_phase = 0	next_phase = 1	reward = -0.248100	array([[-2.0147054, -3.1218517]], dtype=float32)

time = 28339	action = 0	current_phase = 0	next_phase = 1	reward = -0.178604	array([[-1.9813058, -3.4588437]], dtype=float32)

time = 28344	action = 1	current_phase = 0	next_phase = 1	reward = -0.601478	array([[-3.40431  , -2.0825589]], dtype=float32)

time = 28352	action = 0	current_phase = 1	next_phase = 0	reward = -0.622619	array([[-2.2292206, -2.918471 ]], dtype=float32)

time = 28357	action = 0	current_phase = 1	next_phase = 0	reward = -0.471001	array([[-2.175071 , -3.1828322]], dtype=float32)

time = 28362	action = 0	current_phase = 1	next_phase = 0	reward = -0.326180	array([[-2.1369507, -2.9499261]], dtype=float32)

time = 28367	action = 0	current_phase = 1	next_phase = 0	reward = -0.185286	array([[-2.321034 , -3.0186064]], dtype=float32)

time = 28372	action = 0	current_phase = 1	next_phase = 0	reward = 0.210113	array([[-2.5756054, -3.6507597]], dtype=float32)

time = 28377	action = 1	current_phase = 1	next_phase = 0	reward = -1.732909	array([[-5.5061436, -3.5790896]], dtype=float32)

time = 28385	action = 0	current_phase = 0	next_phase = 1	reward = -0.526287	array([[-2.1717322, -2.91473  ]], dtype=float32)

time = 28390	action = 0	current_phase = 0	next_phase = 1	reward = -0.380237	array([[-2.0476367, -2.549069 ]], dtype=float32)

time = 28395	action = 0	current_phase = 0	next_phase = 1	reward = -0.225803	array([[-2.0133998, -3.117106 ]], dtype=float32)

time = 28400	action = 0	current_phase = 0	next_phase = 1	reward = 0.367934	array([[-2.0820513, -3.167232 ]], dtype=float32)

time = 28405	action = 1	current_phase = 0	next_phase = 1	reward = -1.249234	array([[-3.9801965, -2.9356408]], dtype=float32)

time = 28413	action = 0	current_phase = 1	next_phase = 0	reward = -0.578614	array([[-2.205545 , -2.9185855]], dtype=float32)

time = 28418	action = 0	current_phase = 1	next_phase = 0	reward = -0.426532	array([[-2.0814826, -2.9817536]], dtype=float32)

time = 28423	action = 0	current_phase = 1	next_phase = 0	reward = -0.278963	array([[-2.1373086, -2.9418626]], dtype=float32)

time = 28428	action = 0	current_phase = 1	next_phase = 0	reward = -0.161443	array([[-2.3602848, -3.015322 ]], dtype=float32)

time = 28433	action = 1	current_phase = 1	next_phase = 0	reward = -0.252510	array([[-2.7460785, -2.5185328]], dtype=float32)

time = 28441	action = 0	current_phase = 0	next_phase = 1	reward = -0.654838	array([[-2.253464, -2.777277]], dtype=float32)

time = 28446	action = 0	current_phase = 0	next_phase = 1	reward = -0.494545	array([[-2.3014643, -2.741286 ]], dtype=float32)

time = 28451	action = 0	current_phase = 0	next_phase = 1	reward = -0.352454	array([[-2.0236032, -2.8461316]], dtype=float32)

time = 28456	action = 0	current_phase = 0	next_phase = 1	reward = -0.216637	array([[-1.9985604, -3.0166056]], dtype=float32)

time = 28461	action = 0	current_phase = 0	next_phase = 1	reward = 0.310241	array([[-2.3811479, -3.5755584]], dtype=float32)

time = 28466	action = 1	current_phase = 0	next_phase = 1	reward = -1.606156	array([[-4.647538 , -3.1407964]], dtype=float32)

time = 28474	action = 0	current_phase = 1	next_phase = 0	reward = -0.559566	array([[-2.005474 , -2.8319187]], dtype=float32)

time = 28479	action = 0	current_phase = 1	next_phase = 0	reward = -0.418234	array([[-1.9348634, -3.069975 ]], dtype=float32)

time = 28484	action = 0	current_phase = 1	next_phase = 0	reward = -0.261238	array([[-1.9219713, -3.0623934]], dtype=float32)

time = 28489	action = 0	current_phase = 1	next_phase = 0	reward = -0.175145	array([[-2.0474048, -3.4104493]], dtype=float32)

time = 28494	action = 1	current_phase = 1	next_phase = 0	reward = -0.541927	array([[-2.705122 , -2.3535376]], dtype=float32)

time = 28502	action = 0	current_phase = 0	next_phase = 1	reward = -0.619686	array([[-2.3174932, -2.804579 ]], dtype=float32)

time = 28507	action = 0	current_phase = 0	next_phase = 1	reward = -0.467256	array([[-2.0825267, -2.5522933]], dtype=float32)

time = 28512	action = 0	current_phase = 0	next_phase = 1	reward = -0.320337	array([[-2.0841272, -2.94279  ]], dtype=float32)

time = 28517	action = 0	current_phase = 0	next_phase = 1	reward = -0.183243	array([[-2.233018 , -2.6922982]], dtype=float32)

time = 28522	action = 0	current_phase = 0	next_phase = 1	reward = 0.270421	array([[-2.5977728, -4.1178055]], dtype=float32)

time = 28527	action = 1	current_phase = 0	next_phase = 1	reward = -1.623765	array([[-5.28105  , -3.3452544]], dtype=float32)

time = 28535	action = 0	current_phase = 1	next_phase = 0	reward = -0.525076	array([[-2.0505118, -2.9602928]], dtype=float32)

time = 28540	action = 0	current_phase = 1	next_phase = 0	reward = -0.358494	array([[-1.9311165, -3.0690315]], dtype=float32)

time = 28545	action = 0	current_phase = 1	next_phase = 0	reward = -0.203854	array([[-1.8644508, -3.0154395]], dtype=float32)

time = 28550	action = 0	current_phase = 1	next_phase = 0	reward = 0.357016	array([[-2.1422825, -3.5053368]], dtype=float32)

time = 28555	action = 1	current_phase = 1	next_phase = 0	reward = -1.312215	array([[-3.9886885, -3.088605 ]], dtype=float32)

time = 28563	action = 0	current_phase = 0	next_phase = 1	reward = -0.582603	array([[-2.2608864, -2.7423737]], dtype=float32)

time = 28568	action = 0	current_phase = 0	next_phase = 1	reward = -0.420421	array([[-2.0434382, -2.5979104]], dtype=float32)

time = 28573	action = 0	current_phase = 0	next_phase = 1	reward = -0.259583	array([[-2.1664093, -3.1383612]], dtype=float32)

time = 28578	action = 0	current_phase = 0	next_phase = 1	reward = -0.162287	array([[-2.3820796, -2.7334454]], dtype=float32)

time = 28583	action = 0	current_phase = 0	next_phase = 1	reward = 0.039155	array([[-2.9759119, -3.7857044]], dtype=float32)

time = 28588	action = 1	current_phase = 0	next_phase = 1	reward = -1.901135	array([[-5.7698917, -3.53155  ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0662 - val_loss: 0.0278

Epoch 2/50

 - 4s - loss: 0.0590 - val_loss: 0.0256

Epoch 3/50

 - 5s - loss: 0.0568 - val_loss: 0.0271

Epoch 4/50

 - 4s - loss: 0.0419 - val_loss: 0.0257

Epoch 5/50

 - 4s - loss: 0.0407 - val_loss: 0.0258

Epoch 6/50

 - 4s - loss: 0.0379 - val_loss: 0.0263

Epoch 7/50

 - 4s - loss: 0.0363 - val_loss: 0.0267

Epoch 8/50

 - 4s - loss: 0.0399 - val_loss: 0.0273

Epoch 9/50

 - 4s - loss: 0.0525 - val_loss: 0.0266

Epoch 10/50

 - 4s - loss: 0.0403 - val_loss: 0.0283

Epoch 11/50

 - 4s - loss: 0.0550 - val_loss: 0.0269

Epoch 12/50

 - 4s - loss: 0.0422 - val_loss: 0.0282

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 812, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 799, after forget

time = 28596	action = 0	current_phase = 1	next_phase = 0	reward = -0.502761	array([[-2.0922177, -3.17995  ]], dtype=float32)

time = 28601	action = 0	current_phase = 1	next_phase = 0	reward = -0.360676	array([[-2.054372 , -2.9946885]], dtype=float32)

time = 28606	action = 0	current_phase = 1	next_phase = 0	reward = -0.208521	array([[-2.0914726, -3.0880876]], dtype=float32)

time = 28611	action = 0	current_phase = 1	next_phase = 0	reward = 0.342257	array([[-2.297644 , -3.7188423]], dtype=float32)

time = 28616	action = 1	current_phase = 1	next_phase = 0	reward = -1.497749	array([[-5.0322385, -3.3015819]], dtype=float32)

time = 28624	action = 0	current_phase = 0	next_phase = 1	reward = -0.553118	array([[-2.180558, -2.647145]], dtype=float32)

time = 28629	action = 0	current_phase = 0	next_phase = 1	reward = -0.405127	array([[-2.0547063, -2.5510094]], dtype=float32)

time = 28634	action = 0	current_phase = 0	next_phase = 1	reward = -0.250887	array([[-2.04456  , -3.1294265]], dtype=float32)

time = 28639	action = 0	current_phase = 0	next_phase = 1	reward = -0.189674	array([[-2.0015175, -3.5437593]], dtype=float32)

time = 28644	action = 1	current_phase = 0	next_phase = 1	reward = -0.577472	array([[-3.3422287, -2.0216076]], dtype=float32)

time = 28652	action = 0	current_phase = 1	next_phase = 0	reward = -0.608898	array([[-2.1990352, -2.9376214]], dtype=float32)

time = 28657	action = 0	current_phase = 1	next_phase = 0	reward = -0.452592	array([[-2.1238253, -3.2206697]], dtype=float32)

time = 28662	action = 0	current_phase = 1	next_phase = 0	reward = -0.301969	array([[-2.1147912, -2.958797 ]], dtype=float32)

time = 28667	action = 0	current_phase = 1	next_phase = 0	reward = -0.173433	array([[-2.2611182, -3.0545933]], dtype=float32)

time = 28672	action = 0	current_phase = 1	next_phase = 0	reward = 0.180727	array([[-2.5212977, -3.7193506]], dtype=float32)

time = 28677	action = 1	current_phase = 1	next_phase = 0	reward = -1.779296	array([[-5.5098133, -3.6080818]], dtype=float32)

time = 28685	action = 0	current_phase = 0	next_phase = 1	reward = -0.521745	array([[-2.200212 , -2.9312737]], dtype=float32)

time = 28690	action = 0	current_phase = 0	next_phase = 1	reward = -0.373420	array([[-2.054591 , -2.5518181]], dtype=float32)

time = 28695	action = 0	current_phase = 0	next_phase = 1	reward = -0.220803	array([[-2.0437365, -3.1295319]], dtype=float32)

time = 28700	action = 0	current_phase = 0	next_phase = 1	reward = 0.356749	array([[-2.1102653, -3.1810102]], dtype=float32)

time = 28705	action = 1	current_phase = 0	next_phase = 1	reward = -1.308958	array([[-4.100302 , -2.9426756]], dtype=float32)

time = 28713	action = 0	current_phase = 1	next_phase = 0	reward = -0.584042	array([[-2.1619923, -2.9491725]], dtype=float32)

time = 28718	action = 0	current_phase = 1	next_phase = 0	reward = -0.420532	array([[-2.0560026, -2.9966471]], dtype=float32)

time = 28723	action = 0	current_phase = 1	next_phase = 0	reward = -0.259605	array([[-2.1076643, -2.9703524]], dtype=float32)

time = 28728	action = 0	current_phase = 1	next_phase = 0	reward = -0.159927	array([[-2.168205 , -3.0852323]], dtype=float32)

time = 28733	action = 1	current_phase = 1	next_phase = 0	reward = -0.267022	array([[-2.728247 , -2.6169274]], dtype=float32)

time = 28741	action = 0	current_phase = 0	next_phase = 1	reward = -0.641223	array([[-2.3360717, -2.8309236]], dtype=float32)

time = 28746	action = 0	current_phase = 0	next_phase = 1	reward = -0.480222	array([[-2.1368403, -2.6756842]], dtype=float32)

time = 28751	action = 0	current_phase = 0	next_phase = 1	reward = -0.326388	array([[-2.0665205, -2.646101 ]], dtype=float32)

time = 28756	action = 0	current_phase = 0	next_phase = 1	reward = -0.182894	array([[-2.2142735, -2.664559 ]], dtype=float32)

time = 28761	action = 0	current_phase = 0	next_phase = 1	reward = 0.265654	array([[-2.432362 , -3.7955203]], dtype=float32)

time = 28766	action = 1	current_phase = 0	next_phase = 1	reward = -1.667358	array([[-5.0958486, -3.3717465]], dtype=float32)

time = 28774	action = 0	current_phase = 1	next_phase = 0	reward = -0.564614	array([[-1.8247019, -2.7397695]], dtype=float32)

time = 28779	action = 0	current_phase = 1	next_phase = 0	reward = -0.405464	array([[-1.8929547, -3.0935385]], dtype=float32)

time = 28784	action = 0	current_phase = 1	next_phase = 0	reward = -0.254532	array([[-1.8430651, -3.045776 ]], dtype=float32)

time = 28789	action = 0	current_phase = 1	next_phase = 0	reward = -0.175240	array([[-2.052861 , -3.4691489]], dtype=float32)

time = 28794	action = 1	current_phase = 1	next_phase = 0	reward = -0.563219	array([[-2.6923318, -2.3864655]], dtype=float32)

time = 28802	action = 0	current_phase = 0	next_phase = 1	reward = -0.621308	array([[-2.3341496, -2.822892 ]], dtype=float32)

time = 28807	action = 0	current_phase = 0	next_phase = 1	reward = -0.468836	array([[-2.0826707, -2.6101995]], dtype=float32)

time = 28812	action = 0	current_phase = 0	next_phase = 1	reward = -0.313355	array([[-2.0600429, -3.1223843]], dtype=float32)

time = 28817	action = 0	current_phase = 0	next_phase = 1	reward = -0.179277	array([[-2.2326574, -2.6738527]], dtype=float32)

time = 28822	action = 0	current_phase = 0	next_phase = 1	reward = 0.257398	array([[-2.4879653, -4.1396885]], dtype=float32)

time = 28827	action = 1	current_phase = 0	next_phase = 1	reward = -1.730907	array([[-5.3157353, -3.3263931]], dtype=float32)

time = 28835	action = 0	current_phase = 1	next_phase = 0	reward = -0.530078	array([[-2.0102344, -2.9361155]], dtype=float32)

time = 28840	action = 0	current_phase = 1	next_phase = 0	reward = -0.367792	array([[-1.8933508, -3.0948796]], dtype=float32)

time = 28845	action = 0	current_phase = 1	next_phase = 0	reward = -0.215348	array([[-1.8864311, -3.0868645]], dtype=float32)

time = 28850	action = 0	current_phase = 1	next_phase = 0	reward = 0.363251	array([[-2.1705492, -3.5106604]], dtype=float32)

time = 28855	action = 1	current_phase = 1	next_phase = 0	reward = -1.309005	array([[-3.7673283, -2.8829725]], dtype=float32)

time = 28863	action = 0	current_phase = 0	next_phase = 1	reward = -0.594984	array([[-2.2804465, -2.7703915]], dtype=float32)

time = 28868	action = 0	current_phase = 0	next_phase = 1	reward = -0.439448	array([[-2.0555334, -2.5522058]], dtype=float32)

time = 28873	action = 0	current_phase = 0	next_phase = 1	reward = -0.290135	array([[-2.1485507, -3.1246698]], dtype=float32)

time = 28878	action = 0	current_phase = 0	next_phase = 1	reward = -0.164395	array([[-2.3323276, -2.752716 ]], dtype=float32)

time = 28883	action = 0	current_phase = 0	next_phase = 1	reward = -0.036277	array([[-2.8296556, -4.222845 ]], dtype=float32)

time = 28888	action = 1	current_phase = 0	next_phase = 1	reward = -1.904254	array([[-5.8431616, -3.527725 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0481 - val_loss: 0.0139

Epoch 2/50

 - 5s - loss: 0.0483 - val_loss: 0.0150

Epoch 3/50

 - 5s - loss: 0.0392 - val_loss: 0.0136

Epoch 4/50

 - 5s - loss: 0.0407 - val_loss: 0.0152

Epoch 5/50

 - 4s - loss: 0.0355 - val_loss: 0.0142

Epoch 6/50

 - 4s - loss: 0.0330 - val_loss: 0.0142

Epoch 7/50

 - 5s - loss: 0.0329 - val_loss: 0.0178

Epoch 8/50

 - 5s - loss: 0.0296 - val_loss: 0.0160

Epoch 9/50

 - 5s - loss: 0.0357 - val_loss: 0.0168

Epoch 10/50

 - 5s - loss: 0.0298 - val_loss: 0.0161

Epoch 11/50

 - 4s - loss: 0.0432 - val_loss: 0.0175

Epoch 12/50

 - 4s - loss: 0.0320 - val_loss: 0.0226

Epoch 13/50

 - 4s - loss: 0.0572 - val_loss: 0.0184

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 817, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 804, after forget

time = 28896	action = 0	current_phase = 1	next_phase = 0	reward = -0.494514	array([[-2.0322318, -3.116585 ]], dtype=float32)

time = 28901	action = 0	current_phase = 1	next_phase = 0	reward = -0.348081	array([[-2.002734, -3.026955]], dtype=float32)

time = 28906	action = 0	current_phase = 1	next_phase = 0	reward = -0.204540	array([[-2.1701107, -3.0419917]], dtype=float32)

time = 28911	action = 0	current_phase = 1	next_phase = 0	reward = 0.307950	array([[-2.5325692, -3.6813965]], dtype=float32)

time = 28916	action = 1	current_phase = 1	next_phase = 0	reward = -1.555512	array([[-5.1843653, -3.3124855]], dtype=float32)

time = 28924	action = 0	current_phase = 0	next_phase = 1	reward = -0.565339	array([[-2.2062361, -2.7416353]], dtype=float32)

time = 28929	action = 0	current_phase = 0	next_phase = 1	reward = -0.419196	array([[-2.069617 , -2.5937967]], dtype=float32)

time = 28934	action = 0	current_phase = 0	next_phase = 1	reward = -0.269079	array([[-2.0287585, -3.1516984]], dtype=float32)

time = 28939	action = 0	current_phase = 0	next_phase = 1	reward = -0.172390	array([[-2.0780835, -3.2934124]], dtype=float32)

time = 28944	action = 1	current_phase = 0	next_phase = 1	reward = -0.499466	array([[-3.4179742, -2.4124687]], dtype=float32)

time = 28952	action = 0	current_phase = 1	next_phase = 0	reward = -0.623222	array([[-2.3258991, -2.8965771]], dtype=float32)

time = 28957	action = 0	current_phase = 1	next_phase = 0	reward = -0.471591	array([[-2.1024418, -3.2227888]], dtype=float32)

time = 28962	action = 0	current_phase = 1	next_phase = 0	reward = -0.318137	array([[-2.1318507, -2.9590986]], dtype=float32)

time = 28967	action = 0	current_phase = 1	next_phase = 0	reward = -0.174706	array([[-2.3386843, -2.9800158]], dtype=float32)

time = 28972	action = 0	current_phase = 1	next_phase = 0	reward = 0.244096	array([[-2.8736405, -3.504563 ]], dtype=float32)

time = 28977	action = 1	current_phase = 1	next_phase = 0	reward = -1.727234	array([[-5.5289183, -3.5317137]], dtype=float32)

time = 28985	action = 0	current_phase = 0	next_phase = 1	reward = -0.530697	array([[-2.2013946, -3.0165079]], dtype=float32)

time = 28990	action = 0	current_phase = 0	next_phase = 1	reward = -0.375242	array([[-2.0678155, -2.606251 ]], dtype=float32)

time = 28995	action = 0	current_phase = 0	next_phase = 1	reward = -0.231503	array([[-2.0229263, -3.1499212]], dtype=float32)

time = 29000	action = 0	current_phase = 0	next_phase = 1	reward = 0.059590	array([[-1.9867165, -3.5304716]], dtype=float32)

time = 29005	action = 1	current_phase = 0	next_phase = 1	reward = -1.035301	array([[-3.8779624, -2.7894833]], dtype=float32)

time = 29013	action = 0	current_phase = 1	next_phase = 0	reward = -0.592904	array([[-2.2238302, -2.932596 ]], dtype=float32)

time = 29018	action = 0	current_phase = 1	next_phase = 0	reward = -0.444595	array([[-2.130585 , -2.9601548]], dtype=float32)

time = 29023	action = 0	current_phase = 1	next_phase = 0	reward = -0.289497	array([[-2.1124945, -2.9616497]], dtype=float32)

time = 29028	action = 0	current_phase = 1	next_phase = 0	reward = -0.166234	array([[-2.3565016, -2.970513 ]], dtype=float32)

time = 29033	action = 0	current_phase = 1	next_phase = 0	reward = 0.086371	array([[-2.9531422, -3.4278667]], dtype=float32)

time = 29038	action = 1	current_phase = 1	next_phase = 0	reward = -1.894294	array([[-5.4777184, -3.565666 ]], dtype=float32)

time = 29046	action = 0	current_phase = 0	next_phase = 1	reward = -0.491591	array([[-2.1772876, -2.9802406]], dtype=float32)

time = 29051	action = 0	current_phase = 0	next_phase = 1	reward = -0.333065	array([[-2.0716677, -2.5954833]], dtype=float32)

time = 29056	action = 0	current_phase = 0	next_phase = 1	reward = -0.193819	array([[-2.158508, -2.748738]], dtype=float32)

time = 29061	action = 0	current_phase = 0	next_phase = 1	reward = 0.312840	array([[-2.3003538, -3.8143725]], dtype=float32)

time = 29066	action = 1	current_phase = 0	next_phase = 1	reward = -1.613110	array([[-4.322288 , -3.2769814]], dtype=float32)

time = 29074	action = 0	current_phase = 1	next_phase = 0	reward = -0.564573	array([[-2.0848665, -2.8772526]], dtype=float32)

time = 29079	action = 0	current_phase = 1	next_phase = 0	reward = -0.411223	array([[-1.9032745, -3.0838478]], dtype=float32)

time = 29084	action = 0	current_phase = 1	next_phase = 0	reward = -0.258027	array([[-1.9015803, -3.0843034]], dtype=float32)

time = 29089	action = 0	current_phase = 1	next_phase = 0	reward = -0.174850	array([[-2.0737617, -3.4306142]], dtype=float32)

time = 29094	action = 1	current_phase = 1	next_phase = 0	reward = -0.541618	array([[-2.3963642, -2.3203063]], dtype=float32)

time = 29102	action = 0	current_phase = 0	next_phase = 1	reward = -0.615962	array([[-2.3313076, -2.8809338]], dtype=float32)

time = 29107	action = 0	current_phase = 0	next_phase = 1	reward = -0.457625	array([[-2.1183202, -2.63536  ]], dtype=float32)

time = 29112	action = 0	current_phase = 0	next_phase = 1	reward = -0.302945	array([[-2.039459 , -3.1359966]], dtype=float32)

time = 29117	action = 0	current_phase = 0	next_phase = 1	reward = -0.173325	array([[-2.3470461, -2.704903 ]], dtype=float32)

time = 29122	action = 0	current_phase = 0	next_phase = 1	reward = 0.159635	array([[-2.539022, -3.822698]], dtype=float32)

time = 29127	action = 1	current_phase = 0	next_phase = 1	reward = -1.779529	array([[-5.85535, -3.55806]], dtype=float32)

time = 29135	action = 0	current_phase = 1	next_phase = 0	reward = -0.518511	array([[-2.0605288, -2.950072 ]], dtype=float32)

time = 29140	action = 0	current_phase = 1	next_phase = 0	reward = -0.361846	array([[-1.9043489, -3.0820305]], dtype=float32)

time = 29145	action = 0	current_phase = 1	next_phase = 0	reward = -0.212456	array([[-1.9599366, -3.0736923]], dtype=float32)

time = 29150	action = 0	current_phase = 1	next_phase = 0	reward = 0.338248	array([[-2.067633 , -3.5562007]], dtype=float32)

time = 29155	action = 1	current_phase = 1	next_phase = 0	reward = -1.319476	array([[-4.00622  , -3.1133204]], dtype=float32)

time = 29163	action = 0	current_phase = 0	next_phase = 1	reward = -0.597785	array([[-2.2458134, -2.7922363]], dtype=float32)

time = 29168	action = 0	current_phase = 0	next_phase = 1	reward = -0.439149	array([[-2.0927873, -2.6183941]], dtype=float32)

time = 29173	action = 0	current_phase = 0	next_phase = 1	reward = -0.288123	array([[-2.1829863, -3.1774049]], dtype=float32)

time = 29178	action = 0	current_phase = 0	next_phase = 1	reward = -0.165625	array([[-2.3378751, -2.7442346]], dtype=float32)

time = 29183	action = 0	current_phase = 0	next_phase = 1	reward = 0.084677	array([[-2.7707934, -4.293691 ]], dtype=float32)

time = 29188	action = 1	current_phase = 0	next_phase = 1	reward = -1.894832	array([[-5.8183756, -3.535352 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 7s - loss: 0.0276 - val_loss: 0.0103

Epoch 2/50

 - 4s - loss: 0.0415 - val_loss: 0.0107

Epoch 3/50

 - 6s - loss: 0.0329 - val_loss: 0.0135

Epoch 4/50

 - 5s - loss: 0.0250 - val_loss: 0.0119

Epoch 5/50

 - 5s - loss: 0.0324 - val_loss: 0.0125

Epoch 6/50

 - 4s - loss: 0.0251 - val_loss: 0.0124

Epoch 7/50

 - 5s - loss: 0.0377 - val_loss: 0.0131

Epoch 8/50

 - 4s - loss: 0.0201 - val_loss: 0.0142

Epoch 9/50

 - 4s - loss: 0.0223 - val_loss: 0.0130

Epoch 10/50

 - 4s - loss: 0.0322 - val_loss: 0.0128

Epoch 11/50

 - 4s - loss: 0.0259 - val_loss: 0.0117

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 822, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 809, after forget

time = 29196	action = 0	current_phase = 1	next_phase = 0	reward = -0.492945	array([[-2.1918333, -3.2202952]], dtype=float32)

time = 29201	action = 0	current_phase = 1	next_phase = 0	reward = -0.335930	array([[-2.0251315, -3.0406208]], dtype=float32)

time = 29206	action = 0	current_phase = 1	next_phase = 0	reward = -0.196122	array([[-2.3604193, -2.9553437]], dtype=float32)

time = 29211	action = 0	current_phase = 1	next_phase = 0	reward = 0.295565	array([[-2.5235748, -3.7226467]], dtype=float32)

time = 29216	action = 1	current_phase = 1	next_phase = 0	reward = -1.504158	array([[-4.9953446, -3.3218417]], dtype=float32)

time = 29224	action = 0	current_phase = 0	next_phase = 1	reward = -0.555725	array([[-2.1675682, -2.7510633]], dtype=float32)

time = 29229	action = 0	current_phase = 0	next_phase = 1	reward = -0.405021	array([[-2.06338  , -2.6258173]], dtype=float32)

time = 29234	action = 0	current_phase = 0	next_phase = 1	reward = -0.255392	array([[-2.0106864, -3.1468897]], dtype=float32)

time = 29239	action = 0	current_phase = 0	next_phase = 1	reward = -0.175353	array([[-2.1694727, -3.151942 ]], dtype=float32)

time = 29244	action = 1	current_phase = 0	next_phase = 1	reward = -0.470810	array([[-3.3065753, -2.4646082]], dtype=float32)

time = 29252	action = 0	current_phase = 1	next_phase = 0	reward = -0.612728	array([[-2.541025 , -2.8247159]], dtype=float32)

time = 29257	action = 0	current_phase = 1	next_phase = 0	reward = -0.451191	array([[-2.2217174, -3.2171242]], dtype=float32)

time = 29262	action = 0	current_phase = 1	next_phase = 0	reward = -0.295490	array([[-2.1464708, -2.9627986]], dtype=float32)

time = 29267	action = 0	current_phase = 1	next_phase = 0	reward = -0.166610	array([[-2.2058046, -3.1065562]], dtype=float32)

time = 29272	action = 0	current_phase = 1	next_phase = 0	reward = 0.174651	array([[-2.4704962, -3.7127516]], dtype=float32)

time = 29277	action = 1	current_phase = 1	next_phase = 0	reward = -1.777986	array([[-5.5757346, -3.5856514]], dtype=float32)

time = 29285	action = 0	current_phase = 0	next_phase = 1	reward = -0.514808	array([[-2.146732 , -3.0172315]], dtype=float32)

time = 29290	action = 0	current_phase = 0	next_phase = 1	reward = -0.358479	array([[-2.063636, -2.622734]], dtype=float32)

time = 29295	action = 0	current_phase = 0	next_phase = 1	reward = -0.210337	array([[-2.0762455, -2.96312  ]], dtype=float32)

time = 29300	action = 0	current_phase = 0	next_phase = 1	reward = 0.335663	array([[-2.1759427, -3.2164495]], dtype=float32)

time = 29305	action = 1	current_phase = 0	next_phase = 1	reward = -1.320957	array([[-4.2251415, -3.1407943]], dtype=float32)

time = 29313	action = 0	current_phase = 1	next_phase = 0	reward = -0.583686	array([[-2.2269127, -2.9417598]], dtype=float32)

time = 29318	action = 0	current_phase = 1	next_phase = 0	reward = -0.424353	array([[-2.1339388, -2.970291 ]], dtype=float32)

time = 29323	action = 0	current_phase = 1	next_phase = 0	reward = -0.271937	array([[-2.1173544, -2.922547 ]], dtype=float32)

time = 29328	action = 0	current_phase = 1	next_phase = 0	reward = -0.165411	array([[-2.312413 , -3.0363224]], dtype=float32)

time = 29333	action = 1	current_phase = 1	next_phase = 0	reward = -1.017082	array([[-2.747646 , -2.6053357]], dtype=float32)

time = 29341	action = 1	current_phase = 0	next_phase = 1	reward = -2.022270	array([[-4.799581 , -3.4369607]], dtype=float32)

time = 29349	action = 0	current_phase = 1	next_phase = 0	reward = -0.404489	array([[-1.9203811, -3.1089008]], dtype=float32)

time = 29354	action = 0	current_phase = 1	next_phase = 0	reward = -0.246774	array([[-1.950507, -3.094878]], dtype=float32)

time = 29359	action = 0	current_phase = 1	next_phase = 0	reward = -0.177917	array([[-2.2468088, -3.4328632]], dtype=float32)

time = 29364	action = 0	current_phase = 1	next_phase = 0	reward = -0.142007	array([[-1.889522 , -2.3184042]], dtype=float32)

time = 29369	action = 1	current_phase = 1	next_phase = 0	reward = -2.009909	array([[-5.018659 , -3.7624218]], dtype=float32)

time = 29377	action = 0	current_phase = 0	next_phase = 1	reward = -0.470613	array([[-2.116981 , -2.8657541]], dtype=float32)

time = 29382	action = 0	current_phase = 0	next_phase = 1	reward = -0.319961	array([[-2.0521069, -2.6743736]], dtype=float32)

time = 29387	action = 0	current_phase = 0	next_phase = 1	reward = -0.175240	array([[-2.1927295, -2.6682196]], dtype=float32)

time = 29392	action = 0	current_phase = 0	next_phase = 1	reward = 0.193628	array([[-2.4038858, -3.5869377]], dtype=float32)

time = 29397	action = 1	current_phase = 0	next_phase = 1	reward = -1.780848	array([[-5.108608 , -3.5181968]], dtype=float32)

time = 29405	action = 0	current_phase = 1	next_phase = 0	reward = -0.528441	array([[-2.098679, -2.938599]], dtype=float32)

time = 29410	action = 0	current_phase = 1	next_phase = 0	reward = -0.378331	array([[-1.9520855, -3.0916069]], dtype=float32)

time = 29415	action = 0	current_phase = 1	next_phase = 0	reward = -0.224246	array([[-1.9468743, -3.0937188]], dtype=float32)

time = 29420	action = 0	current_phase = 1	next_phase = 0	reward = 0.358889	array([[-2.0380964, -3.4640777]], dtype=float32)

time = 29425	action = 1	current_phase = 1	next_phase = 0	reward = -1.309930	array([[-3.7979639, -2.9523494]], dtype=float32)

time = 29433	action = 0	current_phase = 0	next_phase = 1	reward = -0.586360	array([[-2.2189617, -2.819689 ]], dtype=float32)

time = 29438	action = 0	current_phase = 0	next_phase = 1	reward = -0.432562	array([[-2.063844 , -2.6243157]], dtype=float32)

time = 29443	action = 0	current_phase = 0	next_phase = 1	reward = -0.271132	array([[-2.139512 , -3.1648018]], dtype=float32)

time = 29448	action = 0	current_phase = 0	next_phase = 1	reward = -0.157211	array([[-2.3298123, -2.6986885]], dtype=float32)

time = 29453	action = 0	current_phase = 0	next_phase = 1	reward = 0.010140	array([[-2.831307, -4.139854]], dtype=float32)

time = 29458	action = 1	current_phase = 0	next_phase = 1	reward = -1.906104	array([[-5.9171486, -3.5600293]], dtype=float32)

time = 29466	action = 0	current_phase = 1	next_phase = 0	reward = -0.509445	array([[-2.1561317, -3.2060187]], dtype=float32)

time = 29471	action = 0	current_phase = 1	next_phase = 0	reward = -0.361089	array([[-1.9991629, -3.058245 ]], dtype=float32)

time = 29476	action = 0	current_phase = 1	next_phase = 0	reward = -0.213592	array([[-2.1927073, -3.0402327]], dtype=float32)

time = 29481	action = 0	current_phase = 1	next_phase = 0	reward = 0.343942	array([[-2.5249846, -3.741866 ]], dtype=float32)

time = 29486	action = 1	current_phase = 1	next_phase = 0	reward = -1.445117	array([[-4.499057 , -3.1784124]], dtype=float32)

time = 29494	action = 0	current_phase = 0	next_phase = 1	reward = -0.563629	array([[-2.1532156, -2.7324364]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0388 - val_loss: 0.0129

Epoch 2/50

 - 4s - loss: 0.0518 - val_loss: 0.0155

Epoch 3/50

 - 4s - loss: 0.0402 - val_loss: 0.0151

Epoch 4/50

 - 4s - loss: 0.0385 - val_loss: 0.0146

Epoch 5/50

 - 4s - loss: 0.0330 - val_loss: 0.0147

Epoch 6/50

 - 4s - loss: 0.0408 - val_loss: 0.0145

Epoch 7/50

 - 4s - loss: 0.0385 - val_loss: 0.0161

Epoch 8/50

 - 4s - loss: 0.0345 - val_loss: 0.0145

Epoch 9/50

 - 4s - loss: 0.0374 - val_loss: 0.0156

Epoch 10/50

 - 4s - loss: 0.0350 - val_loss: 0.0147

Epoch 11/50

 - 4s - loss: 0.0369 - val_loss: 0.0152

length of memory (state 0, action 0): 1018, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 827, after forget

length of memory (state 1, action 0): 1025, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 815, after forget

time = 29499	action = 0	current_phase = 0	next_phase = 1	reward = -0.409281	array([[-2.059504, -2.611904]], dtype=float32)

time = 29504	action = 0	current_phase = 0	next_phase = 1	reward = -0.258859	array([[-1.9800583, -3.108566 ]], dtype=float32)

time = 29509	action = 0	current_phase = 0	next_phase = 1	reward = -0.172256	array([[-1.9915744, -3.2446873]], dtype=float32)

time = 29514	action = 1	current_phase = 0	next_phase = 1	reward = -0.433565	array([[-3.4727588, -2.3365812]], dtype=float32)

time = 29522	action = 0	current_phase = 1	next_phase = 0	reward = -0.616818	array([[-2.3576834, -2.8605146]], dtype=float32)

time = 29527	action = 0	current_phase = 1	next_phase = 0	reward = -0.462863	array([[-2.1799953, -3.2056105]], dtype=float32)

time = 29532	action = 0	current_phase = 1	next_phase = 0	reward = -0.295784	array([[-2.0887964, -2.936655 ]], dtype=float32)

time = 29537	action = 0	current_phase = 1	next_phase = 0	reward = -0.169034	array([[-2.3487396, -2.912277 ]], dtype=float32)

time = 29542	action = 0	current_phase = 1	next_phase = 0	reward = 0.176018	array([[-2.5173795, -3.7509043]], dtype=float32)

time = 29547	action = 1	current_phase = 1	next_phase = 0	reward = -1.782269	array([[-5.5187016, -3.5789042]], dtype=float32)

time = 29555	action = 0	current_phase = 0	next_phase = 1	reward = -0.524924	array([[-2.1654356, -3.0520136]], dtype=float32)

time = 29560	action = 0	current_phase = 0	next_phase = 1	reward = -0.375304	array([[-2.059423 , -2.6134386]], dtype=float32)

time = 29565	action = 0	current_phase = 0	next_phase = 1	reward = -0.227103	array([[-1.9796965, -3.107026 ]], dtype=float32)

time = 29570	action = 0	current_phase = 0	next_phase = 1	reward = 0.366408	array([[-1.9735081, -3.2898104]], dtype=float32)

time = 29575	action = 1	current_phase = 0	next_phase = 1	reward = -1.357815	array([[-4.255117 , -2.9845104]], dtype=float32)

time = 29583	action = 0	current_phase = 1	next_phase = 0	reward = -0.586388	array([[-2.1646554, -2.921282 ]], dtype=float32)

time = 29588	action = 0	current_phase = 1	next_phase = 0	reward = -0.443267	array([[-2.0990672, -2.94306  ]], dtype=float32)

time = 29593	action = 0	current_phase = 1	next_phase = 0	reward = -0.300726	array([[-2.1013916, -2.9186378]], dtype=float32)

time = 29598	action = 0	current_phase = 1	next_phase = 0	reward = -0.176197	array([[-2.3217368, -2.949771 ]], dtype=float32)

time = 29603	action = 0	current_phase = 1	next_phase = 0	reward = 0.150563	array([[-2.9091718, -3.5657444]], dtype=float32)

time = 29608	action = 1	current_phase = 1	next_phase = 0	reward = -1.891684	array([[-5.5362763, -3.5871985]], dtype=float32)

time = 29616	action = 0	current_phase = 0	next_phase = 1	reward = -0.497457	array([[-2.15891  , -2.9747295]], dtype=float32)

time = 29621	action = 0	current_phase = 0	next_phase = 1	reward = -0.346644	array([[-2.059551 , -2.6150591]], dtype=float32)

time = 29626	action = 0	current_phase = 0	next_phase = 1	reward = -0.201389	array([[-2.098309 , -2.7752635]], dtype=float32)

time = 29631	action = 0	current_phase = 0	next_phase = 1	reward = 0.296970	array([[-2.1843164, -3.4158783]], dtype=float32)

time = 29636	action = 1	current_phase = 0	next_phase = 1	reward = -1.612040	array([[-4.31034  , -3.1737146]], dtype=float32)

time = 29644	action = 0	current_phase = 1	next_phase = 0	reward = -0.557104	array([[-2.0333676, -2.8391354]], dtype=float32)

time = 29649	action = 0	current_phase = 1	next_phase = 0	reward = -0.408632	array([[-1.9107037, -3.0850146]], dtype=float32)

time = 29654	action = 0	current_phase = 1	next_phase = 0	reward = -0.257284	array([[-1.9232028, -3.0493593]], dtype=float32)

time = 29659	action = 0	current_phase = 1	next_phase = 0	reward = -0.169204	array([[-2.1230774, -3.4474106]], dtype=float32)

time = 29664	action = 1	current_phase = 1	next_phase = 0	reward = -0.407455	array([[-2.447484 , -2.2934744]], dtype=float32)

time = 29672	action = 0	current_phase = 0	next_phase = 1	reward = -0.618424	array([[-2.3044908, -2.9449947]], dtype=float32)

time = 29677	action = 0	current_phase = 0	next_phase = 1	reward = -0.456747	array([[-2.079187 , -2.6249053]], dtype=float32)

time = 29682	action = 0	current_phase = 0	next_phase = 1	reward = -0.296181	array([[-2.0476394, -2.909682 ]], dtype=float32)

time = 29687	action = 0	current_phase = 0	next_phase = 1	reward = -0.162687	array([[-2.154016, -2.623955]], dtype=float32)

time = 29692	action = 0	current_phase = 0	next_phase = 1	reward = 0.176551	array([[-2.5576901, -4.1176367]], dtype=float32)

time = 29697	action = 1	current_phase = 0	next_phase = 1	reward = -1.781560	array([[-5.91225  , -3.4241624]], dtype=float32)

time = 29705	action = 0	current_phase = 1	next_phase = 0	reward = -0.520053	array([[-2.0782304, -2.9456656]], dtype=float32)

time = 29710	action = 0	current_phase = 1	next_phase = 0	reward = -0.362164	array([[-1.9155172, -3.078365 ]], dtype=float32)

time = 29715	action = 0	current_phase = 1	next_phase = 0	reward = -0.209315	array([[-1.8734528, -3.059052 ]], dtype=float32)

time = 29720	action = 0	current_phase = 1	next_phase = 0	reward = 0.044376	array([[-2.058221 , -3.6182532]], dtype=float32)

time = 29725	action = 1	current_phase = 1	next_phase = 0	reward = -1.091378	array([[-3.6356354, -2.9614158]], dtype=float32)

time = 29733	action = 0	current_phase = 0	next_phase = 1	reward = -0.598731	array([[-2.2283535, -2.8327804]], dtype=float32)

time = 29738	action = 0	current_phase = 0	next_phase = 1	reward = -0.438302	array([[-2.05911  , -2.6129782]], dtype=float32)

time = 29743	action = 0	current_phase = 0	next_phase = 1	reward = -0.279136	array([[-2.0551496, -3.1167188]], dtype=float32)

time = 29748	action = 0	current_phase = 0	next_phase = 1	reward = -0.160196	array([[-2.3965373, -2.911249 ]], dtype=float32)

time = 29753	action = 0	current_phase = 0	next_phase = 1	reward = 0.069134	array([[-3.0159483, -4.264166 ]], dtype=float32)

time = 29758	action = 1	current_phase = 0	next_phase = 1	reward = -1.894063	array([[-5.870734, -3.54022 ]], dtype=float32)

time = 29766	action = 0	current_phase = 1	next_phase = 0	reward = -0.496382	array([[-2.0689154, -3.1289914]], dtype=float32)

time = 29771	action = 0	current_phase = 1	next_phase = 0	reward = -0.340585	array([[-2.0985646, -2.9419875]], dtype=float32)

time = 29776	action = 0	current_phase = 1	next_phase = 0	reward = -0.195042	array([[-1.9501705, -3.0747862]], dtype=float32)

time = 29781	action = 0	current_phase = 1	next_phase = 0	reward = 0.315756	array([[-2.4794865, -3.744672 ]], dtype=float32)

time = 29786	action = 1	current_phase = 1	next_phase = 0	reward = -1.604267	array([[-5.191908 , -3.2733707]], dtype=float32)

time = 29794	action = 0	current_phase = 0	next_phase = 1	reward = -0.550341	array([[-2.1674159, -2.7491324]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0502 - val_loss: 0.0089

Epoch 2/50

 - 4s - loss: 0.0379 - val_loss: 0.0091

Epoch 3/50

 - 4s - loss: 0.0387 - val_loss: 0.0087

Epoch 4/50

 - 4s - loss: 0.0457 - val_loss: 0.0094

Epoch 5/50

 - 4s - loss: 0.0427 - val_loss: 0.0096

Epoch 6/50

 - 5s - loss: 0.0329 - val_loss: 0.0091

Epoch 7/50

 - 4s - loss: 0.0385 - val_loss: 0.0111

Epoch 8/50

 - 5s - loss: 0.0359 - val_loss: 0.0100

Epoch 9/50

 - 4s - loss: 0.0500 - val_loss: 0.0115

Epoch 10/50

 - 4s - loss: 0.0364 - val_loss: 0.0106

Epoch 11/50

 - 5s - loss: 0.0377 - val_loss: 0.0110

Epoch 12/50

 - 4s - loss: 0.0317 - val_loss: 0.0114

Epoch 13/50

 - 5s - loss: 0.0360 - val_loss: 0.0117

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 832, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 820, after forget

time = 29799	action = 0	current_phase = 0	next_phase = 1	reward = -0.408230	array([[-2.0835605, -2.6057613]], dtype=float32)

time = 29804	action = 0	current_phase = 0	next_phase = 1	reward = -0.253937	array([[-1.9898093, -3.0555334]], dtype=float32)

time = 29809	action = 0	current_phase = 0	next_phase = 1	reward = -0.173784	array([[-1.9452572, -3.4235187]], dtype=float32)

time = 29814	action = 1	current_phase = 0	next_phase = 1	reward = -0.429134	array([[-3.1616406, -2.1334517]], dtype=float32)

time = 29822	action = 0	current_phase = 1	next_phase = 0	reward = -0.615622	array([[-2.2914386, -2.837546 ]], dtype=float32)

time = 29827	action = 0	current_phase = 1	next_phase = 0	reward = -0.466157	array([[-2.1069682, -3.1951149]], dtype=float32)

time = 29832	action = 0	current_phase = 1	next_phase = 0	reward = -0.300578	array([[-2.0347662, -2.8857386]], dtype=float32)

time = 29837	action = 0	current_phase = 1	next_phase = 0	reward = -0.168843	array([[-2.2633557, -2.9781427]], dtype=float32)

time = 29842	action = 0	current_phase = 1	next_phase = 0	reward = 0.176645	array([[-2.5448084, -3.6000347]], dtype=float32)

time = 29847	action = 1	current_phase = 1	next_phase = 0	reward = -1.782083	array([[-5.5480847, -3.611466 ]], dtype=float32)

time = 29855	action = 0	current_phase = 0	next_phase = 1	reward = -0.519350	array([[-2.1929426, -3.022735 ]], dtype=float32)

time = 29860	action = 0	current_phase = 0	next_phase = 1	reward = -0.359579	array([[-2.085747 , -2.5897706]], dtype=float32)

time = 29865	action = 0	current_phase = 0	next_phase = 1	reward = -0.205032	array([[-1.99498  , -3.0485716]], dtype=float32)

time = 29870	action = 0	current_phase = 0	next_phase = 1	reward = 0.345576	array([[-2.2183523, -3.2701435]], dtype=float32)

time = 29875	action = 1	current_phase = 0	next_phase = 1	reward = -1.263520	array([[-4.272495 , -3.1341488]], dtype=float32)

time = 29883	action = 0	current_phase = 1	next_phase = 0	reward = -0.590042	array([[-2.1347299, -2.8967497]], dtype=float32)

time = 29888	action = 0	current_phase = 1	next_phase = 0	reward = -0.434225	array([[-2.059734 , -2.9223464]], dtype=float32)

time = 29893	action = 0	current_phase = 1	next_phase = 0	reward = -0.279358	array([[-2.0615566, -2.9102988]], dtype=float32)

time = 29898	action = 0	current_phase = 1	next_phase = 0	reward = -0.160324	array([[-2.3035138, -2.9352698]], dtype=float32)

time = 29903	action = 0	current_phase = 1	next_phase = 0	reward = 0.125997	array([[-2.966814, -3.509474]], dtype=float32)

time = 29908	action = 1	current_phase = 1	next_phase = 0	reward = -1.907362	array([[-5.538912 , -3.6141183]], dtype=float32)

time = 29916	action = 0	current_phase = 0	next_phase = 1	reward = -0.514324	array([[-2.1547556, -3.030491 ]], dtype=float32)

time = 29921	action = 0	current_phase = 0	next_phase = 1	reward = -0.364420	array([[-2.0869813, -2.5896177]], dtype=float32)

time = 29926	action = 0	current_phase = 0	next_phase = 1	reward = -0.204039	array([[-2.1006656, -2.7360432]], dtype=float32)

time = 29931	action = 0	current_phase = 0	next_phase = 1	reward = 0.302107	array([[-2.085009 , -3.3421066]], dtype=float32)

time = 29936	action = 1	current_phase = 0	next_phase = 1	reward = -1.503441	array([[-4.223504 , -3.1895392]], dtype=float32)

time = 29944	action = 0	current_phase = 1	next_phase = 0	reward = -0.550626	array([[-2.0126672, -2.8477004]], dtype=float32)

time = 29949	action = 0	current_phase = 1	next_phase = 0	reward = -0.402537	array([[-1.8606751, -3.0792534]], dtype=float32)

time = 29954	action = 0	current_phase = 1	next_phase = 0	reward = -0.248081	array([[-1.8110867, -2.9551961]], dtype=float32)

time = 29959	action = 0	current_phase = 1	next_phase = 0	reward = -0.183850	array([[-1.9953706, -3.4842522]], dtype=float32)

time = 29964	action = 1	current_phase = 1	next_phase = 0	reward = -0.557459	array([[-2.485847 , -2.3165476]], dtype=float32)

time = 29972	action = 0	current_phase = 0	next_phase = 1	reward = -0.612136	array([[-2.3035636, -2.9194188]], dtype=float32)

time = 29977	action = 0	current_phase = 0	next_phase = 1	reward = -0.467959	array([[-2.1002505, -2.606116 ]], dtype=float32)

time = 29982	action = 0	current_phase = 0	next_phase = 1	reward = -0.315801	array([[-2.0836082, -2.7970455]], dtype=float32)

time = 29987	action = 0	current_phase = 0	next_phase = 1	reward = -0.176449	array([[-2.3151414, -2.5318525]], dtype=float32)

time = 29992	action = 0	current_phase = 0	next_phase = 1	reward = 0.126085	array([[-2.4228363, -4.060026 ]], dtype=float32)

time = 29997	action = 1	current_phase = 0	next_phase = 1	reward = -1.785054	array([[-6.019675 , -3.5210562]], dtype=float32)

time = 30005	action = 0	current_phase = 1	next_phase = 0	reward = -0.526934	array([[-1.988306 , -2.8796103]], dtype=float32)

time = 30010	action = 0	current_phase = 1	next_phase = 0	reward = -0.378933	array([[-1.8604248, -3.0793023]], dtype=float32)

time = 30015	action = 0	current_phase = 1	next_phase = 0	reward = -0.225507	array([[-1.8244622, -3.0581243]], dtype=float32)

time = 30020	action = 0	current_phase = 1	next_phase = 0	reward = 0.360397	array([[-2.0183578, -3.5683138]], dtype=float32)

time = 30025	action = 1	current_phase = 1	next_phase = 0	reward = -1.362522	array([[-3.9683092, -3.0744035]], dtype=float32)

time = 30033	action = 0	current_phase = 0	next_phase = 1	reward = -0.596941	array([[-2.2642841, -2.8273427]], dtype=float32)

time = 30038	action = 0	current_phase = 0	next_phase = 1	reward = -0.433772	array([[-2.1204035, -2.6297581]], dtype=float32)

time = 30043	action = 0	current_phase = 0	next_phase = 1	reward = -0.270684	array([[-2.109903 , -3.0748112]], dtype=float32)

time = 30048	action = 0	current_phase = 0	next_phase = 1	reward = -0.158748	array([[-2.2811   , -2.5177562]], dtype=float32)

time = 30053	action = 0	current_phase = 0	next_phase = 1	reward = 0.013575	array([[-2.8121629, -4.1777945]], dtype=float32)

time = 30058	action = 1	current_phase = 0	next_phase = 1	reward = -1.907617	array([[-5.945863 , -3.5633936]], dtype=float32)

time = 30066	action = 0	current_phase = 1	next_phase = 0	reward = -0.499766	array([[-1.9735308, -3.1099389]], dtype=float32)

time = 30071	action = 0	current_phase = 1	next_phase = 0	reward = -0.339330	array([[-2.054728 , -2.9238958]], dtype=float32)

time = 30076	action = 0	current_phase = 1	next_phase = 0	reward = -0.188254	array([[-2.1449687, -3.0367253]], dtype=float32)

time = 30081	action = 0	current_phase = 1	next_phase = 0	reward = 0.317824	array([[-2.4430645, -3.7465067]], dtype=float32)

time = 30086	action = 1	current_phase = 1	next_phase = 0	reward = -1.610096	array([[-5.1686783, -3.3614101]], dtype=float32)

time = 30094	action = 0	current_phase = 0	next_phase = 1	reward = -0.557101	array([[-2.1964533, -2.724979 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0467 - val_loss: 0.0105

Epoch 2/50

 - 4s - loss: 0.0317 - val_loss: 0.0108

Epoch 3/50

 - 4s - loss: 0.0354 - val_loss: 0.0110

Epoch 4/50

 - 4s - loss: 0.0291 - val_loss: 0.0110

Epoch 5/50

 - 4s - loss: 0.0287 - val_loss: 0.0106

Epoch 6/50

 - 5s - loss: 0.0370 - val_loss: 0.0125

Epoch 7/50

 - 4s - loss: 0.0334 - val_loss: 0.0118

Epoch 8/50

 - 4s - loss: 0.0291 - val_loss: 0.0129

Epoch 9/50

 - 5s - loss: 0.0258 - val_loss: 0.0122

Epoch 10/50

 - 6s - loss: 0.0324 - val_loss: 0.0115

Epoch 11/50

 - 4s - loss: 0.0221 - val_loss: 0.0125

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 837, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 825, after forget

time = 30099	action = 0	current_phase = 0	next_phase = 1	reward = -0.409991	array([[-2.0473366, -2.6244588]], dtype=float32)

time = 30104	action = 0	current_phase = 0	next_phase = 1	reward = -0.269681	array([[-1.9536196, -3.1193523]], dtype=float32)

time = 30109	action = 0	current_phase = 0	next_phase = 1	reward = -0.183628	array([[-1.8613077, -3.5556977]], dtype=float32)

time = 30114	action = 1	current_phase = 0	next_phase = 1	reward = -0.566387	array([[-3.406853 , -2.3101423]], dtype=float32)

time = 30122	action = 0	current_phase = 1	next_phase = 0	reward = -0.623307	array([[-2.353611 , -2.7798285]], dtype=float32)

time = 30127	action = 0	current_phase = 1	next_phase = 0	reward = -0.470888	array([[-2.102561 , -3.1595483]], dtype=float32)

time = 30132	action = 0	current_phase = 1	next_phase = 0	reward = -0.323414	array([[-2.1289747, -2.8788617]], dtype=float32)

time = 30137	action = 0	current_phase = 1	next_phase = 0	reward = -0.186122	array([[-2.3232152, -2.9334157]], dtype=float32)

time = 30142	action = 0	current_phase = 1	next_phase = 0	reward = 0.265496	array([[-2.5756106, -3.672955 ]], dtype=float32)

time = 30147	action = 1	current_phase = 1	next_phase = 0	reward = -1.787390	array([[-5.4215937, -3.549703 ]], dtype=float32)

time = 30155	action = 0	current_phase = 0	next_phase = 1	reward = -0.543005	array([[-2.128661, -2.978677]], dtype=float32)

time = 30160	action = 0	current_phase = 0	next_phase = 1	reward = -0.382555	array([[-2.0471418, -2.6250684]], dtype=float32)

time = 30165	action = 0	current_phase = 0	next_phase = 1	reward = -0.231001	array([[-1.9538262, -3.1195164]], dtype=float32)

time = 30170	action = 0	current_phase = 0	next_phase = 1	reward = 0.088636	array([[-1.999453, -3.058958]], dtype=float32)

time = 30175	action = 1	current_phase = 0	next_phase = 1	reward = -1.064755	array([[-3.844519, -2.920506]], dtype=float32)

time = 30183	action = 0	current_phase = 1	next_phase = 0	reward = -0.590656	array([[-2.231504, -2.839959]], dtype=float32)

time = 30188	action = 0	current_phase = 1	next_phase = 0	reward = -0.439171	array([[-2.0456657, -2.9352438]], dtype=float32)

time = 30193	action = 0	current_phase = 1	next_phase = 0	reward = -0.283599	array([[-2.1286054, -2.8787234]], dtype=float32)

time = 30198	action = 0	current_phase = 1	next_phase = 0	reward = -0.161662	array([[-2.3713088, -2.9234922]], dtype=float32)

time = 30203	action = 0	current_phase = 1	next_phase = 0	reward = 0.206131	array([[-2.9024978, -3.2675388]], dtype=float32)

time = 30208	action = 1	current_phase = 1	next_phase = 0	reward = -1.889200	array([[-5.4636154, -3.5171642]], dtype=float32)

time = 30216	action = 0	current_phase = 0	next_phase = 1	reward = -0.486472	array([[-2.0873587, -2.9027379]], dtype=float32)

time = 30221	action = 0	current_phase = 0	next_phase = 1	reward = -0.328440	array([[-2.0449865, -2.631129 ]], dtype=float32)

time = 30226	action = 0	current_phase = 0	next_phase = 1	reward = -0.188985	array([[-2.1276011, -2.636587 ]], dtype=float32)

time = 30231	action = 0	current_phase = 0	next_phase = 1	reward = 0.293942	array([[-2.208009 , -3.4765735]], dtype=float32)

time = 30236	action = 1	current_phase = 0	next_phase = 1	reward = -1.608952	array([[-4.2635307, -3.1152828]], dtype=float32)

time = 30244	action = 0	current_phase = 1	next_phase = 0	reward = -0.549434	array([[-2.0494635, -2.8021238]], dtype=float32)

time = 30249	action = 0	current_phase = 1	next_phase = 0	reward = -0.389154	array([[-1.9116497, -3.0282006]], dtype=float32)

time = 30254	action = 0	current_phase = 1	next_phase = 0	reward = -0.234297	array([[-1.8802019, -3.0179043]], dtype=float32)

time = 30259	action = 0	current_phase = 1	next_phase = 0	reward = -0.177641	array([[-1.9469883, -3.3766193]], dtype=float32)

time = 30264	action = 1	current_phase = 1	next_phase = 0	reward = -0.532218	array([[-2.5630527, -2.3154986]], dtype=float32)

time = 30272	action = 0	current_phase = 0	next_phase = 1	reward = -0.621820	array([[-2.271079 , -2.9527106]], dtype=float32)

time = 30277	action = 0	current_phase = 0	next_phase = 1	reward = -0.468172	array([[-2.0552518, -2.6343846]], dtype=float32)

time = 30282	action = 0	current_phase = 0	next_phase = 1	reward = -0.313881	array([[-1.9817823, -3.0406842]], dtype=float32)

time = 30287	action = 0	current_phase = 0	next_phase = 1	reward = -0.180694	array([[-2.1444259, -2.57014  ]], dtype=float32)

time = 30292	action = 0	current_phase = 0	next_phase = 1	reward = 0.248662	array([[-2.5853465, -4.1729345]], dtype=float32)

time = 30297	action = 1	current_phase = 0	next_phase = 1	reward = -1.721772	array([[-5.5580964, -3.305433 ]], dtype=float32)

time = 30305	action = 0	current_phase = 1	next_phase = 0	reward = -0.513570	array([[-2.038756, -2.847702]], dtype=float32)

time = 30310	action = 0	current_phase = 1	next_phase = 0	reward = -0.350716	array([[-1.902402, -3.034462]], dtype=float32)

time = 30315	action = 0	current_phase = 1	next_phase = 0	reward = -0.197478	array([[-1.8857585, -3.0240421]], dtype=float32)

time = 30320	action = 0	current_phase = 1	next_phase = 0	reward = 0.346230	array([[-2.049327 , -3.4043703]], dtype=float32)

time = 30325	action = 1	current_phase = 1	next_phase = 0	reward = -1.367018	array([[-4.2544966, -3.160698 ]], dtype=float32)

time = 30333	action = 0	current_phase = 0	next_phase = 1	reward = -0.588878	array([[-2.221973, -2.876742]], dtype=float32)

time = 30338	action = 0	current_phase = 0	next_phase = 1	reward = -0.445906	array([[-2.0076246, -2.785879 ]], dtype=float32)

time = 30343	action = 0	current_phase = 0	next_phase = 1	reward = -0.297778	array([[-2.0976653, -3.14118  ]], dtype=float32)

time = 30348	action = 0	current_phase = 0	next_phase = 1	reward = -0.169397	array([[-2.2257905, -2.5889127]], dtype=float32)

time = 30353	action = 0	current_phase = 0	next_phase = 1	reward = 0.010167	array([[-2.9185398, -4.0556912]], dtype=float32)

time = 30358	action = 1	current_phase = 0	next_phase = 1	reward = -1.887404	array([[-5.9656105, -3.5265634]], dtype=float32)

time = 30366	action = 0	current_phase = 1	next_phase = 0	reward = -0.486410	array([[-2.0369134, -3.0823357]], dtype=float32)

time = 30371	action = 0	current_phase = 1	next_phase = 0	reward = -0.341257	array([[-2.0263338, -2.9477553]], dtype=float32)

time = 30376	action = 0	current_phase = 1	next_phase = 0	reward = -0.193889	array([[-2.13217  , -3.0009954]], dtype=float32)

time = 30381	action = 0	current_phase = 1	next_phase = 0	reward = 0.311289	array([[-2.544988 , -3.6775913]], dtype=float32)

time = 30386	action = 1	current_phase = 1	next_phase = 0	reward = -1.559139	array([[-5.273402 , -3.3426962]], dtype=float32)

time = 30394	action = 0	current_phase = 0	next_phase = 1	reward = -0.565406	array([[-2.1444764, -2.7578459]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0480 - val_loss: 0.0145

Epoch 2/50

 - 4s - loss: 0.0502 - val_loss: 0.0143

Epoch 3/50

 - 4s - loss: 0.0534 - val_loss: 0.0141

Epoch 4/50

 - 5s - loss: 0.0507 - val_loss: 0.0137

Epoch 5/50

 - 4s - loss: 0.0472 - val_loss: 0.0149

Epoch 6/50

 - 4s - loss: 0.0557 - val_loss: 0.0149

Epoch 7/50

 - 4s - loss: 0.0413 - val_loss: 0.0145

Epoch 8/50

 - 4s - loss: 0.0431 - val_loss: 0.0159

Epoch 9/50

 - 4s - loss: 0.0436 - val_loss: 0.0155

Epoch 10/50

 - 4s - loss: 0.0489 - val_loss: 0.0154

Epoch 11/50

 - 4s - loss: 0.0477 - val_loss: 0.0164

Epoch 12/50

 - 4s - loss: 0.0522 - val_loss: 0.0161

Epoch 13/50

 - 4s - loss: 0.0397 - val_loss: 0.0173

Epoch 14/50

 - 4s - loss: 0.0418 - val_loss: 0.0173

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 842, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 830, after forget

time = 30399	action = 0	current_phase = 0	next_phase = 1	reward = -0.416800	array([[-2.0352347, -2.6102972]], dtype=float32)

time = 30404	action = 0	current_phase = 0	next_phase = 1	reward = -0.264603	array([[-1.9180658, -3.0927315]], dtype=float32)

time = 30409	action = 0	current_phase = 0	next_phase = 1	reward = -0.177925	array([[-1.9772346, -3.5032623]], dtype=float32)

time = 30414	action = 1	current_phase = 0	next_phase = 1	reward = -0.586675	array([[-3.5520802, -2.252174 ]], dtype=float32)

time = 30422	action = 0	current_phase = 1	next_phase = 0	reward = -0.612889	array([[-2.3223228, -2.7908354]], dtype=float32)

time = 30427	action = 0	current_phase = 1	next_phase = 0	reward = -0.454927	array([[-2.157567, -3.156975]], dtype=float32)

time = 30432	action = 0	current_phase = 1	next_phase = 0	reward = -0.301896	array([[-2.132882 , -2.8660488]], dtype=float32)

time = 30437	action = 0	current_phase = 1	next_phase = 0	reward = -0.176604	array([[-2.3775458, -2.900764 ]], dtype=float32)

time = 30442	action = 0	current_phase = 1	next_phase = 0	reward = 0.176057	array([[-2.8458223, -3.4868917]], dtype=float32)

time = 30447	action = 1	current_phase = 1	next_phase = 0	reward = -1.788380	array([[-5.5094466, -3.551957 ]], dtype=float32)

time = 30455	action = 0	current_phase = 0	next_phase = 1	reward = -0.535540	array([[-2.1432807, -3.0186582]], dtype=float32)

time = 30460	action = 0	current_phase = 0	next_phase = 1	reward = -0.390850	array([[-2.030707 , -2.6172597]], dtype=float32)

time = 30465	action = 0	current_phase = 0	next_phase = 1	reward = -0.235294	array([[-1.9145656, -3.092246 ]], dtype=float32)

time = 30470	action = 0	current_phase = 0	next_phase = 1	reward = 0.079624	array([[-1.9677761, -2.8907719]], dtype=float32)

time = 30475	action = 1	current_phase = 0	next_phase = 1	reward = -1.024172	array([[-3.8197472, -2.6668463]], dtype=float32)

time = 30483	action = 0	current_phase = 1	next_phase = 0	reward = -0.591369	array([[-2.2745166, -2.8132029]], dtype=float32)

time = 30488	action = 0	current_phase = 1	next_phase = 0	reward = -0.440772	array([[-2.1335797, -2.8676198]], dtype=float32)

time = 30493	action = 0	current_phase = 1	next_phase = 0	reward = -0.283808	array([[-2.1280267, -2.8782465]], dtype=float32)

time = 30498	action = 0	current_phase = 1	next_phase = 0	reward = -0.164527	array([[-2.3532782, -3.0698931]], dtype=float32)

time = 30503	action = 0	current_phase = 1	next_phase = 0	reward = 0.068817	array([[-2.7374535, -3.467107 ]], dtype=float32)

time = 30508	action = 1	current_phase = 1	next_phase = 0	reward = -1.896417	array([[-5.4825134, -3.569694 ]], dtype=float32)

time = 30516	action = 0	current_phase = 0	next_phase = 1	reward = -0.497565	array([[-2.1099548, -2.9227014]], dtype=float32)

time = 30521	action = 0	current_phase = 0	next_phase = 1	reward = -0.350284	array([[-2.0351202, -2.6225286]], dtype=float32)

time = 30526	action = 0	current_phase = 0	next_phase = 1	reward = -0.198013	array([[-1.9916723, -2.7857401]], dtype=float32)

time = 30531	action = 0	current_phase = 0	next_phase = 1	reward = 0.311724	array([[-2.329261 , -3.4676595]], dtype=float32)

time = 30536	action = 1	current_phase = 0	next_phase = 1	reward = -1.562590	array([[-4.1823435, -3.1685047]], dtype=float32)

time = 30544	action = 0	current_phase = 1	next_phase = 0	reward = -0.567640	array([[-2.0499005, -2.7889714]], dtype=float32)

time = 30549	action = 0	current_phase = 1	next_phase = 0	reward = -0.406750	array([[-1.8908437, -3.0198164]], dtype=float32)

time = 30554	action = 0	current_phase = 1	next_phase = 0	reward = -0.248471	array([[-1.8509701, -2.9712172]], dtype=float32)

time = 30559	action = 0	current_phase = 1	next_phase = 0	reward = -0.166624	array([[-2.0652514, -3.3678532]], dtype=float32)

time = 30564	action = 1	current_phase = 1	next_phase = 0	reward = -0.431979	array([[-2.43684 , -2.223598]], dtype=float32)

time = 30572	action = 0	current_phase = 0	next_phase = 1	reward = -0.621683	array([[-2.2866557, -2.9640384]], dtype=float32)

time = 30577	action = 0	current_phase = 0	next_phase = 1	reward = -0.464938	array([[-2.0499685, -2.634327 ]], dtype=float32)

time = 30582	action = 0	current_phase = 0	next_phase = 1	reward = -0.314055	array([[-1.9287038, -3.0533092]], dtype=float32)

time = 30587	action = 0	current_phase = 0	next_phase = 1	reward = -0.182212	array([[-2.0696492, -2.5110946]], dtype=float32)

time = 30592	action = 0	current_phase = 0	next_phase = 1	reward = 0.270253	array([[-2.5422883, -4.052225 ]], dtype=float32)

time = 30597	action = 1	current_phase = 0	next_phase = 1	reward = -1.731812	array([[-5.6475773, -3.475037 ]], dtype=float32)

time = 30605	action = 0	current_phase = 1	next_phase = 0	reward = -0.535174	array([[-2.0616527, -2.8251853]], dtype=float32)

time = 30610	action = 0	current_phase = 1	next_phase = 0	reward = -0.383105	array([[-1.89043 , -3.020097]], dtype=float32)

time = 30615	action = 0	current_phase = 1	next_phase = 0	reward = -0.229681	array([[-1.8632662, -3.000482 ]], dtype=float32)

time = 30620	action = 0	current_phase = 1	next_phase = 0	reward = 0.377513	array([[-2.017616 , -3.4794626]], dtype=float32)

time = 30625	action = 1	current_phase = 1	next_phase = 0	reward = -1.299766	array([[-3.8488474, -3.0153267]], dtype=float32)

time = 30633	action = 0	current_phase = 0	next_phase = 1	reward = -0.590111	array([[-2.199568 , -2.8298993]], dtype=float32)

time = 30638	action = 0	current_phase = 0	next_phase = 1	reward = -0.434727	array([[-2.0107896, -2.676092 ]], dtype=float32)

time = 30643	action = 0	current_phase = 0	next_phase = 1	reward = -0.284558	array([[-1.9704888, -3.0999203]], dtype=float32)

time = 30648	action = 0	current_phase = 0	next_phase = 1	reward = -0.174416	array([[-2.263754 , -2.5677328]], dtype=float32)

time = 30653	action = 0	current_phase = 0	next_phase = 1	reward = -0.074222	array([[-2.8159735, -3.8236704]], dtype=float32)

time = 30658	action = 1	current_phase = 0	next_phase = 1	reward = -1.902299	array([[-5.990743, -3.493033]], dtype=float32)

time = 30666	action = 0	current_phase = 1	next_phase = 0	reward = -0.484016	array([[-2.1065154, -3.152145 ]], dtype=float32)

time = 30671	action = 0	current_phase = 1	next_phase = 0	reward = -0.327098	array([[-1.9050251, -3.010657 ]], dtype=float32)

time = 30676	action = 0	current_phase = 1	next_phase = 0	reward = -0.181469	array([[-2.2402434, -2.9410796]], dtype=float32)

time = 30681	action = 0	current_phase = 1	next_phase = 0	reward = 0.311684	array([[-2.406526, -3.663245]], dtype=float32)

time = 30686	action = 1	current_phase = 1	next_phase = 0	reward = -1.510520	array([[-5.2056537, -3.2494416]], dtype=float32)

time = 30694	action = 0	current_phase = 0	next_phase = 1	reward = -0.571451	array([[-2.1186213, -2.718628 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0539 - val_loss: 0.0088

Epoch 2/50

 - 5s - loss: 0.0500 - val_loss: 0.0092

Epoch 3/50

 - 4s - loss: 0.0497 - val_loss: 0.0091

Epoch 4/50

 - 4s - loss: 0.0494 - val_loss: 0.0096

Epoch 5/50

 - 4s - loss: 0.0517 - val_loss: 0.0095

Epoch 6/50

 - 4s - loss: 0.0429 - val_loss: 0.0088

Epoch 7/50

 - 4s - loss: 0.0656 - val_loss: 0.0103

Epoch 8/50

 - 4s - loss: 0.0711 - val_loss: 0.0130

Epoch 9/50

 - 4s - loss: 0.0394 - val_loss: 0.0111

Epoch 10/50

 - 4s - loss: 0.0485 - val_loss: 0.0098

Epoch 11/50

 - 4s - loss: 0.0437 - val_loss: 0.0101

Epoch 12/50

 - 4s - loss: 0.0521 - val_loss: 0.0104

Epoch 13/50

 - 4s - loss: 0.0422 - val_loss: 0.0116

Epoch 14/50

 - 4s - loss: 0.0463 - val_loss: 0.0127

Epoch 15/50

 - 4s - loss: 0.0500 - val_loss: 0.0145

Epoch 16/50

 - 5s - loss: 0.0580 - val_loss: 0.0118

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 847, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 835, after forget

time = 30699	action = 0	current_phase = 0	next_phase = 1	reward = -0.416515	array([[-2.0403948, -2.5659938]], dtype=float32)

time = 30704	action = 0	current_phase = 0	next_phase = 1	reward = -0.256887	array([[-1.9063724, -3.0624418]], dtype=float32)

time = 30709	action = 0	current_phase = 0	next_phase = 1	reward = -0.168388	array([[-1.7961046, -3.3962934]], dtype=float32)

time = 30714	action = 1	current_phase = 0	next_phase = 1	reward = -0.484705	array([[-3.370232 , -2.3955438]], dtype=float32)

time = 30722	action = 0	current_phase = 1	next_phase = 0	reward = -0.617989	array([[-2.358773 , -2.7666945]], dtype=float32)

time = 30727	action = 0	current_phase = 1	next_phase = 0	reward = -0.473108	array([[-2.171542 , -3.1637902]], dtype=float32)

time = 30732	action = 0	current_phase = 1	next_phase = 0	reward = -0.318389	array([[-2.1451554, -2.8577337]], dtype=float32)

time = 30737	action = 0	current_phase = 1	next_phase = 0	reward = -0.181869	array([[-2.33223  , -2.9551387]], dtype=float32)

time = 30742	action = 0	current_phase = 1	next_phase = 0	reward = 0.201729	array([[-2.4738345, -3.7740865]], dtype=float32)

time = 30747	action = 1	current_phase = 1	next_phase = 0	reward = -1.728348	array([[-5.4925995, -3.5419142]], dtype=float32)

time = 30755	action = 0	current_phase = 0	next_phase = 1	reward = -0.521072	array([[-2.1757898, -2.9466558]], dtype=float32)

time = 30760	action = 0	current_phase = 0	next_phase = 1	reward = -0.370111	array([[-2.0372944, -2.569346 ]], dtype=float32)

time = 30765	action = 0	current_phase = 0	next_phase = 1	reward = -0.217674	array([[-1.9066511, -3.0625806]], dtype=float32)

time = 30770	action = 0	current_phase = 0	next_phase = 1	reward = 0.355761	array([[-2.0050201, -2.862346 ]], dtype=float32)

time = 30775	action = 1	current_phase = 0	next_phase = 1	reward = -1.364836	array([[-4.147848 , -3.1066413]], dtype=float32)

time = 30783	action = 0	current_phase = 1	next_phase = 0	reward = -0.598439	array([[-2.2944055, -2.7998302]], dtype=float32)

time = 30788	action = 0	current_phase = 1	next_phase = 0	reward = -0.446320	array([[-2.1419067, -2.8624406]], dtype=float32)

time = 30793	action = 0	current_phase = 1	next_phase = 0	reward = -0.285618	array([[-2.1441827, -2.8573778]], dtype=float32)

time = 30798	action = 0	current_phase = 1	next_phase = 0	reward = -0.161729	array([[-2.3117487, -2.9433665]], dtype=float32)

time = 30803	action = 1	current_phase = 1	next_phase = 0	reward = -1.814366	array([[-2.7863748, -2.7225447]], dtype=float32)

time = 30811	action = 1	current_phase = 0	next_phase = 1	reward = -2.057773	array([[-4.104676, -3.691435]], dtype=float32)

time = 30819	action = 0	current_phase = 1	next_phase = 0	reward = -0.403301	array([[-1.9909374, -2.9244745]], dtype=float32)

time = 30824	action = 0	current_phase = 1	next_phase = 0	reward = -0.260777	array([[-1.9060405, -3.025795 ]], dtype=float32)

time = 30829	action = 0	current_phase = 1	next_phase = 0	reward = -0.168442	array([[-1.7531329, -3.1464975]], dtype=float32)

time = 30834	action = 0	current_phase = 1	next_phase = 0	reward = 0.042325	array([[-1.8917835, -2.270969 ]], dtype=float32)

time = 30839	action = 1	current_phase = 1	next_phase = 0	reward = -2.011410	array([[-4.89945  , -3.7658195]], dtype=float32)

time = 30847	action = 0	current_phase = 0	next_phase = 1	reward = -0.482593	array([[-2.1030645, -2.8518727]], dtype=float32)

time = 30852	action = 0	current_phase = 0	next_phase = 1	reward = -0.329964	array([[-1.9661363, -2.6799438]], dtype=float32)

time = 30857	action = 0	current_phase = 0	next_phase = 1	reward = -0.184624	array([[-2.0465062, -2.579489 ]], dtype=float32)

time = 30862	action = 0	current_phase = 0	next_phase = 1	reward = 0.218562	array([[-2.420237 , -3.3075264]], dtype=float32)

time = 30867	action = 1	current_phase = 0	next_phase = 1	reward = -1.781070	array([[-5.12486  , -3.4693894]], dtype=float32)

time = 30875	action = 0	current_phase = 1	next_phase = 0	reward = -0.529875	array([[-2.0685937, -2.808457 ]], dtype=float32)

time = 30880	action = 0	current_phase = 1	next_phase = 0	reward = -0.380184	array([[-1.9115747, -3.0208917]], dtype=float32)

time = 30885	action = 0	current_phase = 1	next_phase = 0	reward = -0.237028	array([[-1.7688202, -2.9372556]], dtype=float32)

time = 30890	action = 0	current_phase = 1	next_phase = 0	reward = 0.373088	array([[-1.9400758, -3.4132233]], dtype=float32)

time = 30895	action = 1	current_phase = 1	next_phase = 0	reward = -1.305742	array([[-3.9656396, -2.9215493]], dtype=float32)

time = 30903	action = 0	current_phase = 0	next_phase = 1	reward = -0.597755	array([[-2.3109388, -2.899992 ]], dtype=float32)

time = 30908	action = 0	current_phase = 0	next_phase = 1	reward = -0.447001	array([[-2.041305 , -2.5650322]], dtype=float32)

time = 30913	action = 0	current_phase = 0	next_phase = 1	reward = -0.300020	array([[-2.2942643, -3.1138337]], dtype=float32)

time = 30918	action = 0	current_phase = 0	next_phase = 1	reward = -0.171082	array([[-2.2585936, -2.4944723]], dtype=float32)

time = 30923	action = 0	current_phase = 0	next_phase = 1	reward = 0.007093	array([[-2.829638 , -3.9179442]], dtype=float32)

time = 30928	action = 1	current_phase = 0	next_phase = 1	reward = -1.904879	array([[-6.0184836, -3.493381 ]], dtype=float32)

time = 30936	action = 0	current_phase = 1	next_phase = 0	reward = -0.505460	array([[-2.130943, -3.145825]], dtype=float32)

time = 30941	action = 0	current_phase = 1	next_phase = 0	reward = -0.348833	array([[-2.1015754, -2.8874679]], dtype=float32)

time = 30946	action = 0	current_phase = 1	next_phase = 0	reward = -0.201276	array([[-2.18518  , -2.9664757]], dtype=float32)

time = 30951	action = 0	current_phase = 1	next_phase = 0	reward = 0.339628	array([[-2.1850028, -3.5390952]], dtype=float32)

time = 30956	action = 1	current_phase = 1	next_phase = 0	reward = -1.550598	array([[-4.3448753, -3.2084208]], dtype=float32)

time = 30964	action = 0	current_phase = 0	next_phase = 1	reward = -0.563443	array([[-2.2296538, -2.7927408]], dtype=float32)

time = 30969	action = 0	current_phase = 0	next_phase = 1	reward = -0.418284	array([[-2.040315 , -2.5658054]], dtype=float32)

time = 30974	action = 0	current_phase = 0	next_phase = 1	reward = -0.260933	array([[-1.9069005, -3.0626438]], dtype=float32)

time = 30979	action = 0	current_phase = 0	next_phase = 1	reward = -0.186884	array([[-2.0204105, -2.8962483]], dtype=float32)

time = 30984	action = 1	current_phase = 0	next_phase = 1	reward = -1.379165	array([[-3.1150603, -2.618126 ]], dtype=float32)

time = 30992	action = 1	current_phase = 1	next_phase = 0	reward = -1.958267	array([[-2.7072694, -2.671974 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0363 - val_loss: 0.0509

Epoch 2/50

 - 4s - loss: 0.0319 - val_loss: 0.0490

Epoch 3/50

 - 4s - loss: 0.0426 - val_loss: 0.0496

Epoch 4/50

 - 4s - loss: 0.0403 - val_loss: 0.0483

Epoch 5/50

 - 4s - loss: 0.0339 - val_loss: 0.0490

Epoch 6/50

 - 4s - loss: 0.0366 - val_loss: 0.0490

Epoch 7/50

 - 4s - loss: 0.0322 - val_loss: 0.0500

Epoch 8/50

 - 4s - loss: 0.0315 - val_loss: 0.0489

Epoch 9/50

 - 4s - loss: 0.0446 - val_loss: 0.0490

Epoch 10/50

 - 4s - loss: 0.0381 - val_loss: 0.0501

Epoch 11/50

 - 4s - loss: 0.0365 - val_loss: 0.0486

Epoch 12/50

 - 4s - loss: 0.0272 - val_loss: 0.0484

Epoch 13/50

 - 4s - loss: 0.0399 - val_loss: 0.0510

Epoch 14/50

 - 4s - loss: 0.0440 - val_loss: 0.0491

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 853, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 841, after forget

time = 31000	action = 0	current_phase = 0	next_phase = 1	reward = -0.359345	array([[-1.925082, -2.998443]], dtype=float32)

time = 31005	action = 0	current_phase = 0	next_phase = 1	reward = -0.197641	array([[-1.9186265, -3.0513604]], dtype=float32)

time = 31010	action = 0	current_phase = 0	next_phase = 1	reward = 0.337336	array([[-1.8119965, -3.464165 ]], dtype=float32)

time = 31015	action = 1	current_phase = 0	next_phase = 1	reward = -1.371517	array([[-2.7357898, -2.3867192]], dtype=float32)

time = 31023	action = 0	current_phase = 1	next_phase = 0	reward = -0.592469	array([[-2.0154731, -3.006954 ]], dtype=float32)

time = 31028	action = 0	current_phase = 1	next_phase = 0	reward = -0.434926	array([[-2.1776433, -2.885323 ]], dtype=float32)

time = 31033	action = 0	current_phase = 1	next_phase = 0	reward = -0.276654	array([[-2.1657722, -2.874181 ]], dtype=float32)

time = 31038	action = 0	current_phase = 1	next_phase = 0	reward = -0.164191	array([[-2.2181273, -3.036077 ]], dtype=float32)

time = 31043	action = 0	current_phase = 1	next_phase = 0	reward = -0.044871	array([[-2.9049494, -3.0242183]], dtype=float32)

time = 31048	action = 1	current_phase = 1	next_phase = 0	reward = -1.900470	array([[-5.5192885, -3.6002612]], dtype=float32)

time = 31056	action = 0	current_phase = 0	next_phase = 1	reward = -0.492430	array([[-2.195834 , -3.0023103]], dtype=float32)

time = 31061	action = 0	current_phase = 0	next_phase = 1	reward = -0.334437	array([[-2.0189755, -2.5595205]], dtype=float32)

time = 31066	action = 0	current_phase = 0	next_phase = 1	reward = -0.186299	array([[-2.0415714, -2.5710433]], dtype=float32)

time = 31071	action = 0	current_phase = 0	next_phase = 1	reward = 0.308385	array([[-2.3567197, -3.2758934]], dtype=float32)

time = 31076	action = 1	current_phase = 0	next_phase = 1	reward = -1.607540	array([[-4.280437 , -3.1131387]], dtype=float32)

time = 31084	action = 0	current_phase = 1	next_phase = 0	reward = -0.550459	array([[-2.0923083, -2.7806659]], dtype=float32)

time = 31089	action = 0	current_phase = 1	next_phase = 0	reward = -0.396315	array([[-1.9391911, -3.014424 ]], dtype=float32)

time = 31094	action = 0	current_phase = 1	next_phase = 0	reward = -0.248190	array([[-1.8203297, -2.938329 ]], dtype=float32)

time = 31099	action = 0	current_phase = 1	next_phase = 0	reward = -0.199394	array([[-2.0844023, -3.4821858]], dtype=float32)

time = 31104	action = 0	current_phase = 1	next_phase = 0	reward = -0.166164	array([[-2.4305995, -2.4935553]], dtype=float32)

time = 31109	action = 1	current_phase = 1	next_phase = 0	reward = -2.009625	array([[-5.505957 , -3.6015024]], dtype=float32)

time = 31117	action = 0	current_phase = 0	next_phase = 1	reward = -0.460939	array([[-2.0701444, -2.8393059]], dtype=float32)

time = 31122	action = 0	current_phase = 0	next_phase = 1	reward = -0.307559	array([[-2.0602267, -2.599655 ]], dtype=float32)

time = 31127	action = 0	current_phase = 0	next_phase = 1	reward = -0.173955	array([[-2.1381304, -2.5196083]], dtype=float32)

time = 31132	action = 0	current_phase = 0	next_phase = 1	reward = 0.103734	array([[-2.4669676, -3.8887103]], dtype=float32)

time = 31137	action = 1	current_phase = 0	next_phase = 1	reward = -1.785680	array([[-5.578001 , -3.4634008]], dtype=float32)

time = 31145	action = 0	current_phase = 1	next_phase = 0	reward = -0.516244	array([[-2.119145, -2.873524]], dtype=float32)

time = 31150	action = 0	current_phase = 1	next_phase = 0	reward = -0.353744	array([[-1.932219 , -3.0203989]], dtype=float32)

time = 31155	action = 0	current_phase = 1	next_phase = 0	reward = -0.202185	array([[-1.9230266, -3.0140743]], dtype=float32)

time = 31160	action = 0	current_phase = 1	next_phase = 0	reward = 0.348223	array([[-2.048053 , -3.5722048]], dtype=float32)

time = 31165	action = 1	current_phase = 1	next_phase = 0	reward = -1.419053	array([[-4.044946 , -3.0873184]], dtype=float32)

time = 31173	action = 0	current_phase = 0	next_phase = 1	reward = -0.588518	array([[-2.2407222, -2.831184 ]], dtype=float32)

time = 31178	action = 0	current_phase = 0	next_phase = 1	reward = -0.432219	array([[-2.020726 , -2.5508742]], dtype=float32)

time = 31183	action = 0	current_phase = 0	next_phase = 1	reward = -0.273546	array([[-2.0678704, -3.0648596]], dtype=float32)

time = 31188	action = 0	current_phase = 0	next_phase = 1	reward = -0.165011	array([[-2.2356026, -2.552419 ]], dtype=float32)

time = 31193	action = 0	current_phase = 0	next_phase = 1	reward = 0.088916	array([[-2.6310887, -3.8223798]], dtype=float32)

time = 31198	action = 1	current_phase = 0	next_phase = 1	reward = -1.890580	array([[-6.05113 , -3.490403]], dtype=float32)

time = 31206	action = 0	current_phase = 1	next_phase = 0	reward = -0.488825	array([[-2.1890163, -3.2013311]], dtype=float32)

time = 31211	action = 0	current_phase = 1	next_phase = 0	reward = -0.340551	array([[-2.1707947, -2.8677573]], dtype=float32)

time = 31216	action = 0	current_phase = 1	next_phase = 0	reward = -0.198712	array([[-2.3300552, -2.8951597]], dtype=float32)

time = 31221	action = 0	current_phase = 1	next_phase = 0	reward = 0.282936	array([[-2.5249114, -3.7393966]], dtype=float32)

time = 31226	action = 1	current_phase = 1	next_phase = 0	reward = -1.608435	array([[-5.2493677, -3.3026142]], dtype=float32)

time = 31234	action = 0	current_phase = 0	next_phase = 1	reward = -0.551690	array([[-2.163058 , -2.7244463]], dtype=float32)

time = 31239	action = 0	current_phase = 0	next_phase = 1	reward = -0.393949	array([[-2.0195067, -2.5522852]], dtype=float32)

time = 31244	action = 0	current_phase = 0	next_phase = 1	reward = -0.243419	array([[-1.9206111, -3.044373 ]], dtype=float32)

time = 31249	action = 0	current_phase = 0	next_phase = 1	reward = -0.184038	array([[-2.092159, -2.846484]], dtype=float32)

time = 31254	action = 1	current_phase = 0	next_phase = 1	reward = -0.550134	array([[-3.5780175, -2.2192032]], dtype=float32)

time = 31262	action = 0	current_phase = 1	next_phase = 0	reward = -0.616194	array([[-2.2670686, -2.848428 ]], dtype=float32)

time = 31267	action = 0	current_phase = 1	next_phase = 0	reward = -0.466000	array([[-2.1963224, -3.2073357]], dtype=float32)

time = 31272	action = 0	current_phase = 1	next_phase = 0	reward = -0.321100	array([[-2.1732442, -2.8662655]], dtype=float32)

time = 31277	action = 0	current_phase = 1	next_phase = 0	reward = -0.173052	array([[-2.3476334, -2.9553146]], dtype=float32)

time = 31282	action = 0	current_phase = 1	next_phase = 0	reward = 0.249442	array([[-2.661241, -3.702901]], dtype=float32)

time = 31287	action = 1	current_phase = 1	next_phase = 0	reward = -1.731820	array([[-5.5090437, -3.52641  ]], dtype=float32)

time = 31295	action = 0	current_phase = 0	next_phase = 1	reward = -0.534292	array([[-2.1473434, -2.9684541]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0454 - val_loss: 0.0148

Epoch 2/50

 - 4s - loss: 0.0465 - val_loss: 0.0153

Epoch 3/50

 - 4s - loss: 0.0628 - val_loss: 0.0174

Epoch 4/50

 - 4s - loss: 0.0413 - val_loss: 0.0180

Epoch 5/50

 - 4s - loss: 0.0465 - val_loss: 0.0168

Epoch 6/50

 - 4s - loss: 0.0602 - val_loss: 0.0176

Epoch 7/50

 - 4s - loss: 0.0450 - val_loss: 0.0177

Epoch 8/50

 - 4s - loss: 0.0448 - val_loss: 0.0179

Epoch 9/50

 - 4s - loss: 0.0417 - val_loss: 0.0186

Epoch 10/50

 - 4s - loss: 0.0413 - val_loss: 0.0189

Epoch 11/50

 - 4s - loss: 0.0423 - val_loss: 0.0169

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 858, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 846, after forget

time = 31300	action = 0	current_phase = 0	next_phase = 1	reward = -0.379117	array([[-2.000622 , -2.5403824]], dtype=float32)

time = 31305	action = 0	current_phase = 0	next_phase = 1	reward = -0.219824	array([[-1.9034886, -3.063451 ]], dtype=float32)

time = 31310	action = 0	current_phase = 0	next_phase = 1	reward = 0.365287	array([[-2.022613 , -2.7694917]], dtype=float32)

time = 31315	action = 1	current_phase = 0	next_phase = 1	reward = -1.297784	array([[-4.106251 , -2.9158912]], dtype=float32)

time = 31323	action = 0	current_phase = 1	next_phase = 0	reward = -0.597742	array([[-2.2389548, -2.8564014]], dtype=float32)

time = 31328	action = 0	current_phase = 1	next_phase = 0	reward = -0.443203	array([[-2.1355755, -2.8848004]], dtype=float32)

time = 31333	action = 0	current_phase = 1	next_phase = 0	reward = -0.298980	array([[-2.1291354, -2.9121428]], dtype=float32)

time = 31338	action = 0	current_phase = 1	next_phase = 0	reward = -0.167625	array([[-2.3394833, -2.8993607]], dtype=float32)

time = 31343	action = 0	current_phase = 1	next_phase = 0	reward = 0.158321	array([[-2.8702478, -3.4918938]], dtype=float32)

time = 31348	action = 1	current_phase = 1	next_phase = 0	reward = -1.890066	array([[-5.534459 , -3.5439062]], dtype=float32)

time = 31356	action = 0	current_phase = 0	next_phase = 1	reward = -0.483758	array([[-2.1548347, -2.9600935]], dtype=float32)

time = 31361	action = 0	current_phase = 0	next_phase = 1	reward = -0.324282	array([[-2.0013971, -2.539614 ]], dtype=float32)

time = 31366	action = 0	current_phase = 0	next_phase = 1	reward = -0.180349	array([[-2.0364654, -2.5316255]], dtype=float32)

time = 31371	action = 0	current_phase = 0	next_phase = 1	reward = 0.275058	array([[-2.298157 , -3.1686482]], dtype=float32)

time = 31376	action = 1	current_phase = 0	next_phase = 1	reward = -1.663555	array([[-4.292985 , -3.1857855]], dtype=float32)

time = 31384	action = 0	current_phase = 1	next_phase = 0	reward = -0.557706	array([[-2.0337474, -2.7880898]], dtype=float32)

time = 31389	action = 0	current_phase = 1	next_phase = 0	reward = -0.402391	array([[-1.9018929, -3.0521865]], dtype=float32)

time = 31394	action = 0	current_phase = 1	next_phase = 0	reward = -0.255439	array([[-1.8593339, -2.9332156]], dtype=float32)

time = 31399	action = 0	current_phase = 1	next_phase = 0	reward = -0.188181	array([[-1.9612464, -3.4205267]], dtype=float32)

time = 31404	action = 1	current_phase = 1	next_phase = 0	reward = -1.372344	array([[-2.417427 , -2.3368006]], dtype=float32)

time = 31412	action = 0	current_phase = 0	next_phase = 1	reward = -1.152507	array([[-2.3155136, -2.9068658]], dtype=float32)

time = 31417	action = 0	current_phase = 0	next_phase = 1	reward = -1.011806	array([[-2.1476507, -2.5994196]], dtype=float32)

time = 31422	action = 0	current_phase = 0	next_phase = 1	reward = -0.885334	array([[-1.9734427, -3.0359545]], dtype=float32)

time = 31427	action = 1	current_phase = 0	next_phase = 1	reward = -0.790376	array([[-2.9274085, -2.5169506]], dtype=float32)

time = 31435	action = 0	current_phase = 1	next_phase = 0	reward = -0.843003	array([[ 5.1888003, -3.1779826]], dtype=float32)

time = 31440	action = 1	current_phase = 1	next_phase = 0	reward = -2.106687	array([[-5.6270924, -3.6624615]], dtype=float32)

time = 31448	action = 0	current_phase = 0	next_phase = 1	reward = -0.428779	array([[-2.0684712, -2.812743 ]], dtype=float32)

time = 31453	action = 0	current_phase = 0	next_phase = 1	reward = -0.279917	array([[-2.1685197, -3.0866358]], dtype=float32)

time = 31458	action = 0	current_phase = 0	next_phase = 1	reward = -0.161893	array([[-2.299059 , -2.9554284]], dtype=float32)

time = 31463	action = 0	current_phase = 0	next_phase = 1	reward = -0.034433	array([[-2.6304615, -3.6906054]], dtype=float32)

time = 31468	action = 1	current_phase = 0	next_phase = 1	reward = -1.901670	array([[-5.594568 , -3.4590209]], dtype=float32)

time = 31476	action = 0	current_phase = 1	next_phase = 0	reward = -0.492226	array([[-2.1597402, -3.1814995]], dtype=float32)

time = 31481	action = 0	current_phase = 1	next_phase = 0	reward = -0.335878	array([[-2.131108 , -2.8859847]], dtype=float32)

time = 31486	action = 0	current_phase = 1	next_phase = 0	reward = -0.195051	array([[-2.337692 , -2.8702257]], dtype=float32)

time = 31491	action = 0	current_phase = 1	next_phase = 0	reward = 0.280061	array([[-2.4599714, -3.77435  ]], dtype=float32)

time = 31496	action = 1	current_phase = 1	next_phase = 0	reward = -1.613199	array([[-5.207331 , -3.2754583]], dtype=float32)

time = 31504	action = 0	current_phase = 0	next_phase = 1	reward = -0.555674	array([[-2.0914483, -2.6451545]], dtype=float32)

time = 31509	action = 0	current_phase = 0	next_phase = 1	reward = -0.399598	array([[-2.0009336, -2.5383885]], dtype=float32)

time = 31514	action = 0	current_phase = 0	next_phase = 1	reward = -0.243704	array([[-1.9038485, -3.063204 ]], dtype=float32)

time = 31519	action = 0	current_phase = 0	next_phase = 1	reward = -0.185386	array([[-1.9286636, -3.2656672]], dtype=float32)

time = 31524	action = 1	current_phase = 0	next_phase = 1	reward = -0.486445	array([[-3.3737087, -2.391074 ]], dtype=float32)

time = 31532	action = 0	current_phase = 1	next_phase = 0	reward = -0.623645	array([[-2.285491 , -2.8421996]], dtype=float32)

time = 31537	action = 0	current_phase = 1	next_phase = 0	reward = -0.476805	array([[-2.17721  , -3.2151787]], dtype=float32)

time = 31542	action = 0	current_phase = 1	next_phase = 0	reward = -0.323878	array([[-2.1347666, -2.8837504]], dtype=float32)

time = 31547	action = 0	current_phase = 1	next_phase = 0	reward = -0.182233	array([[-2.2571304, -2.9239707]], dtype=float32)

time = 31552	action = 0	current_phase = 1	next_phase = 0	reward = 0.275098	array([[-2.5139613, -3.6865325]], dtype=float32)

time = 31557	action = 1	current_phase = 1	next_phase = 0	reward = -1.723419	array([[-5.527583 , -3.5137615]], dtype=float32)

time = 31565	action = 0	current_phase = 0	next_phase = 1	reward = -0.512245	array([[-2.1154795, -2.9672801]], dtype=float32)

time = 31570	action = 0	current_phase = 0	next_phase = 1	reward = -0.352477	array([[-2.0015652, -2.5339854]], dtype=float32)

time = 31575	action = 0	current_phase = 0	next_phase = 1	reward = -0.203668	array([[-1.9028325, -3.0626528]], dtype=float32)

time = 31580	action = 0	current_phase = 0	next_phase = 1	reward = 0.334557	array([[-2.035583, -3.014244]], dtype=float32)

time = 31585	action = 1	current_phase = 0	next_phase = 1	reward = -1.426000	array([[-4.1913223, -3.0119221]], dtype=float32)

time = 31593	action = 0	current_phase = 1	next_phase = 0	reward = -0.601203	array([[-2.2464516, -2.8549461]], dtype=float32)

time = 31598	action = 0	current_phase = 1	next_phase = 0	reward = -0.436381	array([[-2.1068337, -2.9050462]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0518 - val_loss: 0.0564

Epoch 2/50

 - 4s - loss: 0.0238 - val_loss: 0.0576

Epoch 3/50

 - 5s - loss: 0.0374 - val_loss: 0.0552

Epoch 4/50

 - 4s - loss: 0.0244 - val_loss: 0.0557

Epoch 5/50

 - 4s - loss: 0.0253 - val_loss: 0.0564

Epoch 6/50

 - 4s - loss: 0.0235 - val_loss: 0.0559

Epoch 7/50

 - 5s - loss: 0.0241 - val_loss: 0.0581

Epoch 8/50

 - 4s - loss: 0.0255 - val_loss: 0.0583

Epoch 9/50

 - 4s - loss: 0.0410 - val_loss: 0.0567

Epoch 10/50

 - 4s - loss: 0.0222 - val_loss: 0.0571

Epoch 11/50

 - 4s - loss: 0.0313 - val_loss: 0.0562

Epoch 12/50

 - 4s - loss: 0.0255 - val_loss: 0.0586

Epoch 13/50

 - 5s - loss: 0.0222 - val_loss: 0.0582

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 864, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 851, after forget

time = 31603	action = 0	current_phase = 1	next_phase = 0	reward = -0.272070	array([[-2.156997, -2.898831]], dtype=float32)

time = 31608	action = 0	current_phase = 1	next_phase = 0	reward = -0.160841	array([[-2.1317651, -3.3638575]], dtype=float32)

time = 31613	action = 0	current_phase = 1	next_phase = 0	reward = 0.063226	array([[-3.0483315, -3.2553198]], dtype=float32)

time = 31618	action = 1	current_phase = 1	next_phase = 0	reward = -1.900023	array([[-5.5437417, -3.5825074]], dtype=float32)

time = 31626	action = 0	current_phase = 0	next_phase = 1	reward = -0.490142	array([[-2.1648571, -3.0233185]], dtype=float32)

time = 31631	action = 0	current_phase = 0	next_phase = 1	reward = -0.340269	array([[-1.9987423, -2.5597322]], dtype=float32)

time = 31636	action = 0	current_phase = 0	next_phase = 1	reward = -0.191825	array([[-2.0254915, -2.4809916]], dtype=float32)

time = 31641	action = 0	current_phase = 0	next_phase = 1	reward = 0.300735	array([[-2.3214374, -3.2010753]], dtype=float32)

time = 31646	action = 1	current_phase = 0	next_phase = 1	reward = -1.665335	array([[-4.3476553, -3.211328 ]], dtype=float32)

time = 31654	action = 0	current_phase = 1	next_phase = 0	reward = -0.557240	array([[-1.9235994, -2.6988418]], dtype=float32)

time = 31659	action = 0	current_phase = 1	next_phase = 0	reward = -0.413199	array([[-1.9018784, -3.0497015]], dtype=float32)

time = 31664	action = 0	current_phase = 1	next_phase = 0	reward = -0.261176	array([[-1.8111954, -2.9981601]], dtype=float32)

time = 31669	action = 0	current_phase = 1	next_phase = 0	reward = -0.181698	array([[-2.0199049, -3.5211422]], dtype=float32)

time = 31674	action = 0	current_phase = 1	next_phase = 0	reward = -0.083298	array([[-2.292989 , -2.3120623]], dtype=float32)

time = 31679	action = 1	current_phase = 1	next_phase = 0	reward = -2.016565	array([[-5.5065045, -3.6050568]], dtype=float32)

time = 31687	action = 0	current_phase = 0	next_phase = 1	reward = -0.464605	array([[-2.0548017, -2.8764248]], dtype=float32)

time = 31692	action = 0	current_phase = 0	next_phase = 1	reward = -0.310429	array([[-1.9312786, -2.6128492]], dtype=float32)

time = 31697	action = 0	current_phase = 0	next_phase = 1	reward = -0.173295	array([[-2.2304351, -2.5003843]], dtype=float32)

time = 31702	action = 0	current_phase = 0	next_phase = 1	reward = 0.186479	array([[-2.3939419, -3.281741 ]], dtype=float32)

time = 31707	action = 1	current_phase = 0	next_phase = 1	reward = -1.785108	array([[-5.263155 , -3.4701786]], dtype=float32)

time = 31715	action = 0	current_phase = 1	next_phase = 0	reward = -0.524947	array([[-2.0774627, -2.86169  ]], dtype=float32)

time = 31720	action = 0	current_phase = 1	next_phase = 0	reward = -0.368528	array([[-1.9030542, -3.048708 ]], dtype=float32)

time = 31725	action = 0	current_phase = 1	next_phase = 0	reward = -0.215543	array([[-1.8820721, -3.0386229]], dtype=float32)

time = 31730	action = 0	current_phase = 1	next_phase = 0	reward = 0.363148	array([[-2.0421681, -3.5777621]], dtype=float32)

time = 31735	action = 1	current_phase = 1	next_phase = 0	reward = -1.305653	array([[-3.706769 , -3.0739977]], dtype=float32)

time = 31743	action = 0	current_phase = 0	next_phase = 1	reward = -0.581960	array([[-2.2510917, -2.8419936]], dtype=float32)

time = 31748	action = 0	current_phase = 0	next_phase = 1	reward = -0.423049	array([[-1.994187 , -2.5366294]], dtype=float32)

time = 31753	action = 0	current_phase = 0	next_phase = 1	reward = -0.275353	array([[-2.0214224, -3.0945792]], dtype=float32)

time = 31758	action = 0	current_phase = 0	next_phase = 1	reward = -0.164347	array([[-2.3493466, -2.5453987]], dtype=float32)

time = 31763	action = 0	current_phase = 0	next_phase = 1	reward = 0.006500	array([[-2.750866, -3.966762]], dtype=float32)

time = 31768	action = 1	current_phase = 0	next_phase = 1	reward = -1.895280	array([[-6.022934 , -3.5244396]], dtype=float32)

time = 31776	action = 0	current_phase = 1	next_phase = 0	reward = -0.496526	array([[-2.1644065, -3.2199602]], dtype=float32)

time = 31781	action = 0	current_phase = 1	next_phase = 0	reward = -0.336912	array([[-2.155431 , -2.8949656]], dtype=float32)

time = 31786	action = 0	current_phase = 1	next_phase = 0	reward = -0.192802	array([[-2.1446874, -3.0181441]], dtype=float32)

time = 31791	action = 0	current_phase = 1	next_phase = 0	reward = 0.310985	array([[-2.3593524, -3.6855323]], dtype=float32)

time = 31796	action = 1	current_phase = 1	next_phase = 0	reward = -1.555540	array([[-5.1829085, -3.2381282]], dtype=float32)

time = 31804	action = 0	current_phase = 0	next_phase = 1	reward = -0.558623	array([[-2.108596 , -2.6653848]], dtype=float32)

time = 31809	action = 0	current_phase = 0	next_phase = 1	reward = -0.399682	array([[-1.9943544, -2.5369904]], dtype=float32)

time = 31814	action = 0	current_phase = 0	next_phase = 1	reward = -0.248267	array([[-1.8510846, -3.0832074]], dtype=float32)

time = 31819	action = 0	current_phase = 0	next_phase = 1	reward = -0.183736	array([[-1.8609992, -3.367039 ]], dtype=float32)

time = 31824	action = 1	current_phase = 0	next_phase = 1	reward = -0.557660	array([[-3.4779134, -2.2762518]], dtype=float32)

time = 31832	action = 0	current_phase = 1	next_phase = 0	reward = -0.617139	array([[-2.30801  , -2.8635247]], dtype=float32)

time = 31837	action = 0	current_phase = 1	next_phase = 0	reward = -0.459956	array([[-2.1444519, -3.2247741]], dtype=float32)

time = 31842	action = 0	current_phase = 1	next_phase = 0	reward = -0.310145	array([[-2.1530352, -2.8901412]], dtype=float32)

time = 31847	action = 0	current_phase = 1	next_phase = 0	reward = -0.174294	array([[-2.2874596, -3.0530682]], dtype=float32)

time = 31852	action = 0	current_phase = 1	next_phase = 0	reward = 0.199874	array([[-2.619577 , -3.7409983]], dtype=float32)

time = 31857	action = 1	current_phase = 1	next_phase = 0	reward = -1.780894	array([[-5.514942 , -3.5860991]], dtype=float32)

time = 31865	action = 0	current_phase = 0	next_phase = 1	reward = -0.528954	array([[-2.142829 , -3.0062819]], dtype=float32)

time = 31870	action = 0	current_phase = 0	next_phase = 1	reward = -0.372714	array([[-1.9909747, -2.5551524]], dtype=float32)

time = 31875	action = 0	current_phase = 0	next_phase = 1	reward = -0.217900	array([[-1.8505408, -3.081583 ]], dtype=float32)

time = 31880	action = 0	current_phase = 0	next_phase = 1	reward = 0.362332	array([[-2.0188649, -2.769234 ]], dtype=float32)

time = 31885	action = 1	current_phase = 0	next_phase = 1	reward = -1.259341	array([[-4.1686597, -3.1361754]], dtype=float32)

time = 31893	action = 0	current_phase = 1	next_phase = 0	reward = -0.588091	array([[-2.2873425, -2.8672209]], dtype=float32)

time = 31898	action = 0	current_phase = 1	next_phase = 0	reward = -0.434734	array([[-2.1441298, -2.901842 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0960 - val_loss: 0.0149

Epoch 2/50

 - 4s - loss: 0.1134 - val_loss: 0.0139

Epoch 3/50

 - 4s - loss: 0.0861 - val_loss: 0.0153

Epoch 4/50

 - 4s - loss: 0.1010 - val_loss: 0.0142

Epoch 5/50

 - 4s - loss: 0.0943 - val_loss: 0.0150

Epoch 6/50

 - 4s - loss: 0.0797 - val_loss: 0.0147

Epoch 7/50

 - 4s - loss: 0.0857 - val_loss: 0.0199

Epoch 8/50

 - 4s - loss: 0.0918 - val_loss: 0.0167

Epoch 9/50

 - 4s - loss: 0.0787 - val_loss: 0.0168

Epoch 10/50

 - 4s - loss: 0.0962 - val_loss: 0.0164

Epoch 11/50

 - 4s - loss: 0.0811 - val_loss: 0.0170

Epoch 12/50

 - 4s - loss: 0.0806 - val_loss: 0.0200

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 869, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 856, after forget

time = 31903	action = 0	current_phase = 1	next_phase = 0	reward = -0.286362	array([[-2.1112394, -2.8864791]], dtype=float32)

time = 31908	action = 0	current_phase = 1	next_phase = 0	reward = -0.165987	array([[-2.1297626, -3.1010065]], dtype=float32)

time = 31913	action = 0	current_phase = 1	next_phase = 0	reward = -0.046055	array([[-2.763434 , -2.9751143]], dtype=float32)

time = 31918	action = 1	current_phase = 1	next_phase = 0	reward = -1.901632	array([[-5.51364  , -3.5800061]], dtype=float32)

time = 31926	action = 0	current_phase = 0	next_phase = 1	reward = -0.496553	array([[-2.0740142, -2.947384 ]], dtype=float32)

time = 31931	action = 0	current_phase = 0	next_phase = 1	reward = -0.337193	array([[-1.9444224, -2.5459023]], dtype=float32)

time = 31936	action = 0	current_phase = 0	next_phase = 1	reward = -0.185963	array([[-1.9779273, -2.6552432]], dtype=float32)

time = 31941	action = 0	current_phase = 0	next_phase = 1	reward = 0.300188	array([[-2.3002234, -2.9230416]], dtype=float32)

time = 31946	action = 1	current_phase = 0	next_phase = 1	reward = -1.559327	array([[-4.188602 , -3.1684766]], dtype=float32)

time = 31954	action = 0	current_phase = 1	next_phase = 0	reward = -0.564222	array([[-2.0481298, -2.781214 ]], dtype=float32)

time = 31959	action = 0	current_phase = 1	next_phase = 0	reward = -0.415802	array([[-1.8702512, -3.0258353]], dtype=float32)

time = 31964	action = 0	current_phase = 1	next_phase = 0	reward = -0.269146	array([[-1.9128292, -2.9978154]], dtype=float32)

time = 31969	action = 0	current_phase = 1	next_phase = 0	reward = -0.168312	array([[-1.9386191, -3.4511364]], dtype=float32)

time = 31974	action = 0	current_phase = 1	next_phase = 0	reward = -0.010255	array([[-2.2020285, -2.2474468]], dtype=float32)

time = 31979	action = 1	current_phase = 1	next_phase = 0	reward = -2.002082	array([[-5.5182114, -3.580457 ]], dtype=float32)

time = 31987	action = 0	current_phase = 0	next_phase = 1	reward = -0.450940	array([[-2.0122929, -2.8921916]], dtype=float32)

time = 31992	action = 0	current_phase = 0	next_phase = 1	reward = -0.280953	array([[-1.936061, -2.675257]], dtype=float32)

time = 31997	action = 0	current_phase = 0	next_phase = 1	reward = -0.159678	array([[-2.152686 , -2.3458712]], dtype=float32)

time = 32002	action = 0	current_phase = 0	next_phase = 1	reward = 0.154086	array([[-2.54328  , -3.2310886]], dtype=float32)

time = 32007	action = 1	current_phase = 0	next_phase = 1	reward = -1.784095	array([[-5.3469543, -3.398529 ]], dtype=float32)

time = 32015	action = 0	current_phase = 1	next_phase = 0	reward = -0.532147	array([[-2.0112827, -2.804493 ]], dtype=float32)

time = 32020	action = 0	current_phase = 1	next_phase = 0	reward = -0.374441	array([[-1.8687737, -3.0257607]], dtype=float32)

time = 32025	action = 0	current_phase = 1	next_phase = 0	reward = -0.219104	array([[-1.8369155, -3.0076482]], dtype=float32)

time = 32030	action = 0	current_phase = 1	next_phase = 0	reward = 0.368959	array([[-1.9921004, -3.5774794]], dtype=float32)

time = 32035	action = 1	current_phase = 1	next_phase = 0	reward = -1.303978	array([[-3.7397454, -3.035728 ]], dtype=float32)

time = 32043	action = 0	current_phase = 0	next_phase = 1	reward = -0.588645	array([[-2.196847 , -2.8335495]], dtype=float32)

time = 32048	action = 0	current_phase = 0	next_phase = 1	reward = -0.437576	array([[-1.9504166, -2.517347 ]], dtype=float32)

time = 32053	action = 0	current_phase = 0	next_phase = 1	reward = -0.280125	array([[-2.0204973, -3.0390847]], dtype=float32)

time = 32058	action = 0	current_phase = 0	next_phase = 1	reward = -0.159753	array([[-2.2516558, -2.2634423]], dtype=float32)

time = 32063	action = 0	current_phase = 0	next_phase = 1	reward = 0.062419	array([[-2.4713836, -4.372759 ]], dtype=float32)

time = 32068	action = 1	current_phase = 0	next_phase = 1	reward = -1.894548	array([[-6.0497966, -3.5137138]], dtype=float32)

time = 32076	action = 0	current_phase = 1	next_phase = 0	reward = -0.496417	array([[-2.1256251, -3.1857498]], dtype=float32)

time = 32081	action = 0	current_phase = 1	next_phase = 0	reward = -0.347416	array([[-2.0301025, -2.9268715]], dtype=float32)

time = 32086	action = 0	current_phase = 1	next_phase = 0	reward = -0.197012	array([[-2.1010668, -2.980488 ]], dtype=float32)

time = 32091	action = 0	current_phase = 1	next_phase = 0	reward = 0.330243	array([[-2.2725744, -3.647485 ]], dtype=float32)

time = 32096	action = 1	current_phase = 1	next_phase = 0	reward = -1.500054	array([[-5.2107573, -3.2664042]], dtype=float32)

time = 32104	action = 0	current_phase = 0	next_phase = 1	reward = -0.543034	array([[-2.0609457, -2.6477249]], dtype=float32)

time = 32109	action = 0	current_phase = 0	next_phase = 1	reward = -0.387003	array([[-1.9499556, -2.5196335]], dtype=float32)

time = 32114	action = 0	current_phase = 0	next_phase = 1	reward = -0.229554	array([[-1.8849887, -3.0274246]], dtype=float32)

time = 32119	action = 0	current_phase = 0	next_phase = 1	reward = -0.183592	array([[-1.9297692, -3.1314654]], dtype=float32)

time = 32124	action = 1	current_phase = 0	next_phase = 1	reward = -0.594731	array([[-3.5272331, -2.253439 ]], dtype=float32)

time = 32132	action = 0	current_phase = 1	next_phase = 0	reward = -0.617489	array([[-2.276476 , -2.8270602]], dtype=float32)

time = 32137	action = 0	current_phase = 1	next_phase = 0	reward = -0.464420	array([[-2.1116898, -3.1886818]], dtype=float32)

time = 32142	action = 0	current_phase = 1	next_phase = 0	reward = -0.305759	array([[-2.0950787, -2.8682144]], dtype=float32)

time = 32147	action = 0	current_phase = 1	next_phase = 0	reward = -0.168894	array([[-2.3375661, -2.8859408]], dtype=float32)

time = 32152	action = 0	current_phase = 1	next_phase = 0	reward = 0.237209	array([[-2.6655135, -3.5726175]], dtype=float32)

time = 32157	action = 1	current_phase = 1	next_phase = 0	reward = -1.778257	array([[-5.53766  , -3.4921682]], dtype=float32)

time = 32165	action = 0	current_phase = 0	next_phase = 1	reward = -0.515819	array([[-2.074126 , -2.9728787]], dtype=float32)

time = 32170	action = 0	current_phase = 0	next_phase = 1	reward = -0.354013	array([[-1.9491891, -2.5241966]], dtype=float32)

time = 32175	action = 0	current_phase = 0	next_phase = 1	reward = -0.208026	array([[-1.918116, -2.893266]], dtype=float32)

time = 32180	action = 0	current_phase = 0	next_phase = 1	reward = 0.352947	array([[-2.0475137, -2.7221675]], dtype=float32)

time = 32185	action = 1	current_phase = 0	next_phase = 1	reward = -1.315998	array([[-3.9116087, -3.038345 ]], dtype=float32)

time = 32193	action = 0	current_phase = 1	next_phase = 0	reward = -0.585198	array([[-2.2346995, -2.8412766]], dtype=float32)

time = 32198	action = 0	current_phase = 1	next_phase = 0	reward = -0.437394	array([[-2.0233274, -2.9322968]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0912 - val_loss: 0.0137

Epoch 2/50

 - 4s - loss: 0.0725 - val_loss: 0.0145

Epoch 3/50

 - 4s - loss: 0.0676 - val_loss: 0.0153

Epoch 4/50

 - 5s - loss: 0.0766 - val_loss: 0.0160

Epoch 5/50

 - 5s - loss: 0.0682 - val_loss: 0.0148

Epoch 6/50

 - 4s - loss: 0.0673 - val_loss: 0.0146

Epoch 7/50

 - 4s - loss: 0.0715 - val_loss: 0.0158

Epoch 8/50

 - 4s - loss: 0.0700 - val_loss: 0.0162

Epoch 9/50

 - 4s - loss: 0.0691 - val_loss: 0.0157

Epoch 10/50

 - 5s - loss: 0.0777 - val_loss: 0.0162

Epoch 11/50

 - 4s - loss: 0.0904 - val_loss: 0.0172

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 874, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 861, after forget

time = 32203	action = 0	current_phase = 1	next_phase = 0	reward = -0.285903	array([[-2.1338449, -2.910455 ]], dtype=float32)

time = 32208	action = 0	current_phase = 1	next_phase = 0	reward = -0.166834	array([[-2.0913138, -3.4630988]], dtype=float32)

time = 32213	action = 0	current_phase = 1	next_phase = 0	reward = 0.066548	array([[-2.8554435, -3.2990797]], dtype=float32)

time = 32218	action = 1	current_phase = 1	next_phase = 0	reward = -1.902626	array([[-5.469415 , -3.5943685]], dtype=float32)

time = 32226	action = 0	current_phase = 0	next_phase = 1	reward = -0.501883	array([[-2.0808442, -2.9836104]], dtype=float32)

time = 32231	action = 0	current_phase = 0	next_phase = 1	reward = -0.348774	array([[-1.9366708, -2.4935138]], dtype=float32)

time = 32236	action = 0	current_phase = 0	next_phase = 1	reward = -0.200735	array([[-2.0456188, -2.086716 ]], dtype=float32)

time = 32241	action = 0	current_phase = 0	next_phase = 1	reward = 0.307471	array([[-2.3015647, -2.6968508]], dtype=float32)

time = 32246	action = 1	current_phase = 0	next_phase = 1	reward = -1.554515	array([[-4.271526 , -3.2188256]], dtype=float32)

time = 32254	action = 0	current_phase = 1	next_phase = 0	reward = -0.551928	array([[-2.1045043, -2.8280122]], dtype=float32)

time = 32259	action = 0	current_phase = 1	next_phase = 0	reward = -0.403628	array([[-1.9240183, -3.0265362]], dtype=float32)

time = 32264	action = 0	current_phase = 1	next_phase = 0	reward = -0.240794	array([[-1.9117143, -3.009017 ]], dtype=float32)

time = 32269	action = 0	current_phase = 1	next_phase = 0	reward = 0.110076	array([[-2.014132, -3.516141]], dtype=float32)

time = 32274	action = 1	current_phase = 1	next_phase = 0	reward = -0.804325	array([[-2.8704486, -2.3934755]], dtype=float32)

time = 32282	action = 0	current_phase = 0	next_phase = 1	reward = -0.615770	array([[-2.1933405, -2.8363903]], dtype=float32)

time = 32287	action = 0	current_phase = 0	next_phase = 1	reward = -0.456496	array([[-1.9429938, -2.4993608]], dtype=float32)

time = 32292	action = 0	current_phase = 0	next_phase = 1	reward = -0.299875	array([[-1.9115475, -2.8653102]], dtype=float32)

time = 32297	action = 1	current_phase = 0	next_phase = 1	reward = -0.756477	array([[-2.380154 , -2.0858762]], dtype=float32)

time = 32305	action = 0	current_phase = 1	next_phase = 0	reward = -0.847258	array([[ 5.595095 , -2.9497693]], dtype=float32)

time = 32310	action = 1	current_phase = 1	next_phase = 0	reward = -2.118140	array([[-5.3061423, -3.6970227]], dtype=float32)

time = 32318	action = 0	current_phase = 0	next_phase = 1	reward = -0.442654	array([[-1.999121 , -2.8871896]], dtype=float32)

time = 32323	action = 0	current_phase = 0	next_phase = 1	reward = -0.285221	array([[-2.116982 , -3.0072188]], dtype=float32)

time = 32328	action = 0	current_phase = 0	next_phase = 1	reward = -0.164111	array([[-2.1795728, -2.8832967]], dtype=float32)

time = 32333	action = 0	current_phase = 0	next_phase = 1	reward = 0.083854	array([[-2.8856444, -3.2568889]], dtype=float32)

time = 32338	action = 1	current_phase = 0	next_phase = 1	reward = -1.903488	array([[-5.573464 , -3.4480927]], dtype=float32)

time = 32346	action = 0	current_phase = 1	next_phase = 0	reward = -0.510131	array([[-2.111935 , -3.1856947]], dtype=float32)

time = 32351	action = 0	current_phase = 1	next_phase = 0	reward = -0.352287	array([[-2.0650568, -2.9382324]], dtype=float32)

time = 32356	action = 0	current_phase = 1	next_phase = 0	reward = -0.196868	array([[-2.0080156, -3.018869 ]], dtype=float32)

time = 32361	action = 0	current_phase = 1	next_phase = 0	reward = 0.309675	array([[-2.3283672, -3.7106974]], dtype=float32)

time = 32366	action = 1	current_phase = 1	next_phase = 0	reward = -1.554439	array([[-5.160207 , -3.2583213]], dtype=float32)

time = 32374	action = 0	current_phase = 0	next_phase = 1	reward = -0.565233	array([[-2.022395 , -2.5995505]], dtype=float32)

time = 32379	action = 0	current_phase = 0	next_phase = 1	reward = -0.415228	array([[-1.9361236, -2.4912465]], dtype=float32)

time = 32384	action = 0	current_phase = 0	next_phase = 1	reward = -0.256188	array([[-1.9706049, -3.0013947]], dtype=float32)

time = 32389	action = 0	current_phase = 0	next_phase = 1	reward = -0.172233	array([[-1.9854146, -3.212004 ]], dtype=float32)

time = 32394	action = 1	current_phase = 0	next_phase = 1	reward = -0.467146	array([[-3.510101 , -2.4307559]], dtype=float32)

time = 32402	action = 0	current_phase = 1	next_phase = 0	reward = -0.621274	array([[-2.2841516, -2.8540316]], dtype=float32)

time = 32407	action = 0	current_phase = 1	next_phase = 0	reward = -0.472246	array([[-2.1051273, -3.1857474]], dtype=float32)

time = 32412	action = 0	current_phase = 1	next_phase = 0	reward = -0.318498	array([[-2.117271 , -2.9089646]], dtype=float32)

time = 32417	action = 0	current_phase = 1	next_phase = 0	reward = -0.185557	array([[-2.1551516, -2.9910412]], dtype=float32)

time = 32422	action = 0	current_phase = 1	next_phase = 0	reward = 0.169161	array([[-2.3264363, -3.8394847]], dtype=float32)

time = 32427	action = 1	current_phase = 1	next_phase = 0	reward = -1.786383	array([[-5.496919 , -3.5054069]], dtype=float32)

time = 32435	action = 0	current_phase = 0	next_phase = 1	reward = -0.533154	array([[-2.0837328, -2.9927053]], dtype=float32)

time = 32440	action = 0	current_phase = 0	next_phase = 1	reward = -0.379430	array([[-1.936102 , -2.4907827]], dtype=float32)

time = 32445	action = 0	current_phase = 0	next_phase = 1	reward = -0.223759	array([[-1.8787498, -2.9964852]], dtype=float32)

time = 32450	action = 0	current_phase = 0	next_phase = 1	reward = 0.063259	array([[-2.0098267, -2.8017933]], dtype=float32)

time = 32455	action = 1	current_phase = 0	next_phase = 1	reward = -1.081414	array([[-3.8493614, -2.7476022]], dtype=float32)

time = 32463	action = 0	current_phase = 1	next_phase = 0	reward = -0.592944	array([[-2.297841 , -2.8456156]], dtype=float32)

time = 32468	action = 0	current_phase = 1	next_phase = 0	reward = -0.448551	array([[-2.1376295, -2.8973994]], dtype=float32)

time = 32473	action = 0	current_phase = 1	next_phase = 0	reward = -0.293453	array([[-2.1158772, -2.9116147]], dtype=float32)

time = 32478	action = 0	current_phase = 1	next_phase = 0	reward = -0.166180	array([[-2.3047554, -2.982454 ]], dtype=float32)

time = 32483	action = 0	current_phase = 1	next_phase = 0	reward = 0.098296	array([[-2.6348698, -3.5295568]], dtype=float32)

time = 32488	action = 1	current_phase = 1	next_phase = 0	reward = -1.903638	array([[-5.5121255, -3.5918171]], dtype=float32)

time = 32496	action = 0	current_phase = 0	next_phase = 1	reward = -0.504965	array([[-2.0808442, -2.9836104]], dtype=float32)

time = 32501	action = 0	current_phase = 0	next_phase = 1	reward = -0.351036	array([[-1.9367448, -2.4855947]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0599 - val_loss: 0.1888

Epoch 2/50

 - 4s - loss: 0.0585 - val_loss: 0.1867

Epoch 3/50

 - 4s - loss: 0.0642 - val_loss: 0.1759

Epoch 4/50

 - 4s - loss: 0.0600 - val_loss: 0.1832

Epoch 5/50

 - 4s - loss: 0.0608 - val_loss: 0.1789

Epoch 6/50

 - 5s - loss: 0.0523 - val_loss: 0.1778

Epoch 7/50

 - 4s - loss: 0.0579 - val_loss: 0.1864

Epoch 8/50

 - 4s - loss: 0.0469 - val_loss: 0.1849

Epoch 9/50

 - 4s - loss: 0.0469 - val_loss: 0.1838

Epoch 10/50

 - 4s - loss: 0.0453 - val_loss: 0.1847

Epoch 11/50

 - 4s - loss: 0.0484 - val_loss: 0.1893

Epoch 12/50

 - 4s - loss: 0.0544 - val_loss: 0.1887

Epoch 13/50

 - 4s - loss: 0.0528 - val_loss: 0.2002

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 879, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 867, after forget

time = 32506	action = 0	current_phase = 0	next_phase = 1	reward = -0.210738	array([[-2.008666 , -2.3166158]], dtype=float32)

time = 32511	action = 0	current_phase = 0	next_phase = 1	reward = 0.317777	array([[-2.2601652, -2.5618753]], dtype=float32)

time = 32516	action = 1	current_phase = 0	next_phase = 1	reward = -1.606298	array([[-4.1685147, -3.1074035]], dtype=float32)

time = 32524	action = 0	current_phase = 1	next_phase = 0	reward = -0.560466	array([[-2.008087, -2.790594]], dtype=float32)

time = 32529	action = 0	current_phase = 1	next_phase = 0	reward = -0.403468	array([[-1.8025829, -3.0071504]], dtype=float32)

time = 32534	action = 0	current_phase = 1	next_phase = 0	reward = -0.247330	array([[-1.7755753, -2.975879 ]], dtype=float32)

time = 32539	action = 0	current_phase = 1	next_phase = 0	reward = -0.171943	array([[-1.8149084, -3.4047751]], dtype=float32)

time = 32544	action = 0	current_phase = 1	next_phase = 0	reward = -0.125052	array([[-2.193298 , -2.3080838]], dtype=float32)

time = 32549	action = 1	current_phase = 1	next_phase = 0	reward = -2.011819	array([[-5.4873676, -3.5841184]], dtype=float32)

time = 32557	action = 0	current_phase = 0	next_phase = 1	reward = -0.465328	array([[-2.0224068, -2.8738458]], dtype=float32)

time = 32562	action = 0	current_phase = 0	next_phase = 1	reward = -0.311782	array([[-1.9490469, -2.637416 ]], dtype=float32)

time = 32567	action = 1	current_phase = 0	next_phase = 1	reward = -0.763812	array([[-2.087026 , -1.8405914]], dtype=float32)

time = 32575	action = 1	current_phase = 1	next_phase = 0	reward = -1.319797	array([[-3.260019 , -3.1545422]], dtype=float32)

time = 32583	action = 0	current_phase = 0	next_phase = 1	reward = -0.604517	array([[-2.01997  , -2.5692263]], dtype=float32)

time = 32588	action = 0	current_phase = 0	next_phase = 1	reward = -0.447795	array([[-1.953659 , -2.4564583]], dtype=float32)

time = 32593	action = 0	current_phase = 0	next_phase = 1	reward = -0.290464	array([[-1.9872344, -2.9517043]], dtype=float32)

time = 32598	action = 0	current_phase = 0	next_phase = 1	reward = -0.163061	array([[-2.1689136, -2.3468254]], dtype=float32)

time = 32603	action = 0	current_phase = 0	next_phase = 1	reward = 0.130658	array([[-2.637421 , -3.7779589]], dtype=float32)

time = 32608	action = 1	current_phase = 0	next_phase = 1	reward = -1.896461	array([[-6.0201697, -3.5125482]], dtype=float32)

time = 32616	action = 0	current_phase = 1	next_phase = 0	reward = -0.505800	array([[-2.0364122, -3.167495 ]], dtype=float32)

time = 32621	action = 0	current_phase = 1	next_phase = 0	reward = -0.358263	array([[-2.0324275, -2.87694  ]], dtype=float32)

time = 32626	action = 0	current_phase = 1	next_phase = 0	reward = -0.203917	array([[-2.1125083, -2.9355407]], dtype=float32)

time = 32631	action = 0	current_phase = 1	next_phase = 0	reward = 0.332975	array([[-2.330536 , -3.7899995]], dtype=float32)

time = 32636	action = 1	current_phase = 1	next_phase = 0	reward = -1.557179	array([[-4.2611866, -3.0876331]], dtype=float32)

time = 32644	action = 0	current_phase = 0	next_phase = 1	reward = -0.569480	array([[-2.0534527, -2.5931456]], dtype=float32)

time = 32649	action = 0	current_phase = 0	next_phase = 1	reward = -0.411221	array([[-1.937702 , -2.4553072]], dtype=float32)

time = 32654	action = 0	current_phase = 0	next_phase = 1	reward = -0.248948	array([[-1.9191076, -2.9476073]], dtype=float32)

time = 32659	action = 0	current_phase = 0	next_phase = 1	reward = -0.167571	array([[-2.0266364, -2.9994912]], dtype=float32)

time = 32664	action = 1	current_phase = 0	next_phase = 1	reward = -0.370094	array([[-3.5525987, -2.140965 ]], dtype=float32)

time = 32672	action = 0	current_phase = 1	next_phase = 0	reward = -0.619090	array([[-2.2026577, -2.8105092]], dtype=float32)

time = 32677	action = 0	current_phase = 1	next_phase = 0	reward = -0.465794	array([[-2.0296748, -3.1579695]], dtype=float32)

time = 32682	action = 0	current_phase = 1	next_phase = 0	reward = -0.313993	array([[-2.0432088, -2.8564599]], dtype=float32)

time = 32687	action = 0	current_phase = 1	next_phase = 0	reward = -0.173096	array([[-2.2759845, -2.908453 ]], dtype=float32)

time = 32692	action = 0	current_phase = 1	next_phase = 0	reward = 0.201444	array([[-2.371261 , -3.7720394]], dtype=float32)

time = 32697	action = 1	current_phase = 1	next_phase = 0	reward = -1.785550	array([[-5.4068975, -3.577437 ]], dtype=float32)

time = 32705	action = 0	current_phase = 0	next_phase = 1	reward = -0.537897	array([[-2.069872, -2.927897]], dtype=float32)

time = 32710	action = 0	current_phase = 0	next_phase = 1	reward = -0.392978	array([[-1.9372274, -2.4563236]], dtype=float32)

time = 32715	action = 0	current_phase = 0	next_phase = 1	reward = -0.239778	array([[-1.9107653, -2.9472725]], dtype=float32)

time = 32720	action = 0	current_phase = 0	next_phase = 1	reward = -0.208953	array([[-2.0944402, -2.1208897]], dtype=float32)

time = 32725	action = 1	current_phase = 0	next_phase = 1	reward = -0.792855	array([[-3.5918982, -2.2816935]], dtype=float32)

time = 32733	action = 0	current_phase = 1	next_phase = 0	reward = -0.597053	array([[-2.217888 , -2.7983649]], dtype=float32)

time = 32738	action = 0	current_phase = 1	next_phase = 0	reward = -0.435244	array([[-2.0549278, -2.8659632]], dtype=float32)

time = 32743	action = 0	current_phase = 1	next_phase = 0	reward = -0.278407	array([[-2.0523036, -2.8897789]], dtype=float32)

time = 32748	action = 0	current_phase = 1	next_phase = 0	reward = -0.166147	array([[-2.2607844, -2.9588811]], dtype=float32)

time = 32753	action = 0	current_phase = 1	next_phase = 0	reward = 0.015530	array([[-2.6167707, -3.2853441]], dtype=float32)

time = 32758	action = 1	current_phase = 1	next_phase = 0	reward = -1.893963	array([[-5.485906 , -3.5878222]], dtype=float32)

time = 32766	action = 0	current_phase = 0	next_phase = 1	reward = -0.503346	array([[-2.0564566, -2.9024315]], dtype=float32)

time = 32771	action = 0	current_phase = 0	next_phase = 1	reward = -0.357879	array([[-1.9358122, -2.4883149]], dtype=float32)

time = 32776	action = 0	current_phase = 0	next_phase = 1	reward = -0.206615	array([[-2.0006251, -2.390605 ]], dtype=float32)

time = 32781	action = 0	current_phase = 0	next_phase = 1	reward = 0.334302	array([[-2.2977333, -2.685013 ]], dtype=float32)

time = 32786	action = 1	current_phase = 0	next_phase = 1	reward = -1.495034	array([[-4.153333 , -3.1233814]], dtype=float32)

time = 32794	action = 0	current_phase = 1	next_phase = 0	reward = -0.551267	array([[-1.89514  , -2.7147791]], dtype=float32)

time = 32799	action = 0	current_phase = 1	next_phase = 0	reward = -0.393044	array([[-1.8055673, -3.0054603]], dtype=float32)

time = 32804	action = 0	current_phase = 1	next_phase = 0	reward = -0.244017	array([[-1.7811413, -2.9941752]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 6s - loss: 0.0597 - val_loss: 0.0595

Epoch 2/50

 - 4s - loss: 0.0509 - val_loss: 0.0581

Epoch 3/50

 - 4s - loss: 0.0563 - val_loss: 0.0591

Epoch 4/50

 - 4s - loss: 0.0555 - val_loss: 0.0589

Epoch 5/50

 - 4s - loss: 0.0436 - val_loss: 0.0576

Epoch 6/50

 - 4s - loss: 0.0498 - val_loss: 0.0593

Epoch 7/50

 - 4s - loss: 0.0418 - val_loss: 0.0602

Epoch 8/50

 - 4s - loss: 0.0332 - val_loss: 0.0607

Epoch 9/50

 - 4s - loss: 0.0409 - val_loss: 0.0615

Epoch 10/50

 - 4s - loss: 0.0590 - val_loss: 0.0602

Epoch 11/50

 - 4s - loss: 0.0323 - val_loss: 0.0620

Epoch 12/50

 - 4s - loss: 0.0334 - val_loss: 0.0614

Epoch 13/50

 - 4s - loss: 0.0570 - val_loss: 0.0621

Epoch 14/50

 - 4s - loss: 0.0745 - val_loss: 0.0638

Epoch 15/50

 - 4s - loss: 0.0414 - val_loss: 0.0626

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 885, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 872, after forget

time = 32809	action = 0	current_phase = 1	next_phase = 0	reward = -0.174199	array([[-2.0219812, -3.4445424]], dtype=float32)

time = 32814	action = 1	current_phase = 1	next_phase = 0	reward = -0.582505	array([[-2.29251  , -2.2151425]], dtype=float32)

time = 32822	action = 0	current_phase = 0	next_phase = 1	reward = -0.623521	array([[-2.2556832, -2.825154 ]], dtype=float32)

time = 32827	action = 0	current_phase = 0	next_phase = 1	reward = -0.467456	array([[-1.96878  , -2.4492066]], dtype=float32)

time = 32832	action = 0	current_phase = 0	next_phase = 1	reward = -0.310462	array([[-1.9811702, -2.7016194]], dtype=float32)

time = 32837	action = 1	current_phase = 0	next_phase = 1	reward = -1.053018	array([[-2.1045792, -1.8774555]], dtype=float32)

time = 32845	action = 0	current_phase = 1	next_phase = 0	reward = -0.617745	array([[ 0.7683629, -3.1271305]], dtype=float32)

time = 32850	action = 1	current_phase = 1	next_phase = 0	reward = -2.120459	array([[-5.2093124, -3.7152462]], dtype=float32)

time = 32858	action = 0	current_phase = 0	next_phase = 1	reward = -0.451420	array([[-2.0743864, -2.8720562]], dtype=float32)

time = 32863	action = 0	current_phase = 0	next_phase = 1	reward = -0.299621	array([[-2.1168687, -2.9632373]], dtype=float32)

time = 32868	action = 0	current_phase = 0	next_phase = 1	reward = -0.166117	array([[-2.133335 , -2.2917674]], dtype=float32)

time = 32873	action = 0	current_phase = 0	next_phase = 1	reward = 0.034320	array([[-2.6867359, -3.6831546]], dtype=float32)

time = 32878	action = 1	current_phase = 0	next_phase = 1	reward = -1.896369	array([[-5.564569 , -3.4933643]], dtype=float32)

time = 32886	action = 0	current_phase = 1	next_phase = 0	reward = -0.480272	array([[-2.1066666, -3.101533 ]], dtype=float32)

time = 32891	action = 0	current_phase = 1	next_phase = 0	reward = -0.328766	array([[-2.105345 , -2.8816051]], dtype=float32)

time = 32896	action = 0	current_phase = 1	next_phase = 0	reward = -0.182088	array([[-2.1900935, -2.954105 ]], dtype=float32)

time = 32901	action = 0	current_phase = 1	next_phase = 0	reward = 0.298928	array([[-2.3832877, -3.7500792]], dtype=float32)

time = 32906	action = 1	current_phase = 1	next_phase = 0	reward = -1.607155	array([[-5.3010254, -3.384068 ]], dtype=float32)

time = 32914	action = 0	current_phase = 0	next_phase = 1	reward = -0.549162	array([[-2.1142743, -2.6357355]], dtype=float32)

time = 32919	action = 0	current_phase = 0	next_phase = 1	reward = -0.395791	array([[-1.9562569, -2.4376514]], dtype=float32)

time = 32924	action = 0	current_phase = 0	next_phase = 1	reward = -0.244849	array([[-1.9460943, -2.9379854]], dtype=float32)

time = 32929	action = 0	current_phase = 0	next_phase = 1	reward = -0.178079	array([[-1.9524784, -3.1094806]], dtype=float32)

time = 32934	action = 1	current_phase = 0	next_phase = 1	reward = -0.581859	array([[-3.727883 , -2.1994095]], dtype=float32)

time = 32942	action = 0	current_phase = 1	next_phase = 0	reward = -0.606018	array([[-2.3669465, -2.7456584]], dtype=float32)

time = 32947	action = 0	current_phase = 1	next_phase = 0	reward = -0.450207	array([[-2.1571746, -3.117815 ]], dtype=float32)

time = 32952	action = 0	current_phase = 1	next_phase = 0	reward = -0.284633	array([[-2.1552188, -2.8361316]], dtype=float32)

time = 32957	action = 0	current_phase = 1	next_phase = 0	reward = -0.162469	array([[-2.3643012, -2.9499712]], dtype=float32)

time = 32962	action = 0	current_phase = 1	next_phase = 0	reward = 0.102559	array([[-2.8931518, -3.2885919]], dtype=float32)

time = 32967	action = 1	current_phase = 1	next_phase = 0	reward = -1.779631	array([[-5.4985805, -3.5684018]], dtype=float32)

time = 32975	action = 0	current_phase = 0	next_phase = 1	reward = -0.525717	array([[-2.1060333, -2.906402 ]], dtype=float32)

time = 32980	action = 0	current_phase = 0	next_phase = 1	reward = -0.372297	array([[-1.9557844, -2.440527 ]], dtype=float32)

time = 32985	action = 0	current_phase = 0	next_phase = 1	reward = -0.211218	array([[-1.9451299, -2.935251 ]], dtype=float32)

time = 32990	action = 0	current_phase = 0	next_phase = 1	reward = 0.356454	array([[-2.087382, -2.183993]], dtype=float32)

time = 32995	action = 1	current_phase = 0	next_phase = 1	reward = -1.419084	array([[-4.2061853, -3.1296785]], dtype=float32)

time = 33003	action = 0	current_phase = 1	next_phase = 0	reward = -0.594501	array([[-2.3041804, -2.7954717]], dtype=float32)

time = 33008	action = 0	current_phase = 1	next_phase = 0	reward = -0.448768	array([[-2.1230915, -2.8735046]], dtype=float32)

time = 33013	action = 0	current_phase = 1	next_phase = 0	reward = -0.287794	array([[-2.1583858, -2.8689427]], dtype=float32)

time = 33018	action = 0	current_phase = 1	next_phase = 0	reward = -0.163645	array([[-2.352129, -2.95079 ]], dtype=float32)

time = 33023	action = 0	current_phase = 1	next_phase = 0	reward = 0.080642	array([[-2.842796, -3.36623 ]], dtype=float32)

time = 33028	action = 1	current_phase = 1	next_phase = 0	reward = -1.905290	array([[-5.493106, -3.553381]], dtype=float32)

time = 33036	action = 0	current_phase = 0	next_phase = 1	reward = -0.509148	array([[-2.176579 , -2.9777977]], dtype=float32)

time = 33041	action = 0	current_phase = 0	next_phase = 1	reward = -0.354812	array([[-1.9563117, -2.4373198]], dtype=float32)

time = 33046	action = 0	current_phase = 0	next_phase = 1	reward = -0.204908	array([[-2.037162, -2.328   ]], dtype=float32)

time = 33051	action = 0	current_phase = 0	next_phase = 1	reward = 0.339057	array([[-2.2044308, -2.6194375]], dtype=float32)

time = 33056	action = 1	current_phase = 0	next_phase = 1	reward = -1.398153	array([[-4.1676316, -3.1855743]], dtype=float32)

time = 33064	action = 0	current_phase = 1	next_phase = 0	reward = -0.567654	array([[-2.1730185, -2.7740593]], dtype=float32)

time = 33069	action = 0	current_phase = 1	next_phase = 0	reward = -0.406640	array([[-1.9453773, -2.9827018]], dtype=float32)

time = 33074	action = 0	current_phase = 1	next_phase = 0	reward = -0.248582	array([[-1.9401293, -2.978765 ]], dtype=float32)

time = 33079	action = 0	current_phase = 1	next_phase = 0	reward = -0.168904	array([[-2.0386443, -3.4593573]], dtype=float32)

time = 33084	action = 0	current_phase = 1	next_phase = 0	reward = -0.060075	array([[-2.199835, -2.299397]], dtype=float32)

time = 33089	action = 1	current_phase = 1	next_phase = 0	reward = -2.006315	array([[-5.5005965, -3.5693746]], dtype=float32)

time = 33097	action = 0	current_phase = 0	next_phase = 1	reward = -0.469253	array([[-2.0712197, -2.8702707]], dtype=float32)

time = 33102	action = 0	current_phase = 0	next_phase = 1	reward = -0.313324	array([[-1.9564487, -2.4553316]], dtype=float32)

time = 33107	action = 1	current_phase = 0	next_phase = 1	reward = -0.749141	array([[-2.0903318, -1.966748 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0507 - val_loss: 0.1118

Epoch 2/50

 - 4s - loss: 0.0563 - val_loss: 0.1018

Epoch 3/50

 - 4s - loss: 0.0627 - val_loss: 0.1159

Epoch 4/50

 - 4s - loss: 0.0594 - val_loss: 0.1203

Epoch 5/50

 - 4s - loss: 0.0600 - val_loss: 0.1056

Epoch 6/50

 - 4s - loss: 0.0542 - val_loss: 0.1212

Epoch 7/50

 - 4s - loss: 0.0667 - val_loss: 0.1302

Epoch 8/50

 - 4s - loss: 0.0577 - val_loss: 0.1202

Epoch 9/50

 - 4s - loss: 0.0571 - val_loss: 0.1226

Epoch 10/50

 - 4s - loss: 0.0664 - val_loss: 0.1125

Epoch 11/50

 - 4s - loss: 0.0558 - val_loss: 0.1078

Epoch 12/50

 - 4s - loss: 0.0534 - val_loss: 0.1038

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 891, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 878, after forget

time = 33115	action = 1	current_phase = 1	next_phase = 0	reward = -1.355298	array([[-3.3490925, -3.10919  ]], dtype=float32)

time = 33123	action = 0	current_phase = 0	next_phase = 1	reward = -0.590884	array([[-2.0840907, -2.5125647]], dtype=float32)

time = 33128	action = 0	current_phase = 0	next_phase = 1	reward = -0.445897	array([[-1.9614359, -2.4760616]], dtype=float32)

time = 33133	action = 0	current_phase = 0	next_phase = 1	reward = -0.302761	array([[-2.1689692, -3.0527554]], dtype=float32)

time = 33138	action = 1	current_phase = 0	next_phase = 1	reward = -0.795494	array([[-2.2067497, -1.8864785]], dtype=float32)

time = 33146	action = 1	current_phase = 1	next_phase = 0	reward = -1.606165	array([[-4.061389 , -3.4833717]], dtype=float32)

time = 33154	action = 1	current_phase = 0	next_phase = 1	reward = -1.823418	array([[-2.783111 , -2.6064377]], dtype=float32)

time = 33162	action = 0	current_phase = 1	next_phase = 0	reward = -0.305361	array([[-1.9051985, -2.9965415]], dtype=float32)

time = 33167	action = 0	current_phase = 1	next_phase = 0	reward = -0.171699	array([[-1.3312563, -3.1484768]], dtype=float32)

time = 33172	action = 0	current_phase = 1	next_phase = 0	reward = 0.259675	array([[-2.2968385, -3.8345857]], dtype=float32)

time = 33177	action = 0	current_phase = 1	next_phase = 0	reward = -1.261035	array([[ 4.427359 , -3.6264577]], dtype=float32)

time = 33182	action = 1	current_phase = 1	next_phase = 0	reward = -2.008839	array([[-4.7368712, -3.504591 ]], dtype=float32)

time = 33190	action = 0	current_phase = 0	next_phase = 1	reward = -0.379007	array([[-2.0299232, -2.8618932]], dtype=float32)

time = 33195	action = 0	current_phase = 0	next_phase = 1	reward = -0.220615	array([[-1.957706 , -3.0179875]], dtype=float32)

time = 33200	action = 0	current_phase = 0	next_phase = 1	reward = 0.356844	array([[ 0.34503156, -2.6118026 ]], dtype=float32)

time = 33205	action = 1	current_phase = 0	next_phase = 1	reward = -1.419542	array([[-4.300332 , -3.2068732]], dtype=float32)

time = 33213	action = 0	current_phase = 1	next_phase = 0	reward = -0.591987	array([[-2.2993138, -2.904444 ]], dtype=float32)

time = 33218	action = 0	current_phase = 1	next_phase = 0	reward = -0.436656	array([[-2.1459236, -2.8518798]], dtype=float32)

time = 33223	action = 0	current_phase = 1	next_phase = 0	reward = -0.274903	array([[-2.138605, -2.857723]], dtype=float32)

time = 33228	action = 0	current_phase = 1	next_phase = 0	reward = -0.167062	array([[-2.3181095, -2.9671936]], dtype=float32)

time = 33233	action = 0	current_phase = 1	next_phase = 0	reward = 0.012652	array([[-2.830044, -3.300653]], dtype=float32)

time = 33238	action = 1	current_phase = 1	next_phase = 0	reward = -1.897365	array([[-5.370861 , -3.6307495]], dtype=float32)

time = 33246	action = 0	current_phase = 0	next_phase = 1	reward = -0.489390	array([[-2.1405962, -2.9145055]], dtype=float32)

time = 33251	action = 0	current_phase = 0	next_phase = 1	reward = -0.335240	array([[-1.9612433, -2.4780786]], dtype=float32)

time = 33256	action = 0	current_phase = 0	next_phase = 1	reward = -0.186105	array([[-2.0309913, -2.548497 ]], dtype=float32)

time = 33261	action = 0	current_phase = 0	next_phase = 1	reward = 0.319588	array([[-2.4654841, -2.6164036]], dtype=float32)

time = 33266	action = 1	current_phase = 0	next_phase = 1	reward = -1.607963	array([[-4.287452 , -3.2310264]], dtype=float32)

time = 33274	action = 0	current_phase = 1	next_phase = 0	reward = -0.550363	array([[-2.0647237, -2.717181 ]], dtype=float32)

time = 33279	action = 0	current_phase = 1	next_phase = 0	reward = -0.393765	array([[-1.9053966, -2.975959 ]], dtype=float32)

time = 33284	action = 0	current_phase = 1	next_phase = 0	reward = -0.239274	array([[-1.810047, -2.901671]], dtype=float32)

time = 33289	action = 0	current_phase = 1	next_phase = 0	reward = -0.179657	array([[-1.9403014, -3.4922047]], dtype=float32)

time = 33294	action = 1	current_phase = 1	next_phase = 0	reward = -0.535535	array([[-2.5210671, -2.2880707]], dtype=float32)

time = 33302	action = 0	current_phase = 0	next_phase = 1	reward = -0.614396	array([[-2.2256618, -2.8446198]], dtype=float32)

time = 33307	action = 0	current_phase = 0	next_phase = 1	reward = -0.464525	array([[-1.9656898, -2.4836738]], dtype=float32)

time = 33312	action = 0	current_phase = 0	next_phase = 1	reward = -0.318604	array([[-1.995885 , -2.9482732]], dtype=float32)

time = 33317	action = 1	current_phase = 0	next_phase = 1	reward = -0.746512	array([[-2.204562 , -1.8748168]], dtype=float32)

time = 33325	action = 0	current_phase = 1	next_phase = 0	reward = -0.774462	array([[ 4.958015 , -3.2899628]], dtype=float32)

time = 33330	action = 1	current_phase = 1	next_phase = 0	reward = -2.106955	array([[-5.140819, -3.726056]], dtype=float32)

time = 33338	action = 0	current_phase = 0	next_phase = 1	reward = -0.426576	array([[-2.0338116, -2.8956158]], dtype=float32)

time = 33343	action = 0	current_phase = 0	next_phase = 1	reward = -0.279709	array([[-2.157498 , -3.0504787]], dtype=float32)

time = 33348	action = 0	current_phase = 0	next_phase = 1	reward = -0.164466	array([[-2.431903, -3.043678]], dtype=float32)

time = 33353	action = 0	current_phase = 0	next_phase = 1	reward = 0.131131	array([[-2.757618, -3.055731]], dtype=float32)

time = 33358	action = 1	current_phase = 0	next_phase = 1	reward = -1.897776	array([[-5.367588 , -3.4987893]], dtype=float32)

time = 33366	action = 0	current_phase = 1	next_phase = 0	reward = -0.500067	array([[-2.1018338, -3.093765 ]], dtype=float32)

time = 33371	action = 0	current_phase = 1	next_phase = 0	reward = -0.341690	array([[-2.1431336, -2.8430781]], dtype=float32)

time = 33376	action = 0	current_phase = 1	next_phase = 0	reward = -0.190025	array([[-2.2967377, -2.8815265]], dtype=float32)

time = 33381	action = 0	current_phase = 1	next_phase = 0	reward = 0.307129	array([[-2.439158 , -3.7929034]], dtype=float32)

time = 33386	action = 1	current_phase = 1	next_phase = 0	reward = -1.556733	array([[-4.073447, -3.186684]], dtype=float32)

time = 33394	action = 0	current_phase = 0	next_phase = 1	reward = -0.559044	array([[-2.136042, -2.689154]], dtype=float32)

time = 33399	action = 0	current_phase = 0	next_phase = 1	reward = -0.401736	array([[-1.9563984, -2.4752972]], dtype=float32)

time = 33404	action = 0	current_phase = 0	next_phase = 1	reward = -0.246995	array([[-1.9589486, -3.0178103]], dtype=float32)

time = 33409	action = 0	current_phase = 0	next_phase = 1	reward = -0.184955	array([[-2.0111294, -3.1195004]], dtype=float32)

time = 33414	action = 1	current_phase = 0	next_phase = 1	reward = -0.457909	array([[-3.6562774, -2.3063445]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 3s - loss: 0.1041 - val_loss: 0.0446

Epoch 2/50

 - 4s - loss: 0.0870 - val_loss: 0.0437

Epoch 3/50

 - 4s - loss: 0.0576 - val_loss: 0.0467

Epoch 4/50

 - 4s - loss: 0.0697 - val_loss: 0.0506

Epoch 5/50

 - 4s - loss: 0.0937 - val_loss: 0.0508

Epoch 6/50

 - 4s - loss: 0.0571 - val_loss: 0.0490

Epoch 7/50

 - 4s - loss: 0.1007 - val_loss: 0.0542

Epoch 8/50

 - 4s - loss: 0.0758 - val_loss: 0.0535

Epoch 9/50

 - 4s - loss: 0.0638 - val_loss: 0.0531

Epoch 10/50

 - 4s - loss: 0.0634 - val_loss: 0.0540

Epoch 11/50

 - 4s - loss: 0.0537 - val_loss: 0.0516

Epoch 12/50

 - 4s - loss: 0.0905 - val_loss: 0.0498

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 898, after forget

length of memory (state 1, action 0): 1018, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 885, after forget

time = 33422	action = 0	current_phase = 1	next_phase = 0	reward = -0.633075	array([[-2.3083198, -2.7307422]], dtype=float32)

time = 33427	action = 0	current_phase = 1	next_phase = 0	reward = -0.480087	array([[-2.145272, -3.090699]], dtype=float32)

time = 33432	action = 0	current_phase = 1	next_phase = 0	reward = -0.327625	array([[-2.0419877, -2.848873 ]], dtype=float32)

time = 33437	action = 0	current_phase = 1	next_phase = 0	reward = -0.180116	array([[-2.1630082, -2.8361197]], dtype=float32)

time = 33442	action = 0	current_phase = 1	next_phase = 0	reward = 0.198049	array([[-2.4755876, -3.7168715]], dtype=float32)

time = 33447	action = 1	current_phase = 1	next_phase = 0	reward = -1.783463	array([[-5.4022045, -3.5579994]], dtype=float32)

time = 33455	action = 0	current_phase = 0	next_phase = 1	reward = -0.528230	array([[-2.102118 , -2.9711626]], dtype=float32)

time = 33460	action = 0	current_phase = 0	next_phase = 1	reward = -0.374133	array([[-1.9924101, -2.5124452]], dtype=float32)

time = 33465	action = 0	current_phase = 0	next_phase = 1	reward = -0.227317	array([[-1.9460958, -3.0288978]], dtype=float32)

time = 33470	action = 0	current_phase = 0	next_phase = 1	reward = 0.050452	array([[-2.02489  , -2.8334389]], dtype=float32)

time = 33475	action = 1	current_phase = 0	next_phase = 1	reward = -1.086498	array([[-3.9166565, -2.6557117]], dtype=float32)

time = 33483	action = 0	current_phase = 1	next_phase = 0	reward = -0.590420	array([[-2.2785053, -2.7473862]], dtype=float32)

time = 33488	action = 0	current_phase = 1	next_phase = 0	reward = -0.438506	array([[-2.1040456, -2.8243697]], dtype=float32)

time = 33493	action = 0	current_phase = 1	next_phase = 0	reward = -0.282753	array([[-2.1158402, -2.8213017]], dtype=float32)

time = 33498	action = 0	current_phase = 1	next_phase = 0	reward = -0.164775	array([[-2.3295422, -2.919649 ]], dtype=float32)

time = 33503	action = 0	current_phase = 1	next_phase = 0	reward = 0.217330	array([[-2.7237906, -3.4173164]], dtype=float32)

time = 33508	action = 1	current_phase = 1	next_phase = 0	reward = -1.837132	array([[-5.3959513, -3.4877458]], dtype=float32)

time = 33516	action = 0	current_phase = 0	next_phase = 1	reward = -0.487483	array([[-2.070907 , -2.9319248]], dtype=float32)

time = 33521	action = 0	current_phase = 0	next_phase = 1	reward = -0.328746	array([[-1.9927559, -2.5127757]], dtype=float32)

time = 33526	action = 0	current_phase = 0	next_phase = 1	reward = -0.183642	array([[-2.0807776, -2.1196003]], dtype=float32)

time = 33531	action = 0	current_phase = 0	next_phase = 1	reward = 0.306378	array([[-2.4202304, -2.5937378]], dtype=float32)

time = 33536	action = 1	current_phase = 0	next_phase = 1	reward = -1.556535	array([[-4.3068705, -3.1417089]], dtype=float32)

time = 33544	action = 0	current_phase = 1	next_phase = 0	reward = -0.555335	array([[-2.0760648, -2.6979454]], dtype=float32)

time = 33549	action = 0	current_phase = 1	next_phase = 0	reward = -0.396400	array([[-1.8552085, -2.9431465]], dtype=float32)

time = 33554	action = 0	current_phase = 1	next_phase = 0	reward = -0.244144	array([[-1.8940337, -2.9171512]], dtype=float32)

time = 33559	action = 0	current_phase = 1	next_phase = 0	reward = 0.109704	array([[-2.0396216, -3.4204628]], dtype=float32)

time = 33564	action = 1	current_phase = 1	next_phase = 0	reward = -0.753289	array([[-2.7155557, -2.3782818]], dtype=float32)

time = 33572	action = 0	current_phase = 0	next_phase = 1	reward = -0.616199	array([[-2.2560387, -2.877585 ]], dtype=float32)

time = 33577	action = 0	current_phase = 0	next_phase = 1	reward = -0.467389	array([[-1.9984726, -2.5175383]], dtype=float32)

time = 33582	action = 0	current_phase = 0	next_phase = 1	reward = -0.304964	array([[-1.9455762, -2.9011734]], dtype=float32)

time = 33587	action = 1	current_phase = 0	next_phase = 1	reward = -0.751596	array([[-2.2850938, -1.8665057]], dtype=float32)

time = 33595	action = 1	current_phase = 1	next_phase = 0	reward = -1.363789	array([[-3.2646441, -2.8013182]], dtype=float32)

time = 33603	action = 0	current_phase = 0	next_phase = 1	reward = -0.592274	array([[-2.255096, -2.837193]], dtype=float32)

time = 33608	action = 0	current_phase = 0	next_phase = 1	reward = -0.443562	array([[-1.9930481, -2.5124397]], dtype=float32)

time = 33613	action = 0	current_phase = 0	next_phase = 1	reward = -0.295139	array([[-1.9625484, -3.032514 ]], dtype=float32)

time = 33618	action = 1	current_phase = 0	next_phase = 1	reward = -0.768924	array([[-2.2493072, -1.8564802]], dtype=float32)

time = 33626	action = 0	current_phase = 1	next_phase = 0	reward = -0.952134	array([[ 5.2864237, -2.9629593]], dtype=float32)

time = 33631	action = 1	current_phase = 1	next_phase = 0	reward = -2.052988	array([[-4.791979, -3.518129]], dtype=float32)

time = 33639	action = 0	current_phase = 0	next_phase = 1	reward = -0.395299	array([[-2.0130315, -2.857328 ]], dtype=float32)

time = 33644	action = 0	current_phase = 0	next_phase = 1	reward = -0.236173	array([[-1.9474268, -3.0307586]], dtype=float32)

time = 33649	action = 0	current_phase = 0	next_phase = 1	reward = -0.184299	array([[-2.0558238, -3.2781355]], dtype=float32)

time = 33654	action = 1	current_phase = 0	next_phase = 1	reward = -0.488886	array([[-3.5719128, -2.227814 ]], dtype=float32)

time = 33662	action = 0	current_phase = 1	next_phase = 0	reward = -0.614956	array([[-2.627893 , -2.9993675]], dtype=float32)

time = 33667	action = 0	current_phase = 1	next_phase = 0	reward = -0.461215	array([[-2.1395972, -3.0730772]], dtype=float32)

time = 33672	action = 0	current_phase = 1	next_phase = 0	reward = -0.306696	array([[-2.1070416, -2.8207746]], dtype=float32)

time = 33677	action = 0	current_phase = 1	next_phase = 0	reward = -0.175821	array([[-2.329565, -2.909704]], dtype=float32)

time = 33682	action = 0	current_phase = 1	next_phase = 0	reward = 0.243970	array([[-2.7772853, -3.572198 ]], dtype=float32)

time = 33687	action = 1	current_phase = 1	next_phase = 0	reward = -1.782421	array([[-5.3715725, -3.4548514]], dtype=float32)

time = 33695	action = 0	current_phase = 0	next_phase = 1	reward = -0.534306	array([[-2.0989745, -2.96181  ]], dtype=float32)

time = 33700	action = 0	current_phase = 0	next_phase = 1	reward = -0.379114	array([[-1.9922211, -2.5136578]], dtype=float32)

time = 33705	action = 0	current_phase = 0	next_phase = 1	reward = -0.227788	array([[-1.946568 , -3.0289063]], dtype=float32)

time = 33710	action = 0	current_phase = 0	next_phase = 1	reward = 0.371475	array([[-2.1048532, -2.1246798]], dtype=float32)

time = 33715	action = 1	current_phase = 0	next_phase = 1	reward = -1.299300	array([[-4.208935 , -3.0441415]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1687 - val_loss: 0.0598

Epoch 2/50

 - 4s - loss: 0.1661 - val_loss: 0.0586

Epoch 3/50

 - 4s - loss: 0.1117 - val_loss: 0.0592

Epoch 4/50

 - 4s - loss: 0.1320 - val_loss: 0.0593

Epoch 5/50

 - 4s - loss: 0.1040 - val_loss: 0.0594

Epoch 6/50

 - 4s - loss: 0.0830 - val_loss: 0.0595

Epoch 7/50

 - 4s - loss: 0.0767 - val_loss: 0.0601

Epoch 8/50

 - 4s - loss: 0.0590 - val_loss: 0.0600

Epoch 9/50

 - 4s - loss: 0.0639 - val_loss: 0.0607

Epoch 10/50

 - 4s - loss: 0.0727 - val_loss: 0.0646

Epoch 11/50

 - 4s - loss: 0.0694 - val_loss: 0.0610

Epoch 12/50

 - 4s - loss: 0.0969 - val_loss: 0.0654

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 904, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 891, after forget

time = 33723	action = 0	current_phase = 1	next_phase = 0	reward = -0.579156	array([[-2.286531 , -2.6935818]], dtype=float32)

time = 33728	action = 0	current_phase = 1	next_phase = 0	reward = -0.426278	array([[-2.0412936, -2.7951007]], dtype=float32)

time = 33733	action = 0	current_phase = 1	next_phase = 0	reward = -0.257794	array([[-2.0343947, -2.7861   ]], dtype=float32)

time = 33738	action = 0	current_phase = 1	next_phase = 0	reward = -0.162516	array([[-2.040076, -3.160153]], dtype=float32)

time = 33743	action = 1	current_phase = 1	next_phase = 0	reward = -0.987966	array([[-2.2893267, -2.0995123]], dtype=float32)

time = 33751	action = 1	current_phase = 0	next_phase = 1	reward = -2.010294	array([[-4.5390835, -3.4980104]], dtype=float32)

time = 33759	action = 0	current_phase = 1	next_phase = 0	reward = -0.400011	array([[-1.7653518, -2.9132996]], dtype=float32)

time = 33764	action = 0	current_phase = 1	next_phase = 0	reward = -0.246895	array([[-1.7740631, -2.9194095]], dtype=float32)

time = 33769	action = 0	current_phase = 1	next_phase = 0	reward = -0.176187	array([[-1.9205453, -3.3223424]], dtype=float32)

time = 33774	action = 1	current_phase = 1	next_phase = 0	reward = -0.494886	array([[-1.8132533, -1.7269973]], dtype=float32)

time = 33782	action = 0	current_phase = 0	next_phase = 1	reward = -0.622934	array([[-2.1484416, -2.773391 ]], dtype=float32)

time = 33787	action = 0	current_phase = 0	next_phase = 1	reward = -0.469485	array([[-1.97948  , -2.5439925]], dtype=float32)

time = 33792	action = 0	current_phase = 0	next_phase = 1	reward = -0.312950	array([[-1.9186445, -3.0076082]], dtype=float32)

time = 33797	action = 1	current_phase = 0	next_phase = 1	reward = -0.745544	array([[-2.1668398, -1.8508035]], dtype=float32)

time = 33805	action = 0	current_phase = 1	next_phase = 0	reward = -0.734374	array([[ 1.9301666, -3.3974311]], dtype=float32)

time = 33810	action = 1	current_phase = 1	next_phase = 0	reward = -2.114798	array([[-5.1434903, -3.6689303]], dtype=float32)

time = 33818	action = 0	current_phase = 0	next_phase = 1	reward = -0.441247	array([[-2.0239823, -2.9031909]], dtype=float32)

time = 33823	action = 0	current_phase = 0	next_phase = 1	reward = -0.292488	array([[-1.9958678, -2.7854798]], dtype=float32)

time = 33828	action = 1	current_phase = 0	next_phase = 1	reward = -0.755405	array([[-2.2403293, -2.1636455]], dtype=float32)

time = 33836	action = 1	current_phase = 1	next_phase = 0	reward = -1.498610	array([[-3.471178, -3.321162]], dtype=float32)

time = 33844	action = 0	current_phase = 0	next_phase = 1	reward = -0.561949	array([[-2.372243 , -2.5583723]], dtype=float32)

time = 33849	action = 0	current_phase = 0	next_phase = 1	reward = -0.409478	array([[-1.9768786, -2.5349374]], dtype=float32)

time = 33854	action = 0	current_phase = 0	next_phase = 1	reward = -0.257257	array([[-1.9187813, -3.0161633]], dtype=float32)

time = 33859	action = 0	current_phase = 0	next_phase = 1	reward = -0.181032	array([[-1.9716772, -2.845699 ]], dtype=float32)

time = 33864	action = 1	current_phase = 0	next_phase = 1	reward = -0.491713	array([[-3.6043398, -2.3417048]], dtype=float32)

time = 33872	action = 0	current_phase = 1	next_phase = 0	reward = -0.617857	array([[-2.2544215, -2.7177532]], dtype=float32)

time = 33877	action = 0	current_phase = 1	next_phase = 0	reward = -0.466174	array([[-2.0309448, -3.0844727]], dtype=float32)

time = 33882	action = 0	current_phase = 1	next_phase = 0	reward = -0.313024	array([[-2.0309494, -2.7990897]], dtype=float32)

time = 33887	action = 0	current_phase = 1	next_phase = 0	reward = -0.174725	array([[-2.076635 , -2.9868944]], dtype=float32)

time = 33892	action = 0	current_phase = 1	next_phase = 0	reward = 0.282804	array([[-2.606537 , -3.6279948]], dtype=float32)

time = 33897	action = 1	current_phase = 1	next_phase = 0	reward = -1.724163	array([[-5.352705 , -3.4027355]], dtype=float32)

time = 33905	action = 0	current_phase = 0	next_phase = 1	reward = -0.512029	array([[-2.0718348, -2.9431717]], dtype=float32)

time = 33910	action = 0	current_phase = 0	next_phase = 1	reward = -0.364160	array([[-1.976187, -2.536583]], dtype=float32)

time = 33915	action = 0	current_phase = 0	next_phase = 1	reward = -0.216445	array([[-1.9181907, -3.0108259]], dtype=float32)

time = 33920	action = 1	current_phase = 0	next_phase = 1	reward = -1.117140	array([[-2.1279113, -2.0990663]], dtype=float32)

time = 33928	action = 0	current_phase = 1	next_phase = 0	reward = -1.464211	array([[-2.6371474, -3.8033097]], dtype=float32)

time = 33933	action = 0	current_phase = 1	next_phase = 0	reward = -1.663744	array([[-3.3329248, -3.5163777]], dtype=float32)

time = 33938	action = 1	current_phase = 1	next_phase = 0	reward = -1.695515	array([[-4.6512   , -3.2838063]], dtype=float32)

time = 33946	action = 0	current_phase = 0	next_phase = 1	reward = -0.195036	array([[-2.032587, -2.671854]], dtype=float32)

time = 33951	action = 0	current_phase = 0	next_phase = 1	reward = 0.290950	array([[-1.8413972, -3.8721304]], dtype=float32)

time = 33956	action = 1	current_phase = 0	next_phase = 1	reward = -1.610615	array([[-4.3963447, -3.1303759]], dtype=float32)

time = 33964	action = 0	current_phase = 1	next_phase = 0	reward = -0.564444	array([[-1.9249064, -2.6302502]], dtype=float32)

time = 33969	action = 0	current_phase = 1	next_phase = 0	reward = -0.407539	array([[-1.9401243, -2.8542173]], dtype=float32)

time = 33974	action = 0	current_phase = 1	next_phase = 0	reward = -0.252012	array([[-1.7912076, -2.9067957]], dtype=float32)

time = 33979	action = 0	current_phase = 1	next_phase = 0	reward = -0.166781	array([[-1.7982641, -3.4684935]], dtype=float32)

time = 33984	action = 1	current_phase = 1	next_phase = 0	reward = -0.366024	array([[-2.3805137, -2.2745643]], dtype=float32)

time = 33992	action = 0	current_phase = 0	next_phase = 1	reward = -0.623392	array([[-2.2455678, -2.9025767]], dtype=float32)

time = 33997	action = 0	current_phase = 0	next_phase = 1	reward = -0.475464	array([[-1.9844109, -2.544324 ]], dtype=float32)

time = 34002	action = 0	current_phase = 0	next_phase = 1	reward = -0.322364	array([[-1.9209852, -2.9921331]], dtype=float32)

time = 34007	action = 1	current_phase = 0	next_phase = 1	reward = -0.744122	array([[-2.0867107, -2.0186265]], dtype=float32)

time = 34015	action = 0	current_phase = 1	next_phase = 0	reward = -0.726562	array([[ 0.9482655, -3.1016326]], dtype=float32)

time = 34020	action = 1	current_phase = 1	next_phase = 0	reward = -2.113990	array([[-5.0148573, -3.7131457]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1523 - val_loss: 0.0391

Epoch 2/50

 - 4s - loss: 0.1339 - val_loss: 0.0392

Epoch 3/50

 - 4s - loss: 0.1505 - val_loss: 0.0440

Epoch 4/50

 - 4s - loss: 0.1696 - val_loss: 0.0421

Epoch 5/50

 - 4s - loss: 0.1286 - val_loss: 0.0427

Epoch 6/50

 - 4s - loss: 0.1292 - val_loss: 0.0449

Epoch 7/50

 - 4s - loss: 0.1169 - val_loss: 0.0452

Epoch 8/50

 - 4s - loss: 0.1346 - val_loss: 0.0472

Epoch 9/50

 - 4s - loss: 0.1219 - val_loss: 0.0474

Epoch 10/50

 - 4s - loss: 0.1207 - val_loss: 0.0463

Epoch 11/50

 - 4s - loss: 0.1492 - val_loss: 0.0506

length of memory (state 0, action 0): 1017, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 911, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 899, after forget

time = 34028	action = 0	current_phase = 0	next_phase = 1	reward = -0.446742	array([[-2.1670377, -2.9176345]], dtype=float32)

time = 34033	action = 0	current_phase = 0	next_phase = 1	reward = -0.284362	array([[-2.014182 , -2.8059697]], dtype=float32)

time = 34038	action = 0	current_phase = 0	next_phase = 1	reward = -0.162096	array([[-2.6013942, -3.247784 ]], dtype=float32)

time = 34043	action = 0	current_phase = 0	next_phase = 1	reward = 0.131658	array([[-2.8124912, -3.4534435]], dtype=float32)

time = 34048	action = 1	current_phase = 0	next_phase = 1	reward = -1.896859	array([[-5.482883 , -3.4099607]], dtype=float32)

time = 34056	action = 0	current_phase = 1	next_phase = 0	reward = -0.508292	array([[-2.0161617, -3.0495567]], dtype=float32)

time = 34061	action = 0	current_phase = 1	next_phase = 0	reward = -0.350934	array([[-2.1196244, -2.8171659]], dtype=float32)

time = 34066	action = 0	current_phase = 1	next_phase = 0	reward = -0.197666	array([[-2.1389058, -2.9268892]], dtype=float32)

time = 34071	action = 0	current_phase = 1	next_phase = 0	reward = 0.347030	array([[-2.3403559, -3.7218723]], dtype=float32)

time = 34076	action = 1	current_phase = 1	next_phase = 0	reward = -1.497645	array([[-4.716127 , -3.2655406]], dtype=float32)

time = 34084	action = 0	current_phase = 0	next_phase = 1	reward = -0.555255	array([[-2.1424167, -2.541915 ]], dtype=float32)

time = 34089	action = 0	current_phase = 0	next_phase = 1	reward = -0.386828	array([[-2.1016603, -2.4929864]], dtype=float32)

time = 34094	action = 0	current_phase = 0	next_phase = 1	reward = -0.229472	array([[-2.0068774, -2.8064249]], dtype=float32)

time = 34099	action = 0	current_phase = 0	next_phase = 1	reward = -0.182547	array([[-2.0747368, -2.9357226]], dtype=float32)

time = 34104	action = 1	current_phase = 0	next_phase = 1	reward = -0.592018	array([[-3.7071443, -2.166864 ]], dtype=float32)

time = 34112	action = 0	current_phase = 1	next_phase = 0	reward = -0.619752	array([[-2.3629205, -2.6985326]], dtype=float32)

time = 34117	action = 0	current_phase = 1	next_phase = 0	reward = -0.467375	array([[-2.1214278, -3.1095142]], dtype=float32)

time = 34122	action = 0	current_phase = 1	next_phase = 0	reward = -0.322926	array([[-2.1400266, -2.7864044]], dtype=float32)

time = 34127	action = 0	current_phase = 1	next_phase = 0	reward = -0.180823	array([[-2.328163 , -2.8375125]], dtype=float32)

time = 34132	action = 0	current_phase = 1	next_phase = 0	reward = 0.187614	array([[-2.7027605, -3.5731146]], dtype=float32)

time = 34137	action = 1	current_phase = 1	next_phase = 0	reward = -1.788037	array([[-5.419837 , -3.5540586]], dtype=float32)

time = 34145	action = 0	current_phase = 0	next_phase = 1	reward = -0.540853	array([[-2.204822 , -2.9401932]], dtype=float32)

time = 34150	action = 0	current_phase = 0	next_phase = 1	reward = -0.396868	array([[-2.101438 , -2.4935734]], dtype=float32)

time = 34155	action = 0	current_phase = 0	next_phase = 1	reward = -0.247646	array([[-2.0062668, -2.8064775]], dtype=float32)

time = 34160	action = 0	current_phase = 0	next_phase = 1	reward = -0.211884	array([[-2.0542755, -2.8563054]], dtype=float32)

time = 34165	action = 1	current_phase = 0	next_phase = 1	reward = -0.794893	array([[-3.7039733, -2.171501 ]], dtype=float32)

time = 34173	action = 0	current_phase = 1	next_phase = 0	reward = -0.597777	array([[-2.3395796, -2.7261705]], dtype=float32)

time = 34178	action = 0	current_phase = 1	next_phase = 0	reward = -0.443555	array([[-2.147782 , -2.8053057]], dtype=float32)

time = 34183	action = 0	current_phase = 1	next_phase = 0	reward = -0.284145	array([[-2.1451406, -2.8074727]], dtype=float32)

time = 34188	action = 0	current_phase = 1	next_phase = 0	reward = -0.164885	array([[-2.2798662, -2.9847968]], dtype=float32)

time = 34193	action = 0	current_phase = 1	next_phase = 0	reward = 0.021506	array([[-2.734759 , -3.4878795]], dtype=float32)

time = 34198	action = 1	current_phase = 1	next_phase = 0	reward = -1.896863	array([[-5.4346147, -3.5549128]], dtype=float32)

time = 34206	action = 0	current_phase = 0	next_phase = 1	reward = -0.487419	array([[-2.1944478, -2.9279528]], dtype=float32)

time = 34211	action = 0	current_phase = 0	next_phase = 1	reward = -0.330529	array([[-2.092688 , -2.5383449]], dtype=float32)

time = 34216	action = 1	current_phase = 0	next_phase = 1	reward = -1.304262	array([[-2.146383 , -1.8748717]], dtype=float32)

time = 34224	action = 1	current_phase = 1	next_phase = 0	reward = -0.591028	array([[-2.4755104, -2.1672916]], dtype=float32)

time = 34232	action = 0	current_phase = 0	next_phase = 1	reward = -0.623945	array([[-2.1648304, -2.5233736]], dtype=float32)

time = 34237	action = 0	current_phase = 0	next_phase = 1	reward = -0.468276	array([[-2.1298594, -2.4960735]], dtype=float32)

time = 34242	action = 0	current_phase = 0	next_phase = 1	reward = -0.310470	array([[-2.014981 , -2.8029368]], dtype=float32)

time = 34247	action = 1	current_phase = 0	next_phase = 1	reward = -1.040500	array([[-2.3302937, -1.3715572]], dtype=float32)

time = 34255	action = 1	current_phase = 1	next_phase = 0	reward = -1.077255	array([[-3.3794851, -3.1718934]], dtype=float32)

time = 34263	action = 0	current_phase = 0	next_phase = 1	reward = -0.581559	array([[-2.1364472, -2.5049026]], dtype=float32)

time = 34268	action = 0	current_phase = 0	next_phase = 1	reward = -0.422404	array([[-2.1079829, -2.501289 ]], dtype=float32)

time = 34273	action = 0	current_phase = 0	next_phase = 1	reward = -0.272649	array([[-2.0127926, -2.8069806]], dtype=float32)

time = 34278	action = 1	current_phase = 0	next_phase = 1	reward = -0.765038	array([[-2.2478082, -1.3565781]], dtype=float32)

time = 34286	action = 0	current_phase = 1	next_phase = 0	reward = -1.007596	array([[ 0.6881522, -3.6819422]], dtype=float32)

time = 34291	action = 1	current_phase = 1	next_phase = 0	reward = -2.054471	array([[-4.128868, -3.63627 ]], dtype=float32)

time = 34299	action = 0	current_phase = 0	next_phase = 1	reward = -0.394256	array([[-2.1418543, -2.876868 ]], dtype=float32)

time = 34304	action = 0	current_phase = 0	next_phase = 1	reward = -0.239129	array([[-2.0081966, -2.8067093]], dtype=float32)

time = 34309	action = 0	current_phase = 0	next_phase = 1	reward = -0.185698	array([[-1.9042104, -3.0588589]], dtype=float32)

time = 34314	action = 1	current_phase = 0	next_phase = 1	reward = -0.557916	array([[-3.6799707, -2.0671616]], dtype=float32)

time = 34322	action = 0	current_phase = 1	next_phase = 0	reward = -0.614550	array([[-2.6857195, -3.013048 ]], dtype=float32)

time = 34327	action = 0	current_phase = 1	next_phase = 0	reward = -0.455570	array([[-1.6003542, -3.1515307]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0788 - val_loss: 0.1481

Epoch 2/50

 - 4s - loss: 0.1219 - val_loss: 0.1425

Epoch 3/50

 - 4s - loss: 0.0563 - val_loss: 0.1333

Epoch 4/50

 - 4s - loss: 0.0636 - val_loss: 0.1379

Epoch 5/50

 - 4s - loss: 0.0695 - val_loss: 0.1410

Epoch 6/50

 - 4s - loss: 0.0588 - val_loss: 0.1363

Epoch 7/50

 - 4s - loss: 0.0614 - val_loss: 0.1435

Epoch 8/50

 - 4s - loss: 0.0726 - val_loss: 0.1410

Epoch 9/50

 - 4s - loss: 0.0514 - val_loss: 0.1394

Epoch 10/50

 - 4s - loss: 0.0749 - val_loss: 0.1410

Epoch 11/50

 - 4s - loss: 0.0616 - val_loss: 0.1411

Epoch 12/50

 - 4s - loss: 0.0937 - val_loss: 0.1396

Epoch 13/50

 - 4s - loss: 0.0513 - val_loss: 0.1384

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 918, after forget

length of memory (state 1, action 0): 1017, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 905, after forget

time = 34332	action = 0	current_phase = 1	next_phase = 0	reward = -0.298694	array([[-2.0897086, -2.787319 ]], dtype=float32)

time = 34337	action = 0	current_phase = 1	next_phase = 0	reward = -0.170572	array([[-2.2857783, -2.9618568]], dtype=float32)

time = 34342	action = 0	current_phase = 1	next_phase = 0	reward = 0.121410	array([[-2.5987039, -3.5829918]], dtype=float32)

time = 34347	action = 1	current_phase = 1	next_phase = 0	reward = -1.789189	array([[-5.380305 , -3.5925899]], dtype=float32)

time = 34355	action = 0	current_phase = 0	next_phase = 1	reward = -0.521956	array([[-2.1207933, -2.974737 ]], dtype=float32)

time = 34360	action = 0	current_phase = 0	next_phase = 1	reward = -0.364051	array([[-2.0304306, -2.5967064]], dtype=float32)

time = 34365	action = 0	current_phase = 0	next_phase = 1	reward = -0.201553	array([[-1.9569778, -2.880763 ]], dtype=float32)

time = 34370	action = 1	current_phase = 0	next_phase = 1	reward = -1.095064	array([[-2.3760147, -1.9778911]], dtype=float32)

time = 34378	action = 0	current_phase = 1	next_phase = 0	reward = -1.462990	array([[-3.4821851, -3.7969894]], dtype=float32)

time = 34383	action = 0	current_phase = 1	next_phase = 0	reward = -1.663063	array([[-1.3707027, -3.509981 ]], dtype=float32)

time = 34388	action = 1	current_phase = 1	next_phase = 0	reward = -1.702789	array([[-4.6918283, -3.3302875]], dtype=float32)

time = 34396	action = 0	current_phase = 0	next_phase = 1	reward = -0.191043	array([[-2.0910683, -2.4851575]], dtype=float32)

time = 34401	action = 0	current_phase = 0	next_phase = 1	reward = 0.312493	array([[-2.1427402, -3.709426 ]], dtype=float32)

time = 34406	action = 1	current_phase = 0	next_phase = 1	reward = -1.502942	array([[-4.514067 , -3.0418797]], dtype=float32)

time = 34414	action = 0	current_phase = 1	next_phase = 0	reward = -0.555549	array([[-2.0502825, -2.6994498]], dtype=float32)

time = 34419	action = 0	current_phase = 1	next_phase = 0	reward = -0.390196	array([[-1.8789065, -2.948119 ]], dtype=float32)

time = 34424	action = 0	current_phase = 1	next_phase = 0	reward = -0.235008	array([[-1.8926753, -2.8727355]], dtype=float32)

time = 34429	action = 0	current_phase = 1	next_phase = 0	reward = 0.111567	array([[-1.8949647, -3.4883456]], dtype=float32)

time = 34434	action = 1	current_phase = 1	next_phase = 0	reward = -0.709503	array([[-2.7480357, -2.3301415]], dtype=float32)

time = 34442	action = 0	current_phase = 0	next_phase = 1	reward = -0.617117	array([[-2.2422063, -2.8311682]], dtype=float32)

time = 34447	action = 0	current_phase = 0	next_phase = 1	reward = -0.461068	array([[-2.055515, -2.551243]], dtype=float32)

time = 34452	action = 0	current_phase = 0	next_phase = 1	reward = -0.308432	array([[-1.9703128, -2.8434322]], dtype=float32)

time = 34457	action = 1	current_phase = 0	next_phase = 1	reward = -0.741453	array([[-2.2279294, -1.4398754]], dtype=float32)

time = 34465	action = 0	current_phase = 1	next_phase = 0	reward = -0.720549	array([[-1.9838192, -3.7826602]], dtype=float32)

time = 34470	action = 1	current_phase = 1	next_phase = 0	reward = -2.099174	array([[-5.1483064, -3.704451 ]], dtype=float32)

time = 34478	action = 0	current_phase = 0	next_phase = 1	reward = -0.420443	array([[-2.0284047, -2.971917 ]], dtype=float32)

time = 34483	action = 0	current_phase = 0	next_phase = 1	reward = -0.265909	array([[-1.9700745, -2.8720486]], dtype=float32)

time = 34488	action = 0	current_phase = 0	next_phase = 1	reward = -0.158493	array([[-2.4634857, -3.0468972]], dtype=float32)

time = 34493	action = 1	current_phase = 0	next_phase = 1	reward = -0.988497	array([[-3.4230225, -2.604786 ]], dtype=float32)

time = 34501	action = 0	current_phase = 1	next_phase = 0	reward = -1.172955	array([[-1.6856241, -3.503638 ]], dtype=float32)

time = 34506	action = 0	current_phase = 1	next_phase = 0	reward = -1.042096	array([[-2.1251895, -2.9587376]], dtype=float32)

time = 34511	action = 0	current_phase = 1	next_phase = 0	reward = -0.909876	array([[-2.5990539, -2.894306 ]], dtype=float32)

time = 34516	action = 0	current_phase = 1	next_phase = 0	reward = -0.776340	array([[-2.2140865, -2.9367468]], dtype=float32)

time = 34521	action = 1	current_phase = 1	next_phase = 0	reward = -1.320268	array([[-4.5652905, -3.5931969]], dtype=float32)

time = 34529	action = 1	current_phase = 0	next_phase = 1	reward = -2.007592	array([[-5.1109633, -3.5078995]], dtype=float32)

time = 34537	action = 0	current_phase = 1	next_phase = 0	reward = -0.463438	array([[-2.1399748, -3.1247375]], dtype=float32)

time = 34542	action = 0	current_phase = 1	next_phase = 0	reward = -0.307589	array([[-2.1131017, -2.8203638]], dtype=float32)

time = 34547	action = 0	current_phase = 1	next_phase = 0	reward = -0.172241	array([[-2.250449 , -2.8801844]], dtype=float32)

time = 34552	action = 0	current_phase = 1	next_phase = 0	reward = 0.203971	array([[-2.3707001, -3.7892952]], dtype=float32)

time = 34557	action = 1	current_phase = 1	next_phase = 0	reward = -1.735636	array([[-5.251063, -3.589369]], dtype=float32)

time = 34565	action = 0	current_phase = 0	next_phase = 1	reward = -0.535859	array([[-2.116627 , -2.9763875]], dtype=float32)

time = 34570	action = 0	current_phase = 0	next_phase = 1	reward = -0.384870	array([[-2.0461626, -2.541247 ]], dtype=float32)

time = 34575	action = 0	current_phase = 0	next_phase = 1	reward = -0.236810	array([[-1.9573618, -2.887534 ]], dtype=float32)

time = 34580	action = 1	current_phase = 0	next_phase = 1	reward = -0.942524	array([[-2.151042 , -1.7091701]], dtype=float32)

time = 34588	action = 0	current_phase = 1	next_phase = 0	reward = -1.456875	array([[ 0.1331773, -3.6603963]], dtype=float32)

time = 34593	action = 1	current_phase = 1	next_phase = 0	reward = -1.967227	array([[-4.3006387, -3.5894773]], dtype=float32)

time = 34601	action = 0	current_phase = 0	next_phase = 1	reward = -0.345176	array([[-2.073714 , -2.9640923]], dtype=float32)

time = 34606	action = 0	current_phase = 0	next_phase = 1	reward = -0.194882	array([[-1.9559245, -2.8791358]], dtype=float32)

time = 34611	action = 1	current_phase = 0	next_phase = 1	reward = -1.204739	array([[-2.5614471, -2.5603144]], dtype=float32)

time = 34619	action = 0	current_phase = 1	next_phase = 0	reward = -1.599565	array([[-3.7114017, -3.837214 ]], dtype=float32)

time = 34624	action = 0	current_phase = 1	next_phase = 0	reward = -1.638812	array([[ 7.5201507, -3.5829833]], dtype=float32)

time = 34629	action = 1	current_phase = 1	next_phase = 0	reward = -1.637826	array([[-4.6665187, -3.4562712]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1287 - val_loss: 0.0595

Epoch 2/50

 - 4s - loss: 0.1232 - val_loss: 0.0592

Epoch 3/50

 - 4s - loss: 0.0818 - val_loss: 0.0596

Epoch 4/50

 - 4s - loss: 0.0911 - val_loss: 0.0602

Epoch 5/50

 - 4s - loss: 0.0929 - val_loss: 0.0597

Epoch 6/50

 - 4s - loss: 0.0970 - val_loss: 0.0602

Epoch 7/50

 - 4s - loss: 0.0956 - val_loss: 0.0636

Epoch 8/50

 - 4s - loss: 0.0820 - val_loss: 0.0623

Epoch 9/50

 - 4s - loss: 0.0750 - val_loss: 0.0618

Epoch 10/50

 - 4s - loss: 0.0814 - val_loss: 0.0629

Epoch 11/50

 - 4s - loss: 0.0811 - val_loss: 0.0613

Epoch 12/50

 - 4s - loss: 0.0742 - val_loss: 0.0623

length of memory (state 0, action 0): 1016, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 925, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 913, after forget

time = 34637	action = 1	current_phase = 0	next_phase = 1	reward = -1.037535	array([[-2.2516744, -1.8242717]], dtype=float32)

time = 34645	action = 1	current_phase = 1	next_phase = 0	reward = -1.027359	array([[-3.124227 , -2.3339474]], dtype=float32)

time = 34653	action = 0	current_phase = 0	next_phase = 1	reward = -0.585860	array([[-2.0301328, -2.857456 ]], dtype=float32)

time = 34658	action = 0	current_phase = 0	next_phase = 1	reward = -0.423212	array([[-1.9519125, -2.834315 ]], dtype=float32)

time = 34663	action = 0	current_phase = 0	next_phase = 1	reward = -0.260717	array([[-1.9795842, -2.8441498]], dtype=float32)

time = 34668	action = 0	current_phase = 0	next_phase = 1	reward = -0.165133	array([[-2.3172245, -2.8673978]], dtype=float32)

time = 34673	action = 0	current_phase = 0	next_phase = 1	reward = -0.064080	array([[-2.877874 , -3.8392863]], dtype=float32)

time = 34678	action = 1	current_phase = 0	next_phase = 1	reward = -1.899585	array([[-6.197324 , -3.5614243]], dtype=float32)

time = 34686	action = 0	current_phase = 1	next_phase = 0	reward = -0.489752	array([[-2.0706415, -3.1172242]], dtype=float32)

time = 34691	action = 0	current_phase = 1	next_phase = 0	reward = -0.324024	array([[-2.082121 , -2.8613818]], dtype=float32)

time = 34696	action = 0	current_phase = 1	next_phase = 0	reward = -0.181337	array([[-2.1140046, -2.9256392]], dtype=float32)

time = 34701	action = 0	current_phase = 1	next_phase = 0	reward = 0.282322	array([[-2.336466 , -3.7542775]], dtype=float32)

time = 34706	action = 1	current_phase = 1	next_phase = 0	reward = -1.612500	array([[-5.010039 , -3.3235407]], dtype=float32)

time = 34714	action = 0	current_phase = 0	next_phase = 1	reward = -0.563048	array([[-2.0573163, -2.5710514]], dtype=float32)

time = 34719	action = 0	current_phase = 0	next_phase = 1	reward = -0.402287	array([[-2.0278351, -2.529988 ]], dtype=float32)

time = 34724	action = 0	current_phase = 0	next_phase = 1	reward = -0.247350	array([[-1.960669, -2.843277]], dtype=float32)

time = 34729	action = 0	current_phase = 0	next_phase = 1	reward = -0.191751	array([[-2.0555658, -2.9409797]], dtype=float32)

time = 34734	action = 1	current_phase = 0	next_phase = 1	reward = -1.430299	array([[-3.7000706, -2.7319183]], dtype=float32)

time = 34742	action = 0	current_phase = 1	next_phase = 0	reward = -1.159387	array([[ 1.5990834, -3.7559516]], dtype=float32)

time = 34747	action = 0	current_phase = 1	next_phase = 0	reward = -1.022326	array([[-0.07972197, -3.4446707 ]], dtype=float32)

time = 34752	action = 0	current_phase = 1	next_phase = 0	reward = -0.882665	array([[-2.4266107, -2.8820667]], dtype=float32)

time = 34757	action = 0	current_phase = 1	next_phase = 0	reward = -0.768473	array([[-2.562207 , -2.9646673]], dtype=float32)

time = 34762	action = 0	current_phase = 1	next_phase = 0	reward = -0.437720	array([[-2.9393368, -3.3630068]], dtype=float32)

time = 34767	action = 1	current_phase = 1	next_phase = 0	reward = -1.761596	array([[-5.428756 , -3.5020127]], dtype=float32)

time = 34775	action = 0	current_phase = 0	next_phase = 1	reward = -0.523112	array([[-2.0643282, -2.592259 ]], dtype=float32)

time = 34780	action = 0	current_phase = 0	next_phase = 1	reward = -0.366119	array([[-2.0264993, -2.5347745]], dtype=float32)

time = 34785	action = 0	current_phase = 0	next_phase = 1	reward = -0.211705	array([[-1.9610255, -2.8428924]], dtype=float32)

time = 34790	action = 0	current_phase = 0	next_phase = 1	reward = 0.336526	array([[-2.1219156, -2.6622427]], dtype=float32)

time = 34795	action = 1	current_phase = 0	next_phase = 1	reward = -1.370398	array([[-4.3443317, -3.1607707]], dtype=float32)

time = 34803	action = 0	current_phase = 1	next_phase = 0	reward = -0.587704	array([[-2.289467 , -2.8015285]], dtype=float32)

time = 34808	action = 0	current_phase = 1	next_phase = 0	reward = -0.433846	array([[-2.089562 , -2.8579931]], dtype=float32)

time = 34813	action = 0	current_phase = 1	next_phase = 0	reward = -0.280389	array([[-2.0723808, -2.8111458]], dtype=float32)

time = 34818	action = 0	current_phase = 1	next_phase = 0	reward = -0.165630	array([[-2.2539985, -2.939061 ]], dtype=float32)

time = 34823	action = 0	current_phase = 1	next_phase = 0	reward = 0.032275	array([[-2.8524926, -3.2699554]], dtype=float32)

time = 34828	action = 1	current_phase = 1	next_phase = 0	reward = -1.891796	array([[-5.3560376, -3.6206725]], dtype=float32)

time = 34836	action = 0	current_phase = 0	next_phase = 1	reward = -0.481151	array([[-2.0691164, -2.9300613]], dtype=float32)

time = 34841	action = 0	current_phase = 0	next_phase = 1	reward = -0.327457	array([[-2.0234196, -2.537081 ]], dtype=float32)

time = 34846	action = 0	current_phase = 0	next_phase = 1	reward = -0.188292	array([[-2.0178373, -2.5079768]], dtype=float32)

time = 34851	action = 1	current_phase = 0	next_phase = 1	reward = -1.302111	array([[-2.340176 , -2.0304728]], dtype=float32)

time = 34859	action = 0	current_phase = 1	next_phase = 0	reward = -1.600027	array([[-2.9987879, -3.9403844]], dtype=float32)

time = 34864	action = 0	current_phase = 1	next_phase = 0	reward = -1.646089	array([[-1.8055986, -3.4839776]], dtype=float32)

time = 34869	action = 1	current_phase = 1	next_phase = 0	reward = -1.673700	array([[-4.6156645, -3.2773879]], dtype=float32)

time = 34877	action = 1	current_phase = 0	next_phase = 1	reward = -1.036128	array([[-2.1697702, -1.8375007]], dtype=float32)

time = 34885	action = 1	current_phase = 1	next_phase = 0	reward = -1.067111	array([[-2.8531017, -2.306722 ]], dtype=float32)

time = 34893	action = 0	current_phase = 0	next_phase = 1	reward = -0.590979	array([[-1.9611448, -2.8497243]], dtype=float32)

time = 34898	action = 0	current_phase = 0	next_phase = 1	reward = -0.446359	array([[-1.9965484, -2.824579 ]], dtype=float32)

time = 34903	action = 0	current_phase = 0	next_phase = 1	reward = -0.290314	array([[-1.9717699, -2.8439386]], dtype=float32)

time = 34908	action = 0	current_phase = 0	next_phase = 1	reward = -0.164865	array([[-2.416876, -2.915191]], dtype=float32)

time = 34913	action = 0	current_phase = 0	next_phase = 1	reward = 0.027483	array([[-2.6837497, -3.8755546]], dtype=float32)

time = 34918	action = 1	current_phase = 0	next_phase = 1	reward = -1.890503	array([[-6.217199, -3.549642]], dtype=float32)

time = 34926	action = 0	current_phase = 1	next_phase = 0	reward = -0.480213	array([[-2.1388712, -3.1699102]], dtype=float32)

time = 34931	action = 0	current_phase = 1	next_phase = 0	reward = -0.324043	array([[-2.060681, -2.868705]], dtype=float32)

time = 34936	action = 0	current_phase = 1	next_phase = 0	reward = -0.191266	array([[-2.091084 , -2.9454868]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1104 - val_loss: 0.0310

Epoch 2/50

 - 4s - loss: 0.1055 - val_loss: 0.0335

Epoch 3/50

 - 4s - loss: 0.1309 - val_loss: 0.0326

Epoch 4/50

 - 4s - loss: 0.0827 - val_loss: 0.0325

Epoch 5/50

 - 4s - loss: 0.0653 - val_loss: 0.0314

Epoch 6/50

 - 4s - loss: 0.0595 - val_loss: 0.0335

Epoch 7/50

 - 4s - loss: 0.0573 - val_loss: 0.0337

Epoch 8/50

 - 4s - loss: 0.0817 - val_loss: 0.0339

Epoch 9/50

 - 4s - loss: 0.0948 - val_loss: 0.0355

Epoch 10/50

 - 4s - loss: 0.0881 - val_loss: 0.0311

Epoch 11/50

 - 4s - loss: 0.0583 - val_loss: 0.0341

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 932, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 919, after forget

time = 34941	action = 0	current_phase = 1	next_phase = 0	reward = 0.322736	array([[-2.4256005, -3.7189689]], dtype=float32)

time = 34946	action = 1	current_phase = 1	next_phase = 0	reward = -1.659181	array([[-5.0739346, -3.3007438]], dtype=float32)

time = 34954	action = 0	current_phase = 0	next_phase = 1	reward = -0.544719	array([[-1.9737681, -2.642924 ]], dtype=float32)

time = 34959	action = 0	current_phase = 0	next_phase = 1	reward = -0.382696	array([[-1.9333954, -2.6072533]], dtype=float32)

time = 34964	action = 0	current_phase = 0	next_phase = 1	reward = -0.229578	array([[-1.7325094, -2.9675367]], dtype=float32)

time = 34969	action = 0	current_phase = 0	next_phase = 1	reward = -0.204608	array([[-2.0295186, -2.6270099]], dtype=float32)

time = 34974	action = 1	current_phase = 0	next_phase = 1	reward = -0.573277	array([[-3.608674 , -2.3898737]], dtype=float32)

time = 34982	action = 0	current_phase = 1	next_phase = 0	reward = -0.619611	array([[-2.3422992, -2.7839518]], dtype=float32)

time = 34987	action = 0	current_phase = 1	next_phase = 0	reward = -0.460276	array([[-2.1790633, -3.214788 ]], dtype=float32)

time = 34992	action = 0	current_phase = 1	next_phase = 0	reward = -0.312221	array([[-2.114343, -2.876579]], dtype=float32)

time = 34997	action = 0	current_phase = 1	next_phase = 0	reward = -0.176634	array([[-2.3537295, -2.9189844]], dtype=float32)

time = 35002	action = 0	current_phase = 1	next_phase = 0	reward = 0.268428	array([[-2.7550185, -3.518502 ]], dtype=float32)

time = 35007	action = 1	current_phase = 1	next_phase = 0	reward = -1.784396	array([[-5.4024444, -3.4939203]], dtype=float32)

time = 35015	action = 0	current_phase = 0	next_phase = 1	reward = -0.534635	array([[-2.0710695, -2.9930613]], dtype=float32)

time = 35020	action = 0	current_phase = 0	next_phase = 1	reward = -0.378542	array([[-1.9321889, -2.6096375]], dtype=float32)

time = 35025	action = 0	current_phase = 0	next_phase = 1	reward = -0.221689	array([[-1.733609 , -2.9663782]], dtype=float32)

time = 35030	action = 1	current_phase = 0	next_phase = 1	reward = -0.993176	array([[-2.3203077, -2.1548028]], dtype=float32)

time = 35038	action = 0	current_phase = 1	next_phase = 0	reward = -1.460037	array([[-3.6076694, -3.7733228]], dtype=float32)

time = 35043	action = 0	current_phase = 1	next_phase = 0	reward = -1.655499	array([[-1.2923974, -3.5299895]], dtype=float32)

time = 35048	action = 1	current_phase = 1	next_phase = 0	reward = -1.669388	array([[-4.692037 , -3.3826847]], dtype=float32)

time = 35056	action = 0	current_phase = 0	next_phase = 1	reward = -0.179773	array([[-1.8956002, -2.4405649]], dtype=float32)

time = 35061	action = 0	current_phase = 0	next_phase = 1	reward = 0.278727	array([[-2.568853 , -3.7011952]], dtype=float32)

time = 35066	action = 1	current_phase = 0	next_phase = 1	reward = -1.555400	array([[-4.467201 , -3.1714396]], dtype=float32)

time = 35074	action = 0	current_phase = 1	next_phase = 0	reward = -0.549131	array([[-2.129665 , -2.8096464]], dtype=float32)

time = 35079	action = 0	current_phase = 1	next_phase = 0	reward = -0.397547	array([[-1.8805567, -3.0823565]], dtype=float32)

time = 35084	action = 0	current_phase = 1	next_phase = 0	reward = -0.235654	array([[-1.9047987, -2.9886107]], dtype=float32)

time = 35089	action = 0	current_phase = 1	next_phase = 0	reward = -0.180701	array([[-2.0098174, -3.4641063]], dtype=float32)

time = 35094	action = 1	current_phase = 1	next_phase = 0	reward = -0.486089	array([[-2.4023087, -2.2048025]], dtype=float32)

time = 35102	action = 0	current_phase = 0	next_phase = 1	reward = -0.620734	array([[-2.2611775, -3.0383   ]], dtype=float32)

time = 35107	action = 0	current_phase = 0	next_phase = 1	reward = -0.465399	array([[-1.9404848, -2.6066656]], dtype=float32)

time = 35112	action = 0	current_phase = 0	next_phase = 1	reward = -0.305722	array([[-1.73989 , -2.940161]], dtype=float32)

time = 35117	action = 1	current_phase = 0	next_phase = 1	reward = -0.746374	array([[-2.2291212, -1.5153257]], dtype=float32)

time = 35125	action = 1	current_phase = 1	next_phase = 0	reward = -1.353852	array([[-3.984179 , -3.6314373]], dtype=float32)

time = 35133	action = 0	current_phase = 0	next_phase = 1	reward = -0.583114	array([[-2.048758 , -2.6432958]], dtype=float32)

time = 35138	action = 0	current_phase = 0	next_phase = 1	reward = -0.428698	array([[-1.916306 , -2.6460292]], dtype=float32)

time = 35143	action = 0	current_phase = 0	next_phase = 1	reward = -0.275993	array([[-1.7391294, -2.9681408]], dtype=float32)

time = 35148	action = 1	current_phase = 0	next_phase = 1	reward = -0.781856	array([[-2.4838128, -1.5895066]], dtype=float32)

time = 35156	action = 0	current_phase = 1	next_phase = 0	reward = -1.117126	array([[-3.6123087, -3.7261128]], dtype=float32)

time = 35161	action = 1	current_phase = 1	next_phase = 0	reward = -2.076084	array([[-4.2884455, -3.6435206]], dtype=float32)

time = 35169	action = 0	current_phase = 0	next_phase = 1	reward = -0.416460	array([[-2.0211756, -2.9402702]], dtype=float32)

time = 35174	action = 0	current_phase = 0	next_phase = 1	reward = -0.256513	array([[-1.7342212, -2.967678 ]], dtype=float32)

time = 35179	action = 0	current_phase = 0	next_phase = 1	reward = -0.168171	array([[ 2.1445637, -3.6051197]], dtype=float32)

time = 35184	action = 1	current_phase = 0	next_phase = 1	reward = -0.486321	array([[-3.7284822, -2.461787 ]], dtype=float32)

time = 35192	action = 0	current_phase = 1	next_phase = 0	reward = -0.618479	array([[-2.7779586, -3.1458669]], dtype=float32)

time = 35197	action = 0	current_phase = 1	next_phase = 0	reward = -0.467021	array([[-2.195653 , -3.1917577]], dtype=float32)

time = 35202	action = 0	current_phase = 1	next_phase = 0	reward = -0.321760	array([[-2.1179025, -2.8752844]], dtype=float32)

time = 35207	action = 0	current_phase = 1	next_phase = 0	reward = -0.180364	array([[-2.259829 , -2.9592056]], dtype=float32)

time = 35212	action = 0	current_phase = 1	next_phase = 0	reward = 0.244525	array([[-2.7128222, -3.5737727]], dtype=float32)

time = 35217	action = 1	current_phase = 1	next_phase = 0	reward = -1.728033	array([[-5.403783, -3.512304]], dtype=float32)

time = 35225	action = 0	current_phase = 0	next_phase = 1	reward = -0.526940	array([[-2.073527 , -3.0033677]], dtype=float32)

time = 35230	action = 0	current_phase = 0	next_phase = 1	reward = -0.378134	array([[-1.9334477, -2.6069613]], dtype=float32)

time = 35235	action = 0	current_phase = 0	next_phase = 1	reward = -0.232233	array([[-1.7333301, -2.9668627]], dtype=float32)

time = 35240	action = 0	current_phase = 0	next_phase = 1	reward = 0.356114	array([[-2.0783896, -2.9672978]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1284 - val_loss: 0.3307

Epoch 2/50

 - 4s - loss: 0.1122 - val_loss: 0.3268

Epoch 3/50

 - 4s - loss: 0.0847 - val_loss: 0.3295

Epoch 4/50

 - 4s - loss: 0.0731 - val_loss: 0.3301

Epoch 5/50

 - 4s - loss: 0.0959 - val_loss: 0.3275

Epoch 6/50

 - 4s - loss: 0.0805 - val_loss: 0.3331

Epoch 7/50

 - 4s - loss: 0.0698 - val_loss: 0.3360

Epoch 8/50

 - 4s - loss: 0.0590 - val_loss: 0.3368

Epoch 9/50

 - 4s - loss: 0.0525 - val_loss: 0.3259

Epoch 10/50

 - 4s - loss: 0.0558 - val_loss: 0.3309

Epoch 11/50

 - 4s - loss: 0.0528 - val_loss: 0.3381

Epoch 12/50

 - 4s - loss: 0.0531 - val_loss: 0.3418

Epoch 13/50

 - 4s - loss: 0.0439 - val_loss: 0.3309

Epoch 14/50

 - 4s - loss: 0.0747 - val_loss: 0.3375

Epoch 15/50

 - 4s - loss: 0.0565 - val_loss: 0.3379

Epoch 16/50

 - 4s - loss: 0.0437 - val_loss: 0.3427

Epoch 17/50

 - 4s - loss: 0.0760 - val_loss: 0.3448

Epoch 18/50

 - 4s - loss: 0.0646 - val_loss: 0.3346

Epoch 19/50

 - 4s - loss: 0.0708 - val_loss: 0.3393

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 938, after forget

length of memory (state 1, action 0): 1018, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 926, after forget

time = 35245	action = 1	current_phase = 0	next_phase = 1	reward = -1.356389	array([[-4.3261843, -3.1461003]], dtype=float32)

time = 35253	action = 0	current_phase = 1	next_phase = 0	reward = -0.595002	array([[-2.2344875, -2.82737  ]], dtype=float32)

time = 35258	action = 0	current_phase = 1	next_phase = 0	reward = -0.443464	array([[-2.0678692, -2.8734915]], dtype=float32)

time = 35263	action = 0	current_phase = 1	next_phase = 0	reward = -0.287920	array([[-2.0670626, -2.8702104]], dtype=float32)

time = 35268	action = 0	current_phase = 1	next_phase = 0	reward = -0.163153	array([[-2.3110502, -2.962808 ]], dtype=float32)

time = 35273	action = 1	current_phase = 1	next_phase = 0	reward = -1.871532	array([[-2.679391 , -2.3273878]], dtype=float32)

time = 35281	action = 1	current_phase = 0	next_phase = 1	reward = -2.043078	array([[-4.1778183, -3.8020234]], dtype=float32)

time = 35289	action = 0	current_phase = 1	next_phase = 0	reward = -0.386935	array([[-1.9995012, -2.8240418]], dtype=float32)

time = 35294	action = 0	current_phase = 1	next_phase = 0	reward = -0.232074	array([[-1.8164251, -3.0163546]], dtype=float32)

time = 35299	action = 0	current_phase = 1	next_phase = 0	reward = 0.103179	array([[-1.3384557, -3.5587003]], dtype=float32)

time = 35304	action = 1	current_phase = 1	next_phase = 0	reward = -0.764188	array([[-2.7758672, -2.4436922]], dtype=float32)

time = 35312	action = 0	current_phase = 0	next_phase = 1	reward = -0.612051	array([[-2.2744164, -2.998757 ]], dtype=float32)

time = 35317	action = 0	current_phase = 0	next_phase = 1	reward = -0.461305	array([[-1.9966776, -2.6583054]], dtype=float32)

time = 35322	action = 0	current_phase = 0	next_phase = 1	reward = -0.308042	array([[-1.7044235, -3.0108237]], dtype=float32)

time = 35327	action = 1	current_phase = 0	next_phase = 1	reward = -0.766140	array([[-2.0362234, -1.8451537]], dtype=float32)

time = 35335	action = 1	current_phase = 1	next_phase = 0	reward = -1.315528	array([[-3.4915621, -3.2918117]], dtype=float32)

time = 35343	action = 0	current_phase = 0	next_phase = 1	reward = -0.591227	array([[-2.1161704, -2.6636348]], dtype=float32)

time = 35348	action = 0	current_phase = 0	next_phase = 1	reward = -0.433020	array([[-1.97891  , -2.6352773]], dtype=float32)

time = 35353	action = 0	current_phase = 0	next_phase = 1	reward = -0.272403	array([[-1.7083637, -3.0163407]], dtype=float32)

time = 35358	action = 1	current_phase = 0	next_phase = 1	reward = -0.806560	array([[-2.3175673, -1.8792864]], dtype=float32)

time = 35366	action = 0	current_phase = 1	next_phase = 0	reward = -1.118099	array([[-3.3108323, -3.571844 ]], dtype=float32)

time = 35371	action = 1	current_phase = 1	next_phase = 0	reward = -2.045123	array([[-4.7477326, -3.6525514]], dtype=float32)

time = 35379	action = 0	current_phase = 0	next_phase = 1	reward = -0.367376	array([[-2.0563085, -2.933916 ]], dtype=float32)

time = 35384	action = 0	current_phase = 0	next_phase = 1	reward = -0.202256	array([[-1.7081579, -3.0162206]], dtype=float32)

time = 35389	action = 0	current_phase = 0	next_phase = 1	reward = -0.203108	array([[-2.1740649, -2.32615  ]], dtype=float32)

time = 35394	action = 1	current_phase = 0	next_phase = 1	reward = -0.557669	array([[-3.7653122, -2.793563 ]], dtype=float32)

time = 35402	action = 0	current_phase = 1	next_phase = 0	reward = -0.620690	array([[-2.77402  , -3.2012336]], dtype=float32)

time = 35407	action = 0	current_phase = 1	next_phase = 0	reward = -0.470144	array([[-2.1252577, -3.2599788]], dtype=float32)

time = 35412	action = 0	current_phase = 1	next_phase = 0	reward = -0.317357	array([[-2.1466365, -2.8547935]], dtype=float32)

time = 35417	action = 0	current_phase = 1	next_phase = 0	reward = -0.182156	array([[-2.2825017, -2.897636 ]], dtype=float32)

time = 35422	action = 0	current_phase = 1	next_phase = 0	reward = 0.189522	array([[-2.7464073, -3.3460486]], dtype=float32)

time = 35427	action = 1	current_phase = 1	next_phase = 0	reward = -1.733990	array([[-5.4158955, -3.527968 ]], dtype=float32)

time = 35435	action = 0	current_phase = 0	next_phase = 1	reward = -0.538584	array([[-2.1470246, -3.0497305]], dtype=float32)

time = 35440	action = 0	current_phase = 0	next_phase = 1	reward = -0.388239	array([[-1.9773244, -2.6352363]], dtype=float32)

time = 35445	action = 0	current_phase = 0	next_phase = 1	reward = -0.235073	array([[-1.7037823, -3.0157795]], dtype=float32)

time = 35450	action = 0	current_phase = 0	next_phase = 1	reward = 0.051121	array([[-2.1219742, -2.6080542]], dtype=float32)

time = 35455	action = 1	current_phase = 0	next_phase = 1	reward = -1.049686	array([[-4.115043 , -2.8452978]], dtype=float32)

time = 35463	action = 0	current_phase = 1	next_phase = 0	reward = -0.582373	array([[-2.266975 , -2.8094823]], dtype=float32)

time = 35468	action = 0	current_phase = 1	next_phase = 0	reward = -0.426166	array([[-2.058914 , -2.8784075]], dtype=float32)

time = 35473	action = 0	current_phase = 1	next_phase = 0	reward = -0.276525	array([[-2.0550313, -2.8545496]], dtype=float32)

time = 35478	action = 0	current_phase = 1	next_phase = 0	reward = -0.159530	array([[-2.2499506, -3.0836678]], dtype=float32)

time = 35483	action = 1	current_phase = 1	next_phase = 0	reward = -0.250506	array([[-2.1085641, -2.0547216]], dtype=float32)

time = 35491	action = 0	current_phase = 0	next_phase = 1	reward = -0.656091	array([[-2.2771754, -2.9957078]], dtype=float32)

time = 35496	action = 0	current_phase = 0	next_phase = 1	reward = -0.496683	array([[-2.0716376, -2.717366 ]], dtype=float32)

time = 35501	action = 0	current_phase = 0	next_phase = 1	reward = -0.333393	array([[-1.8554201, -2.8677924]], dtype=float32)

time = 35506	action = 0	current_phase = 0	next_phase = 1	reward = -0.185892	array([[-1.8429159, -2.6554582]], dtype=float32)

time = 35511	action = 0	current_phase = 0	next_phase = 1	reward = 0.278384	array([[-2.3623025, -2.820003 ]], dtype=float32)

time = 35516	action = 1	current_phase = 0	next_phase = 1	reward = -1.616489	array([[-5.0407248, -3.6491103]], dtype=float32)

time = 35524	action = 0	current_phase = 1	next_phase = 0	reward = -0.567829	array([[-1.9695853, -2.7440329]], dtype=float32)

time = 35529	action = 0	current_phase = 1	next_phase = 0	reward = -0.419599	array([[-1.8581545, -2.9902   ]], dtype=float32)

time = 35534	action = 0	current_phase = 1	next_phase = 0	reward = -0.266649	array([[-1.7634115, -2.9493563]], dtype=float32)

time = 35539	action = 0	current_phase = 1	next_phase = 0	reward = -0.167182	array([[-1.8355427, -3.4921825]], dtype=float32)

time = 35544	action = 1	current_phase = 1	next_phase = 0	reward = -0.441991	array([[-2.3263276, -2.2385447]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1114 - val_loss: 0.0551

Epoch 2/50

 - 4s - loss: 0.0972 - val_loss: 0.0587

Epoch 3/50

 - 4s - loss: 0.0968 - val_loss: 0.0609

Epoch 4/50

 - 4s - loss: 0.0896 - val_loss: 0.0677

Epoch 5/50

 - 4s - loss: 0.0933 - val_loss: 0.0675

Epoch 6/50

 - 4s - loss: 0.0771 - val_loss: 0.0723

Epoch 7/50

 - 4s - loss: 0.0579 - val_loss: 0.0590

Epoch 8/50

 - 4s - loss: 0.0571 - val_loss: 0.0604

Epoch 9/50

 - 4s - loss: 0.1114 - val_loss: 0.0572

Epoch 10/50

 - 4s - loss: 0.0509 - val_loss: 0.0711

Epoch 11/50

 - 4s - loss: 0.0999 - val_loss: 0.0728

length of memory (state 0, action 0): 1018, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 945, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 933, after forget

time = 35552	action = 0	current_phase = 0	next_phase = 1	reward = -0.612207	array([[-2.3878946, -3.1329005]], dtype=float32)

time = 35557	action = 0	current_phase = 0	next_phase = 1	reward = -0.456663	array([[-2.0430126, -2.7195084]], dtype=float32)

time = 35562	action = 0	current_phase = 0	next_phase = 1	reward = -0.296294	array([[-1.7442358, -3.0602841]], dtype=float32)

time = 35567	action = 1	current_phase = 0	next_phase = 1	reward = -0.751600	array([[-2.406102 , -2.0337238]], dtype=float32)

time = 35575	action = 1	current_phase = 1	next_phase = 0	reward = -1.362902	array([[-3.7751563, -3.501333 ]], dtype=float32)

time = 35583	action = 0	current_phase = 0	next_phase = 1	reward = -0.582375	array([[-2.0589352, -2.7153914]], dtype=float32)

time = 35588	action = 0	current_phase = 0	next_phase = 1	reward = -0.426239	array([[-2.0434275, -2.7090914]], dtype=float32)

time = 35593	action = 0	current_phase = 0	next_phase = 1	reward = -0.276784	array([[-1.7431722, -3.0618763]], dtype=float32)

time = 35598	action = 1	current_phase = 0	next_phase = 1	reward = -0.812151	array([[-2.6104555, -2.4287539]], dtype=float32)

time = 35606	action = 1	current_phase = 1	next_phase = 0	reward = -1.558561	array([[-4.023326, -3.616088]], dtype=float32)

time = 35614	action = 0	current_phase = 0	next_phase = 1	reward = -0.561530	array([[-2.3032317, -2.764883 ]], dtype=float32)

time = 35619	action = 0	current_phase = 0	next_phase = 1	reward = -0.408644	array([[-2.0432546, -2.708854 ]], dtype=float32)

time = 35624	action = 0	current_phase = 0	next_phase = 1	reward = -0.259118	array([[-1.74006  , -3.0617564]], dtype=float32)

time = 35629	action = 0	current_phase = 0	next_phase = 1	reward = -0.177984	array([[-2.1794262, -2.5508785]], dtype=float32)

time = 35634	action = 1	current_phase = 0	next_phase = 1	reward = -0.497708	array([[-3.827105 , -2.2928908]], dtype=float32)

time = 35642	action = 0	current_phase = 1	next_phase = 0	reward = -0.612874	array([[-2.2705958, -2.8324761]], dtype=float32)

time = 35647	action = 0	current_phase = 1	next_phase = 0	reward = -0.468656	array([[-2.0471923, -3.271712 ]], dtype=float32)

time = 35652	action = 0	current_phase = 1	next_phase = 0	reward = -0.322986	array([[-2.0284607, -2.8844054]], dtype=float32)

time = 35657	action = 0	current_phase = 1	next_phase = 0	reward = -0.182229	array([[-2.228611 , -3.0592484]], dtype=float32)

time = 35662	action = 0	current_phase = 1	next_phase = 0	reward = 0.260610	array([[-2.3620563, -3.828667 ]], dtype=float32)

time = 35667	action = 1	current_phase = 1	next_phase = 0	reward = -1.730291	array([[-5.346615 , -3.4768932]], dtype=float32)

time = 35675	action = 0	current_phase = 0	next_phase = 1	reward = -0.540095	array([[-2.180773 , -3.0811236]], dtype=float32)

time = 35680	action = 0	current_phase = 0	next_phase = 1	reward = -0.391566	array([[-2.0429714, -2.7088397]], dtype=float32)

time = 35685	action = 0	current_phase = 0	next_phase = 1	reward = -0.244352	array([[-1.7419362, -3.0615313]], dtype=float32)

time = 35690	action = 1	current_phase = 0	next_phase = 1	reward = -0.887210	array([[-2.1913764, -2.0904927]], dtype=float32)

time = 35698	action = 0	current_phase = 1	next_phase = 0	reward = -1.453710	array([[-1.5283868, -3.3929443]], dtype=float32)

time = 35703	action = 1	current_phase = 1	next_phase = 0	reward = -1.972453	array([[-4.6853123, -3.549201 ]], dtype=float32)

time = 35711	action = 0	current_phase = 0	next_phase = 1	reward = -0.353856	array([[-2.1236737, -3.0390842]], dtype=float32)

time = 35716	action = 0	current_phase = 0	next_phase = 1	reward = -0.208422	array([[-1.8029981, -3.016968 ]], dtype=float32)

time = 35721	action = 0	current_phase = 0	next_phase = 1	reward = 0.321119	array([[-2.2905557, -2.5455582]], dtype=float32)

time = 35726	action = 1	current_phase = 0	next_phase = 1	reward = -1.547547	array([[-4.629831 , -3.2931669]], dtype=float32)

time = 35734	action = 0	current_phase = 1	next_phase = 0	reward = -0.553549	array([[-2.0102136, -2.8395298]], dtype=float32)

time = 35739	action = 0	current_phase = 1	next_phase = 0	reward = -0.401110	array([[-1.9763396, -2.926208 ]], dtype=float32)

time = 35744	action = 0	current_phase = 1	next_phase = 0	reward = -0.249735	array([[-1.7961273, -2.9364498]], dtype=float32)

time = 35749	action = 0	current_phase = 1	next_phase = 0	reward = -0.175458	array([[-1.9026151, -3.6145625]], dtype=float32)

time = 35754	action = 1	current_phase = 1	next_phase = 0	reward = -0.480379	array([[-2.4739118, -2.3295708]], dtype=float32)

time = 35762	action = 0	current_phase = 0	next_phase = 1	reward = -0.624198	array([[-2.3856971, -3.1319458]], dtype=float32)

time = 35767	action = 0	current_phase = 0	next_phase = 1	reward = -0.464990	array([[-2.0816941, -2.7209113]], dtype=float32)

time = 35772	action = 0	current_phase = 0	next_phase = 1	reward = -0.307202	array([[-1.7536995, -3.061777 ]], dtype=float32)

time = 35777	action = 1	current_phase = 0	next_phase = 1	reward = -0.746442	array([[-2.416409 , -2.0084472]], dtype=float32)

time = 35785	action = 0	current_phase = 1	next_phase = 0	reward = -0.834881	array([[-2.8784878, -3.8212621]], dtype=float32)

time = 35790	action = 1	current_phase = 1	next_phase = 0	reward = -2.121571	array([[-5.2195153, -3.6652918]], dtype=float32)

time = 35798	action = 0	current_phase = 0	next_phase = 1	reward = -0.439239	array([[-2.145635 , -3.0529778]], dtype=float32)

time = 35803	action = 0	current_phase = 0	next_phase = 1	reward = -0.286013	array([[-1.7549397, -3.0562706]], dtype=float32)

time = 35808	action = 0	current_phase = 0	next_phase = 1	reward = -0.165917	array([[-2.339158 , -3.0277932]], dtype=float32)

time = 35813	action = 0	current_phase = 0	next_phase = 1	reward = 0.007293	array([[-3.0995514, -3.7428782]], dtype=float32)

time = 35818	action = 1	current_phase = 0	next_phase = 1	reward = -1.900778	array([[-5.7729135, -3.4710948]], dtype=float32)

time = 35826	action = 0	current_phase = 1	next_phase = 0	reward = -0.494543	array([[-2.092882 , -3.1710443]], dtype=float32)

time = 35831	action = 0	current_phase = 1	next_phase = 0	reward = -0.342534	array([[-1.878432 , -2.9870348]], dtype=float32)

time = 35836	action = 0	current_phase = 1	next_phase = 0	reward = -0.197829	array([[-2.0599253, -3.0193343]], dtype=float32)

time = 35841	action = 0	current_phase = 1	next_phase = 0	reward = 0.323692	array([[-2.1699755, -3.7538252]], dtype=float32)

time = 35846	action = 1	current_phase = 1	next_phase = 0	reward = -1.556883	array([[-5.0487356, -3.298424 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1055 - val_loss: 0.0384

Epoch 2/50

 - 4s - loss: 0.0554 - val_loss: 0.0420

Epoch 3/50

 - 4s - loss: 0.0814 - val_loss: 0.0396

Epoch 4/50

 - 4s - loss: 0.0429 - val_loss: 0.0397

Epoch 5/50

 - 4s - loss: 0.1141 - val_loss: 0.0428

Epoch 6/50

 - 4s - loss: 0.0880 - val_loss: 0.0395

Epoch 7/50

 - 4s - loss: 0.0758 - val_loss: 0.0373

Epoch 8/50

 - 4s - loss: 0.0792 - val_loss: 0.0381

Epoch 9/50

 - 4s - loss: 0.0465 - val_loss: 0.0378

Epoch 10/50

 - 4s - loss: 0.0628 - val_loss: 0.0377

Epoch 11/50

 - 4s - loss: 0.0513 - val_loss: 0.0363

Epoch 12/50

 - 4s - loss: 0.0367 - val_loss: 0.0373

Epoch 13/50

 - 4s - loss: 0.0635 - val_loss: 0.0385

Epoch 14/50

 - 4s - loss: 0.0528 - val_loss: 0.0377

Epoch 15/50

 - 4s - loss: 0.0832 - val_loss: 0.0389

Epoch 16/50

 - 4s - loss: 0.0485 - val_loss: 0.0374

Epoch 17/50

 - 4s - loss: 0.0440 - val_loss: 0.0365

Epoch 18/50

 - 4s - loss: 0.0371 - val_loss: 0.0370

Epoch 19/50

 - 4s - loss: 0.0404 - val_loss: 0.0496

Epoch 20/50

 - 4s - loss: 0.0441 - val_loss: 0.0421

Epoch 21/50

 - 4s - loss: 0.0390 - val_loss: 0.0375

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 952, after forget

length of memory (state 1, action 0): 1015, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 940, after forget

time = 35854	action = 0	current_phase = 0	next_phase = 1	reward = -0.561781	array([[-2.1334083, -2.9561527]], dtype=float32)

time = 35859	action = 0	current_phase = 0	next_phase = 1	reward = -0.397898	array([[-1.9568312, -2.7394469]], dtype=float32)

time = 35864	action = 0	current_phase = 0	next_phase = 1	reward = -0.242690	array([[-1.5799336, -3.0807617]], dtype=float32)

time = 35869	action = 0	current_phase = 0	next_phase = 1	reward = -0.171853	array([[-2.1951876, -2.635548 ]], dtype=float32)

time = 35874	action = 1	current_phase = 0	next_phase = 1	reward = -0.467120	array([[-3.8994646, -2.2697337]], dtype=float32)

time = 35882	action = 0	current_phase = 1	next_phase = 0	reward = -0.615339	array([[-2.3020744, -2.8223002]], dtype=float32)

time = 35887	action = 0	current_phase = 1	next_phase = 0	reward = -0.457916	array([[-2.1849217, -3.262357 ]], dtype=float32)

time = 35892	action = 0	current_phase = 1	next_phase = 0	reward = -0.299516	array([[-2.0558867, -2.8972735]], dtype=float32)

time = 35897	action = 0	current_phase = 1	next_phase = 0	reward = -0.165938	array([[-2.259847 , -3.0260174]], dtype=float32)

time = 35902	action = 0	current_phase = 1	next_phase = 0	reward = 0.190254	array([[-2.747324 , -3.6015842]], dtype=float32)

time = 35907	action = 1	current_phase = 1	next_phase = 0	reward = -1.778942	array([[-5.388196 , -3.5432785]], dtype=float32)

time = 35915	action = 0	current_phase = 0	next_phase = 1	reward = -0.518080	array([[-2.0838282, -3.0978348]], dtype=float32)

time = 35920	action = 0	current_phase = 0	next_phase = 1	reward = -0.371651	array([[-1.9565332, -2.7396226]], dtype=float32)

time = 35925	action = 0	current_phase = 0	next_phase = 1	reward = -0.219972	array([[-1.5759654, -3.0787423]], dtype=float32)

time = 35930	action = 0	current_phase = 0	next_phase = 1	reward = 0.043190	array([[-2.044725 , -2.1778038]], dtype=float32)

time = 35935	action = 1	current_phase = 0	next_phase = 1	reward = -1.088809	array([[-4.2151494, -2.8969908]], dtype=float32)

time = 35943	action = 0	current_phase = 1	next_phase = 0	reward = -0.592542	array([[-2.2521222, -2.856482 ]], dtype=float32)

time = 35948	action = 0	current_phase = 1	next_phase = 0	reward = -0.437803	array([[-2.0573556, -2.9034138]], dtype=float32)

time = 35953	action = 0	current_phase = 1	next_phase = 0	reward = -0.264706	array([[-2.0576553, -2.8994632]], dtype=float32)

time = 35958	action = 0	current_phase = 1	next_phase = 0	reward = -0.157180	array([[-2.1788874, -3.1250434]], dtype=float32)

time = 35963	action = 1	current_phase = 1	next_phase = 0	reward = -1.116830	array([[-2.2088149, -2.0786037]], dtype=float32)

time = 35971	action = 0	current_phase = 0	next_phase = 1	reward = -1.185720	array([[-2.6125464, -3.197303 ]], dtype=float32)

time = 35976	action = 0	current_phase = 0	next_phase = 1	reward = -1.059776	array([[-2.0299985, -2.897936 ]], dtype=float32)

time = 35981	action = 0	current_phase = 0	next_phase = 1	reward = -0.931376	array([[-1.8166566, -2.94319  ]], dtype=float32)

time = 35986	action = 0	current_phase = 0	next_phase = 1	reward = -0.805807	array([[-2.4592547, -2.5262215]], dtype=float32)

time = 35991	action = 0	current_phase = 0	next_phase = 1	reward = -0.292679	array([[-2.9052145, -3.600564 ]], dtype=float32)

time = 35996	action = 1	current_phase = 0	next_phase = 1	reward = -1.535207	array([[-6.400987, -3.422547]], dtype=float32)

time = 36004	action = 0	current_phase = 1	next_phase = 0	reward = -0.572047	array([[-2.0546613, -2.8561807]], dtype=float32)

time = 36009	action = 0	current_phase = 1	next_phase = 0	reward = -0.416245	array([[-1.8583899, -3.0241246]], dtype=float32)

time = 36014	action = 0	current_phase = 1	next_phase = 0	reward = -0.259454	array([[-1.9135406, -2.954399 ]], dtype=float32)

time = 36019	action = 0	current_phase = 1	next_phase = 0	reward = -0.167962	array([[-2.0501087, -3.58077  ]], dtype=float32)

time = 36024	action = 1	current_phase = 1	next_phase = 0	reward = -0.487020	array([[-2.2485523, -2.2402065]], dtype=float32)

time = 36032	action = 0	current_phase = 0	next_phase = 1	reward = -0.625120	array([[-2.2810829, -3.138725 ]], dtype=float32)

time = 36037	action = 0	current_phase = 0	next_phase = 1	reward = -0.472984	array([[-1.9720216, -2.750519 ]], dtype=float32)

time = 36042	action = 0	current_phase = 0	next_phase = 1	reward = -0.313177	array([[-1.5839517, -3.0761092]], dtype=float32)

time = 36047	action = 1	current_phase = 0	next_phase = 1	reward = -0.734974	array([[-2.5594757, -2.2014418]], dtype=float32)

time = 36055	action = 0	current_phase = 1	next_phase = 0	reward = -0.828454	array([[-2.4966106, -3.513649 ]], dtype=float32)

time = 36060	action = 1	current_phase = 1	next_phase = 0	reward = -2.124036	array([[-5.1141768, -3.6644459]], dtype=float32)

time = 36068	action = 0	current_phase = 0	next_phase = 1	reward = -0.459351	array([[-2.0252404, -3.0305178]], dtype=float32)

time = 36073	action = 0	current_phase = 0	next_phase = 1	reward = -0.310583	array([[-1.5836637, -3.067268 ]], dtype=float32)

time = 36078	action = 0	current_phase = 0	next_phase = 1	reward = -0.174355	array([[-2.2816122, -3.068057 ]], dtype=float32)

time = 36083	action = 0	current_phase = 0	next_phase = 1	reward = 0.150549	array([[-2.9046504, -3.70907  ]], dtype=float32)

time = 36088	action = 1	current_phase = 0	next_phase = 1	reward = -1.894257	array([[-5.4065423, -3.4764779]], dtype=float32)

time = 36096	action = 0	current_phase = 1	next_phase = 0	reward = -0.493193	array([[-2.1176693, -2.974389 ]], dtype=float32)

time = 36101	action = 0	current_phase = 1	next_phase = 0	reward = -0.338959	array([[-1.9914539, -2.9404595]], dtype=float32)

time = 36106	action = 0	current_phase = 1	next_phase = 0	reward = -0.190206	array([[-2.1533246, -2.9715254]], dtype=float32)

time = 36111	action = 0	current_phase = 1	next_phase = 0	reward = 0.320088	array([[-2.3230615, -3.7700899]], dtype=float32)

time = 36116	action = 1	current_phase = 1	next_phase = 0	reward = -1.663345	array([[-5.0311728, -3.2340393]], dtype=float32)

time = 36124	action = 0	current_phase = 0	next_phase = 1	reward = -0.553048	array([[-2.1852694, -3.0198524]], dtype=float32)

time = 36129	action = 0	current_phase = 0	next_phase = 1	reward = -0.397622	array([[-1.9568272, -2.739293 ]], dtype=float32)

time = 36134	action = 0	current_phase = 0	next_phase = 1	reward = -0.244712	array([[-1.5757487, -3.0801008]], dtype=float32)

time = 36139	action = 0	current_phase = 0	next_phase = 1	reward = -0.193094	array([[-2.1111042, -3.1808197]], dtype=float32)

time = 36144	action = 1	current_phase = 0	next_phase = 1	reward = -0.529031	array([[-3.7900949, -2.2454908]], dtype=float32)

time = 36152	action = 0	current_phase = 1	next_phase = 0	reward = -0.621297	array([[-2.3070877, -2.8210535]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0948 - val_loss: 0.0398

Epoch 2/50

 - 4s - loss: 0.0826 - val_loss: 0.0366

Epoch 3/50

 - 4s - loss: 0.0981 - val_loss: 0.0378

Epoch 4/50

 - 4s - loss: 0.0875 - val_loss: 0.0350

Epoch 5/50

 - 4s - loss: 0.0982 - val_loss: 0.0399

Epoch 6/50

 - 4s - loss: 0.0674 - val_loss: 0.0355

Epoch 7/50

 - 4s - loss: 0.0803 - val_loss: 0.0366

Epoch 8/50

 - 4s - loss: 0.0584 - val_loss: 0.0342

Epoch 9/50

 - 4s - loss: 0.0579 - val_loss: 0.0358

Epoch 10/50

 - 4s - loss: 0.0700 - val_loss: 0.0365

Epoch 11/50

 - 4s - loss: 0.0581 - val_loss: 0.0355

Epoch 12/50

 - 4s - loss: 0.0537 - val_loss: 0.0417

Epoch 13/50

 - 4s - loss: 0.0466 - val_loss: 0.0448

Epoch 14/50

 - 4s - loss: 0.0974 - val_loss: 0.0495

Epoch 15/50

 - 4s - loss: 0.0441 - val_loss: 0.0481

Epoch 16/50

 - 4s - loss: 0.0448 - val_loss: 0.0490

Epoch 17/50

 - 4s - loss: 0.0713 - val_loss: 0.0433

Epoch 18/50

 - 4s - loss: 0.0477 - val_loss: 0.0402

length of memory (state 0, action 0): 1024, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 958, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 945, after forget

time = 36157	action = 0	current_phase = 1	next_phase = 0	reward = -0.477573	array([[-2.141039 , -3.2583926]], dtype=float32)

time = 36162	action = 0	current_phase = 1	next_phase = 0	reward = -0.326832	array([[-2.0866766, -2.913485 ]], dtype=float32)

time = 36167	action = 0	current_phase = 1	next_phase = 0	reward = -0.180124	array([[-2.3406549, -2.9676425]], dtype=float32)

time = 36172	action = 0	current_phase = 1	next_phase = 0	reward = 0.254951	array([[-2.7537708, -3.6063502]], dtype=float32)

time = 36177	action = 1	current_phase = 1	next_phase = 0	reward = -1.674447	array([[-5.4398756, -3.4514277]], dtype=float32)

time = 36185	action = 0	current_phase = 0	next_phase = 1	reward = -0.528666	array([[-2.1412263, -3.114217 ]], dtype=float32)

time = 36190	action = 0	current_phase = 0	next_phase = 1	reward = -0.369154	array([[-1.947069, -2.762157]], dtype=float32)

time = 36195	action = 0	current_phase = 0	next_phase = 1	reward = -0.208785	array([[-1.586635, -3.062025]], dtype=float32)

time = 36200	action = 0	current_phase = 0	next_phase = 1	reward = 0.357777	array([[-2.1785855, -2.3302376]], dtype=float32)

time = 36205	action = 1	current_phase = 0	next_phase = 1	reward = -1.418211	array([[-4.499686 , -3.1724665]], dtype=float32)

time = 36213	action = 0	current_phase = 1	next_phase = 0	reward = -0.598019	array([[-2.3309164, -2.8571992]], dtype=float32)

time = 36218	action = 0	current_phase = 1	next_phase = 0	reward = -0.446267	array([[-2.0951598, -2.9103253]], dtype=float32)

time = 36223	action = 0	current_phase = 1	next_phase = 0	reward = -0.288242	array([[-2.1056604, -2.9051764]], dtype=float32)

time = 36228	action = 0	current_phase = 1	next_phase = 0	reward = -0.162653	array([[-2.2944365, -3.0625067]], dtype=float32)

time = 36233	action = 0	current_phase = 1	next_phase = 0	reward = 0.096909	array([[-2.7592359, -3.536998 ]], dtype=float32)

time = 36238	action = 1	current_phase = 1	next_phase = 0	reward = -1.893338	array([[-5.44962  , -3.4787066]], dtype=float32)

time = 36246	action = 0	current_phase = 0	next_phase = 1	reward = -0.489703	array([[-2.094662 , -3.0951247]], dtype=float32)

time = 36251	action = 0	current_phase = 0	next_phase = 1	reward = -0.338492	array([[-1.9498547, -2.758549 ]], dtype=float32)

time = 36256	action = 0	current_phase = 0	next_phase = 1	reward = -0.192931	array([[-1.9344019, -2.2504256]], dtype=float32)

time = 36261	action = 0	current_phase = 0	next_phase = 1	reward = 0.295897	array([[-2.2190757, -2.6651478]], dtype=float32)

time = 36266	action = 1	current_phase = 0	next_phase = 1	reward = -1.661672	array([[-4.5881944, -3.2470572]], dtype=float32)

time = 36274	action = 0	current_phase = 1	next_phase = 0	reward = -0.551257	array([[-2.1021423, -2.8490772]], dtype=float32)

time = 36279	action = 0	current_phase = 1	next_phase = 0	reward = -0.403406	array([[-1.8841838, -3.0123618]], dtype=float32)

time = 36284	action = 0	current_phase = 1	next_phase = 0	reward = -0.254995	array([[-1.8803377, -3.0100951]], dtype=float32)

time = 36289	action = 0	current_phase = 1	next_phase = 0	reward = -0.171565	array([[-1.9892668, -3.5510633]], dtype=float32)

time = 36294	action = 1	current_phase = 1	next_phase = 0	reward = -0.465372	array([[-2.7413764, -2.3391628]], dtype=float32)

time = 36302	action = 0	current_phase = 0	next_phase = 1	reward = -0.628277	array([[-2.247011, -3.119923]], dtype=float32)

time = 36307	action = 0	current_phase = 0	next_phase = 1	reward = -0.472962	array([[-1.9436667, -2.7797828]], dtype=float32)

time = 36312	action = 0	current_phase = 0	next_phase = 1	reward = -0.320738	array([[-1.5866681, -3.0664573]], dtype=float32)

time = 36317	action = 1	current_phase = 0	next_phase = 1	reward = -1.039891	array([[-2.5586913, -2.4032235]], dtype=float32)

time = 36325	action = 0	current_phase = 1	next_phase = 0	reward = -0.500653	array([[-2.1854124, -2.4894142]], dtype=float32)

time = 36330	action = 1	current_phase = 1	next_phase = 0	reward = -2.119996	array([[-5.251445 , -3.6549873]], dtype=float32)

time = 36338	action = 0	current_phase = 0	next_phase = 1	reward = -0.434699	array([[-2.0760622, -3.0564177]], dtype=float32)

time = 36343	action = 0	current_phase = 0	next_phase = 1	reward = -0.284945	array([[-1.621648 , -3.0147486]], dtype=float32)

time = 36348	action = 0	current_phase = 0	next_phase = 1	reward = -0.166705	array([[-2.3308306, -3.1781456]], dtype=float32)

time = 36353	action = 0	current_phase = 0	next_phase = 1	reward = 0.073949	array([[-3.209751 , -3.4665167]], dtype=float32)

time = 36358	action = 1	current_phase = 0	next_phase = 1	reward = -1.899577	array([[-5.7172275, -3.499395 ]], dtype=float32)

time = 36366	action = 0	current_phase = 1	next_phase = 0	reward = -0.486172	array([[-2.1419125, -2.955733 ]], dtype=float32)

time = 36371	action = 0	current_phase = 1	next_phase = 0	reward = -0.331721	array([[-2.0626874, -2.9246676]], dtype=float32)

time = 36376	action = 0	current_phase = 1	next_phase = 0	reward = -0.188089	array([[-2.250681, -2.925546]], dtype=float32)

time = 36381	action = 0	current_phase = 1	next_phase = 0	reward = 0.293360	array([[-2.414956, -3.734048]], dtype=float32)

time = 36386	action = 1	current_phase = 1	next_phase = 0	reward = -1.606856	array([[-5.1102014, -3.2477107]], dtype=float32)

time = 36394	action = 0	current_phase = 0	next_phase = 1	reward = -0.548528	array([[-2.1813385, -3.0399313]], dtype=float32)

time = 36399	action = 0	current_phase = 0	next_phase = 1	reward = -0.397446	array([[-1.9506688, -2.7577958]], dtype=float32)

time = 36404	action = 0	current_phase = 0	next_phase = 1	reward = -0.242765	array([[-1.580514 , -3.0792341]], dtype=float32)

time = 36409	action = 0	current_phase = 0	next_phase = 1	reward = -0.184647	array([[-1.8447832, -3.1426005]], dtype=float32)

time = 36414	action = 1	current_phase = 0	next_phase = 1	reward = -0.543932	array([[-3.808882 , -2.2045162]], dtype=float32)

time = 36422	action = 0	current_phase = 1	next_phase = 0	reward = -0.612748	array([[-2.3445187, -2.8481903]], dtype=float32)

time = 36427	action = 0	current_phase = 1	next_phase = 0	reward = -0.454117	array([[-2.0956378, -3.2699728]], dtype=float32)

time = 36432	action = 0	current_phase = 1	next_phase = 0	reward = -0.304595	array([[-2.1179576, -2.9047441]], dtype=float32)

time = 36437	action = 0	current_phase = 1	next_phase = 0	reward = -0.170006	array([[-2.3560076, -2.9761117]], dtype=float32)

time = 36442	action = 0	current_phase = 1	next_phase = 0	reward = 0.237521	array([[-2.7856812, -3.5779645]], dtype=float32)

time = 36447	action = 1	current_phase = 1	next_phase = 0	reward = -1.781144	array([[-5.360182 , -3.4647176]], dtype=float32)

time = 36455	action = 0	current_phase = 0	next_phase = 1	reward = -0.526451	array([[-2.1327868, -3.1032324]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0831 - val_loss: 0.0967

Epoch 2/50

 - 4s - loss: 0.0643 - val_loss: 0.0839

Epoch 3/50

 - 4s - loss: 0.0835 - val_loss: 0.0953

Epoch 4/50

 - 4s - loss: 0.0801 - val_loss: 0.1164

Epoch 5/50

 - 4s - loss: 0.0563 - val_loss: 0.1073

Epoch 6/50

 - 4s - loss: 0.0804 - val_loss: 0.1082

Epoch 7/50

 - 4s - loss: 0.0803 - val_loss: 0.0956

Epoch 8/50

 - 4s - loss: 0.0535 - val_loss: 0.1065

Epoch 9/50

 - 4s - loss: 0.0926 - val_loss: 0.1130

Epoch 10/50

 - 4s - loss: 0.0486 - val_loss: 0.1141

Epoch 11/50

 - 4s - loss: 0.0501 - val_loss: 0.1162

Epoch 12/50

 - 4s - loss: 0.0610 - val_loss: 0.1196

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 963, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 951, after forget

time = 36460	action = 0	current_phase = 0	next_phase = 1	reward = -0.380364	array([[-1.8268147, -2.7691693]], dtype=float32)

time = 36465	action = 0	current_phase = 0	next_phase = 1	reward = -0.230414	array([[-1.905792 , -3.0213077]], dtype=float32)

time = 36470	action = 0	current_phase = 0	next_phase = 1	reward = 0.363528	array([[-2.1110542, -2.2935464]], dtype=float32)

time = 36475	action = 1	current_phase = 0	next_phase = 1	reward = -1.360779	array([[-4.521625, -3.249033]], dtype=float32)

time = 36483	action = 0	current_phase = 1	next_phase = 0	reward = -0.590400	array([[-2.2786822, -2.8633575]], dtype=float32)

time = 36488	action = 0	current_phase = 1	next_phase = 0	reward = -0.441505	array([[-2.1611755, -2.8939483]], dtype=float32)

time = 36493	action = 0	current_phase = 1	next_phase = 0	reward = -0.296347	array([[-2.1603775, -2.8937016]], dtype=float32)

time = 36498	action = 0	current_phase = 1	next_phase = 0	reward = -0.170148	array([[-2.365794 , -3.0923913]], dtype=float32)

time = 36503	action = 0	current_phase = 1	next_phase = 0	reward = 0.192233	array([[-2.785184, -3.414108]], dtype=float32)

time = 36508	action = 1	current_phase = 1	next_phase = 0	reward = -1.891943	array([[-5.392847, -3.45543 ]], dtype=float32)

time = 36516	action = 0	current_phase = 0	next_phase = 1	reward = -0.495980	array([[-2.0879142, -3.1852367]], dtype=float32)

time = 36521	action = 0	current_phase = 0	next_phase = 1	reward = -0.333706	array([[-1.8278738, -2.7638452]], dtype=float32)

time = 36526	action = 0	current_phase = 0	next_phase = 1	reward = -0.195439	array([[-2.0495424, -2.6336834]], dtype=float32)

time = 36531	action = 0	current_phase = 0	next_phase = 1	reward = 0.307674	array([[-2.2039804, -2.5208495]], dtype=float32)

time = 36536	action = 1	current_phase = 0	next_phase = 1	reward = -1.610037	array([[-4.591441, -3.287866]], dtype=float32)

time = 36544	action = 0	current_phase = 1	next_phase = 0	reward = -0.559857	array([[-2.1617172, -2.8853157]], dtype=float32)

time = 36549	action = 0	current_phase = 1	next_phase = 0	reward = -0.421024	array([[-1.9444427, -3.007518 ]], dtype=float32)

time = 36554	action = 0	current_phase = 1	next_phase = 0	reward = -0.275078	array([[-1.9469064, -3.0001397]], dtype=float32)

time = 36559	action = 0	current_phase = 1	next_phase = 0	reward = -0.170201	array([[-2.0415695, -3.6234791]], dtype=float32)

time = 36564	action = 1	current_phase = 1	next_phase = 0	reward = -0.409155	array([[-2.610344, -2.253317]], dtype=float32)

time = 36572	action = 0	current_phase = 0	next_phase = 1	reward = -0.623315	array([[-2.1671917, -3.20165  ]], dtype=float32)

time = 36577	action = 0	current_phase = 0	next_phase = 1	reward = -0.471815	array([[-1.8529265, -2.7982512]], dtype=float32)

time = 36582	action = 0	current_phase = 0	next_phase = 1	reward = -0.317564	array([[-1.9126608, -2.9535923]], dtype=float32)

time = 36587	action = 0	current_phase = 0	next_phase = 1	reward = -0.182574	array([[-2.182913, -2.439343]], dtype=float32)

time = 36592	action = 0	current_phase = 0	next_phase = 1	reward = 0.190753	array([[-2.6344998, -3.4387329]], dtype=float32)

time = 36597	action = 1	current_phase = 0	next_phase = 1	reward = -1.786963	array([[-6.346119 , -3.5393634]], dtype=float32)

time = 36605	action = 0	current_phase = 1	next_phase = 0	reward = -0.532513	array([[-2.1008532, -2.7950513]], dtype=float32)

time = 36610	action = 0	current_phase = 1	next_phase = 0	reward = -0.379999	array([[-1.9454077, -3.0072222]], dtype=float32)

time = 36615	action = 0	current_phase = 1	next_phase = 0	reward = -0.227910	array([[-1.943817 , -3.0079615]], dtype=float32)

time = 36620	action = 0	current_phase = 1	next_phase = 0	reward = 0.075078	array([[-2.0654202, -3.6157837]], dtype=float32)

time = 36625	action = 1	current_phase = 1	next_phase = 0	reward = -1.026936	array([[-3.183262, -2.723598]], dtype=float32)

time = 36633	action = 0	current_phase = 0	next_phase = 1	reward = -0.594805	array([[-2.1609375, -3.1822643]], dtype=float32)

time = 36638	action = 0	current_phase = 0	next_phase = 1	reward = -0.444799	array([[-1.8281443, -2.7644167]], dtype=float32)

time = 36643	action = 0	current_phase = 0	next_phase = 1	reward = -0.294407	array([[-1.9036958, -3.0274246]], dtype=float32)

time = 36648	action = 0	current_phase = 0	next_phase = 1	reward = -0.164327	array([[-2.3214498, -2.8137228]], dtype=float32)

time = 36653	action = 0	current_phase = 0	next_phase = 1	reward = 0.100325	array([[-2.9153771, -3.8081195]], dtype=float32)

time = 36658	action = 1	current_phase = 0	next_phase = 1	reward = -1.895276	array([[-6.31623 , -3.588774]], dtype=float32)

time = 36666	action = 0	current_phase = 1	next_phase = 0	reward = -0.491718	array([[-2.1834474, -3.2324786]], dtype=float32)

time = 36671	action = 0	current_phase = 1	next_phase = 0	reward = -0.346155	array([[-2.205941, -2.90953 ]], dtype=float32)

time = 36676	action = 0	current_phase = 1	next_phase = 0	reward = -0.201111	array([[-2.020354 , -3.0162468]], dtype=float32)

time = 36681	action = 0	current_phase = 1	next_phase = 0	reward = 0.284048	array([[-2.3952205, -3.8034887]], dtype=float32)

time = 36686	action = 1	current_phase = 1	next_phase = 0	reward = -1.606813	array([[-5.2489295, -3.392828 ]], dtype=float32)

time = 36694	action = 0	current_phase = 0	next_phase = 1	reward = -0.553251	array([[-2.0738876, -3.0729911]], dtype=float32)

time = 36699	action = 0	current_phase = 0	next_phase = 1	reward = -0.397264	array([[-1.8279094, -2.7643056]], dtype=float32)

time = 36704	action = 0	current_phase = 0	next_phase = 1	reward = -0.245379	array([[-1.9036491, -3.0274107]], dtype=float32)

time = 36709	action = 0	current_phase = 0	next_phase = 1	reward = -0.181881	array([[-2.1291757, -2.6121588]], dtype=float32)

time = 36714	action = 1	current_phase = 0	next_phase = 1	reward = -0.611633	array([[-3.8715572, -2.3118205]], dtype=float32)

time = 36722	action = 0	current_phase = 1	next_phase = 0	reward = -0.624599	array([[-2.3375556, -2.8110106]], dtype=float32)

time = 36727	action = 0	current_phase = 1	next_phase = 0	reward = -0.470702	array([[-2.1629133, -3.2357204]], dtype=float32)

time = 36732	action = 0	current_phase = 1	next_phase = 0	reward = -0.318692	array([[-2.1610992, -2.8943155]], dtype=float32)

time = 36737	action = 0	current_phase = 1	next_phase = 0	reward = -0.178674	array([[-2.4315162, -2.9500234]], dtype=float32)

time = 36742	action = 0	current_phase = 1	next_phase = 0	reward = 0.263505	array([[-2.7287474, -3.6497555]], dtype=float32)

time = 36747	action = 1	current_phase = 1	next_phase = 0	reward = -1.625682	array([[-5.4326205, -3.4997923]], dtype=float32)

time = 36755	action = 0	current_phase = 0	next_phase = 1	reward = -0.535146	array([[-2.0840328, -3.1690943]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2376 - val_loss: 0.0298

Epoch 2/50

 - 4s - loss: 0.2101 - val_loss: 0.0299

Epoch 3/50

 - 4s - loss: 0.1697 - val_loss: 0.0294

Epoch 4/50

 - 4s - loss: 0.2104 - val_loss: 0.0320

Epoch 5/50

 - 4s - loss: 0.2029 - val_loss: 0.0325

Epoch 6/50

 - 4s - loss: 0.1357 - val_loss: 0.0345

Epoch 7/50

 - 4s - loss: 0.1531 - val_loss: 0.0317

Epoch 8/50

 - 4s - loss: 0.1538 - val_loss: 0.0335

Epoch 9/50

 - 4s - loss: 0.1643 - val_loss: 0.0348

Epoch 10/50

 - 4s - loss: 0.1361 - val_loss: 0.0354

Epoch 11/50

 - 4s - loss: 0.1591 - val_loss: 0.0395

Epoch 12/50

 - 4s - loss: 0.1562 - val_loss: 0.0438

Epoch 13/50

 - 4s - loss: 0.0898 - val_loss: 0.0631

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 968, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 956, after forget

time = 36760	action = 0	current_phase = 0	next_phase = 1	reward = -0.384352	array([[-1.7854925, -2.7506456]], dtype=float32)

time = 36765	action = 0	current_phase = 0	next_phase = 1	reward = -0.229684	array([[-1.9702772, -2.9277794]], dtype=float32)

time = 36770	action = 0	current_phase = 0	next_phase = 1	reward = 0.081559	array([[-2.143499 , -2.5566888]], dtype=float32)

time = 36775	action = 1	current_phase = 0	next_phase = 1	reward = -0.965913	array([[-4.259324 , -2.8326867]], dtype=float32)

time = 36783	action = 0	current_phase = 1	next_phase = 0	reward = -0.586645	array([[-2.2959726, -2.8560884]], dtype=float32)

time = 36788	action = 0	current_phase = 1	next_phase = 0	reward = -0.432630	array([[-2.1371768, -2.9364853]], dtype=float32)

time = 36793	action = 0	current_phase = 1	next_phase = 0	reward = -0.283250	array([[-2.14067  , -2.9346428]], dtype=float32)

time = 36798	action = 0	current_phase = 1	next_phase = 0	reward = -0.165140	array([[-2.4054575, -3.0460951]], dtype=float32)

time = 36803	action = 0	current_phase = 1	next_phase = 0	reward = 0.128243	array([[-2.7666757, -3.47616  ]], dtype=float32)

time = 36808	action = 1	current_phase = 1	next_phase = 0	reward = -1.892993	array([[-5.5433865, -3.5843863]], dtype=float32)

time = 36816	action = 0	current_phase = 0	next_phase = 1	reward = -0.498874	array([[-2.103334 , -3.1561348]], dtype=float32)

time = 36821	action = 0	current_phase = 0	next_phase = 1	reward = -0.344050	array([[-1.7872849, -2.7519846]], dtype=float32)

time = 36826	action = 0	current_phase = 0	next_phase = 1	reward = -0.197399	array([[-2.0098996, -2.3239381]], dtype=float32)

time = 36831	action = 0	current_phase = 0	next_phase = 1	reward = 0.286881	array([[-2.3321538, -2.6675785]], dtype=float32)

time = 36836	action = 1	current_phase = 0	next_phase = 1	reward = -1.610604	array([[-4.651513 , -3.2854831]], dtype=float32)

time = 36844	action = 0	current_phase = 1	next_phase = 0	reward = -0.560791	array([[-2.062411 , -2.8206272]], dtype=float32)

time = 36849	action = 0	current_phase = 1	next_phase = 0	reward = -0.411899	array([[-2.0208797, -3.0030673]], dtype=float32)

time = 36854	action = 0	current_phase = 1	next_phase = 0	reward = -0.257147	array([[-1.9453154, -3.024016 ]], dtype=float32)

time = 36859	action = 0	current_phase = 1	next_phase = 0	reward = -0.165659	array([[-2.229643, -3.280737]], dtype=float32)

time = 36864	action = 1	current_phase = 1	next_phase = 0	reward = -0.460781	array([[-2.6137161, -2.3924007]], dtype=float32)

time = 36872	action = 0	current_phase = 0	next_phase = 1	reward = -0.614993	array([[-2.1715353, -3.1895971]], dtype=float32)

time = 36877	action = 0	current_phase = 0	next_phase = 1	reward = -0.457635	array([[-1.885155 , -2.7548473]], dtype=float32)

time = 36882	action = 0	current_phase = 0	next_phase = 1	reward = -0.311703	array([[-1.9931476, -2.9319384]], dtype=float32)

time = 36887	action = 0	current_phase = 0	next_phase = 1	reward = -0.178246	array([[-2.275782 , -2.6901498]], dtype=float32)

time = 36892	action = 0	current_phase = 0	next_phase = 1	reward = 0.176313	array([[-2.6396544, -3.7017815]], dtype=float32)

time = 36897	action = 1	current_phase = 0	next_phase = 1	reward = -1.786718	array([[-6.3950706, -3.4412575]], dtype=float32)

time = 36905	action = 0	current_phase = 1	next_phase = 0	reward = -0.534724	array([[-2.0901341, -2.838266 ]], dtype=float32)

time = 36910	action = 0	current_phase = 1	next_phase = 0	reward = -0.385478	array([[-1.9092104, -3.046264 ]], dtype=float32)

time = 36915	action = 0	current_phase = 1	next_phase = 0	reward = -0.243383	array([[-1.9131187, -3.0450776]], dtype=float32)

time = 36920	action = 0	current_phase = 1	next_phase = 0	reward = 0.072478	array([[-2.0224013, -3.6369817]], dtype=float32)

time = 36925	action = 1	current_phase = 1	next_phase = 0	reward = -1.070986	array([[-3.0332837, -2.5982027]], dtype=float32)

time = 36933	action = 0	current_phase = 0	next_phase = 1	reward = -0.596082	array([[-2.1678288, -3.1856318]], dtype=float32)

time = 36938	action = 0	current_phase = 0	next_phase = 1	reward = -0.444217	array([[-1.7859895, -2.750559 ]], dtype=float32)

time = 36943	action = 0	current_phase = 0	next_phase = 1	reward = -0.300072	array([[-1.9805753, -2.9272823]], dtype=float32)

time = 36948	action = 0	current_phase = 0	next_phase = 1	reward = -0.172028	array([[-2.3098743, -2.6190128]], dtype=float32)

time = 36953	action = 0	current_phase = 0	next_phase = 1	reward = 0.162292	array([[-2.641823 , -3.5908606]], dtype=float32)

time = 36958	action = 1	current_phase = 0	next_phase = 1	reward = -1.896942	array([[-6.3371196, -3.5207458]], dtype=float32)

time = 36966	action = 0	current_phase = 1	next_phase = 0	reward = -0.498267	array([[-2.2393823, -3.2517715]], dtype=float32)

time = 36971	action = 0	current_phase = 1	next_phase = 0	reward = -0.347662	array([[-2.1244504, -2.942543 ]], dtype=float32)

time = 36976	action = 0	current_phase = 1	next_phase = 0	reward = -0.203003	array([[-1.9740748, -3.0286722]], dtype=float32)

time = 36981	action = 0	current_phase = 1	next_phase = 0	reward = 0.277372	array([[-2.2937365, -3.8959727]], dtype=float32)

time = 36986	action = 1	current_phase = 1	next_phase = 0	reward = -1.610957	array([[-3.753925 , -3.3116574]], dtype=float32)

time = 36994	action = 0	current_phase = 0	next_phase = 1	reward = -0.559494	array([[-2.1663313, -3.1849833]], dtype=float32)

time = 36999	action = 0	current_phase = 0	next_phase = 1	reward = -0.406831	array([[-1.7856802, -2.7502491]], dtype=float32)

time = 37004	action = 0	current_phase = 0	next_phase = 1	reward = -0.254780	array([[-1.9803292, -2.927194 ]], dtype=float32)

time = 37009	action = 0	current_phase = 0	next_phase = 1	reward = -0.191214	array([[-2.2948542, -2.4190989]], dtype=float32)

time = 37014	action = 1	current_phase = 0	next_phase = 1	reward = -0.526954	array([[-3.7460778, -2.302229 ]], dtype=float32)

time = 37022	action = 0	current_phase = 1	next_phase = 0	reward = -0.621866	array([[-2.3267353, -2.8146744]], dtype=float32)

time = 37027	action = 0	current_phase = 1	next_phase = 0	reward = -0.476375	array([[-2.0505583, -3.2691188]], dtype=float32)

time = 37032	action = 0	current_phase = 1	next_phase = 0	reward = -0.318624	array([[-2.0857148, -2.9597194]], dtype=float32)

time = 37037	action = 0	current_phase = 1	next_phase = 0	reward = -0.176526	array([[-2.2520518, -2.9529886]], dtype=float32)

time = 37042	action = 0	current_phase = 1	next_phase = 0	reward = 0.182798	array([[-2.7381337, -3.7186239]], dtype=float32)

time = 37047	action = 1	current_phase = 1	next_phase = 0	reward = -1.785865	array([[-5.5399327, -3.5889072]], dtype=float32)

time = 37055	action = 0	current_phase = 0	next_phase = 1	reward = -0.529554	array([[-2.1844482, -3.2393594]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1080 - val_loss: 0.0397

Epoch 2/50

 - 4s - loss: 0.0699 - val_loss: 0.0429

Epoch 3/50

 - 4s - loss: 0.0801 - val_loss: 0.0454

Epoch 4/50

 - 4s - loss: 0.0601 - val_loss: 0.0473

Epoch 5/50

 - 4s - loss: 0.0414 - val_loss: 0.0559

Epoch 6/50

 - 4s - loss: 0.0560 - val_loss: 0.0555

Epoch 7/50

 - 4s - loss: 0.0384 - val_loss: 0.0527

Epoch 8/50

 - 4s - loss: 0.0420 - val_loss: 0.0605

Epoch 9/50

 - 4s - loss: 0.0501 - val_loss: 0.0713

Epoch 10/50

 - 4s - loss: 0.0493 - val_loss: 0.0727

Epoch 11/50

 - 4s - loss: 0.0346 - val_loss: 0.0720

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 973, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 961, after forget

time = 37060	action = 0	current_phase = 0	next_phase = 1	reward = -0.379137	array([[-1.7348549, -2.7343678]], dtype=float32)

time = 37065	action = 0	current_phase = 0	next_phase = 1	reward = -0.223778	array([[-1.9768747, -2.8623886]], dtype=float32)

time = 37070	action = 0	current_phase = 0	next_phase = 1	reward = 0.351647	array([[-2.0781937, -2.2248688]], dtype=float32)

time = 37075	action = 1	current_phase = 0	next_phase = 1	reward = -1.364665	array([[-4.4565754, -3.0904114]], dtype=float32)

time = 37083	action = 0	current_phase = 1	next_phase = 0	reward = -0.587888	array([[-2.3331518, -2.8667676]], dtype=float32)

time = 37088	action = 0	current_phase = 1	next_phase = 0	reward = -0.432167	array([[-2.1714725, -2.9462848]], dtype=float32)

time = 37093	action = 0	current_phase = 1	next_phase = 0	reward = -0.283170	array([[-2.173994 , -2.9420834]], dtype=float32)

time = 37098	action = 0	current_phase = 1	next_phase = 0	reward = -0.165022	array([[-2.359637 , -3.1745245]], dtype=float32)

time = 37103	action = 0	current_phase = 1	next_phase = 0	reward = 0.132095	array([[-2.5603447, -2.7575514]], dtype=float32)

time = 37108	action = 1	current_phase = 1	next_phase = 0	reward = -1.897382	array([[-5.5574923, -3.5566874]], dtype=float32)

time = 37116	action = 0	current_phase = 0	next_phase = 1	reward = -0.497455	array([[-2.0242567, -3.1717792]], dtype=float32)

time = 37121	action = 0	current_phase = 0	next_phase = 1	reward = -0.338477	array([[-1.7518908, -2.8035479]], dtype=float32)

time = 37126	action = 0	current_phase = 0	next_phase = 1	reward = -0.195333	array([[-2.183278 , -2.2664647]], dtype=float32)

time = 37131	action = 0	current_phase = 0	next_phase = 1	reward = 0.291919	array([[-2.174744 , -2.3656816]], dtype=float32)

time = 37136	action = 1	current_phase = 0	next_phase = 1	reward = -1.501442	array([[-4.486189 , -3.1583319]], dtype=float32)

time = 37144	action = 0	current_phase = 1	next_phase = 0	reward = -0.555797	array([[-2.0648572, -2.796314 ]], dtype=float32)

time = 37149	action = 0	current_phase = 1	next_phase = 0	reward = -0.402352	array([[-1.9472871, -3.0532744]], dtype=float32)

time = 37154	action = 0	current_phase = 1	next_phase = 0	reward = -0.239757	array([[-1.947199 , -3.0522575]], dtype=float32)

time = 37159	action = 0	current_phase = 1	next_phase = 0	reward = -0.166732	array([[-2.0102477, -3.7309763]], dtype=float32)

time = 37164	action = 1	current_phase = 1	next_phase = 0	reward = -0.472299	array([[-2.6461468, -2.2966492]], dtype=float32)

time = 37172	action = 0	current_phase = 0	next_phase = 1	reward = -0.615404	array([[-2.1620557, -3.22071  ]], dtype=float32)

time = 37177	action = 0	current_phase = 0	next_phase = 1	reward = -0.455780	array([[-1.742608 , -2.7431238]], dtype=float32)

time = 37182	action = 0	current_phase = 0	next_phase = 1	reward = -0.303234	array([[-1.9760907, -2.862155 ]], dtype=float32)

time = 37187	action = 0	current_phase = 0	next_phase = 1	reward = -0.172588	array([[-2.0471478, -2.7443504]], dtype=float32)

time = 37192	action = 0	current_phase = 0	next_phase = 1	reward = 0.172652	array([[-2.6881738, -3.775489 ]], dtype=float32)

time = 37197	action = 1	current_phase = 0	next_phase = 1	reward = -1.782685	array([[-6.3122163, -3.5836177]], dtype=float32)

time = 37205	action = 0	current_phase = 1	next_phase = 0	reward = -0.524246	array([[-2.119114, -2.844037]], dtype=float32)

time = 37210	action = 0	current_phase = 1	next_phase = 0	reward = -0.368989	array([[-1.9449978, -3.0545301]], dtype=float32)

time = 37215	action = 0	current_phase = 1	next_phase = 0	reward = -0.208685	array([[-1.9508458, -3.051204 ]], dtype=float32)

time = 37220	action = 0	current_phase = 1	next_phase = 0	reward = 0.344055	array([[-2.108083 , -3.6656122]], dtype=float32)

time = 37225	action = 1	current_phase = 1	next_phase = 0	reward = -1.368015	array([[-3.3936627, -2.884011 ]], dtype=float32)

time = 37233	action = 0	current_phase = 0	next_phase = 1	reward = -0.586382	array([[-2.1589756, -3.1970146]], dtype=float32)

time = 37238	action = 0	current_phase = 0	next_phase = 1	reward = -0.425199	array([[-1.7361118, -2.740388 ]], dtype=float32)

time = 37243	action = 0	current_phase = 0	next_phase = 1	reward = -0.273870	array([[-1.9761361, -2.8620107]], dtype=float32)

time = 37248	action = 0	current_phase = 0	next_phase = 1	reward = -0.168531	array([[-2.329284 , -2.9540238]], dtype=float32)

time = 37253	action = 0	current_phase = 0	next_phase = 1	reward = -0.006649	array([[-2.6972003, -3.5797563]], dtype=float32)

time = 37258	action = 1	current_phase = 0	next_phase = 1	reward = -1.905946	array([[-6.34469  , -3.5608354]], dtype=float32)

time = 37266	action = 0	current_phase = 1	next_phase = 0	reward = -0.497586	array([[-2.2648165, -3.238687 ]], dtype=float32)

time = 37271	action = 0	current_phase = 1	next_phase = 0	reward = -0.349114	array([[-2.116872 , -2.9710147]], dtype=float32)

time = 37276	action = 0	current_phase = 1	next_phase = 0	reward = -0.197567	array([[-2.2273505, -3.0838318]], dtype=float32)

time = 37281	action = 0	current_phase = 1	next_phase = 0	reward = 0.327291	array([[-2.3554397, -3.9221272]], dtype=float32)

time = 37286	action = 1	current_phase = 1	next_phase = 0	reward = -1.610836	array([[-5.24939 , -3.270015]], dtype=float32)

time = 37294	action = 0	current_phase = 0	next_phase = 1	reward = -0.560915	array([[-2.1231663, -3.1551838]], dtype=float32)

time = 37299	action = 0	current_phase = 0	next_phase = 1	reward = -0.403839	array([[-1.7353027, -2.7343392]], dtype=float32)

time = 37304	action = 0	current_phase = 0	next_phase = 1	reward = -0.254879	array([[-1.9765631, -2.8638527]], dtype=float32)

time = 37309	action = 0	current_phase = 0	next_phase = 1	reward = -0.175569	array([[-2.1108062, -3.0156538]], dtype=float32)

time = 37314	action = 1	current_phase = 0	next_phase = 1	reward = -0.546750	array([[-3.8695428, -2.314216 ]], dtype=float32)

time = 37322	action = 0	current_phase = 1	next_phase = 0	reward = -0.624614	array([[-2.3817527, -2.7984583]], dtype=float32)

time = 37327	action = 0	current_phase = 1	next_phase = 0	reward = -0.484533	array([[-2.2628372, -3.214905 ]], dtype=float32)

time = 37332	action = 0	current_phase = 1	next_phase = 0	reward = -0.338889	array([[-2.1696706, -2.9462752]], dtype=float32)

time = 37337	action = 0	current_phase = 1	next_phase = 0	reward = -0.194697	array([[-2.456903 , -3.0344229]], dtype=float32)

time = 37342	action = 0	current_phase = 1	next_phase = 0	reward = 0.265192	array([[-2.7501757, -3.7657127]], dtype=float32)

time = 37347	action = 1	current_phase = 1	next_phase = 0	reward = -1.776068	array([[-5.519469, -3.526216]], dtype=float32)

time = 37355	action = 0	current_phase = 0	next_phase = 1	reward = -0.520722	array([[-2.1210196, -3.226248 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1137 - val_loss: 0.0238

Epoch 2/50

 - 4s - loss: 0.0576 - val_loss: 0.0233

Epoch 3/50

 - 4s - loss: 0.0984 - val_loss: 0.0241

Epoch 4/50

 - 4s - loss: 0.0966 - val_loss: 0.0238

Epoch 5/50

 - 4s - loss: 0.0743 - val_loss: 0.0253

Epoch 6/50

 - 4s - loss: 0.0686 - val_loss: 0.0235

Epoch 7/50

 - 4s - loss: 0.0621 - val_loss: 0.0240

Epoch 8/50

 - 4s - loss: 0.0535 - val_loss: 0.0237

Epoch 9/50

 - 4s - loss: 0.0718 - val_loss: 0.0260

Epoch 10/50

 - 4s - loss: 0.0540 - val_loss: 0.0258

Epoch 11/50

 - 4s - loss: 0.0622 - val_loss: 0.0279

Epoch 12/50

 - 4s - loss: 0.0488 - val_loss: 0.0272

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 978, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 966, after forget

time = 37360	action = 0	current_phase = 0	next_phase = 1	reward = -0.371344	array([[-1.7244639, -2.7417643]], dtype=float32)

time = 37365	action = 0	current_phase = 0	next_phase = 1	reward = -0.214167	array([[-1.989427, -2.828351]], dtype=float32)

time = 37370	action = 0	current_phase = 0	next_phase = 1	reward = 0.356389	array([[-2.101715, -2.208179]], dtype=float32)

time = 37375	action = 1	current_phase = 0	next_phase = 1	reward = -1.363596	array([[-4.5096703, -3.1686537]], dtype=float32)

time = 37383	action = 0	current_phase = 1	next_phase = 0	reward = -0.587329	array([[-2.3374426, -2.8431382]], dtype=float32)

time = 37388	action = 0	current_phase = 1	next_phase = 0	reward = -0.430489	array([[-2.1359541, -2.9649973]], dtype=float32)

time = 37393	action = 0	current_phase = 1	next_phase = 0	reward = -0.280606	array([[-2.1373475, -2.9630544]], dtype=float32)

time = 37398	action = 0	current_phase = 1	next_phase = 0	reward = -0.166781	array([[-2.271735 , -3.2190282]], dtype=float32)

time = 37403	action = 0	current_phase = 1	next_phase = 0	reward = -0.062834	array([[-2.69094  , -2.7459388]], dtype=float32)

time = 37408	action = 1	current_phase = 1	next_phase = 0	reward = -1.899755	array([[-5.600024 , -3.5840383]], dtype=float32)

time = 37416	action = 0	current_phase = 0	next_phase = 1	reward = -0.491648	array([[-2.0725038, -3.2034483]], dtype=float32)

time = 37421	action = 0	current_phase = 0	next_phase = 1	reward = -0.338477	array([[-1.724015 , -2.7391043]], dtype=float32)

time = 37426	action = 0	current_phase = 0	next_phase = 1	reward = -0.191852	array([[-2.073727 , -2.6026607]], dtype=float32)

time = 37431	action = 0	current_phase = 0	next_phase = 1	reward = 0.315010	array([[-2.2492266, -2.5313249]], dtype=float32)

time = 37436	action = 1	current_phase = 0	next_phase = 1	reward = -1.555200	array([[-4.6850834, -3.2437992]], dtype=float32)

time = 37444	action = 0	current_phase = 1	next_phase = 0	reward = -0.557520	array([[-2.080941 , -2.8498065]], dtype=float32)

time = 37449	action = 0	current_phase = 1	next_phase = 0	reward = -0.401299	array([[-1.9213415, -3.068496 ]], dtype=float32)

time = 37454	action = 0	current_phase = 1	next_phase = 0	reward = -0.256234	array([[-1.9180342, -3.0701494]], dtype=float32)

time = 37459	action = 0	current_phase = 1	next_phase = 0	reward = -0.173993	array([[-1.9638928, -3.669362 ]], dtype=float32)

time = 37464	action = 1	current_phase = 1	next_phase = 0	reward = -0.492148	array([[-2.4567199, -2.1536956]], dtype=float32)

time = 37472	action = 0	current_phase = 0	next_phase = 1	reward = -0.620719	array([[-2.1448638, -3.2038467]], dtype=float32)

time = 37477	action = 0	current_phase = 0	next_phase = 1	reward = -0.467300	array([[-1.7489891, -2.7730963]], dtype=float32)

time = 37482	action = 0	current_phase = 0	next_phase = 1	reward = -0.310598	array([[-1.9892471, -2.8276324]], dtype=float32)

time = 37487	action = 0	current_phase = 0	next_phase = 1	reward = -0.173461	array([[-2.3062325, -2.503944 ]], dtype=float32)

time = 37492	action = 0	current_phase = 0	next_phase = 1	reward = 0.108806	array([[-2.5752132, -3.2605286]], dtype=float32)

time = 37497	action = 1	current_phase = 0	next_phase = 1	reward = -1.784839	array([[-6.3440313, -3.5764437]], dtype=float32)

time = 37505	action = 0	current_phase = 1	next_phase = 0	reward = -0.523783	array([[-2.0571303, -2.8301284]], dtype=float32)

time = 37510	action = 0	current_phase = 1	next_phase = 0	reward = -0.374986	array([[-1.9207715, -3.069034 ]], dtype=float32)

time = 37515	action = 0	current_phase = 1	next_phase = 0	reward = -0.226666	array([[-1.9200068, -3.0685682]], dtype=float32)

time = 37520	action = 0	current_phase = 1	next_phase = 0	reward = 0.356515	array([[-2.0110548, -3.6102827]], dtype=float32)

time = 37525	action = 1	current_phase = 1	next_phase = 0	reward = -1.361077	array([[-3.6466537, -3.1413682]], dtype=float32)

time = 37533	action = 0	current_phase = 0	next_phase = 1	reward = -0.593132	array([[-2.1449325, -3.1951363]], dtype=float32)

time = 37538	action = 0	current_phase = 0	next_phase = 1	reward = -0.434150	array([[-1.7238623, -2.7390049]], dtype=float32)

time = 37543	action = 0	current_phase = 0	next_phase = 1	reward = -0.281150	array([[-1.9926965, -2.8348777]], dtype=float32)

time = 37548	action = 0	current_phase = 0	next_phase = 1	reward = -0.165884	array([[-2.467774 , -2.7086618]], dtype=float32)

time = 37553	action = 0	current_phase = 0	next_phase = 1	reward = 0.024080	array([[-2.801189 , -3.7426138]], dtype=float32)

time = 37558	action = 1	current_phase = 0	next_phase = 1	reward = -1.902618	array([[-6.357649 , -3.5532491]], dtype=float32)

time = 37566	action = 0	current_phase = 1	next_phase = 0	reward = -0.497847	array([[-2.1890917, -3.1694858]], dtype=float32)

time = 37571	action = 0	current_phase = 1	next_phase = 0	reward = -0.346026	array([[-2.1366618, -2.9643977]], dtype=float32)

time = 37576	action = 0	current_phase = 1	next_phase = 0	reward = -0.199723	array([[-2.057984 , -3.0095453]], dtype=float32)

time = 37581	action = 0	current_phase = 1	next_phase = 0	reward = 0.280781	array([[-2.2556844, -3.898516 ]], dtype=float32)

time = 37586	action = 1	current_phase = 1	next_phase = 0	reward = -1.609510	array([[-5.3540397, -3.3624177]], dtype=float32)

time = 37594	action = 0	current_phase = 0	next_phase = 1	reward = -0.553495	array([[-2.1270142, -3.1765857]], dtype=float32)

time = 37599	action = 0	current_phase = 0	next_phase = 1	reward = -0.391683	array([[-1.7238939, -2.73919  ]], dtype=float32)

time = 37604	action = 0	current_phase = 0	next_phase = 1	reward = -0.237345	array([[-1.9907193, -2.8348901]], dtype=float32)

time = 37609	action = 0	current_phase = 0	next_phase = 1	reward = -0.186458	array([[-2.1216068, -2.3776603]], dtype=float32)

time = 37614	action = 1	current_phase = 0	next_phase = 1	reward = -0.563385	array([[-4.0202856, -2.4391725]], dtype=float32)

time = 37622	action = 0	current_phase = 1	next_phase = 0	reward = -0.613150	array([[-2.3505592, -2.8221705]], dtype=float32)

time = 37627	action = 0	current_phase = 1	next_phase = 0	reward = -0.454150	array([[-2.178811 , -3.1878445]], dtype=float32)

time = 37632	action = 0	current_phase = 1	next_phase = 0	reward = -0.291599	array([[-2.1313713, -2.9353456]], dtype=float32)

time = 37637	action = 0	current_phase = 1	next_phase = 0	reward = -0.166556	array([[-2.324282 , -3.1722193]], dtype=float32)

time = 37642	action = 0	current_phase = 1	next_phase = 0	reward = 0.239835	array([[-2.715458 , -3.7119336]], dtype=float32)

time = 37647	action = 1	current_phase = 1	next_phase = 0	reward = -1.728630	array([[-5.517289 , -3.5544386]], dtype=float32)

time = 37655	action = 0	current_phase = 0	next_phase = 1	reward = -0.521760	array([[-2.0892687, -3.187447 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0737 - val_loss: 0.0322

Epoch 2/50

 - 4s - loss: 0.0600 - val_loss: 0.0378

Epoch 3/50

 - 4s - loss: 0.0544 - val_loss: 0.0387

Epoch 4/50

 - 4s - loss: 0.0494 - val_loss: 0.0344

Epoch 5/50

 - 4s - loss: 0.0606 - val_loss: 0.0348

Epoch 6/50

 - 4s - loss: 0.0542 - val_loss: 0.0354

Epoch 7/50

 - 4s - loss: 0.0530 - val_loss: 0.0365

Epoch 8/50

 - 4s - loss: 0.0421 - val_loss: 0.0395

Epoch 9/50

 - 4s - loss: 0.0535 - val_loss: 0.0458

Epoch 10/50

 - 4s - loss: 0.0569 - val_loss: 0.0404

Epoch 11/50

 - 4s - loss: 0.0517 - val_loss: 0.0377

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 983, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 971, after forget

time = 37660	action = 0	current_phase = 0	next_phase = 1	reward = -0.361963	array([[-1.7125418, -2.7013247]], dtype=float32)

time = 37665	action = 0	current_phase = 0	next_phase = 1	reward = -0.212769	array([[-1.9641824, -2.7531502]], dtype=float32)

time = 37670	action = 0	current_phase = 0	next_phase = 1	reward = 0.345695	array([[-2.1243908, -2.1871812]], dtype=float32)

time = 37675	action = 1	current_phase = 0	next_phase = 1	reward = -1.421951	array([[-4.5232143, -3.150849 ]], dtype=float32)

time = 37683	action = 0	current_phase = 1	next_phase = 0	reward = -0.592310	array([[-2.2210324, -2.9135835]], dtype=float32)

time = 37688	action = 0	current_phase = 1	next_phase = 0	reward = -0.437490	array([[-2.1077802, -2.9610195]], dtype=float32)

time = 37693	action = 0	current_phase = 1	next_phase = 0	reward = -0.280839	array([[-2.1151805, -2.9549594]], dtype=float32)

time = 37698	action = 0	current_phase = 1	next_phase = 0	reward = -0.159447	array([[-2.3022108, -3.2255812]], dtype=float32)

time = 37703	action = 0	current_phase = 1	next_phase = 0	reward = 0.025149	array([[-2.709223, -3.669089]], dtype=float32)

time = 37708	action = 1	current_phase = 1	next_phase = 0	reward = -1.891734	array([[-5.6322026, -3.590761 ]], dtype=float32)

time = 37716	action = 0	current_phase = 0	next_phase = 1	reward = -0.475192	array([[-2.0991752, -3.1868234]], dtype=float32)

time = 37721	action = 0	current_phase = 0	next_phase = 1	reward = -0.327968	array([[-1.7139076, -2.7007952]], dtype=float32)

time = 37726	action = 0	current_phase = 0	next_phase = 1	reward = -0.180484	array([[-2.047777 , -2.5567923]], dtype=float32)

time = 37731	action = 0	current_phase = 0	next_phase = 1	reward = 0.256436	array([[-2.322252 , -2.6211238]], dtype=float32)

time = 37736	action = 1	current_phase = 0	next_phase = 1	reward = -1.611659	array([[-4.651919 , -3.2439418]], dtype=float32)

time = 37744	action = 0	current_phase = 1	next_phase = 0	reward = -0.553480	array([[-2.0855742, -2.8862798]], dtype=float32)

time = 37749	action = 0	current_phase = 1	next_phase = 0	reward = -0.392732	array([[-1.9021493, -3.0791934]], dtype=float32)

time = 37754	action = 0	current_phase = 1	next_phase = 0	reward = -0.239414	array([[-1.8986053, -3.0725467]], dtype=float32)

time = 37759	action = 0	current_phase = 1	next_phase = 0	reward = -0.179810	array([[-1.9971888, -3.7091558]], dtype=float32)

time = 37764	action = 1	current_phase = 1	next_phase = 0	reward = -0.531335	array([[-2.5889304, -2.3609018]], dtype=float32)

time = 37772	action = 0	current_phase = 0	next_phase = 1	reward = -0.624731	array([[-2.1479862, -3.1628654]], dtype=float32)

time = 37777	action = 0	current_phase = 0	next_phase = 1	reward = -0.477197	array([[-1.7219759, -2.710944 ]], dtype=float32)

time = 37782	action = 0	current_phase = 0	next_phase = 1	reward = -0.324761	array([[-1.9602263, -2.7607598]], dtype=float32)

time = 37787	action = 0	current_phase = 0	next_phase = 1	reward = -0.180842	array([[-2.1081266, -2.5982876]], dtype=float32)

time = 37792	action = 0	current_phase = 0	next_phase = 1	reward = 0.196257	array([[-2.6407304, -3.3371596]], dtype=float32)

time = 37797	action = 1	current_phase = 0	next_phase = 1	reward = -1.785856	array([[-6.3803296, -3.5341465]], dtype=float32)

time = 37805	action = 0	current_phase = 1	next_phase = 0	reward = -0.534993	array([[-2.0581248, -2.8495226]], dtype=float32)

time = 37810	action = 0	current_phase = 1	next_phase = 0	reward = -0.384391	array([[-1.908082 , -3.0760348]], dtype=float32)

time = 37815	action = 0	current_phase = 1	next_phase = 0	reward = -0.225522	array([[-1.8992277, -3.0766795]], dtype=float32)

time = 37820	action = 0	current_phase = 1	next_phase = 0	reward = 0.362482	array([[-2.0955408, -3.6398103]], dtype=float32)

time = 37825	action = 1	current_phase = 1	next_phase = 0	reward = -1.359611	array([[-3.4948795, -2.9306064]], dtype=float32)

time = 37833	action = 0	current_phase = 0	next_phase = 1	reward = -0.586895	array([[-2.145693 , -3.1606362]], dtype=float32)

time = 37838	action = 0	current_phase = 0	next_phase = 1	reward = -0.433382	array([[-1.7163076, -2.6990712]], dtype=float32)

time = 37843	action = 0	current_phase = 0	next_phase = 1	reward = -0.275662	array([[-1.9605949, -2.7620895]], dtype=float32)

time = 37848	action = 1	current_phase = 0	next_phase = 1	reward = -0.796651	array([[-2.436443 , -2.3828876]], dtype=float32)

time = 37856	action = 1	current_phase = 1	next_phase = 0	reward = -1.609838	array([[-4.0685635, -3.4580681]], dtype=float32)

time = 37864	action = 0	current_phase = 0	next_phase = 1	reward = -0.552604	array([[-2.0324259, -2.758129 ]], dtype=float32)

time = 37869	action = 0	current_phase = 0	next_phase = 1	reward = -0.390957	array([[-1.7144407, -2.7035413]], dtype=float32)

time = 37874	action = 0	current_phase = 0	next_phase = 1	reward = -0.235148	array([[-1.9604932, -2.7622592]], dtype=float32)

time = 37879	action = 0	current_phase = 0	next_phase = 1	reward = -0.175278	array([[-2.10998 , -2.794281]], dtype=float32)

time = 37884	action = 1	current_phase = 0	next_phase = 1	reward = -0.583043	array([[-3.91679 , -2.344576]], dtype=float32)

time = 37892	action = 0	current_phase = 1	next_phase = 0	reward = -0.630699	array([[-2.3200583, -2.8368807]], dtype=float32)

time = 37897	action = 0	current_phase = 1	next_phase = 0	reward = -0.480230	array([[-2.1609423, -3.176686 ]], dtype=float32)

time = 37902	action = 0	current_phase = 1	next_phase = 0	reward = -0.321363	array([[-2.111043 , -2.9580195]], dtype=float32)

time = 37907	action = 0	current_phase = 1	next_phase = 0	reward = -0.172244	array([[-2.399924 , -3.0362566]], dtype=float32)

time = 37912	action = 0	current_phase = 1	next_phase = 0	reward = 0.266919	array([[-2.6965737, -3.7285414]], dtype=float32)

time = 37917	action = 1	current_phase = 1	next_phase = 0	reward = -1.729041	array([[-5.606843 , -3.5293531]], dtype=float32)

time = 37925	action = 0	current_phase = 0	next_phase = 1	reward = -0.532091	array([[-2.161074 , -3.2550912]], dtype=float32)

time = 37930	action = 0	current_phase = 0	next_phase = 1	reward = -0.371396	array([[-1.7129878, -2.702962 ]], dtype=float32)

time = 37935	action = 0	current_phase = 0	next_phase = 1	reward = -0.217262	array([[-1.9610361, -2.7628207]], dtype=float32)

time = 37940	action = 0	current_phase = 0	next_phase = 1	reward = 0.349384	array([[-2.1314075, -2.1943076]], dtype=float32)

time = 37945	action = 1	current_phase = 0	next_phase = 1	reward = -1.366276	array([[-4.5576844, -3.1315358]], dtype=float32)

time = 37953	action = 0	current_phase = 1	next_phase = 0	reward = -0.587931	array([[-2.1754353, -2.92229  ]], dtype=float32)

time = 37958	action = 0	current_phase = 1	next_phase = 0	reward = -0.424145	array([[-2.1174994, -2.9555607]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0845 - val_loss: 0.0259

Epoch 2/50

 - 4s - loss: 0.0729 - val_loss: 0.0236

Epoch 3/50

 - 4s - loss: 0.0787 - val_loss: 0.0257

Epoch 4/50

 - 4s - loss: 0.0822 - val_loss: 0.0226

Epoch 5/50

 - 4s - loss: 0.0978 - val_loss: 0.0272

Epoch 6/50

 - 4s - loss: 0.0740 - val_loss: 0.0269

Epoch 7/50

 - 4s - loss: 0.0850 - val_loss: 0.0332

Epoch 8/50

 - 4s - loss: 0.0789 - val_loss: 0.0293

Epoch 9/50

 - 4s - loss: 0.0764 - val_loss: 0.0289

Epoch 10/50

 - 4s - loss: 0.0735 - val_loss: 0.0425

Epoch 11/50

 - 4s - loss: 0.0615 - val_loss: 0.0353

Epoch 12/50

 - 4s - loss: 0.0655 - val_loss: 0.0330

Epoch 13/50

 - 4s - loss: 0.0724 - val_loss: 0.0257

Epoch 14/50

 - 4s - loss: 0.0709 - val_loss: 0.0260

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 989, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 976, after forget

time = 37963	action = 0	current_phase = 1	next_phase = 0	reward = -0.267021	array([[-2.0982535, -2.945907 ]], dtype=float32)

time = 37968	action = 0	current_phase = 1	next_phase = 0	reward = -0.167135	array([[-2.2656393, -3.2058456]], dtype=float32)

time = 37973	action = 0	current_phase = 1	next_phase = 0	reward = -0.006976	array([[-2.5709476, -2.8049273]], dtype=float32)

time = 37978	action = 1	current_phase = 1	next_phase = 0	reward = -1.902536	array([[-5.621539 , -3.5768435]], dtype=float32)

time = 37986	action = 0	current_phase = 0	next_phase = 1	reward = -0.499210	array([[-1.9805148, -3.2235727]], dtype=float32)

time = 37991	action = 0	current_phase = 0	next_phase = 1	reward = -0.344138	array([[-1.8533509, -2.7603068]], dtype=float32)

time = 37996	action = 0	current_phase = 0	next_phase = 1	reward = -0.199595	array([[-2.0934088, -2.3963785]], dtype=float32)

time = 38001	action = 0	current_phase = 0	next_phase = 1	reward = 0.335977	array([[-2.2471006, -2.6012392]], dtype=float32)

time = 38006	action = 1	current_phase = 0	next_phase = 1	reward = -1.451786	array([[-4.480881 , -3.1981313]], dtype=float32)

time = 38014	action = 0	current_phase = 1	next_phase = 0	reward = -0.561480	array([[-2.110921 , -2.8855014]], dtype=float32)

time = 38019	action = 0	current_phase = 1	next_phase = 0	reward = -0.402975	array([[-1.9118044, -3.0824878]], dtype=float32)

time = 38024	action = 0	current_phase = 1	next_phase = 0	reward = -0.247004	array([[-1.9069453, -3.0863483]], dtype=float32)

time = 38029	action = 0	current_phase = 1	next_phase = 0	reward = -0.183015	array([[-1.9907811, -3.7138622]], dtype=float32)

time = 38034	action = 1	current_phase = 1	next_phase = 0	reward = -0.527202	array([[-2.8215141, -2.3712983]], dtype=float32)

time = 38042	action = 0	current_phase = 0	next_phase = 1	reward = -0.618726	array([[-2.1342938, -3.1686273]], dtype=float32)

time = 38047	action = 0	current_phase = 0	next_phase = 1	reward = -0.462994	array([[-1.8859444, -2.7904868]], dtype=float32)

time = 38052	action = 0	current_phase = 0	next_phase = 1	reward = -0.313548	array([[-1.9739062, -2.7441008]], dtype=float32)

time = 38057	action = 0	current_phase = 0	next_phase = 1	reward = -0.182231	array([[-2.0180328, -2.7203004]], dtype=float32)

time = 38062	action = 0	current_phase = 0	next_phase = 1	reward = 0.216493	array([[-2.5301523, -3.0033429]], dtype=float32)

time = 38067	action = 1	current_phase = 0	next_phase = 1	reward = -1.729108	array([[-6.3894506, -3.561602 ]], dtype=float32)

time = 38075	action = 0	current_phase = 1	next_phase = 0	reward = -0.519501	array([[-2.0563765, -2.8626132]], dtype=float32)

time = 38080	action = 0	current_phase = 1	next_phase = 0	reward = -0.364710	array([[-1.9121304, -3.082754 ]], dtype=float32)

time = 38085	action = 0	current_phase = 1	next_phase = 0	reward = -0.209652	array([[-1.9136347, -3.0889652]], dtype=float32)

time = 38090	action = 0	current_phase = 1	next_phase = 0	reward = 0.348802	array([[-2.2590404, -3.8100114]], dtype=float32)

time = 38095	action = 1	current_phase = 1	next_phase = 0	reward = -1.312170	array([[-3.5952187, -3.0845037]], dtype=float32)

time = 38103	action = 0	current_phase = 0	next_phase = 1	reward = -0.590231	array([[-2.106062, -3.128731]], dtype=float32)

time = 38108	action = 0	current_phase = 0	next_phase = 1	reward = -0.427942	array([[-1.8539252, -2.7624478]], dtype=float32)

time = 38113	action = 0	current_phase = 0	next_phase = 1	reward = -0.276283	array([[-1.9741704, -2.7434366]], dtype=float32)

time = 38118	action = 0	current_phase = 0	next_phase = 1	reward = -0.164050	array([[-2.2881675, -2.8726966]], dtype=float32)

time = 38123	action = 0	current_phase = 0	next_phase = 1	reward = 0.053102	array([[-2.6531982, -3.5137813]], dtype=float32)

time = 38128	action = 1	current_phase = 0	next_phase = 1	reward = -1.900688	array([[-6.3679886, -3.5683558]], dtype=float32)

time = 38136	action = 0	current_phase = 1	next_phase = 0	reward = -0.501527	array([[-2.191329 , -3.1946363]], dtype=float32)

time = 38141	action = 0	current_phase = 1	next_phase = 0	reward = -0.346572	array([[-2.0180628, -3.01349  ]], dtype=float32)

time = 38146	action = 0	current_phase = 1	next_phase = 0	reward = -0.197702	array([[-1.9971799, -3.1022258]], dtype=float32)

time = 38151	action = 0	current_phase = 1	next_phase = 0	reward = 0.337135	array([[-2.3955946, -3.804773 ]], dtype=float32)

time = 38156	action = 1	current_phase = 1	next_phase = 0	reward = -1.499823	array([[-3.6929793, -3.1516387]], dtype=float32)

time = 38164	action = 0	current_phase = 0	next_phase = 1	reward = -0.556182	array([[-2.0916028, -3.1467595]], dtype=float32)

time = 38169	action = 0	current_phase = 0	next_phase = 1	reward = -0.400337	array([[-1.8532765, -2.7603414]], dtype=float32)

time = 38174	action = 0	current_phase = 0	next_phase = 1	reward = -0.247623	array([[-1.9744229, -2.7450044]], dtype=float32)

time = 38179	action = 0	current_phase = 0	next_phase = 1	reward = -0.182608	array([[-1.9736552, -2.940848 ]], dtype=float32)

time = 38184	action = 1	current_phase = 0	next_phase = 1	reward = -0.532314	array([[-3.9786649, -2.3426137]], dtype=float32)

time = 38192	action = 0	current_phase = 1	next_phase = 0	reward = -0.617579	array([[-2.2934074, -2.8106868]], dtype=float32)

time = 38197	action = 0	current_phase = 1	next_phase = 0	reward = -0.458503	array([[-2.1640978, -3.1842043]], dtype=float32)

time = 38202	action = 0	current_phase = 1	next_phase = 0	reward = -0.304738	array([[-2.097196 , -2.9598577]], dtype=float32)

time = 38207	action = 0	current_phase = 1	next_phase = 0	reward = -0.169528	array([[-2.3273358, -3.1704552]], dtype=float32)

time = 38212	action = 0	current_phase = 1	next_phase = 0	reward = 0.244951	array([[-2.6766343, -3.7773604]], dtype=float32)

time = 38217	action = 1	current_phase = 1	next_phase = 0	reward = -1.677389	array([[-5.643861 , -3.5153306]], dtype=float32)

time = 38225	action = 0	current_phase = 0	next_phase = 1	reward = -0.526768	array([[-1.9317086, -3.1952598]], dtype=float32)

time = 38230	action = 0	current_phase = 0	next_phase = 1	reward = -0.368516	array([[-1.8533368, -2.760748 ]], dtype=float32)

time = 38235	action = 0	current_phase = 0	next_phase = 1	reward = -0.217171	array([[-1.9759603, -2.7389743]], dtype=float32)

time = 38240	action = 0	current_phase = 0	next_phase = 1	reward = 0.351354	array([[-2.0620964, -2.275196 ]], dtype=float32)

time = 38245	action = 1	current_phase = 0	next_phase = 1	reward = -1.310960	array([[-4.4220643, -3.1656616]], dtype=float32)

time = 38253	action = 0	current_phase = 1	next_phase = 0	reward = -0.600107	array([[-2.2957063, -2.8314488]], dtype=float32)

time = 38258	action = 0	current_phase = 1	next_phase = 0	reward = -0.451276	array([[-2.0991938, -2.959006 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0521 - val_loss: 0.2734

Epoch 2/50

 - 4s - loss: 0.0839 - val_loss: 0.2765

Epoch 3/50

 - 3s - loss: 0.0710 - val_loss: 0.2753

Epoch 4/50

 - 4s - loss: 0.0832 - val_loss: 0.2884

Epoch 5/50

 - 4s - loss: 0.0525 - val_loss: 0.2778

Epoch 6/50

 - 4s - loss: 0.0333 - val_loss: 0.2807

Epoch 7/50

 - 4s - loss: 0.0668 - val_loss: 0.2853

Epoch 8/50

 - 4s - loss: 0.0484 - val_loss: 0.2838

Epoch 9/50

 - 4s - loss: 0.0497 - val_loss: 0.2819

Epoch 10/50

 - 4s - loss: 0.0490 - val_loss: 0.2873

Epoch 11/50

 - 4s - loss: 0.0426 - val_loss: 0.2986

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 994, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 981, after forget

time = 38263	action = 0	current_phase = 1	next_phase = 0	reward = -0.294373	array([[-2.0885487, -2.962069 ]], dtype=float32)

time = 38268	action = 0	current_phase = 1	next_phase = 0	reward = -0.166812	array([[-2.277176 , -3.2187574]], dtype=float32)

time = 38273	action = 0	current_phase = 1	next_phase = 0	reward = 0.111263	array([[-2.6625953, -3.7104924]], dtype=float32)

time = 38278	action = 1	current_phase = 1	next_phase = 0	reward = -1.909215	array([[-5.6376505, -3.5645304]], dtype=float32)

time = 38286	action = 0	current_phase = 0	next_phase = 1	reward = -0.517528	array([[-1.852351 , -3.3032625]], dtype=float32)

time = 38291	action = 0	current_phase = 0	next_phase = 1	reward = -0.361531	array([[-1.8995097, -2.8494208]], dtype=float32)

time = 38296	action = 0	current_phase = 0	next_phase = 1	reward = -0.211592	array([[-1.9896669, -2.7302957]], dtype=float32)

time = 38301	action = 0	current_phase = 0	next_phase = 1	reward = 0.303154	array([[-2.2412844, -2.7246485]], dtype=float32)

time = 38306	action = 1	current_phase = 0	next_phase = 1	reward = -1.506992	array([[-4.5886993, -3.259249 ]], dtype=float32)

time = 38314	action = 0	current_phase = 1	next_phase = 0	reward = -0.569126	array([[-2.1204722, -2.9400642]], dtype=float32)

time = 38319	action = 0	current_phase = 1	next_phase = 0	reward = -0.409834	array([[-1.8915193, -3.0941484]], dtype=float32)

time = 38324	action = 0	current_phase = 1	next_phase = 0	reward = -0.252874	array([[-1.8925278, -3.0901518]], dtype=float32)

time = 38329	action = 0	current_phase = 1	next_phase = 0	reward = -0.169287	array([[-1.9896821, -3.6781082]], dtype=float32)

time = 38334	action = 1	current_phase = 1	next_phase = 0	reward = -0.467869	array([[-2.6471786, -2.2069905]], dtype=float32)

time = 38342	action = 0	current_phase = 0	next_phase = 1	reward = -0.615594	array([[-2.1470807, -3.3154337]], dtype=float32)

time = 38347	action = 0	current_phase = 0	next_phase = 1	reward = -0.457853	array([[-1.9133444, -2.8633692]], dtype=float32)

time = 38352	action = 0	current_phase = 0	next_phase = 1	reward = -0.306553	array([[-1.971322 , -2.7611883]], dtype=float32)

time = 38357	action = 0	current_phase = 0	next_phase = 1	reward = -0.174767	array([[-2.297644 , -3.0157902]], dtype=float32)

time = 38362	action = 0	current_phase = 0	next_phase = 1	reward = 0.172854	array([[-2.6388004, -4.042745 ]], dtype=float32)

time = 38367	action = 1	current_phase = 0	next_phase = 1	reward = -1.781525	array([[-6.4038396, -3.557653 ]], dtype=float32)

time = 38375	action = 0	current_phase = 1	next_phase = 0	reward = -0.520948	array([[-2.0343459, -2.8347304]], dtype=float32)

time = 38380	action = 0	current_phase = 1	next_phase = 0	reward = -0.364338	array([[-1.8919044, -3.0941763]], dtype=float32)

time = 38385	action = 0	current_phase = 1	next_phase = 0	reward = -0.213154	array([[-1.8909717, -3.0949562]], dtype=float32)

time = 38390	action = 0	current_phase = 1	next_phase = 0	reward = 0.365215	array([[-2.0294995, -3.7151833]], dtype=float32)

time = 38395	action = 1	current_phase = 1	next_phase = 0	reward = -1.255667	array([[-3.5609593, -3.0675764]], dtype=float32)

time = 38403	action = 0	current_phase = 0	next_phase = 1	reward = -0.587916	array([[-2.0613468, -3.1562357]], dtype=float32)

time = 38408	action = 0	current_phase = 0	next_phase = 1	reward = -0.433833	array([[-1.9005567, -2.852484 ]], dtype=float32)

time = 38413	action = 0	current_phase = 0	next_phase = 1	reward = -0.276397	array([[-1.9610641, -2.7875354]], dtype=float32)

time = 38418	action = 0	current_phase = 0	next_phase = 1	reward = -0.170393	array([[-2.4445071, -3.051998 ]], dtype=float32)

time = 38423	action = 0	current_phase = 0	next_phase = 1	reward = -0.014863	array([[-2.665895 , -4.1572924]], dtype=float32)

time = 38428	action = 1	current_phase = 0	next_phase = 1	reward = -1.899368	array([[-6.408981 , -3.6177895]], dtype=float32)

time = 38436	action = 0	current_phase = 1	next_phase = 0	reward = -0.492937	array([[-2.0951862, -3.1960275]], dtype=float32)

time = 38441	action = 0	current_phase = 1	next_phase = 0	reward = -0.343829	array([[-2.032388 , -3.0019493]], dtype=float32)

time = 38446	action = 0	current_phase = 1	next_phase = 0	reward = -0.195958	array([[-1.9132142, -3.117585 ]], dtype=float32)

time = 38451	action = 0	current_phase = 1	next_phase = 0	reward = 0.306321	array([[-2.2486758, -3.908927 ]], dtype=float32)

time = 38456	action = 1	current_phase = 1	next_phase = 0	reward = -1.503074	array([[-5.312696 , -3.2720473]], dtype=float32)

time = 38464	action = 0	current_phase = 0	next_phase = 1	reward = -0.559614	array([[-2.007548, -3.047287]], dtype=float32)

time = 38469	action = 0	current_phase = 0	next_phase = 1	reward = -0.398443	array([[-1.8981539, -2.8480515]], dtype=float32)

time = 38474	action = 0	current_phase = 0	next_phase = 1	reward = -0.242169	array([[-1.9612026, -2.7881665]], dtype=float32)

time = 38479	action = 0	current_phase = 0	next_phase = 1	reward = -0.175948	array([[-2.025813 , -3.0865357]], dtype=float32)

time = 38484	action = 1	current_phase = 0	next_phase = 1	reward = -0.482756	array([[-3.9309216, -2.3265266]], dtype=float32)

time = 38492	action = 0	current_phase = 1	next_phase = 0	reward = -0.620663	array([[-2.2863126, -2.8089879]], dtype=float32)

time = 38497	action = 0	current_phase = 1	next_phase = 0	reward = -0.461431	array([[-2.0859995, -3.2014782]], dtype=float32)

time = 38502	action = 0	current_phase = 1	next_phase = 0	reward = -0.296978	array([[-2.089318, -2.965868]], dtype=float32)

time = 38507	action = 0	current_phase = 1	next_phase = 0	reward = -0.169351	array([[-2.3366227, -3.1172745]], dtype=float32)

time = 38512	action = 0	current_phase = 1	next_phase = 0	reward = 0.175351	array([[-2.7313504, -3.6014051]], dtype=float32)

time = 38517	action = 1	current_phase = 1	next_phase = 0	reward = -1.781985	array([[-5.590568 , -3.5565379]], dtype=float32)

time = 38525	action = 0	current_phase = 0	next_phase = 1	reward = -0.516537	array([[-1.9322131, -3.2730248]], dtype=float32)

time = 38530	action = 0	current_phase = 0	next_phase = 1	reward = -0.360897	array([[-1.8980751, -2.8482718]], dtype=float32)

time = 38535	action = 0	current_phase = 0	next_phase = 1	reward = -0.208325	array([[-1.9615986, -2.7862518]], dtype=float32)

time = 38540	action = 0	current_phase = 0	next_phase = 1	reward = 0.339748	array([[-2.0466993, -2.314336 ]], dtype=float32)

time = 38545	action = 1	current_phase = 0	next_phase = 1	reward = -1.371472	array([[-4.458484 , -3.1538007]], dtype=float32)

time = 38553	action = 0	current_phase = 1	next_phase = 0	reward = -0.589717	array([[-2.2820554, -2.8256633]], dtype=float32)

time = 38558	action = 0	current_phase = 1	next_phase = 0	reward = -0.422584	array([[-2.0910463, -2.966554 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0890 - val_loss: 0.0266

Epoch 2/50

 - 4s - loss: 0.0599 - val_loss: 0.0252

Epoch 3/50

 - 4s - loss: 0.0501 - val_loss: 0.0269

Epoch 4/50

 - 4s - loss: 0.0589 - val_loss: 0.0287

Epoch 5/50

 - 4s - loss: 0.0491 - val_loss: 0.0249

Epoch 6/50

 - 4s - loss: 0.0408 - val_loss: 0.0251

Epoch 7/50

 - 4s - loss: 0.0593 - val_loss: 0.0251

Epoch 8/50

 - 4s - loss: 0.0406 - val_loss: 0.0262

Epoch 9/50

 - 4s - loss: 0.0663 - val_loss: 0.0253

Epoch 10/50

 - 4s - loss: 0.0558 - val_loss: 0.0257

Epoch 11/50

 - 4s - loss: 0.0407 - val_loss: 0.0258

Epoch 12/50

 - 4s - loss: 0.0350 - val_loss: 0.0266

Epoch 13/50

 - 4s - loss: 0.0388 - val_loss: 0.0276

Epoch 14/50

 - 4s - loss: 0.0345 - val_loss: 0.0261

Epoch 15/50

 - 4s - loss: 0.0541 - val_loss: 0.0257

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 999, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 986, after forget

time = 38563	action = 0	current_phase = 1	next_phase = 0	reward = -0.253910	array([[-2.1178908, -2.9996173]], dtype=float32)

time = 38568	action = 0	current_phase = 1	next_phase = 0	reward = -0.162257	array([[-2.2376711, -3.341033 ]], dtype=float32)

time = 38573	action = 1	current_phase = 1	next_phase = 0	reward = -1.085517	array([[-2.811153 , -2.7796488]], dtype=float32)

time = 38581	action = 1	current_phase = 0	next_phase = 1	reward = -2.006878	array([[-4.6173635, -3.6170664]], dtype=float32)

time = 38589	action = 0	current_phase = 1	next_phase = 0	reward = -0.400239	array([[-1.8549559, -3.0555067]], dtype=float32)

time = 38594	action = 0	current_phase = 1	next_phase = 0	reward = -0.248534	array([[-1.904843 , -3.1295047]], dtype=float32)

time = 38599	action = 0	current_phase = 1	next_phase = 0	reward = -0.175501	array([[-1.740281 , -3.9295168]], dtype=float32)

time = 38604	action = 0	current_phase = 1	next_phase = 0	reward = -0.135959	array([[-1.0803578, -1.9658027]], dtype=float32)

time = 38609	action = 1	current_phase = 1	next_phase = 0	reward = -2.011554	array([[-5.10628  , -3.7638953]], dtype=float32)

time = 38617	action = 0	current_phase = 0	next_phase = 1	reward = -0.464572	array([[-1.8607463, -3.2077193]], dtype=float32)

time = 38622	action = 0	current_phase = 0	next_phase = 1	reward = -0.314090	array([[-2.029446 , -2.5374486]], dtype=float32)

time = 38627	action = 0	current_phase = 0	next_phase = 1	reward = -0.175450	array([[-2.1334667, -2.8381066]], dtype=float32)

time = 38632	action = 0	current_phase = 0	next_phase = 1	reward = 0.236490	array([[-2.5769272, -3.3755007]], dtype=float32)

time = 38637	action = 1	current_phase = 0	next_phase = 1	reward = -1.778290	array([[-4.662934, -3.155208]], dtype=float32)

time = 38645	action = 0	current_phase = 1	next_phase = 0	reward = -0.525131	array([[-2.0701165, -2.826549 ]], dtype=float32)

time = 38650	action = 0	current_phase = 1	next_phase = 0	reward = -0.370440	array([[-1.9088651, -3.1249738]], dtype=float32)

time = 38655	action = 0	current_phase = 1	next_phase = 0	reward = -0.222717	array([[-1.9033566, -3.1290245]], dtype=float32)

time = 38660	action = 0	current_phase = 1	next_phase = 0	reward = 0.362935	array([[-2.0816326, -3.776497 ]], dtype=float32)

time = 38665	action = 1	current_phase = 1	next_phase = 0	reward = -1.311764	array([[-3.5151515, -3.067495 ]], dtype=float32)

time = 38673	action = 0	current_phase = 0	next_phase = 1	reward = -0.595672	array([[-1.9745368, -3.1825044]], dtype=float32)

time = 38678	action = 0	current_phase = 0	next_phase = 1	reward = -0.434595	array([[-1.951417 , -2.8359506]], dtype=float32)

time = 38683	action = 0	current_phase = 0	next_phase = 1	reward = -0.277166	array([[-1.971139 , -2.7235398]], dtype=float32)

time = 38688	action = 0	current_phase = 0	next_phase = 1	reward = -0.161673	array([[-2.352839 , -2.9483247]], dtype=float32)

time = 38693	action = 0	current_phase = 0	next_phase = 1	reward = 0.123850	array([[-2.7050514, -4.0727243]], dtype=float32)

time = 38698	action = 1	current_phase = 0	next_phase = 1	reward = -1.907903	array([[-6.401861 , -3.5462947]], dtype=float32)

time = 38706	action = 0	current_phase = 1	next_phase = 0	reward = -0.522277	array([[-2.189779, -3.23706 ]], dtype=float32)

time = 38711	action = 0	current_phase = 1	next_phase = 0	reward = -0.375353	array([[-1.9771607, -3.0810003]], dtype=float32)

time = 38716	action = 0	current_phase = 1	next_phase = 0	reward = -0.223455	array([[-1.9155124, -3.1284153]], dtype=float32)

time = 38721	action = 0	current_phase = 1	next_phase = 0	reward = 0.346884	array([[-2.2231512, -3.9343193]], dtype=float32)

time = 38726	action = 1	current_phase = 1	next_phase = 0	reward = -1.495962	array([[-3.6013587, -3.1330435]], dtype=float32)

time = 38734	action = 0	current_phase = 0	next_phase = 1	reward = -0.557608	array([[-1.9520538, -3.12566  ]], dtype=float32)

time = 38739	action = 0	current_phase = 0	next_phase = 1	reward = -0.415924	array([[-1.946166 , -2.8274908]], dtype=float32)

time = 38744	action = 0	current_phase = 0	next_phase = 1	reward = -0.262773	array([[-1.8256694, -2.728128 ]], dtype=float32)

time = 38749	action = 0	current_phase = 0	next_phase = 1	reward = -0.170222	array([[-2.0427485, -3.0031989]], dtype=float32)

time = 38754	action = 1	current_phase = 0	next_phase = 1	reward = -0.436333	array([[-3.9811459, -2.2884412]], dtype=float32)

time = 38762	action = 0	current_phase = 1	next_phase = 0	reward = -0.622894	array([[-2.3290687, -2.8522363]], dtype=float32)

time = 38767	action = 0	current_phase = 1	next_phase = 0	reward = -0.465593	array([[-2.1394904, -3.2081432]], dtype=float32)

time = 38772	action = 0	current_phase = 1	next_phase = 0	reward = -0.311266	array([[-2.12681  , -2.9937747]], dtype=float32)

time = 38777	action = 0	current_phase = 1	next_phase = 0	reward = -0.170093	array([[-2.3337474, -3.2235792]], dtype=float32)

time = 38782	action = 0	current_phase = 1	next_phase = 0	reward = 0.201195	array([[-2.6610937, -3.7747269]], dtype=float32)

time = 38787	action = 1	current_phase = 1	next_phase = 0	reward = -1.778194	array([[-5.62433, -3.57064]], dtype=float32)

time = 38795	action = 0	current_phase = 0	next_phase = 1	reward = -0.522176	array([[-1.9264274, -3.2198179]], dtype=float32)

time = 38800	action = 0	current_phase = 0	next_phase = 1	reward = -0.369665	array([[-1.9448532, -2.8302996]], dtype=float32)

time = 38805	action = 0	current_phase = 0	next_phase = 1	reward = -0.216473	array([[-1.9701091, -2.7272463]], dtype=float32)

time = 38810	action = 0	current_phase = 0	next_phase = 1	reward = 0.052007	array([[-2.0771089, -2.360745 ]], dtype=float32)

time = 38815	action = 1	current_phase = 0	next_phase = 1	reward = -1.137155	array([[-4.300092 , -2.9602582]], dtype=float32)

time = 38823	action = 0	current_phase = 1	next_phase = 0	reward = -0.587544	array([[-2.3079302, -2.8901277]], dtype=float32)

time = 38828	action = 0	current_phase = 1	next_phase = 0	reward = -0.436053	array([[-2.132676, -2.99567 ]], dtype=float32)

time = 38833	action = 0	current_phase = 1	next_phase = 0	reward = -0.282342	array([[-2.129917 , -2.9945376]], dtype=float32)

time = 38838	action = 0	current_phase = 1	next_phase = 0	reward = -0.162542	array([[-2.3399122, -3.230732 ]], dtype=float32)

time = 38843	action = 0	current_phase = 1	next_phase = 0	reward = -0.049342	array([[-2.6654074, -2.9896965]], dtype=float32)

time = 38848	action = 1	current_phase = 1	next_phase = 0	reward = -1.904010	array([[-5.639996 , -3.5807734]], dtype=float32)

time = 38856	action = 0	current_phase = 0	next_phase = 1	reward = -0.497460	array([[-1.8991278, -3.2122974]], dtype=float32)

time = 38861	action = 0	current_phase = 0	next_phase = 1	reward = -0.351736	array([[-1.9483773, -2.8195908]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1118 - val_loss: 0.0280

Epoch 2/50

 - 4s - loss: 0.1622 - val_loss: 0.0275

Epoch 3/50

 - 4s - loss: 0.0844 - val_loss: 0.0287

Epoch 4/50

 - 4s - loss: 0.0645 - val_loss: 0.0270

Epoch 5/50

 - 4s - loss: 0.0426 - val_loss: 0.0288

Epoch 6/50

 - 4s - loss: 0.0611 - val_loss: 0.0240

Epoch 7/50

 - 4s - loss: 0.0514 - val_loss: 0.0245

Epoch 8/50

 - 4s - loss: 0.0398 - val_loss: 0.0246

Epoch 9/50

 - 4s - loss: 0.0420 - val_loss: 0.0293

Epoch 10/50

 - 4s - loss: 0.0439 - val_loss: 0.0251

Epoch 11/50

 - 4s - loss: 0.0328 - val_loss: 0.0296

Epoch 12/50

 - 4s - loss: 0.0558 - val_loss: 0.0397

Epoch 13/50

 - 4s - loss: 0.0380 - val_loss: 0.0346

Epoch 14/50

 - 4s - loss: 0.0338 - val_loss: 0.0287

Epoch 15/50

 - 4s - loss: 0.0732 - val_loss: 0.0350

Epoch 16/50

 - 4s - loss: 0.0548 - val_loss: 0.0356

length of memory (state 0, action 0): 1019, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1004, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1024, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 992, after forget

time = 38866	action = 0	current_phase = 0	next_phase = 1	reward = -0.210026	array([[-2.1596766, -2.30172  ]], dtype=float32)

time = 38871	action = 0	current_phase = 0	next_phase = 1	reward = 0.330906	array([[-2.2637024, -2.584876 ]], dtype=float32)

time = 38876	action = 1	current_phase = 0	next_phase = 1	reward = -1.557028	array([[-4.551762 , -3.2049885]], dtype=float32)

time = 38884	action = 0	current_phase = 1	next_phase = 0	reward = -0.557150	array([[-2.1131957, -2.9513843]], dtype=float32)

time = 38889	action = 0	current_phase = 1	next_phase = 0	reward = -0.399718	array([[-1.8965812, -3.107941 ]], dtype=float32)

time = 38894	action = 0	current_phase = 1	next_phase = 0	reward = -0.236598	array([[-1.8948367, -3.10731  ]], dtype=float32)

time = 38899	action = 0	current_phase = 1	next_phase = 0	reward = -0.176510	array([[-1.9768175, -3.7533085]], dtype=float32)

time = 38904	action = 1	current_phase = 1	next_phase = 0	reward = -0.483499	array([[-2.5796099, -2.0722034]], dtype=float32)

time = 38912	action = 0	current_phase = 0	next_phase = 1	reward = -0.615763	array([[-2.053051 , -3.4266186]], dtype=float32)

time = 38917	action = 0	current_phase = 0	next_phase = 1	reward = -0.459502	array([[-1.9776744, -2.8265257]], dtype=float32)

time = 38922	action = 0	current_phase = 0	next_phase = 1	reward = -0.302957	array([[-2.072069, -2.49035 ]], dtype=float32)

time = 38927	action = 0	current_phase = 0	next_phase = 1	reward = -0.167086	array([[-2.2358785, -2.9582393]], dtype=float32)

time = 38932	action = 0	current_phase = 0	next_phase = 1	reward = 0.131217	array([[-2.4801152, -3.4903271]], dtype=float32)

time = 38937	action = 1	current_phase = 0	next_phase = 1	reward = -1.789339	array([[-6.4294624, -3.5685155]], dtype=float32)

time = 38945	action = 0	current_phase = 1	next_phase = 0	reward = -0.524849	array([[-2.1004908, -2.8982365]], dtype=float32)

time = 38950	action = 0	current_phase = 1	next_phase = 0	reward = -0.372298	array([[-1.8971245, -3.10754  ]], dtype=float32)

time = 38955	action = 0	current_phase = 1	next_phase = 0	reward = -0.224446	array([[-1.8960562, -3.1086843]], dtype=float32)

time = 38960	action = 0	current_phase = 1	next_phase = 0	reward = 0.359522	array([[-2.1462154, -3.8147652]], dtype=float32)

time = 38965	action = 1	current_phase = 1	next_phase = 0	reward = -1.299371	array([[-4.7676487, -3.1683068]], dtype=float32)

time = 38973	action = 0	current_phase = 0	next_phase = 1	reward = -0.586625	array([[-1.9839097, -3.1508057]], dtype=float32)

time = 38978	action = 0	current_phase = 0	next_phase = 1	reward = -0.441804	array([[-1.9699323, -2.8114822]], dtype=float32)

time = 38983	action = 0	current_phase = 0	next_phase = 1	reward = -0.298811	array([[-2.029052 , -2.7019317]], dtype=float32)

time = 38988	action = 0	current_phase = 0	next_phase = 1	reward = -0.172142	array([[-2.3336568, -2.949354 ]], dtype=float32)

time = 38993	action = 0	current_phase = 0	next_phase = 1	reward = 0.066044	array([[-2.8519952, -3.9630814]], dtype=float32)

time = 38998	action = 1	current_phase = 0	next_phase = 1	reward = -1.893304	array([[-6.40501  , -3.5486755]], dtype=float32)

time = 39006	action = 0	current_phase = 1	next_phase = 0	reward = -0.494988	array([[-2.0720398, -3.1562967]], dtype=float32)

time = 39011	action = 0	current_phase = 1	next_phase = 0	reward = -0.335961	array([[-2.0159647, -3.0278642]], dtype=float32)

time = 39016	action = 0	current_phase = 1	next_phase = 0	reward = -0.191700	array([[-1.9379148, -3.0904818]], dtype=float32)

time = 39021	action = 0	current_phase = 1	next_phase = 0	reward = 0.290179	array([[-2.2667632, -3.931749 ]], dtype=float32)

time = 39026	action = 1	current_phase = 1	next_phase = 0	reward = -1.563264	array([[-5.44468  , -3.3002489]], dtype=float32)

time = 39034	action = 0	current_phase = 0	next_phase = 1	reward = -0.558830	array([[-1.9636226, -3.0911589]], dtype=float32)

time = 39039	action = 0	current_phase = 0	next_phase = 1	reward = -0.400516	array([[-1.9703658, -2.8099096]], dtype=float32)

time = 39044	action = 0	current_phase = 0	next_phase = 1	reward = -0.239079	array([[-2.0272305, -2.7014487]], dtype=float32)

time = 39049	action = 0	current_phase = 0	next_phase = 1	reward = -0.185010	array([[-2.0360663, -2.9422102]], dtype=float32)

time = 39054	action = 1	current_phase = 0	next_phase = 1	reward = -0.552562	array([[-3.9096065, -2.3140152]], dtype=float32)

time = 39062	action = 0	current_phase = 1	next_phase = 0	reward = -0.619516	array([[-2.3250828, -2.8175216]], dtype=float32)

time = 39067	action = 0	current_phase = 1	next_phase = 0	reward = -0.461425	array([[-2.1252527, -3.192634 ]], dtype=float32)

time = 39072	action = 0	current_phase = 1	next_phase = 0	reward = -0.310394	array([[-2.1153405, -2.96059  ]], dtype=float32)

time = 39077	action = 0	current_phase = 1	next_phase = 0	reward = -0.171679	array([[-2.2654219, -3.2287467]], dtype=float32)

time = 39082	action = 0	current_phase = 1	next_phase = 0	reward = 0.241901	array([[-2.7318542, -3.723644 ]], dtype=float32)

time = 39087	action = 1	current_phase = 1	next_phase = 0	reward = -1.782676	array([[-5.55503  , -3.3579528]], dtype=float32)

time = 39095	action = 0	current_phase = 0	next_phase = 1	reward = -0.534998	array([[-1.860579, -3.21204 ]], dtype=float32)

time = 39100	action = 0	current_phase = 0	next_phase = 1	reward = -0.379677	array([[-1.9706713, -2.8081777]], dtype=float32)

time = 39105	action = 0	current_phase = 0	next_phase = 1	reward = -0.220039	array([[-2.0286095, -2.6969259]], dtype=float32)

time = 39110	action = 0	current_phase = 0	next_phase = 1	reward = 0.068649	array([[-2.1378663, -2.3227963]], dtype=float32)

time = 39115	action = 1	current_phase = 0	next_phase = 1	reward = -1.133698	array([[-4.2099586, -2.9090855]], dtype=float32)

time = 39123	action = 0	current_phase = 1	next_phase = 0	reward = -0.586637	array([[-2.3191926, -2.8293324]], dtype=float32)

time = 39128	action = 0	current_phase = 1	next_phase = 0	reward = -0.434976	array([[-2.1122851, -2.962651 ]], dtype=float32)

time = 39133	action = 0	current_phase = 1	next_phase = 0	reward = -0.276711	array([[-2.1146784, -2.9567988]], dtype=float32)

time = 39138	action = 0	current_phase = 1	next_phase = 0	reward = -0.161510	array([[-2.2402623, -3.2632363]], dtype=float32)

time = 39143	action = 0	current_phase = 1	next_phase = 0	reward = 0.135146	array([[-2.6958   , -3.1263375]], dtype=float32)

time = 39148	action = 1	current_phase = 1	next_phase = 0	reward = -1.899507	array([[-5.654748, -3.518542]], dtype=float32)

time = 39156	action = 0	current_phase = 0	next_phase = 1	reward = -0.504011	array([[-1.8936716, -3.2035408]], dtype=float32)

time = 39161	action = 0	current_phase = 0	next_phase = 1	reward = -0.343570	array([[-1.9729923, -2.7996287]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1205 - val_loss: 0.0239

Epoch 2/50

 - 4s - loss: 0.1296 - val_loss: 0.0263

Epoch 3/50

 - 4s - loss: 0.1241 - val_loss: 0.0264

Epoch 4/50

 - 4s - loss: 0.1360 - val_loss: 0.0265

Epoch 5/50

 - 4s - loss: 0.0885 - val_loss: 0.0265

Epoch 6/50

 - 4s - loss: 0.0796 - val_loss: 0.0253

Epoch 7/50

 - 4s - loss: 0.0750 - val_loss: 0.0258

Epoch 8/50

 - 4s - loss: 0.0959 - val_loss: 0.0283

Epoch 9/50

 - 4s - loss: 0.1044 - val_loss: 0.0326

Epoch 10/50

 - 4s - loss: 0.1180 - val_loss: 0.0266

Epoch 11/50

 - 4s - loss: 0.0739 - val_loss: 0.0286

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 997, after forget

time = 39166	action = 0	current_phase = 0	next_phase = 1	reward = -0.201448	array([[-2.1128802, -2.3832028]], dtype=float32)

time = 39171	action = 0	current_phase = 0	next_phase = 1	reward = 0.301301	array([[-2.2933586, -2.5081894]], dtype=float32)

time = 39176	action = 1	current_phase = 0	next_phase = 1	reward = -1.607081	array([[-4.757059, -3.267687]], dtype=float32)

time = 39184	action = 0	current_phase = 1	next_phase = 0	reward = -0.551064	array([[-2.1512203, -2.9282715]], dtype=float32)

time = 39189	action = 0	current_phase = 1	next_phase = 0	reward = -0.388891	array([[-1.931779 , -3.0826495]], dtype=float32)

time = 39194	action = 0	current_phase = 1	next_phase = 0	reward = -0.237436	array([[-1.9215722, -3.089202 ]], dtype=float32)

time = 39199	action = 0	current_phase = 1	next_phase = 0	reward = 0.113735	array([[-1.9728554, -3.728122 ]], dtype=float32)

time = 39204	action = 1	current_phase = 1	next_phase = 0	reward = -0.658987	array([[-3.0759068, -2.2942026]], dtype=float32)

time = 39212	action = 0	current_phase = 0	next_phase = 1	reward = -0.617146	array([[-2.0647967, -3.278829 ]], dtype=float32)

time = 39217	action = 0	current_phase = 0	next_phase = 1	reward = -0.458902	array([[-2.0342324, -2.8287373]], dtype=float32)

time = 39222	action = 0	current_phase = 0	next_phase = 1	reward = -0.295179	array([[-2.0865715, -2.4670348]], dtype=float32)

time = 39227	action = 0	current_phase = 0	next_phase = 1	reward = -0.166865	array([[-2.3834949, -2.9411166]], dtype=float32)

time = 39232	action = 0	current_phase = 0	next_phase = 1	reward = 0.175732	array([[-2.70465  , -3.5498297]], dtype=float32)

time = 39237	action = 1	current_phase = 0	next_phase = 1	reward = -1.779313	array([[-6.48347, -3.50365]], dtype=float32)

time = 39245	action = 0	current_phase = 1	next_phase = 0	reward = -0.528877	array([[-2.1078568, -2.8742905]], dtype=float32)

time = 39250	action = 0	current_phase = 1	next_phase = 0	reward = -0.371093	array([[-1.9152788, -3.09445  ]], dtype=float32)

time = 39255	action = 0	current_phase = 1	next_phase = 0	reward = -0.208441	array([[-1.9070587, -3.0992894]], dtype=float32)

time = 39260	action = 0	current_phase = 1	next_phase = 0	reward = 0.356017	array([[-2.1167912, -3.8262873]], dtype=float32)

time = 39265	action = 1	current_phase = 1	next_phase = 0	reward = -1.365934	array([[-3.5595381, -3.0850694]], dtype=float32)

time = 39273	action = 0	current_phase = 0	next_phase = 1	reward = -0.586424	array([[-2.073938 , -3.2954845]], dtype=float32)

time = 39278	action = 0	current_phase = 0	next_phase = 1	reward = -0.436812	array([[-2.0305824, -2.818454 ]], dtype=float32)

time = 39283	action = 0	current_phase = 0	next_phase = 1	reward = -0.286513	array([[-2.037591 , -2.6479843]], dtype=float32)

time = 39288	action = 0	current_phase = 0	next_phase = 1	reward = -0.167139	array([[-2.4418151, -2.990768 ]], dtype=float32)

time = 39293	action = 0	current_phase = 0	next_phase = 1	reward = 0.056960	array([[-2.7261589, -4.308025 ]], dtype=float32)

time = 39298	action = 1	current_phase = 0	next_phase = 1	reward = -1.883894	array([[-6.429376, -3.559541]], dtype=float32)

time = 39306	action = 0	current_phase = 1	next_phase = 0	reward = -0.477715	array([[-2.1809018, -3.1367185]], dtype=float32)

time = 39311	action = 0	current_phase = 1	next_phase = 0	reward = -0.324460	array([[-2.1368089, -2.9534297]], dtype=float32)

time = 39316	action = 0	current_phase = 1	next_phase = 0	reward = -0.182249	array([[-2.2054255, -2.9766104]], dtype=float32)

time = 39321	action = 0	current_phase = 1	next_phase = 0	reward = 0.293271	array([[-2.3126562, -3.820444 ]], dtype=float32)

time = 39326	action = 1	current_phase = 1	next_phase = 0	reward = -1.503614	array([[-5.5341597, -3.4051602]], dtype=float32)

time = 39334	action = 0	current_phase = 0	next_phase = 1	reward = -0.552526	array([[-2.0029569, -3.0358737]], dtype=float32)

time = 39339	action = 0	current_phase = 0	next_phase = 1	reward = -0.400706	array([[-2.0297303, -2.8191211]], dtype=float32)

time = 39344	action = 0	current_phase = 0	next_phase = 1	reward = -0.239616	array([[-2.0378942, -2.65551  ]], dtype=float32)

time = 39349	action = 0	current_phase = 0	next_phase = 1	reward = -0.178881	array([[-2.0565963, -2.9161365]], dtype=float32)

time = 39354	action = 1	current_phase = 0	next_phase = 1	reward = -0.553767	array([[-4.038483 , -2.3802366]], dtype=float32)

time = 39362	action = 0	current_phase = 1	next_phase = 0	reward = -0.611382	array([[-2.3381362, -2.7790544]], dtype=float32)

time = 39367	action = 0	current_phase = 1	next_phase = 0	reward = -0.450087	array([[-2.1440377, -3.1783385]], dtype=float32)

time = 39372	action = 0	current_phase = 1	next_phase = 0	reward = -0.286692	array([[-2.1387532, -2.949264 ]], dtype=float32)

time = 39377	action = 0	current_phase = 1	next_phase = 0	reward = -0.164385	array([[-2.3175917, -3.1743064]], dtype=float32)

time = 39382	action = 0	current_phase = 1	next_phase = 0	reward = 0.174407	array([[-2.6898227, -3.7517936]], dtype=float32)

time = 39387	action = 1	current_phase = 1	next_phase = 0	reward = -1.784259	array([[-5.68867  , -3.5198581]], dtype=float32)

time = 39395	action = 0	current_phase = 0	next_phase = 1	reward = -0.522344	array([[-1.9783857, -3.2003274]], dtype=float32)

time = 39400	action = 0	current_phase = 0	next_phase = 1	reward = -0.360826	array([[-2.0268302, -2.825391 ]], dtype=float32)

time = 39405	action = 0	current_phase = 0	next_phase = 1	reward = -0.207546	array([[-2.0362463, -2.6532423]], dtype=float32)

time = 39410	action = 0	current_phase = 0	next_phase = 1	reward = 0.340686	array([[-2.2613478, -2.5080612]], dtype=float32)

time = 39415	action = 1	current_phase = 0	next_phase = 1	reward = -1.424357	array([[-4.5869355, -3.171654 ]], dtype=float32)

time = 39423	action = 0	current_phase = 1	next_phase = 0	reward = -0.592054	array([[-2.3032124, -2.83356  ]], dtype=float32)

time = 39428	action = 0	current_phase = 1	next_phase = 0	reward = -0.436583	array([[-2.136948, -2.955606]], dtype=float32)

time = 39433	action = 0	current_phase = 1	next_phase = 0	reward = -0.281438	array([[-2.1401618, -2.948335 ]], dtype=float32)

time = 39438	action = 0	current_phase = 1	next_phase = 0	reward = -0.163250	array([[-2.40677 , -3.089601]], dtype=float32)

time = 39443	action = 0	current_phase = 1	next_phase = 0	reward = 0.145820	array([[-2.726892 , -3.5794868]], dtype=float32)

time = 39448	action = 1	current_phase = 1	next_phase = 0	reward = -1.891397	array([[-5.635738 , -3.5412753]], dtype=float32)

time = 39456	action = 0	current_phase = 0	next_phase = 1	reward = -0.494940	array([[-1.9029113, -3.2000868]], dtype=float32)

time = 39461	action = 0	current_phase = 0	next_phase = 1	reward = -0.342446	array([[-2.0302305, -2.8194678]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1730 - val_loss: 0.0228

Epoch 2/50

 - 4s - loss: 0.1993 - val_loss: 0.0233

Epoch 3/50

 - 4s - loss: 0.1882 - val_loss: 0.0221

Epoch 4/50

 - 4s - loss: 0.1222 - val_loss: 0.0242

Epoch 5/50

 - 4s - loss: 0.1653 - val_loss: 0.0208

Epoch 6/50

 - 4s - loss: 0.1256 - val_loss: 0.0216

Epoch 7/50

 - 4s - loss: 0.1836 - val_loss: 0.0224

Epoch 8/50

 - 4s - loss: 0.1717 - val_loss: 0.0240

Epoch 9/50

 - 4s - loss: 0.1456 - val_loss: 0.0271

Epoch 10/50

 - 4s - loss: 0.1298 - val_loss: 0.0263

Epoch 11/50

 - 4s - loss: 0.1412 - val_loss: 0.0374

Epoch 12/50

 - 4s - loss: 0.1278 - val_loss: 0.0386

Epoch 13/50

 - 4s - loss: 0.1298 - val_loss: 0.0352

Epoch 14/50

 - 4s - loss: 0.0761 - val_loss: 0.0376

Epoch 15/50

 - 4s - loss: 0.1012 - val_loss: 0.0379

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1002, before forget

length of memory (state 1, action 1): 1000, after forget

time = 39466	action = 0	current_phase = 0	next_phase = 1	reward = -0.189221	array([[-2.042075 , -2.4957576]], dtype=float32)

time = 39471	action = 0	current_phase = 0	next_phase = 1	reward = 0.303092	array([[-2.2941701, -2.8063138]], dtype=float32)

time = 39476	action = 1	current_phase = 0	next_phase = 1	reward = -1.558195	array([[-4.6813827, -3.2695258]], dtype=float32)

time = 39484	action = 0	current_phase = 1	next_phase = 0	reward = -0.561316	array([[-2.1141665, -2.9346166]], dtype=float32)

time = 39489	action = 0	current_phase = 1	next_phase = 0	reward = -0.405866	array([[-1.89043  , -3.0988872]], dtype=float32)

time = 39494	action = 0	current_phase = 1	next_phase = 0	reward = -0.248913	array([[-1.8899864, -3.099459 ]], dtype=float32)

time = 39499	action = 0	current_phase = 1	next_phase = 0	reward = -0.173343	array([[-1.9693443, -3.7231407]], dtype=float32)

time = 39504	action = 1	current_phase = 1	next_phase = 0	reward = -0.477854	array([[-2.7034307, -2.148099 ]], dtype=float32)

time = 39512	action = 0	current_phase = 0	next_phase = 1	reward = -0.624037	array([[-2.1657302, -3.3854926]], dtype=float32)

time = 39517	action = 0	current_phase = 0	next_phase = 1	reward = -0.469475	array([[-2.0544627, -2.800522 ]], dtype=float32)

time = 39522	action = 0	current_phase = 0	next_phase = 1	reward = -0.309301	array([[-2.0511007, -2.312494 ]], dtype=float32)

time = 39527	action = 0	current_phase = 0	next_phase = 1	reward = -0.176279	array([[-2.3164353, -2.8588097]], dtype=float32)

time = 39532	action = 0	current_phase = 0	next_phase = 1	reward = 0.273366	array([[-2.472207 , -3.2821205]], dtype=float32)

time = 39537	action = 1	current_phase = 0	next_phase = 1	reward = -1.777693	array([[-6.306949 , -3.4390843]], dtype=float32)

time = 39545	action = 0	current_phase = 1	next_phase = 0	reward = -0.525335	array([[-2.054916 , -2.8446324]], dtype=float32)

time = 39550	action = 0	current_phase = 1	next_phase = 0	reward = -0.377574	array([[-1.8914719, -3.0986419]], dtype=float32)

time = 39555	action = 0	current_phase = 1	next_phase = 0	reward = -0.217782	array([[-1.8894166, -3.1002939]], dtype=float32)

time = 39560	action = 0	current_phase = 1	next_phase = 0	reward = 0.360787	array([[-2.011107 , -3.7197309]], dtype=float32)

time = 39565	action = 1	current_phase = 1	next_phase = 0	reward = -1.308813	array([[-3.4999106, -2.867471 ]], dtype=float32)

time = 39573	action = 0	current_phase = 0	next_phase = 1	reward = -0.584670	array([[-2.0922391, -3.1956222]], dtype=float32)

time = 39578	action = 0	current_phase = 0	next_phase = 1	reward = -0.419881	array([[-2.0327086, -2.7790608]], dtype=float32)

time = 39583	action = 0	current_phase = 0	next_phase = 1	reward = -0.258580	array([[-2.0123105, -2.483082 ]], dtype=float32)

time = 39588	action = 0	current_phase = 0	next_phase = 1	reward = -0.163484	array([[-2.3650074, -2.9358716]], dtype=float32)

time = 39593	action = 0	current_phase = 0	next_phase = 1	reward = -0.008508	array([[-2.716982, -3.552211]], dtype=float32)

time = 39598	action = 1	current_phase = 0	next_phase = 1	reward = -1.902833	array([[-6.4040737, -3.5947413]], dtype=float32)

time = 39606	action = 0	current_phase = 1	next_phase = 0	reward = -0.493286	array([[-2.175477 , -3.2154605]], dtype=float32)

time = 39611	action = 0	current_phase = 1	next_phase = 0	reward = -0.338671	array([[-1.9126952, -3.0762234]], dtype=float32)

time = 39616	action = 0	current_phase = 1	next_phase = 0	reward = -0.195999	array([[-2.154062 , -3.0963938]], dtype=float32)

time = 39621	action = 0	current_phase = 1	next_phase = 0	reward = 0.333967	array([[-2.271075 , -3.8428392]], dtype=float32)

time = 39626	action = 1	current_phase = 1	next_phase = 0	reward = -1.501434	array([[-3.6560192, -3.0356932]], dtype=float32)

time = 39634	action = 0	current_phase = 0	next_phase = 1	reward = -0.564117	array([[-2.0682898, -2.8837838]], dtype=float32)

time = 39639	action = 0	current_phase = 0	next_phase = 1	reward = -0.414140	array([[-2.0322444, -2.779269 ]], dtype=float32)

time = 39644	action = 0	current_phase = 0	next_phase = 1	reward = -0.260046	array([[-2.0119195, -2.4874187]], dtype=float32)

time = 39649	action = 0	current_phase = 0	next_phase = 1	reward = -0.171302	array([[-2.1116126, -2.927491 ]], dtype=float32)

time = 39654	action = 1	current_phase = 0	next_phase = 1	reward = -0.439188	array([[-4.1219354, -2.2743523]], dtype=float32)

time = 39662	action = 0	current_phase = 1	next_phase = 0	reward = -0.615588	array([[-2.3108108, -2.7810946]], dtype=float32)

time = 39667	action = 0	current_phase = 1	next_phase = 0	reward = -0.468814	array([[-2.1521897, -3.1865385]], dtype=float32)

time = 39672	action = 0	current_phase = 1	next_phase = 0	reward = -0.309974	array([[-2.10157  , -2.9676292]], dtype=float32)

time = 39677	action = 0	current_phase = 1	next_phase = 0	reward = -0.174805	array([[-2.320092, -3.149439]], dtype=float32)

time = 39682	action = 0	current_phase = 1	next_phase = 0	reward = 0.251115	array([[-2.7296593, -3.7055905]], dtype=float32)

time = 39687	action = 1	current_phase = 1	next_phase = 0	reward = -1.782878	array([[-5.6260777, -3.347308 ]], dtype=float32)

time = 39695	action = 0	current_phase = 0	next_phase = 1	reward = -0.523181	array([[-2.0631151, -3.166624 ]], dtype=float32)

time = 39700	action = 0	current_phase = 0	next_phase = 1	reward = -0.365754	array([[-2.0251045, -2.7951152]], dtype=float32)

time = 39705	action = 0	current_phase = 0	next_phase = 1	reward = -0.212595	array([[-2.0114176, -2.4862015]], dtype=float32)

time = 39710	action = 0	current_phase = 0	next_phase = 1	reward = 0.356755	array([[-2.1421719, -2.1905196]], dtype=float32)

time = 39715	action = 1	current_phase = 0	next_phase = 1	reward = -1.313891	array([[-4.5766215, -3.1926026]], dtype=float32)

time = 39723	action = 0	current_phase = 1	next_phase = 0	reward = -0.589263	array([[-2.2465415, -2.8767555]], dtype=float32)

time = 39728	action = 0	current_phase = 1	next_phase = 0	reward = -0.448077	array([[-2.1136684, -2.96041  ]], dtype=float32)

time = 39733	action = 0	current_phase = 1	next_phase = 0	reward = -0.291266	array([[-2.1218085, -2.9521837]], dtype=float32)

time = 39738	action = 0	current_phase = 1	next_phase = 0	reward = -0.165367	array([[-2.297159 , -3.1524193]], dtype=float32)

time = 39743	action = 0	current_phase = 1	next_phase = 0	reward = 0.151351	array([[-2.7747462, -3.6049051]], dtype=float32)

time = 39748	action = 1	current_phase = 1	next_phase = 0	reward = -1.895452	array([[-5.6634865, -3.4422271]], dtype=float32)

time = 39756	action = 0	current_phase = 0	next_phase = 1	reward = -0.493066	array([[-2.0371814, -3.172719 ]], dtype=float32)

time = 39761	action = 0	current_phase = 0	next_phase = 1	reward = -0.332266	array([[-2.0335772, -2.778554 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0786 - val_loss: 0.1529

Epoch 2/50

 - 4s - loss: 0.0718 - val_loss: 0.1359

Epoch 3/50

 - 4s - loss: 0.0512 - val_loss: 0.1312

Epoch 4/50

 - 4s - loss: 0.0754 - val_loss: 0.1277

Epoch 5/50

 - 4s - loss: 0.0745 - val_loss: 0.1578

Epoch 6/50

 - 4s - loss: 0.0663 - val_loss: 0.2210

Epoch 7/50

 - 4s - loss: 0.0488 - val_loss: 0.1852

Epoch 8/50

 - 4s - loss: 0.0497 - val_loss: 0.2068

Epoch 9/50

 - 4s - loss: 0.0610 - val_loss: 0.1738

Epoch 10/50

 - 4s - loss: 0.0420 - val_loss: 0.2011

Epoch 11/50

 - 4s - loss: 0.0672 - val_loss: 0.2120

Epoch 12/50

 - 4s - loss: 0.0560 - val_loss: 0.1391

Epoch 13/50

 - 4s - loss: 0.0304 - val_loss: 0.1891

Epoch 14/50

 - 4s - loss: 0.0559 - val_loss: 0.1794

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 39766	action = 0	current_phase = 0	next_phase = 1	reward = -0.190234	array([[-2.0229218, -2.473379 ]], dtype=float32)

time = 39771	action = 0	current_phase = 0	next_phase = 1	reward = 0.306849	array([[-2.2755094, -2.6756194]], dtype=float32)

time = 39776	action = 1	current_phase = 0	next_phase = 1	reward = -1.556609	array([[-4.726199 , -3.2884767]], dtype=float32)

time = 39784	action = 0	current_phase = 1	next_phase = 0	reward = -0.550749	array([[-2.1370888, -2.9427943]], dtype=float32)

time = 39789	action = 0	current_phase = 1	next_phase = 0	reward = -0.402725	array([[-1.9088467, -3.0894625]], dtype=float32)

time = 39794	action = 0	current_phase = 1	next_phase = 0	reward = -0.251392	array([[-1.9079077, -3.0906715]], dtype=float32)

time = 39799	action = 0	current_phase = 1	next_phase = 0	reward = -0.186925	array([[-1.9270849, -3.6813571]], dtype=float32)

time = 39804	action = 1	current_phase = 1	next_phase = 0	reward = -0.608221	array([[-2.6805515, -2.2380843]], dtype=float32)

time = 39812	action = 0	current_phase = 0	next_phase = 1	reward = -0.615880	array([[-2.2575274, -3.3693154]], dtype=float32)

time = 39817	action = 0	current_phase = 0	next_phase = 1	reward = -0.463693	array([[-2.0709028, -2.7531314]], dtype=float32)

time = 39822	action = 0	current_phase = 0	next_phase = 1	reward = -0.300137	array([[-2.0302825, -2.393493 ]], dtype=float32)

time = 39827	action = 0	current_phase = 0	next_phase = 1	reward = -0.165876	array([[-2.2939684, -2.9404843]], dtype=float32)

time = 39832	action = 0	current_phase = 0	next_phase = 1	reward = 0.166061	array([[-2.463749 , -3.7116868]], dtype=float32)

time = 39837	action = 1	current_phase = 0	next_phase = 1	reward = -1.778500	array([[-6.390276 , -3.5565016]], dtype=float32)

time = 39845	action = 0	current_phase = 1	next_phase = 0	reward = -0.512304	array([[-2.0891347, -2.8703601]], dtype=float32)

time = 39850	action = 0	current_phase = 1	next_phase = 0	reward = -0.366308	array([[-1.9077777, -3.0905933]], dtype=float32)

time = 39855	action = 0	current_phase = 1	next_phase = 0	reward = -0.219872	array([[-1.9093645, -3.0896685]], dtype=float32)

time = 39860	action = 0	current_phase = 1	next_phase = 0	reward = 0.046458	array([[-2.3140182, -3.787988 ]], dtype=float32)

time = 39865	action = 1	current_phase = 1	next_phase = 0	reward = -1.089038	array([[-3.1717644, -2.6090171]], dtype=float32)

time = 39873	action = 0	current_phase = 0	next_phase = 1	reward = -0.586019	array([[-2.162491 , -3.2613442]], dtype=float32)

time = 39878	action = 0	current_phase = 0	next_phase = 1	reward = -0.425289	array([[-2.0270958, -2.8499901]], dtype=float32)

time = 39883	action = 0	current_phase = 0	next_phase = 1	reward = -0.266626	array([[-2.0295475, -2.3482082]], dtype=float32)

time = 39888	action = 0	current_phase = 0	next_phase = 1	reward = -0.162561	array([[-2.1411154, -3.097425 ]], dtype=float32)

time = 39893	action = 0	current_phase = 0	next_phase = 1	reward = 0.142288	array([[-2.6144764, -3.765383 ]], dtype=float32)

time = 39898	action = 1	current_phase = 0	next_phase = 1	reward = -1.902611	array([[-6.409675 , -3.5728688]], dtype=float32)

time = 39906	action = 0	current_phase = 1	next_phase = 0	reward = -0.514999	array([[-2.1534634, -3.2707932]], dtype=float32)

time = 39911	action = 0	current_phase = 1	next_phase = 0	reward = -0.360030	array([[-1.9757082, -3.0492942]], dtype=float32)

time = 39916	action = 0	current_phase = 1	next_phase = 0	reward = -0.204827	array([[-1.9378124, -3.1005552]], dtype=float32)

time = 39921	action = 0	current_phase = 1	next_phase = 0	reward = 0.320666	array([[-2.2452188, -3.8213518]], dtype=float32)

time = 39926	action = 1	current_phase = 1	next_phase = 0	reward = -1.605869	array([[-5.5212636, -3.2120433]], dtype=float32)

time = 39934	action = 0	current_phase = 0	next_phase = 1	reward = -0.559718	array([[-2.07455  , -2.9473388]], dtype=float32)

time = 39939	action = 0	current_phase = 0	next_phase = 1	reward = -0.418868	array([[-2.0587244, -2.7668967]], dtype=float32)

time = 39944	action = 0	current_phase = 0	next_phase = 1	reward = -0.258440	array([[-2.0023685, -2.447033 ]], dtype=float32)

time = 39949	action = 0	current_phase = 0	next_phase = 1	reward = -0.179040	array([[-2.1150446, -3.0859547]], dtype=float32)

time = 39954	action = 1	current_phase = 0	next_phase = 1	reward = -0.569250	array([[-4.05332  , -2.3411279]], dtype=float32)

time = 39962	action = 0	current_phase = 1	next_phase = 0	reward = -0.618369	array([[-2.3610435, -2.8184993]], dtype=float32)

time = 39967	action = 0	current_phase = 1	next_phase = 0	reward = -0.458499	array([[-2.1268501, -3.2100863]], dtype=float32)

time = 39972	action = 0	current_phase = 1	next_phase = 0	reward = -0.291046	array([[-2.1234965, -2.9584293]], dtype=float32)

time = 39977	action = 0	current_phase = 1	next_phase = 0	reward = -0.162895	array([[-2.3733563, -3.1202438]], dtype=float32)

time = 39982	action = 0	current_phase = 1	next_phase = 0	reward = 0.120435	array([[-2.7528777, -3.6583135]], dtype=float32)

time = 39987	action = 1	current_phase = 1	next_phase = 0	reward = -1.784603	array([[-5.742648 , -3.4325728]], dtype=float32)

time = 39995	action = 0	current_phase = 0	next_phase = 1	reward = -0.536809	array([[-2.1075718, -3.1864023]], dtype=float32)

time = 40000	action = 0	current_phase = 0	next_phase = 1	reward = -0.386561	array([[-2.022361, -2.858516]], dtype=float32)

time = 40005	action = 0	current_phase = 0	next_phase = 1	reward = -0.237028	array([[-2.0023577, -2.4470408]], dtype=float32)

time = 40010	action = 0	current_phase = 0	next_phase = 1	reward = -0.220716	array([[-2.114224 , -2.2928889]], dtype=float32)

time = 40015	action = 1	current_phase = 0	next_phase = 1	reward = -0.849435	array([[-4.0842667, -2.4087114]], dtype=float32)

time = 40023	action = 0	current_phase = 1	next_phase = 0	reward = -0.589961	array([[-2.3156228, -2.856276 ]], dtype=float32)

time = 40028	action = 0	current_phase = 1	next_phase = 0	reward = -0.442455	array([[-2.135579 , -2.9513419]], dtype=float32)

time = 40033	action = 0	current_phase = 1	next_phase = 0	reward = -0.289018	array([[-2.139565 , -2.9725714]], dtype=float32)

time = 40038	action = 0	current_phase = 1	next_phase = 0	reward = -0.166110	array([[-2.2788982, -3.1562874]], dtype=float32)

time = 40043	action = 0	current_phase = 1	next_phase = 0	reward = 0.079314	array([[-2.698227 , -3.6721492]], dtype=float32)

time = 40048	action = 1	current_phase = 1	next_phase = 0	reward = -1.899525	array([[-5.763215 , -3.4142246]], dtype=float32)

time = 40056	action = 0	current_phase = 0	next_phase = 1	reward = -0.491605	array([[-2.0928748, -3.198179 ]], dtype=float32)

time = 40061	action = 0	current_phase = 0	next_phase = 1	reward = -0.335767	array([[-2.0200531, -2.8649452]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0739 - val_loss: 0.0137

Epoch 2/50

 - 4s - loss: 0.0522 - val_loss: 0.0177

Epoch 3/50

 - 4s - loss: 0.0514 - val_loss: 0.0144

Epoch 4/50

 - 4s - loss: 0.0616 - val_loss: 0.0194

Epoch 5/50

 - 4s - loss: 0.0465 - val_loss: 0.0175

Epoch 6/50

 - 4s - loss: 0.0800 - val_loss: 0.0182

Epoch 7/50

 - 4s - loss: 0.0503 - val_loss: 0.0180

Epoch 8/50

 - 4s - loss: 0.0516 - val_loss: 0.0199

Epoch 9/50

 - 4s - loss: 0.0797 - val_loss: 0.0170

Epoch 10/50

 - 4s - loss: 0.0482 - val_loss: 0.0152

Epoch 11/50

 - 4s - loss: 0.1288 - val_loss: 0.0161

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 40066	action = 0	current_phase = 0	next_phase = 1	reward = -0.189031	array([[-2.0319524, -2.4503894]], dtype=float32)

time = 40071	action = 0	current_phase = 0	next_phase = 1	reward = 0.310033	array([[-2.184066 , -2.4598043]], dtype=float32)

time = 40076	action = 1	current_phase = 0	next_phase = 1	reward = -1.552587	array([[-4.489723 , -3.1946058]], dtype=float32)

time = 40084	action = 0	current_phase = 1	next_phase = 0	reward = -0.549637	array([[-2.1480522, -2.960131 ]], dtype=float32)

time = 40089	action = 0	current_phase = 1	next_phase = 0	reward = -0.385492	array([[-1.9573399, -3.0874038]], dtype=float32)

time = 40094	action = 0	current_phase = 1	next_phase = 0	reward = -0.239018	array([[-1.927784 , -3.1088333]], dtype=float32)

time = 40099	action = 0	current_phase = 1	next_phase = 0	reward = -0.177545	array([[-1.9841543, -3.6310828]], dtype=float32)

time = 40104	action = 1	current_phase = 1	next_phase = 0	reward = -0.432116	array([[-2.6337113, -2.0263708]], dtype=float32)

time = 40112	action = 0	current_phase = 0	next_phase = 1	reward = -0.620026	array([[-2.1967115, -3.4952993]], dtype=float32)

time = 40117	action = 0	current_phase = 0	next_phase = 1	reward = -0.469522	array([[-2.0591097, -2.8266428]], dtype=float32)

time = 40122	action = 0	current_phase = 0	next_phase = 1	reward = -0.301951	array([[-2.0175912, -2.4432566]], dtype=float32)

time = 40127	action = 0	current_phase = 0	next_phase = 1	reward = -0.165496	array([[-2.3389797, -2.9732177]], dtype=float32)

time = 40132	action = 0	current_phase = 0	next_phase = 1	reward = 0.184218	array([[-2.666839 , -3.8712919]], dtype=float32)

time = 40137	action = 1	current_phase = 0	next_phase = 1	reward = -1.779664	array([[-6.4033113, -3.4997077]], dtype=float32)

time = 40145	action = 0	current_phase = 1	next_phase = 0	reward = -0.516933	array([[-2.0532146, -2.8708127]], dtype=float32)

time = 40150	action = 0	current_phase = 1	next_phase = 0	reward = -0.365197	array([[-1.9219421, -3.1133568]], dtype=float32)

time = 40155	action = 0	current_phase = 1	next_phase = 0	reward = -0.216313	array([[-1.9207908, -3.1132138]], dtype=float32)

time = 40160	action = 0	current_phase = 1	next_phase = 0	reward = 0.343802	array([[-2.0737934, -3.7717047]], dtype=float32)

time = 40165	action = 1	current_phase = 1	next_phase = 0	reward = -1.316199	array([[-3.5014994, -2.8102357]], dtype=float32)

time = 40173	action = 0	current_phase = 0	next_phase = 1	reward = -0.586760	array([[-2.1563392, -3.363158 ]], dtype=float32)

time = 40178	action = 0	current_phase = 0	next_phase = 1	reward = -0.430355	array([[-2.0421174, -2.786733 ]], dtype=float32)

time = 40183	action = 0	current_phase = 0	next_phase = 1	reward = -0.279718	array([[-2.017262 , -2.4381607]], dtype=float32)

time = 40188	action = 0	current_phase = 0	next_phase = 1	reward = -0.165827	array([[-2.3632119, -3.017172 ]], dtype=float32)

time = 40193	action = 0	current_phase = 0	next_phase = 1	reward = 0.061067	array([[-2.6979616, -3.9000578]], dtype=float32)

time = 40198	action = 1	current_phase = 0	next_phase = 1	reward = -1.893320	array([[-6.3465405, -3.590817 ]], dtype=float32)

time = 40206	action = 0	current_phase = 1	next_phase = 0	reward = -0.489178	array([[-2.1191847, -3.2244287]], dtype=float32)

time = 40211	action = 0	current_phase = 1	next_phase = 0	reward = -0.329915	array([[-2.00192  , -3.0612924]], dtype=float32)

time = 40216	action = 0	current_phase = 1	next_phase = 0	reward = -0.182633	array([[-1.9972284, -3.1064248]], dtype=float32)

time = 40221	action = 0	current_phase = 1	next_phase = 0	reward = 0.298407	array([[-2.2814522, -3.8254445]], dtype=float32)

time = 40226	action = 1	current_phase = 1	next_phase = 0	reward = -1.612614	array([[-5.5635176, -3.2104053]], dtype=float32)

time = 40234	action = 0	current_phase = 0	next_phase = 1	reward = -0.553536	array([[-2.062107 , -3.0815945]], dtype=float32)

time = 40239	action = 0	current_phase = 0	next_phase = 1	reward = -0.396405	array([[-2.0369744, -2.8017921]], dtype=float32)

time = 40244	action = 0	current_phase = 0	next_phase = 1	reward = -0.244306	array([[-2.01651 , -2.441182]], dtype=float32)

time = 40249	action = 0	current_phase = 0	next_phase = 1	reward = -0.180354	array([[-2.1248498, -3.1069047]], dtype=float32)

time = 40254	action = 1	current_phase = 0	next_phase = 1	reward = -0.482334	array([[-3.99506 , -2.278492]], dtype=float32)

time = 40262	action = 0	current_phase = 1	next_phase = 0	reward = -0.626554	array([[-2.3362916, -2.8342915]], dtype=float32)

time = 40267	action = 0	current_phase = 1	next_phase = 0	reward = -0.472107	array([[-2.0746925, -3.2539365]], dtype=float32)

time = 40272	action = 0	current_phase = 1	next_phase = 0	reward = -0.312503	array([[-2.1278274, -2.9770784]], dtype=float32)

time = 40277	action = 0	current_phase = 1	next_phase = 0	reward = -0.175202	array([[-2.3645573, -3.0999312]], dtype=float32)

time = 40282	action = 0	current_phase = 1	next_phase = 0	reward = 0.254630	array([[-2.7038026, -3.6818025]], dtype=float32)

time = 40287	action = 1	current_phase = 1	next_phase = 0	reward = -1.728069	array([[-5.74228 , -3.357607]], dtype=float32)

time = 40295	action = 0	current_phase = 0	next_phase = 1	reward = -0.516622	array([[-2.1384342, -3.2181065]], dtype=float32)

time = 40300	action = 0	current_phase = 0	next_phase = 1	reward = -0.357776	array([[-2.0111947, -2.8888226]], dtype=float32)

time = 40305	action = 0	current_phase = 0	next_phase = 1	reward = -0.201830	array([[-2.0169232, -2.4397595]], dtype=float32)

time = 40310	action = 0	current_phase = 0	next_phase = 1	reward = 0.323160	array([[-2.150728, -2.344236]], dtype=float32)

time = 40315	action = 1	current_phase = 0	next_phase = 1	reward = -1.430667	array([[-4.5140066, -3.220056 ]], dtype=float32)

time = 40323	action = 0	current_phase = 1	next_phase = 0	reward = -0.595582	array([[-2.305394 , -2.8777418]], dtype=float32)

time = 40328	action = 0	current_phase = 1	next_phase = 0	reward = -0.435915	array([[-2.1320364, -2.975425 ]], dtype=float32)

time = 40333	action = 0	current_phase = 1	next_phase = 0	reward = -0.275541	array([[-2.1312778, -2.969978 ]], dtype=float32)

time = 40338	action = 0	current_phase = 1	next_phase = 0	reward = -0.168253	array([[-2.318883, -3.145002]], dtype=float32)

time = 40343	action = 0	current_phase = 1	next_phase = 0	reward = 0.146750	array([[-2.7674975, -3.4462888]], dtype=float32)

time = 40348	action = 1	current_phase = 1	next_phase = 0	reward = -1.894367	array([[-5.7588077, -3.4192455]], dtype=float32)

time = 40356	action = 0	current_phase = 0	next_phase = 1	reward = -0.498105	array([[-2.1372705, -3.2268384]], dtype=float32)

time = 40361	action = 0	current_phase = 0	next_phase = 1	reward = -0.338054	array([[-2.042749, -2.784636]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0818 - val_loss: 0.0229

Epoch 2/50

 - 4s - loss: 0.1406 - val_loss: 0.0226

Epoch 3/50

 - 4s - loss: 0.0829 - val_loss: 0.0216

Epoch 4/50

 - 4s - loss: 0.0833 - val_loss: 0.0222

Epoch 5/50

 - 4s - loss: 0.0543 - val_loss: 0.0230

Epoch 6/50

 - 4s - loss: 0.0681 - val_loss: 0.0214

Epoch 7/50

 - 4s - loss: 0.0644 - val_loss: 0.0221

Epoch 8/50

 - 4s - loss: 0.0525 - val_loss: 0.0216

Epoch 9/50

 - 4s - loss: 0.0632 - val_loss: 0.0351

Epoch 10/50

 - 4s - loss: 0.0725 - val_loss: 0.0430

Epoch 11/50

 - 4s - loss: 0.0952 - val_loss: 0.0388

Epoch 12/50

 - 4s - loss: 0.0557 - val_loss: 0.0251

Epoch 13/50

 - 4s - loss: 0.1185 - val_loss: 0.0269

Epoch 14/50

 - 4s - loss: 0.0333 - val_loss: 0.0274

Epoch 15/50

 - 4s - loss: 0.0550 - val_loss: 0.0227

Epoch 16/50

 - 4s - loss: 0.0503 - val_loss: 0.0235

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 40366	action = 0	current_phase = 0	next_phase = 1	reward = -0.193706	array([[-2.0497134, -2.380759 ]], dtype=float32)

time = 40371	action = 0	current_phase = 0	next_phase = 1	reward = 0.302096	array([[-2.3187182, -2.8682847]], dtype=float32)

time = 40376	action = 1	current_phase = 0	next_phase = 1	reward = -1.613278	array([[-4.585797 , -3.2879806]], dtype=float32)

time = 40384	action = 0	current_phase = 1	next_phase = 0	reward = -0.562848	array([[-2.0567858, -2.963871 ]], dtype=float32)

time = 40389	action = 0	current_phase = 1	next_phase = 0	reward = -0.407760	array([[-1.8442856, -3.1193628]], dtype=float32)

time = 40394	action = 0	current_phase = 1	next_phase = 0	reward = -0.249916	array([[-1.8459301, -3.1204212]], dtype=float32)

time = 40399	action = 0	current_phase = 1	next_phase = 0	reward = -0.168122	array([[-1.903213 , -3.7659883]], dtype=float32)

time = 40404	action = 1	current_phase = 1	next_phase = 0	reward = -0.414140	array([[-2.5842617, -2.1315222]], dtype=float32)

time = 40412	action = 0	current_phase = 0	next_phase = 1	reward = -0.616052	array([[-2.2269578, -3.5068412]], dtype=float32)

time = 40417	action = 0	current_phase = 0	next_phase = 1	reward = -0.447034	array([[-2.0850546, -2.842037 ]], dtype=float32)

time = 40422	action = 0	current_phase = 0	next_phase = 1	reward = -0.290497	array([[-2.076735, -2.157603]], dtype=float32)

time = 40427	action = 0	current_phase = 0	next_phase = 1	reward = -0.161911	array([[-2.3263836, -2.8956606]], dtype=float32)

time = 40432	action = 0	current_phase = 0	next_phase = 1	reward = 0.152031	array([[-2.6095543, -3.3810718]], dtype=float32)

time = 40437	action = 1	current_phase = 0	next_phase = 1	reward = -1.782572	array([[-6.439537, -3.591197]], dtype=float32)

time = 40445	action = 0	current_phase = 1	next_phase = 0	reward = -0.523233	array([[-1.9791783, -2.8604965]], dtype=float32)

time = 40450	action = 0	current_phase = 1	next_phase = 0	reward = -0.363545	array([[-1.845865 , -3.1201434]], dtype=float32)

time = 40455	action = 0	current_phase = 1	next_phase = 0	reward = -0.207665	array([[-1.8445365, -3.1213343]], dtype=float32)

time = 40460	action = 0	current_phase = 1	next_phase = 0	reward = 0.364149	array([[-2.1072562, -3.8038864]], dtype=float32)

time = 40465	action = 1	current_phase = 1	next_phase = 0	reward = -1.308090	array([[-3.5678456, -2.9402516]], dtype=float32)

time = 40473	action = 0	current_phase = 0	next_phase = 1	reward = -0.586101	array([[-2.1341748, -3.230195 ]], dtype=float32)

time = 40478	action = 0	current_phase = 0	next_phase = 1	reward = -0.432762	array([[-2.0253897, -2.91117  ]], dtype=float32)

time = 40483	action = 0	current_phase = 0	next_phase = 1	reward = -0.276054	array([[-2.0641556, -2.2119842]], dtype=float32)

time = 40488	action = 0	current_phase = 0	next_phase = 1	reward = -0.166342	array([[-2.390914 , -2.9746532]], dtype=float32)

time = 40493	action = 0	current_phase = 0	next_phase = 1	reward = -0.059089	array([[-3.1888313, -3.9456859]], dtype=float32)

time = 40498	action = 1	current_phase = 0	next_phase = 1	reward = -1.897522	array([[-6.3852882, -3.631436 ]], dtype=float32)

time = 40506	action = 0	current_phase = 1	next_phase = 0	reward = -0.485573	array([[-2.0960093, -3.03166  ]], dtype=float32)

time = 40511	action = 0	current_phase = 1	next_phase = 0	reward = -0.337929	array([[-2.0405486, -2.9991686]], dtype=float32)

time = 40516	action = 0	current_phase = 1	next_phase = 0	reward = -0.190170	array([[-1.9295331, -3.0789406]], dtype=float32)

time = 40521	action = 0	current_phase = 1	next_phase = 0	reward = 0.289169	array([[-2.3147151, -3.7975001]], dtype=float32)

time = 40526	action = 1	current_phase = 1	next_phase = 0	reward = -1.607915	array([[-5.5756407, -3.19195  ]], dtype=float32)

time = 40534	action = 0	current_phase = 0	next_phase = 1	reward = -0.548946	array([[-2.0744414, -2.9208775]], dtype=float32)

time = 40539	action = 0	current_phase = 0	next_phase = 1	reward = -0.395167	array([[-2.0357473, -2.8744023]], dtype=float32)

time = 40544	action = 0	current_phase = 0	next_phase = 1	reward = -0.241136	array([[-2.031637 , -2.3545296]], dtype=float32)

time = 40549	action = 0	current_phase = 0	next_phase = 1	reward = -0.179623	array([[-2.2232378, -3.1184492]], dtype=float32)

time = 40554	action = 1	current_phase = 0	next_phase = 1	reward = -0.483897	array([[-4.081331 , -2.5736637]], dtype=float32)

time = 40562	action = 0	current_phase = 1	next_phase = 0	reward = -0.611472	array([[-2.238085, -2.848505]], dtype=float32)

time = 40567	action = 0	current_phase = 1	next_phase = 0	reward = -0.459974	array([[-2.0508714, -3.2288845]], dtype=float32)

time = 40572	action = 0	current_phase = 1	next_phase = 0	reward = -0.302925	array([[-2.0684698, -2.9754107]], dtype=float32)

time = 40577	action = 0	current_phase = 1	next_phase = 0	reward = -0.168811	array([[-2.2695315, -3.1285412]], dtype=float32)

time = 40582	action = 0	current_phase = 1	next_phase = 0	reward = 0.181900	array([[-2.6712444, -3.710648 ]], dtype=float32)

time = 40587	action = 1	current_phase = 1	next_phase = 0	reward = -1.785701	array([[-5.7789583, -3.4009042]], dtype=float32)

time = 40595	action = 0	current_phase = 0	next_phase = 1	reward = -0.529651	array([[-2.1526735, -3.2285948]], dtype=float32)

time = 40600	action = 0	current_phase = 0	next_phase = 1	reward = -0.374691	array([[-2.055479, -2.815332]], dtype=float32)

time = 40605	action = 0	current_phase = 0	next_phase = 1	reward = -0.225219	array([[-2.0314705, -2.3542233]], dtype=float32)

time = 40610	action = 0	current_phase = 0	next_phase = 1	reward = 0.070471	array([[-2.2129772, -2.4913626]], dtype=float32)

time = 40615	action = 1	current_phase = 0	next_phase = 1	reward = -0.978336	array([[-4.311827 , -3.0023003]], dtype=float32)

time = 40623	action = 0	current_phase = 1	next_phase = 0	reward = -0.597026	array([[-2.23688  , -2.8579428]], dtype=float32)

time = 40628	action = 0	current_phase = 1	next_phase = 0	reward = -0.451459	array([[-1.9938731, -3.0312135]], dtype=float32)

time = 40633	action = 0	current_phase = 1	next_phase = 0	reward = -0.303110	array([[-2.0620377, -2.9841828]], dtype=float32)

time = 40638	action = 0	current_phase = 1	next_phase = 0	reward = -0.174305	array([[-2.2603116, -3.1365387]], dtype=float32)

time = 40643	action = 0	current_phase = 1	next_phase = 0	reward = 0.089947	array([[-2.651247, -3.683512]], dtype=float32)

time = 40648	action = 1	current_phase = 1	next_phase = 0	reward = -1.901742	array([[-5.770212 , -3.4066331]], dtype=float32)

time = 40656	action = 0	current_phase = 0	next_phase = 1	reward = -0.501245	array([[-2.083981 , -3.2280807]], dtype=float32)

time = 40661	action = 0	current_phase = 0	next_phase = 1	reward = -0.358705	array([[-2.0443974, -2.8470972]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1288 - val_loss: 0.0177

Epoch 2/50

 - 4s - loss: 0.1120 - val_loss: 0.0184

Epoch 3/50

 - 4s - loss: 0.1025 - val_loss: 0.0177

Epoch 4/50

 - 4s - loss: 0.0775 - val_loss: 0.0175

Epoch 5/50

 - 4s - loss: 0.0891 - val_loss: 0.0202

Epoch 6/50

 - 4s - loss: 0.0819 - val_loss: 0.0199

Epoch 7/50

 - 4s - loss: 0.0630 - val_loss: 0.0194

Epoch 8/50

 - 4s - loss: 0.0662 - val_loss: 0.0206

Epoch 9/50

 - 4s - loss: 0.0534 - val_loss: 0.0182

Epoch 10/50

 - 4s - loss: 0.0502 - val_loss: 0.0192

Epoch 11/50

 - 4s - loss: 0.0678 - val_loss: 0.0224

Epoch 12/50

 - 4s - loss: 0.0669 - val_loss: 0.0200

Epoch 13/50

 - 4s - loss: 0.0681 - val_loss: 0.0182

Epoch 14/50

 - 4s - loss: 0.0882 - val_loss: 0.0194

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 40666	action = 0	current_phase = 0	next_phase = 1	reward = -0.218804	array([[-2.070383 , -2.3576548]], dtype=float32)

time = 40671	action = 0	current_phase = 0	next_phase = 1	reward = 0.296176	array([[-2.3392515, -2.779306 ]], dtype=float32)

time = 40676	action = 1	current_phase = 0	next_phase = 1	reward = -1.606177	array([[-4.6147294, -3.2415137]], dtype=float32)

time = 40684	action = 0	current_phase = 1	next_phase = 0	reward = -0.550404	array([[-2.1424599, -3.0118575]], dtype=float32)

time = 40689	action = 0	current_phase = 1	next_phase = 0	reward = -0.389664	array([[-1.9397987, -3.1498861]], dtype=float32)

time = 40694	action = 0	current_phase = 1	next_phase = 0	reward = -0.227035	array([[-1.9366941, -3.146644 ]], dtype=float32)

time = 40699	action = 0	current_phase = 1	next_phase = 0	reward = -0.180817	array([[-1.9152712, -3.7910633]], dtype=float32)

time = 40704	action = 1	current_phase = 1	next_phase = 0	reward = -0.585911	array([[-2.653776 , -2.3268042]], dtype=float32)

time = 40712	action = 0	current_phase = 0	next_phase = 1	reward = -0.625902	array([[-2.2398806, -3.5078535]], dtype=float32)

time = 40717	action = 0	current_phase = 0	next_phase = 1	reward = -0.481491	array([[-2.0900788, -2.774135 ]], dtype=float32)

time = 40722	action = 0	current_phase = 0	next_phase = 1	reward = -0.323977	array([[-2.0790422, -2.1168349]], dtype=float32)

time = 40727	action = 0	current_phase = 0	next_phase = 1	reward = -0.179281	array([[-2.399371 , -2.9523876]], dtype=float32)

time = 40732	action = 0	current_phase = 0	next_phase = 1	reward = 0.243837	array([[-2.559448 , -3.1416562]], dtype=float32)

time = 40737	action = 1	current_phase = 0	next_phase = 1	reward = -1.732197	array([[-6.297506, -3.388392]], dtype=float32)

time = 40745	action = 0	current_phase = 1	next_phase = 0	reward = -0.523693	array([[-2.017647 , -2.8948798]], dtype=float32)

time = 40750	action = 0	current_phase = 1	next_phase = 0	reward = -0.368635	array([[-1.9372532, -3.150343 ]], dtype=float32)

time = 40755	action = 0	current_phase = 1	next_phase = 0	reward = -0.211940	array([[-1.9372131, -3.153245 ]], dtype=float32)

time = 40760	action = 0	current_phase = 1	next_phase = 0	reward = 0.354985	array([[-1.9766572, -3.8246593]], dtype=float32)

time = 40765	action = 1	current_phase = 1	next_phase = 0	reward = -1.367814	array([[-3.6155074, -3.010119 ]], dtype=float32)

time = 40773	action = 0	current_phase = 0	next_phase = 1	reward = -0.583925	array([[-2.203387, -3.388928]], dtype=float32)

time = 40778	action = 0	current_phase = 0	next_phase = 1	reward = -0.424651	array([[-2.084314 , -2.7653306]], dtype=float32)

time = 40783	action = 0	current_phase = 0	next_phase = 1	reward = -0.273698	array([[-2.0385938, -2.265977 ]], dtype=float32)

time = 40788	action = 0	current_phase = 0	next_phase = 1	reward = -0.171664	array([[-2.3670287, -2.991692 ]], dtype=float32)

time = 40793	action = 0	current_phase = 0	next_phase = 1	reward = -0.016319	array([[-2.9388275, -3.1453505]], dtype=float32)

time = 40798	action = 1	current_phase = 0	next_phase = 1	reward = -1.897530	array([[-6.336321 , -3.5748158]], dtype=float32)

time = 40806	action = 0	current_phase = 1	next_phase = 0	reward = -0.496796	array([[-2.1507196, -3.22893  ]], dtype=float32)

time = 40811	action = 0	current_phase = 1	next_phase = 0	reward = -0.343034	array([[-2.035947 , -3.0829062]], dtype=float32)

time = 40816	action = 0	current_phase = 1	next_phase = 0	reward = -0.187929	array([[-1.9757036, -3.1363664]], dtype=float32)

time = 40821	action = 0	current_phase = 1	next_phase = 0	reward = 0.313299	array([[-2.2853906, -3.8437958]], dtype=float32)

time = 40826	action = 1	current_phase = 1	next_phase = 0	reward = -1.559638	array([[-5.556415 , -3.2102966]], dtype=float32)

time = 40834	action = 0	current_phase = 0	next_phase = 1	reward = -0.561866	array([[-2.133357, -3.171375]], dtype=float32)

time = 40839	action = 0	current_phase = 0	next_phase = 1	reward = -0.405869	array([[-2.0717514, -2.7983284]], dtype=float32)

time = 40844	action = 0	current_phase = 0	next_phase = 1	reward = -0.257301	array([[-2.0620136, -2.1797547]], dtype=float32)

time = 40849	action = 0	current_phase = 0	next_phase = 1	reward = -0.186595	array([[-2.2503936, -3.1565475]], dtype=float32)

time = 40854	action = 1	current_phase = 0	next_phase = 1	reward = -0.529930	array([[-4.077295 , -2.5678065]], dtype=float32)

time = 40862	action = 0	current_phase = 1	next_phase = 0	reward = -0.626905	array([[-2.2633927, -2.9013567]], dtype=float32)

time = 40867	action = 0	current_phase = 1	next_phase = 0	reward = -0.473756	array([[-2.1563308, -3.2068858]], dtype=float32)

time = 40872	action = 0	current_phase = 1	next_phase = 0	reward = -0.319458	array([[-2.0822654, -3.04917  ]], dtype=float32)

time = 40877	action = 0	current_phase = 1	next_phase = 0	reward = -0.178253	array([[-2.3040333, -3.1976733]], dtype=float32)

time = 40882	action = 0	current_phase = 1	next_phase = 0	reward = 0.265677	array([[-2.3662407, -3.813684 ]], dtype=float32)

time = 40887	action = 1	current_phase = 1	next_phase = 0	reward = -1.674253	array([[-5.6628523, -3.3647609]], dtype=float32)

time = 40895	action = 0	current_phase = 0	next_phase = 1	reward = -0.513346	array([[-2.097785 , -3.2486422]], dtype=float32)

time = 40900	action = 0	current_phase = 0	next_phase = 1	reward = -0.361800	array([[-2.0509913, -2.8610766]], dtype=float32)

time = 40905	action = 0	current_phase = 0	next_phase = 1	reward = -0.209043	array([[-2.0358388, -2.2822127]], dtype=float32)

time = 40910	action = 0	current_phase = 0	next_phase = 1	reward = 0.324970	array([[-2.1719012, -2.3205197]], dtype=float32)

time = 40915	action = 1	current_phase = 0	next_phase = 1	reward = -1.323758	array([[-4.54282  , -3.2195315]], dtype=float32)

time = 40923	action = 0	current_phase = 1	next_phase = 0	reward = -0.580757	array([[-2.2781246, -2.8800411]], dtype=float32)

time = 40928	action = 0	current_phase = 1	next_phase = 0	reward = -0.427502	array([[-2.1235328, -3.0193868]], dtype=float32)

time = 40933	action = 0	current_phase = 1	next_phase = 0	reward = -0.282039	array([[-2.108719 , -3.0299497]], dtype=float32)

time = 40938	action = 0	current_phase = 1	next_phase = 0	reward = -0.164631	array([[-2.2539713, -3.3721232]], dtype=float32)

time = 40943	action = 0	current_phase = 1	next_phase = 0	reward = 0.077882	array([[-2.711108 , -3.5301657]], dtype=float32)

time = 40948	action = 1	current_phase = 1	next_phase = 0	reward = -1.896666	array([[-5.770234, -3.473462]], dtype=float32)

time = 40956	action = 0	current_phase = 0	next_phase = 1	reward = -0.488359	array([[-2.099146 , -3.2476673]], dtype=float32)

time = 40961	action = 0	current_phase = 0	next_phase = 1	reward = -0.339179	array([[-2.0868065, -2.7588396]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1887 - val_loss: 0.0440

Epoch 2/50

 - 4s - loss: 0.1822 - val_loss: 0.0449

Epoch 3/50

 - 4s - loss: 0.1865 - val_loss: 0.0459

Epoch 4/50

 - 4s - loss: 0.1567 - val_loss: 0.0438

Epoch 5/50

 - 4s - loss: 0.1939 - val_loss: 0.0469

Epoch 6/50

 - 4s - loss: 0.1016 - val_loss: 0.0445

Epoch 7/50

 - 4s - loss: 0.1314 - val_loss: 0.0456

Epoch 8/50

 - 4s - loss: 0.1781 - val_loss: 0.0493

Epoch 9/50

 - 4s - loss: 0.1445 - val_loss: 0.0446

Epoch 10/50

 - 4s - loss: 0.1143 - val_loss: 0.0473

Epoch 11/50

 - 4s - loss: 0.1442 - val_loss: 0.0455

Epoch 12/50

 - 4s - loss: 0.1273 - val_loss: 0.0491

Epoch 13/50

 - 4s - loss: 0.1450 - val_loss: 0.0601

Epoch 14/50

 - 4s - loss: 0.1057 - val_loss: 0.0536

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 40966	action = 0	current_phase = 0	next_phase = 1	reward = -0.196461	array([[-2.100727, -2.458833]], dtype=float32)

time = 40971	action = 0	current_phase = 0	next_phase = 1	reward = 0.298767	array([[-2.240993, -2.524462]], dtype=float32)

time = 40976	action = 1	current_phase = 0	next_phase = 1	reward = -1.561239	array([[-4.6074734, -3.2417665]], dtype=float32)

time = 40984	action = 0	current_phase = 1	next_phase = 0	reward = -0.567260	array([[-2.1538732, -3.0157743]], dtype=float32)

time = 40989	action = 0	current_phase = 1	next_phase = 0	reward = -0.412158	array([[-1.969923 , -3.1491842]], dtype=float32)

time = 40994	action = 0	current_phase = 1	next_phase = 0	reward = -0.259570	array([[-1.9870198, -3.1368906]], dtype=float32)

time = 40999	action = 0	current_phase = 1	next_phase = 0	reward = -0.169122	array([[-2.1041589, -3.598241 ]], dtype=float32)

time = 41004	action = 1	current_phase = 1	next_phase = 0	reward = -0.464854	array([[-2.5502074, -2.2595077]], dtype=float32)

time = 41012	action = 0	current_phase = 0	next_phase = 1	reward = -0.609984	array([[-2.2658927, -3.5888085]], dtype=float32)

time = 41017	action = 0	current_phase = 0	next_phase = 1	reward = -0.454150	array([[-2.1025429, -2.8567014]], dtype=float32)

time = 41022	action = 1	current_phase = 0	next_phase = 1	reward = -1.401360	array([[-2.1003397, -2.0858352]], dtype=float32)

time = 41030	action = 0	current_phase = 1	next_phase = 0	reward = 0.349093	array([[-1.5004225, -3.850623 ]], dtype=float32)

time = 41035	action = 1	current_phase = 1	next_phase = 0	reward = -1.422750	array([[-4.2770967, -2.9162881]], dtype=float32)

time = 41043	action = 0	current_phase = 0	next_phase = 1	reward = -0.595558	array([[-2.2198548, -3.4005744]], dtype=float32)

time = 41048	action = 0	current_phase = 0	next_phase = 1	reward = -0.444778	array([[-2.0969288, -2.8207688]], dtype=float32)

time = 41053	action = 0	current_phase = 0	next_phase = 1	reward = -0.286542	array([[-2.0335267, -2.2831483]], dtype=float32)

time = 41058	action = 0	current_phase = 0	next_phase = 1	reward = -0.161951	array([[-2.3818495, -3.0221083]], dtype=float32)

time = 41063	action = 0	current_phase = 0	next_phase = 1	reward = 0.024960	array([[-2.7966352, -3.9898608]], dtype=float32)

time = 41068	action = 1	current_phase = 0	next_phase = 1	reward = -1.906257	array([[-6.3884315, -3.581342 ]], dtype=float32)

time = 41076	action = 0	current_phase = 1	next_phase = 0	reward = -0.502831	array([[-2.2486532, -3.248951 ]], dtype=float32)

time = 41081	action = 0	current_phase = 1	next_phase = 0	reward = -0.352387	array([[-1.9683678, -3.1417027]], dtype=float32)

time = 41086	action = 0	current_phase = 1	next_phase = 0	reward = -0.214007	array([[-2.002012, -3.199733]], dtype=float32)

time = 41091	action = 0	current_phase = 1	next_phase = 0	reward = 0.367944	array([[-2.1789975, -3.8681095]], dtype=float32)

time = 41096	action = 1	current_phase = 1	next_phase = 0	reward = -1.494491	array([[-3.767328 , -3.0184498]], dtype=float32)

time = 41104	action = 0	current_phase = 0	next_phase = 1	reward = -0.561917	array([[-2.109084 , -2.9550443]], dtype=float32)

time = 41109	action = 0	current_phase = 0	next_phase = 1	reward = -0.405890	array([[-2.0405722, -2.934048 ]], dtype=float32)

time = 41114	action = 0	current_phase = 0	next_phase = 1	reward = -0.250862	array([[-2.031679 , -2.2998002]], dtype=float32)

time = 41119	action = 0	current_phase = 0	next_phase = 1	reward = -0.173338	array([[-2.19084  , -3.1700442]], dtype=float32)

time = 41124	action = 1	current_phase = 0	next_phase = 1	reward = -0.442532	array([[-3.9904568, -2.340254 ]], dtype=float32)

time = 41132	action = 0	current_phase = 1	next_phase = 0	reward = -0.626674	array([[-2.3588867, -2.8944926]], dtype=float32)

time = 41137	action = 0	current_phase = 1	next_phase = 0	reward = -0.473075	array([[-2.2080472, -3.2732675]], dtype=float32)

time = 41142	action = 0	current_phase = 1	next_phase = 0	reward = -0.312772	array([[-2.1423285, -3.0262916]], dtype=float32)

time = 41147	action = 0	current_phase = 1	next_phase = 0	reward = -0.176235	array([[-2.303857 , -3.1770737]], dtype=float32)

time = 41152	action = 0	current_phase = 1	next_phase = 0	reward = 0.211161	array([[-2.67048  , -3.8024786]], dtype=float32)

time = 41157	action = 1	current_phase = 1	next_phase = 0	reward = -1.730133	array([[-5.820293 , -3.5366995]], dtype=float32)

time = 41165	action = 0	current_phase = 0	next_phase = 1	reward = -0.514546	array([[-2.1444118, -3.2164247]], dtype=float32)

time = 41170	action = 0	current_phase = 0	next_phase = 1	reward = -0.361474	array([[-1.9208097, -3.0059083]], dtype=float32)

time = 41175	action = 0	current_phase = 0	next_phase = 1	reward = -0.214669	array([[-2.0284343, -2.2979305]], dtype=float32)

time = 41180	action = 0	current_phase = 0	next_phase = 1	reward = 0.356248	array([[-2.2787778, -2.6893463]], dtype=float32)

time = 41185	action = 1	current_phase = 0	next_phase = 1	reward = -1.261869	array([[-4.5061727, -3.1849296]], dtype=float32)

time = 41193	action = 0	current_phase = 1	next_phase = 0	reward = -0.592073	array([[-2.3614519, -2.8929796]], dtype=float32)

time = 41198	action = 0	current_phase = 1	next_phase = 0	reward = -0.437196	array([[-2.1508229, -3.0211887]], dtype=float32)

time = 41203	action = 0	current_phase = 1	next_phase = 0	reward = -0.278637	array([[-2.1314225, -3.0178258]], dtype=float32)

time = 41208	action = 0	current_phase = 1	next_phase = 0	reward = -0.163230	array([[-2.2778769, -3.317526 ]], dtype=float32)

time = 41213	action = 0	current_phase = 1	next_phase = 0	reward = -0.040433	array([[-2.708089 , -3.3642504]], dtype=float32)

time = 41218	action = 1	current_phase = 1	next_phase = 0	reward = -1.896915	array([[-5.827681, -3.545087]], dtype=float32)

time = 41226	action = 0	current_phase = 0	next_phase = 1	reward = -0.496514	array([[-2.1090133, -3.2250185]], dtype=float32)

time = 41231	action = 0	current_phase = 0	next_phase = 1	reward = -0.345363	array([[-2.0846963, -2.8356793]], dtype=float32)

time = 41236	action = 0	current_phase = 0	next_phase = 1	reward = -0.194722	array([[-2.0616698, -2.3709443]], dtype=float32)

time = 41241	action = 0	current_phase = 0	next_phase = 1	reward = 0.294990	array([[-2.2067044, -2.328796 ]], dtype=float32)

time = 41246	action = 1	current_phase = 0	next_phase = 1	reward = -1.612871	array([[-4.6693306, -3.2537987]], dtype=float32)

time = 41254	action = 0	current_phase = 1	next_phase = 0	reward = -0.561457	array([[-2.159849 , -3.0152934]], dtype=float32)

time = 41259	action = 0	current_phase = 1	next_phase = 0	reward = -0.404109	array([[-1.9703948, -3.1487532]], dtype=float32)

time = 41264	action = 0	current_phase = 1	next_phase = 0	reward = -0.252240	array([[-1.9682946, -3.1496043]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0897 - val_loss: 0.0222

Epoch 2/50

 - 4s - loss: 0.1007 - val_loss: 0.0270

Epoch 3/50

 - 4s - loss: 0.1162 - val_loss: 0.0313

Epoch 4/50

 - 4s - loss: 0.0957 - val_loss: 0.0176

Epoch 5/50

 - 4s - loss: 0.1012 - val_loss: 0.0209

Epoch 6/50

 - 4s - loss: 0.0853 - val_loss: 0.0213

Epoch 7/50

 - 4s - loss: 0.0766 - val_loss: 0.0175

Epoch 8/50

 - 4s - loss: 0.0706 - val_loss: 0.0197

Epoch 9/50

 - 4s - loss: 0.0875 - val_loss: 0.0190

Epoch 10/50

 - 4s - loss: 0.0741 - val_loss: 0.0198

Epoch 11/50

 - 4s - loss: 0.0637 - val_loss: 0.0191

Epoch 12/50

 - 4s - loss: 0.0612 - val_loss: 0.0189

Epoch 13/50

 - 4s - loss: 0.0820 - val_loss: 0.0291

Epoch 14/50

 - 4s - loss: 0.0814 - val_loss: 0.0254

Epoch 15/50

 - 4s - loss: 0.0752 - val_loss: 0.0203

Epoch 16/50

 - 4s - loss: 0.0810 - val_loss: 0.0308

Epoch 17/50

 - 4s - loss: 0.0800 - val_loss: 0.0185

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 41269	action = 0	current_phase = 1	next_phase = 0	reward = -0.165960	array([[-2.1119552, -3.6082318]], dtype=float32)

time = 41274	action = 1	current_phase = 1	next_phase = 0	reward = -0.409744	array([[-2.6179898, -2.2748523]], dtype=float32)

time = 41282	action = 0	current_phase = 0	next_phase = 1	reward = -0.614476	array([[-2.2360873, -3.5929701]], dtype=float32)

time = 41287	action = 0	current_phase = 0	next_phase = 1	reward = -0.460974	array([[-2.0721338, -2.8489203]], dtype=float32)

time = 41292	action = 1	current_phase = 0	next_phase = 1	reward = -1.418261	array([[-2.1145892, -2.0270834]], dtype=float32)

time = 41300	action = 0	current_phase = 1	next_phase = 0	reward = 0.358301	array([[-1.5331483, -4.1306944]], dtype=float32)

time = 41305	action = 1	current_phase = 1	next_phase = 0	reward = -1.363882	array([[-3.9638536, -2.7557943]], dtype=float32)

time = 41313	action = 0	current_phase = 0	next_phase = 1	reward = -0.585907	array([[-2.217084 , -3.4840968]], dtype=float32)

time = 41318	action = 0	current_phase = 0	next_phase = 1	reward = -0.428302	array([[-2.0434117, -2.878279 ]], dtype=float32)

time = 41323	action = 0	current_phase = 0	next_phase = 1	reward = -0.277639	array([[-2.039854 , -2.2062294]], dtype=float32)

time = 41328	action = 0	current_phase = 0	next_phase = 1	reward = -0.163297	array([[-2.3476007, -2.9071634]], dtype=float32)

time = 41333	action = 0	current_phase = 0	next_phase = 1	reward = 0.021045	array([[-2.969614 , -3.4513137]], dtype=float32)

time = 41338	action = 1	current_phase = 0	next_phase = 1	reward = -1.903457	array([[-6.3486795, -3.5629382]], dtype=float32)

time = 41346	action = 0	current_phase = 1	next_phase = 0	reward = -0.508697	array([[-2.0715349, -3.2337165]], dtype=float32)

time = 41351	action = 0	current_phase = 1	next_phase = 0	reward = -0.362606	array([[-1.8872529, -3.1351027]], dtype=float32)

time = 41356	action = 0	current_phase = 1	next_phase = 0	reward = -0.213037	array([[-1.8980197, -3.157706 ]], dtype=float32)

time = 41361	action = 0	current_phase = 1	next_phase = 0	reward = 0.346839	array([[-2.1258676, -3.8860269]], dtype=float32)

time = 41366	action = 1	current_phase = 1	next_phase = 0	reward = -1.496935	array([[-5.575649, -3.276624]], dtype=float32)

time = 41374	action = 0	current_phase = 0	next_phase = 1	reward = -0.557317	array([[-2.0871398, -3.0691297]], dtype=float32)

time = 41379	action = 0	current_phase = 0	next_phase = 1	reward = -0.407624	array([[-2.0168848, -2.9332154]], dtype=float32)

time = 41384	action = 0	current_phase = 0	next_phase = 1	reward = -0.246306	array([[-2.037812 , -2.2214453]], dtype=float32)

time = 41389	action = 0	current_phase = 0	next_phase = 1	reward = -0.176493	array([[-2.1805463, -3.0479271]], dtype=float32)

time = 41394	action = 1	current_phase = 0	next_phase = 1	reward = -0.532421	array([[-4.1229696, -2.2427924]], dtype=float32)

time = 41402	action = 0	current_phase = 1	next_phase = 0	reward = -0.618935	array([[-2.2878642, -2.8718305]], dtype=float32)

time = 41407	action = 0	current_phase = 1	next_phase = 0	reward = -0.459055	array([[-2.105176 , -3.2486298]], dtype=float32)

time = 41412	action = 0	current_phase = 1	next_phase = 0	reward = -0.307011	array([[-2.0870135, -3.0240905]], dtype=float32)

time = 41417	action = 0	current_phase = 1	next_phase = 0	reward = -0.173599	array([[-2.2597365, -3.1698985]], dtype=float32)

time = 41422	action = 0	current_phase = 1	next_phase = 0	reward = 0.166657	array([[-2.5817544, -3.7351036]], dtype=float32)

time = 41427	action = 1	current_phase = 1	next_phase = 0	reward = -1.781728	array([[-5.843896 , -3.5087101]], dtype=float32)

time = 41435	action = 0	current_phase = 0	next_phase = 1	reward = -0.526971	array([[-2.14978  , -3.2018363]], dtype=float32)

time = 41440	action = 0	current_phase = 0	next_phase = 1	reward = -0.364618	array([[-2.015642 , -2.9357235]], dtype=float32)

time = 41445	action = 0	current_phase = 0	next_phase = 1	reward = -0.209251	array([[-2.0360467, -2.2169714]], dtype=float32)

time = 41450	action = 0	current_phase = 0	next_phase = 1	reward = 0.355390	array([[-2.158099 , -2.5545368]], dtype=float32)

time = 41455	action = 1	current_phase = 0	next_phase = 1	reward = -1.261512	array([[-4.517432, -3.200666]], dtype=float32)

time = 41463	action = 0	current_phase = 1	next_phase = 0	reward = -0.593828	array([[-2.2776968, -2.8939152]], dtype=float32)

time = 41468	action = 0	current_phase = 1	next_phase = 0	reward = -0.442534	array([[-2.0892384, -3.0229506]], dtype=float32)

time = 41473	action = 0	current_phase = 1	next_phase = 0	reward = -0.287652	array([[-2.0866175, -3.022913 ]], dtype=float32)

time = 41478	action = 0	current_phase = 1	next_phase = 0	reward = -0.165167	array([[-2.2567103, -3.1722353]], dtype=float32)

time = 41483	action = 0	current_phase = 1	next_phase = 0	reward = 0.080055	array([[-2.6189637, -3.741513 ]], dtype=float32)

time = 41488	action = 1	current_phase = 1	next_phase = 0	reward = -1.899503	array([[-5.85774  , -3.5212355]], dtype=float32)

time = 41496	action = 0	current_phase = 0	next_phase = 1	reward = -0.510311	array([[-2.1629105, -3.2127197]], dtype=float32)

time = 41501	action = 0	current_phase = 0	next_phase = 1	reward = -0.356040	array([[-2.0156846, -2.9359376]], dtype=float32)

time = 41506	action = 0	current_phase = 0	next_phase = 1	reward = -0.202664	array([[-2.0439913, -2.2371857]], dtype=float32)

time = 41511	action = 0	current_phase = 0	next_phase = 1	reward = 0.299787	array([[-2.294109 , -2.5491178]], dtype=float32)

time = 41516	action = 1	current_phase = 0	next_phase = 1	reward = -1.559565	array([[-4.5764775, -3.2261398]], dtype=float32)

time = 41524	action = 0	current_phase = 1	next_phase = 0	reward = -0.569486	array([[-2.125744 , -3.0097165]], dtype=float32)

time = 41529	action = 0	current_phase = 1	next_phase = 0	reward = -0.414387	array([[-1.8939552, -3.1325743]], dtype=float32)

time = 41534	action = 0	current_phase = 1	next_phase = 0	reward = -0.258094	array([[-2.0112083, -3.0623586]], dtype=float32)

time = 41539	action = 0	current_phase = 1	next_phase = 0	reward = -0.161808	array([[-2.0993063, -3.5776534]], dtype=float32)

time = 41544	action = 1	current_phase = 1	next_phase = 0	reward = -0.354088	array([[-2.549982, -2.216244]], dtype=float32)

time = 41552	action = 0	current_phase = 0	next_phase = 1	reward = -0.613183	array([[-2.235764 , -3.5921447]], dtype=float32)

time = 41557	action = 0	current_phase = 0	next_phase = 1	reward = -0.456049	array([[-2.0770226, -2.8436525]], dtype=float32)

time = 41562	action = 0	current_phase = 0	next_phase = 1	reward = -0.289459	array([[-2.0818505, -2.1066105]], dtype=float32)

time = 41567	action = 0	current_phase = 0	next_phase = 1	reward = -0.163709	array([[-2.3321714, -2.989078 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0944 - val_loss: 0.0780

Epoch 2/50

 - 4s - loss: 0.0591 - val_loss: 0.0801

Epoch 3/50

 - 4s - loss: 0.0651 - val_loss: 0.0808

Epoch 4/50

 - 4s - loss: 0.0779 - val_loss: 0.0833

Epoch 5/50

 - 4s - loss: 0.0509 - val_loss: 0.0835

Epoch 6/50

 - 4s - loss: 0.0530 - val_loss: 0.0879

Epoch 7/50

 - 4s - loss: 0.0450 - val_loss: 0.0911

Epoch 8/50

 - 4s - loss: 0.0813 - val_loss: 0.0936

Epoch 9/50

 - 4s - loss: 0.0693 - val_loss: 0.0940

Epoch 10/50

 - 4s - loss: 0.0445 - val_loss: 0.0959

Epoch 11/50

 - 4s - loss: 0.0640 - val_loss: 0.0959

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 41572	action = 0	current_phase = 0	next_phase = 1	reward = 0.162278	array([[-2.5361047, -3.5422668]], dtype=float32)

time = 41577	action = 1	current_phase = 0	next_phase = 1	reward = -1.783202	array([[-6.5333714, -3.431957 ]], dtype=float32)

time = 41585	action = 0	current_phase = 1	next_phase = 0	reward = -0.522984	array([[-2.0391846, -2.9482274]], dtype=float32)

time = 41590	action = 0	current_phase = 1	next_phase = 0	reward = -0.380974	array([[-1.8657439, -3.1510534]], dtype=float32)

time = 41595	action = 0	current_phase = 1	next_phase = 0	reward = -0.239236	array([[-1.8655884, -3.1506472]], dtype=float32)

time = 41600	action = 0	current_phase = 1	next_phase = 0	reward = 0.365097	array([[-1.9549421, -3.8196068]], dtype=float32)

time = 41605	action = 1	current_phase = 1	next_phase = 0	reward = -1.359751	array([[-3.6112993, -3.0963893]], dtype=float32)

time = 41613	action = 0	current_phase = 0	next_phase = 1	reward = -0.582649	array([[-2.2575588, -3.5387642]], dtype=float32)

time = 41618	action = 0	current_phase = 0	next_phase = 1	reward = -0.431558	array([[-2.0634024, -2.8283703]], dtype=float32)

time = 41623	action = 1	current_phase = 0	next_phase = 1	reward = -1.381357	array([[-2.0918443, -2.0912855]], dtype=float32)

time = 41631	action = 0	current_phase = 1	next_phase = 0	reward = 0.301421	array([[-1.0336355, -4.18169  ]], dtype=float32)

time = 41636	action = 0	current_phase = 1	next_phase = 0	reward = -1.064055	array([[-0.8069283, -3.5726392]], dtype=float32)

time = 41641	action = 1	current_phase = 1	next_phase = 0	reward = -2.062494	array([[-4.863819 , -3.7586732]], dtype=float32)

time = 41649	action = 0	current_phase = 0	next_phase = 1	reward = -0.390118	array([[-2.0492332, -3.2268786]], dtype=float32)

time = 41654	action = 0	current_phase = 0	next_phase = 1	reward = -0.230318	array([[-2.0379117, -2.2172725]], dtype=float32)

time = 41659	action = 0	current_phase = 0	next_phase = 1	reward = -0.189916	array([[-2.358925 , -2.9601166]], dtype=float32)

time = 41664	action = 1	current_phase = 0	next_phase = 1	reward = -0.511981	array([[-4.0494933, -2.252131 ]], dtype=float32)

time = 41672	action = 0	current_phase = 1	next_phase = 0	reward = -0.623896	array([[-2.576202 , -3.0519147]], dtype=float32)

time = 41677	action = 0	current_phase = 1	next_phase = 0	reward = -0.468639	array([[-2.1631   , -3.1733952]], dtype=float32)

time = 41682	action = 0	current_phase = 1	next_phase = 0	reward = -0.307591	array([[-2.0529928, -3.0615232]], dtype=float32)

time = 41687	action = 0	current_phase = 1	next_phase = 0	reward = -0.176149	array([[-2.2823348, -3.2034004]], dtype=float32)

time = 41692	action = 0	current_phase = 1	next_phase = 0	reward = 0.255040	array([[-2.5617268, -3.7660093]], dtype=float32)

time = 41697	action = 1	current_phase = 1	next_phase = 0	reward = -1.783520	array([[-5.80751  , -3.5485563]], dtype=float32)

time = 41705	action = 0	current_phase = 0	next_phase = 1	reward = -0.534910	array([[-2.1678593, -3.178688 ]], dtype=float32)

time = 41710	action = 0	current_phase = 0	next_phase = 1	reward = -0.381594	array([[-2.0184848, -2.923441 ]], dtype=float32)

time = 41715	action = 0	current_phase = 0	next_phase = 1	reward = -0.221546	array([[-2.0343122, -2.225837 ]], dtype=float32)

time = 41720	action = 0	current_phase = 0	next_phase = 1	reward = 0.360116	array([[-2.2009454, -2.2770035]], dtype=float32)

time = 41725	action = 1	current_phase = 0	next_phase = 1	reward = -1.311447	array([[-4.470376 , -3.1470263]], dtype=float32)

time = 41733	action = 0	current_phase = 1	next_phase = 0	reward = -0.580268	array([[-2.2357059, -2.892258 ]], dtype=float32)

time = 41738	action = 0	current_phase = 1	next_phase = 0	reward = -0.427404	array([[-2.0675716, -3.0584457]], dtype=float32)

time = 41743	action = 0	current_phase = 1	next_phase = 0	reward = -0.272915	array([[-2.0793576, -3.0509644]], dtype=float32)

time = 41748	action = 0	current_phase = 1	next_phase = 0	reward = -0.161723	array([[-2.2699704, -3.2187233]], dtype=float32)

time = 41753	action = 0	current_phase = 1	next_phase = 0	reward = 0.070588	array([[-2.686911 , -3.4190645]], dtype=float32)

time = 41758	action = 1	current_phase = 1	next_phase = 0	reward = -1.886521	array([[-5.8040237, -3.551627 ]], dtype=float32)

time = 41766	action = 0	current_phase = 0	next_phase = 1	reward = -0.482710	array([[-2.1393862, -3.1938026]], dtype=float32)

time = 41771	action = 0	current_phase = 0	next_phase = 1	reward = -0.329669	array([[-2.0764117, -2.8050528]], dtype=float32)

time = 41776	action = 0	current_phase = 0	next_phase = 1	reward = -0.184283	array([[-2.0500977, -2.2491815]], dtype=float32)

time = 41781	action = 0	current_phase = 0	next_phase = 1	reward = 0.275123	array([[-2.2260704, -2.3691478]], dtype=float32)

time = 41786	action = 1	current_phase = 0	next_phase = 1	reward = -1.613945	array([[-4.5234904, -3.1760852]], dtype=float32)

time = 41794	action = 0	current_phase = 1	next_phase = 0	reward = -0.562234	array([[-2.099321 , -3.0434926]], dtype=float32)

time = 41799	action = 0	current_phase = 1	next_phase = 0	reward = -0.417045	array([[-1.8680278, -3.1499438]], dtype=float32)

time = 41804	action = 0	current_phase = 1	next_phase = 0	reward = -0.260876	array([[-1.8650377, -3.1497142]], dtype=float32)

time = 41809	action = 0	current_phase = 1	next_phase = 0	reward = -0.168196	array([[-1.9050174, -3.7751997]], dtype=float32)

time = 41814	action = 1	current_phase = 1	next_phase = 0	reward = -0.378260	array([[-2.5792565, -2.2731323]], dtype=float32)

time = 41822	action = 0	current_phase = 0	next_phase = 1	reward = -0.619394	array([[-2.2692518, -3.5680466]], dtype=float32)

time = 41827	action = 0	current_phase = 0	next_phase = 1	reward = -0.458404	array([[-2.0636063, -2.8533573]], dtype=float32)

time = 41832	action = 1	current_phase = 0	next_phase = 1	reward = -1.407070	array([[-2.1167598, -2.0392342]], dtype=float32)

time = 41840	action = 0	current_phase = 1	next_phase = 0	reward = 0.354382	array([[-1.2000178, -4.0036383]], dtype=float32)

time = 41845	action = 1	current_phase = 1	next_phase = 0	reward = -1.312369	array([[-3.646691 , -3.0487645]], dtype=float32)

time = 41853	action = 0	current_phase = 0	next_phase = 1	reward = -0.594252	array([[-2.2200747, -3.4321957]], dtype=float32)

time = 41858	action = 0	current_phase = 0	next_phase = 1	reward = -0.441620	array([[-2.0228062, -2.913304 ]], dtype=float32)

time = 41863	action = 0	current_phase = 0	next_phase = 1	reward = -0.288985	array([[-2.0877833, -2.1009145]], dtype=float32)

time = 41868	action = 0	current_phase = 0	next_phase = 1	reward = -0.166826	array([[-2.398217 , -2.9612477]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1034 - val_loss: 0.3470

Epoch 2/50

 - 4s - loss: 0.0942 - val_loss: 0.3590

Epoch 3/50

 - 4s - loss: 0.0570 - val_loss: 0.3538

Epoch 4/50

 - 4s - loss: 0.0623 - val_loss: 0.3720

Epoch 5/50

 - 4s - loss: 0.0468 - val_loss: 0.3854

Epoch 6/50

 - 4s - loss: 0.0648 - val_loss: 0.3772

Epoch 7/50

 - 4s - loss: 0.0380 - val_loss: 0.3698

Epoch 8/50

 - 4s - loss: 0.0438 - val_loss: 0.3825

Epoch 9/50

 - 4s - loss: 0.0435 - val_loss: 0.4043

Epoch 10/50

 - 4s - loss: 0.0361 - val_loss: 0.4006

Epoch 11/50

 - 4s - loss: 0.0411 - val_loss: 0.3975

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 41873	action = 0	current_phase = 0	next_phase = 1	reward = 0.148461	array([[-2.950207 , -3.0798888]], dtype=float32)

time = 41878	action = 1	current_phase = 0	next_phase = 1	reward = -1.894574	array([[-6.354274 , -3.5350664]], dtype=float32)

time = 41886	action = 0	current_phase = 1	next_phase = 0	reward = -0.485638	array([[-2.1080961, -3.22566  ]], dtype=float32)

time = 41891	action = 0	current_phase = 1	next_phase = 0	reward = -0.331420	array([[-2.0933752, -3.0498254]], dtype=float32)

time = 41896	action = 0	current_phase = 1	next_phase = 0	reward = -0.187023	array([[-2.0688086, -3.084429 ]], dtype=float32)

time = 41901	action = 0	current_phase = 1	next_phase = 0	reward = 0.274023	array([[-2.3183534, -3.8114638]], dtype=float32)

time = 41906	action = 1	current_phase = 1	next_phase = 0	reward = -1.612681	array([[-5.6045566, -3.267753 ]], dtype=float32)

time = 41914	action = 0	current_phase = 0	next_phase = 1	reward = -0.562269	array([[-2.084319 , -2.9753132]], dtype=float32)

time = 41919	action = 0	current_phase = 0	next_phase = 1	reward = -0.406045	array([[-2.1089702, -2.8356478]], dtype=float32)

time = 41924	action = 0	current_phase = 0	next_phase = 1	reward = -0.248383	array([[-2.056957, -2.212186]], dtype=float32)

time = 41929	action = 0	current_phase = 0	next_phase = 1	reward = -0.176279	array([[-2.2197678, -3.1558683]], dtype=float32)

time = 41934	action = 1	current_phase = 0	next_phase = 1	reward = -0.544706	array([[-4.1402636, -2.2557507]], dtype=float32)

time = 41942	action = 0	current_phase = 1	next_phase = 0	reward = -0.615490	array([[-2.305479 , -2.8762257]], dtype=float32)

time = 41947	action = 0	current_phase = 1	next_phase = 0	reward = -0.465036	array([[-2.1618671, -3.239693 ]], dtype=float32)

time = 41952	action = 0	current_phase = 1	next_phase = 0	reward = -0.310311	array([[-2.1366792, -3.024263 ]], dtype=float32)

time = 41957	action = 0	current_phase = 1	next_phase = 0	reward = -0.173426	array([[-2.3181562, -3.1652467]], dtype=float32)

time = 41962	action = 0	current_phase = 1	next_phase = 0	reward = 0.184884	array([[-2.593175 , -3.7257671]], dtype=float32)

time = 41967	action = 1	current_phase = 1	next_phase = 0	reward = -1.786144	array([[-5.841919 , -3.5211685]], dtype=float32)

time = 41975	action = 0	current_phase = 0	next_phase = 1	reward = -0.537210	array([[-2.146558 , -3.1656733]], dtype=float32)

time = 41980	action = 0	current_phase = 0	next_phase = 1	reward = -0.389259	array([[-2.034571, -2.911753]], dtype=float32)

time = 41985	action = 0	current_phase = 0	next_phase = 1	reward = -0.236732	array([[-2.0556636, -2.218249 ]], dtype=float32)

time = 41990	action = 0	current_phase = 0	next_phase = 1	reward = 0.387666	array([[-2.2041862, -2.586533 ]], dtype=float32)

time = 41995	action = 1	current_phase = 0	next_phase = 1	reward = -1.180843	array([[-4.4324865, -3.1320038]], dtype=float32)

time = 42003	action = 0	current_phase = 1	next_phase = 0	reward = -0.582579	array([[-2.3066525, -2.8758948]], dtype=float32)

time = 42008	action = 0	current_phase = 1	next_phase = 0	reward = -0.426360	array([[-2.144945 , -3.0235472]], dtype=float32)

time = 42013	action = 0	current_phase = 1	next_phase = 0	reward = -0.265160	array([[-2.136716 , -3.0198944]], dtype=float32)

time = 42018	action = 0	current_phase = 1	next_phase = 0	reward = -0.165456	array([[-2.2595448, -3.218082 ]], dtype=float32)

time = 42023	action = 0	current_phase = 1	next_phase = 0	reward = 0.036260	array([[-2.7017775, -3.4747314]], dtype=float32)

time = 42028	action = 1	current_phase = 1	next_phase = 0	reward = -1.899144	array([[-5.816896, -3.551137]], dtype=float32)

time = 42036	action = 0	current_phase = 0	next_phase = 1	reward = -0.503571	array([[-2.1370797, -3.184393 ]], dtype=float32)

time = 42041	action = 0	current_phase = 0	next_phase = 1	reward = -0.357588	array([[-2.1006432, -2.806648 ]], dtype=float32)

time = 42046	action = 0	current_phase = 0	next_phase = 1	reward = -0.200954	array([[-2.0569394, -2.2177777]], dtype=float32)

time = 42051	action = 0	current_phase = 0	next_phase = 1	reward = 0.330273	array([[-2.28085  , -2.5299456]], dtype=float32)

time = 42056	action = 1	current_phase = 0	next_phase = 1	reward = -1.553173	array([[-4.5333176, -3.215327 ]], dtype=float32)

time = 42064	action = 0	current_phase = 1	next_phase = 0	reward = -0.559314	array([[-2.1896706, -3.0072248]], dtype=float32)

time = 42069	action = 0	current_phase = 1	next_phase = 0	reward = -0.397139	array([[-1.9599932, -3.1193507]], dtype=float32)

time = 42074	action = 0	current_phase = 1	next_phase = 0	reward = -0.235224	array([[-1.9480369, -3.115159 ]], dtype=float32)

time = 42079	action = 0	current_phase = 1	next_phase = 0	reward = -0.177109	array([[-1.9615519, -3.728368 ]], dtype=float32)

time = 42084	action = 1	current_phase = 1	next_phase = 0	reward = -0.584981	array([[-2.5160618, -2.272468 ]], dtype=float32)

time = 42092	action = 0	current_phase = 0	next_phase = 1	reward = -0.613828	array([[-2.2748919, -3.5694058]], dtype=float32)

time = 42097	action = 0	current_phase = 0	next_phase = 1	reward = -0.462413	array([[-2.1029   , -2.8086977]], dtype=float32)

time = 42102	action = 1	current_phase = 0	next_phase = 1	reward = -1.422890	array([[-2.1447978, -2.0311487]], dtype=float32)

time = 42110	action = 0	current_phase = 1	next_phase = 0	reward = 0.359497	array([[-0.7092909, -3.9634922]], dtype=float32)

time = 42115	action = 1	current_phase = 1	next_phase = 0	reward = -1.364313	array([[-3.9601567, -3.0699813]], dtype=float32)

time = 42123	action = 0	current_phase = 0	next_phase = 1	reward = -0.588611	array([[-2.1480918, -2.943087 ]], dtype=float32)

time = 42128	action = 0	current_phase = 0	next_phase = 1	reward = -0.434994	array([[-2.0789185, -2.8375063]], dtype=float32)

time = 42133	action = 0	current_phase = 0	next_phase = 1	reward = -0.277938	array([[-2.0657625, -2.1946328]], dtype=float32)

time = 42138	action = 0	current_phase = 0	next_phase = 1	reward = -0.161047	array([[-2.4177835, -2.9732602]], dtype=float32)

time = 42143	action = 0	current_phase = 0	next_phase = 1	reward = 0.009587	array([[-2.5694132, -4.3965735]], dtype=float32)

time = 42148	action = 1	current_phase = 0	next_phase = 1	reward = -1.898758	array([[-6.373457 , -3.5856104]], dtype=float32)

time = 42156	action = 0	current_phase = 1	next_phase = 0	reward = -0.500714	array([[-2.1192882, -3.2318769]], dtype=float32)

time = 42161	action = 0	current_phase = 1	next_phase = 0	reward = -0.348876	array([[-1.9536793, -3.1225631]], dtype=float32)

time = 42166	action = 0	current_phase = 1	next_phase = 0	reward = -0.194617	array([[-1.9626756, -3.1328852]], dtype=float32)

time = 42171	action = 0	current_phase = 1	next_phase = 0	reward = 0.333960	array([[-2.1973884, -3.8551023]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1624 - val_loss: 0.0234

Epoch 2/50

 - 4s - loss: 0.1580 - val_loss: 0.0219

Epoch 3/50

 - 4s - loss: 0.1214 - val_loss: 0.0211

Epoch 4/50

 - 4s - loss: 0.1275 - val_loss: 0.0241

Epoch 5/50

 - 4s - loss: 0.1221 - val_loss: 0.0253

Epoch 6/50

 - 4s - loss: 0.1078 - val_loss: 0.0251

Epoch 7/50

 - 4s - loss: 0.1261 - val_loss: 0.0242

Epoch 8/50

 - 4s - loss: 0.1403 - val_loss: 0.0233

Epoch 9/50

 - 4s - loss: 0.1153 - val_loss: 0.0266

Epoch 10/50

 - 4s - loss: 0.0811 - val_loss: 0.0262

Epoch 11/50

 - 4s - loss: 0.1001 - val_loss: 0.0252

Epoch 12/50

 - 4s - loss: 0.0807 - val_loss: 0.0240

Epoch 13/50

 - 4s - loss: 0.1122 - val_loss: 0.0251

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 42176	action = 1	current_phase = 1	next_phase = 0	reward = -1.556437	array([[-3.8518348, -3.1747897]], dtype=float32)

time = 42184	action = 0	current_phase = 0	next_phase = 1	reward = -0.557303	array([[-2.123686 , -3.0210853]], dtype=float32)

time = 42189	action = 0	current_phase = 0	next_phase = 1	reward = -0.411204	array([[-2.0295973, -2.9366815]], dtype=float32)

time = 42194	action = 0	current_phase = 0	next_phase = 1	reward = -0.255754	array([[-2.084424 , -2.2647145]], dtype=float32)

time = 42199	action = 0	current_phase = 0	next_phase = 1	reward = -0.172631	array([[-2.239225 , -3.1842682]], dtype=float32)

time = 42204	action = 1	current_phase = 0	next_phase = 1	reward = -0.439815	array([[-4.191157 , -2.3687453]], dtype=float32)

time = 42212	action = 0	current_phase = 1	next_phase = 0	reward = -0.620168	array([[-2.292553 , -2.9121432]], dtype=float32)

time = 42217	action = 0	current_phase = 1	next_phase = 0	reward = -0.464561	array([[-2.0935817, -3.2793663]], dtype=float32)

time = 42222	action = 0	current_phase = 1	next_phase = 0	reward = -0.302575	array([[-2.076286 , -3.0776165]], dtype=float32)

time = 42227	action = 0	current_phase = 1	next_phase = 0	reward = -0.167577	array([[-2.3536353, -3.1477015]], dtype=float32)

time = 42232	action = 0	current_phase = 1	next_phase = 0	reward = 0.169505	array([[-2.5619442, -3.808565 ]], dtype=float32)

time = 42237	action = 1	current_phase = 1	next_phase = 0	reward = -1.784211	array([[-5.847994 , -3.5600557]], dtype=float32)

time = 42245	action = 0	current_phase = 0	next_phase = 1	reward = -0.528208	array([[-2.1394384, -3.1943812]], dtype=float32)

time = 42250	action = 0	current_phase = 0	next_phase = 1	reward = -0.373407	array([[-2.048829 , -2.8956323]], dtype=float32)

time = 42255	action = 0	current_phase = 0	next_phase = 1	reward = -0.226175	array([[-2.0837579, -2.2648942]], dtype=float32)

time = 42260	action = 0	current_phase = 0	next_phase = 1	reward = 0.053737	array([[-2.2059133, -2.336164 ]], dtype=float32)

time = 42265	action = 1	current_phase = 0	next_phase = 1	reward = -1.084010	array([[-4.2282224, -2.895308 ]], dtype=float32)

time = 42273	action = 0	current_phase = 1	next_phase = 0	reward = -0.590339	array([[-2.2924547, -2.9175112]], dtype=float32)

time = 42278	action = 0	current_phase = 1	next_phase = 0	reward = -0.438718	array([[-2.1379821, -3.0491369]], dtype=float32)

time = 42283	action = 0	current_phase = 1	next_phase = 0	reward = -0.288967	array([[-2.1360972, -3.04802  ]], dtype=float32)

time = 42288	action = 0	current_phase = 1	next_phase = 0	reward = -0.167433	array([[-2.3058848, -3.1920142]], dtype=float32)

time = 42293	action = 0	current_phase = 1	next_phase = 0	reward = 0.023953	array([[-2.3967588, -3.0712726]], dtype=float32)

time = 42298	action = 1	current_phase = 1	next_phase = 0	reward = -1.901464	array([[-5.865421 , -3.5611918]], dtype=float32)

time = 42306	action = 0	current_phase = 0	next_phase = 1	reward = -0.502585	array([[-2.1621523, -3.200367 ]], dtype=float32)

time = 42311	action = 0	current_phase = 0	next_phase = 1	reward = -0.348216	array([[-2.05263  , -2.8886259]], dtype=float32)

time = 42316	action = 0	current_phase = 0	next_phase = 1	reward = -0.200905	array([[-2.0864773, -2.2639668]], dtype=float32)

time = 42321	action = 0	current_phase = 0	next_phase = 1	reward = 0.325048	array([[-2.3713975, -2.712159 ]], dtype=float32)

time = 42326	action = 1	current_phase = 0	next_phase = 1	reward = -1.558116	array([[-4.5444026, -3.2762377]], dtype=float32)

time = 42334	action = 0	current_phase = 1	next_phase = 0	reward = -0.577727	array([[-2.1240385, -3.023753 ]], dtype=float32)

time = 42339	action = 0	current_phase = 1	next_phase = 0	reward = -0.431347	array([[-1.9330685, -3.1492798]], dtype=float32)

time = 42344	action = 0	current_phase = 1	next_phase = 0	reward = -0.269630	array([[-2.0436928, -3.090952 ]], dtype=float32)

time = 42349	action = 0	current_phase = 1	next_phase = 0	reward = -0.173996	array([[-1.9260364, -3.7759707]], dtype=float32)

time = 42354	action = 1	current_phase = 1	next_phase = 0	reward = -0.469957	array([[-2.6889353, -2.4837987]], dtype=float32)

time = 42362	action = 0	current_phase = 0	next_phase = 1	reward = -0.622421	array([[-2.2629282, -3.6117468]], dtype=float32)

time = 42367	action = 0	current_phase = 0	next_phase = 1	reward = -0.480317	array([[-2.0890121, -2.8389971]], dtype=float32)

time = 42372	action = 1	current_phase = 0	next_phase = 1	reward = -1.454888	array([[-2.169376 , -2.1088836]], dtype=float32)

time = 42380	action = 0	current_phase = 1	next_phase = 0	reward = 0.082424	array([[-1.25652 , -3.912213]], dtype=float32)

time = 42385	action = 0	current_phase = 1	next_phase = 0	reward = -0.543534	array([[-1.2385037, -3.7765012]], dtype=float32)

time = 42390	action = 0	current_phase = 1	next_phase = 0	reward = -1.739917	array([[ 8.739094 , -3.6644502]], dtype=float32)

time = 42395	action = 1	current_phase = 1	next_phase = 0	reward = -1.872425	array([[-5.442828 , -3.5509336]], dtype=float32)

time = 42403	action = 0	current_phase = 0	next_phase = 1	reward = -0.302678	array([[-2.061215 , -2.8389938]], dtype=float32)

time = 42408	action = 0	current_phase = 0	next_phase = 1	reward = -0.175837	array([[-2.4152606, -3.0302439]], dtype=float32)

time = 42413	action = 0	current_phase = 0	next_phase = 1	reward = 0.132034	array([[-2.2295518, -4.008232 ]], dtype=float32)

time = 42418	action = 1	current_phase = 0	next_phase = 1	reward = -1.848306	array([[-5.4550524, -3.4445448]], dtype=float32)

time = 42426	action = 0	current_phase = 1	next_phase = 0	reward = -0.504822	array([[-1.9468093, -3.1988692]], dtype=float32)

time = 42431	action = 0	current_phase = 1	next_phase = 0	reward = -0.354919	array([[-2.0511322, -3.0913088]], dtype=float32)

time = 42436	action = 0	current_phase = 1	next_phase = 0	reward = -0.211775	array([[-1.9327497, -3.1503465]], dtype=float32)

time = 42441	action = 0	current_phase = 1	next_phase = 0	reward = 0.292205	array([[-2.1600637, -3.9328573]], dtype=float32)

time = 42446	action = 1	current_phase = 1	next_phase = 0	reward = -1.554819	array([[-5.6060658, -3.3084147]], dtype=float32)

time = 42454	action = 0	current_phase = 0	next_phase = 1	reward = -0.565421	array([[-2.1605952, -3.0432727]], dtype=float32)

time = 42459	action = 0	current_phase = 0	next_phase = 1	reward = -0.414165	array([[-2.0268447, -2.9429605]], dtype=float32)

time = 42464	action = 0	current_phase = 0	next_phase = 1	reward = -0.259790	array([[-2.1374836, -2.1511023]], dtype=float32)

time = 42469	action = 0	current_phase = 0	next_phase = 1	reward = -0.172757	array([[-2.388263, -3.038601]], dtype=float32)

time = 42474	action = 1	current_phase = 0	next_phase = 1	reward = -0.513126	array([[-4.147863 , -2.2896616]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2541 - val_loss: 0.0563

Epoch 2/50

 - 4s - loss: 0.1943 - val_loss: 0.0363

Epoch 3/50

 - 4s - loss: 0.1594 - val_loss: 0.0318

Epoch 4/50

 - 4s - loss: 0.2386 - val_loss: 0.0312

Epoch 5/50

 - 4s - loss: 0.1734 - val_loss: 0.0352

Epoch 6/50

 - 4s - loss: 0.1932 - val_loss: 0.0198

Epoch 7/50

 - 4s - loss: 0.2299 - val_loss: 0.0200

Epoch 8/50

 - 4s - loss: 0.1353 - val_loss: 0.0191

Epoch 9/50

 - 4s - loss: 0.2157 - val_loss: 0.0255

Epoch 10/50

 - 4s - loss: 0.2174 - val_loss: 0.0244

Epoch 11/50

 - 4s - loss: 0.1195 - val_loss: 0.0276

Epoch 12/50

 - 4s - loss: 0.1589 - val_loss: 0.0270

Epoch 13/50

 - 4s - loss: 0.1086 - val_loss: 0.0222

Epoch 14/50

 - 4s - loss: 0.1796 - val_loss: 0.0169

Epoch 15/50

 - 4s - loss: 0.1670 - val_loss: 0.0181

Epoch 16/50

 - 4s - loss: 0.1320 - val_loss: 0.0275

Epoch 17/50

 - 4s - loss: 0.1405 - val_loss: 0.0181

Epoch 18/50

 - 4s - loss: 0.1383 - val_loss: 0.0173

Epoch 19/50

 - 4s - loss: 0.0879 - val_loss: 0.0200

Epoch 20/50

 - 4s - loss: 0.1325 - val_loss: 0.0235

Epoch 21/50

 - 4s - loss: 0.1493 - val_loss: 0.0198

Epoch 22/50

 - 4s - loss: 0.0994 - val_loss: 0.0187

Epoch 23/50

 - 4s - loss: 0.1277 - val_loss: 0.0182

Epoch 24/50

 - 4s - loss: 0.0869 - val_loss: 0.0188

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 42482	action = 0	current_phase = 1	next_phase = 0	reward = -0.615908	array([[-2.4223502, -2.9402719]], dtype=float32)

time = 42487	action = 0	current_phase = 1	next_phase = 0	reward = -0.456965	array([[-2.20518 , -3.238695]], dtype=float32)

time = 42492	action = 0	current_phase = 1	next_phase = 0	reward = -0.296584	array([[-2.2102585, -3.0557306]], dtype=float32)

time = 42497	action = 0	current_phase = 1	next_phase = 0	reward = -0.165784	array([[-2.3742425, -3.212986 ]], dtype=float32)

time = 42502	action = 0	current_phase = 1	next_phase = 0	reward = 0.170449	array([[-2.724286 , -3.7599976]], dtype=float32)

time = 42507	action = 1	current_phase = 1	next_phase = 0	reward = -1.781760	array([[-5.8504467, -3.5151927]], dtype=float32)

time = 42515	action = 0	current_phase = 0	next_phase = 1	reward = -0.528241	array([[-2.0688653, -3.2018566]], dtype=float32)

time = 42520	action = 0	current_phase = 0	next_phase = 1	reward = -0.373463	array([[-2.043207, -2.896901]], dtype=float32)

time = 42525	action = 0	current_phase = 0	next_phase = 1	reward = -0.207979	array([[-2.0471303, -2.1623883]], dtype=float32)

time = 42530	action = 0	current_phase = 0	next_phase = 1	reward = 0.052577	array([[-2.2506292, -2.6478226]], dtype=float32)

time = 42535	action = 1	current_phase = 0	next_phase = 1	reward = -1.087160	array([[-4.232137 , -2.8353615]], dtype=float32)

time = 42543	action = 0	current_phase = 1	next_phase = 0	reward = -0.596597	array([[-2.3950152, -2.9255238]], dtype=float32)

time = 42548	action = 0	current_phase = 1	next_phase = 0	reward = -0.439793	array([[-2.2355094, -3.0766041]], dtype=float32)

time = 42553	action = 0	current_phase = 1	next_phase = 0	reward = -0.278491	array([[-2.2134984, -3.0541651]], dtype=float32)

time = 42558	action = 0	current_phase = 1	next_phase = 0	reward = -0.160719	array([[-2.3611927, -3.208201 ]], dtype=float32)

time = 42563	action = 1	current_phase = 1	next_phase = 0	reward = -1.040126	array([[-2.74061  , -2.4745817]], dtype=float32)

time = 42571	action = 0	current_phase = 0	next_phase = 1	reward = -1.179418	array([[-2.768818 , -4.1623073]], dtype=float32)

time = 42576	action = 1	current_phase = 0	next_phase = 1	reward = -1.755302	array([[-3.586286 , -3.2586806]], dtype=float32)

time = 42584	action = 0	current_phase = 1	next_phase = 0	reward = -0.229375	array([[-1.9998978, -3.1746817]], dtype=float32)

time = 42589	action = 0	current_phase = 1	next_phase = 0	reward = -0.174950	array([[-1.6803402, -3.848101 ]], dtype=float32)

time = 42594	action = 0	current_phase = 1	next_phase = 0	reward = -0.136070	array([[-0.75382876, -3.2534842 ]], dtype=float32)

time = 42599	action = 1	current_phase = 1	next_phase = 0	reward = -2.014131	array([[-5.246043 , -3.7481587]], dtype=float32)

time = 42607	action = 0	current_phase = 0	next_phase = 1	reward = -0.478069	array([[-2.094825, -3.1649  ]], dtype=float32)

time = 42612	action = 1	current_phase = 0	next_phase = 1	reward = -1.453076	array([[-2.1509023, -2.0056877]], dtype=float32)

time = 42620	action = 0	current_phase = 1	next_phase = 0	reward = 0.378315	array([[-0.5112585, -4.059972 ]], dtype=float32)

time = 42625	action = 1	current_phase = 1	next_phase = 0	reward = -1.190188	array([[-3.2648458, -2.965956 ]], dtype=float32)

time = 42633	action = 0	current_phase = 0	next_phase = 1	reward = -0.592152	array([[-2.1614687, -2.8996496]], dtype=float32)

time = 42638	action = 0	current_phase = 0	next_phase = 1	reward = -0.449996	array([[-2.0935376, -2.8257487]], dtype=float32)

time = 42643	action = 1	current_phase = 0	next_phase = 1	reward = -1.405537	array([[-2.1347237, -2.0263672]], dtype=float32)

time = 42651	action = 0	current_phase = 1	next_phase = 0	reward = 0.323806	array([[-0.45542383, -4.0148005 ]], dtype=float32)

time = 42656	action = 1	current_phase = 1	next_phase = 0	reward = -1.603892	array([[-4.348718 , -3.1976972]], dtype=float32)

time = 42664	action = 0	current_phase = 0	next_phase = 1	reward = -0.547609	array([[-2.123575 , -2.9019263]], dtype=float32)

time = 42669	action = 0	current_phase = 0	next_phase = 1	reward = -0.394359	array([[-2.04416  , -2.8952944]], dtype=float32)

time = 42674	action = 0	current_phase = 0	next_phase = 1	reward = -0.229945	array([[-2.04706  , -2.1623573]], dtype=float32)

time = 42679	action = 0	current_phase = 0	next_phase = 1	reward = -0.186859	array([[-2.2059033, -3.0401678]], dtype=float32)

time = 42684	action = 1	current_phase = 0	next_phase = 1	reward = -0.493709	array([[-4.1379857, -2.2480836]], dtype=float32)

time = 42692	action = 0	current_phase = 1	next_phase = 0	reward = -0.615703	array([[-2.3939338, -2.9263585]], dtype=float32)

time = 42697	action = 0	current_phase = 1	next_phase = 0	reward = -0.466643	array([[-2.1679487, -3.2767887]], dtype=float32)

time = 42702	action = 0	current_phase = 1	next_phase = 0	reward = -0.310761	array([[-2.2110837, -3.054702 ]], dtype=float32)

time = 42707	action = 0	current_phase = 1	next_phase = 0	reward = -0.174315	array([[-2.3813808, -3.182475 ]], dtype=float32)

time = 42712	action = 0	current_phase = 1	next_phase = 0	reward = 0.187311	array([[-2.6630101, -3.8071392]], dtype=float32)

time = 42717	action = 1	current_phase = 1	next_phase = 0	reward = -1.785835	array([[-5.901232 , -3.5666697]], dtype=float32)

time = 42725	action = 0	current_phase = 0	next_phase = 1	reward = -0.535619	array([[-2.1374285, -3.1720276]], dtype=float32)

time = 42730	action = 0	current_phase = 0	next_phase = 1	reward = -0.389659	array([[-2.0433643, -2.8967276]], dtype=float32)

time = 42735	action = 0	current_phase = 0	next_phase = 1	reward = -0.227872	array([[-2.046784, -2.162443]], dtype=float32)

time = 42740	action = 0	current_phase = 0	next_phase = 1	reward = 0.371029	array([[-2.208042 , -2.3618393]], dtype=float32)

time = 42745	action = 1	current_phase = 0	next_phase = 1	reward = -1.352401	array([[-4.482203 , -3.1368384]], dtype=float32)

time = 42753	action = 0	current_phase = 1	next_phase = 0	reward = -0.583865	array([[-2.3945575, -2.9284945]], dtype=float32)

time = 42758	action = 0	current_phase = 1	next_phase = 0	reward = -0.436247	array([[-2.2140822, -3.0541186]], dtype=float32)

time = 42763	action = 0	current_phase = 1	next_phase = 0	reward = -0.277827	array([[-2.2101011, -3.0519779]], dtype=float32)

time = 42768	action = 0	current_phase = 1	next_phase = 0	reward = -0.159261	array([[-2.3364124, -3.1952052]], dtype=float32)

time = 42773	action = 0	current_phase = 1	next_phase = 0	reward = 0.127988	array([[-2.7571597, -3.6884916]], dtype=float32)

time = 42778	action = 1	current_phase = 1	next_phase = 0	reward = -1.896069	array([[-5.9238043, -3.560688 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 3s - loss: 0.1689 - val_loss: 0.0189

Epoch 2/50

 - 4s - loss: 0.1708 - val_loss: 0.0281

Epoch 3/50

 - 3s - loss: 0.1383 - val_loss: 0.0232

Epoch 4/50

 - 4s - loss: 0.1400 - val_loss: 0.0275

Epoch 5/50

 - 4s - loss: 0.0918 - val_loss: 0.0274

Epoch 6/50

 - 4s - loss: 0.0750 - val_loss: 0.0276

Epoch 7/50

 - 4s - loss: 0.0611 - val_loss: 0.0271

Epoch 8/50

 - 4s - loss: 0.0437 - val_loss: 0.0261

Epoch 9/50

 - 4s - loss: 0.0856 - val_loss: 0.0266

Epoch 10/50

 - 4s - loss: 0.0483 - val_loss: 0.0206

Epoch 11/50

 - 4s - loss: 0.0381 - val_loss: 0.0212

length of memory (state 0, action 0): 1016, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1024, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1007, before forget

length of memory (state 1, action 1): 1000, after forget

time = 42786	action = 0	current_phase = 0	next_phase = 1	reward = -0.499409	array([[-2.1771958, -3.1664732]], dtype=float32)

time = 42791	action = 0	current_phase = 0	next_phase = 1	reward = -0.348475	array([[-2.1022632, -2.8307917]], dtype=float32)

time = 42796	action = 0	current_phase = 0	next_phase = 1	reward = -0.199611	array([[-2.0506072, -2.2339942]], dtype=float32)

time = 42801	action = 0	current_phase = 0	next_phase = 1	reward = 0.292271	array([[-2.2914507, -2.4593813]], dtype=float32)

time = 42806	action = 1	current_phase = 0	next_phase = 1	reward = -1.665274	array([[-4.450264 , -3.2344642]], dtype=float32)

time = 42814	action = 0	current_phase = 1	next_phase = 0	reward = -0.572285	array([[-2.1077268, -3.1026437]], dtype=float32)

time = 42819	action = 0	current_phase = 1	next_phase = 0	reward = -0.416734	array([[-1.937973 , -3.2257571]], dtype=float32)

time = 42824	action = 0	current_phase = 1	next_phase = 0	reward = -0.263277	array([[-1.9423429, -3.223688 ]], dtype=float32)

time = 42829	action = 0	current_phase = 1	next_phase = 0	reward = -0.180199	array([[-1.9168588, -3.8599854]], dtype=float32)

time = 42834	action = 1	current_phase = 1	next_phase = 0	reward = -1.481615	array([[-2.6605377, -2.3542373]], dtype=float32)

time = 42842	action = 0	current_phase = 0	next_phase = 1	reward = -1.153803	array([[-2.3028789, -3.6623237]], dtype=float32)

time = 42847	action = 0	current_phase = 0	next_phase = 1	reward = -1.029874	array([[-2.3512845, -2.9032173]], dtype=float32)

time = 42852	action = 0	current_phase = 0	next_phase = 1	reward = -0.902704	array([[-2.3942697, -2.663997 ]], dtype=float32)

time = 42857	action = 0	current_phase = 0	next_phase = 1	reward = -0.781869	array([[-2.3118124, -3.068835 ]], dtype=float32)

time = 42862	action = 0	current_phase = 0	next_phase = 1	reward = -0.416045	array([[-2.5145936, -3.361186 ]], dtype=float32)

time = 42867	action = 1	current_phase = 0	next_phase = 1	reward = -1.719180	array([[-6.3519864, -3.566151 ]], dtype=float32)

time = 42875	action = 0	current_phase = 1	next_phase = 0	reward = -0.530450	array([[-2.0572052, -3.0116725]], dtype=float32)

time = 42880	action = 0	current_phase = 1	next_phase = 0	reward = -0.370456	array([[-1.9380231, -3.2257373]], dtype=float32)

time = 42885	action = 0	current_phase = 1	next_phase = 0	reward = -0.216107	array([[-1.9379674, -3.2256653]], dtype=float32)

time = 42890	action = 0	current_phase = 1	next_phase = 0	reward = 0.371390	array([[-1.9797772, -3.872024 ]], dtype=float32)

time = 42895	action = 1	current_phase = 1	next_phase = 0	reward = -1.306200	array([[-3.8315756, -3.2132308]], dtype=float32)

time = 42903	action = 0	current_phase = 0	next_phase = 1	reward = -0.599136	array([[-2.2682798, -3.592679 ]], dtype=float32)

time = 42908	action = 0	current_phase = 0	next_phase = 1	reward = -0.451724	array([[-2.0601356, -2.8859751]], dtype=float32)

time = 42913	action = 1	current_phase = 0	next_phase = 1	reward = -1.410357	array([[-2.1447148, -2.0978763]], dtype=float32)

time = 42921	action = 0	current_phase = 1	next_phase = 0	reward = 0.322589	array([[-0.20513308, -4.1166544 ]], dtype=float32)

time = 42926	action = 1	current_phase = 1	next_phase = 0	reward = -1.559934	array([[-4.039354 , -3.4202175]], dtype=float32)

time = 42934	action = 0	current_phase = 0	next_phase = 1	reward = -0.570646	array([[-2.0657098, -2.9110997]], dtype=float32)

time = 42939	action = 0	current_phase = 0	next_phase = 1	reward = -0.418726	array([[-2.038655 , -2.9171684]], dtype=float32)

time = 42944	action = 1	current_phase = 0	next_phase = 1	reward = -1.367296	array([[-2.1533844, -2.0853355]], dtype=float32)

time = 42952	action = 0	current_phase = 1	next_phase = 0	reward = 0.210463	array([[-0.55482984, -4.5784464 ]], dtype=float32)

time = 42957	action = 1	current_phase = 1	next_phase = 0	reward = -1.786408	array([[-4.3301463, -3.4953249]], dtype=float32)

time = 42965	action = 0	current_phase = 0	next_phase = 1	reward = -0.531735	array([[-2.1179724, -3.1538427]], dtype=float32)

time = 42970	action = 0	current_phase = 0	next_phase = 1	reward = -0.376493	array([[-2.0382555, -2.9177876]], dtype=float32)

time = 42975	action = 0	current_phase = 0	next_phase = 1	reward = -0.221545	array([[-2.0502973, -2.2336113]], dtype=float32)

time = 42980	action = 0	current_phase = 0	next_phase = 1	reward = 0.365668	array([[-2.158987 , -2.6992474]], dtype=float32)

time = 42985	action = 1	current_phase = 0	next_phase = 1	reward = -1.355655	array([[-4.516774 , -3.2952502]], dtype=float32)

time = 42993	action = 0	current_phase = 1	next_phase = 0	reward = -0.588718	array([[-2.298112 , -3.0203736]], dtype=float32)

time = 42998	action = 0	current_phase = 1	next_phase = 0	reward = -0.434832	array([[-2.1362033, -3.1165094]], dtype=float32)

time = 43003	action = 0	current_phase = 1	next_phase = 0	reward = -0.277194	array([[-2.1322806, -3.1052456]], dtype=float32)

time = 43008	action = 0	current_phase = 1	next_phase = 0	reward = -0.165079	array([[-2.2612267, -3.2705426]], dtype=float32)

time = 43013	action = 0	current_phase = 1	next_phase = 0	reward = 0.083799	array([[-2.703698 , -3.8076537]], dtype=float32)

time = 43018	action = 1	current_phase = 1	next_phase = 0	reward = -1.896954	array([[-5.9021983, -3.5991735]], dtype=float32)

time = 43026	action = 0	current_phase = 0	next_phase = 1	reward = -0.491182	array([[-2.127591, -3.216399]], dtype=float32)

time = 43031	action = 0	current_phase = 0	next_phase = 1	reward = -0.327603	array([[-2.103803 , -2.8315752]], dtype=float32)

time = 43036	action = 0	current_phase = 0	next_phase = 1	reward = -0.182236	array([[-2.0511847, -2.234312 ]], dtype=float32)

time = 43041	action = 0	current_phase = 0	next_phase = 1	reward = 0.280801	array([[-2.29995  , -2.3683004]], dtype=float32)

time = 43046	action = 1	current_phase = 0	next_phase = 1	reward = -1.667023	array([[-4.473298, -3.21553 ]], dtype=float32)

time = 43054	action = 0	current_phase = 1	next_phase = 0	reward = -0.559477	array([[-2.1251068, -3.1120868]], dtype=float32)

time = 43059	action = 0	current_phase = 1	next_phase = 0	reward = -0.397203	array([[-1.9422387, -3.2234275]], dtype=float32)

time = 43064	action = 0	current_phase = 1	next_phase = 0	reward = -0.245916	array([[-1.9381354, -3.2210193]], dtype=float32)

time = 43069	action = 0	current_phase = 1	next_phase = 0	reward = -0.179253	array([[-1.9279327, -3.8554342]], dtype=float32)

time = 43074	action = 1	current_phase = 1	next_phase = 0	reward = -0.479546	array([[-2.7184143, -2.5128832]], dtype=float32)

time = 43082	action = 0	current_phase = 0	next_phase = 1	reward = -0.616267	array([[-2.2800975, -3.6274004]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1133 - val_loss: 0.0975

Epoch 2/50

 - 4s - loss: 0.1346 - val_loss: 0.0974

Epoch 3/50

 - 4s - loss: 0.1369 - val_loss: 0.1016

Epoch 4/50

 - 4s - loss: 0.1436 - val_loss: 0.0987

Epoch 5/50

 - 4s - loss: 0.1053 - val_loss: 0.1000

Epoch 6/50

 - 4s - loss: 0.1367 - val_loss: 0.1018

Epoch 7/50

 - 4s - loss: 0.1329 - val_loss: 0.1065

Epoch 8/50

 - 4s - loss: 0.1160 - val_loss: 0.1026

Epoch 9/50

 - 4s - loss: 0.1077 - val_loss: 0.1002

Epoch 10/50

 - 4s - loss: 0.0942 - val_loss: 0.0971

Epoch 11/50

 - 4s - loss: 0.0994 - val_loss: 0.0965

Epoch 12/50

 - 4s - loss: 0.0965 - val_loss: 0.0979

Epoch 13/50

 - 4s - loss: 0.0864 - val_loss: 0.0961

Epoch 14/50

 - 4s - loss: 0.1010 - val_loss: 0.0983

Epoch 15/50

 - 4s - loss: 0.0812 - val_loss: 0.0995

Epoch 16/50

 - 4s - loss: 0.0829 - val_loss: 0.1024

Epoch 17/50

 - 4s - loss: 0.0730 - val_loss: 0.1008

Epoch 18/50

 - 4s - loss: 0.0869 - val_loss: 0.1028

Epoch 19/50

 - 4s - loss: 0.1306 - val_loss: 0.1070

Epoch 20/50

 - 4s - loss: 0.0839 - val_loss: 0.1057

Epoch 21/50

 - 4s - loss: 0.1083 - val_loss: 0.1096

Epoch 22/50

 - 4s - loss: 0.1071 - val_loss: 0.1030

Epoch 23/50

 - 4s - loss: 0.1062 - val_loss: 0.1029

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 43087	action = 0	current_phase = 0	next_phase = 1	reward = -0.461857	array([[-2.1859598, -2.8498874]], dtype=float32)

time = 43092	action = 0	current_phase = 0	next_phase = 1	reward = -0.301715	array([[-2.0958617, -2.2312822]], dtype=float32)

time = 43097	action = 0	current_phase = 0	next_phase = 1	reward = -0.168880	array([[-2.3736312, -3.0478206]], dtype=float32)

time = 43102	action = 0	current_phase = 0	next_phase = 1	reward = 0.152535	array([[-2.518429 , -4.0943074]], dtype=float32)

time = 43107	action = 1	current_phase = 0	next_phase = 1	reward = -1.786935	array([[-6.4105535, -3.5228028]], dtype=float32)

time = 43115	action = 0	current_phase = 1	next_phase = 0	reward = -0.540356	array([[-2.1321025, -3.010136 ]], dtype=float32)

time = 43120	action = 0	current_phase = 1	next_phase = 0	reward = -0.391867	array([[-1.8775221, -3.2390695]], dtype=float32)

time = 43125	action = 0	current_phase = 1	next_phase = 0	reward = -0.248155	array([[-1.8821168, -3.236783 ]], dtype=float32)

time = 43130	action = 0	current_phase = 1	next_phase = 0	reward = 0.085001	array([[-1.8954679, -3.8793807]], dtype=float32)

time = 43135	action = 1	current_phase = 1	next_phase = 0	reward = -1.011253	array([[-3.3056269, -2.8907595]], dtype=float32)

time = 43143	action = 0	current_phase = 0	next_phase = 1	reward = -0.582532	array([[-2.3779066, -3.5942464]], dtype=float32)

time = 43148	action = 0	current_phase = 0	next_phase = 1	reward = -0.423588	array([[-2.0867033, -2.915804 ]], dtype=float32)

time = 43153	action = 0	current_phase = 0	next_phase = 1	reward = -0.274442	array([[-2.0969918, -2.227427 ]], dtype=float32)

time = 43158	action = 0	current_phase = 0	next_phase = 1	reward = -0.161464	array([[-2.424333, -3.131965]], dtype=float32)

time = 43163	action = 0	current_phase = 0	next_phase = 1	reward = 0.060583	array([[-2.6032727, -3.7185497]], dtype=float32)

time = 43168	action = 1	current_phase = 0	next_phase = 1	reward = -1.903190	array([[-6.430451 , -3.5467618]], dtype=float32)

time = 43176	action = 0	current_phase = 1	next_phase = 0	reward = -0.505512	array([[-1.9107947, -3.2862766]], dtype=float32)

time = 43181	action = 0	current_phase = 1	next_phase = 0	reward = -0.357003	array([[-1.9070492, -3.224203 ]], dtype=float32)

time = 43186	action = 0	current_phase = 1	next_phase = 0	reward = -0.205867	array([[-1.8839005, -3.2540987]], dtype=float32)

time = 43191	action = 0	current_phase = 1	next_phase = 0	reward = 0.326868	array([[-2.1685688, -3.9683776]], dtype=float32)

time = 43196	action = 1	current_phase = 1	next_phase = 0	reward = -1.501384	array([[-5.6257873, -3.2497544]], dtype=float32)

time = 43204	action = 0	current_phase = 0	next_phase = 1	reward = -0.546456	array([[-2.1902318, -3.152004 ]], dtype=float32)

time = 43209	action = 0	current_phase = 0	next_phase = 1	reward = -0.398647	array([[-2.0864124, -2.9158714]], dtype=float32)

time = 43214	action = 0	current_phase = 0	next_phase = 1	reward = -0.243308	array([[-2.0953808, -2.229732 ]], dtype=float32)

time = 43219	action = 0	current_phase = 0	next_phase = 1	reward = -0.190363	array([[-2.20759  , -3.0895717]], dtype=float32)

time = 43224	action = 1	current_phase = 0	next_phase = 1	reward = -0.616591	array([[-4.2118273, -2.3314543]], dtype=float32)

time = 43232	action = 0	current_phase = 1	next_phase = 0	reward = -0.617750	array([[-2.2840865, -3.001747 ]], dtype=float32)

time = 43237	action = 0	current_phase = 1	next_phase = 0	reward = -0.463476	array([[-2.0398808, -3.285713 ]], dtype=float32)

time = 43242	action = 0	current_phase = 1	next_phase = 0	reward = -0.311000	array([[-2.1001186, -3.1212378]], dtype=float32)

time = 43247	action = 0	current_phase = 1	next_phase = 0	reward = -0.174635	array([[-2.2277772, -3.258516 ]], dtype=float32)

time = 43252	action = 0	current_phase = 1	next_phase = 0	reward = 0.246105	array([[-2.6072693, -3.9037702]], dtype=float32)

time = 43257	action = 1	current_phase = 1	next_phase = 0	reward = -1.782900	array([[-5.924709, -3.570512]], dtype=float32)

time = 43265	action = 0	current_phase = 0	next_phase = 1	reward = -0.529856	array([[-2.1715634, -3.167147 ]], dtype=float32)

time = 43270	action = 0	current_phase = 0	next_phase = 1	reward = -0.383718	array([[-2.0863647, -2.9159286]], dtype=float32)

time = 43275	action = 0	current_phase = 0	next_phase = 1	reward = -0.239677	array([[-2.094395 , -2.2291458]], dtype=float32)

time = 43280	action = 1	current_phase = 0	next_phase = 1	reward = -1.007308	array([[-2.2171142, -1.9989251]], dtype=float32)

time = 43288	action = 0	current_phase = 1	next_phase = 0	reward = -1.459504	array([[-1.8142521, -3.7526946]], dtype=float32)

time = 43293	action = 1	current_phase = 1	next_phase = 0	reward = -1.944465	array([[-4.5816383, -3.656377 ]], dtype=float32)

time = 43301	action = 0	current_phase = 0	next_phase = 1	reward = -0.333733	array([[-2.0883813, -3.2236862]], dtype=float32)

time = 43306	action = 0	current_phase = 0	next_phase = 1	reward = -0.187525	array([[-2.0987236, -2.2433496]], dtype=float32)

time = 43311	action = 1	current_phase = 0	next_phase = 1	reward = -1.331696	array([[-2.206449 , -1.5886173]], dtype=float32)

time = 43319	action = 0	current_phase = 1	next_phase = 0	reward = -1.607935	array([[-1.8402165, -3.9898746]], dtype=float32)

time = 43324	action = 0	current_phase = 1	next_phase = 0	reward = -1.650543	array([[10.062455 , -3.7319689]], dtype=float32)

time = 43329	action = 1	current_phase = 1	next_phase = 0	reward = -1.657707	array([[-5.199238 , -3.3708096]], dtype=float32)

time = 43337	action = 0	current_phase = 0	next_phase = 1	reward = -0.174824	array([[-2.057312, -2.899522]], dtype=float32)

time = 43342	action = 0	current_phase = 0	next_phase = 1	reward = 0.210618	array([[-2.3786244, -4.1948533]], dtype=float32)

time = 43347	action = 1	current_phase = 0	next_phase = 1	reward = -1.780511	array([[-5.156135, -3.491081]], dtype=float32)

time = 43355	action = 0	current_phase = 1	next_phase = 0	reward = -0.517475	array([[-2.0045373, -3.1378434]], dtype=float32)

time = 43360	action = 0	current_phase = 1	next_phase = 0	reward = -0.358616	array([[-1.8805401, -3.237489 ]], dtype=float32)

time = 43365	action = 0	current_phase = 1	next_phase = 0	reward = -0.210297	array([[-1.8811282, -3.2386851]], dtype=float32)

time = 43370	action = 0	current_phase = 1	next_phase = 0	reward = 0.336878	array([[-2.0253358, -3.904593 ]], dtype=float32)

time = 43375	action = 1	current_phase = 1	next_phase = 0	reward = -1.370372	array([[-3.8501475, -3.1563418]], dtype=float32)

time = 43383	action = 0	current_phase = 0	next_phase = 1	reward = -0.590245	array([[-2.3793013, -3.5974762]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.3247 - val_loss: 0.0478

Epoch 2/50

 - 4s - loss: 0.2206 - val_loss: 0.0522

Epoch 3/50

 - 4s - loss: 0.1611 - val_loss: 0.0657

Epoch 4/50

 - 4s - loss: 0.1633 - val_loss: 0.0650

Epoch 5/50

 - 4s - loss: 0.1762 - val_loss: 0.0695

Epoch 6/50

 - 4s - loss: 0.1688 - val_loss: 0.0993

Epoch 7/50

 - 4s - loss: 0.1806 - val_loss: 0.0754

Epoch 8/50

 - 4s - loss: 0.1079 - val_loss: 0.0974

Epoch 9/50

 - 4s - loss: 0.1560 - val_loss: 0.0765

Epoch 10/50

 - 4s - loss: 0.1050 - val_loss: 0.1384

Epoch 11/50

 - 4s - loss: 0.1040 - val_loss: 0.1040

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 43388	action = 0	current_phase = 0	next_phase = 1	reward = -0.439779	array([[-2.0491025, -2.8660378]], dtype=float32)

time = 43393	action = 0	current_phase = 0	next_phase = 1	reward = -0.287898	array([[-2.08112  , -2.1057866]], dtype=float32)

time = 43398	action = 0	current_phase = 0	next_phase = 1	reward = -0.164281	array([[-2.3636117, -2.9829931]], dtype=float32)

time = 43403	action = 0	current_phase = 0	next_phase = 1	reward = 0.029469	array([[-2.6670501, -3.7789786]], dtype=float32)

time = 43408	action = 1	current_phase = 0	next_phase = 1	reward = -1.892583	array([[-6.4594803, -3.5276606]], dtype=float32)

time = 43416	action = 0	current_phase = 1	next_phase = 0	reward = -0.482322	array([[-2.0313652, -3.2481887]], dtype=float32)

time = 43421	action = 0	current_phase = 1	next_phase = 0	reward = -0.331164	array([[-1.8407907, -3.2757106]], dtype=float32)

time = 43426	action = 0	current_phase = 1	next_phase = 0	reward = -0.190569	array([[-2.1372488, -3.3154175]], dtype=float32)

time = 43431	action = 0	current_phase = 1	next_phase = 0	reward = 0.295080	array([[-2.21916  , -3.9935176]], dtype=float32)

time = 43436	action = 1	current_phase = 1	next_phase = 0	reward = -1.559611	array([[-5.674404 , -3.2971675]], dtype=float32)

time = 43444	action = 0	current_phase = 0	next_phase = 1	reward = -0.563579	array([[-2.1442895, -3.0955064]], dtype=float32)

time = 43449	action = 0	current_phase = 0	next_phase = 1	reward = -0.397108	array([[-2.0776253, -2.8433902]], dtype=float32)

time = 43454	action = 0	current_phase = 0	next_phase = 1	reward = -0.239761	array([[-2.0782266, -2.1096   ]], dtype=float32)

time = 43459	action = 0	current_phase = 0	next_phase = 1	reward = -0.179200	array([[-2.1792667, -2.928156 ]], dtype=float32)

time = 43464	action = 1	current_phase = 0	next_phase = 1	reward = -0.550049	array([[-4.2364473, -2.277316 ]], dtype=float32)

time = 43472	action = 0	current_phase = 1	next_phase = 0	reward = -0.620866	array([[-2.2654123, -3.044678 ]], dtype=float32)

time = 43477	action = 0	current_phase = 1	next_phase = 0	reward = -0.469711	array([[-1.8569001, -3.3210676]], dtype=float32)

time = 43482	action = 0	current_phase = 1	next_phase = 0	reward = -0.318022	array([[-2.0928245, -3.1609445]], dtype=float32)

time = 43487	action = 0	current_phase = 1	next_phase = 0	reward = -0.178487	array([[-2.2080941, -3.3002079]], dtype=float32)

time = 43492	action = 0	current_phase = 1	next_phase = 0	reward = 0.243992	array([[-2.570425 , -3.9386814]], dtype=float32)

time = 43497	action = 1	current_phase = 1	next_phase = 0	reward = -1.780256	array([[-5.921834, -3.548597]], dtype=float32)

time = 43505	action = 0	current_phase = 0	next_phase = 1	reward = -0.524537	array([[-2.1411428, -3.130513 ]], dtype=float32)

time = 43510	action = 0	current_phase = 0	next_phase = 1	reward = -0.365064	array([[-2.048993, -2.866091]], dtype=float32)

time = 43515	action = 0	current_phase = 0	next_phase = 1	reward = -0.207674	array([[-2.0783083, -2.110272 ]], dtype=float32)

time = 43520	action = 1	current_phase = 0	next_phase = 1	reward = -1.026459	array([[-2.290752 , -2.1039143]], dtype=float32)

time = 43528	action = 1	current_phase = 1	next_phase = 0	reward = -1.893443	array([[-4.3915744, -3.6078057]], dtype=float32)

time = 43536	action = 0	current_phase = 0	next_phase = 1	reward = -0.488298	array([[-2.1130495, -3.1413882]], dtype=float32)

time = 43541	action = 0	current_phase = 0	next_phase = 1	reward = -0.347018	array([[-2.1095414, -2.8048754]], dtype=float32)

time = 43546	action = 0	current_phase = 0	next_phase = 1	reward = -0.205850	array([[-2.0784228, -2.1072788]], dtype=float32)

time = 43551	action = 1	current_phase = 0	next_phase = 1	reward = -1.331585	array([[-2.3319235, -2.2300024]], dtype=float32)

time = 43559	action = 1	current_phase = 1	next_phase = 0	reward = -2.007535	array([[-4.33235 , -3.774137]], dtype=float32)

time = 43567	action = 0	current_phase = 0	next_phase = 1	reward = -0.461597	array([[-2.1434922, -3.1336844]], dtype=float32)

time = 43572	action = 1	current_phase = 0	next_phase = 1	reward = -1.418597	array([[-2.1894715, -1.9807185]], dtype=float32)

time = 43580	action = 0	current_phase = 1	next_phase = 0	reward = 0.356796	array([[-1.213594, -4.088165]], dtype=float32)

time = 43585	action = 0	current_phase = 1	next_phase = 0	reward = -0.844223	array([[-2.993933 , -3.2768643]], dtype=float32)

time = 43590	action = 0	current_phase = 1	next_phase = 0	reward = -1.728046	array([[ 8.427269 , -3.7963877]], dtype=float32)

time = 43595	action = 1	current_phase = 1	next_phase = 0	reward = -1.842955	array([[-5.1562333, -3.5845613]], dtype=float32)

time = 43603	action = 0	current_phase = 0	next_phase = 1	reward = -0.270383	array([[-2.0700088, -2.8310258]], dtype=float32)

time = 43608	action = 0	current_phase = 0	next_phase = 1	reward = -0.160491	array([[-2.3608265, -2.9801733]], dtype=float32)

time = 43613	action = 0	current_phase = 0	next_phase = 1	reward = 0.028088	array([[ 2.4191294, -3.3988328]], dtype=float32)

time = 43618	action = 1	current_phase = 0	next_phase = 1	reward = -1.892828	array([[-5.666923 , -3.4125729]], dtype=float32)

time = 43626	action = 0	current_phase = 1	next_phase = 0	reward = -0.485921	array([[-1.7058069, -3.2286067]], dtype=float32)

time = 43631	action = 0	current_phase = 1	next_phase = 0	reward = -0.333503	array([[-2.0924911, -3.1611538]], dtype=float32)

time = 43636	action = 0	current_phase = 1	next_phase = 0	reward = -0.195463	array([[-2.0788445, -3.2307124]], dtype=float32)

time = 43641	action = 0	current_phase = 1	next_phase = 0	reward = 0.306113	array([[-2.150008 , -3.9876866]], dtype=float32)

time = 43646	action = 1	current_phase = 1	next_phase = 0	reward = -1.560896	array([[-5.6398473, -3.2794547]], dtype=float32)

time = 43654	action = 0	current_phase = 0	next_phase = 1	reward = -0.558999	array([[-2.145658 , -3.1066787]], dtype=float32)

time = 43659	action = 0	current_phase = 0	next_phase = 1	reward = -0.405773	array([[-2.053779 , -2.8610945]], dtype=float32)

time = 43664	action = 0	current_phase = 0	next_phase = 1	reward = -0.260086	array([[-2.0781636, -2.1093447]], dtype=float32)

time = 43669	action = 0	current_phase = 0	next_phase = 1	reward = -0.185854	array([[-2.1686096, -2.8940682]], dtype=float32)

time = 43674	action = 1	current_phase = 0	next_phase = 1	reward = -0.475947	array([[-4.193428 , -2.3938067]], dtype=float32)

time = 43682	action = 0	current_phase = 1	next_phase = 0	reward = -0.622665	array([[-2.2681599, -3.0404425]], dtype=float32)

time = 43687	action = 0	current_phase = 1	next_phase = 0	reward = -0.472612	array([[-1.8569546, -3.3184743]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.3093 - val_loss: 0.0460

Epoch 2/50

 - 4s - loss: 0.2201 - val_loss: 0.0319

Epoch 3/50

 - 4s - loss: 0.3544 - val_loss: 0.0337

Epoch 4/50

 - 4s - loss: 0.2600 - val_loss: 0.0361

Epoch 5/50

 - 4s - loss: 0.1878 - val_loss: 0.0414

Epoch 6/50

 - 4s - loss: 0.1275 - val_loss: 0.0358

Epoch 7/50

 - 4s - loss: 0.1641 - val_loss: 0.0380

Epoch 8/50

 - 4s - loss: 0.1765 - val_loss: 0.0367

Epoch 9/50

 - 4s - loss: 0.1545 - val_loss: 0.0351

Epoch 10/50

 - 4s - loss: 0.1287 - val_loss: 0.0377

Epoch 11/50

 - 4s - loss: 0.1154 - val_loss: 0.0732

Epoch 12/50

 - 4s - loss: 0.1570 - val_loss: 0.0554

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1007, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1018, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 43692	action = 0	current_phase = 1	next_phase = 0	reward = -0.317578	array([[-2.1068084, -3.1552093]], dtype=float32)

time = 43697	action = 0	current_phase = 1	next_phase = 0	reward = -0.180124	array([[-2.0470557, -3.2611933]], dtype=float32)

time = 43702	action = 0	current_phase = 1	next_phase = 0	reward = 0.214475	array([[-2.5616088, -3.8764625]], dtype=float32)

time = 43707	action = 1	current_phase = 1	next_phase = 0	reward = -1.781899	array([[-5.9234967, -3.5539842]], dtype=float32)

time = 43715	action = 0	current_phase = 0	next_phase = 1	reward = -0.522260	array([[-2.1828675, -3.150873 ]], dtype=float32)

time = 43720	action = 0	current_phase = 0	next_phase = 1	reward = -0.360225	array([[-2.0537188, -2.8573513]], dtype=float32)

time = 43725	action = 0	current_phase = 0	next_phase = 1	reward = -0.207671	array([[-2.0738275, -2.146859 ]], dtype=float32)

time = 43730	action = 1	current_phase = 0	next_phase = 1	reward = -1.098570	array([[-2.2897189, -2.1962302]], dtype=float32)

time = 43738	action = 1	current_phase = 1	next_phase = 0	reward = -1.896332	array([[-3.953326, -3.508618]], dtype=float32)

time = 43746	action = 0	current_phase = 0	next_phase = 1	reward = -0.486929	array([[-2.1428838, -3.131954 ]], dtype=float32)

time = 43751	action = 0	current_phase = 0	next_phase = 1	reward = -0.328367	array([[-2.1196928, -2.8032765]], dtype=float32)

time = 43756	action = 0	current_phase = 0	next_phase = 1	reward = -0.180165	array([[-2.0811749, -2.1498888]], dtype=float32)

time = 43761	action = 0	current_phase = 0	next_phase = 1	reward = 0.280899	array([[-2.3235586, -2.4924343]], dtype=float32)

time = 43766	action = 1	current_phase = 0	next_phase = 1	reward = -1.665413	array([[-4.5797625, -3.2611587]], dtype=float32)

time = 43774	action = 0	current_phase = 1	next_phase = 0	reward = -0.565966	array([[-2.17866  , -3.1160834]], dtype=float32)

time = 43779	action = 0	current_phase = 1	next_phase = 0	reward = -0.411334	array([[-1.9328067, -3.245726 ]], dtype=float32)

time = 43784	action = 0	current_phase = 1	next_phase = 0	reward = -0.255649	array([[-1.9273273, -3.2518144]], dtype=float32)

time = 43789	action = 0	current_phase = 1	next_phase = 0	reward = -0.173029	array([[-1.8922442, -3.8467963]], dtype=float32)

time = 43794	action = 1	current_phase = 1	next_phase = 0	reward = -0.436173	array([[-2.5622861, -2.244016 ]], dtype=float32)

time = 43802	action = 0	current_phase = 0	next_phase = 1	reward = -0.620296	array([[-2.3094573, -3.5548325]], dtype=float32)

time = 43807	action = 0	current_phase = 0	next_phase = 1	reward = -0.464823	array([[-2.1263647, -2.8046253]], dtype=float32)

time = 43812	action = 1	current_phase = 0	next_phase = 1	reward = -1.433690	array([[-2.1554782, -2.0568166]], dtype=float32)

time = 43820	action = 0	current_phase = 1	next_phase = 0	reward = 0.355206	array([[-1.4048718, -4.078742 ]], dtype=float32)

time = 43825	action = 1	current_phase = 1	next_phase = 0	reward = -1.365836	array([[-3.943464 , -3.0594738]], dtype=float32)

time = 43833	action = 0	current_phase = 0	next_phase = 1	reward = -0.594043	array([[-2.160539, -2.889322]], dtype=float32)

time = 43838	action = 0	current_phase = 0	next_phase = 1	reward = -0.441068	array([[-2.096182 , -2.8210707]], dtype=float32)

time = 43843	action = 0	current_phase = 0	next_phase = 1	reward = -0.303470	array([[-2.0744824, -2.1466491]], dtype=float32)

time = 43848	action = 0	current_phase = 0	next_phase = 1	reward = -0.179987	array([[-2.3045845, -3.0277035]], dtype=float32)

time = 43853	action = 0	current_phase = 0	next_phase = 1	reward = 0.074240	array([[-2.625516 , -3.1973486]], dtype=float32)

time = 43858	action = 1	current_phase = 0	next_phase = 1	reward = -1.902496	array([[-6.4849195, -3.5379224]], dtype=float32)

time = 43866	action = 0	current_phase = 1	next_phase = 0	reward = -0.501389	array([[-2.1624022, -3.142594 ]], dtype=float32)

time = 43871	action = 0	current_phase = 1	next_phase = 0	reward = -0.348539	array([[-1.9280598, -3.2469609]], dtype=float32)

time = 43876	action = 0	current_phase = 1	next_phase = 0	reward = -0.203391	array([[-1.9848306, -3.2486372]], dtype=float32)

time = 43881	action = 0	current_phase = 1	next_phase = 0	reward = 0.306883	array([[-2.2026134, -3.9590125]], dtype=float32)

time = 43886	action = 1	current_phase = 1	next_phase = 0	reward = -1.502201	array([[-5.653668, -3.217111]], dtype=float32)

time = 43894	action = 0	current_phase = 0	next_phase = 1	reward = -0.555985	array([[-2.1830714, -3.1428099]], dtype=float32)

time = 43899	action = 0	current_phase = 0	next_phase = 1	reward = -0.402974	array([[-2.044428 , -2.8666062]], dtype=float32)

time = 43904	action = 0	current_phase = 0	next_phase = 1	reward = -0.241556	array([[-2.0744777, -2.1502616]], dtype=float32)

time = 43909	action = 0	current_phase = 0	next_phase = 1	reward = -0.174301	array([[-2.1263778, -2.9586015]], dtype=float32)

time = 43914	action = 1	current_phase = 0	next_phase = 1	reward = -0.579034	array([[-4.3005986, -2.34194  ]], dtype=float32)

time = 43922	action = 0	current_phase = 1	next_phase = 0	reward = -0.610510	array([[-2.3656592, -2.9846375]], dtype=float32)

time = 43927	action = 0	current_phase = 1	next_phase = 0	reward = -0.448574	array([[-2.011368 , -3.2820156]], dtype=float32)

time = 43932	action = 0	current_phase = 1	next_phase = 0	reward = -0.295342	array([[-2.1815073, -3.1035333]], dtype=float32)

time = 43937	action = 0	current_phase = 1	next_phase = 0	reward = -0.166947	array([[-2.2686937, -3.235224 ]], dtype=float32)

time = 43942	action = 0	current_phase = 1	next_phase = 0	reward = 0.166856	array([[-2.758434 , -3.7746341]], dtype=float32)

time = 43947	action = 1	current_phase = 1	next_phase = 0	reward = -1.788433	array([[-5.9606776, -3.553587 ]], dtype=float32)

time = 43955	action = 0	current_phase = 0	next_phase = 1	reward = -0.532824	array([[-2.1643145, -3.1066008]], dtype=float32)

time = 43960	action = 0	current_phase = 0	next_phase = 1	reward = -0.378173	array([[-2.041846 , -2.8689835]], dtype=float32)

time = 43965	action = 0	current_phase = 0	next_phase = 1	reward = -0.226192	array([[-2.0738487, -2.1469047]], dtype=float32)

time = 43970	action = 1	current_phase = 0	next_phase = 1	reward = -0.939969	array([[-2.2148814, -1.8728638]], dtype=float32)

time = 43978	action = 0	current_phase = 1	next_phase = 0	reward = -1.456092	array([[-2.9915175, -3.624009 ]], dtype=float32)

time = 43983	action = 1	current_phase = 1	next_phase = 0	reward = -1.952389	array([[-4.509079 , -3.6074235]], dtype=float32)

time = 43991	action = 0	current_phase = 0	next_phase = 1	reward = -0.337483	array([[-2.1162424, -3.1406615]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1472 - val_loss: 0.0285

Epoch 2/50

 - 4s - loss: 0.0914 - val_loss: 0.0284

Epoch 3/50

 - 4s - loss: 0.1452 - val_loss: 0.0283

Epoch 4/50

 - 4s - loss: 0.0924 - val_loss: 0.0263

Epoch 5/50

 - 4s - loss: 0.0877 - val_loss: 0.0312

Epoch 6/50

 - 4s - loss: 0.0660 - val_loss: 0.0307

Epoch 7/50

 - 4s - loss: 0.1054 - val_loss: 0.0287

Epoch 8/50

 - 4s - loss: 0.0744 - val_loss: 0.0302

Epoch 9/50

 - 4s - loss: 0.0579 - val_loss: 0.0288

Epoch 10/50

 - 4s - loss: 0.1052 - val_loss: 0.0285

Epoch 11/50

 - 4s - loss: 0.0770 - val_loss: 0.0281

Epoch 12/50

 - 4s - loss: 0.0760 - val_loss: 0.0301

Epoch 13/50

 - 4s - loss: 0.0714 - val_loss: 0.0338

Epoch 14/50

 - 4s - loss: 0.0692 - val_loss: 0.0319

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1018, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1007, before forget

length of memory (state 1, action 1): 1000, after forget

time = 43996	action = 0	current_phase = 0	next_phase = 1	reward = -0.187137	array([[-1.9653746, -2.0452251]], dtype=float32)

time = 44001	action = 0	current_phase = 0	next_phase = 1	reward = 0.301936	array([[ 2.0530756, -2.122479 ]], dtype=float32)

time = 44006	action = 1	current_phase = 0	next_phase = 1	reward = -1.554893	array([[-4.6922946, -3.303933 ]], dtype=float32)

time = 44014	action = 0	current_phase = 1	next_phase = 0	reward = -0.560469	array([[-2.1971722, -3.1773334]], dtype=float32)

time = 44019	action = 0	current_phase = 1	next_phase = 0	reward = -0.410198	array([[-2.1319914, -3.1413302]], dtype=float32)

time = 44024	action = 0	current_phase = 1	next_phase = 0	reward = -0.259057	array([[-1.9834336, -3.2285786]], dtype=float32)

time = 44029	action = 0	current_phase = 1	next_phase = 0	reward = -0.178648	array([[-2.1218667, -3.8075948]], dtype=float32)

time = 44034	action = 1	current_phase = 1	next_phase = 0	reward = -0.595285	array([[-2.5490146, -2.321443 ]], dtype=float32)

time = 44042	action = 0	current_phase = 0	next_phase = 1	reward = -0.627550	array([[-2.3016508, -3.5251074]], dtype=float32)

time = 44047	action = 0	current_phase = 0	next_phase = 1	reward = -0.471648	array([[-2.1285439, -2.770117 ]], dtype=float32)

time = 44052	action = 0	current_phase = 0	next_phase = 1	reward = -0.314133	array([[-1.9670671, -2.0429661]], dtype=float32)

time = 44057	action = 0	current_phase = 0	next_phase = 1	reward = -0.178544	array([[-2.1966777, -2.7924545]], dtype=float32)

time = 44062	action = 0	current_phase = 0	next_phase = 1	reward = 0.192635	array([[-2.3754497, -3.3800778]], dtype=float32)

time = 44067	action = 1	current_phase = 0	next_phase = 1	reward = -1.778884	array([[-6.4494114, -3.5131474]], dtype=float32)

time = 44075	action = 0	current_phase = 1	next_phase = 0	reward = -0.514473	array([[-2.1819143, -3.0800037]], dtype=float32)

time = 44080	action = 0	current_phase = 1	next_phase = 0	reward = -0.363319	array([[-1.9586831, -3.2432141]], dtype=float32)

time = 44085	action = 0	current_phase = 1	next_phase = 0	reward = -0.204247	array([[-1.9586483, -3.2434163]], dtype=float32)

time = 44090	action = 0	current_phase = 1	next_phase = 0	reward = 0.350596	array([[-2.1423216, -3.8805046]], dtype=float32)

time = 44095	action = 1	current_phase = 1	next_phase = 0	reward = -1.368675	array([[-3.6539416, -3.1396956]], dtype=float32)

time = 44103	action = 0	current_phase = 0	next_phase = 1	reward = -0.588596	array([[-2.2828958, -3.5088568]], dtype=float32)

time = 44108	action = 0	current_phase = 0	next_phase = 1	reward = -0.438635	array([[-2.0425012, -2.830017 ]], dtype=float32)

time = 44113	action = 0	current_phase = 0	next_phase = 1	reward = -0.272966	array([[-1.9643133, -2.0367036]], dtype=float32)

time = 44118	action = 0	current_phase = 0	next_phase = 1	reward = -0.162054	array([[-2.2861543, -2.976346 ]], dtype=float32)

time = 44123	action = 0	current_phase = 0	next_phase = 1	reward = 0.013412	array([[-2.7211118, -3.903222 ]], dtype=float32)

time = 44128	action = 1	current_phase = 0	next_phase = 1	reward = -1.897254	array([[-6.4848275, -3.5519295]], dtype=float32)

time = 44136	action = 0	current_phase = 1	next_phase = 0	reward = -0.494611	array([[-2.1651893, -3.2364106]], dtype=float32)

time = 44141	action = 0	current_phase = 1	next_phase = 0	reward = -0.342293	array([[-1.9636563, -3.2254057]], dtype=float32)

time = 44146	action = 0	current_phase = 1	next_phase = 0	reward = -0.199694	array([[-1.9721937, -3.2701087]], dtype=float32)

time = 44151	action = 0	current_phase = 1	next_phase = 0	reward = 0.330390	array([[-2.2350125, -3.9113617]], dtype=float32)

time = 44156	action = 1	current_phase = 1	next_phase = 0	reward = -1.501219	array([[-5.683935, -3.396181]], dtype=float32)

time = 44164	action = 0	current_phase = 0	next_phase = 1	reward = -0.560262	array([[-2.1428912, -3.0068798]], dtype=float32)

time = 44169	action = 0	current_phase = 0	next_phase = 1	reward = -0.409852	array([[-2.0486972, -2.8245025]], dtype=float32)

time = 44174	action = 0	current_phase = 0	next_phase = 1	reward = -0.254591	array([[-1.9634581, -2.0379994]], dtype=float32)

time = 44179	action = 0	current_phase = 0	next_phase = 1	reward = -0.171227	array([[-2.1582668, -2.8266985]], dtype=float32)

time = 44184	action = 1	current_phase = 0	next_phase = 1	reward = -0.475450	array([[-4.227946, -2.363278]], dtype=float32)

time = 44192	action = 0	current_phase = 1	next_phase = 0	reward = -0.619391	array([[-2.317483 , -2.9988217]], dtype=float32)

time = 44197	action = 0	current_phase = 1	next_phase = 0	reward = -0.457411	array([[-2.144146 , -3.2755904]], dtype=float32)

time = 44202	action = 0	current_phase = 1	next_phase = 0	reward = -0.298499	array([[-2.0647588, -3.1826034]], dtype=float32)

time = 44207	action = 0	current_phase = 1	next_phase = 0	reward = -0.168281	array([[-2.2013607, -3.2625518]], dtype=float32)

time = 44212	action = 0	current_phase = 1	next_phase = 0	reward = 0.253421	array([[-2.654224, -3.84729 ]], dtype=float32)

time = 44217	action = 1	current_phase = 1	next_phase = 0	reward = -1.674706	array([[-5.8372827, -3.5209818]], dtype=float32)

time = 44225	action = 0	current_phase = 0	next_phase = 1	reward = -0.524435	array([[-2.159122, -3.119107]], dtype=float32)

time = 44230	action = 0	current_phase = 0	next_phase = 1	reward = -0.372362	array([[-2.0424678, -2.8300135]], dtype=float32)

time = 44235	action = 0	current_phase = 0	next_phase = 1	reward = -0.217225	array([[-1.963363 , -2.0376225]], dtype=float32)

time = 44240	action = 1	current_phase = 0	next_phase = 1	reward = -1.059247	array([[-2.1135821, -1.3009102]], dtype=float32)

time = 44248	action = 0	current_phase = 1	next_phase = 0	reward = -1.465647	array([[ 5.220205 , -3.8177834]], dtype=float32)

time = 44253	action = 1	current_phase = 1	next_phase = 0	reward = -1.962261	array([[-4.419314 , -3.6223707]], dtype=float32)

time = 44261	action = 0	current_phase = 0	next_phase = 1	reward = -0.336062	array([[-2.1308677, -3.1109624]], dtype=float32)

time = 44266	action = 0	current_phase = 0	next_phase = 1	reward = -0.182538	array([[-1.9638716, -2.0392554]], dtype=float32)

time = 44271	action = 1	current_phase = 0	next_phase = 1	reward = -1.238952	array([[-2.2132983, -2.021142 ]], dtype=float32)

time = 44279	action = 0	current_phase = 1	next_phase = 0	reward = -1.598331	array([[ 2.1879659, -4.427198 ]], dtype=float32)

time = 44284	action = 0	current_phase = 1	next_phase = 0	reward = -1.633171	array([[ 9.25986  , -3.6548662]], dtype=float32)

time = 44289	action = 1	current_phase = 1	next_phase = 0	reward = -1.628959	array([[-5.1444116, -3.3652334]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1989 - val_loss: 0.0332

Epoch 2/50

 - 4s - loss: 0.1499 - val_loss: 0.0397

Epoch 3/50

 - 4s - loss: 0.1446 - val_loss: 0.0358

Epoch 4/50

 - 4s - loss: 0.0959 - val_loss: 0.0329

Epoch 5/50

 - 4s - loss: 0.0941 - val_loss: 0.0408

Epoch 6/50

 - 4s - loss: 0.1234 - val_loss: 0.0439

Epoch 7/50

 - 4s - loss: 0.0881 - val_loss: 0.0445

Epoch 8/50

 - 4s - loss: 0.0861 - val_loss: 0.0476

Epoch 9/50

 - 4s - loss: 0.0962 - val_loss: 0.0478

Epoch 10/50

 - 4s - loss: 0.1098 - val_loss: 0.0571

Epoch 11/50

 - 4s - loss: 0.0909 - val_loss: 0.0396

Epoch 12/50

 - 4s - loss: 0.1114 - val_loss: 0.0414

Epoch 13/50

 - 4s - loss: 0.1061 - val_loss: 0.0527

Epoch 14/50

 - 4s - loss: 0.0996 - val_loss: 0.0480

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 44297	action = 0	current_phase = 0	next_phase = 1	reward = -0.168819	array([[-2.156998 , -2.8743885]], dtype=float32)

time = 44302	action = 0	current_phase = 0	next_phase = 1	reward = 0.169513	array([[ 0.36958268, -3.6805468 ]], dtype=float32)

time = 44307	action = 1	current_phase = 0	next_phase = 1	reward = -1.785238	array([[-5.327399 , -3.5763848]], dtype=float32)

time = 44315	action = 0	current_phase = 1	next_phase = 0	reward = -0.534398	array([[-2.1306922, -3.1054487]], dtype=float32)

time = 44320	action = 0	current_phase = 1	next_phase = 0	reward = -0.371333	array([[-1.9959676, -3.1919131]], dtype=float32)

time = 44325	action = 0	current_phase = 1	next_phase = 0	reward = -0.224961	array([[-1.9284198, -3.231122 ]], dtype=float32)

time = 44330	action = 0	current_phase = 1	next_phase = 0	reward = 0.079358	array([[-2.0374353, -3.7917418]], dtype=float32)

time = 44335	action = 1	current_phase = 1	next_phase = 0	reward = -0.970838	array([[-3.3784485, -2.7657943]], dtype=float32)

time = 44343	action = 0	current_phase = 0	next_phase = 1	reward = -0.584155	array([[-2.2877655, -3.459081 ]], dtype=float32)

time = 44348	action = 0	current_phase = 0	next_phase = 1	reward = -0.436727	array([[-2.0574603, -2.8151183]], dtype=float32)

time = 44353	action = 1	current_phase = 0	next_phase = 1	reward = -1.382870	array([[-2.0149004, -1.8865212]], dtype=float32)

time = 44361	action = 0	current_phase = 1	next_phase = 0	reward = 0.304156	array([[-1.020543 , -4.0702586]], dtype=float32)

time = 44366	action = 1	current_phase = 1	next_phase = 0	reward = -1.608013	array([[-4.301109, -3.511046]], dtype=float32)

time = 44374	action = 0	current_phase = 0	next_phase = 1	reward = -0.555749	array([[-2.1419492, -2.9258933]], dtype=float32)

time = 44379	action = 0	current_phase = 0	next_phase = 1	reward = -0.403991	array([[-2.0583248, -2.8139052]], dtype=float32)

time = 44384	action = 1	current_phase = 0	next_phase = 1	reward = -1.349363	array([[-1.9652297, -1.9450792]], dtype=float32)

time = 44392	action = 0	current_phase = 1	next_phase = 0	reward = 0.227293	array([[-1.2874671, -4.209531 ]], dtype=float32)

time = 44397	action = 1	current_phase = 1	next_phase = 0	reward = -1.786081	array([[-4.3590875, -3.3833947]], dtype=float32)

time = 44405	action = 0	current_phase = 0	next_phase = 1	reward = -0.534799	array([[-2.1651998, -3.0944724]], dtype=float32)

time = 44410	action = 0	current_phase = 0	next_phase = 1	reward = -0.386134	array([[-2.0573778, -2.8151107]], dtype=float32)

time = 44415	action = 1	current_phase = 0	next_phase = 1	reward = -1.324514	array([[-1.9644676, -1.9416046]], dtype=float32)

time = 44423	action = 0	current_phase = 1	next_phase = 0	reward = -0.046456	array([[-0.92830884, -3.2949924 ]], dtype=float32)

time = 44428	action = 0	current_phase = 1	next_phase = 0	reward = -1.466388	array([[ 1.8623518, -3.5687766]], dtype=float32)

time = 44433	action = 1	current_phase = 1	next_phase = 0	reward = -1.954205	array([[-4.406156 , -3.6411953]], dtype=float32)

time = 44441	action = 0	current_phase = 0	next_phase = 1	reward = -0.339597	array([[-2.0248454, -3.2023993]], dtype=float32)

time = 44446	action = 0	current_phase = 0	next_phase = 1	reward = -0.193248	array([[-2.0454793, -2.2799287]], dtype=float32)

time = 44451	action = 1	current_phase = 0	next_phase = 1	reward = -1.170498	array([[-2.1830792 , -0.96759593]], dtype=float32)

time = 44459	action = 0	current_phase = 1	next_phase = 0	reward = -1.594990	array([[-3.101176 , -3.8464708]], dtype=float32)

time = 44464	action = 0	current_phase = 1	next_phase = 0	reward = -1.637190	array([[10.756384 , -3.5611024]], dtype=float32)

time = 44469	action = 1	current_phase = 1	next_phase = 0	reward = -1.659301	array([[-5.142116 , -3.3800712]], dtype=float32)

time = 44477	action = 0	current_phase = 0	next_phase = 1	reward = -0.171200	array([[-2.1053998, -2.971527 ]], dtype=float32)

time = 44482	action = 0	current_phase = 0	next_phase = 1	reward = 0.190741	array([[-1.87368  , -3.4176443]], dtype=float32)

time = 44487	action = 1	current_phase = 0	next_phase = 1	reward = -1.727881	array([[-5.3136086, -3.6423764]], dtype=float32)

time = 44495	action = 0	current_phase = 1	next_phase = 0	reward = -0.533144	array([[-2.13464 , -3.096826]], dtype=float32)

time = 44500	action = 0	current_phase = 1	next_phase = 0	reward = -0.376232	array([[-1.9476266, -3.22017  ]], dtype=float32)

time = 44505	action = 0	current_phase = 1	next_phase = 0	reward = -0.220129	array([[-1.928763 , -3.2300925]], dtype=float32)

time = 44510	action = 0	current_phase = 1	next_phase = 0	reward = 0.379913	array([[-2.0019107, -3.775487 ]], dtype=float32)

time = 44515	action = 1	current_phase = 1	next_phase = 0	reward = -1.193059	array([[-3.678955 , -2.9527264]], dtype=float32)

time = 44523	action = 0	current_phase = 0	next_phase = 1	reward = -0.585046	array([[-2.3122795, -3.5306523]], dtype=float32)

time = 44528	action = 0	current_phase = 0	next_phase = 1	reward = -0.432360	array([[-2.057708 , -2.8157952]], dtype=float32)

time = 44533	action = 1	current_phase = 0	next_phase = 1	reward = -1.377126	array([[-2.0690844, -1.8288157]], dtype=float32)

time = 44541	action = 0	current_phase = 1	next_phase = 0	reward = 0.293172	array([[-1.6620538, -4.070893 ]], dtype=float32)

time = 44546	action = 1	current_phase = 1	next_phase = 0	reward = -1.665198	array([[-4.2321134, -3.2103682]], dtype=float32)

time = 44554	action = 0	current_phase = 0	next_phase = 1	reward = -0.564999	array([[-2.1225104, -2.940349 ]], dtype=float32)

time = 44559	action = 0	current_phase = 0	next_phase = 1	reward = -0.414024	array([[-2.0653682, -2.8062122]], dtype=float32)

time = 44564	action = 1	current_phase = 0	next_phase = 1	reward = -1.362416	array([[-1.9646934, -1.9424844]], dtype=float32)

time = 44572	action = 0	current_phase = 1	next_phase = 0	reward = 0.207687	array([[-1.9963709, -3.5975614]], dtype=float32)

time = 44577	action = 0	current_phase = 1	next_phase = 0	reward = -1.264837	array([[-0.51906776, -3.6617265 ]], dtype=float32)

time = 44582	action = 1	current_phase = 1	next_phase = 0	reward = -2.020077	array([[-4.396587 , -3.6419864]], dtype=float32)

time = 44590	action = 0	current_phase = 0	next_phase = 1	reward = -0.379663	array([[-2.023597 , -3.2027764]], dtype=float32)

time = 44595	action = 1	current_phase = 0	next_phase = 1	reward = -1.314183	array([[-1.9648306, -1.9421536]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1755 - val_loss: 0.0332

Epoch 2/50

 - 4s - loss: 0.1485 - val_loss: 0.0326

Epoch 3/50

 - 4s - loss: 0.1260 - val_loss: 0.0360

Epoch 4/50

 - 4s - loss: 0.1337 - val_loss: 0.0347

Epoch 5/50

 - 4s - loss: 0.1610 - val_loss: 0.0390

Epoch 6/50

 - 4s - loss: 0.1422 - val_loss: 0.0388

Epoch 7/50

 - 4s - loss: 0.2790 - val_loss: 0.0407

Epoch 8/50

 - 4s - loss: 0.1157 - val_loss: 0.0420

Epoch 9/50

 - 4s - loss: 0.2115 - val_loss: 0.0388

Epoch 10/50

 - 4s - loss: 0.1135 - val_loss: 0.0455

Epoch 11/50

 - 4s - loss: 0.1126 - val_loss: 0.0413

Epoch 12/50

 - 4s - loss: 0.0856 - val_loss: 0.0426

length of memory (state 0, action 0): 1017, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1009, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1017, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1008, before forget

length of memory (state 1, action 1): 1000, after forget

time = 44603	action = 0	current_phase = 1	next_phase = 0	reward = 0.098098	array([[-1.9727173, -3.945038 ]], dtype=float32)

time = 44608	action = 0	current_phase = 1	next_phase = 0	reward = -1.459433	array([[-3.240995 , -3.7831328]], dtype=float32)

time = 44613	action = 0	current_phase = 1	next_phase = 0	reward = -1.666239	array([[11.049035 , -3.6297104]], dtype=float32)

time = 44618	action = 1	current_phase = 1	next_phase = 0	reward = -1.694125	array([[-5.174908, -3.48617 ]], dtype=float32)

time = 44626	action = 0	current_phase = 0	next_phase = 1	reward = -0.187201	array([[-1.9654995, -3.0696657]], dtype=float32)

time = 44631	action = 0	current_phase = 0	next_phase = 1	reward = 0.299495	array([[-2.6479876, -2.9788082]], dtype=float32)

time = 44636	action = 1	current_phase = 0	next_phase = 1	reward = -1.554754	array([[-4.7132325, -3.2377   ]], dtype=float32)

time = 44644	action = 0	current_phase = 1	next_phase = 0	reward = -0.546354	array([[-2.1072922, -3.1160648]], dtype=float32)

time = 44649	action = 0	current_phase = 1	next_phase = 0	reward = -0.378885	array([[-1.9643939, -3.209963 ]], dtype=float32)

time = 44654	action = 0	current_phase = 1	next_phase = 0	reward = -0.218762	array([[-1.9330657, -3.231456 ]], dtype=float32)

time = 44659	action = 0	current_phase = 1	next_phase = 0	reward = 0.098491	array([[-2.010875 , -3.7816188]], dtype=float32)

time = 44664	action = 1	current_phase = 1	next_phase = 0	reward = -0.766218	array([[-3.0638227, -2.7583833]], dtype=float32)

time = 44672	action = 0	current_phase = 0	next_phase = 1	reward = -0.612593	array([[-2.3087108, -3.5822554]], dtype=float32)

time = 44677	action = 0	current_phase = 0	next_phase = 1	reward = -0.458378	array([[-2.142428, -2.77369 ]], dtype=float32)

time = 44682	action = 1	current_phase = 0	next_phase = 1	reward = -1.415185	array([[-1.9843787, -1.8486955]], dtype=float32)

time = 44690	action = 0	current_phase = 1	next_phase = 0	reward = 0.350604	array([[-1.8788419, -3.8876715]], dtype=float32)

time = 44695	action = 1	current_phase = 1	next_phase = 0	reward = -1.365840	array([[-3.9034262, -3.1003218]], dtype=float32)

time = 44703	action = 0	current_phase = 0	next_phase = 1	reward = -0.588715	array([[-2.0618422, -2.8131018]], dtype=float32)

time = 44708	action = 0	current_phase = 0	next_phase = 1	reward = -0.435241	array([[-2.0552056, -2.8067844]], dtype=float32)

time = 44713	action = 1	current_phase = 0	next_phase = 1	reward = -1.377075	array([[-1.9820255, -1.8500824]], dtype=float32)

time = 44721	action = 0	current_phase = 1	next_phase = 0	reward = 0.316791	array([[-1.8489604, -4.0218067]], dtype=float32)

time = 44726	action = 1	current_phase = 1	next_phase = 0	reward = -1.560533	array([[-3.6406388, -3.484435 ]], dtype=float32)

time = 44734	action = 0	current_phase = 0	next_phase = 1	reward = -0.557420	array([[-2.1402588, -2.9682782]], dtype=float32)

time = 44739	action = 0	current_phase = 0	next_phase = 1	reward = -0.403325	array([[-2.0553482, -2.8060157]], dtype=float32)

time = 44744	action = 0	current_phase = 0	next_phase = 1	reward = -0.253388	array([[-1.899871 , -1.9099027]], dtype=float32)

time = 44749	action = 0	current_phase = 0	next_phase = 1	reward = -0.180590	array([[-2.1615076, -2.7033186]], dtype=float32)

time = 44754	action = 1	current_phase = 0	next_phase = 1	reward = -0.502443	array([[-4.374368 , -2.2966492]], dtype=float32)

time = 44762	action = 0	current_phase = 1	next_phase = 0	reward = -0.619048	array([[-2.2753742, -2.968558 ]], dtype=float32)

time = 44767	action = 0	current_phase = 1	next_phase = 0	reward = -0.455276	array([[-1.9991548, -3.2574663]], dtype=float32)

time = 44772	action = 0	current_phase = 1	next_phase = 0	reward = -0.305441	array([[-2.1102126, -3.1073883]], dtype=float32)

time = 44777	action = 0	current_phase = 1	next_phase = 0	reward = -0.173758	array([[-2.2578657, -3.2127314]], dtype=float32)

time = 44782	action = 0	current_phase = 1	next_phase = 0	reward = 0.139495	array([[-2.649963, -3.755409]], dtype=float32)

time = 44787	action = 1	current_phase = 1	next_phase = 0	reward = -1.789660	array([[-5.966874, -3.573868]], dtype=float32)

time = 44795	action = 0	current_phase = 0	next_phase = 1	reward = -0.534030	array([[-2.070416 , -2.9994445]], dtype=float32)

time = 44800	action = 0	current_phase = 0	next_phase = 1	reward = -0.377578	array([[-2.054975 , -2.8063326]], dtype=float32)

time = 44805	action = 0	current_phase = 0	next_phase = 1	reward = -0.220501	array([[-1.8999743, -1.9105351]], dtype=float32)

time = 44810	action = 1	current_phase = 0	next_phase = 1	reward = -1.020653	array([[-2.0746102, -0.6110534]], dtype=float32)

time = 44818	action = 1	current_phase = 1	next_phase = 0	reward = -1.893690	array([[-4.7114983, -3.4359524]], dtype=float32)

time = 44826	action = 0	current_phase = 0	next_phase = 1	reward = -0.489276	array([[-2.529539 , -3.1639574]], dtype=float32)

time = 44831	action = 0	current_phase = 0	next_phase = 1	reward = -0.327277	array([[-2.0704417, -2.762397 ]], dtype=float32)

time = 44836	action = 0	current_phase = 0	next_phase = 1	reward = -0.180800	array([[-1.901869 , -1.9155644]], dtype=float32)

time = 44841	action = 1	current_phase = 0	next_phase = 1	reward = -1.177703	array([[-2.2074213, -1.2289244]], dtype=float32)

time = 44849	action = 1	current_phase = 1	next_phase = 0	reward = -1.998023	array([[-4.074678 , -3.6730502]], dtype=float32)

time = 44857	action = 0	current_phase = 0	next_phase = 1	reward = -0.459452	array([[-2.2588913, -3.215462 ]], dtype=float32)

time = 44862	action = 1	current_phase = 0	next_phase = 1	reward = -1.403505	array([[-2.0522778, -1.8745689]], dtype=float32)

time = 44870	action = 0	current_phase = 1	next_phase = 0	reward = 0.346008	array([[-1.6498272, -3.9044158]], dtype=float32)

time = 44875	action = 0	current_phase = 1	next_phase = 0	reward = -0.795300	array([[-3.1217322, -3.1322644]], dtype=float32)

time = 44880	action = 0	current_phase = 1	next_phase = 0	reward = -1.730361	array([[-3.4615932, -3.7599752]], dtype=float32)

time = 44885	action = 1	current_phase = 1	next_phase = 0	reward = -1.862064	array([[-5.1309667, -3.5245388]], dtype=float32)

time = 44893	action = 0	current_phase = 0	next_phase = 1	reward = -0.295556	array([[-2.1036246, -2.8049357]], dtype=float32)

time = 44898	action = 0	current_phase = 0	next_phase = 1	reward = -0.169304	array([[-2.274073 , -3.0509064]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2442 - val_loss: 0.0654

Epoch 2/50

 - 4s - loss: 0.1865 - val_loss: 0.0662

Epoch 3/50

 - 4s - loss: 0.2911 - val_loss: 0.0708

Epoch 4/50

 - 4s - loss: 0.1675 - val_loss: 0.0643

Epoch 5/50

 - 4s - loss: 0.1839 - val_loss: 0.0678

Epoch 6/50

 - 4s - loss: 0.1810 - val_loss: 0.0728

Epoch 7/50

 - 4s - loss: 0.1783 - val_loss: 0.0814

Epoch 8/50

 - 4s - loss: 0.1476 - val_loss: 0.0732

Epoch 9/50

 - 4s - loss: 0.2007 - val_loss: 0.0780

Epoch 10/50

 - 4s - loss: 0.1344 - val_loss: 0.0756

Epoch 11/50

 - 4s - loss: 0.1315 - val_loss: 0.0778

Epoch 12/50

 - 4s - loss: 0.1241 - val_loss: 0.0706

Epoch 13/50

 - 4s - loss: 0.1258 - val_loss: 0.0774

Epoch 14/50

 - 4s - loss: 0.1698 - val_loss: 0.0837

length of memory (state 0, action 0): 1019, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1007, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1017, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1008, before forget

length of memory (state 1, action 1): 1000, after forget

time = 44903	action = 0	current_phase = 0	next_phase = 1	reward = 0.064722	array([[-2.6499817, -3.641519 ]], dtype=float32)

time = 44908	action = 1	current_phase = 0	next_phase = 1	reward = -1.898974	array([[-5.3196936, -3.468145 ]], dtype=float32)

time = 44916	action = 0	current_phase = 1	next_phase = 0	reward = -0.498954	array([[-2.163167 , -3.1900125]], dtype=float32)

time = 44921	action = 0	current_phase = 1	next_phase = 0	reward = -0.350688	array([[-2.127432 , -3.1262574]], dtype=float32)

time = 44926	action = 0	current_phase = 1	next_phase = 0	reward = -0.209800	array([[-1.8483841, -3.2278976]], dtype=float32)

time = 44931	action = 0	current_phase = 1	next_phase = 0	reward = 0.300433	array([[-2.1248608, -3.8472764]], dtype=float32)

time = 44936	action = 1	current_phase = 1	next_phase = 0	reward = -1.555153	array([[-5.703492 , -3.3322344]], dtype=float32)

time = 44944	action = 0	current_phase = 0	next_phase = 1	reward = -0.551697	array([[-2.1154656, -3.0065107]], dtype=float32)

time = 44949	action = 0	current_phase = 0	next_phase = 1	reward = -0.395140	array([[-2.0301967, -2.7994287]], dtype=float32)

time = 44954	action = 0	current_phase = 0	next_phase = 1	reward = -0.233089	array([[-1.8981999, -2.0255485]], dtype=float32)

time = 44959	action = 0	current_phase = 0	next_phase = 1	reward = 0.115678	array([[-2.2452395, -3.0584536]], dtype=float32)

time = 44964	action = 1	current_phase = 0	next_phase = 1	reward = -0.805927	array([[-4.363415 , -2.7328186]], dtype=float32)

time = 44972	action = 0	current_phase = 1	next_phase = 0	reward = -0.613875	array([[-2.361192 , -3.0081744]], dtype=float32)

time = 44977	action = 0	current_phase = 1	next_phase = 0	reward = -0.458934	array([[-1.9951025, -3.2822084]], dtype=float32)

time = 44982	action = 0	current_phase = 1	next_phase = 0	reward = -0.306834	array([[-2.1351664, -3.1229353]], dtype=float32)

time = 44987	action = 0	current_phase = 1	next_phase = 0	reward = -0.173131	array([[-2.3435287, -3.197368 ]], dtype=float32)

time = 44992	action = 0	current_phase = 1	next_phase = 0	reward = 0.227077	array([[-2.6454155, -3.8107295]], dtype=float32)

time = 44997	action = 1	current_phase = 1	next_phase = 0	reward = -1.783276	array([[-5.9129844, -3.4629927]], dtype=float32)

time = 45005	action = 0	current_phase = 0	next_phase = 1	reward = -0.525090	array([[-2.1292653, -3.1584506]], dtype=float32)

time = 45010	action = 0	current_phase = 0	next_phase = 1	reward = -0.370129	array([[-2.0107663, -2.8118525]], dtype=float32)

time = 45015	action = 0	current_phase = 0	next_phase = 1	reward = -0.216794	array([[-1.8975779, -2.024201 ]], dtype=float32)

time = 45020	action = 1	current_phase = 0	next_phase = 1	reward = -1.067794	array([[-2.179336 , -1.4507109]], dtype=float32)

time = 45028	action = 1	current_phase = 1	next_phase = 0	reward = -1.894202	array([[-4.559466 , -3.7091446]], dtype=float32)

time = 45036	action = 0	current_phase = 0	next_phase = 1	reward = -0.492126	array([[-2.199954 , -3.1828158]], dtype=float32)

time = 45041	action = 0	current_phase = 0	next_phase = 1	reward = -0.336826	array([[-2.0692208, -2.7799904]], dtype=float32)

time = 45046	action = 0	current_phase = 0	next_phase = 1	reward = -0.186710	array([[-1.8978715, -2.0230374]], dtype=float32)

time = 45051	action = 1	current_phase = 0	next_phase = 1	reward = -1.293907	array([[-2.3028414, -1.7300069]], dtype=float32)

time = 45059	action = 1	current_phase = 1	next_phase = 0	reward = -2.020979	array([[-4.292586, -3.514634]], dtype=float32)

time = 45067	action = 0	current_phase = 0	next_phase = 1	reward = -0.491191	array([[-2.146807, -3.182719]], dtype=float32)

time = 45072	action = 0	current_phase = 0	next_phase = 1	reward = -0.343382	array([[-2.0642786, -2.710772 ]], dtype=float32)

time = 45077	action = 0	current_phase = 0	next_phase = 1	reward = -0.197395	array([[-2.05814  , -2.5829449]], dtype=float32)

time = 45082	action = 1	current_phase = 0	next_phase = 1	reward = -1.306736	array([[-2.4016843, -1.8838537]], dtype=float32)

time = 45090	action = 1	current_phase = 1	next_phase = 0	reward = -2.103589	array([[-4.041096, -3.50996 ]], dtype=float32)

time = 45098	action = 0	current_phase = 0	next_phase = 1	reward = -0.431118	array([[-2.0935857, -3.1796823]], dtype=float32)

time = 45103	action = 1	current_phase = 0	next_phase = 1	reward = -1.370375	array([[-1.9946713, -1.9518725]], dtype=float32)

time = 45111	action = 0	current_phase = 1	next_phase = 0	reward = 0.316285	array([[ 0.4518832, -4.0135403]], dtype=float32)

time = 45116	action = 0	current_phase = 1	next_phase = 0	reward = -1.064539	array([[-2.932613 , -3.3299553]], dtype=float32)

time = 45121	action = 0	current_phase = 1	next_phase = 0	reward = -1.708787	array([[ 8.195883 , -3.6724613]], dtype=float32)

time = 45126	action = 1	current_phase = 1	next_phase = 0	reward = -1.788941	array([[-5.014322 , -3.4927485]], dtype=float32)

time = 45134	action = 0	current_phase = 0	next_phase = 1	reward = -0.233368	array([[-1.933659 , -3.0919807]], dtype=float32)

time = 45139	action = 0	current_phase = 0	next_phase = 1	reward = -0.176350	array([[-2.1407814, -2.7268448]], dtype=float32)

time = 45144	action = 1	current_phase = 0	next_phase = 1	reward = -0.529013	array([[-4.5483117, -2.6284916]], dtype=float32)

time = 45152	action = 0	current_phase = 1	next_phase = 0	reward = -0.625238	array([[-2.573031 , -3.0914335]], dtype=float32)

time = 45157	action = 0	current_phase = 1	next_phase = 0	reward = -0.468300	array([[-2.3429372, -3.2544904]], dtype=float32)

time = 45162	action = 0	current_phase = 1	next_phase = 0	reward = -0.307842	array([[-2.1350453, -3.1214278]], dtype=float32)

time = 45167	action = 0	current_phase = 1	next_phase = 0	reward = -0.172987	array([[-2.2824435, -3.199464 ]], dtype=float32)

time = 45172	action = 0	current_phase = 1	next_phase = 0	reward = 0.202306	array([[-2.6143456, -3.811219 ]], dtype=float32)

time = 45177	action = 1	current_phase = 1	next_phase = 0	reward = -1.781917	array([[-6.005584, -3.529554]], dtype=float32)

time = 45185	action = 0	current_phase = 0	next_phase = 1	reward = -0.527267	array([[-2.120267 , -3.1622674]], dtype=float32)

time = 45190	action = 0	current_phase = 0	next_phase = 1	reward = -0.376955	array([[-2.010759 , -2.8120391]], dtype=float32)

time = 45195	action = 0	current_phase = 0	next_phase = 1	reward = -0.224470	array([[-1.8975041, -2.023662 ]], dtype=float32)

time = 45200	action = 1	current_phase = 0	next_phase = 1	reward = -1.012670	array([[-2.2611995, -1.6498499]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2512 - val_loss: 0.4693

Epoch 2/50

 - 4s - loss: 0.1741 - val_loss: 0.4543

Epoch 3/50

 - 4s - loss: 0.1735 - val_loss: 0.4505

Epoch 4/50

 - 4s - loss: 0.1869 - val_loss: 0.4450

Epoch 5/50

 - 4s - loss: 0.1661 - val_loss: 0.4517

Epoch 6/50

 - 4s - loss: 0.3184 - val_loss: 0.4561

Epoch 7/50

 - 4s - loss: 0.1397 - val_loss: 0.4591

Epoch 8/50

 - 4s - loss: 0.1842 - val_loss: 0.4615

Epoch 9/50

 - 4s - loss: 0.1575 - val_loss: 0.4697

Epoch 10/50

 - 4s - loss: 0.1492 - val_loss: 0.4628

Epoch 11/50

 - 4s - loss: 0.1482 - val_loss: 0.4692

Epoch 12/50

 - 4s - loss: 0.1587 - val_loss: 0.4744

Epoch 13/50

 - 4s - loss: 0.1407 - val_loss: 0.4611

Epoch 14/50

 - 4s - loss: 0.1375 - val_loss: 0.4854

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1008, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1017, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1007, before forget

length of memory (state 1, action 1): 1000, after forget

time = 45208	action = 1	current_phase = 1	next_phase = 0	reward = -1.897934	array([[-4.189292, -3.663356]], dtype=float32)

time = 45216	action = 0	current_phase = 0	next_phase = 1	reward = -0.503331	array([[-2.1920168, -3.1604855]], dtype=float32)

time = 45221	action = 0	current_phase = 0	next_phase = 1	reward = -0.351012	array([[-1.9952248, -2.8416867]], dtype=float32)

time = 45226	action = 0	current_phase = 0	next_phase = 1	reward = -0.204554	array([[-1.9918091, -2.6031034]], dtype=float32)

time = 45231	action = 0	current_phase = 0	next_phase = 1	reward = 0.293914	array([[-2.249918 , -2.9063098]], dtype=float32)

time = 45236	action = 1	current_phase = 0	next_phase = 1	reward = -1.556702	array([[-4.4515624, -3.3092103]], dtype=float32)

time = 45244	action = 0	current_phase = 1	next_phase = 0	reward = -0.553416	array([[-2.10632 , -3.064865]], dtype=float32)

time = 45249	action = 0	current_phase = 1	next_phase = 0	reward = -0.406579	array([[-1.9853904, -3.1419775]], dtype=float32)

time = 45254	action = 0	current_phase = 1	next_phase = 0	reward = -0.257134	array([[-1.8932066, -3.1843262]], dtype=float32)

time = 45259	action = 0	current_phase = 1	next_phase = 0	reward = -0.168759	array([[-1.9875757, -3.7475793]], dtype=float32)

time = 45264	action = 1	current_phase = 1	next_phase = 0	reward = -0.366604	array([[-2.5379436, -2.2999144]], dtype=float32)

time = 45272	action = 0	current_phase = 0	next_phase = 1	reward = -0.616640	array([[-2.2347562, -3.6114967]], dtype=float32)

time = 45277	action = 0	current_phase = 0	next_phase = 1	reward = -0.462163	array([[-2.0713596, -2.8179286]], dtype=float32)

time = 45282	action = 1	current_phase = 0	next_phase = 1	reward = -1.438351	array([[-1.9825442, -1.9537075]], dtype=float32)

time = 45290	action = 0	current_phase = 1	next_phase = 0	reward = 0.352201	array([[ 0.32245126, -4.0225263 ]], dtype=float32)

time = 45295	action = 0	current_phase = 1	next_phase = 0	reward = -0.845113	array([[-2.33564  , -3.0185483]], dtype=float32)

time = 45300	action = 1	current_phase = 1	next_phase = 0	reward = -2.098587	array([[-4.6822295, -3.6386592]], dtype=float32)

time = 45308	action = 0	current_phase = 0	next_phase = 1	reward = -0.420269	array([[-2.0782843, -3.2320702]], dtype=float32)

time = 45313	action = 1	current_phase = 0	next_phase = 1	reward = -1.357139	array([[-1.9793545, -1.9532101]], dtype=float32)

time = 45321	action = 0	current_phase = 1	next_phase = 0	reward = 0.301480	array([[ 0.6213546, -4.1166587]], dtype=float32)

time = 45326	action = 1	current_phase = 1	next_phase = 0	reward = -1.610515	array([[-3.1959853, -3.1557784]], dtype=float32)

time = 45334	action = 0	current_phase = 0	next_phase = 1	reward = -0.557026	array([[-2.0694923, -2.9888122]], dtype=float32)

time = 45339	action = 0	current_phase = 0	next_phase = 1	reward = -0.398293	array([[-2.059692 , -2.8226295]], dtype=float32)

time = 45344	action = 0	current_phase = 0	next_phase = 1	reward = -0.252190	array([[-1.8535038, -2.0269618]], dtype=float32)

time = 45349	action = 0	current_phase = 0	next_phase = 1	reward = -0.177130	array([[-2.0697684, -2.8804247]], dtype=float32)

time = 45354	action = 1	current_phase = 0	next_phase = 1	reward = -0.548880	array([[-4.416482 , -2.4146194]], dtype=float32)

time = 45362	action = 0	current_phase = 1	next_phase = 0	reward = -0.619820	array([[-2.2816541, -2.9588711]], dtype=float32)

time = 45367	action = 0	current_phase = 1	next_phase = 0	reward = -0.462184	array([[-2.1775753, -3.0738516]], dtype=float32)

time = 45372	action = 0	current_phase = 1	next_phase = 0	reward = -0.301085	array([[-2.113053, -3.073858]], dtype=float32)

time = 45377	action = 0	current_phase = 1	next_phase = 0	reward = -0.168231	array([[-2.275263, -3.162612]], dtype=float32)

time = 45382	action = 0	current_phase = 1	next_phase = 0	reward = 0.155766	array([[-2.615326 , -3.7751486]], dtype=float32)

time = 45387	action = 1	current_phase = 1	next_phase = 0	reward = -1.779439	array([[-6.0215325, -3.572774 ]], dtype=float32)

time = 45395	action = 0	current_phase = 0	next_phase = 1	reward = -0.526695	array([[-2.08223  , -3.2204442]], dtype=float32)

time = 45400	action = 0	current_phase = 0	next_phase = 1	reward = -0.368994	array([[-1.9948691, -2.8412776]], dtype=float32)

time = 45405	action = 0	current_phase = 0	next_phase = 1	reward = -0.213634	array([[-1.8535696, -2.027291 ]], dtype=float32)

time = 45410	action = 1	current_phase = 0	next_phase = 1	reward = -1.022366	array([[-2.1184804, -1.4344795]], dtype=float32)

time = 45418	action = 0	current_phase = 1	next_phase = 0	reward = -1.460780	array([[ 6.6574535, -3.7314596]], dtype=float32)

time = 45423	action = 1	current_phase = 1	next_phase = 0	reward = -1.959276	array([[-4.4009356, -3.5872858]], dtype=float32)

time = 45431	action = 0	current_phase = 0	next_phase = 1	reward = -0.333918	array([[-2.0167255, -3.2277699]], dtype=float32)

time = 45436	action = 0	current_phase = 0	next_phase = 1	reward = -0.188028	array([[-1.8580686, -2.0496013]], dtype=float32)

time = 45441	action = 1	current_phase = 0	next_phase = 1	reward = -1.233047	array([[-2.117372 , -1.2751143]], dtype=float32)

time = 45449	action = 0	current_phase = 1	next_phase = 0	reward = -1.597592	array([[-2.4864404, -3.9672434]], dtype=float32)

time = 45454	action = 0	current_phase = 1	next_phase = 0	reward = -1.646133	array([[11.254708, -3.615329]], dtype=float32)

time = 45459	action = 1	current_phase = 1	next_phase = 0	reward = -1.632252	array([[-5.229428 , -3.3322783]], dtype=float32)

time = 45467	action = 0	current_phase = 0	next_phase = 1	reward = -0.166100	array([[-1.9931374, -2.8457012]], dtype=float32)

time = 45472	action = 0	current_phase = 0	next_phase = 1	reward = 0.199287	array([[ 2.8127356, -3.7072327]], dtype=float32)

time = 45477	action = 1	current_phase = 0	next_phase = 1	reward = -1.783793	array([[-5.390872 , -3.4959426]], dtype=float32)

time = 45485	action = 0	current_phase = 1	next_phase = 0	reward = -0.529131	array([[-2.134762, -3.036771]], dtype=float32)

time = 45490	action = 0	current_phase = 1	next_phase = 0	reward = -0.371501	array([[-1.9720054, -3.148466 ]], dtype=float32)

time = 45495	action = 0	current_phase = 1	next_phase = 0	reward = -0.224059	array([[-1.9366162, -3.1656477]], dtype=float32)

time = 45500	action = 0	current_phase = 1	next_phase = 0	reward = 0.068892	array([[-2.0772524, -3.73169  ]], dtype=float32)

time = 45505	action = 1	current_phase = 1	next_phase = 0	reward = -1.076925	array([[-3.2994432, -2.8087301]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.3869 - val_loss: 0.0758

Epoch 2/50

 - 4s - loss: 0.2187 - val_loss: 0.0781

Epoch 3/50

 - 4s - loss: 0.2703 - val_loss: 0.0778

Epoch 4/50

 - 4s - loss: 0.2391 - val_loss: 0.0750

Epoch 5/50

 - 4s - loss: 0.1923 - val_loss: 0.0706

Epoch 6/50

 - 4s - loss: 0.2371 - val_loss: 0.0733

Epoch 7/50

 - 4s - loss: 0.1766 - val_loss: 0.0708

Epoch 8/50

 - 4s - loss: 0.1808 - val_loss: 0.0763

Epoch 9/50

 - 4s - loss: 0.2024 - val_loss: 0.0819

Epoch 10/50

 - 4s - loss: 0.1829 - val_loss: 0.0716

Epoch 11/50

 - 4s - loss: 0.2016 - val_loss: 0.0781

Epoch 12/50

 - 4s - loss: 0.2102 - val_loss: 0.0724

Epoch 13/50

 - 4s - loss: 0.2164 - val_loss: 0.0681

Epoch 14/50

 - 4s - loss: 0.1382 - val_loss: 0.0694

Epoch 15/50

 - 4s - loss: 0.1391 - val_loss: 0.0747

Epoch 16/50

 - 4s - loss: 0.1404 - val_loss: 0.0803

Epoch 17/50

 - 4s - loss: 0.1495 - val_loss: 0.0791

Epoch 18/50

 - 4s - loss: 0.1394 - val_loss: 0.0753

Epoch 19/50

 - 4s - loss: 0.1376 - val_loss: 0.0812

Epoch 20/50

 - 4s - loss: 0.1177 - val_loss: 0.0734

Epoch 21/50

 - 4s - loss: 0.2062 - val_loss: 0.0848

Epoch 22/50

 - 4s - loss: 0.1180 - val_loss: 0.0822

Epoch 23/50

 - 4s - loss: 0.1386 - val_loss: 0.0882

length of memory (state 0, action 0): 1018, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1007, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1008, before forget

length of memory (state 1, action 1): 1000, after forget

time = 45513	action = 0	current_phase = 0	next_phase = 1	reward = -0.581178	array([[-2.2396605, -3.6598642]], dtype=float32)

time = 45518	action = 0	current_phase = 0	next_phase = 1	reward = -0.431758	array([[-1.9216018, -2.8932047]], dtype=float32)

time = 45523	action = 1	current_phase = 0	next_phase = 1	reward = -1.373260	array([[-1.9726301, -1.897999 ]], dtype=float32)

time = 45531	action = 0	current_phase = 1	next_phase = 0	reward = 0.305177	array([[-1.4386606, -4.142686 ]], dtype=float32)

time = 45536	action = 0	current_phase = 1	next_phase = 0	reward = -1.173204	array([[-2.3975046, -3.0348985]], dtype=float32)

time = 45541	action = 1	current_phase = 1	next_phase = 0	reward = -2.058358	array([[-4.641705 , -3.6621692]], dtype=float32)

time = 45549	action = 0	current_phase = 0	next_phase = 1	reward = -0.395520	array([[-2.0120163, -3.2658372]], dtype=float32)

time = 45554	action = 0	current_phase = 0	next_phase = 1	reward = -0.229231	array([[-1.834912 , -1.9572327]], dtype=float32)

time = 45559	action = 0	current_phase = 0	next_phase = 1	reward = -0.172738	array([[ 1.8827238, -3.1155858]], dtype=float32)

time = 45564	action = 1	current_phase = 0	next_phase = 1	reward = -0.523052	array([[-4.262715 , -2.4130974]], dtype=float32)

time = 45572	action = 0	current_phase = 1	next_phase = 0	reward = -0.619340	array([[-2.454646 , -3.1676557]], dtype=float32)

time = 45577	action = 0	current_phase = 1	next_phase = 0	reward = -0.468700	array([[-2.1837718, -3.0658743]], dtype=float32)

time = 45582	action = 0	current_phase = 1	next_phase = 0	reward = -0.313858	array([[-2.0979564, -3.094166 ]], dtype=float32)

time = 45587	action = 0	current_phase = 1	next_phase = 0	reward = -0.178566	array([[-2.2444754, -3.1787171]], dtype=float32)

time = 45592	action = 0	current_phase = 1	next_phase = 0	reward = 0.265671	array([[-2.624824 , -3.8155942]], dtype=float32)

time = 45597	action = 1	current_phase = 1	next_phase = 0	reward = -1.724562	array([[-6.000353 , -3.5027153]], dtype=float32)

time = 45605	action = 0	current_phase = 0	next_phase = 1	reward = -0.524571	array([[-2.1158788, -3.2027273]], dtype=float32)

time = 45610	action = 0	current_phase = 0	next_phase = 1	reward = -0.371913	array([[-1.919048 , -2.8872817]], dtype=float32)

time = 45615	action = 0	current_phase = 0	next_phase = 1	reward = -0.224513	array([[-1.8352464, -1.9581648]], dtype=float32)

time = 45620	action = 0	current_phase = 0	next_phase = 1	reward = 0.356550	array([[-2.1962943, -2.57797  ]], dtype=float32)

time = 45625	action = 1	current_phase = 0	next_phase = 1	reward = -1.310989	array([[-4.4732633, -3.261164 ]], dtype=float32)

time = 45633	action = 0	current_phase = 1	next_phase = 0	reward = -0.600627	array([[-2.2586157, -2.9876049]], dtype=float32)

time = 45638	action = 0	current_phase = 1	next_phase = 0	reward = -0.451987	array([[-2.0975034, -3.0945883]], dtype=float32)

time = 45643	action = 0	current_phase = 1	next_phase = 0	reward = -0.298170	array([[-2.0570478, -3.0056286]], dtype=float32)

time = 45648	action = 0	current_phase = 1	next_phase = 0	reward = -0.165570	array([[-2.1940064, -3.1953547]], dtype=float32)

time = 45653	action = 0	current_phase = 1	next_phase = 0	reward = 0.155490	array([[-2.6206112, -3.796662 ]], dtype=float32)

time = 45658	action = 1	current_phase = 1	next_phase = 0	reward = -1.888364	array([[-6.0013676, -3.5593383]], dtype=float32)

time = 45666	action = 0	current_phase = 0	next_phase = 1	reward = -0.491352	array([[-2.152486, -3.216574]], dtype=float32)

time = 45671	action = 0	current_phase = 0	next_phase = 1	reward = -0.332124	array([[-1.9204645, -2.8870063]], dtype=float32)

time = 45676	action = 0	current_phase = 0	next_phase = 1	reward = -0.185317	array([[-1.8558838, -2.0477147]], dtype=float32)

time = 45681	action = 1	current_phase = 0	next_phase = 1	reward = -1.234983	array([[-2.1892173, -2.0311048]], dtype=float32)

time = 45689	action = 0	current_phase = 1	next_phase = 0	reward = -1.596183	array([[ 5.185072 , -3.6902242]], dtype=float32)

time = 45694	action = 0	current_phase = 1	next_phase = 0	reward = -1.638631	array([[-1.6699737, -3.4394157]], dtype=float32)

time = 45699	action = 1	current_phase = 1	next_phase = 0	reward = -1.676549	array([[-5.1626806, -3.4290318]], dtype=float32)

time = 45707	action = 0	current_phase = 0	next_phase = 1	reward = -0.180290	array([[-1.8729978, -2.9752414]], dtype=float32)

time = 45712	action = 0	current_phase = 0	next_phase = 1	reward = 0.145471	array([[-2.6820073, -4.1082516]], dtype=float32)

time = 45717	action = 1	current_phase = 0	next_phase = 1	reward = -1.780739	array([[-6.068322 , -3.5531847]], dtype=float32)

time = 45725	action = 0	current_phase = 1	next_phase = 0	reward = -0.523385	array([[-2.0397232, -2.988228 ]], dtype=float32)

time = 45730	action = 0	current_phase = 1	next_phase = 0	reward = -0.371101	array([[-1.9028742, -3.1597462]], dtype=float32)

time = 45735	action = 0	current_phase = 1	next_phase = 0	reward = -0.218280	array([[-1.9166999, -3.1602025]], dtype=float32)

time = 45740	action = 0	current_phase = 1	next_phase = 0	reward = 0.348780	array([[-2.0548246, -3.9007857]], dtype=float32)

time = 45745	action = 1	current_phase = 1	next_phase = 0	reward = -1.366082	array([[-3.6951334, -3.0516434]], dtype=float32)

time = 45753	action = 0	current_phase = 0	next_phase = 1	reward = -0.584151	array([[-2.264064 , -3.7063396]], dtype=float32)

time = 45758	action = 0	current_phase = 0	next_phase = 1	reward = -0.430598	array([[-1.9199882, -2.8879945]], dtype=float32)

time = 45763	action = 1	current_phase = 0	next_phase = 1	reward = -1.366611	array([[-1.9725491, -1.8947682]], dtype=float32)

time = 45771	action = 0	current_phase = 1	next_phase = 0	reward = 0.311523	array([[-1.3742008, -4.141179 ]], dtype=float32)

time = 45776	action = 1	current_phase = 1	next_phase = 0	reward = -1.612588	array([[-4.5492687, -3.273987 ]], dtype=float32)

time = 45784	action = 0	current_phase = 0	next_phase = 1	reward = -0.559097	array([[-2.182348 , -3.0418801]], dtype=float32)

time = 45789	action = 0	current_phase = 0	next_phase = 1	reward = -0.396894	array([[-1.9295962, -2.883917 ]], dtype=float32)

time = 45794	action = 0	current_phase = 0	next_phase = 1	reward = -0.244813	array([[-1.8356414, -1.9612627]], dtype=float32)

time = 45799	action = 0	current_phase = 0	next_phase = 1	reward = -0.175305	array([[-2.1207337, -2.914602 ]], dtype=float32)

time = 45804	action = 1	current_phase = 0	next_phase = 1	reward = -0.522889	array([[-4.420708 , -2.3099194]], dtype=float32)

time = 45812	action = 0	current_phase = 1	next_phase = 0	reward = -0.623367	array([[-2.2687094, -2.9833062]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2119 - val_loss: 0.1462

Epoch 2/50

 - 4s - loss: 0.2757 - val_loss: 0.1588

Epoch 3/50

 - 4s - loss: 0.2739 - val_loss: 0.1530

Epoch 4/50

 - 4s - loss: 0.2630 - val_loss: 0.1533

Epoch 5/50

 - 4s - loss: 0.1571 - val_loss: 0.1572

Epoch 6/50

 - 4s - loss: 0.1833 - val_loss: 0.1660

Epoch 7/50

 - 4s - loss: 0.1260 - val_loss: 0.1744

Epoch 8/50

 - 4s - loss: 0.1515 - val_loss: 0.1764

Epoch 9/50

 - 4s - loss: 0.2122 - val_loss: 0.1680

Epoch 10/50

 - 4s - loss: 0.1667 - val_loss: 0.1766

Epoch 11/50

 - 4s - loss: 0.1220 - val_loss: 0.1872

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1007, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 45817	action = 0	current_phase = 1	next_phase = 0	reward = -0.468693	array([[-2.1415408, -3.0814295]], dtype=float32)

time = 45822	action = 0	current_phase = 1	next_phase = 0	reward = -0.304564	array([[-2.1335542, -3.0831096]], dtype=float32)

time = 45827	action = 0	current_phase = 1	next_phase = 0	reward = -0.172234	array([[-2.2561646, -3.196741 ]], dtype=float32)

time = 45832	action = 0	current_phase = 1	next_phase = 0	reward = 0.171990	array([[-2.7193408, -3.7941902]], dtype=float32)

time = 45837	action = 1	current_phase = 1	next_phase = 0	reward = -1.785555	array([[-6.0015283, -3.526441 ]], dtype=float32)

time = 45845	action = 0	current_phase = 0	next_phase = 1	reward = -0.526426	array([[-2.1102424, -3.219542 ]], dtype=float32)

time = 45850	action = 0	current_phase = 0	next_phase = 1	reward = -0.371178	array([[-1.895036 , -2.9116411]], dtype=float32)

time = 45855	action = 0	current_phase = 0	next_phase = 1	reward = -0.219915	array([[-1.8365407, -1.9345824]], dtype=float32)

time = 45860	action = 0	current_phase = 0	next_phase = 1	reward = 0.358790	array([[-2.2692811, -3.1101   ]], dtype=float32)

time = 45865	action = 1	current_phase = 0	next_phase = 1	reward = -1.305409	array([[-4.4222817, -3.1603446]], dtype=float32)

time = 45873	action = 0	current_phase = 1	next_phase = 0	reward = -0.580339	array([[-2.2534366, -2.9946272]], dtype=float32)

time = 45878	action = 0	current_phase = 1	next_phase = 0	reward = -0.425278	array([[-2.1342216, -3.0828645]], dtype=float32)

time = 45883	action = 0	current_phase = 1	next_phase = 0	reward = -0.274729	array([[-2.10144  , -3.0947506]], dtype=float32)

time = 45888	action = 0	current_phase = 1	next_phase = 0	reward = -0.165399	array([[-2.242818 , -3.1942112]], dtype=float32)

time = 45893	action = 0	current_phase = 1	next_phase = 0	reward = 0.056703	array([[-2.6001964, -2.667225 ]], dtype=float32)

time = 45898	action = 1	current_phase = 1	next_phase = 0	reward = -1.893209	array([[-6.016689 , -3.5204964]], dtype=float32)

time = 45906	action = 0	current_phase = 0	next_phase = 1	reward = -0.486954	array([[-2.134216, -3.250901]], dtype=float32)

time = 45911	action = 0	current_phase = 0	next_phase = 1	reward = -0.333115	array([[-1.9240377, -2.903737 ]], dtype=float32)

time = 45916	action = 0	current_phase = 0	next_phase = 1	reward = -0.190947	array([[-1.8590338, -2.0384703]], dtype=float32)

time = 45921	action = 1	current_phase = 0	next_phase = 1	reward = -1.360026	array([[-2.4534562, -2.1479738]], dtype=float32)

time = 45929	action = 1	current_phase = 1	next_phase = 0	reward = -2.015372	array([[-4.9281797, -3.4952526]], dtype=float32)

time = 45937	action = 0	current_phase = 0	next_phase = 1	reward = -0.477113	array([[-2.0879452, -3.2215736]], dtype=float32)

time = 45942	action = 0	current_phase = 0	next_phase = 1	reward = -0.321118	array([[-1.98263 , -2.801607]], dtype=float32)

time = 45947	action = 0	current_phase = 0	next_phase = 1	reward = -0.176600	array([[-2.142312 , -2.9332507]], dtype=float32)

time = 45952	action = 1	current_phase = 0	next_phase = 1	reward = -1.408095	array([[-2.5267243, -2.4055812]], dtype=float32)

time = 45960	action = 1	current_phase = 1	next_phase = 0	reward = -2.108028	array([[-5.060531 , -3.4521863]], dtype=float32)

time = 45968	action = 0	current_phase = 0	next_phase = 1	reward = -0.423244	array([[-2.0901668, -3.2705724]], dtype=float32)

time = 45973	action = 1	current_phase = 0	next_phase = 1	reward = -1.362250	array([[-1.9685897, -1.8862315]], dtype=float32)

time = 45981	action = 0	current_phase = 1	next_phase = 0	reward = 0.310552	array([[-1.8824403, -4.0064135]], dtype=float32)

time = 45986	action = 0	current_phase = 1	next_phase = 0	reward = -1.118456	array([[ 3.034789 , -4.1939573]], dtype=float32)

time = 45991	action = 0	current_phase = 1	next_phase = 0	reward = -1.718421	array([[ 7.6491504, -3.7148583]], dtype=float32)

time = 45996	action = 1	current_phase = 1	next_phase = 0	reward = -1.821372	array([[-4.9454346, -3.515818 ]], dtype=float32)

time = 46004	action = 0	current_phase = 0	next_phase = 1	reward = -0.252123	array([[-2.0387838, -3.1563575]], dtype=float32)

time = 46009	action = 0	current_phase = 0	next_phase = 1	reward = -0.168011	array([[-2.1097813, -2.7232866]], dtype=float32)

time = 46014	action = 1	current_phase = 0	next_phase = 1	reward = -0.365044	array([[-4.342781 , -2.5241175]], dtype=float32)

time = 46022	action = 0	current_phase = 1	next_phase = 0	reward = -0.617649	array([[-2.3053546, -3.0005064]], dtype=float32)

time = 46027	action = 0	current_phase = 1	next_phase = 0	reward = -0.463206	array([[-1.8127028, -3.274373 ]], dtype=float32)

time = 46032	action = 0	current_phase = 1	next_phase = 0	reward = -0.323374	array([[-2.12105  , -3.0774336]], dtype=float32)

time = 46037	action = 0	current_phase = 1	next_phase = 0	reward = -0.185166	array([[-2.2433429, -3.1929522]], dtype=float32)

time = 46042	action = 0	current_phase = 1	next_phase = 0	reward = 0.208976	array([[-2.6764398, -3.8858078]], dtype=float32)

time = 46047	action = 1	current_phase = 1	next_phase = 0	reward = -1.777583	array([[-5.992994 , -3.5320294]], dtype=float32)

time = 46055	action = 0	current_phase = 0	next_phase = 1	reward = -0.518288	array([[-2.1349225, -3.2171218]], dtype=float32)

time = 46060	action = 0	current_phase = 0	next_phase = 1	reward = -0.366710	array([[-1.8950206, -2.9114425]], dtype=float32)

time = 46065	action = 0	current_phase = 0	next_phase = 1	reward = -0.222451	array([[-1.8356589, -1.9409063]], dtype=float32)

time = 46070	action = 0	current_phase = 0	next_phase = 1	reward = 0.350148	array([[-2.3361583, -2.7242672]], dtype=float32)

time = 46075	action = 1	current_phase = 0	next_phase = 1	reward = -1.368729	array([[-4.431765 , -3.1574955]], dtype=float32)

time = 46083	action = 0	current_phase = 1	next_phase = 0	reward = -0.586411	array([[-2.2370985, -2.9855392]], dtype=float32)

time = 46088	action = 0	current_phase = 1	next_phase = 0	reward = -0.426093	array([[-2.1247137, -3.086896 ]], dtype=float32)

time = 46093	action = 0	current_phase = 1	next_phase = 0	reward = -0.280961	array([[-2.1331656, -3.0801535]], dtype=float32)

time = 46098	action = 0	current_phase = 1	next_phase = 0	reward = -0.168095	array([[-2.167575 , -3.2643216]], dtype=float32)

time = 46103	action = 1	current_phase = 1	next_phase = 0	reward = -1.896010	array([[-2.8310275, -2.8286748]], dtype=float32)

time = 46111	action = 0	current_phase = 0	next_phase = 1	reward = -1.713034	array([[-4.022676 , -4.1306734]], dtype=float32)

time = 46116	action = 1	current_phase = 0	next_phase = 1	reward = -1.759685	array([[-6.04772  , -3.4698617]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2098 - val_loss: 0.0622

Epoch 2/50

 - 4s - loss: 0.3941 - val_loss: 0.0595

Epoch 3/50

 - 4s - loss: 0.2886 - val_loss: 0.0601

Epoch 4/50

 - 4s - loss: 0.2666 - val_loss: 0.0805

Epoch 5/50

 - 4s - loss: 0.2592 - val_loss: 0.1222

Epoch 6/50

 - 4s - loss: 0.1378 - val_loss: 0.0796

Epoch 7/50

 - 4s - loss: 0.1848 - val_loss: 0.1102

Epoch 8/50

 - 4s - loss: 0.3367 - val_loss: 0.0830

Epoch 9/50

 - 4s - loss: 0.1285 - val_loss: 0.0813

Epoch 10/50

 - 4s - loss: 0.1293 - val_loss: 0.0684

Epoch 11/50

 - 4s - loss: 0.1244 - val_loss: 0.0748

Epoch 12/50

 - 4s - loss: 0.1617 - val_loss: 0.0868

length of memory (state 0, action 0): 1018, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1007, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1007, before forget

length of memory (state 1, action 1): 1000, after forget

time = 46124	action = 0	current_phase = 1	next_phase = 0	reward = -0.249610	array([[-1.8997396, -3.1635334]], dtype=float32)

time = 46129	action = 0	current_phase = 1	next_phase = 0	reward = -0.175030	array([[-2.2018619, -3.5258343]], dtype=float32)

time = 46134	action = 0	current_phase = 1	next_phase = 0	reward = -0.073150	array([[-2.4733589, -2.600715 ]], dtype=float32)

time = 46139	action = 1	current_phase = 1	next_phase = 0	reward = -2.014864	array([[-5.4876604, -3.6978498]], dtype=float32)

time = 46147	action = 0	current_phase = 0	next_phase = 1	reward = -0.485454	array([[-2.0850506, -3.216092 ]], dtype=float32)

time = 46152	action = 0	current_phase = 0	next_phase = 1	reward = -0.327173	array([[-1.9665145, -2.0562   ]], dtype=float32)

time = 46157	action = 0	current_phase = 0	next_phase = 1	reward = -0.178635	array([[-2.18797  , -2.9951394]], dtype=float32)

time = 46162	action = 0	current_phase = 0	next_phase = 1	reward = 0.250430	array([[-2.6402378, -2.7549653]], dtype=float32)

time = 46167	action = 1	current_phase = 0	next_phase = 1	reward = -1.726009	array([[-4.767401 , -3.2602484]], dtype=float32)

time = 46175	action = 0	current_phase = 1	next_phase = 0	reward = -0.516741	array([[-1.9976772, -2.92768  ]], dtype=float32)

time = 46180	action = 0	current_phase = 1	next_phase = 0	reward = -0.358929	array([[-1.8844775, -3.16378  ]], dtype=float32)

time = 46185	action = 0	current_phase = 1	next_phase = 0	reward = -0.214098	array([[-1.8902801, -3.1628242]], dtype=float32)

time = 46190	action = 0	current_phase = 1	next_phase = 0	reward = 0.354462	array([[-2.0232313, -3.810055 ]], dtype=float32)

time = 46195	action = 1	current_phase = 1	next_phase = 0	reward = -1.416965	array([[-3.606111 , -3.0592058]], dtype=float32)

time = 46203	action = 0	current_phase = 0	next_phase = 1	reward = -0.586166	array([[-2.3382273, -3.7516367]], dtype=float32)

time = 46208	action = 0	current_phase = 0	next_phase = 1	reward = -0.433716	array([[-1.8867849, -2.8778496]], dtype=float32)

time = 46213	action = 1	current_phase = 0	next_phase = 1	reward = -1.379306	array([[-1.94204  , -1.8255311]], dtype=float32)

time = 46221	action = 0	current_phase = 1	next_phase = 0	reward = 0.318377	array([[-1.7941492, -4.1573367]], dtype=float32)

time = 46226	action = 1	current_phase = 1	next_phase = 0	reward = -1.507089	array([[-4.4958515, -3.3036294]], dtype=float32)

time = 46234	action = 0	current_phase = 0	next_phase = 1	reward = -0.561688	array([[-2.1506166, -3.082623 ]], dtype=float32)

time = 46239	action = 0	current_phase = 0	next_phase = 1	reward = -0.397416	array([[-1.8877026, -2.877615 ]], dtype=float32)

time = 46244	action = 0	current_phase = 0	next_phase = 1	reward = -0.237373	array([[-1.8186301, -1.8758193]], dtype=float32)

time = 46249	action = 0	current_phase = 0	next_phase = 1	reward = -0.178088	array([[-2.1698482, -2.8195236]], dtype=float32)

time = 46254	action = 1	current_phase = 0	next_phase = 1	reward = -0.586679	array([[-4.48498  , -2.3806307]], dtype=float32)

time = 46262	action = 0	current_phase = 1	next_phase = 0	reward = -0.621233	array([[-2.3110993, -2.9846537]], dtype=float32)

time = 46267	action = 0	current_phase = 1	next_phase = 0	reward = -0.462401	array([[-2.129522 , -3.0754733]], dtype=float32)

time = 46272	action = 0	current_phase = 1	next_phase = 0	reward = -0.316873	array([[-2.128519 , -3.0758853]], dtype=float32)

time = 46277	action = 0	current_phase = 1	next_phase = 0	reward = -0.184274	array([[-2.2869034, -3.1933115]], dtype=float32)

time = 46282	action = 0	current_phase = 1	next_phase = 0	reward = 0.209175	array([[-2.5964348, -3.8096235]], dtype=float32)

time = 46287	action = 1	current_phase = 1	next_phase = 0	reward = -1.783590	array([[-6.026122 , -3.5187993]], dtype=float32)

time = 46295	action = 0	current_phase = 0	next_phase = 1	reward = -0.520388	array([[-2.0984254, -3.216884 ]], dtype=float32)

time = 46300	action = 0	current_phase = 0	next_phase = 1	reward = -0.358787	array([[-1.8863629, -2.8778114]], dtype=float32)

time = 46305	action = 0	current_phase = 0	next_phase = 1	reward = -0.210354	array([[-1.81843  , -1.8750306]], dtype=float32)

time = 46310	action = 0	current_phase = 0	next_phase = 1	reward = 0.042218	array([[-2.3241236, -3.1661735]], dtype=float32)

time = 46315	action = 1	current_phase = 0	next_phase = 1	reward = -1.141001	array([[-4.4653835, -2.7165577]], dtype=float32)

time = 46323	action = 0	current_phase = 1	next_phase = 0	reward = -0.586186	array([[-2.3120177, -2.9845343]], dtype=float32)

time = 46328	action = 0	current_phase = 1	next_phase = 0	reward = -0.435306	array([[-2.12157 , -3.078771]], dtype=float32)

time = 46333	action = 0	current_phase = 1	next_phase = 0	reward = -0.276123	array([[-2.1273687, -3.073794 ]], dtype=float32)

time = 46338	action = 0	current_phase = 1	next_phase = 0	reward = -0.158739	array([[-2.2463996, -3.2136323]], dtype=float32)

time = 46343	action = 0	current_phase = 1	next_phase = 0	reward = -0.040876	array([[-2.6378086, -3.1878006]], dtype=float32)

time = 46348	action = 1	current_phase = 1	next_phase = 0	reward = -1.907717	array([[-5.976229, -3.589941]], dtype=float32)

time = 46356	action = 0	current_phase = 0	next_phase = 1	reward = -0.506989	array([[-2.157647 , -3.1990051]], dtype=float32)

time = 46361	action = 0	current_phase = 0	next_phase = 1	reward = -0.349245	array([[-1.8835766, -2.8873408]], dtype=float32)

time = 46366	action = 0	current_phase = 0	next_phase = 1	reward = -0.200234	array([[-1.8284277, -1.9271249]], dtype=float32)

time = 46371	action = 1	current_phase = 0	next_phase = 1	reward = -1.130546	array([[-2.2860904, -1.7468959]], dtype=float32)

time = 46379	action = 0	current_phase = 1	next_phase = 0	reward = -1.592733	array([[-3.237363, -3.440203]], dtype=float32)

time = 46384	action = 1	current_phase = 1	next_phase = 0	reward = -1.888667	array([[-4.1645927, -3.555312 ]], dtype=float32)

time = 46392	action = 0	current_phase = 0	next_phase = 1	reward = -0.304868	array([[-2.0628963, -3.1706376]], dtype=float32)

time = 46397	action = 0	current_phase = 0	next_phase = 1	reward = -0.174787	array([[-2.0908973, -3.2304447]], dtype=float32)

time = 46402	action = 0	current_phase = 0	next_phase = 1	reward = 0.192895	array([[-2.3658   , -3.7894487]], dtype=float32)

time = 46407	action = 1	current_phase = 0	next_phase = 1	reward = -1.786068	array([[-5.4783764, -3.4203088]], dtype=float32)

time = 46415	action = 0	current_phase = 1	next_phase = 0	reward = -0.532116	array([[-2.0310187, -2.9640265]], dtype=float32)

time = 46420	action = 0	current_phase = 1	next_phase = 0	reward = -0.377069	array([[-1.9631195, -3.139058 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2068 - val_loss: 0.4153

Epoch 2/50

 - 4s - loss: 0.1780 - val_loss: 0.3504

Epoch 3/50

 - 4s - loss: 0.3128 - val_loss: 0.3417

Epoch 4/50

 - 4s - loss: 0.3385 - val_loss: 0.3342

Epoch 5/50

 - 4s - loss: 0.2310 - val_loss: 0.3311

Epoch 6/50

 - 4s - loss: 0.2049 - val_loss: 0.3471

Epoch 7/50

 - 4s - loss: 0.2340 - val_loss: 0.3395

Epoch 8/50

 - 4s - loss: 0.2591 - val_loss: 0.2772

Epoch 9/50

 - 4s - loss: 0.1729 - val_loss: 0.3171

Epoch 10/50

 - 4s - loss: 0.2477 - val_loss: 0.3153

Epoch 11/50

 - 4s - loss: 0.2807 - val_loss: 0.3087

Epoch 12/50

 - 4s - loss: 0.2031 - val_loss: 0.2726

Epoch 13/50

 - 4s - loss: 0.1787 - val_loss: 0.2547

Epoch 14/50

 - 4s - loss: 0.2250 - val_loss: 0.1941

Epoch 15/50

 - 4s - loss: 0.2449 - val_loss: 0.2416

Epoch 16/50

 - 4s - loss: 0.2458 - val_loss: 0.3431

Epoch 17/50

 - 4s - loss: 0.2032 - val_loss: 0.2605

Epoch 18/50

 - 4s - loss: 0.4041 - val_loss: 0.3071

Epoch 19/50

 - 4s - loss: 0.2423 - val_loss: 0.2048

Epoch 20/50

 - 4s - loss: 0.1866 - val_loss: 0.2744

Epoch 21/50

 - 4s - loss: 0.1648 - val_loss: 0.2285

Epoch 22/50

 - 4s - loss: 0.1643 - val_loss: 0.2466

Epoch 23/50

 - 4s - loss: 0.1557 - val_loss: 0.2609

Epoch 24/50

 - 4s - loss: 0.2173 - val_loss: 0.2221

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 46425	action = 0	current_phase = 1	next_phase = 0	reward = -0.224706	array([[-1.9835699, -3.1752512]], dtype=float32)

time = 46430	action = 0	current_phase = 1	next_phase = 0	reward = 0.369938	array([[-2.2113702, -3.9500735]], dtype=float32)

time = 46435	action = 1	current_phase = 1	next_phase = 0	reward = -1.303819	array([[-3.6276617, -3.0025842]], dtype=float32)

time = 46443	action = 0	current_phase = 0	next_phase = 1	reward = -0.584213	array([[-2.282133 , -3.7720902]], dtype=float32)

time = 46448	action = 0	current_phase = 0	next_phase = 1	reward = -0.431526	array([[-1.8891499, -2.837838 ]], dtype=float32)

time = 46453	action = 1	current_phase = 0	next_phase = 1	reward = -1.383013	array([[-1.9506966, -1.7510574]], dtype=float32)

time = 46461	action = 0	current_phase = 1	next_phase = 0	reward = 0.312042	array([[-1.791929, -4.154119]], dtype=float32)

time = 46466	action = 1	current_phase = 1	next_phase = 0	reward = -1.604562	array([[-3.8555567, -3.0510976]], dtype=float32)

time = 46474	action = 0	current_phase = 0	next_phase = 1	reward = -0.550395	array([[-2.0844777, -3.0283237]], dtype=float32)

time = 46479	action = 0	current_phase = 0	next_phase = 1	reward = -0.404131	array([[-1.8861613, -2.8422925]], dtype=float32)

time = 46484	action = 0	current_phase = 0	next_phase = 1	reward = -0.253193	array([[-1.8050108, -1.8253134]], dtype=float32)

time = 46489	action = 0	current_phase = 0	next_phase = 1	reward = -0.179098	array([[-2.190362, -2.785607]], dtype=float32)

time = 46494	action = 1	current_phase = 0	next_phase = 1	reward = -0.531474	array([[-4.549197 , -2.3375235]], dtype=float32)

time = 46502	action = 0	current_phase = 1	next_phase = 0	reward = -0.618081	array([[-2.3866982, -2.9842682]], dtype=float32)

time = 46507	action = 0	current_phase = 1	next_phase = 0	reward = -0.465224	array([[-2.2013004, -3.0883777]], dtype=float32)

time = 46512	action = 0	current_phase = 1	next_phase = 0	reward = -0.315159	array([[-2.197671 , -3.0848172]], dtype=float32)

time = 46517	action = 0	current_phase = 1	next_phase = 0	reward = -0.179647	array([[-2.2620666, -3.1891851]], dtype=float32)

time = 46522	action = 0	current_phase = 1	next_phase = 0	reward = 0.190873	array([[-2.6591666, -3.947554 ]], dtype=float32)

time = 46527	action = 1	current_phase = 1	next_phase = 0	reward = -1.727856	array([[-6.0744076, -3.524603 ]], dtype=float32)

time = 46535	action = 0	current_phase = 0	next_phase = 1	reward = -0.524424	array([[-2.0515094, -3.1735675]], dtype=float32)

time = 46540	action = 0	current_phase = 0	next_phase = 1	reward = -0.362752	array([[-1.8853623, -2.8397293]], dtype=float32)

time = 46545	action = 0	current_phase = 0	next_phase = 1	reward = -0.210636	array([[-1.7862282, -1.8363197]], dtype=float32)

time = 46550	action = 0	current_phase = 0	next_phase = 1	reward = 0.037532	array([[-2.238432 , -2.9811935]], dtype=float32)

time = 46555	action = 1	current_phase = 0	next_phase = 1	reward = -1.143099	array([[-4.432386 , -2.7387025]], dtype=float32)

time = 46563	action = 0	current_phase = 1	next_phase = 0	reward = -0.582623	array([[-2.3850758, -2.985792 ]], dtype=float32)

time = 46568	action = 0	current_phase = 1	next_phase = 0	reward = -0.418170	array([[-2.0753174, -3.1408534]], dtype=float32)

time = 46573	action = 0	current_phase = 1	next_phase = 0	reward = -0.263183	array([[-2.1744225, -3.0955179]], dtype=float32)

time = 46578	action = 0	current_phase = 1	next_phase = 0	reward = -0.159789	array([[-2.229909 , -3.1998687]], dtype=float32)

time = 46583	action = 0	current_phase = 1	next_phase = 0	reward = 0.067553	array([[-2.6802602, -3.4974089]], dtype=float32)

time = 46588	action = 1	current_phase = 1	next_phase = 0	reward = -1.900339	array([[-6.0862627, -3.5286539]], dtype=float32)

time = 46596	action = 0	current_phase = 0	next_phase = 1	reward = -0.494154	array([[-2.1074777, -3.170739 ]], dtype=float32)

time = 46601	action = 0	current_phase = 0	next_phase = 1	reward = -0.342631	array([[-1.8904178, -2.8378363]], dtype=float32)

time = 46606	action = 0	current_phase = 0	next_phase = 1	reward = -0.195730	array([[-1.7873877, -1.8479091]], dtype=float32)

time = 46611	action = 1	current_phase = 0	next_phase = 1	reward = -1.293811	array([[-2.2643797, -1.34963  ]], dtype=float32)

time = 46619	action = 1	current_phase = 1	next_phase = 0	reward = -2.006049	array([[-5.011554, -3.535656]], dtype=float32)

time = 46627	action = 0	current_phase = 0	next_phase = 1	reward = -0.457530	array([[-2.052233, -3.189905]], dtype=float32)

time = 46632	action = 1	current_phase = 0	next_phase = 1	reward = -1.422978	array([[-1.9495603, -1.7513101]], dtype=float32)

time = 46640	action = 0	current_phase = 1	next_phase = 0	reward = 0.346351	array([[-1.781256 , -3.9771795]], dtype=float32)

time = 46645	action = 0	current_phase = 1	next_phase = 0	reward = -0.901819	array([[-1.6047405, -3.0534396]], dtype=float32)

time = 46650	action = 0	current_phase = 1	next_phase = 0	reward = -1.742400	array([[ 0.7559699, -3.4002342]], dtype=float32)

time = 46655	action = 1	current_phase = 1	next_phase = 0	reward = -1.879685	array([[-5.1321745, -3.47047  ]], dtype=float32)

time = 46663	action = 0	current_phase = 0	next_phase = 1	reward = -0.294377	array([[-1.9287573, -2.8663857]], dtype=float32)

time = 46668	action = 0	current_phase = 0	next_phase = 1	reward = -0.165866	array([[-2.1933932, -3.0136013]], dtype=float32)

time = 46673	action = 0	current_phase = 0	next_phase = 1	reward = 0.037922	array([[-2.873054 , -3.6213872]], dtype=float32)

time = 46678	action = 1	current_phase = 0	next_phase = 1	reward = -1.898178	array([[-5.782876 , -3.4089282]], dtype=float32)

time = 46686	action = 0	current_phase = 1	next_phase = 0	reward = -0.491441	array([[-1.9594792, -3.1792634]], dtype=float32)

time = 46691	action = 0	current_phase = 1	next_phase = 0	reward = -0.340460	array([[-2.2125962, -3.0769596]], dtype=float32)

time = 46696	action = 0	current_phase = 1	next_phase = 0	reward = -0.191235	array([[-2.0338585, -3.1735432]], dtype=float32)

time = 46701	action = 0	current_phase = 1	next_phase = 0	reward = 0.303613	array([[-2.6426532, -3.940901 ]], dtype=float32)

time = 46706	action = 1	current_phase = 1	next_phase = 0	reward = -1.559061	array([[-3.9104414, -3.1958697]], dtype=float32)

time = 46714	action = 0	current_phase = 0	next_phase = 1	reward = -0.564259	array([[-2.1067767, -3.2491064]], dtype=float32)

time = 46719	action = 0	current_phase = 0	next_phase = 1	reward = -0.406476	array([[-1.8865173, -2.8397   ]], dtype=float32)

time = 46724	action = 0	current_phase = 0	next_phase = 1	reward = -0.255637	array([[-1.801992 , -1.8321803]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2973 - val_loss: 0.1795

Epoch 2/50

 - 4s - loss: 0.2554 - val_loss: 0.3170

Epoch 3/50

 - 4s - loss: 0.2610 - val_loss: 0.2226

Epoch 4/50

 - 4s - loss: 0.2301 - val_loss: 0.3301

Epoch 5/50

 - 4s - loss: 0.1745 - val_loss: 0.3438

Epoch 6/50

 - 4s - loss: 0.1765 - val_loss: 0.2965

Epoch 7/50

 - 4s - loss: 0.1877 - val_loss: 0.3236

Epoch 8/50

 - 4s - loss: 0.1922 - val_loss: 0.2984

Epoch 9/50

 - 4s - loss: 0.1660 - val_loss: 0.3629

Epoch 10/50

 - 4s - loss: 0.2486 - val_loss: 0.2546

Epoch 11/50

 - 4s - loss: 0.1680 - val_loss: 0.3290

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1007, before forget

length of memory (state 1, action 1): 1000, after forget

time = 46729	action = 0	current_phase = 0	next_phase = 1	reward = -0.172028	array([[-2.249056 , -2.7608404]], dtype=float32)

time = 46734	action = 1	current_phase = 0	next_phase = 1	reward = -0.487827	array([[-4.610742 , -2.3107011]], dtype=float32)

time = 46742	action = 0	current_phase = 1	next_phase = 0	reward = -0.619553	array([[-2.3372102, -3.0113516]], dtype=float32)

time = 46747	action = 0	current_phase = 1	next_phase = 0	reward = -0.466400	array([[-2.161057, -3.088993]], dtype=float32)

time = 46752	action = 0	current_phase = 1	next_phase = 0	reward = -0.304919	array([[-2.0757663, -3.1252985]], dtype=float32)

time = 46757	action = 0	current_phase = 1	next_phase = 0	reward = -0.174690	array([[-2.2540824, -3.2340837]], dtype=float32)

time = 46762	action = 0	current_phase = 1	next_phase = 0	reward = 0.173777	array([[-2.7052946, -3.9491925]], dtype=float32)

time = 46767	action = 1	current_phase = 1	next_phase = 0	reward = -1.733722	array([[-6.105807, -3.539102]], dtype=float32)

time = 46775	action = 0	current_phase = 0	next_phase = 1	reward = -0.525285	array([[-2.114431 , -3.1082206]], dtype=float32)

time = 46780	action = 0	current_phase = 0	next_phase = 1	reward = -0.369032	array([[-1.84027  , -2.7580407]], dtype=float32)

time = 46785	action = 1	current_phase = 0	next_phase = 1	reward = -1.314541	array([[-1.7521672, -1.4248595]], dtype=float32)

time = 46793	action = 0	current_phase = 1	next_phase = 0	reward = 0.015241	array([[ 1.4072354, -2.5038352]], dtype=float32)

time = 46798	action = 1	current_phase = 1	next_phase = 0	reward = -1.903419	array([[-4.9889855, -3.5973244]], dtype=float32)

time = 46806	action = 0	current_phase = 0	next_phase = 1	reward = -0.505236	array([[-2.1800246, -3.0667515]], dtype=float32)

time = 46811	action = 0	current_phase = 0	next_phase = 1	reward = -0.342970	array([[-1.8343008, -2.7572088]], dtype=float32)

time = 46816	action = 1	current_phase = 0	next_phase = 1	reward = -1.301183	array([[-1.7293408, -1.702665 ]], dtype=float32)

time = 46824	action = 0	current_phase = 1	next_phase = 0	reward = -0.071896	array([[ 1.02695  , -2.2078443]], dtype=float32)

time = 46829	action = 0	current_phase = 1	next_phase = 0	reward = -1.599047	array([[ 9.053204, -3.768053]], dtype=float32)

time = 46834	action = 1	current_phase = 1	next_phase = 0	reward = -1.909239	array([[-5.113157 , -3.4635215]], dtype=float32)

time = 46842	action = 0	current_phase = 0	next_phase = 1	reward = -0.310937	array([[-1.9826581, -2.8647   ]], dtype=float32)

time = 46847	action = 0	current_phase = 0	next_phase = 1	reward = -0.176230	array([[-1.9489903, -2.3664207]], dtype=float32)

time = 46852	action = 0	current_phase = 0	next_phase = 1	reward = 0.186544	array([[-2.7371812, -3.7660306]], dtype=float32)

time = 46857	action = 1	current_phase = 0	next_phase = 1	reward = -1.780663	array([[-5.519929 , -3.4091165]], dtype=float32)

time = 46865	action = 0	current_phase = 1	next_phase = 0	reward = -0.513751	array([[-1.97568  , -2.9712229]], dtype=float32)

time = 46870	action = 0	current_phase = 1	next_phase = 0	reward = -0.353883	array([[-1.9435855, -3.1749153]], dtype=float32)

time = 46875	action = 0	current_phase = 1	next_phase = 0	reward = -0.203591	array([[-1.9210702, -3.1844788]], dtype=float32)

time = 46880	action = 0	current_phase = 1	next_phase = 0	reward = 0.338753	array([[-2.2702992, -3.9634323]], dtype=float32)

time = 46885	action = 1	current_phase = 1	next_phase = 0	reward = -1.371120	array([[-3.6200411, -3.0034246]], dtype=float32)

time = 46893	action = 0	current_phase = 0	next_phase = 1	reward = -0.587534	array([[-2.3082912, -3.739089 ]], dtype=float32)

time = 46898	action = 0	current_phase = 0	next_phase = 1	reward = -0.425309	array([[-1.841264 , -2.7658768]], dtype=float32)

time = 46903	action = 1	current_phase = 0	next_phase = 1	reward = -1.357599	array([[-1.9381475, -1.6072625]], dtype=float32)

time = 46911	action = 0	current_phase = 1	next_phase = 0	reward = 0.268960	array([[-0.19181058, -4.5791144 ]], dtype=float32)

time = 46916	action = 1	current_phase = 1	next_phase = 0	reward = -1.611563	array([[-4.4174495, -3.2123966]], dtype=float32)

time = 46924	action = 0	current_phase = 0	next_phase = 1	reward = -0.561527	array([[-2.1747198, -2.9593763]], dtype=float32)

time = 46929	action = 0	current_phase = 0	next_phase = 1	reward = -0.399527	array([[-1.8491628, -2.7559803]], dtype=float32)

time = 46934	action = 1	current_phase = 0	next_phase = 1	reward = -1.343091	array([[-1.9369128, -1.6078174]], dtype=float32)

time = 46942	action = 0	current_phase = 1	next_phase = 0	reward = 0.201849	array([[-0.3606027, -4.444419 ]], dtype=float32)

time = 46947	action = 0	current_phase = 1	next_phase = 0	reward = -1.320160	array([[ 8.167714 , -3.6292806]], dtype=float32)

time = 46952	action = 1	current_phase = 1	next_phase = 0	reward = -2.019719	array([[-4.394374 , -3.5473843]], dtype=float32)

time = 46960	action = 0	current_phase = 0	next_phase = 1	reward = -0.374765	array([[-1.9492459, -3.1172202]], dtype=float32)

time = 46965	action = 1	current_phase = 0	next_phase = 1	reward = -1.320592	array([[-1.7533128, -1.5410342]], dtype=float32)

time = 46973	action = 0	current_phase = 1	next_phase = 0	reward = 0.027516	array([[ 0.04127392, -2.8893847 ]], dtype=float32)

time = 46978	action = 0	current_phase = 1	next_phase = 0	reward = -1.464107	array([[-0.37078613, -4.0014596 ]], dtype=float32)

time = 46983	action = 0	current_phase = 1	next_phase = 0	reward = -1.667044	array([[ 9.187557 , -3.7223182]], dtype=float32)

time = 46988	action = 1	current_phase = 1	next_phase = 0	reward = -1.718542	array([[-5.191386 , -3.3509107]], dtype=float32)

time = 46996	action = 0	current_phase = 0	next_phase = 1	reward = -0.210013	array([[-1.9431479, -3.004922 ]], dtype=float32)

time = 47001	action = 0	current_phase = 0	next_phase = 1	reward = 0.309455	array([[-2.2978199, -2.7573128]], dtype=float32)

time = 47006	action = 1	current_phase = 0	next_phase = 1	reward = -1.606656	array([[-4.8098516, -3.1657212]], dtype=float32)

time = 47014	action = 0	current_phase = 1	next_phase = 0	reward = -0.550589	array([[-2.047534 , -3.1846275]], dtype=float32)

time = 47019	action = 0	current_phase = 1	next_phase = 0	reward = -0.391568	array([[-1.931841 , -3.1744676]], dtype=float32)

time = 47024	action = 0	current_phase = 1	next_phase = 0	reward = -0.245961	array([[-1.9251515, -3.1805568]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2445 - val_loss: 0.4702

Epoch 2/50

 - 4s - loss: 0.2732 - val_loss: 0.4640

Epoch 3/50

 - 4s - loss: 0.2258 - val_loss: 0.4791

Epoch 4/50

 - 4s - loss: 0.2182 - val_loss: 0.4790

Epoch 5/50

 - 4s - loss: 0.2629 - val_loss: 0.4835

Epoch 6/50

 - 4s - loss: 0.1619 - val_loss: 0.5076

Epoch 7/50

 - 4s - loss: 0.1826 - val_loss: 0.4724

Epoch 8/50

 - 4s - loss: 0.1794 - val_loss: 0.4727

Epoch 9/50

 - 4s - loss: 0.1610 - val_loss: 0.4927

Epoch 10/50

 - 4s - loss: 0.1807 - val_loss: 0.5090

Epoch 11/50

 - 4s - loss: 0.1778 - val_loss: 0.4930

Epoch 12/50

 - 4s - loss: 0.1573 - val_loss: 0.6136

length of memory (state 0, action 0): 1015, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1008, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1007, before forget

length of memory (state 1, action 1): 1000, after forget

time = 47029	action = 0	current_phase = 1	next_phase = 0	reward = -0.186523	array([[-2.0090477, -3.8333201]], dtype=float32)

time = 47034	action = 1	current_phase = 1	next_phase = 0	reward = -0.558283	array([[-2.7936902, -2.316278 ]], dtype=float32)

time = 47042	action = 0	current_phase = 0	next_phase = 1	reward = -0.606081	array([[-2.2208838, -3.7317524]], dtype=float32)

time = 47047	action = 0	current_phase = 0	next_phase = 1	reward = -0.452821	array([[-1.8752191, -2.7540555]], dtype=float32)

time = 47052	action = 1	current_phase = 0	next_phase = 1	reward = -1.405369	array([[-2.0798028, -1.7029554]], dtype=float32)

time = 47060	action = 0	current_phase = 1	next_phase = 0	reward = 0.343710	array([[-1.723739 , -4.0134516]], dtype=float32)

time = 47065	action = 1	current_phase = 1	next_phase = 0	reward = -1.368548	array([[-4.0611944, -2.7445855]], dtype=float32)

time = 47073	action = 0	current_phase = 0	next_phase = 1	reward = -0.592576	array([[-1.9831468, -2.9979706]], dtype=float32)

time = 47078	action = 0	current_phase = 0	next_phase = 1	reward = -0.438680	array([[-1.8652214, -2.7531333]], dtype=float32)

time = 47083	action = 1	current_phase = 0	next_phase = 1	reward = -1.392826	array([[-2.08178  , -1.6921741]], dtype=float32)

time = 47091	action = 0	current_phase = 1	next_phase = 0	reward = 0.307139	array([[-1.9814785, -4.1885858]], dtype=float32)

time = 47096	action = 1	current_phase = 1	next_phase = 0	reward = -1.555691	array([[-4.7014413, -3.3314717]], dtype=float32)

time = 47104	action = 0	current_phase = 0	next_phase = 1	reward = -0.553225	array([[-1.9665995, -2.9968894]], dtype=float32)

time = 47109	action = 0	current_phase = 0	next_phase = 1	reward = -0.396121	array([[-1.8216753, -2.7703295]], dtype=float32)

time = 47114	action = 1	current_phase = 0	next_phase = 1	reward = -1.339535	array([[-2.068029 , -1.6969337]], dtype=float32)

time = 47122	action = 0	current_phase = 1	next_phase = 0	reward = 0.236523	array([[ 0.19521554, -4.574996  ]], dtype=float32)

time = 47127	action = 1	current_phase = 1	next_phase = 0	reward = -1.780650	array([[-4.1680565, -3.419658 ]], dtype=float32)

time = 47135	action = 0	current_phase = 0	next_phase = 1	reward = -0.525553	array([[-1.9686298, -3.0687313]], dtype=float32)

time = 47140	action = 0	current_phase = 0	next_phase = 1	reward = -0.364500	array([[-1.8207918, -2.7665355]], dtype=float32)

time = 47145	action = 1	current_phase = 0	next_phase = 1	reward = -1.307129	array([[-1.9483047, -1.7407093]], dtype=float32)

time = 47153	action = 0	current_phase = 1	next_phase = 0	reward = 0.082311	array([[-1.875392, -3.44442 ]], dtype=float32)

time = 47158	action = 1	current_phase = 1	next_phase = 0	reward = -1.891143	array([[-4.5296097, -3.6581538]], dtype=float32)

time = 47166	action = 0	current_phase = 0	next_phase = 1	reward = -0.492296	array([[-2.0257835, -3.1038332]], dtype=float32)

time = 47171	action = 0	current_phase = 0	next_phase = 1	reward = -0.342381	array([[-1.8215818, -2.7663345]], dtype=float32)

time = 47176	action = 1	current_phase = 0	next_phase = 1	reward = -1.311698	array([[-1.9495715, -1.7470119]], dtype=float32)

time = 47184	action = 0	current_phase = 1	next_phase = 0	reward = -0.027420	array([[ 1.1322576, -2.2630339]], dtype=float32)

time = 47189	action = 1	current_phase = 1	next_phase = 0	reward = -2.007342	array([[-4.9466176, -3.517913 ]], dtype=float32)

time = 47197	action = 0	current_phase = 0	next_phase = 1	reward = -0.470661	array([[-1.9592793, -3.1047125]], dtype=float32)

time = 47202	action = 1	current_phase = 0	next_phase = 1	reward = -1.418015	array([[-2.0775568, -1.6942558]], dtype=float32)

time = 47210	action = 0	current_phase = 1	next_phase = 0	reward = 0.356980	array([[-1.9874984, -4.1903725]], dtype=float32)

time = 47215	action = 0	current_phase = 1	next_phase = 0	reward = -0.843317	array([[-1.1501833, -2.4827323]], dtype=float32)

time = 47220	action = 0	current_phase = 1	next_phase = 0	reward = -1.725425	array([[-3.0246975, -3.5096154]], dtype=float32)

time = 47225	action = 1	current_phase = 1	next_phase = 0	reward = -1.830159	array([[-5.172333 , -3.3870459]], dtype=float32)

time = 47233	action = 0	current_phase = 0	next_phase = 1	reward = -0.259884	array([[-1.8104458, -2.761782 ]], dtype=float32)

time = 47238	action = 0	current_phase = 0	next_phase = 1	reward = -0.167056	array([[-2.2605212, -2.9180262]], dtype=float32)

time = 47243	action = 1	current_phase = 0	next_phase = 1	reward = -1.159358	array([[-2.6751077, -2.1661446]], dtype=float32)

time = 47251	action = 0	current_phase = 1	next_phase = 0	reward = -1.174556	array([[-1.4417382, -3.4901624]], dtype=float32)

time = 47256	action = 0	current_phase = 1	next_phase = 0	reward = -1.035158	array([[-2.9952314, -3.1152978]], dtype=float32)

time = 47261	action = 0	current_phase = 1	next_phase = 0	reward = -0.909223	array([[-2.8715336, -3.2711945]], dtype=float32)

time = 47266	action = 0	current_phase = 1	next_phase = 0	reward = -0.788546	array([[-2.3067849, -3.2183185]], dtype=float32)

time = 47271	action = 0	current_phase = 1	next_phase = 0	reward = -0.317534	array([[-2.8832793, -3.7217326]], dtype=float32)

time = 47276	action = 1	current_phase = 1	next_phase = 0	reward = -1.690315	array([[-6.107022 , -3.5119176]], dtype=float32)

time = 47284	action = 0	current_phase = 0	next_phase = 1	reward = -0.557383	array([[-2.1606452, -3.4317126]], dtype=float32)

time = 47289	action = 0	current_phase = 0	next_phase = 1	reward = -0.410706	array([[-1.8209586, -2.7676103]], dtype=float32)

time = 47294	action = 1	current_phase = 0	next_phase = 1	reward = -1.359113	array([[-1.9588058, -1.7421231]], dtype=float32)

time = 47302	action = 0	current_phase = 1	next_phase = 0	reward = 0.210398	array([[ 0.26283976, -4.585504  ]], dtype=float32)

time = 47307	action = 0	current_phase = 1	next_phase = 0	reward = -1.266179	array([[ 3.671373, -3.705728]], dtype=float32)

time = 47312	action = 0	current_phase = 1	next_phase = 0	reward = -1.695550	array([[-1.7754614, -3.3471208]], dtype=float32)

time = 47317	action = 1	current_phase = 1	next_phase = 0	reward = -1.749884	array([[-5.274265 , -3.3485034]], dtype=float32)

time = 47325	action = 0	current_phase = 0	next_phase = 1	reward = -0.213996	array([[-1.7171872, -2.987567 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1727 - val_loss: 0.3786

Epoch 2/50

 - 4s - loss: 0.1811 - val_loss: 0.3474

Epoch 3/50

 - 4s - loss: 0.1552 - val_loss: 0.3834

Epoch 4/50

 - 4s - loss: 0.0964 - val_loss: 0.4447

Epoch 5/50

 - 4s - loss: 0.1019 - val_loss: 0.3379

Epoch 6/50

 - 4s - loss: 0.1113 - val_loss: 0.3460

Epoch 7/50

 - 4s - loss: 0.0923 - val_loss: 0.3297

Epoch 8/50

 - 4s - loss: 0.0811 - val_loss: 0.3655

Epoch 9/50

 - 4s - loss: 0.1107 - val_loss: 0.4033

Epoch 10/50

 - 4s - loss: 0.1380 - val_loss: 0.3482

Epoch 11/50

 - 4s - loss: 0.0802 - val_loss: 0.3041

Epoch 12/50

 - 4s - loss: 0.1320 - val_loss: 0.3215

Epoch 13/50

 - 4s - loss: 0.1084 - val_loss: 0.3334

Epoch 14/50

 - 4s - loss: 0.0705 - val_loss: 0.3558

Epoch 15/50

 - 4s - loss: 0.0892 - val_loss: 0.3875

Epoch 16/50

 - 4s - loss: 0.1027 - val_loss: 0.4426

Epoch 17/50

 - 4s - loss: 0.1140 - val_loss: 0.3104

Epoch 18/50

 - 4s - loss: 0.0798 - val_loss: 0.3448

Epoch 19/50

 - 4s - loss: 0.0839 - val_loss: 0.3341

Epoch 20/50

 - 4s - loss: 0.1836 - val_loss: 0.3593

Epoch 21/50

 - 4s - loss: 0.0790 - val_loss: 0.3131

length of memory (state 0, action 0): 1016, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1008, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1017, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1009, before forget

length of memory (state 1, action 1): 1000, after forget

time = 47330	action = 0	current_phase = 0	next_phase = 1	reward = 0.354440	array([[-1.9353113, -1.990836 ]], dtype=float32)

time = 47335	action = 1	current_phase = 0	next_phase = 1	reward = -1.313943	array([[-4.777632 , -3.0226216]], dtype=float32)

time = 47343	action = 0	current_phase = 1	next_phase = 0	reward = -0.591501	array([[-2.2773066, -2.994959 ]], dtype=float32)

time = 47348	action = 0	current_phase = 1	next_phase = 0	reward = -0.439514	array([[-2.133861 , -3.0430782]], dtype=float32)

time = 47353	action = 0	current_phase = 1	next_phase = 0	reward = -0.281638	array([[-2.1333025, -3.0430977]], dtype=float32)

time = 47358	action = 0	current_phase = 1	next_phase = 0	reward = -0.164328	array([[-2.2687511, -3.225886 ]], dtype=float32)

time = 47363	action = 1	current_phase = 1	next_phase = 0	reward = -0.943541	array([[-2.6928551, -2.6380496]], dtype=float32)

time = 47371	action = 0	current_phase = 0	next_phase = 1	reward = -1.172594	array([[-2.470085, -3.889806]], dtype=float32)

time = 47376	action = 1	current_phase = 0	next_phase = 1	reward = -1.762628	array([[-4.0549955, -2.5909195]], dtype=float32)

time = 47384	action = 0	current_phase = 1	next_phase = 0	reward = -0.244905	array([[-2.0009344, -3.1469855]], dtype=float32)

time = 47389	action = 0	current_phase = 1	next_phase = 0	reward = -0.180224	array([[-2.1025198, -3.7811885]], dtype=float32)

time = 47394	action = 0	current_phase = 1	next_phase = 0	reward = -0.145134	array([[-2.2427344, -2.2717338]], dtype=float32)

time = 47399	action = 1	current_phase = 1	next_phase = 0	reward = -1.998515	array([[-5.6448865, -3.6486309]], dtype=float32)

time = 47407	action = 0	current_phase = 0	next_phase = 1	reward = -0.455687	array([[-1.8684745, -3.1427555]], dtype=float32)

time = 47412	action = 1	current_phase = 0	next_phase = 1	reward = -1.396866	array([[-2.0319726, -1.9283047]], dtype=float32)

time = 47420	action = 0	current_phase = 1	next_phase = 0	reward = 0.337458	array([[-2.0801322, -4.079025 ]], dtype=float32)

time = 47425	action = 0	current_phase = 1	next_phase = 0	reward = -0.851248	array([[-1.7570363, -2.8572857]], dtype=float32)

time = 47430	action = 1	current_phase = 1	next_phase = 0	reward = -2.099003	array([[-4.76284 , -3.595101]], dtype=float32)

time = 47438	action = 0	current_phase = 0	next_phase = 1	reward = -0.420385	array([[-1.8371098, -3.1290252]], dtype=float32)

time = 47443	action = 1	current_phase = 0	next_phase = 1	reward = -1.356110	array([[-2.0382528, -1.9036971]], dtype=float32)

time = 47451	action = 0	current_phase = 1	next_phase = 0	reward = 0.290336	array([[-2.3242126, -4.0900197]], dtype=float32)

time = 47456	action = 0	current_phase = 1	next_phase = 0	reward = -1.118375	array([[-2.5108457e-03, -3.2261844e+00]], dtype=float32)

time = 47461	action = 0	current_phase = 1	next_phase = 0	reward = -1.719654	array([[ 8.669351 , -3.8183653]], dtype=float32)

time = 47466	action = 1	current_phase = 1	next_phase = 0	reward = -1.811391	array([[-5.029396 , -3.4080064]], dtype=float32)

time = 47474	action = 0	current_phase = 0	next_phase = 1	reward = -0.243783	array([[-1.766531 , -2.9453514]], dtype=float32)

time = 47479	action = 0	current_phase = 0	next_phase = 1	reward = -0.172117	array([[-2.1079392, -2.7011356]], dtype=float32)

time = 47484	action = 1	current_phase = 0	next_phase = 1	reward = -0.485947	array([[-4.486801 , -1.7774866]], dtype=float32)

time = 47492	action = 0	current_phase = 1	next_phase = 0	reward = -0.622247	array([[-2.2883494, -2.9904306]], dtype=float32)

time = 47497	action = 0	current_phase = 1	next_phase = 0	reward = -0.473236	array([[-2.165951 , -3.0416245]], dtype=float32)

time = 47502	action = 0	current_phase = 1	next_phase = 0	reward = -0.326665	array([[-2.131168 , -3.0265517]], dtype=float32)

time = 47507	action = 0	current_phase = 1	next_phase = 0	reward = -0.186040	array([[-2.3120708, -3.1842322]], dtype=float32)

time = 47512	action = 0	current_phase = 1	next_phase = 0	reward = 0.279146	array([[-2.7102697, -3.8296306]], dtype=float32)

time = 47517	action = 1	current_phase = 1	next_phase = 0	reward = -1.774242	array([[-6.0951858, -3.5161211]], dtype=float32)

time = 47525	action = 0	current_phase = 0	next_phase = 1	reward = -0.510799	array([[-1.9851736, -3.1372669]], dtype=float32)

time = 47530	action = 0	current_phase = 0	next_phase = 1	reward = -0.353985	array([[-1.7442586, -2.808996 ]], dtype=float32)

time = 47535	action = 1	current_phase = 0	next_phase = 1	reward = -1.303749	array([[-1.92521  , -1.8615716]], dtype=float32)

time = 47543	action = 0	current_phase = 1	next_phase = 0	reward = 0.041147	array([[-0.58075166, -2.6400392 ]], dtype=float32)

time = 47548	action = 1	current_phase = 1	next_phase = 0	reward = -1.896544	array([[-5.140953 , -3.5554862]], dtype=float32)

time = 47556	action = 0	current_phase = 0	next_phase = 1	reward = -0.492648	array([[-1.958089, -3.122193]], dtype=float32)

time = 47561	action = 0	current_phase = 0	next_phase = 1	reward = -0.339852	array([[-1.7519099, -2.8202584]], dtype=float32)

time = 47566	action = 1	current_phase = 0	next_phase = 1	reward = -1.305393	array([[-1.9249122, -1.8654072]], dtype=float32)

time = 47574	action = 0	current_phase = 1	next_phase = 0	reward = -0.136882	array([[ 1.0918843, -2.3355715]], dtype=float32)

time = 47579	action = 1	current_phase = 1	next_phase = 0	reward = -2.008593	array([[-4.5599623, -3.5505564]], dtype=float32)

time = 47587	action = 0	current_phase = 0	next_phase = 1	reward = -0.473827	array([[-1.8953156, -3.1420705]], dtype=float32)

time = 47592	action = 1	current_phase = 0	next_phase = 1	reward = -1.448661	array([[-2.0134778, -1.9470376]], dtype=float32)

time = 47600	action = 0	current_phase = 1	next_phase = 0	reward = 0.082720	array([[-2.1922045, -4.1897154]], dtype=float32)

time = 47605	action = 0	current_phase = 1	next_phase = 0	reward = -0.444422	array([[ 0.7662423, -2.4654098]], dtype=float32)

time = 47610	action = 0	current_phase = 1	next_phase = 0	reward = -1.722317	array([[ 7.7175164, -3.9122777]], dtype=float32)

time = 47615	action = 1	current_phase = 1	next_phase = 0	reward = -1.840098	array([[-5.223616 , -3.3674908]], dtype=float32)

time = 47623	action = 0	current_phase = 0	next_phase = 1	reward = -0.262436	array([[-1.8830395, -2.98333  ]], dtype=float32)

time = 47628	action = 0	current_phase = 0	next_phase = 1	reward = -0.164477	array([[-2.112691, -2.557337]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.3328 - val_loss: 0.1959

Epoch 2/50

 - 4s - loss: 0.3496 - val_loss: 0.1975

Epoch 3/50

 - 4s - loss: 0.3416 - val_loss: 0.1989

Epoch 4/50

 - 4s - loss: 0.2693 - val_loss: 0.1926

Epoch 5/50

 - 4s - loss: 0.3382 - val_loss: 0.1995

Epoch 6/50

 - 4s - loss: 0.1544 - val_loss: 0.1978

Epoch 7/50

 - 4s - loss: 0.2351 - val_loss: 0.1880

Epoch 8/50

 - 4s - loss: 0.2795 - val_loss: 0.1957

Epoch 9/50

 - 4s - loss: 0.2500 - val_loss: 0.1869

Epoch 10/50

 - 4s - loss: 0.1578 - val_loss: 0.1856

Epoch 11/50

 - 4s - loss: 0.1427 - val_loss: 0.1941

Epoch 12/50

 - 4s - loss: 0.1446 - val_loss: 0.2081

Epoch 13/50

 - 4s - loss: 0.1789 - val_loss: 0.2692

Epoch 14/50

 - 4s - loss: 0.2856 - val_loss: 0.2927

Epoch 15/50

 - 4s - loss: 0.1155 - val_loss: 0.2652

Epoch 16/50

 - 4s - loss: 0.1298 - val_loss: 0.2364

Epoch 17/50

 - 4s - loss: 0.1548 - val_loss: 0.2518

Epoch 18/50

 - 4s - loss: 0.1152 - val_loss: 0.2307

Epoch 19/50

 - 4s - loss: 0.1355 - val_loss: 0.1897

Epoch 20/50

 - 4s - loss: 0.1425 - val_loss: 0.2596

length of memory (state 0, action 0): 1013, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1008, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1008, before forget

length of memory (state 1, action 1): 1000, after forget

time = 47633	action = 1	current_phase = 0	next_phase = 1	reward = -1.029679	array([[-1.9862591, -1.6175867]], dtype=float32)

time = 47641	action = 1	current_phase = 1	next_phase = 0	reward = -1.999099	array([[-3.494367, -3.480438]], dtype=float32)

time = 47649	action = 1	current_phase = 0	next_phase = 1	reward = -1.574736	array([[-1.9871628, -1.8554306]], dtype=float32)

time = 47657	action = 0	current_phase = 1	next_phase = 0	reward = -0.172708	array([[-2.2596083, -3.1967635]], dtype=float32)

time = 47662	action = 0	current_phase = 1	next_phase = 0	reward = 0.190510	array([[-2.5994797, -3.8401597]], dtype=float32)

time = 47667	action = 1	current_phase = 1	next_phase = 0	reward = -1.731630	array([[-4.067175 , -3.9785457]], dtype=float32)

time = 47675	action = 0	current_phase = 0	next_phase = 1	reward = -0.528206	array([[-2.0255318, -2.880994 ]], dtype=float32)

time = 47680	action = 0	current_phase = 0	next_phase = 1	reward = -0.374566	array([[-1.7868975, -2.784425 ]], dtype=float32)

time = 47685	action = 1	current_phase = 0	next_phase = 1	reward = -1.313883	array([[-1.9862723, -1.8369393]], dtype=float32)

time = 47693	action = 0	current_phase = 1	next_phase = 0	reward = 0.126724	array([[-1.8687671, -3.6143937]], dtype=float32)

time = 47698	action = 0	current_phase = 1	next_phase = 0	reward = -1.456751	array([[ 1.8271127, -3.6249583]], dtype=float32)

time = 47703	action = 1	current_phase = 1	next_phase = 0	reward = -1.961837	array([[-4.3742294, -3.4647405]], dtype=float32)

time = 47711	action = 0	current_phase = 0	next_phase = 1	reward = -0.352978	array([[-1.8698128, -2.9976335]], dtype=float32)

time = 47716	action = 1	current_phase = 0	next_phase = 1	reward = -1.322576	array([[-1.9838816, -1.8531203]], dtype=float32)

time = 47724	action = 0	current_phase = 1	next_phase = 0	reward = -0.034965	array([[-0.04966133, -2.1581686 ]], dtype=float32)

time = 47729	action = 0	current_phase = 1	next_phase = 0	reward = -1.593153	array([[-2.376396 , -3.8915093]], dtype=float32)

time = 47734	action = 0	current_phase = 1	next_phase = 0	reward = -1.639629	array([[ 7.948636 , -3.6948247]], dtype=float32)

time = 47739	action = 1	current_phase = 1	next_phase = 0	reward = -1.659745	array([[-5.2364798, -3.3408177]], dtype=float32)

time = 47747	action = 0	current_phase = 0	next_phase = 1	reward = -0.180551	array([[-1.9108666, -2.9290059]], dtype=float32)

time = 47752	action = 0	current_phase = 0	next_phase = 1	reward = 0.252405	array([[-2.3980165, -3.5790896]], dtype=float32)

time = 47757	action = 1	current_phase = 0	next_phase = 1	reward = -1.726097	array([[-4.9086533, -3.0676224]], dtype=float32)

time = 47765	action = 0	current_phase = 1	next_phase = 0	reward = -0.528168	array([[-2.0143561, -3.0564592]], dtype=float32)

time = 47770	action = 0	current_phase = 1	next_phase = 0	reward = -0.379093	array([[-1.8938897, -3.129571 ]], dtype=float32)

time = 47775	action = 0	current_phase = 1	next_phase = 0	reward = -0.212933	array([[-1.8874545, -3.1352239]], dtype=float32)

time = 47780	action = 0	current_phase = 1	next_phase = 0	reward = 0.357591	array([[-2.0211256, -3.9206212]], dtype=float32)

time = 47785	action = 1	current_phase = 1	next_phase = 0	reward = -1.313615	array([[-3.8172565, -3.2250836]], dtype=float32)

time = 47793	action = 0	current_phase = 0	next_phase = 1	reward = -0.586371	array([[-2.275164, -3.681661]], dtype=float32)

time = 47798	action = 0	current_phase = 0	next_phase = 1	reward = -0.438993	array([[-1.7872171, -2.786764 ]], dtype=float32)

time = 47803	action = 1	current_phase = 0	next_phase = 1	reward = -1.383660	array([[-2.0839803, -2.0401075]], dtype=float32)

time = 47811	action = 0	current_phase = 1	next_phase = 0	reward = 0.286763	array([[-1.852892 , -4.2276154]], dtype=float32)

time = 47816	action = 1	current_phase = 1	next_phase = 0	reward = -1.612522	array([[-3.8648155, -3.4455328]], dtype=float32)

time = 47824	action = 0	current_phase = 0	next_phase = 1	reward = -0.561396	array([[-2.0095348, -2.98845  ]], dtype=float32)

time = 47829	action = 0	current_phase = 0	next_phase = 1	reward = -0.402522	array([[-1.7870063, -2.7846975]], dtype=float32)

time = 47834	action = 1	current_phase = 0	next_phase = 1	reward = -1.339758	array([[-2.0754795, -2.0217087]], dtype=float32)

time = 47842	action = 0	current_phase = 1	next_phase = 0	reward = 0.205373	array([[-1.9787173, -4.1805463]], dtype=float32)

time = 47847	action = 1	current_phase = 1	next_phase = 0	reward = -1.734500	array([[-4.872984 , -3.4633298]], dtype=float32)

time = 47855	action = 0	current_phase = 0	next_phase = 1	reward = -0.536779	array([[-2.0001504, -3.09056  ]], dtype=float32)

time = 47860	action = 0	current_phase = 0	next_phase = 1	reward = -0.392613	array([[-1.78689  , -2.7844603]], dtype=float32)

time = 47865	action = 1	current_phase = 0	next_phase = 1	reward = -1.334647	array([[-1.9842626, -1.83032  ]], dtype=float32)

time = 47873	action = 0	current_phase = 1	next_phase = 0	reward = 0.161678	array([[-0.96799576, -4.008601  ]], dtype=float32)

time = 47878	action = 0	current_phase = 1	next_phase = 0	reward = -1.456594	array([[-2.225118 , -3.5859027]], dtype=float32)

time = 47883	action = 1	current_phase = 1	next_phase = 0	reward = -1.951471	array([[-4.3553095, -3.4646537]], dtype=float32)

time = 47891	action = 0	current_phase = 0	next_phase = 1	reward = -0.332133	array([[-1.9663149, -3.060925 ]], dtype=float32)

time = 47896	action = 1	current_phase = 0	next_phase = 1	reward = -1.300717	array([[-1.9864564, -1.8379166]], dtype=float32)

time = 47904	action = 0	current_phase = 1	next_phase = 0	reward = -0.085367	array([[ 0.54002243, -2.203263  ]], dtype=float32)

time = 47909	action = 0	current_phase = 1	next_phase = 0	reward = -1.599368	array([[ 7.0252647, -4.382265 ]], dtype=float32)

time = 47914	action = 0	current_phase = 1	next_phase = 0	reward = -1.638542	array([[ 4.869878 , -3.4346879]], dtype=float32)

time = 47919	action = 1	current_phase = 1	next_phase = 0	reward = -1.666291	array([[-5.3193007, -3.3250856]], dtype=float32)

time = 47927	action = 0	current_phase = 0	next_phase = 1	reward = -0.184649	array([[-2.005956 , -2.9922085]], dtype=float32)

time = 47932	action = 0	current_phase = 0	next_phase = 1	reward = 0.257660	array([[-2.3027723, -2.9692152]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.4744 - val_loss: 0.3942

Epoch 2/50

 - 4s - loss: 0.4390 - val_loss: 0.3897

Epoch 3/50

 - 4s - loss: 0.3388 - val_loss: 0.4010

Epoch 4/50

 - 4s - loss: 0.3408 - val_loss: 0.4014

Epoch 5/50

 - 4s - loss: 0.3869 - val_loss: 0.3986

Epoch 6/50

 - 4s - loss: 0.3129 - val_loss: 0.4015

Epoch 7/50

 - 4s - loss: 0.3071 - val_loss: 0.3865

Epoch 8/50

 - 4s - loss: 0.2476 - val_loss: 0.3972

Epoch 9/50

 - 4s - loss: 0.3685 - val_loss: 0.3768

Epoch 10/50

 - 4s - loss: 0.3383 - val_loss: 0.3844

Epoch 11/50

 - 4s - loss: 0.2244 - val_loss: 0.4030

Epoch 12/50

 - 4s - loss: 0.1793 - val_loss: 0.3993

Epoch 13/50

 - 4s - loss: 0.1970 - val_loss: 0.3614

Epoch 14/50

 - 4s - loss: 0.2078 - val_loss: 0.3705

Epoch 15/50

 - 4s - loss: 0.1734 - val_loss: 0.3861

Epoch 16/50

 - 4s - loss: 0.2645 - val_loss: 0.3708

Epoch 17/50

 - 4s - loss: 0.1857 - val_loss: 0.3539

Epoch 18/50

 - 4s - loss: 0.1508 - val_loss: 0.3435

Epoch 19/50

 - 4s - loss: 0.1354 - val_loss: 0.3344

Epoch 20/50

 - 4s - loss: 0.1408 - val_loss: 0.3206

Epoch 21/50

 - 4s - loss: 0.1661 - val_loss: 0.2671

Epoch 22/50

 - 4s - loss: 0.1561 - val_loss: 0.3050

Epoch 23/50

 - 4s - loss: 0.1218 - val_loss: 0.3125

Epoch 24/50

 - 4s - loss: 0.1803 - val_loss: 0.3141

Epoch 25/50

 - 4s - loss: 0.1458 - val_loss: 0.2975

Epoch 26/50

 - 4s - loss: 0.1290 - val_loss: 0.2306

Epoch 27/50

 - 4s - loss: 0.2420 - val_loss: 0.2452

Epoch 28/50

 - 4s - loss: 0.1640 - val_loss: 0.2600

Epoch 29/50

 - 4s - loss: 0.2154 - val_loss: 0.2787

Epoch 30/50

 - 4s - loss: 0.1462 - val_loss: 0.2646

Epoch 31/50

 - 4s - loss: 0.1543 - val_loss: 0.2525

Epoch 32/50

 - 4s - loss: 0.1732 - val_loss: 0.2445

Epoch 33/50

 - 4s - loss: 0.1858 - val_loss: 0.2622

Epoch 34/50

 - 4s - loss: 0.1321 - val_loss: 0.3036

Epoch 35/50

 - 4s - loss: 0.1312 - val_loss: 0.2672

Epoch 36/50

 - 4s - loss: 0.1721 - val_loss: 0.2684

length of memory (state 0, action 0): 1014, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1009, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1018, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1009, before forget

length of memory (state 1, action 1): 1000, after forget

time = 47937	action = 1	current_phase = 0	next_phase = 1	reward = -1.779765	array([[-4.5066476, -2.5816228]], dtype=float32)

time = 47945	action = 0	current_phase = 1	next_phase = 0	reward = -0.530500	array([[-2.0496678, -3.0469124]], dtype=float32)

time = 47950	action = 0	current_phase = 1	next_phase = 0	reward = -0.382830	array([[-2.004179, -3.104678]], dtype=float32)

time = 47955	action = 0	current_phase = 1	next_phase = 0	reward = -0.242268	array([[-1.9872041, -3.1217983]], dtype=float32)

time = 47960	action = 0	current_phase = 1	next_phase = 0	reward = 0.065683	array([[-2.1197648, -3.9599311]], dtype=float32)

time = 47965	action = 1	current_phase = 1	next_phase = 0	reward = -1.082203	array([[-3.319794 , -2.7577891]], dtype=float32)

time = 47973	action = 0	current_phase = 0	next_phase = 1	reward = -0.587474	array([[-2.2281396, -3.685494 ]], dtype=float32)

time = 47978	action = 0	current_phase = 0	next_phase = 1	reward = -0.428721	array([[-1.79983 , -2.744186]], dtype=float32)

time = 47983	action = 1	current_phase = 0	next_phase = 1	reward = -1.378769	array([[-2.0964525, -2.0681705]], dtype=float32)

time = 47991	action = 0	current_phase = 1	next_phase = 0	reward = 0.292984	array([[-1.9826615, -4.272692 ]], dtype=float32)

time = 47996	action = 1	current_phase = 1	next_phase = 0	reward = -1.610584	array([[-4.569214 , -3.4837637]], dtype=float32)

time = 48004	action = 0	current_phase = 0	next_phase = 1	reward = -0.547128	array([[-2.0219514, -2.9933424]], dtype=float32)

time = 48009	action = 0	current_phase = 0	next_phase = 1	reward = -0.378781	array([[-1.7998124, -2.743968 ]], dtype=float32)

time = 48014	action = 1	current_phase = 0	next_phase = 1	reward = -1.308862	array([[-2.049206 , -1.7670251]], dtype=float32)

time = 48022	action = 0	current_phase = 1	next_phase = 0	reward = 0.147758	array([[-0.42246848, -4.333379  ]], dtype=float32)

time = 48027	action = 1	current_phase = 1	next_phase = 0	reward = -1.783084	array([[-4.952724 , -3.5635736]], dtype=float32)

time = 48035	action = 0	current_phase = 0	next_phase = 1	reward = -0.522465	array([[-2.0272315, -3.1723888]], dtype=float32)

time = 48040	action = 0	current_phase = 0	next_phase = 1	reward = -0.364174	array([[-1.7998142, -2.7438211]], dtype=float32)

time = 48045	action = 1	current_phase = 0	next_phase = 1	reward = -1.305029	array([[-2.0225015, -1.6144141]], dtype=float32)

time = 48053	action = 0	current_phase = 1	next_phase = 0	reward = -0.045278	array([[ 2.3605068, -3.5146885]], dtype=float32)

time = 48058	action = 1	current_phase = 1	next_phase = 0	reward = -1.903390	array([[-5.390609 , -3.7191641]], dtype=float32)

time = 48066	action = 0	current_phase = 0	next_phase = 1	reward = -0.505950	array([[-1.9953783, -3.1576388]], dtype=float32)

time = 48071	action = 0	current_phase = 0	next_phase = 1	reward = -0.349516	array([[-1.8025864, -2.8489783]], dtype=float32)

time = 48076	action = 1	current_phase = 0	next_phase = 1	reward = -1.304662	array([[-2.0225103, -1.6143608]], dtype=float32)

time = 48084	action = 0	current_phase = 1	next_phase = 0	reward = -0.056068	array([[ 3.286159, -2.411253]], dtype=float32)

time = 48089	action = 0	current_phase = 1	next_phase = 0	reward = -1.598305	array([[11.3750305, -3.7447133]], dtype=float32)

time = 48094	action = 1	current_phase = 1	next_phase = 0	reward = -1.895424	array([[-5.5849853, -3.4555252]], dtype=float32)

time = 48102	action = 0	current_phase = 0	next_phase = 1	reward = -0.306090	array([[-1.9793314, -3.1801987]], dtype=float32)

time = 48107	action = 1	current_phase = 0	next_phase = 1	reward = -0.756239	array([[-2.0525177, -1.8305818]], dtype=float32)

time = 48115	action = 0	current_phase = 1	next_phase = 0	reward = -0.791617	array([[-2.9935997, -3.2803543]], dtype=float32)

time = 48120	action = 0	current_phase = 1	next_phase = 0	reward = -1.725046	array([[ 3.2022507, -4.0998526]], dtype=float32)

time = 48125	action = 0	current_phase = 1	next_phase = 0	reward = -1.610777	array([[ 4.760759 , -3.1962128]], dtype=float32)

time = 48130	action = 1	current_phase = 1	next_phase = 0	reward = -1.596195	array([[-5.2434564, -3.1774015]], dtype=float32)

time = 48138	action = 0	current_phase = 0	next_phase = 1	reward = -0.163214	array([[-1.9783499, -2.923476 ]], dtype=float32)

time = 48143	action = 0	current_phase = 0	next_phase = 1	reward = 0.015576	array([[-2.5980418, -3.6002946]], dtype=float32)

time = 48148	action = 1	current_phase = 0	next_phase = 1	reward = -1.903834	array([[-6.2482147, -3.480381 ]], dtype=float32)

time = 48156	action = 0	current_phase = 1	next_phase = 0	reward = -0.491336	array([[-2.1094217, -3.123561 ]], dtype=float32)

time = 48161	action = 0	current_phase = 1	next_phase = 0	reward = -0.337936	array([[-1.961497 , -3.1244376]], dtype=float32)

time = 48166	action = 0	current_phase = 1	next_phase = 0	reward = -0.191309	array([[-2.220787 , -3.1232605]], dtype=float32)

time = 48171	action = 0	current_phase = 1	next_phase = 0	reward = 0.321196	array([[-2.3889341, -4.0586176]], dtype=float32)

time = 48176	action = 1	current_phase = 1	next_phase = 0	reward = -1.604629	array([[-5.964403 , -3.3921127]], dtype=float32)

time = 48184	action = 0	current_phase = 0	next_phase = 1	reward = -0.567433	array([[-2.0816548, -3.17129  ]], dtype=float32)

time = 48189	action = 0	current_phase = 0	next_phase = 1	reward = -0.420026	array([[-1.800172 , -2.7448916]], dtype=float32)

time = 48194	action = 1	current_phase = 0	next_phase = 1	reward = -1.374506	array([[-2.0942802, -2.0554821]], dtype=float32)

time = 48202	action = 0	current_phase = 1	next_phase = 0	reward = 0.280528	array([[-2.2072759, -4.16067  ]], dtype=float32)

time = 48207	action = 1	current_phase = 1	next_phase = 0	reward = -1.723347	array([[-4.5213327, -3.295201 ]], dtype=float32)

time = 48215	action = 0	current_phase = 0	next_phase = 1	reward = -0.524046	array([[-1.9505024, -3.1413233]], dtype=float32)

time = 48220	action = 0	current_phase = 0	next_phase = 1	reward = -0.372094	array([[-1.799778 , -2.7438579]], dtype=float32)

time = 48225	action = 1	current_phase = 0	next_phase = 1	reward = -1.316557	array([[-2.0225532, -1.6145875]], dtype=float32)

time = 48233	action = 0	current_phase = 1	next_phase = 0	reward = -0.042053	array([[-0.3788875, -3.023208 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.5023 - val_loss: 0.2452

Epoch 2/50

 - 4s - loss: 0.3333 - val_loss: 0.2356

Epoch 3/50

 - 4s - loss: 0.3103 - val_loss: 0.2684

Epoch 4/50

 - 4s - loss: 0.3710 - val_loss: 0.2549

Epoch 5/50

 - 4s - loss: 0.2968 - val_loss: 0.2808

Epoch 6/50

 - 4s - loss: 0.3474 - val_loss: 0.3050

Epoch 7/50

 - 4s - loss: 0.2305 - val_loss: 0.3498

Epoch 8/50

 - 4s - loss: 0.2567 - val_loss: 0.3832

Epoch 9/50

 - 4s - loss: 0.1665 - val_loss: 0.3762

Epoch 10/50

 - 4s - loss: 0.1834 - val_loss: 0.3627

Epoch 11/50

 - 4s - loss: 0.2357 - val_loss: 0.3440

Epoch 12/50

 - 4s - loss: 0.1625 - val_loss: 0.3614

length of memory (state 0, action 0): 1015, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1009, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1018, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1008, before forget

length of memory (state 1, action 1): 1000, after forget

time = 48238	action = 0	current_phase = 1	next_phase = 0	reward = -1.467450	array([[-1.3635832, -3.6750484]], dtype=float32)

time = 48243	action = 1	current_phase = 1	next_phase = 0	reward = -1.942143	array([[-4.1699014, -3.4853344]], dtype=float32)

time = 48251	action = 0	current_phase = 0	next_phase = 1	reward = -0.331509	array([[-2.002192, -2.980573]], dtype=float32)

time = 48256	action = 1	current_phase = 0	next_phase = 1	reward = -1.310608	array([[-2.044309 , -1.5642918]], dtype=float32)

time = 48264	action = 0	current_phase = 1	next_phase = 0	reward = -0.202183	array([[ 2.5116572, -2.1944098]], dtype=float32)

time = 48269	action = 0	current_phase = 1	next_phase = 0	reward = -1.608000	array([[ 8.14498  , -4.0609674]], dtype=float32)

time = 48274	action = 1	current_phase = 1	next_phase = 0	reward = -1.918254	array([[-3.5499668, -3.5121937]], dtype=float32)

time = 48282	action = 0	current_phase = 0	next_phase = 1	reward = -0.320316	array([[-1.9413404, -3.1663096]], dtype=float32)

time = 48287	action = 1	current_phase = 0	next_phase = 1	reward = -1.045353	array([[-2.081506 , -1.8110797]], dtype=float32)

time = 48295	action = 0	current_phase = 1	next_phase = 0	reward = -0.554216	array([[ 3.585996, -2.428349]], dtype=float32)

time = 48300	action = 0	current_phase = 1	next_phase = 0	reward = -1.728675	array([[-0.75788784, -3.572071  ]], dtype=float32)

time = 48305	action = 0	current_phase = 1	next_phase = 0	reward = -1.616860	array([[ 4.224812 , -3.1914754]], dtype=float32)

time = 48310	action = 1	current_phase = 1	next_phase = 0	reward = -1.592960	array([[-5.272844, -3.119173]], dtype=float32)

time = 48318	action = 0	current_phase = 0	next_phase = 1	reward = -0.158859	array([[-2.2146416, -3.1545243]], dtype=float32)

time = 48323	action = 0	current_phase = 0	next_phase = 1	reward = 0.001264	array([[-2.3786452, -3.8887346]], dtype=float32)

time = 48328	action = 1	current_phase = 0	next_phase = 1	reward = -1.896737	array([[-6.2854233, -3.490976 ]], dtype=float32)

time = 48336	action = 0	current_phase = 1	next_phase = 0	reward = -0.489551	array([[-2.053565 , -3.1001453]], dtype=float32)

time = 48341	action = 0	current_phase = 1	next_phase = 0	reward = -0.335752	array([[-2.00278  , -3.0961828]], dtype=float32)

time = 48346	action = 0	current_phase = 1	next_phase = 0	reward = -0.192497	array([[-2.3473263, -3.143343 ]], dtype=float32)

time = 48351	action = 0	current_phase = 1	next_phase = 0	reward = 0.303579	array([[-2.306785, -4.060446]], dtype=float32)

time = 48356	action = 1	current_phase = 1	next_phase = 0	reward = -1.611525	array([[-5.8845997, -3.2270637]], dtype=float32)

time = 48364	action = 0	current_phase = 0	next_phase = 1	reward = -0.557769	array([[-2.1140022, -3.2058656]], dtype=float32)

time = 48369	action = 0	current_phase = 0	next_phase = 1	reward = -0.403150	array([[-1.7903333, -2.7511482]], dtype=float32)

time = 48374	action = 1	current_phase = 0	next_phase = 1	reward = -1.340049	array([[-2.1171415, -2.0808384]], dtype=float32)

time = 48382	action = 0	current_phase = 1	next_phase = 0	reward = 0.268524	array([[-1.7948426, -4.257814 ]], dtype=float32)

time = 48387	action = 0	current_phase = 1	next_phase = 0	reward = -1.207347	array([[-0.9111186, -3.3591342]], dtype=float32)

time = 48392	action = 1	current_phase = 1	next_phase = 0	reward = -2.020346	array([[-4.1309776, -3.53016  ]], dtype=float32)

time = 48400	action = 0	current_phase = 0	next_phase = 1	reward = -0.385019	array([[-1.8299094, -2.8971066]], dtype=float32)

time = 48405	action = 1	current_phase = 0	next_phase = 1	reward = -1.322513	array([[-2.0744522, -1.7668405]], dtype=float32)

time = 48413	action = 0	current_phase = 1	next_phase = 0	reward = 0.142931	array([[-1.7072219, -3.96351  ]], dtype=float32)

time = 48418	action = 0	current_phase = 1	next_phase = 0	reward = -1.456934	array([[-1.3419003, -3.62639  ]], dtype=float32)

time = 48423	action = 0	current_phase = 1	next_phase = 0	reward = -1.667100	array([[12.699158 , -3.5806532]], dtype=float32)

time = 48428	action = 1	current_phase = 1	next_phase = 0	reward = -1.720331	array([[-5.3286147, -3.2051811]], dtype=float32)

time = 48436	action = 0	current_phase = 0	next_phase = 1	reward = -0.203928	array([[-2.0111482, -2.9397871]], dtype=float32)

time = 48441	action = 1	current_phase = 0	next_phase = 1	reward = -1.111328	array([[-2.03725  , -1.3599161]], dtype=float32)

time = 48449	action = 0	current_phase = 1	next_phase = 0	reward = -1.593669	array([[ 0.15576175, -3.9669995 ]], dtype=float32)

time = 48454	action = 0	current_phase = 1	next_phase = 0	reward = -1.631954	array([[-2.8373168, -3.317442 ]], dtype=float32)

time = 48459	action = 0	current_phase = 1	next_phase = 0	reward = -1.519456	array([[-0.8466672, -3.2731419]], dtype=float32)

time = 48464	action = 1	current_phase = 1	next_phase = 0	reward = -1.412205	array([[-5.3523498, -3.4001846]], dtype=float32)

time = 48472	action = 0	current_phase = 0	next_phase = 1	reward = 0.202517	array([[-2.1564472, -3.1204464]], dtype=float32)

time = 48477	action = 1	current_phase = 0	next_phase = 1	reward = -1.789910	array([[-6.0869617, -3.476702 ]], dtype=float32)

time = 48485	action = 0	current_phase = 1	next_phase = 0	reward = -0.538178	array([[-1.896017, -3.080656]], dtype=float32)

time = 48490	action = 0	current_phase = 1	next_phase = 0	reward = -0.393754	array([[-1.7949629, -3.1573052]], dtype=float32)

time = 48495	action = 0	current_phase = 1	next_phase = 0	reward = -0.245696	array([[-1.8241271, -3.149189 ]], dtype=float32)

time = 48500	action = 0	current_phase = 1	next_phase = 0	reward = 0.382106	array([[-1.9256699, -3.8678493]], dtype=float32)

time = 48505	action = 1	current_phase = 1	next_phase = 0	reward = -1.293190	array([[-3.5935822, -3.1061163]], dtype=float32)

time = 48513	action = 0	current_phase = 0	next_phase = 1	reward = -0.588848	array([[-2.258362 , -3.7039218]], dtype=float32)

time = 48518	action = 0	current_phase = 0	next_phase = 1	reward = -0.433824	array([[-1.7879199, -2.7436378]], dtype=float32)

time = 48523	action = 1	current_phase = 0	next_phase = 1	reward = -1.378637	array([[-2.1182806, -2.0855606]], dtype=float32)

time = 48531	action = 0	current_phase = 1	next_phase = 0	reward = 0.307086	array([[-2.006251, -4.226457]], dtype=float32)

time = 48536	action = 1	current_phase = 1	next_phase = 0	reward = -1.612781	array([[-4.02302  , -2.8652854]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2270 - val_loss: 0.3051

Epoch 2/50

 - 4s - loss: 0.3275 - val_loss: 0.3090

Epoch 3/50

 - 4s - loss: 0.4780 - val_loss: 0.3220

Epoch 4/50

 - 4s - loss: 0.3183 - val_loss: 0.3168

Epoch 5/50

 - 4s - loss: 0.4268 - val_loss: 0.3458

Epoch 6/50

 - 4s - loss: 0.2639 - val_loss: 0.3695

Epoch 7/50

 - 4s - loss: 0.3945 - val_loss: 0.3688

Epoch 8/50

 - 4s - loss: 0.2821 - val_loss: 0.4509

Epoch 9/50

 - 4s - loss: 0.1621 - val_loss: 0.4830

Epoch 10/50

 - 4s - loss: 0.2636 - val_loss: 0.5694

Epoch 11/50

 - 4s - loss: 0.2327 - val_loss: 0.5555

length of memory (state 0, action 0): 1011, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1008, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1009, before forget

length of memory (state 1, action 1): 1000, after forget

time = 48544	action = 0	current_phase = 0	next_phase = 1	reward = -0.561982	array([[-1.9581496, -3.0332637]], dtype=float32)

time = 48549	action = 0	current_phase = 0	next_phase = 1	reward = -0.401348	array([[-1.8599683, -2.8150873]], dtype=float32)

time = 48554	action = 0	current_phase = 0	next_phase = 1	reward = -0.243927	array([[-2.1069863, -2.3488526]], dtype=float32)

time = 48559	action = 0	current_phase = 0	next_phase = 1	reward = -0.173024	array([[-2.1815553, -2.687363 ]], dtype=float32)

time = 48564	action = 1	current_phase = 0	next_phase = 1	reward = -0.472194	array([[-4.9159107, -2.412962 ]], dtype=float32)

time = 48572	action = 0	current_phase = 1	next_phase = 0	reward = -0.612974	array([[-2.2904198, -2.9764924]], dtype=float32)

time = 48577	action = 0	current_phase = 1	next_phase = 0	reward = -0.448097	array([[-2.042226 , -3.0380597]], dtype=float32)

time = 48582	action = 0	current_phase = 1	next_phase = 0	reward = -0.298542	array([[-1.9350766, -3.098239 ]], dtype=float32)

time = 48587	action = 0	current_phase = 1	next_phase = 0	reward = -0.172061	array([[-2.2459216, -3.141518 ]], dtype=float32)

time = 48592	action = 0	current_phase = 1	next_phase = 0	reward = 0.243532	array([[-2.578616, -3.86971 ]], dtype=float32)

time = 48597	action = 1	current_phase = 1	next_phase = 0	reward = -1.785484	array([[-6.1239676, -3.4053235]], dtype=float32)

time = 48605	action = 0	current_phase = 0	next_phase = 1	reward = -0.536361	array([[-1.9940447, -3.2426145]], dtype=float32)

time = 48610	action = 0	current_phase = 0	next_phase = 1	reward = -0.380615	array([[-1.8599497, -2.8149533]], dtype=float32)

time = 48615	action = 1	current_phase = 0	next_phase = 1	reward = -1.315727	array([[-2.0804014, -1.8232874]], dtype=float32)

time = 48623	action = 0	current_phase = 1	next_phase = 0	reward = 0.150854	array([[-2.2011218, -3.6399965]], dtype=float32)

time = 48628	action = 1	current_phase = 1	next_phase = 0	reward = -1.899719	array([[-4.526309 , -3.3434124]], dtype=float32)

time = 48636	action = 0	current_phase = 0	next_phase = 1	reward = -0.502221	array([[-1.9360254, -3.2321043]], dtype=float32)

time = 48641	action = 0	current_phase = 0	next_phase = 1	reward = -0.342768	array([[-1.8595238, -2.8219063]], dtype=float32)

time = 48646	action = 1	current_phase = 0	next_phase = 1	reward = -1.303711	array([[-2.0803766, -1.8229396]], dtype=float32)

time = 48654	action = 0	current_phase = 1	next_phase = 0	reward = -0.137270	array([[ 1.9377906, -2.4885979]], dtype=float32)

time = 48659	action = 1	current_phase = 1	next_phase = 0	reward = -2.019932	array([[-4.060873 , -3.4545283]], dtype=float32)

time = 48667	action = 0	current_phase = 0	next_phase = 1	reward = -0.477634	array([[-1.8947061, -3.2047474]], dtype=float32)

time = 48672	action = 0	current_phase = 0	next_phase = 1	reward = -0.320694	array([[-1.9300141, -2.946072 ]], dtype=float32)

time = 48677	action = 1	current_phase = 0	next_phase = 1	reward = -1.035186	array([[-2.0884688, -1.8801583]], dtype=float32)

time = 48685	action = 0	current_phase = 1	next_phase = 0	reward = -0.495176	array([[-2.1649308, -3.005722 ]], dtype=float32)

time = 48690	action = 0	current_phase = 1	next_phase = 0	reward = -1.730009	array([[-2.8219314, -3.5873952]], dtype=float32)

time = 48695	action = 1	current_phase = 1	next_phase = 0	reward = -1.855919	array([[-5.0004907, -3.3898644]], dtype=float32)

time = 48703	action = 0	current_phase = 0	next_phase = 1	reward = -0.291583	array([[-1.8837972, -3.251188 ]], dtype=float32)

time = 48708	action = 1	current_phase = 0	next_phase = 1	reward = -0.771947	array([[-2.0822716, -1.932319 ]], dtype=float32)

time = 48716	action = 0	current_phase = 1	next_phase = 0	reward = -1.062032	array([[-0.75358754, -3.2601352 ]], dtype=float32)

time = 48721	action = 0	current_phase = 1	next_phase = 0	reward = -1.701829	array([[ 2.9851606, -3.8135467]], dtype=float32)

time = 48726	action = 0	current_phase = 1	next_phase = 0	reward = -1.587889	array([[ 5.691832 , -3.2475524]], dtype=float32)

time = 48731	action = 1	current_phase = 1	next_phase = 0	reward = -1.544636	array([[-5.206383, -3.149363]], dtype=float32)

time = 48739	action = 0	current_phase = 0	next_phase = 1	reward = -0.178874	array([[-2.353344, -3.312539]], dtype=float32)

time = 48744	action = 1	current_phase = 0	next_phase = 1	reward = -0.535181	array([[-4.6678257, -2.6533835]], dtype=float32)

time = 48752	action = 0	current_phase = 1	next_phase = 0	reward = -0.616004	array([[-2.972065 , -3.2742734]], dtype=float32)

time = 48757	action = 0	current_phase = 1	next_phase = 0	reward = -0.458551	array([[-2.034897 , -3.0379658]], dtype=float32)

time = 48762	action = 0	current_phase = 1	next_phase = 0	reward = -0.305545	array([[-2.0318017, -3.0374289]], dtype=float32)

time = 48767	action = 0	current_phase = 1	next_phase = 0	reward = -0.172434	array([[-2.2466614, -3.1413126]], dtype=float32)

time = 48772	action = 0	current_phase = 1	next_phase = 0	reward = 0.162351	array([[-2.5927627, -3.9038177]], dtype=float32)

time = 48777	action = 1	current_phase = 1	next_phase = 0	reward = -1.782484	array([[-6.130384 , -3.4142585]], dtype=float32)

time = 48785	action = 0	current_phase = 0	next_phase = 1	reward = -0.518816	array([[-1.9612095, -3.2140708]], dtype=float32)

time = 48790	action = 0	current_phase = 0	next_phase = 1	reward = -0.366888	array([[-1.8599366, -2.8149714]], dtype=float32)

time = 48795	action = 1	current_phase = 0	next_phase = 1	reward = -1.303762	array([[-2.0803556, -1.8228877]], dtype=float32)

time = 48803	action = 0	current_phase = 1	next_phase = 0	reward = -0.058656	array([[-2.3902512, -3.488472 ]], dtype=float32)

time = 48808	action = 1	current_phase = 1	next_phase = 0	reward = -1.897128	array([[-4.3641605, -3.4343429]], dtype=float32)

time = 48816	action = 0	current_phase = 0	next_phase = 1	reward = -0.487123	array([[-1.9338174, -3.2299378]], dtype=float32)

time = 48821	action = 0	current_phase = 0	next_phase = 1	reward = -0.330348	array([[-1.8609139, -2.8129077]], dtype=float32)

time = 48826	action = 1	current_phase = 0	next_phase = 1	reward = -1.312652	array([[-2.0804794, -1.8236868]], dtype=float32)

time = 48834	action = 0	current_phase = 1	next_phase = 0	reward = -0.214793	array([[-1.9497302, -2.680171 ]], dtype=float32)

time = 48839	action = 0	current_phase = 1	next_phase = 0	reward = -1.606211	array([[-2.2208016, -3.6014395]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.4605 - val_loss: 0.4726

Epoch 2/50

 - 4s - loss: 0.5517 - val_loss: 0.4326

Epoch 3/50

 - 4s - loss: 0.5078 - val_loss: 0.4184

Epoch 4/50

 - 4s - loss: 0.5095 - val_loss: 0.4484

Epoch 5/50

 - 4s - loss: 0.4258 - val_loss: 0.4589

Epoch 6/50

 - 4s - loss: 0.2840 - val_loss: 0.5025

Epoch 7/50

 - 4s - loss: 0.3192 - val_loss: 0.3633

Epoch 8/50

 - 4s - loss: 0.2431 - val_loss: 0.3389

Epoch 9/50

 - 4s - loss: 0.2258 - val_loss: 0.3228

Epoch 10/50

 - 4s - loss: 0.2210 - val_loss: 0.3091

Epoch 11/50

 - 4s - loss: 0.2442 - val_loss: 0.2959

Epoch 12/50

 - 4s - loss: 0.2342 - val_loss: 0.3573

Epoch 13/50

 - 4s - loss: 0.1358 - val_loss: 0.3659

Epoch 14/50

 - 4s - loss: 0.2248 - val_loss: 0.2888

Epoch 15/50

 - 4s - loss: 0.1784 - val_loss: 0.2917

Epoch 16/50

 - 4s - loss: 0.2687 - val_loss: 0.4305

Epoch 17/50

 - 4s - loss: 0.2120 - val_loss: 0.3821

Epoch 18/50

 - 4s - loss: 0.1393 - val_loss: 0.3529

Epoch 19/50

 - 4s - loss: 0.1513 - val_loss: 0.3324

Epoch 20/50

 - 4s - loss: 0.2052 - val_loss: 0.3466

Epoch 21/50

 - 4s - loss: 0.1238 - val_loss: 0.3788

Epoch 22/50

 - 4s - loss: 0.1255 - val_loss: 0.3252

Epoch 23/50

 - 4s - loss: 0.2382 - val_loss: 0.2418

Epoch 24/50

 - 4s - loss: 0.1799 - val_loss: 0.1680

Epoch 25/50

 - 4s - loss: 0.1113 - val_loss: 0.1992

Epoch 26/50

 - 4s - loss: 0.1257 - val_loss: 0.1904

Epoch 27/50

 - 4s - loss: 0.1322 - val_loss: 0.1795

Epoch 28/50

 - 4s - loss: 0.1204 - val_loss: 0.2019

Epoch 29/50

 - 4s - loss: 0.1372 - val_loss: 0.1845

Epoch 30/50

 - 4s - loss: 0.1116 - val_loss: 0.2479

Epoch 31/50

 - 4s - loss: 0.1320 - val_loss: 0.1943

Epoch 32/50

 - 4s - loss: 0.1293 - val_loss: 0.2240

Epoch 33/50

 - 4s - loss: 0.1050 - val_loss: 0.2037

Epoch 34/50

 - 4s - loss: 0.1246 - val_loss: 0.2067

length of memory (state 0, action 0): 1016, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1008, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1007, before forget

length of memory (state 1, action 1): 1000, after forget

time = 48844	action = 1	current_phase = 1	next_phase = 0	reward = -1.911431	array([[-5.0641627, -3.486735 ]], dtype=float32)

time = 48852	action = 0	current_phase = 0	next_phase = 1	reward = -0.307056	array([[-1.7418697, -3.2392516]], dtype=float32)

time = 48857	action = 1	current_phase = 0	next_phase = 1	reward = -0.750105	array([[-2.0072618, -1.8892298]], dtype=float32)

time = 48865	action = 0	current_phase = 1	next_phase = 0	reward = -0.842160	array([[-1.0358974, -2.89151  ]], dtype=float32)

time = 48870	action = 0	current_phase = 1	next_phase = 0	reward = -1.736065	array([[-1.1345356, -3.4437127]], dtype=float32)

time = 48875	action = 0	current_phase = 1	next_phase = 0	reward = -1.616396	array([[-1.6729829, -3.432327 ]], dtype=float32)

time = 48880	action = 1	current_phase = 1	next_phase = 0	reward = -1.584806	array([[-5.154599 , -3.3587935]], dtype=float32)

time = 48888	action = 0	current_phase = 0	next_phase = 1	reward = -0.160230	array([[-1.9700338, -3.1725512]], dtype=float32)

time = 48893	action = 0	current_phase = 0	next_phase = 1	reward = 0.126951	array([[-2.9331074, -3.125897 ]], dtype=float32)

time = 48898	action = 1	current_phase = 0	next_phase = 1	reward = -1.898123	array([[-5.5394654, -3.3052363]], dtype=float32)

time = 48906	action = 0	current_phase = 1	next_phase = 0	reward = -0.499467	array([[-1.9532458, -3.133532 ]], dtype=float32)

time = 48911	action = 0	current_phase = 1	next_phase = 0	reward = -0.349351	array([[-1.9775366, -3.1149755]], dtype=float32)

time = 48916	action = 0	current_phase = 1	next_phase = 0	reward = -0.199790	array([[-2.0184107, -3.082973 ]], dtype=float32)

time = 48921	action = 0	current_phase = 1	next_phase = 0	reward = 0.338732	array([[-2.2542477, -3.9457042]], dtype=float32)

time = 48926	action = 1	current_phase = 1	next_phase = 0	reward = -1.552172	array([[-3.5479143, -3.1301847]], dtype=float32)

time = 48934	action = 0	current_phase = 0	next_phase = 1	reward = -0.558397	array([[-1.9013934, -3.113468 ]], dtype=float32)

time = 48939	action = 0	current_phase = 0	next_phase = 1	reward = -0.401545	array([[-1.7560728, -2.7506626]], dtype=float32)

time = 48944	action = 0	current_phase = 0	next_phase = 1	reward = -0.245457	array([[-1.9961013, -2.3843038]], dtype=float32)

time = 48949	action = 0	current_phase = 0	next_phase = 1	reward = -0.174143	array([[-2.100102 , -2.6533368]], dtype=float32)

time = 48954	action = 1	current_phase = 0	next_phase = 1	reward = -0.477687	array([[-4.979484 , -2.3159783]], dtype=float32)

time = 48962	action = 0	current_phase = 1	next_phase = 0	reward = -0.623236	array([[-2.184259 , -2.9788487]], dtype=float32)

time = 48967	action = 0	current_phase = 1	next_phase = 0	reward = -0.476899	array([[-2.0305333, -3.0542235]], dtype=float32)

time = 48972	action = 0	current_phase = 1	next_phase = 0	reward = -0.321692	array([[-2.011194 , -3.0572212]], dtype=float32)

time = 48977	action = 0	current_phase = 1	next_phase = 0	reward = -0.185623	array([[-2.2084153, -3.1646512]], dtype=float32)

time = 48982	action = 0	current_phase = 1	next_phase = 0	reward = 0.208464	array([[-2.5706499, -3.9013503]], dtype=float32)

time = 48987	action = 1	current_phase = 1	next_phase = 0	reward = -1.787810	array([[-6.081221, -3.483247]], dtype=float32)

time = 48995	action = 0	current_phase = 0	next_phase = 1	reward = -0.532185	array([[-1.91531 , -3.216231]], dtype=float32)

time = 49000	action = 0	current_phase = 0	next_phase = 1	reward = -0.367259	array([[-1.7566792, -2.7442815]], dtype=float32)

time = 49005	action = 0	current_phase = 0	next_phase = 1	reward = -0.210493	array([[-1.9956046, -2.3483412]], dtype=float32)

time = 49010	action = 0	current_phase = 0	next_phase = 1	reward = 0.347989	array([[-2.294065, -3.520859]], dtype=float32)

time = 49015	action = 1	current_phase = 0	next_phase = 1	reward = -1.313323	array([[-4.559485, -3.140402]], dtype=float32)

time = 49023	action = 0	current_phase = 1	next_phase = 0	reward = -0.592116	array([[-2.1842425, -2.98147  ]], dtype=float32)

time = 49028	action = 0	current_phase = 1	next_phase = 0	reward = -0.435692	array([[-2.0093744, -3.0570085]], dtype=float32)

time = 49033	action = 0	current_phase = 1	next_phase = 0	reward = -0.290607	array([[-2.0086596, -3.056032 ]], dtype=float32)

time = 49038	action = 0	current_phase = 1	next_phase = 0	reward = -0.171275	array([[-2.2043002, -3.1763864]], dtype=float32)

time = 49043	action = 0	current_phase = 1	next_phase = 0	reward = 0.117547	array([[-2.5613217, -3.77252  ]], dtype=float32)

time = 49048	action = 1	current_phase = 1	next_phase = 0	reward = -1.896142	array([[-6.1010613, -3.4672048]], dtype=float32)

time = 49056	action = 0	current_phase = 0	next_phase = 1	reward = -0.499985	array([[-1.9437648, -3.232664 ]], dtype=float32)

time = 49061	action = 0	current_phase = 0	next_phase = 1	reward = -0.342825	array([[-1.7564477, -2.7453206]], dtype=float32)

time = 49066	action = 1	current_phase = 0	next_phase = 1	reward = -1.300413	array([[-1.9820964, -1.6526709]], dtype=float32)

time = 49074	action = 0	current_phase = 1	next_phase = 0	reward = -0.022327	array([[-1.0408816, -2.6685967]], dtype=float32)

time = 49079	action = 1	current_phase = 1	next_phase = 0	reward = -2.003301	array([[-4.42652 , -3.541143]], dtype=float32)

time = 49087	action = 0	current_phase = 0	next_phase = 1	reward = -0.459331	array([[-1.867866 , -3.1824253]], dtype=float32)

time = 49092	action = 0	current_phase = 0	next_phase = 1	reward = -0.315181	array([[-1.7784859, -3.1832721]], dtype=float32)

time = 49097	action = 1	current_phase = 0	next_phase = 1	reward = -0.753084	array([[-1.9525305, -1.4456303]], dtype=float32)

time = 49105	action = 0	current_phase = 1	next_phase = 0	reward = -0.832021	array([[-1.0644944, -3.2085924]], dtype=float32)

time = 49110	action = 1	current_phase = 1	next_phase = 0	reward = -2.118803	array([[-4.845082 , -3.5063012]], dtype=float32)

time = 49118	action = 0	current_phase = 0	next_phase = 1	reward = -0.434473	array([[-1.7882893, -2.9773827]], dtype=float32)

time = 49123	action = 0	current_phase = 0	next_phase = 1	reward = -0.273006	array([[-1.9953154, -2.3876648]], dtype=float32)

time = 49128	action = 1	current_phase = 0	next_phase = 1	reward = -0.776906	array([[-1.9914289, -1.7371228]], dtype=float32)

time = 49136	action = 1	current_phase = 1	next_phase = 0	reward = -1.607339	array([[-3.1281908, -3.1244018]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1760 - val_loss: 0.6475

Epoch 2/50

 - 4s - loss: 0.1861 - val_loss: 0.6543

Epoch 3/50

 - 4s - loss: 0.1957 - val_loss: 0.6654

Epoch 4/50

 - 4s - loss: 0.1526 - val_loss: 0.7214

Epoch 5/50

 - 4s - loss: 0.1773 - val_loss: 0.7192

Epoch 6/50

 - 4s - loss: 0.1678 - val_loss: 0.7091

Epoch 7/50

 - 4s - loss: 0.1199 - val_loss: 0.7161

Epoch 8/50

 - 4s - loss: 0.1769 - val_loss: 0.7135

Epoch 9/50

 - 4s - loss: 0.1089 - val_loss: 0.7159

Epoch 10/50

 - 4s - loss: 0.1560 - val_loss: 0.7332

Epoch 11/50

 - 4s - loss: 0.1390 - val_loss: 0.7160

length of memory (state 0, action 0): 1017, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1007, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1008, before forget

length of memory (state 1, action 1): 1000, after forget

time = 49144	action = 0	current_phase = 0	next_phase = 1	reward = -0.565402	array([[-1.9910865, -3.008469 ]], dtype=float32)

time = 49149	action = 0	current_phase = 0	next_phase = 1	reward = -0.420454	array([[-1.8299844, -2.7080553]], dtype=float32)

time = 49154	action = 0	current_phase = 0	next_phase = 1	reward = -0.263699	array([[-1.9622785, -2.3882816]], dtype=float32)

time = 49159	action = 0	current_phase = 0	next_phase = 1	reward = -0.168861	array([[-2.1932554, -2.6021452]], dtype=float32)

time = 49164	action = 1	current_phase = 0	next_phase = 1	reward = -0.497060	array([[-4.9815884, -2.3385472]], dtype=float32)

time = 49172	action = 0	current_phase = 1	next_phase = 0	reward = -0.617774	array([[-2.2100437, -2.9626293]], dtype=float32)

time = 49177	action = 0	current_phase = 1	next_phase = 0	reward = -0.463409	array([[-2.0230863, -3.0468478]], dtype=float32)

time = 49182	action = 0	current_phase = 1	next_phase = 0	reward = -0.306049	array([[-2.0237026, -3.047081 ]], dtype=float32)

time = 49187	action = 0	current_phase = 1	next_phase = 0	reward = -0.171573	array([[-2.221107, -3.142681]], dtype=float32)

time = 49192	action = 0	current_phase = 1	next_phase = 0	reward = 0.182563	array([[-2.6013653, -3.8624806]], dtype=float32)

time = 49197	action = 1	current_phase = 1	next_phase = 0	reward = -1.781475	array([[-6.0329723, -3.4183912]], dtype=float32)

time = 49205	action = 0	current_phase = 0	next_phase = 1	reward = -0.512643	array([[-1.9527903, -3.221309 ]], dtype=float32)

time = 49210	action = 0	current_phase = 0	next_phase = 1	reward = -0.355082	array([[-1.8312532, -2.6888285]], dtype=float32)

time = 49215	action = 1	current_phase = 0	next_phase = 1	reward = -1.303845	array([[-1.951613 , -1.5854404]], dtype=float32)

time = 49223	action = 0	current_phase = 1	next_phase = 0	reward = -0.016577	array([[-1.291192 , -3.0241346]], dtype=float32)

time = 49228	action = 1	current_phase = 1	next_phase = 0	reward = -1.898561	array([[-4.9377756, -3.371025 ]], dtype=float32)

time = 49236	action = 0	current_phase = 0	next_phase = 1	reward = -0.487720	array([[-1.9530909, -3.219799 ]], dtype=float32)

time = 49241	action = 0	current_phase = 0	next_phase = 1	reward = -0.332010	array([[-1.8283203, -2.7357535]], dtype=float32)

time = 49246	action = 1	current_phase = 0	next_phase = 1	reward = -1.306866	array([[-1.947564 , -1.5509616]], dtype=float32)

time = 49254	action = 1	current_phase = 1	next_phase = 0	reward = -0.489131	array([[-2.556084 , -2.5479584]], dtype=float32)

time = 49262	action = 0	current_phase = 0	next_phase = 1	reward = -0.622409	array([[-2.0264406, -2.9738457]], dtype=float32)

time = 49267	action = 0	current_phase = 0	next_phase = 1	reward = -0.466574	array([[-2.1776826, -3.278115 ]], dtype=float32)

time = 49272	action = 0	current_phase = 0	next_phase = 1	reward = -0.306844	array([[-1.9622918, -2.3886595]], dtype=float32)

time = 49277	action = 0	current_phase = 0	next_phase = 1	reward = -0.170334	array([[-2.243441 , -3.0485148]], dtype=float32)

time = 49282	action = 0	current_phase = 0	next_phase = 1	reward = 0.197974	array([[-2.6059515, -4.01438  ]], dtype=float32)

time = 49287	action = 1	current_phase = 0	next_phase = 1	reward = -1.780821	array([[-6.6247187, -3.3700535]], dtype=float32)

time = 49295	action = 0	current_phase = 1	next_phase = 0	reward = -0.516190	array([[-2.019318 , -3.0899715]], dtype=float32)

time = 49300	action = 0	current_phase = 1	next_phase = 0	reward = -0.358631	array([[-1.8218094, -3.1483045]], dtype=float32)

time = 49305	action = 0	current_phase = 1	next_phase = 0	reward = -0.210182	array([[-1.9532037, -3.0913217]], dtype=float32)

time = 49310	action = 0	current_phase = 1	next_phase = 0	reward = 0.343643	array([[-2.1782281, -3.841621 ]], dtype=float32)

time = 49315	action = 1	current_phase = 1	next_phase = 0	reward = -1.270943	array([[-3.5208645, -2.9776752]], dtype=float32)

time = 49323	action = 0	current_phase = 0	next_phase = 1	reward = -0.587521	array([[-2.1553512, -3.6561868]], dtype=float32)

time = 49328	action = 0	current_phase = 0	next_phase = 1	reward = -0.429447	array([[-1.8500881, -2.7573268]], dtype=float32)

time = 49333	action = 0	current_phase = 0	next_phase = 1	reward = -0.277345	array([[-1.9622765, -2.388473 ]], dtype=float32)

time = 49338	action = 0	current_phase = 0	next_phase = 1	reward = -0.166448	array([[-2.240956 , -2.9519413]], dtype=float32)

time = 49343	action = 0	current_phase = 0	next_phase = 1	reward = 0.004483	array([[-2.8307023, -4.0094776]], dtype=float32)

time = 49348	action = 1	current_phase = 0	next_phase = 1	reward = -1.907064	array([[-6.567979 , -3.4138198]], dtype=float32)

time = 49356	action = 0	current_phase = 1	next_phase = 0	reward = -0.514532	array([[-1.9958985, -3.1318045]], dtype=float32)

time = 49361	action = 0	current_phase = 1	next_phase = 0	reward = -0.360345	array([[-1.9974581, -3.0656214]], dtype=float32)

time = 49366	action = 0	current_phase = 1	next_phase = 0	reward = -0.206818	array([[-1.9771767, -3.0780525]], dtype=float32)

time = 49371	action = 0	current_phase = 1	next_phase = 0	reward = 0.302401	array([[-2.2245708, -3.8998988]], dtype=float32)

time = 49376	action = 1	current_phase = 1	next_phase = 0	reward = -1.560518	array([[-5.8399653, -3.1128335]], dtype=float32)

time = 49384	action = 0	current_phase = 0	next_phase = 1	reward = -0.562912	array([[-1.9815607, -3.0067525]], dtype=float32)

time = 49389	action = 0	current_phase = 0	next_phase = 1	reward = -0.399510	array([[-1.8312567, -2.6887407]], dtype=float32)

time = 49394	action = 0	current_phase = 0	next_phase = 1	reward = -0.241713	array([[-1.9621443, -2.3884988]], dtype=float32)

time = 49399	action = 0	current_phase = 0	next_phase = 1	reward = -0.175318	array([[-2.1969297, -2.6522222]], dtype=float32)

time = 49404	action = 1	current_phase = 0	next_phase = 1	reward = -0.494453	array([[-5.008136 , -2.3863745]], dtype=float32)

time = 49412	action = 0	current_phase = 1	next_phase = 0	reward = -0.620068	array([[-2.210105 , -2.9616768]], dtype=float32)

time = 49417	action = 0	current_phase = 1	next_phase = 0	reward = -0.466704	array([[-2.0236697, -3.0464306]], dtype=float32)

time = 49422	action = 0	current_phase = 1	next_phase = 0	reward = -0.312537	array([[-2.0694883, -3.064832 ]], dtype=float32)

time = 49427	action = 0	current_phase = 1	next_phase = 0	reward = -0.174339	array([[-2.231565 , -3.1391032]], dtype=float32)

time = 49432	action = 0	current_phase = 1	next_phase = 0	reward = 0.124730	array([[-2.5956771, -3.8643289]], dtype=float32)

time = 49437	action = 1	current_phase = 1	next_phase = 0	reward = -1.785973	array([[-6.0417175, -3.4345345]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.2769 - val_loss: 0.2109

Epoch 2/50

 - 4s - loss: 0.3224 - val_loss: 0.2050

Epoch 3/50

 - 4s - loss: 0.2113 - val_loss: 0.1998

Epoch 4/50

 - 4s - loss: 0.2040 - val_loss: 0.2004

Epoch 5/50

 - 4s - loss: 0.1913 - val_loss: 0.2052

Epoch 6/50

 - 4s - loss: 0.1756 - val_loss: 0.1975

Epoch 7/50

 - 4s - loss: 0.1582 - val_loss: 0.2014

Epoch 8/50

 - 4s - loss: 0.1872 - val_loss: 0.1899

Epoch 9/50

 - 4s - loss: 0.0983 - val_loss: 0.2056

Epoch 10/50

 - 4s - loss: 0.1402 - val_loss: 0.2148

Epoch 11/50

 - 4s - loss: 0.1501 - val_loss: 0.2147

Epoch 12/50

 - 4s - loss: 0.1144 - val_loss: 0.2137

Epoch 13/50

 - 4s - loss: 0.1301 - val_loss: 0.2003

Epoch 14/50

 - 4s - loss: 0.1213 - val_loss: 0.2089

Epoch 15/50

 - 4s - loss: 0.1844 - val_loss: 0.2084

Epoch 16/50

 - 4s - loss: 0.0925 - val_loss: 0.2116

Epoch 17/50

 - 4s - loss: 0.0970 - val_loss: 0.2141

Epoch 18/50

 - 4s - loss: 0.1211 - val_loss: 0.2138

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 49445	action = 0	current_phase = 0	next_phase = 1	reward = -0.533510	array([[-1.94215  , -3.2429793]], dtype=float32)

time = 49450	action = 0	current_phase = 0	next_phase = 1	reward = -0.376037	array([[-1.795274, -2.659396]], dtype=float32)

time = 49455	action = 1	current_phase = 0	next_phase = 1	reward = -1.316635	array([[-1.899656, -1.583996]], dtype=float32)

time = 49463	action = 0	current_phase = 1	next_phase = 0	reward = 0.061642	array([[-1.5516022, -3.4999633]], dtype=float32)

time = 49468	action = 1	current_phase = 1	next_phase = 0	reward = -1.896016	array([[-4.297614 , -3.4443457]], dtype=float32)

time = 49476	action = 0	current_phase = 0	next_phase = 1	reward = -0.489581	array([[-1.95362  , -3.2779026]], dtype=float32)

time = 49481	action = 0	current_phase = 0	next_phase = 1	reward = -0.342400	array([[-1.7953174, -2.659324 ]], dtype=float32)

time = 49486	action = 1	current_phase = 0	next_phase = 1	reward = -1.310820	array([[-1.8624855, -1.1348709]], dtype=float32)

time = 49494	action = 0	current_phase = 1	next_phase = 0	reward = -0.144288	array([[-3.0337408, -3.0638666]], dtype=float32)

time = 49499	action = 1	current_phase = 1	next_phase = 0	reward = -2.003862	array([[-4.3662653, -3.4544957]], dtype=float32)

time = 49507	action = 0	current_phase = 0	next_phase = 1	reward = -0.460959	array([[-1.9121681, -3.2068589]], dtype=float32)

time = 49512	action = 0	current_phase = 0	next_phase = 1	reward = -0.306104	array([[-1.8870376, -2.5805652]], dtype=float32)

time = 49517	action = 1	current_phase = 0	next_phase = 1	reward = -0.769115	array([[-1.8436052, -0.9316455]], dtype=float32)

time = 49525	action = 1	current_phase = 1	next_phase = 0	reward = -1.423782	array([[-3.137436 , -3.0980773]], dtype=float32)

time = 49533	action = 0	current_phase = 0	next_phase = 1	reward = -0.585101	array([[-2.4349709, -2.9358919]], dtype=float32)

time = 49538	action = 0	current_phase = 0	next_phase = 1	reward = -0.435018	array([[-2.3421478, -2.7369735]], dtype=float32)

time = 49543	action = 0	current_phase = 0	next_phase = 1	reward = -0.286417	array([[-1.935827, -2.483692]], dtype=float32)

time = 49548	action = 0	current_phase = 0	next_phase = 1	reward = -0.164150	array([[-2.1871338, -2.7376554]], dtype=float32)

time = 49553	action = 0	current_phase = 0	next_phase = 1	reward = 0.020249	array([[-2.6839085, -3.943692 ]], dtype=float32)

time = 49558	action = 1	current_phase = 0	next_phase = 1	reward = -1.894710	array([[-6.604472 , -3.4334698]], dtype=float32)

time = 49566	action = 0	current_phase = 1	next_phase = 0	reward = -0.492032	array([[-1.9845514, -3.138566 ]], dtype=float32)

time = 49571	action = 0	current_phase = 1	next_phase = 0	reward = -0.343349	array([[-1.9662924, -3.0843585]], dtype=float32)

time = 49576	action = 0	current_phase = 1	next_phase = 0	reward = -0.193644	array([[-1.9375145, -3.0587382]], dtype=float32)

time = 49581	action = 0	current_phase = 1	next_phase = 0	reward = 0.326787	array([[-2.1778529, -3.8948126]], dtype=float32)

time = 49586	action = 1	current_phase = 1	next_phase = 0	reward = -1.554312	array([[-5.894027, -3.311158]], dtype=float32)

time = 49594	action = 0	current_phase = 0	next_phase = 1	reward = -0.558788	array([[-1.9343266, -2.9544497]], dtype=float32)

time = 49599	action = 0	current_phase = 0	next_phase = 1	reward = -0.404479	array([[-1.7977039, -2.6733453]], dtype=float32)

time = 49604	action = 0	current_phase = 0	next_phase = 1	reward = -0.249849	array([[-1.9008237, -2.4703498]], dtype=float32)

time = 49609	action = 0	current_phase = 0	next_phase = 1	reward = -0.190646	array([[-2.1739676, -2.619337 ]], dtype=float32)

time = 49614	action = 1	current_phase = 0	next_phase = 1	reward = -0.523068	array([[-5.0230517, -2.388557 ]], dtype=float32)

time = 49622	action = 0	current_phase = 1	next_phase = 0	reward = -0.616652	array([[-2.2716694, -2.9622974]], dtype=float32)

time = 49627	action = 0	current_phase = 1	next_phase = 0	reward = -0.466811	array([[-1.955464 , -3.0484543]], dtype=float32)

time = 49632	action = 0	current_phase = 1	next_phase = 0	reward = -0.305466	array([[-1.9558883, -3.0525672]], dtype=float32)

time = 49637	action = 0	current_phase = 1	next_phase = 0	reward = -0.171072	array([[-2.2472367, -3.160511 ]], dtype=float32)

time = 49642	action = 0	current_phase = 1	next_phase = 0	reward = 0.233743	array([[-2.6063547, -3.8136575]], dtype=float32)

time = 49647	action = 1	current_phase = 1	next_phase = 0	reward = -1.782993	array([[-6.044661 , -3.3753006]], dtype=float32)

time = 49655	action = 0	current_phase = 0	next_phase = 1	reward = -0.527964	array([[-1.9250039, -3.2227023]], dtype=float32)

time = 49660	action = 0	current_phase = 0	next_phase = 1	reward = -0.376391	array([[-1.795294, -2.659282]], dtype=float32)

time = 49665	action = 0	current_phase = 0	next_phase = 1	reward = -0.229808	array([[-1.9009022, -2.4633682]], dtype=float32)

time = 49670	action = 0	current_phase = 0	next_phase = 1	reward = 0.366703	array([[-2.3313642, -3.44543  ]], dtype=float32)

time = 49675	action = 1	current_phase = 0	next_phase = 1	reward = -1.355191	array([[-4.5189877, -3.1974504]], dtype=float32)

time = 49683	action = 0	current_phase = 1	next_phase = 0	reward = -0.591708	array([[-2.2631936, -2.9637203]], dtype=float32)

time = 49688	action = 0	current_phase = 1	next_phase = 0	reward = -0.452296	array([[-1.9545833, -3.048291 ]], dtype=float32)

time = 49693	action = 0	current_phase = 1	next_phase = 0	reward = -0.300604	array([[-1.9545541, -3.048226 ]], dtype=float32)

time = 49698	action = 0	current_phase = 1	next_phase = 0	reward = -0.171006	array([[-2.2075617, -3.2986815]], dtype=float32)

time = 49703	action = 0	current_phase = 1	next_phase = 0	reward = 0.164334	array([[-2.5937865, -3.8234444]], dtype=float32)

time = 49708	action = 1	current_phase = 1	next_phase = 0	reward = -1.840672	array([[-6.067142 , -3.4352398]], dtype=float32)

time = 49716	action = 0	current_phase = 0	next_phase = 1	reward = -0.505963	array([[-1.9502698, -3.2548711]], dtype=float32)

time = 49721	action = 0	current_phase = 0	next_phase = 1	reward = -0.346100	array([[-1.7953634, -2.659425 ]], dtype=float32)

time = 49726	action = 1	current_phase = 0	next_phase = 1	reward = -1.316649	array([[-1.8987575, -1.5344926]], dtype=float32)

time = 49734	action = 0	current_phase = 1	next_phase = 0	reward = -0.090086	array([[-1.8784071, -2.8963842]], dtype=float32)

time = 49739	action = 1	current_phase = 1	next_phase = 0	reward = -1.997743	array([[-4.845806, -3.402249]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1177 - val_loss: 0.5241

Epoch 2/50

 - 4s - loss: 0.1144 - val_loss: 0.5899

Epoch 3/50

 - 4s - loss: 0.1440 - val_loss: 0.5547

Epoch 4/50

 - 4s - loss: 0.1324 - val_loss: 0.5794

Epoch 5/50

 - 4s - loss: 0.1188 - val_loss: 0.5659

Epoch 6/50

 - 4s - loss: 0.0963 - val_loss: 0.5331

Epoch 7/50

 - 4s - loss: 0.0964 - val_loss: 0.5209

Epoch 8/50

 - 4s - loss: 0.0898 - val_loss: 0.5512

Epoch 9/50

 - 4s - loss: 0.1170 - val_loss: 0.5275

Epoch 10/50

 - 4s - loss: 0.0862 - val_loss: 0.5225

Epoch 11/50

 - 4s - loss: 0.0935 - val_loss: 0.5331

Epoch 12/50

 - 4s - loss: 0.0829 - val_loss: 0.5483

Epoch 13/50

 - 4s - loss: 0.0872 - val_loss: 0.6370

Epoch 14/50

 - 4s - loss: 0.1064 - val_loss: 0.6190

Epoch 15/50

 - 4s - loss: 0.0810 - val_loss: 0.5306

Epoch 16/50

 - 4s - loss: 0.0789 - val_loss: 0.5050

Epoch 17/50

 - 4s - loss: 0.0765 - val_loss: 0.5268

Epoch 18/50

 - 4s - loss: 0.0707 - val_loss: 0.5935

Epoch 19/50

 - 4s - loss: 0.0822 - val_loss: 0.6193

Epoch 20/50

 - 4s - loss: 0.0713 - val_loss: 0.6146

Epoch 21/50

 - 4s - loss: 0.0762 - val_loss: 0.6083

Epoch 22/50

 - 4s - loss: 0.0797 - val_loss: 0.6220

Epoch 23/50

 - 4s - loss: 0.0694 - val_loss: 0.6296

Epoch 24/50

 - 4s - loss: 0.0799 - val_loss: 0.6119

Epoch 25/50

 - 4s - loss: 0.0698 - val_loss: 0.5715

Epoch 26/50

 - 4s - loss: 0.0948 - val_loss: 0.5450

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1007, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1017, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1007, before forget

length of memory (state 1, action 1): 1000, after forget

time = 49747	action = 0	current_phase = 0	next_phase = 1	reward = -0.461388	array([[-1.9420382, -3.2364872]], dtype=float32)

time = 49752	action = 0	current_phase = 0	next_phase = 1	reward = -0.311307	array([[-1.9741219, -2.5865233]], dtype=float32)

time = 49757	action = 1	current_phase = 0	next_phase = 1	reward = -0.747803	array([[-1.8664684, -1.0305058]], dtype=float32)

time = 49765	action = 0	current_phase = 1	next_phase = 0	reward = -0.787237	array([[-2.66508  , -3.1162326]], dtype=float32)

time = 49770	action = 1	current_phase = 1	next_phase = 0	reward = -2.104273	array([[-4.49744  , -3.4621334]], dtype=float32)

time = 49778	action = 0	current_phase = 0	next_phase = 1	reward = -0.436389	array([[-1.9010214, -3.208996 ]], dtype=float32)

time = 49783	action = 0	current_phase = 0	next_phase = 1	reward = -0.281588	array([[-1.9733292, -2.5278149]], dtype=float32)

time = 49788	action = 1	current_phase = 0	next_phase = 1	reward = -0.764427	array([[-1.9270006, -1.3469638]], dtype=float32)

time = 49796	action = 0	current_phase = 1	next_phase = 0	reward = -0.950798	array([[-3.0683312, -3.1290536]], dtype=float32)

time = 49801	action = 0	current_phase = 1	next_phase = 0	reward = -1.702166	array([[ 8.058716 , -3.9169161]], dtype=float32)

time = 49806	action = 1	current_phase = 1	next_phase = 0	reward = -1.815176	array([[-4.852304 , -3.4121635]], dtype=float32)

time = 49814	action = 0	current_phase = 0	next_phase = 1	reward = -0.260289	array([[-1.6634717, -3.1623094]], dtype=float32)

time = 49819	action = 0	current_phase = 0	next_phase = 1	reward = -0.187440	array([[-2.0903137, -2.3042681]], dtype=float32)

time = 49824	action = 1	current_phase = 0	next_phase = 1	reward = -0.491633	array([[-4.8305235, -2.7411282]], dtype=float32)

time = 49832	action = 0	current_phase = 1	next_phase = 0	reward = -0.612940	array([[-2.1587303, -3.004197 ]], dtype=float32)

time = 49837	action = 0	current_phase = 1	next_phase = 0	reward = -0.461883	array([[-2.1357832, -3.022458 ]], dtype=float32)

time = 49842	action = 0	current_phase = 1	next_phase = 0	reward = -0.309418	array([[-1.9097959, -3.1664243]], dtype=float32)

time = 49847	action = 0	current_phase = 1	next_phase = 0	reward = -0.174534	array([[-2.185163 , -3.1859562]], dtype=float32)

time = 49852	action = 0	current_phase = 1	next_phase = 0	reward = 0.109518	array([[-2.6202796, -3.7936146]], dtype=float32)

time = 49857	action = 1	current_phase = 1	next_phase = 0	reward = -1.783523	array([[-6.022581 , -3.4611382]], dtype=float32)

time = 49865	action = 0	current_phase = 0	next_phase = 1	reward = -0.520508	array([[-1.9672202, -3.2506945]], dtype=float32)

time = 49870	action = 0	current_phase = 0	next_phase = 1	reward = -0.365522	array([[-1.803856 , -2.5977087]], dtype=float32)

time = 49875	action = 1	current_phase = 0	next_phase = 1	reward = -1.311282	array([[-1.9733268, -1.9286518]], dtype=float32)

time = 49883	action = 0	current_phase = 1	next_phase = 0	reward = 0.117278	array([[-1.4465328, -3.2139645]], dtype=float32)

time = 49888	action = 1	current_phase = 1	next_phase = 0	reward = -1.902519	array([[-4.176174 , -3.3098066]], dtype=float32)

time = 49896	action = 0	current_phase = 0	next_phase = 1	reward = -0.505894	array([[-1.9975226, -3.2358105]], dtype=float32)

time = 49901	action = 0	current_phase = 0	next_phase = 1	reward = -0.341952	array([[-1.8043631, -2.6017191]], dtype=float32)

time = 49906	action = 1	current_phase = 0	next_phase = 1	reward = -1.298913	array([[-1.8333976, -0.851003 ]], dtype=float32)

time = 49914	action = 0	current_phase = 1	next_phase = 0	reward = -0.119825	array([[ 0.56158215, -2.4886591 ]], dtype=float32)

time = 49919	action = 1	current_phase = 1	next_phase = 0	reward = -1.998895	array([[-4.701693 , -3.4362679]], dtype=float32)

time = 49927	action = 0	current_phase = 0	next_phase = 1	reward = -0.460580	array([[-1.8994708, -3.2060153]], dtype=float32)

time = 49932	action = 0	current_phase = 0	next_phase = 1	reward = -0.308847	array([[-1.979241 , -2.3130133]], dtype=float32)

time = 49937	action = 1	current_phase = 0	next_phase = 1	reward = -0.750143	array([[-1.8676802, -1.0357393]], dtype=float32)

time = 49945	action = 0	current_phase = 1	next_phase = 0	reward = -0.895054	array([[-2.0362701, -3.1060424]], dtype=float32)

time = 49950	action = 1	current_phase = 1	next_phase = 0	reward = -2.122246	array([[-4.489565, -3.461435]], dtype=float32)

time = 49958	action = 0	current_phase = 0	next_phase = 1	reward = -0.442939	array([[-1.8932401, -3.196223 ]], dtype=float32)

time = 49963	action = 0	current_phase = 0	next_phase = 1	reward = -0.297370	array([[-1.9725949, -2.5312133]], dtype=float32)

time = 49968	action = 1	current_phase = 0	next_phase = 1	reward = -0.762267	array([[-1.9870434, -1.6732125]], dtype=float32)

time = 49976	action = 0	current_phase = 1	next_phase = 0	reward = -1.110929	array([[ 0.20294745, -3.0004961 ]], dtype=float32)

time = 49981	action = 0	current_phase = 1	next_phase = 0	reward = -1.710570	array([[-2.0174851, -3.6487744]], dtype=float32)

time = 49986	action = 1	current_phase = 1	next_phase = 0	reward = -1.811123	array([[-4.6993904, -3.455287 ]], dtype=float32)

time = 49994	action = 0	current_phase = 0	next_phase = 1	reward = -0.248629	array([[-1.8157349, -3.1769147]], dtype=float32)

time = 49999	action = 0	current_phase = 0	next_phase = 1	reward = -0.181850	array([[-2.0606194, -2.1698363]], dtype=float32)

time = 50004	action = 1	current_phase = 0	next_phase = 1	reward = -0.607913	array([[-4.9446125, -2.4096227]], dtype=float32)

time = 50012	action = 0	current_phase = 1	next_phase = 0	reward = -0.616812	array([[-2.155323 , -3.0115745]], dtype=float32)

time = 50017	action = 0	current_phase = 1	next_phase = 0	reward = -0.470042	array([[-2.1462126, -3.0159895]], dtype=float32)

time = 50022	action = 0	current_phase = 1	next_phase = 0	reward = -0.313481	array([[-1.9293368, -3.1017663]], dtype=float32)

time = 50027	action = 0	current_phase = 1	next_phase = 0	reward = -0.175105	array([[-2.2019114, -3.1751719]], dtype=float32)

time = 50032	action = 0	current_phase = 1	next_phase = 0	reward = 0.257209	array([[-2.6002357, -3.8542466]], dtype=float32)

time = 50037	action = 1	current_phase = 1	next_phase = 0	reward = -1.670931	array([[-6.0299163, -3.4230838]], dtype=float32)

time = 50045	action = 0	current_phase = 0	next_phase = 1	reward = -0.519570	array([[-1.962384 , -3.2476437]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1911 - val_loss: 0.1174

Epoch 2/50

 - 4s - loss: 0.1247 - val_loss: 0.1143

Epoch 3/50

 - 4s - loss: 0.1132 - val_loss: 0.1164

Epoch 4/50

 - 4s - loss: 0.1213 - val_loss: 0.1057

Epoch 5/50

 - 4s - loss: 0.1009 - val_loss: 0.1274

Epoch 6/50

 - 4s - loss: 0.0948 - val_loss: 0.1036

Epoch 7/50

 - 4s - loss: 0.1093 - val_loss: 0.1275

Epoch 8/50

 - 4s - loss: 0.0832 - val_loss: 0.1070

Epoch 9/50

 - 4s - loss: 0.1011 - val_loss: 0.1085

Epoch 10/50

 - 4s - loss: 0.1218 - val_loss: 0.1244

Epoch 11/50

 - 4s - loss: 0.0807 - val_loss: 0.1176

Epoch 12/50

 - 4s - loss: 0.0693 - val_loss: 0.1248

Epoch 13/50

 - 4s - loss: 0.0709 - val_loss: 0.1243

Epoch 14/50

 - 4s - loss: 0.0664 - val_loss: 0.1185

Epoch 15/50

 - 4s - loss: 0.0769 - val_loss: 0.1278

Epoch 16/50

 - 4s - loss: 0.0809 - val_loss: 0.1282

length of memory (state 0, action 0): 1017, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1008, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1018, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1008, before forget

length of memory (state 1, action 1): 1000, after forget

time = 50050	action = 0	current_phase = 0	next_phase = 1	reward = -0.361812	array([[-1.7585974, -2.5584147]], dtype=float32)

time = 50055	action = 1	current_phase = 0	next_phase = 1	reward = -1.300396	array([[-1.9339262, -1.2130847]], dtype=float32)

time = 50063	action = 0	current_phase = 1	next_phase = 0	reward = -0.044826	array([[-2.020251 , -3.2951791]], dtype=float32)

time = 50068	action = 1	current_phase = 1	next_phase = 0	reward = -1.906872	array([[-4.67138  , -3.4055996]], dtype=float32)

time = 50076	action = 0	current_phase = 0	next_phase = 1	reward = -0.499810	array([[-1.931705 , -3.2274024]], dtype=float32)

time = 50081	action = 0	current_phase = 0	next_phase = 1	reward = -0.344851	array([[-1.7573348, -2.5682077]], dtype=float32)

time = 50086	action = 1	current_phase = 0	next_phase = 1	reward = -1.299667	array([[-1.843704, -0.649533]], dtype=float32)

time = 50094	action = 0	current_phase = 1	next_phase = 0	reward = -0.119217	array([[ 1.953446, -2.399586]], dtype=float32)

time = 50099	action = 1	current_phase = 1	next_phase = 0	reward = -1.995081	array([[-4.5773854, -3.45482  ]], dtype=float32)

time = 50107	action = 0	current_phase = 0	next_phase = 1	reward = -0.445355	array([[-1.918525 , -3.2104464]], dtype=float32)

time = 50112	action = 0	current_phase = 0	next_phase = 1	reward = -0.282987	array([[-1.9512335, -2.447017 ]], dtype=float32)

time = 50117	action = 1	current_phase = 0	next_phase = 1	reward = -0.784535	array([[-1.9890695, -1.6374578]], dtype=float32)

time = 50125	action = 0	current_phase = 1	next_phase = 0	reward = -0.911826	array([[-2.6471627, -3.0607657]], dtype=float32)

time = 50130	action = 1	current_phase = 1	next_phase = 0	reward = -2.117063	array([[-4.589588 , -3.4535625]], dtype=float32)

time = 50138	action = 0	current_phase = 0	next_phase = 1	reward = -0.429990	array([[-1.8818758, -3.188379 ]], dtype=float32)

time = 50143	action = 0	current_phase = 0	next_phase = 1	reward = -0.277745	array([[-1.949385 , -2.4439588]], dtype=float32)

time = 50148	action = 1	current_phase = 0	next_phase = 1	reward = -0.772905	array([[-2.0239573, -1.8082616]], dtype=float32)

time = 50156	action = 1	current_phase = 1	next_phase = 0	reward = -1.553932	array([[-3.5317795, -3.121496 ]], dtype=float32)

time = 50164	action = 0	current_phase = 0	next_phase = 1	reward = -0.555828	array([[-1.9375067, -2.8398721]], dtype=float32)

time = 50169	action = 0	current_phase = 0	next_phase = 1	reward = -0.398858	array([[-1.8633335, -2.6119795]], dtype=float32)

time = 50174	action = 0	current_phase = 0	next_phase = 1	reward = -0.239222	array([[-1.9494648, -2.4436479]], dtype=float32)

time = 50179	action = 0	current_phase = 0	next_phase = 1	reward = -0.174719	array([[-2.1206195, -2.615469 ]], dtype=float32)

time = 50184	action = 1	current_phase = 0	next_phase = 1	reward = -0.479489	array([[-5.130709 , -2.2564738]], dtype=float32)

time = 50192	action = 0	current_phase = 1	next_phase = 0	reward = -0.609584	array([[-2.159689 , -2.9636762]], dtype=float32)

time = 50197	action = 0	current_phase = 1	next_phase = 0	reward = -0.447879	array([[-1.992135 , -3.0690832]], dtype=float32)

time = 50202	action = 0	current_phase = 1	next_phase = 0	reward = -0.294328	array([[-1.9917843, -3.0690658]], dtype=float32)

time = 50207	action = 0	current_phase = 1	next_phase = 0	reward = -0.170632	array([[-2.220741 , -3.1809952]], dtype=float32)

time = 50212	action = 0	current_phase = 1	next_phase = 0	reward = 0.168806	array([[-2.6679375, -3.825202 ]], dtype=float32)

time = 50217	action = 1	current_phase = 1	next_phase = 0	reward = -1.789110	array([[-6.0402975, -3.3960404]], dtype=float32)

time = 50225	action = 0	current_phase = 0	next_phase = 1	reward = -0.532090	array([[-1.9385757, -3.2178595]], dtype=float32)

time = 50230	action = 0	current_phase = 0	next_phase = 1	reward = -0.380664	array([[-1.758661 , -2.5583255]], dtype=float32)

time = 50235	action = 0	current_phase = 0	next_phase = 1	reward = -0.231202	array([[-1.9552974, -2.3393433]], dtype=float32)

time = 50240	action = 0	current_phase = 0	next_phase = 1	reward = 0.081231	array([[-2.2409604, -3.67214  ]], dtype=float32)

time = 50245	action = 1	current_phase = 0	next_phase = 1	reward = -1.023535	array([[-4.839247, -2.683139]], dtype=float32)

time = 50253	action = 0	current_phase = 1	next_phase = 0	reward = -0.576683	array([[-2.1589284, -2.9641078]], dtype=float32)

time = 50258	action = 0	current_phase = 1	next_phase = 0	reward = -0.427472	array([[-1.9969015, -3.0788348]], dtype=float32)

time = 50263	action = 0	current_phase = 1	next_phase = 0	reward = -0.275677	array([[-1.9916137, -3.068958 ]], dtype=float32)

time = 50268	action = 0	current_phase = 1	next_phase = 0	reward = -0.164290	array([[-2.2503707, -3.1692832]], dtype=float32)

time = 50273	action = 0	current_phase = 1	next_phase = 0	reward = -0.057886	array([[-2.5046382, -3.4270184]], dtype=float32)

time = 50278	action = 1	current_phase = 1	next_phase = 0	reward = -1.904633	array([[-6.0620604, -3.4034185]], dtype=float32)

time = 50286	action = 0	current_phase = 0	next_phase = 1	reward = -0.499507	array([[-1.9358089, -3.212541 ]], dtype=float32)

time = 50291	action = 0	current_phase = 0	next_phase = 1	reward = -0.344885	array([[-1.7597556, -2.5588756]], dtype=float32)

time = 50296	action = 1	current_phase = 0	next_phase = 1	reward = -1.296533	array([[-1.8424689, -0.6420329]], dtype=float32)

time = 50304	action = 0	current_phase = 1	next_phase = 0	reward = -0.014289	array([[-2.0271008, -2.223637 ]], dtype=float32)

time = 50309	action = 1	current_phase = 1	next_phase = 0	reward = -1.995735	array([[-4.546743 , -3.4556034]], dtype=float32)

time = 50317	action = 0	current_phase = 0	next_phase = 1	reward = -0.457897	array([[-1.9244158, -3.2098753]], dtype=float32)

time = 50322	action = 0	current_phase = 0	next_phase = 1	reward = -0.300089	array([[-1.8859264, -2.6662552]], dtype=float32)

time = 50327	action = 1	current_phase = 0	next_phase = 1	reward = -0.753966	array([[-1.9812251, -1.4995959]], dtype=float32)

time = 50335	action = 0	current_phase = 1	next_phase = 0	reward = -0.900264	array([[-2.6759655, -3.1369581]], dtype=float32)

time = 50340	action = 1	current_phase = 1	next_phase = 0	reward = -2.112746	array([[-4.532    , -3.4630983]], dtype=float32)

time = 50348	action = 0	current_phase = 0	next_phase = 1	reward = -0.437154	array([[-1.8602533, -3.16885  ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1361 - val_loss: 0.0866

Epoch 2/50

 - 4s - loss: 0.0851 - val_loss: 0.0846

Epoch 3/50

 - 4s - loss: 0.0838 - val_loss: 0.0781

Epoch 4/50

 - 4s - loss: 0.0806 - val_loss: 0.0789

Epoch 5/50

 - 4s - loss: 0.0625 - val_loss: 0.0812

Epoch 6/50

 - 4s - loss: 0.0628 - val_loss: 0.0879

Epoch 7/50

 - 4s - loss: 0.0536 - val_loss: 0.0863

Epoch 8/50

 - 4s - loss: 0.0539 - val_loss: 0.0873

Epoch 9/50

 - 4s - loss: 0.1152 - val_loss: 0.0898

Epoch 10/50

 - 4s - loss: 0.0934 - val_loss: 0.0915

Epoch 11/50

 - 4s - loss: 0.1356 - val_loss: 0.0904

Epoch 12/50

 - 4s - loss: 0.0628 - val_loss: 0.0895

Epoch 13/50

 - 4s - loss: 0.0466 - val_loss: 0.0985

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1008, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1015, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1008, before forget

length of memory (state 1, action 1): 1000, after forget

time = 50353	action = 0	current_phase = 0	next_phase = 1	reward = -0.282532	array([[-1.9665155, -2.4230459]], dtype=float32)

time = 50358	action = 1	current_phase = 0	next_phase = 1	reward = -0.800770	array([[-2.0521142, -1.3426217]], dtype=float32)

time = 50366	action = 0	current_phase = 1	next_phase = 0	reward = -1.010358	array([[-2.5281956, -3.372758 ]], dtype=float32)

time = 50371	action = 0	current_phase = 1	next_phase = 0	reward = -1.703910	array([[-1.5712919, -3.5857534]], dtype=float32)

time = 50376	action = 1	current_phase = 1	next_phase = 0	reward = -1.805473	array([[-4.7602816, -3.3094182]], dtype=float32)

time = 50384	action = 0	current_phase = 0	next_phase = 1	reward = -0.258458	array([[-1.7950997, -2.9974806]], dtype=float32)

time = 50389	action = 1	current_phase = 0	next_phase = 1	reward = -0.890007	array([[-2.0420265, -1.7583803]], dtype=float32)

time = 50397	action = 0	current_phase = 1	next_phase = 0	reward = -1.320058	array([[-1.234802, -3.618818]], dtype=float32)

time = 50402	action = 0	current_phase = 1	next_phase = 0	reward = -1.687261	array([[-0.8237699, -3.6769905]], dtype=float32)

time = 50407	action = 1	current_phase = 1	next_phase = 0	reward = -1.742287	array([[-3.3403897, -3.1899261]], dtype=float32)

time = 50415	action = 0	current_phase = 0	next_phase = 1	reward = -0.220655	array([[-1.8417115, -3.1934066]], dtype=float32)

time = 50420	action = 0	current_phase = 0	next_phase = 1	reward = 0.038971	array([[-2.2196496, -3.284076 ]], dtype=float32)

time = 50425	action = 1	current_phase = 0	next_phase = 1	reward = -1.198843	array([[-4.811146 , -2.8031158]], dtype=float32)

time = 50433	action = 0	current_phase = 1	next_phase = 0	reward = -0.583385	array([[-2.2042685, -2.9986353]], dtype=float32)

time = 50438	action = 0	current_phase = 1	next_phase = 0	reward = -0.435900	array([[-1.9786646, -3.0716155]], dtype=float32)

time = 50443	action = 0	current_phase = 1	next_phase = 0	reward = -0.288209	array([[-1.9739743, -3.068304 ]], dtype=float32)

time = 50448	action = 0	current_phase = 1	next_phase = 0	reward = -0.163251	array([[-2.2364893, -3.1704314]], dtype=float32)

time = 50453	action = 0	current_phase = 1	next_phase = 0	reward = 0.084818	array([[-2.6414812, -3.9179401]], dtype=float32)

time = 50458	action = 1	current_phase = 1	next_phase = 0	reward = -1.891253	array([[-6.052042 , -3.4189184]], dtype=float32)

time = 50466	action = 0	current_phase = 0	next_phase = 1	reward = -0.482658	array([[-1.9529278, -3.1981268]], dtype=float32)

time = 50471	action = 0	current_phase = 0	next_phase = 1	reward = -0.325121	array([[-1.7842596, -2.6080065]], dtype=float32)

time = 50476	action = 1	current_phase = 0	next_phase = 1	reward = -1.305978	array([[-2.0109699, -1.0175277]], dtype=float32)

time = 50484	action = 0	current_phase = 1	next_phase = 0	reward = -0.084702	array([[-0.9816442, -2.4562395]], dtype=float32)

time = 50489	action = 1	current_phase = 1	next_phase = 0	reward = -1.998236	array([[-4.4831853, -3.4945278]], dtype=float32)

time = 50497	action = 0	current_phase = 0	next_phase = 1	reward = -0.448766	array([[-1.9248555, -3.193581 ]], dtype=float32)

time = 50502	action = 0	current_phase = 0	next_phase = 1	reward = -0.299164	array([[-1.9288287, -2.5554144]], dtype=float32)

time = 50507	action = 1	current_phase = 0	next_phase = 1	reward = -0.770215	array([[-2.0131955, -1.3067397]], dtype=float32)

time = 50515	action = 1	current_phase = 1	next_phase = 0	reward = -1.421937	array([[-3.408399 , -3.1083777]], dtype=float32)

time = 50523	action = 0	current_phase = 0	next_phase = 1	reward = -0.583497	array([[-2.1054776, -2.8188016]], dtype=float32)

time = 50528	action = 0	current_phase = 0	next_phase = 1	reward = -0.422257	array([[-2.20224  , -2.7460701]], dtype=float32)

time = 50533	action = 0	current_phase = 0	next_phase = 1	reward = -0.270541	array([[-1.9671683, -2.4211674]], dtype=float32)

time = 50538	action = 0	current_phase = 0	next_phase = 1	reward = -0.165450	array([[-2.2642827, -3.0764213]], dtype=float32)

time = 50543	action = 0	current_phase = 0	next_phase = 1	reward = -0.017667	array([[-2.7849464, -4.3750477]], dtype=float32)

time = 50548	action = 1	current_phase = 0	next_phase = 1	reward = -1.902922	array([[-6.571016 , -3.4619954]], dtype=float32)

time = 50556	action = 0	current_phase = 1	next_phase = 0	reward = -0.502119	array([[-2.0067525, -3.1430697]], dtype=float32)

time = 50561	action = 0	current_phase = 1	next_phase = 0	reward = -0.355646	array([[-1.973705 , -3.0808182]], dtype=float32)

time = 50566	action = 0	current_phase = 1	next_phase = 0	reward = -0.204202	array([[-2.0756562, -3.1191196]], dtype=float32)

time = 50571	action = 0	current_phase = 1	next_phase = 0	reward = 0.287499	array([[-2.2904334, -3.9352107]], dtype=float32)

time = 50576	action = 1	current_phase = 1	next_phase = 0	reward = -1.560839	array([[-5.827565 , -3.2298841]], dtype=float32)

time = 50584	action = 0	current_phase = 0	next_phase = 1	reward = -0.562787	array([[-1.9855223, -2.8472967]], dtype=float32)

time = 50589	action = 0	current_phase = 0	next_phase = 1	reward = -0.406221	array([[-1.7968919, -2.5560627]], dtype=float32)

time = 50594	action = 0	current_phase = 0	next_phase = 1	reward = -0.247514	array([[-1.9671266, -2.4210787]], dtype=float32)

time = 50599	action = 0	current_phase = 0	next_phase = 1	reward = -0.170754	array([[-2.1691568, -2.6507058]], dtype=float32)

time = 50604	action = 1	current_phase = 0	next_phase = 1	reward = -0.522049	array([[-5.183626 , -2.3228867]], dtype=float32)

time = 50612	action = 0	current_phase = 1	next_phase = 0	reward = -0.621824	array([[-2.257085 , -2.9663143]], dtype=float32)

time = 50617	action = 0	current_phase = 1	next_phase = 0	reward = -0.467459	array([[-1.997991 , -3.0692885]], dtype=float32)

time = 50622	action = 0	current_phase = 1	next_phase = 0	reward = -0.316766	array([[-1.9804034, -3.0718117]], dtype=float32)

time = 50627	action = 0	current_phase = 1	next_phase = 0	reward = -0.177330	array([[-2.2048633, -3.1852968]], dtype=float32)

time = 50632	action = 0	current_phase = 1	next_phase = 0	reward = 0.182295	array([[-2.647273, -3.964185]], dtype=float32)

time = 50637	action = 1	current_phase = 1	next_phase = 0	reward = -1.781987	array([[-6.0349097, -3.4173377]], dtype=float32)

time = 50645	action = 0	current_phase = 0	next_phase = 1	reward = -0.520471	array([[-1.9480555, -3.1987343]], dtype=float32)

time = 50650	action = 0	current_phase = 0	next_phase = 1	reward = -0.358975	array([[-1.7964921, -2.5553231]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1252 - val_loss: 0.0642

Epoch 2/50

 - 4s - loss: 0.0974 - val_loss: 0.0625

Epoch 3/50

 - 4s - loss: 0.1365 - val_loss: 0.0592

Epoch 4/50

 - 4s - loss: 0.1037 - val_loss: 0.0583

Epoch 5/50

 - 4s - loss: 0.1125 - val_loss: 0.0619

Epoch 6/50

 - 4s - loss: 0.0994 - val_loss: 0.0588

Epoch 7/50

 - 4s - loss: 0.1903 - val_loss: 0.0602

Epoch 8/50

 - 4s - loss: 0.0843 - val_loss: 0.0605

Epoch 9/50

 - 4s - loss: 0.0938 - val_loss: 0.0617

Epoch 10/50

 - 4s - loss: 0.0719 - val_loss: 0.0571

Epoch 11/50

 - 4s - loss: 0.0654 - val_loss: 0.0611

Epoch 12/50

 - 4s - loss: 0.0867 - val_loss: 0.0593

Epoch 13/50

 - 4s - loss: 0.0905 - val_loss: 0.0570

Epoch 14/50

 - 4s - loss: 0.0968 - val_loss: 0.0620

Epoch 15/50

 - 4s - loss: 0.0619 - val_loss: 0.0612

Epoch 16/50

 - 4s - loss: 0.0835 - val_loss: 0.0607

Epoch 17/50

 - 4s - loss: 0.1118 - val_loss: 0.0605

Epoch 18/50

 - 4s - loss: 0.0760 - val_loss: 0.0601

Epoch 19/50

 - 4s - loss: 0.0967 - val_loss: 0.0600

Epoch 20/50

 - 4s - loss: 0.0836 - val_loss: 0.0655

Epoch 21/50

 - 4s - loss: 0.0972 - val_loss: 0.0633

Epoch 22/50

 - 4s - loss: 0.0794 - val_loss: 0.0653

Epoch 23/50

 - 4s - loss: 0.0737 - val_loss: 0.0651

length of memory (state 0, action 0): 1019, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1007, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1019, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1007, before forget

length of memory (state 1, action 1): 1000, after forget

time = 50655	action = 0	current_phase = 0	next_phase = 1	reward = -0.213376	array([[-1.963668 , -2.3581343]], dtype=float32)

time = 50660	action = 0	current_phase = 0	next_phase = 1	reward = 0.337333	array([[-2.1869786, -3.8440053]], dtype=float32)

time = 50665	action = 1	current_phase = 0	next_phase = 1	reward = -1.372227	array([[-4.5824337, -3.0867093]], dtype=float32)

time = 50673	action = 0	current_phase = 1	next_phase = 0	reward = -0.590967	array([[-2.1996434, -2.9737573]], dtype=float32)

time = 50678	action = 0	current_phase = 1	next_phase = 0	reward = -0.439881	array([[-1.9260925, -3.076849 ]], dtype=float32)

time = 50683	action = 0	current_phase = 1	next_phase = 0	reward = -0.290315	array([[-1.9236882, -3.0752933]], dtype=float32)

time = 50688	action = 0	current_phase = 1	next_phase = 0	reward = -0.163661	array([[-2.2092125, -3.1954372]], dtype=float32)

time = 50693	action = 0	current_phase = 1	next_phase = 0	reward = 0.039847	array([[-2.6753564, -3.8948867]], dtype=float32)

time = 50698	action = 1	current_phase = 1	next_phase = 0	reward = -1.892895	array([[-6.0696573, -3.4289365]], dtype=float32)

time = 50706	action = 0	current_phase = 0	next_phase = 1	reward = -0.486669	array([[-1.9369729, -3.1704152]], dtype=float32)

time = 50711	action = 0	current_phase = 0	next_phase = 1	reward = -0.335817	array([[-1.7590959, -2.4963634]], dtype=float32)

time = 50716	action = 1	current_phase = 0	next_phase = 1	reward = -1.307192	array([[-2.0288956, -0.986789 ]], dtype=float32)

time = 50724	action = 1	current_phase = 1	next_phase = 0	reward = -0.583259	array([[-2.6818292, -2.3417645]], dtype=float32)

time = 50732	action = 0	current_phase = 0	next_phase = 1	reward = -0.620834	array([[-2.2904706, -2.7994525]], dtype=float32)

time = 50737	action = 0	current_phase = 0	next_phase = 1	reward = -0.462091	array([[-2.0063798, -2.5814838]], dtype=float32)

time = 50742	action = 0	current_phase = 0	next_phase = 1	reward = -0.309655	array([[-2.082141 , -2.4268115]], dtype=float32)

time = 50747	action = 0	current_phase = 0	next_phase = 1	reward = -0.174227	array([[-2.331476 , -2.9941466]], dtype=float32)

time = 50752	action = 0	current_phase = 0	next_phase = 1	reward = 0.118331	array([[-2.5598204, -4.2610307]], dtype=float32)

time = 50757	action = 1	current_phase = 0	next_phase = 1	reward = -1.786750	array([[-6.616235 , -3.3537824]], dtype=float32)

time = 50765	action = 0	current_phase = 1	next_phase = 0	reward = -0.534945	array([[-1.9644778, -3.1475043]], dtype=float32)

time = 50770	action = 0	current_phase = 1	next_phase = 0	reward = -0.383840	array([[-1.9181565, -3.0856857]], dtype=float32)

time = 50775	action = 0	current_phase = 1	next_phase = 0	reward = -0.230676	array([[-1.9234926, -3.0753703]], dtype=float32)

time = 50780	action = 0	current_phase = 1	next_phase = 0	reward = 0.079494	array([[-2.2038116, -3.9288828]], dtype=float32)

time = 50785	action = 1	current_phase = 1	next_phase = 0	reward = -1.018659	array([[-2.9172165, -2.4954405]], dtype=float32)

time = 50793	action = 0	current_phase = 0	next_phase = 1	reward = -0.583775	array([[-2.1854277, -3.405711 ]], dtype=float32)

time = 50798	action = 0	current_phase = 0	next_phase = 1	reward = -0.415997	array([[-1.9930719, -2.56996  ]], dtype=float32)

time = 50803	action = 0	current_phase = 0	next_phase = 1	reward = -0.245710	array([[-1.963715 , -2.3586977]], dtype=float32)

time = 50808	action = 0	current_phase = 0	next_phase = 1	reward = -0.157431	array([[-2.2360065, -2.5949214]], dtype=float32)

time = 50813	action = 1	current_phase = 0	next_phase = 1	reward = -0.272344	array([[-3.7415292, -3.4125223]], dtype=float32)

time = 50821	action = 0	current_phase = 1	next_phase = 0	reward = -0.652309	array([[-2.2256975, -2.966879 ]], dtype=float32)

time = 50826	action = 0	current_phase = 1	next_phase = 0	reward = -0.508061	array([[-1.9597813, -3.1028936]], dtype=float32)

time = 50831	action = 0	current_phase = 1	next_phase = 0	reward = -0.355040	array([[-2.5680351, -3.2096574]], dtype=float32)

time = 50836	action = 0	current_phase = 1	next_phase = 0	reward = -0.209773	array([[-2.265374 , -3.3133028]], dtype=float32)

time = 50841	action = 0	current_phase = 1	next_phase = 0	reward = 0.308871	array([[-2.1628914, -3.949413 ]], dtype=float32)

time = 50846	action = 1	current_phase = 1	next_phase = 0	reward = -1.613424	array([[-5.894384, -3.296931]], dtype=float32)

time = 50854	action = 0	current_phase = 0	next_phase = 1	reward = -0.562688	array([[-1.961641 , -2.7902358]], dtype=float32)

time = 50859	action = 0	current_phase = 0	next_phase = 1	reward = -0.413411	array([[-1.7797334, -2.5205305]], dtype=float32)

time = 50864	action = 0	current_phase = 0	next_phase = 1	reward = -0.261291	array([[-1.963565, -2.358318]], dtype=float32)

time = 50869	action = 0	current_phase = 0	next_phase = 1	reward = -0.170983	array([[-2.2219062, -2.6310935]], dtype=float32)

time = 50874	action = 1	current_phase = 0	next_phase = 1	reward = -0.380590	array([[-5.106493 , -2.2290847]], dtype=float32)

time = 50882	action = 0	current_phase = 1	next_phase = 0	reward = -0.617469	array([[-2.205248 , -2.9690456]], dtype=float32)

time = 50887	action = 0	current_phase = 1	next_phase = 0	reward = -0.463772	array([[-1.9317459, -3.0772362]], dtype=float32)

time = 50892	action = 0	current_phase = 1	next_phase = 0	reward = -0.311030	array([[-1.9245296, -3.0754702]], dtype=float32)

time = 50897	action = 0	current_phase = 1	next_phase = 0	reward = -0.175086	array([[-2.2194648, -3.1891446]], dtype=float32)

time = 50902	action = 0	current_phase = 1	next_phase = 0	reward = 0.255244	array([[-2.6024356, -3.974907 ]], dtype=float32)

time = 50907	action = 1	current_phase = 1	next_phase = 0	reward = -1.781139	array([[-5.9567504, -3.3261309]], dtype=float32)

time = 50915	action = 0	current_phase = 0	next_phase = 1	reward = -0.524652	array([[-1.9786733, -3.1769352]], dtype=float32)

time = 50920	action = 0	current_phase = 0	next_phase = 1	reward = -0.369312	array([[-1.7579298, -2.4996068]], dtype=float32)

time = 50925	action = 0	current_phase = 0	next_phase = 1	reward = -0.214652	array([[-1.9678986, -2.3485303]], dtype=float32)

time = 50930	action = 0	current_phase = 0	next_phase = 1	reward = 0.343538	array([[-2.2258315, -3.7073672]], dtype=float32)

time = 50935	action = 1	current_phase = 0	next_phase = 1	reward = -1.370616	array([[-4.5981812, -3.0729795]], dtype=float32)

time = 50943	action = 0	current_phase = 1	next_phase = 0	reward = -0.593187	array([[-2.198872 , -2.9757965]], dtype=float32)

time = 50948	action = 0	current_phase = 1	next_phase = 0	reward = -0.447421	array([[-1.9293308, -3.079147 ]], dtype=float32)

time = 50953	action = 0	current_phase = 1	next_phase = 0	reward = -0.301795	array([[-1.9236635, -3.0752828]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.1129 - val_loss: 0.0459

Epoch 2/50

 - 4s - loss: 0.0838 - val_loss: 0.0477

Epoch 3/50

 - 4s - loss: 0.0948 - val_loss: 0.0472

Epoch 4/50

 - 4s - loss: 0.0944 - val_loss: 0.0466

Epoch 5/50

 - 4s - loss: 0.0793 - val_loss: 0.0477

Epoch 6/50

 - 4s - loss: 0.0816 - val_loss: 0.0488

Epoch 7/50

 - 4s - loss: 0.0755 - val_loss: 0.0502

Epoch 8/50

 - 4s - loss: 0.0812 - val_loss: 0.0524

Epoch 9/50

 - 4s - loss: 0.0715 - val_loss: 0.0506

Epoch 10/50

 - 4s - loss: 0.0779 - val_loss: 0.0489

Epoch 11/50

 - 4s - loss: 0.0680 - val_loss: 0.0498

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 50958	action = 0	current_phase = 1	next_phase = 0	reward = -0.168700	array([[-2.173599 , -3.2182627]], dtype=float32)

time = 50963	action = 0	current_phase = 1	next_phase = 0	reward = 0.030007	array([[-2.6415038, -3.8654447]], dtype=float32)

time = 50968	action = 1	current_phase = 1	next_phase = 0	reward = -1.899806	array([[-6.038855 , -3.4202764]], dtype=float32)

time = 50976	action = 0	current_phase = 0	next_phase = 1	reward = -0.499156	array([[-1.9696779, -3.174708 ]], dtype=float32)

time = 50981	action = 0	current_phase = 0	next_phase = 1	reward = -0.344757	array([[-1.7929649, -2.5313144]], dtype=float32)

time = 50986	action = 1	current_phase = 0	next_phase = 1	reward = -1.308047	array([[-2.043371 , -0.9802767]], dtype=float32)

time = 50994	action = 1	current_phase = 1	next_phase = 0	reward = -0.470273	array([[-2.7817335, -2.5002744]], dtype=float32)

time = 51002	action = 0	current_phase = 0	next_phase = 1	reward = -0.619791	array([[-2.2222931, -2.81693  ]], dtype=float32)

time = 51007	action = 0	current_phase = 0	next_phase = 1	reward = -0.468109	array([[-1.9752831, -2.6156416]], dtype=float32)

time = 51012	action = 0	current_phase = 0	next_phase = 1	reward = -0.323231	array([[-2.1215842, -2.4343154]], dtype=float32)

time = 51017	action = 0	current_phase = 0	next_phase = 1	reward = -0.183413	array([[-2.3029075, -3.0990164]], dtype=float32)

time = 51022	action = 0	current_phase = 0	next_phase = 1	reward = 0.253615	array([[-2.5952573, -4.3470254]], dtype=float32)

time = 51027	action = 1	current_phase = 0	next_phase = 1	reward = -1.781849	array([[-6.599825 , -3.3526797]], dtype=float32)

time = 51035	action = 0	current_phase = 1	next_phase = 0	reward = -0.533290	array([[-1.9550141, -3.1676948]], dtype=float32)

time = 51040	action = 0	current_phase = 1	next_phase = 0	reward = -0.380754	array([[-1.9353386, -3.0975862]], dtype=float32)

time = 51045	action = 0	current_phase = 1	next_phase = 0	reward = -0.220760	array([[-1.9303102, -3.091185 ]], dtype=float32)

time = 51050	action = 0	current_phase = 1	next_phase = 0	reward = 0.067612	array([[-2.1336622, -3.9041748]], dtype=float32)

time = 51055	action = 0	current_phase = 1	next_phase = 0	reward = -0.614780	array([[-2.7977836, -2.821834 ]], dtype=float32)

time = 51060	action = 1	current_phase = 1	next_phase = 0	reward = -2.125377	array([[-6.0564055, -3.424395 ]], dtype=float32)

time = 51068	action = 0	current_phase = 0	next_phase = 1	reward = -0.444221	array([[-1.9505203, -3.1740153]], dtype=float32)

time = 51073	action = 0	current_phase = 0	next_phase = 1	reward = -0.287708	array([[-2.1935205, -2.4436495]], dtype=float32)

time = 51078	action = 1	current_phase = 0	next_phase = 1	reward = -0.848463	array([[-2.1062202, -1.4775436]], dtype=float32)

time = 51086	action = 1	current_phase = 1	next_phase = 0	reward = -1.611610	array([[-3.285242 , -3.1720035]], dtype=float32)

time = 51094	action = 0	current_phase = 0	next_phase = 1	reward = -0.564261	array([[-2.075862 , -2.8487349]], dtype=float32)

time = 51099	action = 0	current_phase = 0	next_phase = 1	reward = -0.400880	array([[-1.9754002, -2.61019  ]], dtype=float32)

time = 51104	action = 0	current_phase = 0	next_phase = 1	reward = -0.246832	array([[-2.0142572, -2.3376296]], dtype=float32)

time = 51109	action = 0	current_phase = 0	next_phase = 1	reward = -0.178856	array([[-2.206914, -2.734735]], dtype=float32)

time = 51114	action = 1	current_phase = 0	next_phase = 1	reward = -0.542117	array([[-5.125438, -2.332236]], dtype=float32)

time = 51122	action = 0	current_phase = 1	next_phase = 0	reward = -0.616825	array([[-2.2473416, -2.9613183]], dtype=float32)

time = 51127	action = 0	current_phase = 1	next_phase = 0	reward = -0.457712	array([[-1.9357549, -3.0954158]], dtype=float32)

time = 51132	action = 0	current_phase = 1	next_phase = 0	reward = -0.296452	array([[-1.9336871, -3.0917208]], dtype=float32)

time = 51137	action = 0	current_phase = 1	next_phase = 0	reward = -0.165726	array([[-2.1838267, -3.2126596]], dtype=float32)

time = 51142	action = 0	current_phase = 1	next_phase = 0	reward = 0.182706	array([[-2.5777857, -3.793055 ]], dtype=float32)

time = 51147	action = 1	current_phase = 1	next_phase = 0	reward = -1.779129	array([[-6.0531297, -3.418923 ]], dtype=float32)

time = 51155	action = 0	current_phase = 0	next_phase = 1	reward = -0.519729	array([[-1.9979775, -3.1758919]], dtype=float32)

time = 51160	action = 0	current_phase = 0	next_phase = 1	reward = -0.366170	array([[-1.7920685, -2.526764 ]], dtype=float32)

time = 51165	action = 0	current_phase = 0	next_phase = 1	reward = -0.211217	array([[-2.0142946, -2.3372304]], dtype=float32)

time = 51170	action = 0	current_phase = 0	next_phase = 1	reward = 0.340572	array([[-2.2678866, -3.7489743]], dtype=float32)

time = 51175	action = 1	current_phase = 0	next_phase = 1	reward = -1.424660	array([[-4.5899477, -3.1201627]], dtype=float32)

time = 51183	action = 0	current_phase = 1	next_phase = 0	reward = -0.596115	array([[-2.1999512, -2.9796512]], dtype=float32)

time = 51188	action = 0	current_phase = 1	next_phase = 0	reward = -0.440583	array([[-1.9323249, -3.0915499]], dtype=float32)

time = 51193	action = 0	current_phase = 1	next_phase = 0	reward = -0.289865	array([[-1.9320945, -3.0913606]], dtype=float32)

time = 51198	action = 0	current_phase = 1	next_phase = 0	reward = -0.173663	array([[-2.1747696, -3.21794  ]], dtype=float32)

time = 51203	action = 0	current_phase = 1	next_phase = 0	reward = 0.071893	array([[-2.7238839, -3.8957832]], dtype=float32)

time = 51208	action = 1	current_phase = 1	next_phase = 0	reward = -1.895630	array([[-6.0541224, -3.4271777]], dtype=float32)

time = 51216	action = 0	current_phase = 0	next_phase = 1	reward = -0.494937	array([[-1.9653175, -3.1737332]], dtype=float32)

time = 51221	action = 0	current_phase = 0	next_phase = 1	reward = -0.339155	array([[-1.7924528, -2.529482 ]], dtype=float32)

time = 51226	action = 1	current_phase = 0	next_phase = 1	reward = -1.303680	array([[-2.1636245, -1.9832244]], dtype=float32)

time = 51234	action = 1	current_phase = 1	next_phase = 0	reward = -0.529422	array([[-2.6108341, -2.4681654]], dtype=float32)

time = 51242	action = 0	current_phase = 0	next_phase = 1	reward = -0.628928	array([[-2.1876276, -2.8151684]], dtype=float32)

time = 51247	action = 0	current_phase = 0	next_phase = 1	reward = -0.475993	array([[-1.9756069, -2.6142118]], dtype=float32)

time = 51252	action = 0	current_phase = 0	next_phase = 1	reward = -0.316477	array([[-2.0187473, -2.3847141]], dtype=float32)

time = 51257	action = 0	current_phase = 0	next_phase = 1	reward = -0.177750	array([[-2.3323367, -2.9980662]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0734 - val_loss: 0.0445

Epoch 2/50

 - 4s - loss: 0.0675 - val_loss: 0.0437

Epoch 3/50

 - 4s - loss: 0.0661 - val_loss: 0.0434

Epoch 4/50

 - 4s - loss: 0.0687 - val_loss: 0.0440

Epoch 5/50

 - 4s - loss: 0.0764 - val_loss: 0.0452

Epoch 6/50

 - 4s - loss: 0.0591 - val_loss: 0.0473

Epoch 7/50

 - 4s - loss: 0.0666 - val_loss: 0.0447

Epoch 8/50

 - 4s - loss: 0.0576 - val_loss: 0.0454

Epoch 9/50

 - 4s - loss: 0.0666 - val_loss: 0.0481

Epoch 10/50

 - 4s - loss: 0.0607 - val_loss: 0.0461

Epoch 11/50

 - 4s - loss: 0.0548 - val_loss: 0.0453

Epoch 12/50

 - 4s - loss: 0.0615 - val_loss: 0.0451

Epoch 13/50

 - 4s - loss: 0.0527 - val_loss: 0.0455

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1017, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1007, before forget

length of memory (state 1, action 1): 1000, after forget

time = 51262	action = 0	current_phase = 0	next_phase = 1	reward = 0.203758	array([[-2.6143153, -4.346971 ]], dtype=float32)

time = 51267	action = 1	current_phase = 0	next_phase = 1	reward = -1.785174	array([[-6.695782 , -3.3472557]], dtype=float32)

time = 51275	action = 0	current_phase = 1	next_phase = 0	reward = -0.532762	array([[-1.9313618, -3.1529615]], dtype=float32)

time = 51280	action = 0	current_phase = 1	next_phase = 0	reward = -0.383093	array([[-1.9435238, -3.0848694]], dtype=float32)

time = 51285	action = 0	current_phase = 1	next_phase = 0	reward = -0.231684	array([[-1.9388022, -3.081553 ]], dtype=float32)

time = 51290	action = 0	current_phase = 1	next_phase = 0	reward = 0.376923	array([[-2.0490577, -3.7222795]], dtype=float32)

time = 51295	action = 1	current_phase = 1	next_phase = 0	reward = -1.296866	array([[-3.3343227, -2.9740314]], dtype=float32)

time = 51303	action = 0	current_phase = 0	next_phase = 1	reward = -0.595551	array([[-2.1497195, -3.453259 ]], dtype=float32)

time = 51308	action = 0	current_phase = 0	next_phase = 1	reward = -0.438866	array([[-1.9472553, -2.6248927]], dtype=float32)

time = 51313	action = 0	current_phase = 0	next_phase = 1	reward = -0.283634	array([[-2.154282 , -2.5030441]], dtype=float32)

time = 51318	action = 0	current_phase = 0	next_phase = 1	reward = -0.160875	array([[-2.3249292, -3.1144435]], dtype=float32)

time = 51323	action = 0	current_phase = 0	next_phase = 1	reward = 0.013727	array([[-2.673133 , -4.3559985]], dtype=float32)

time = 51328	action = 1	current_phase = 0	next_phase = 1	reward = -1.902088	array([[-6.6990027, -3.3370068]], dtype=float32)

time = 51336	action = 0	current_phase = 1	next_phase = 0	reward = -0.495533	array([[-1.960777 , -3.1665814]], dtype=float32)

time = 51341	action = 0	current_phase = 1	next_phase = 0	reward = -0.346576	array([[-1.9303565, -3.097284 ]], dtype=float32)

time = 51346	action = 0	current_phase = 1	next_phase = 0	reward = -0.205409	array([[-1.9527265, -3.0945494]], dtype=float32)

time = 51351	action = 0	current_phase = 1	next_phase = 0	reward = 0.300634	array([[-2.2515922, -3.9626725]], dtype=float32)

time = 51356	action = 1	current_phase = 1	next_phase = 0	reward = -1.606904	array([[-3.5051594, -3.054863 ]], dtype=float32)

time = 51364	action = 0	current_phase = 0	next_phase = 1	reward = -0.552403	array([[-1.9255834, -2.847982 ]], dtype=float32)

time = 51369	action = 0	current_phase = 0	next_phase = 1	reward = -0.404762	array([[-1.9461832, -2.6234405]], dtype=float32)

time = 51374	action = 0	current_phase = 0	next_phase = 1	reward = -0.246239	array([[-1.99033 , -2.411929]], dtype=float32)

time = 51379	action = 0	current_phase = 0	next_phase = 1	reward = -0.186441	array([[-2.215697 , -2.6138973]], dtype=float32)

time = 51384	action = 1	current_phase = 0	next_phase = 1	reward = -0.559586	array([[-5.2382464, -2.3903775]], dtype=float32)

time = 51392	action = 0	current_phase = 1	next_phase = 0	reward = -0.624674	array([[-2.2202985, -2.9986522]], dtype=float32)

time = 51397	action = 0	current_phase = 1	next_phase = 0	reward = -0.472278	array([[-1.945173 , -3.0846798]], dtype=float32)

time = 51402	action = 0	current_phase = 1	next_phase = 0	reward = -0.314648	array([[-1.9450353, -3.084971 ]], dtype=float32)

time = 51407	action = 0	current_phase = 1	next_phase = 0	reward = -0.179826	array([[-2.199436 , -3.2168596]], dtype=float32)

time = 51412	action = 0	current_phase = 1	next_phase = 0	reward = 0.259186	array([[-2.5550942, -3.9567297]], dtype=float32)

time = 51417	action = 1	current_phase = 1	next_phase = 0	reward = -1.732868	array([[-6.0239844, -3.3623033]], dtype=float32)

time = 51425	action = 0	current_phase = 0	next_phase = 1	reward = -0.540059	array([[-1.9579865, -3.1485627]], dtype=float32)

time = 51430	action = 0	current_phase = 0	next_phase = 1	reward = -0.390838	array([[-1.7498962, -2.5766227]], dtype=float32)

time = 51435	action = 0	current_phase = 0	next_phase = 1	reward = -0.233653	array([[-1.9903616, -2.4115324]], dtype=float32)

time = 51440	action = 0	current_phase = 0	next_phase = 1	reward = -0.210012	array([[-2.2800508, -3.9391007]], dtype=float32)

time = 51445	action = 1	current_phase = 0	next_phase = 1	reward = -0.739643	array([[-5.202003 , -2.3263814]], dtype=float32)

time = 51453	action = 0	current_phase = 1	next_phase = 0	reward = -0.586475	array([[-2.2185872, -2.9982169]], dtype=float32)

time = 51458	action = 0	current_phase = 1	next_phase = 0	reward = -0.433325	array([[-1.9450988, -3.0852256]], dtype=float32)

time = 51463	action = 0	current_phase = 1	next_phase = 0	reward = -0.286666	array([[-1.9447354, -3.0842552]], dtype=float32)

time = 51468	action = 0	current_phase = 1	next_phase = 0	reward = -0.168664	array([[-2.192998, -3.207845]], dtype=float32)

time = 51473	action = 0	current_phase = 1	next_phase = 0	reward = 0.137229	array([[-2.6014407, -3.9789603]], dtype=float32)

time = 51478	action = 1	current_phase = 1	next_phase = 0	reward = -1.887255	array([[-6.0593214, -3.4009006]], dtype=float32)

time = 51486	action = 0	current_phase = 0	next_phase = 1	reward = -0.488000	array([[-1.9539821, -3.14826  ]], dtype=float32)

time = 51491	action = 0	current_phase = 0	next_phase = 1	reward = -0.337065	array([[-1.7339548, -2.552854 ]], dtype=float32)

time = 51496	action = 1	current_phase = 0	next_phase = 1	reward = -1.311811	array([[-2.0919173, -1.5363079]], dtype=float32)

time = 51504	action = 1	current_phase = 1	next_phase = 0	reward = -0.541140	array([[-2.7217467, -2.3476696]], dtype=float32)

time = 51512	action = 0	current_phase = 0	next_phase = 1	reward = -0.623831	array([[-2.2191255, -2.800344 ]], dtype=float32)

time = 51517	action = 0	current_phase = 0	next_phase = 1	reward = -0.472899	array([[-1.9485182, -2.7185006]], dtype=float32)

time = 51522	action = 0	current_phase = 0	next_phase = 1	reward = -0.323344	array([[-2.158506 , -2.5068593]], dtype=float32)

time = 51527	action = 0	current_phase = 0	next_phase = 1	reward = -0.185129	array([[-2.3032634, -3.145821 ]], dtype=float32)

time = 51532	action = 0	current_phase = 0	next_phase = 1	reward = 0.234599	array([[-2.6313078, -4.365333 ]], dtype=float32)

time = 51537	action = 1	current_phase = 0	next_phase = 1	reward = -1.774142	array([[-6.6869516, -3.3215945]], dtype=float32)

time = 51545	action = 0	current_phase = 1	next_phase = 0	reward = -0.511719	array([[-1.9312356, -3.1509407]], dtype=float32)

time = 51550	action = 0	current_phase = 1	next_phase = 0	reward = -0.353690	array([[-1.9429145, -3.0853639]], dtype=float32)

time = 51555	action = 0	current_phase = 1	next_phase = 0	reward = -0.208493	array([[-1.9447665, -3.0846686]], dtype=float32)

time = 51560	action = 0	current_phase = 1	next_phase = 0	reward = 0.343125	array([[-2.2239044, -3.9356418]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0416 - val_loss: 0.0328

Epoch 2/50

 - 4s - loss: 0.0450 - val_loss: 0.0416

Epoch 3/50

 - 4s - loss: 0.0383 - val_loss: 0.0333

Epoch 4/50

 - 4s - loss: 0.0394 - val_loss: 0.0298

Epoch 5/50

 - 4s - loss: 0.0393 - val_loss: 0.0332

Epoch 6/50

 - 4s - loss: 0.0394 - val_loss: 0.0364

Epoch 7/50

 - 4s - loss: 0.0417 - val_loss: 0.0370

Epoch 8/50

 - 4s - loss: 0.0323 - val_loss: 0.0370

Epoch 9/50

 - 4s - loss: 0.0559 - val_loss: 0.0413

Epoch 10/50

 - 4s - loss: 0.0362 - val_loss: 0.0352

Epoch 11/50

 - 4s - loss: 0.0333 - val_loss: 0.0376

Epoch 12/50

 - 4s - loss: 0.0289 - val_loss: 0.0430

Epoch 13/50

 - 4s - loss: 0.0340 - val_loss: 0.0465

Epoch 14/50

 - 4s - loss: 0.0362 - val_loss: 0.0358

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 51565	action = 1	current_phase = 1	next_phase = 0	reward = -1.267897	array([[-3.291831 , -3.0951195]], dtype=float32)

time = 51573	action = 0	current_phase = 0	next_phase = 1	reward = -0.579069	array([[-2.1743972, -3.4939313]], dtype=float32)

time = 51578	action = 0	current_phase = 0	next_phase = 1	reward = -0.418936	array([[-2.1180906, -2.7300045]], dtype=float32)

time = 51583	action = 0	current_phase = 0	next_phase = 1	reward = -0.253362	array([[-2.0059257, -2.6885583]], dtype=float32)

time = 51588	action = 0	current_phase = 0	next_phase = 1	reward = -0.161987	array([[-2.2038043, -3.020777 ]], dtype=float32)

time = 51593	action = 0	current_phase = 0	next_phase = 1	reward = 0.037309	array([[-3.5794141, -3.582996 ]], dtype=float32)

time = 51598	action = 1	current_phase = 0	next_phase = 1	reward = -1.890280	array([[-6.693119 , -3.4247453]], dtype=float32)

time = 51606	action = 0	current_phase = 1	next_phase = 0	reward = -0.485282	array([[-2.064484 , -3.1460857]], dtype=float32)

time = 51611	action = 0	current_phase = 1	next_phase = 0	reward = -0.331421	array([[-1.98848  , -3.0820293]], dtype=float32)

time = 51616	action = 0	current_phase = 1	next_phase = 0	reward = -0.183978	array([[-2.1111465, -3.1512852]], dtype=float32)

time = 51621	action = 0	current_phase = 1	next_phase = 0	reward = 0.304403	array([[-2.3741076, -3.9184906]], dtype=float32)

time = 51626	action = 1	current_phase = 1	next_phase = 0	reward = -1.609402	array([[-5.741833 , -3.1943538]], dtype=float32)

time = 51634	action = 0	current_phase = 0	next_phase = 1	reward = -0.556536	array([[-1.9815264, -2.8902583]], dtype=float32)

time = 51639	action = 0	current_phase = 0	next_phase = 1	reward = -0.401206	array([[-2.026614 , -2.6549609]], dtype=float32)

time = 51644	action = 0	current_phase = 0	next_phase = 1	reward = -0.250806	array([[-2.0050633, -2.686874 ]], dtype=float32)

time = 51649	action = 0	current_phase = 0	next_phase = 1	reward = -0.185008	array([[-2.0985737, -2.751602 ]], dtype=float32)

time = 51654	action = 1	current_phase = 0	next_phase = 1	reward = -0.609798	array([[-5.2791657, -2.350681 ]], dtype=float32)

time = 51662	action = 0	current_phase = 1	next_phase = 0	reward = -0.616077	array([[-2.170708 , -2.9993987]], dtype=float32)

time = 51667	action = 0	current_phase = 1	next_phase = 0	reward = -0.470179	array([[-1.9890571, -3.0814233]], dtype=float32)

time = 51672	action = 0	current_phase = 1	next_phase = 0	reward = -0.315315	array([[-1.9885633, -3.0814655]], dtype=float32)

time = 51677	action = 0	current_phase = 1	next_phase = 0	reward = -0.176184	array([[-2.19283  , -3.1750233]], dtype=float32)

time = 51682	action = 0	current_phase = 1	next_phase = 0	reward = 0.244005	array([[-2.4982882, -3.9303377]], dtype=float32)

time = 51687	action = 1	current_phase = 1	next_phase = 0	reward = -1.726462	array([[-6.0593987, -3.3807955]], dtype=float32)

time = 51695	action = 0	current_phase = 0	next_phase = 1	reward = -0.518585	array([[-1.9050602, -3.1536531]], dtype=float32)

time = 51700	action = 0	current_phase = 0	next_phase = 1	reward = -0.365158	array([[-1.8779799, -2.662762 ]], dtype=float32)

time = 51705	action = 0	current_phase = 0	next_phase = 1	reward = -0.214485	array([[-2.0056937, -2.6889045]], dtype=float32)

time = 51710	action = 0	current_phase = 0	next_phase = 1	reward = 0.346905	array([[-2.1311965, -3.3588364]], dtype=float32)

time = 51715	action = 1	current_phase = 0	next_phase = 1	reward = -1.367904	array([[-4.613701 , -3.1605182]], dtype=float32)

time = 51723	action = 0	current_phase = 1	next_phase = 0	reward = -0.579420	array([[-2.1732166, -2.998087 ]], dtype=float32)

time = 51728	action = 0	current_phase = 1	next_phase = 0	reward = -0.425279	array([[-1.9884254, -3.0814176]], dtype=float32)

time = 51733	action = 0	current_phase = 1	next_phase = 0	reward = -0.275337	array([[-1.9882731, -3.0811443]], dtype=float32)

time = 51738	action = 0	current_phase = 1	next_phase = 0	reward = -0.162269	array([[-2.1813464, -3.1776989]], dtype=float32)

time = 51743	action = 0	current_phase = 1	next_phase = 0	reward = 0.067105	array([[-2.6006682, -3.6309934]], dtype=float32)

time = 51748	action = 1	current_phase = 1	next_phase = 0	reward = -1.896243	array([[-6.0762677, -3.3921168]], dtype=float32)

time = 51756	action = 0	current_phase = 0	next_phase = 1	reward = -0.486390	array([[-1.8917528, -3.1526709]], dtype=float32)

time = 51761	action = 0	current_phase = 0	next_phase = 1	reward = -0.334106	array([[-1.7952006, -2.6449654]], dtype=float32)

time = 51766	action = 1	current_phase = 0	next_phase = 1	reward = -1.315808	array([[-2.019799 , -1.5489911]], dtype=float32)

time = 51774	action = 1	current_phase = 1	next_phase = 0	reward = -0.543867	array([[-2.95363  , -2.6138604]], dtype=float32)

time = 51782	action = 0	current_phase = 0	next_phase = 1	reward = -0.622404	array([[-2.2689798, -2.8189008]], dtype=float32)

time = 51787	action = 0	current_phase = 0	next_phase = 1	reward = -0.475886	array([[-2.0489526, -2.6765294]], dtype=float32)

time = 51792	action = 0	current_phase = 0	next_phase = 1	reward = -0.326889	array([[-2.116393 , -2.7292523]], dtype=float32)

time = 51797	action = 0	current_phase = 0	next_phase = 1	reward = -0.187501	array([[-2.271115 , -3.2023566]], dtype=float32)

time = 51802	action = 0	current_phase = 0	next_phase = 1	reward = 0.181066	array([[-2.2424953, -4.0194793]], dtype=float32)

time = 51807	action = 1	current_phase = 0	next_phase = 1	reward = -1.784047	array([[-6.7060676, -3.3972723]], dtype=float32)

time = 51815	action = 0	current_phase = 1	next_phase = 0	reward = -0.530487	array([[-2.0655158, -3.1508098]], dtype=float32)

time = 51820	action = 0	current_phase = 1	next_phase = 0	reward = -0.370157	array([[-1.9884385, -3.0815215]], dtype=float32)

time = 51825	action = 0	current_phase = 1	next_phase = 0	reward = -0.212903	array([[-1.9889002, -3.0836296]], dtype=float32)

time = 51830	action = 0	current_phase = 1	next_phase = 0	reward = 0.361428	array([[-2.054994 , -3.7961047]], dtype=float32)

time = 51835	action = 1	current_phase = 1	next_phase = 0	reward = -1.363247	array([[-3.2674036, -3.0388846]], dtype=float32)

time = 51843	action = 0	current_phase = 0	next_phase = 1	reward = -0.595685	array([[-2.1737678, -3.4938042]], dtype=float32)

time = 51848	action = 0	current_phase = 0	next_phase = 1	reward = -0.442884	array([[-2.0663254, -2.6960645]], dtype=float32)

time = 51853	action = 0	current_phase = 0	next_phase = 1	reward = -0.285476	array([[-2.015738 , -2.6993296]], dtype=float32)

time = 51858	action = 0	current_phase = 0	next_phase = 1	reward = -0.163697	array([[-2.2717295, -3.2028248]], dtype=float32)

time = 51863	action = 0	current_phase = 0	next_phase = 1	reward = 0.006425	array([[-2.8540435, -4.431104 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0376 - val_loss: 0.0207

Epoch 2/50

 - 4s - loss: 0.0333 - val_loss: 0.0213

Epoch 3/50

 - 4s - loss: 0.0391 - val_loss: 0.0215

Epoch 4/50

 - 4s - loss: 0.0395 - val_loss: 0.0210

Epoch 5/50

 - 4s - loss: 0.0307 - val_loss: 0.0232

Epoch 6/50

 - 4s - loss: 0.0417 - val_loss: 0.0232

Epoch 7/50

 - 4s - loss: 0.0319 - val_loss: 0.0232

Epoch 8/50

 - 4s - loss: 0.0291 - val_loss: 0.0240

Epoch 9/50

 - 4s - loss: 0.0296 - val_loss: 0.0246

Epoch 10/50

 - 4s - loss: 0.0301 - val_loss: 0.0220

Epoch 11/50

 - 4s - loss: 0.0251 - val_loss: 0.0229

length of memory (state 0, action 0): 1025, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1018, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 51868	action = 1	current_phase = 0	next_phase = 1	reward = -1.898846	array([[-6.625266 , -3.4317067]], dtype=float32)

time = 51876	action = 0	current_phase = 1	next_phase = 0	reward = -0.496691	array([[-2.0736215, -3.1294677]], dtype=float32)

time = 51881	action = 0	current_phase = 1	next_phase = 0	reward = -0.343782	array([[-1.9864885, -3.093079 ]], dtype=float32)

time = 51886	action = 0	current_phase = 1	next_phase = 0	reward = -0.193907	array([[-2.014814 , -3.1113648]], dtype=float32)

time = 51891	action = 0	current_phase = 1	next_phase = 0	reward = 0.308410	array([[-2.1848319, -3.9421053]], dtype=float32)

time = 51896	action = 1	current_phase = 1	next_phase = 0	reward = -1.613185	array([[-5.6223054, -3.1297317]], dtype=float32)

time = 51904	action = 0	current_phase = 0	next_phase = 1	reward = -0.561645	array([[-1.9252217, -2.8463361]], dtype=float32)

time = 51909	action = 0	current_phase = 0	next_phase = 1	reward = -0.405728	array([[-1.6596346, -2.688867 ]], dtype=float32)

time = 51914	action = 0	current_phase = 0	next_phase = 1	reward = -0.259106	array([[-1.909628, -2.84864 ]], dtype=float32)

time = 51919	action = 0	current_phase = 0	next_phase = 1	reward = -0.179154	array([[-2.0586011, -2.8087006]], dtype=float32)

time = 51924	action = 1	current_phase = 0	next_phase = 1	reward = -0.565757	array([[-5.292373 , -2.2700403]], dtype=float32)

time = 51932	action = 0	current_phase = 1	next_phase = 0	reward = -0.609566	array([[-2.1623316, -3.0070574]], dtype=float32)

time = 51937	action = 0	current_phase = 1	next_phase = 0	reward = -0.459566	array([[-1.9811437, -3.079831 ]], dtype=float32)

time = 51942	action = 0	current_phase = 1	next_phase = 0	reward = -0.299107	array([[-1.9876926, -3.0853398]], dtype=float32)

time = 51947	action = 0	current_phase = 1	next_phase = 0	reward = -0.168680	array([[-2.199051, -3.173313]], dtype=float32)

time = 51952	action = 0	current_phase = 1	next_phase = 0	reward = 0.228951	array([[-2.5268223, -3.9285247]], dtype=float32)

time = 51957	action = 1	current_phase = 1	next_phase = 0	reward = -1.785523	array([[-6.0550265, -3.3914285]], dtype=float32)

time = 51965	action = 0	current_phase = 0	next_phase = 1	reward = -0.537445	array([[-1.8713863, -3.1288633]], dtype=float32)

time = 51970	action = 0	current_phase = 0	next_phase = 1	reward = -0.388051	array([[-1.8472519, -2.6544473]], dtype=float32)

time = 51975	action = 0	current_phase = 0	next_phase = 1	reward = -0.234836	array([[-1.9118141, -2.855533 ]], dtype=float32)

time = 51980	action = 0	current_phase = 0	next_phase = 1	reward = 0.080627	array([[-2.1302936, -3.975315 ]], dtype=float32)

time = 51985	action = 1	current_phase = 0	next_phase = 1	reward = -1.020466	array([[-4.980103, -2.646313]], dtype=float32)

time = 51993	action = 0	current_phase = 1	next_phase = 0	reward = -0.588745	array([[-2.1164985, -3.0216508]], dtype=float32)

time = 51998	action = 0	current_phase = 1	next_phase = 0	reward = -0.441503	array([[-1.9801022, -3.078996 ]], dtype=float32)

time = 52003	action = 0	current_phase = 1	next_phase = 0	reward = -0.286432	array([[-1.9814914, -3.0782905]], dtype=float32)

time = 52008	action = 0	current_phase = 1	next_phase = 0	reward = -0.165784	array([[-2.1974564, -3.1738298]], dtype=float32)

time = 52013	action = 0	current_phase = 1	next_phase = 0	reward = 0.139513	array([[-2.5504842, -3.8307056]], dtype=float32)

time = 52018	action = 1	current_phase = 1	next_phase = 0	reward = -1.905010	array([[-6.076917 , -3.4132452]], dtype=float32)

time = 52026	action = 0	current_phase = 0	next_phase = 1	reward = -0.513711	array([[-1.8450471, -3.1194878]], dtype=float32)

time = 52031	action = 0	current_phase = 0	next_phase = 1	reward = -0.370376	array([[-1.6452312, -2.6760767]], dtype=float32)

time = 52036	action = 0	current_phase = 0	next_phase = 1	reward = -0.211849	array([[-1.9347914, -2.7900538]], dtype=float32)

time = 52041	action = 0	current_phase = 0	next_phase = 1	reward = 0.342222	array([[-2.1321874, -4.0096354]], dtype=float32)

time = 52046	action = 1	current_phase = 0	next_phase = 1	reward = -1.443661	array([[-4.5191774, -3.191519 ]], dtype=float32)

time = 52054	action = 0	current_phase = 1	next_phase = 0	reward = -0.560589	array([[-2.0780118, -3.0482254]], dtype=float32)

time = 52059	action = 0	current_phase = 1	next_phase = 0	reward = -0.403514	array([[-1.9802351, -3.0790322]], dtype=float32)

time = 52064	action = 0	current_phase = 1	next_phase = 0	reward = -0.252613	array([[-1.9766623, -3.07044  ]], dtype=float32)

time = 52069	action = 0	current_phase = 1	next_phase = 0	reward = 0.117016	array([[-2.0455472, -3.6810288]], dtype=float32)

time = 52074	action = 1	current_phase = 1	next_phase = 0	reward = -0.647746	array([[-2.6082442, -2.3039284]], dtype=float32)

time = 52082	action = 0	current_phase = 0	next_phase = 1	reward = -0.613996	array([[-2.1300225, -3.4466035]], dtype=float32)

time = 52087	action = 0	current_phase = 0	next_phase = 1	reward = -0.458800	array([[-1.9322681, -2.6419635]], dtype=float32)

time = 52092	action = 0	current_phase = 0	next_phase = 1	reward = -0.300379	array([[-1.9488385, -2.8581018]], dtype=float32)

time = 52097	action = 0	current_phase = 0	next_phase = 1	reward = -0.171804	array([[-2.1902122, -3.2328272]], dtype=float32)

time = 52102	action = 0	current_phase = 0	next_phase = 1	reward = 0.124632	array([[-2.4658952, -4.3748097]], dtype=float32)

time = 52107	action = 1	current_phase = 0	next_phase = 1	reward = -1.785704	array([[-6.661986 , -3.3828027]], dtype=float32)

time = 52115	action = 0	current_phase = 1	next_phase = 0	reward = -0.530515	array([[-2.06439  , -3.1366782]], dtype=float32)

time = 52120	action = 0	current_phase = 1	next_phase = 0	reward = -0.370218	array([[-1.9803191, -3.0804858]], dtype=float32)

time = 52125	action = 0	current_phase = 1	next_phase = 0	reward = -0.215933	array([[-1.9819134, -3.0804882]], dtype=float32)

time = 52130	action = 0	current_phase = 1	next_phase = 0	reward = 0.355988	array([[-2.1623886, -3.8768885]], dtype=float32)

time = 52135	action = 1	current_phase = 1	next_phase = 0	reward = -1.251550	array([[-3.330027 , -3.0478094]], dtype=float32)

time = 52143	action = 0	current_phase = 0	next_phase = 1	reward = -0.574524	array([[-2.1254003, -3.4283578]], dtype=float32)

time = 52148	action = 0	current_phase = 0	next_phase = 1	reward = -0.413475	array([[-1.9309986, -2.6401591]], dtype=float32)

time = 52153	action = 0	current_phase = 0	next_phase = 1	reward = -0.239486	array([[-2.1086085, -2.8326125]], dtype=float32)

time = 52158	action = 0	current_phase = 0	next_phase = 1	reward = -0.167497	array([[-2.056221 , -2.8512619]], dtype=float32)

time = 52163	action = 1	current_phase = 0	next_phase = 1	reward = -1.132313	array([[-4.7596173, -3.0753083]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0314 - val_loss: 0.0234

Epoch 2/50

 - 4s - loss: 0.0316 - val_loss: 0.0227

Epoch 3/50

 - 4s - loss: 0.0256 - val_loss: 0.0213

Epoch 4/50

 - 4s - loss: 0.0246 - val_loss: 0.0236

Epoch 5/50

 - 4s - loss: 0.0250 - val_loss: 0.0255

Epoch 6/50

 - 4s - loss: 0.0220 - val_loss: 0.0229

Epoch 7/50

 - 4s - loss: 0.0233 - val_loss: 0.0225

Epoch 8/50

 - 4s - loss: 0.0230 - val_loss: 0.0221

Epoch 9/50

 - 4s - loss: 0.0249 - val_loss: 0.0225

Epoch 10/50

 - 4s - loss: 0.0223 - val_loss: 0.0229

Epoch 11/50

 - 4s - loss: 0.0219 - val_loss: 0.0215

Epoch 12/50

 - 4s - loss: 0.0240 - val_loss: 0.0214

Epoch 13/50

 - 4s - loss: 0.0215 - val_loss: 0.0209

Epoch 14/50

 - 4s - loss: 0.0219 - val_loss: 0.0209

Epoch 15/50

 - 4s - loss: 0.0233 - val_loss: 0.0228

Epoch 16/50

 - 4s - loss: 0.0262 - val_loss: 0.0209

Epoch 17/50

 - 4s - loss: 0.0222 - val_loss: 0.0236

Epoch 18/50

 - 4s - loss: 0.0203 - val_loss: 0.0214

Epoch 19/50

 - 4s - loss: 0.0216 - val_loss: 0.0214

Epoch 20/50

 - 4s - loss: 0.0222 - val_loss: 0.0224

Epoch 21/50

 - 4s - loss: 0.0197 - val_loss: 0.0246

Epoch 22/50

 - 4s - loss: 0.0201 - val_loss: 0.0242

Epoch 23/50

 - 4s - loss: 0.0230 - val_loss: 0.0256

Epoch 24/50

 - 4s - loss: 0.0220 - val_loss: 0.0221

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 52171	action = 0	current_phase = 1	next_phase = 0	reward = -1.182998	array([[-3.1722167, -3.2116053]], dtype=float32)

time = 52176	action = 0	current_phase = 1	next_phase = 0	reward = -1.042513	array([[-2.8295922, -3.2818434]], dtype=float32)

time = 52181	action = 0	current_phase = 1	next_phase = 0	reward = -0.904113	array([[-2.8482764, -3.3264987]], dtype=float32)

time = 52186	action = 0	current_phase = 1	next_phase = 0	reward = -0.781802	array([[-2.1069717, -3.184451 ]], dtype=float32)

time = 52191	action = 0	current_phase = 1	next_phase = 0	reward = -0.312287	array([[-2.5739584, -3.9947035]], dtype=float32)

time = 52196	action = 1	current_phase = 1	next_phase = 0	reward = -1.694739	array([[-6.0859985, -3.3768635]], dtype=float32)

time = 52204	action = 0	current_phase = 0	next_phase = 1	reward = -0.561259	array([[-2.0059707, -2.8354197]], dtype=float32)

time = 52209	action = 0	current_phase = 0	next_phase = 1	reward = -0.407580	array([[-1.990965 , -2.6475804]], dtype=float32)

time = 52214	action = 0	current_phase = 0	next_phase = 1	reward = -0.262621	array([[-1.963324 , -2.9728937]], dtype=float32)

time = 52219	action = 0	current_phase = 0	next_phase = 1	reward = -0.173865	array([[-2.0758088, -2.884729 ]], dtype=float32)

time = 52224	action = 1	current_phase = 0	next_phase = 1	reward = -0.425086	array([[-5.1799192, -2.4634256]], dtype=float32)

time = 52232	action = 0	current_phase = 1	next_phase = 0	reward = -0.621352	array([[-2.1417885, -3.034479 ]], dtype=float32)

time = 52237	action = 0	current_phase = 1	next_phase = 0	reward = -0.474530	array([[-1.9683982, -3.0961242]], dtype=float32)

time = 52242	action = 0	current_phase = 1	next_phase = 0	reward = -0.326543	array([[-1.9691504, -3.0968325]], dtype=float32)

time = 52247	action = 0	current_phase = 1	next_phase = 0	reward = -0.189363	array([[-2.2114897, -3.1881573]], dtype=float32)

time = 52252	action = 0	current_phase = 1	next_phase = 0	reward = 0.179556	array([[-2.509946 , -3.8375692]], dtype=float32)

time = 52257	action = 1	current_phase = 1	next_phase = 0	reward = -1.783511	array([[-6.043123 , -3.4043572]], dtype=float32)

time = 52265	action = 0	current_phase = 0	next_phase = 1	reward = -0.536689	array([[-1.8999513, -3.1215682]], dtype=float32)

time = 52270	action = 0	current_phase = 0	next_phase = 1	reward = -0.383420	array([[-1.9606814, -2.6553094]], dtype=float32)

time = 52275	action = 0	current_phase = 0	next_phase = 1	reward = -0.233804	array([[-1.9590839, -2.9797935]], dtype=float32)

time = 52280	action = 0	current_phase = 0	next_phase = 1	reward = 0.088189	array([[-2.1136317, -3.1907735]], dtype=float32)

time = 52285	action = 1	current_phase = 0	next_phase = 1	reward = -0.958428	array([[-5.02275  , -2.6633482]], dtype=float32)

time = 52293	action = 0	current_phase = 1	next_phase = 0	reward = -0.579400	array([[-2.115962 , -3.0435147]], dtype=float32)

time = 52298	action = 0	current_phase = 1	next_phase = 0	reward = -0.429190	array([[-1.9657038, -3.0942552]], dtype=float32)

time = 52303	action = 0	current_phase = 1	next_phase = 0	reward = -0.269124	array([[-1.9658128, -3.094167 ]], dtype=float32)

time = 52308	action = 0	current_phase = 1	next_phase = 0	reward = -0.162022	array([[-2.2009041, -3.1893358]], dtype=float32)

time = 52313	action = 0	current_phase = 1	next_phase = 0	reward = 0.062077	array([[-2.5433514, -3.924396 ]], dtype=float32)

time = 52318	action = 1	current_phase = 1	next_phase = 0	reward = -1.898383	array([[-6.1006284, -3.4137473]], dtype=float32)

time = 52326	action = 0	current_phase = 0	next_phase = 1	reward = -0.503892	array([[-1.8931999, -3.1225038]], dtype=float32)

time = 52331	action = 0	current_phase = 0	next_phase = 1	reward = -0.341721	array([[-1.7322779, -2.7252412]], dtype=float32)

time = 52336	action = 0	current_phase = 0	next_phase = 1	reward = -0.186153	array([[-2.20088  , -3.3622203]], dtype=float32)

time = 52341	action = 0	current_phase = 0	next_phase = 1	reward = 0.297757	array([[-2.1966765, -3.9249926]], dtype=float32)

time = 52346	action = 1	current_phase = 0	next_phase = 1	reward = -1.611691	array([[-4.546783 , -3.2134256]], dtype=float32)

time = 52354	action = 0	current_phase = 1	next_phase = 0	reward = -0.557591	array([[-2.0689554, -3.0681899]], dtype=float32)

time = 52359	action = 0	current_phase = 1	next_phase = 0	reward = -0.397199	array([[-1.9657668, -3.0942721]], dtype=float32)

time = 52364	action = 0	current_phase = 1	next_phase = 0	reward = -0.239029	array([[-1.9027742, -3.0371754]], dtype=float32)

time = 52369	action = 0	current_phase = 1	next_phase = 0	reward = -0.174187	array([[-2.0150325, -3.734882 ]], dtype=float32)

time = 52374	action = 1	current_phase = 1	next_phase = 0	reward = -0.529141	array([[-2.4740815, -2.234505 ]], dtype=float32)

time = 52382	action = 0	current_phase = 0	next_phase = 1	reward = -0.624083	array([[-2.1654625, -3.4831033]], dtype=float32)

time = 52387	action = 0	current_phase = 0	next_phase = 1	reward = -0.475269	array([[-2.0118425, -2.6578076]], dtype=float32)

time = 52392	action = 0	current_phase = 0	next_phase = 1	reward = -0.322313	array([[-2.1493568, -2.9219077]], dtype=float32)

time = 52397	action = 0	current_phase = 0	next_phase = 1	reward = -0.183313	array([[-2.1923947, -3.2547688]], dtype=float32)

time = 52402	action = 0	current_phase = 0	next_phase = 1	reward = 0.247804	array([[-2.48898  , -4.3902097]], dtype=float32)

time = 52407	action = 1	current_phase = 0	next_phase = 1	reward = -1.777631	array([[-6.382384 , -3.3149395]], dtype=float32)

time = 52415	action = 0	current_phase = 1	next_phase = 0	reward = -0.524723	array([[-2.053199 , -3.1429775]], dtype=float32)

time = 52420	action = 0	current_phase = 1	next_phase = 0	reward = -0.367979	array([[-1.9658741, -3.0944073]], dtype=float32)

time = 52425	action = 0	current_phase = 1	next_phase = 0	reward = -0.213448	array([[-1.9306244, -3.0578716]], dtype=float32)

time = 52430	action = 0	current_phase = 1	next_phase = 0	reward = 0.379209	array([[-2.0549958, -3.7756715]], dtype=float32)

time = 52435	action = 1	current_phase = 1	next_phase = 0	reward = -1.300751	array([[-3.3160353, -3.1033294]], dtype=float32)

time = 52443	action = 0	current_phase = 0	next_phase = 1	reward = -0.594611	array([[-2.1618283, -3.4640884]], dtype=float32)

time = 52448	action = 0	current_phase = 0	next_phase = 1	reward = -0.443294	array([[-1.9927353, -2.650947 ]], dtype=float32)

time = 52453	action = 0	current_phase = 0	next_phase = 1	reward = -0.290414	array([[-1.957361 , -2.9729598]], dtype=float32)

time = 52458	action = 0	current_phase = 0	next_phase = 1	reward = -0.167542	array([[-2.193731 , -3.2625368]], dtype=float32)

time = 52463	action = 0	current_phase = 0	next_phase = 1	reward = 0.090691	array([[-2.494624 , -4.3705506]], dtype=float32)

time = 52468	action = 1	current_phase = 0	next_phase = 1	reward = -1.900765	array([[-6.637855 , -3.4158423]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0228 - val_loss: 0.0184

Epoch 2/50

 - 4s - loss: 0.0178 - val_loss: 0.0181

Epoch 3/50

 - 4s - loss: 0.0201 - val_loss: 0.0164

Epoch 4/50

 - 4s - loss: 0.0164 - val_loss: 0.0174

Epoch 5/50

 - 4s - loss: 0.0152 - val_loss: 0.0163

Epoch 6/50

 - 4s - loss: 0.0182 - val_loss: 0.0171

Epoch 7/50

 - 4s - loss: 0.0203 - val_loss: 0.0194

Epoch 8/50

 - 4s - loss: 0.0174 - val_loss: 0.0197

Epoch 9/50

 - 4s - loss: 0.0145 - val_loss: 0.0179

Epoch 10/50

 - 4s - loss: 0.0160 - val_loss: 0.0172

Epoch 11/50

 - 4s - loss: 0.0165 - val_loss: 0.0175

Epoch 12/50

 - 4s - loss: 0.0149 - val_loss: 0.0166

Epoch 13/50

 - 4s - loss: 0.0153 - val_loss: 0.0178

Epoch 14/50

 - 4s - loss: 0.0172 - val_loss: 0.0167

Epoch 15/50

 - 4s - loss: 0.0170 - val_loss: 0.0173

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 52476	action = 0	current_phase = 1	next_phase = 0	reward = -0.501756	array([[-2.0578  , -3.181011]], dtype=float32)

time = 52481	action = 0	current_phase = 1	next_phase = 0	reward = -0.345500	array([[-1.9999456, -3.131929 ]], dtype=float32)

time = 52486	action = 0	current_phase = 1	next_phase = 0	reward = -0.195920	array([[-2.0664096, -3.179483 ]], dtype=float32)

time = 52491	action = 0	current_phase = 1	next_phase = 0	reward = 0.338852	array([[-2.187292 , -3.9868202]], dtype=float32)

time = 52496	action = 1	current_phase = 1	next_phase = 0	reward = -1.601336	array([[-3.3433661, -3.125087 ]], dtype=float32)

time = 52504	action = 0	current_phase = 0	next_phase = 1	reward = -0.553834	array([[-2.0249448, -2.8439708]], dtype=float32)

time = 52509	action = 0	current_phase = 0	next_phase = 1	reward = -0.401383	array([[-1.9845802, -2.6624897]], dtype=float32)

time = 52514	action = 0	current_phase = 0	next_phase = 1	reward = -0.249048	array([[-1.9863529, -3.0402167]], dtype=float32)

time = 52519	action = 0	current_phase = 0	next_phase = 1	reward = -0.181018	array([[-2.0765991, -2.970398 ]], dtype=float32)

time = 52524	action = 1	current_phase = 0	next_phase = 1	reward = -0.545971	array([[-5.3089695, -2.2836213]], dtype=float32)

time = 52532	action = 0	current_phase = 1	next_phase = 0	reward = -0.611514	array([[-2.182128 , -3.0646186]], dtype=float32)

time = 52537	action = 0	current_phase = 1	next_phase = 0	reward = -0.461482	array([[-2.0071347, -3.13333  ]], dtype=float32)

time = 52542	action = 0	current_phase = 1	next_phase = 0	reward = -0.308729	array([[-1.9956973, -3.1212585]], dtype=float32)

time = 52547	action = 0	current_phase = 1	next_phase = 0	reward = -0.172718	array([[-2.21761  , -3.2274137]], dtype=float32)

time = 52552	action = 0	current_phase = 1	next_phase = 0	reward = 0.120211	array([[-2.5754611, -3.9338486]], dtype=float32)

time = 52557	action = 1	current_phase = 1	next_phase = 0	reward = -1.784109	array([[-6.1022224, -3.4273863]], dtype=float32)

time = 52565	action = 0	current_phase = 0	next_phase = 1	reward = -0.518011	array([[-1.884832 , -3.1118739]], dtype=float32)

time = 52570	action = 0	current_phase = 0	next_phase = 1	reward = -0.357018	array([[-1.9399468, -2.6720214]], dtype=float32)

time = 52575	action = 0	current_phase = 0	next_phase = 1	reward = -0.208765	array([[-1.9954245, -3.067917 ]], dtype=float32)

time = 52580	action = 0	current_phase = 0	next_phase = 1	reward = 0.357144	array([[-2.1341965, -3.824213 ]], dtype=float32)

time = 52585	action = 1	current_phase = 0	next_phase = 1	reward = -1.417820	array([[-4.4985695, -3.139815 ]], dtype=float32)

time = 52593	action = 0	current_phase = 1	next_phase = 0	reward = -0.592571	array([[-2.1835182, -3.0635195]], dtype=float32)

time = 52598	action = 0	current_phase = 1	next_phase = 0	reward = -0.436108	array([[-1.99821  , -3.1241128]], dtype=float32)

time = 52603	action = 0	current_phase = 1	next_phase = 0	reward = -0.287883	array([[-1.9939986, -3.1193454]], dtype=float32)

time = 52608	action = 0	current_phase = 1	next_phase = 0	reward = -0.162959	array([[-2.2215674, -3.2343822]], dtype=float32)

time = 52613	action = 0	current_phase = 1	next_phase = 0	reward = 0.064971	array([[-2.5211458, -3.8440464]], dtype=float32)

time = 52618	action = 1	current_phase = 1	next_phase = 0	reward = -1.890296	array([[-6.0927134, -3.4251153]], dtype=float32)

time = 52626	action = 0	current_phase = 0	next_phase = 1	reward = -0.474395	array([[-1.8796296, -3.1120417]], dtype=float32)

time = 52631	action = 0	current_phase = 0	next_phase = 1	reward = -0.322174	array([[-1.7028717, -2.7359664]], dtype=float32)

time = 52636	action = 0	current_phase = 0	next_phase = 1	reward = -0.182684	array([[-2.192914 , -3.3072371]], dtype=float32)

time = 52641	action = 0	current_phase = 0	next_phase = 1	reward = 0.253176	array([[-2.1367204, -3.81786  ]], dtype=float32)

time = 52646	action = 1	current_phase = 0	next_phase = 1	reward = -1.663950	array([[-4.5331306, -3.1573653]], dtype=float32)

time = 52654	action = 0	current_phase = 1	next_phase = 0	reward = -0.560906	array([[-2.1080058, -3.1090665]], dtype=float32)

time = 52659	action = 0	current_phase = 1	next_phase = 0	reward = -0.407081	array([[-1.9956002, -3.1212108]], dtype=float32)

time = 52664	action = 0	current_phase = 1	next_phase = 0	reward = -0.245624	array([[-1.9886751, -3.1136627]], dtype=float32)

time = 52669	action = 0	current_phase = 1	next_phase = 0	reward = -0.171108	array([[-2.0270288, -3.7619762]], dtype=float32)

time = 52674	action = 1	current_phase = 1	next_phase = 0	reward = -0.573276	array([[-2.3248312, -2.1865883]], dtype=float32)

time = 52682	action = 0	current_phase = 0	next_phase = 1	reward = -0.613498	array([[-2.1730149, -3.518812 ]], dtype=float32)

time = 52687	action = 0	current_phase = 0	next_phase = 1	reward = -0.456256	array([[-2.1104543, -2.7009318]], dtype=float32)

time = 52692	action = 0	current_phase = 0	next_phase = 1	reward = -0.301078	array([[-2.1771781, -2.9913235]], dtype=float32)

time = 52697	action = 0	current_phase = 0	next_phase = 1	reward = -0.170250	array([[-2.2280264, -3.263893 ]], dtype=float32)

time = 52702	action = 0	current_phase = 0	next_phase = 1	reward = 0.182040	array([[-2.5085182, -4.375949 ]], dtype=float32)

time = 52707	action = 1	current_phase = 0	next_phase = 1	reward = -1.785094	array([[-6.67171  , -3.3969233]], dtype=float32)

time = 52715	action = 0	current_phase = 1	next_phase = 0	reward = -0.528870	array([[-2.0623548, -3.178105 ]], dtype=float32)

time = 52720	action = 0	current_phase = 1	next_phase = 0	reward = -0.371794	array([[-1.9956287, -3.1216025]], dtype=float32)

time = 52725	action = 0	current_phase = 1	next_phase = 0	reward = -0.220729	array([[-1.9176208, -3.0566416]], dtype=float32)

time = 52730	action = 0	current_phase = 1	next_phase = 0	reward = 0.372541	array([[-2.0347223, -3.8035078]], dtype=float32)

time = 52735	action = 1	current_phase = 1	next_phase = 0	reward = -1.304603	array([[-3.2713757, -3.0897615]], dtype=float32)

time = 52743	action = 0	current_phase = 0	next_phase = 1	reward = -0.585704	array([[-2.169729 , -3.4555972]], dtype=float32)

time = 52748	action = 0	current_phase = 0	next_phase = 1	reward = -0.428970	array([[-2.0447018, -2.6830063]], dtype=float32)

time = 52753	action = 0	current_phase = 0	next_phase = 1	reward = -0.275013	array([[-1.985782 , -3.0402877]], dtype=float32)

time = 52758	action = 0	current_phase = 0	next_phase = 1	reward = -0.163512	array([[-2.2283514, -3.2635407]], dtype=float32)

time = 52763	action = 0	current_phase = 0	next_phase = 1	reward = 0.060067	array([[-2.6523554, -4.230643 ]], dtype=float32)

time = 52768	action = 1	current_phase = 0	next_phase = 1	reward = -1.900771	array([[-6.6443915, -3.429437 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0211 - val_loss: 0.0178

Epoch 2/50

 - 4s - loss: 0.0219 - val_loss: 0.0199

Epoch 3/50

 - 4s - loss: 0.0187 - val_loss: 0.0186

Epoch 4/50

 - 4s - loss: 0.0196 - val_loss: 0.0198

Epoch 5/50

 - 4s - loss: 0.0179 - val_loss: 0.0191

Epoch 6/50

 - 4s - loss: 0.0184 - val_loss: 0.0192

Epoch 7/50

 - 4s - loss: 0.0185 - val_loss: 0.0206

Epoch 8/50

 - 4s - loss: 0.0202 - val_loss: 0.0207

Epoch 9/50

 - 4s - loss: 0.0159 - val_loss: 0.0200

Epoch 10/50

 - 4s - loss: 0.0182 - val_loss: 0.0203

Epoch 11/50

 - 4s - loss: 0.0176 - val_loss: 0.0206

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 52776	action = 0	current_phase = 1	next_phase = 0	reward = -0.508078	array([[-2.0701504, -3.1826053]], dtype=float32)

time = 52781	action = 0	current_phase = 1	next_phase = 0	reward = -0.351791	array([[-1.9941585, -3.1209557]], dtype=float32)

time = 52786	action = 0	current_phase = 1	next_phase = 0	reward = -0.200852	array([[-2.0591695, -3.16904  ]], dtype=float32)

time = 52791	action = 0	current_phase = 1	next_phase = 0	reward = 0.332673	array([[-2.1977322, -4.0420613]], dtype=float32)

time = 52796	action = 1	current_phase = 1	next_phase = 0	reward = -1.607335	array([[-3.334046 , -3.0819683]], dtype=float32)

time = 52804	action = 0	current_phase = 0	next_phase = 1	reward = -0.554924	array([[-1.9891496, -2.870844 ]], dtype=float32)

time = 52809	action = 0	current_phase = 0	next_phase = 1	reward = -0.391220	array([[-1.9276597, -2.6928985]], dtype=float32)

time = 52814	action = 0	current_phase = 0	next_phase = 1	reward = -0.239388	array([[-1.9608212, -3.087983 ]], dtype=float32)

time = 52819	action = 0	current_phase = 0	next_phase = 1	reward = -0.186356	array([[-2.047637 , -2.8666232]], dtype=float32)

time = 52824	action = 1	current_phase = 0	next_phase = 1	reward = -0.508244	array([[-5.3067594, -2.3400352]], dtype=float32)

time = 52832	action = 0	current_phase = 1	next_phase = 0	reward = -0.618212	array([[-2.1957724, -3.062106 ]], dtype=float32)

time = 52837	action = 0	current_phase = 1	next_phase = 0	reward = -0.463925	array([[-1.9980826, -3.1168828]], dtype=float32)

time = 52842	action = 0	current_phase = 1	next_phase = 0	reward = -0.312677	array([[-1.9867076, -3.1097894]], dtype=float32)

time = 52847	action = 0	current_phase = 1	next_phase = 0	reward = -0.174916	array([[-2.2504516, -3.218607 ]], dtype=float32)

time = 52852	action = 0	current_phase = 1	next_phase = 0	reward = 0.239126	array([[-2.5748813, -4.0284557]], dtype=float32)

time = 52857	action = 1	current_phase = 1	next_phase = 0	reward = -1.781625	array([[-6.096864 , -3.3693175]], dtype=float32)

time = 52865	action = 0	current_phase = 0	next_phase = 1	reward = -0.523716	array([[-1.8719814, -3.1182656]], dtype=float32)

time = 52870	action = 0	current_phase = 0	next_phase = 1	reward = -0.374886	array([[-1.9177185, -2.696088 ]], dtype=float32)

time = 52875	action = 0	current_phase = 0	next_phase = 1	reward = -0.217913	array([[-1.9612297, -3.0890598]], dtype=float32)

time = 52880	action = 0	current_phase = 0	next_phase = 1	reward = 0.059600	array([[-2.0900075, -3.7144752]], dtype=float32)

time = 52885	action = 1	current_phase = 0	next_phase = 1	reward = -1.033128	array([[-4.719344 , -2.9490352]], dtype=float32)

time = 52893	action = 0	current_phase = 1	next_phase = 0	reward = -0.593661	array([[-2.198719 , -3.0600593]], dtype=float32)

time = 52898	action = 0	current_phase = 1	next_phase = 0	reward = -0.436364	array([[-1.9864283, -3.1095634]], dtype=float32)

time = 52903	action = 0	current_phase = 1	next_phase = 0	reward = -0.281387	array([[-1.9856647, -3.10847  ]], dtype=float32)

time = 52908	action = 0	current_phase = 1	next_phase = 0	reward = -0.163315	array([[-2.2444837, -3.2207508]], dtype=float32)

time = 52913	action = 0	current_phase = 1	next_phase = 0	reward = 0.087540	array([[-2.6168559, -4.02516  ]], dtype=float32)

time = 52918	action = 1	current_phase = 1	next_phase = 0	reward = -1.889559	array([[-6.13265  , -3.4260707]], dtype=float32)

time = 52926	action = 0	current_phase = 0	next_phase = 1	reward = -0.484861	array([[-1.8381855, -3.117084 ]], dtype=float32)

time = 52931	action = 0	current_phase = 0	next_phase = 1	reward = -0.330622	array([[-1.6501813, -2.7928686]], dtype=float32)

time = 52936	action = 0	current_phase = 0	next_phase = 1	reward = -0.183593	array([[-2.1662872, -3.1529636]], dtype=float32)

time = 52941	action = 0	current_phase = 0	next_phase = 1	reward = 0.277664	array([[-2.1268818, -4.0269823]], dtype=float32)

time = 52946	action = 1	current_phase = 0	next_phase = 1	reward = -1.662163	array([[-4.5224977, -3.2457387]], dtype=float32)

time = 52954	action = 0	current_phase = 1	next_phase = 0	reward = -0.551929	array([[-2.1236937, -3.128278 ]], dtype=float32)

time = 52959	action = 0	current_phase = 1	next_phase = 0	reward = -0.405079	array([[-1.986327 , -3.1094885]], dtype=float32)

time = 52964	action = 0	current_phase = 1	next_phase = 0	reward = -0.242758	array([[-1.9851468, -3.1085162]], dtype=float32)

time = 52969	action = 0	current_phase = 1	next_phase = 0	reward = -0.187377	array([[-2.0392747, -3.7873845]], dtype=float32)

time = 52974	action = 1	current_phase = 1	next_phase = 0	reward = -0.561754	array([[-2.449044 , -2.2222323]], dtype=float32)

time = 52982	action = 0	current_phase = 0	next_phase = 1	reward = -0.621030	array([[-2.1558652, -3.5731938]], dtype=float32)

time = 52987	action = 0	current_phase = 0	next_phase = 1	reward = -0.465899	array([[-1.971705 , -2.6933386]], dtype=float32)

time = 52992	action = 0	current_phase = 0	next_phase = 1	reward = -0.301728	array([[-1.9636312, -3.0899665]], dtype=float32)

time = 52997	action = 0	current_phase = 0	next_phase = 1	reward = -0.167796	array([[-2.182114, -3.269593]], dtype=float32)

time = 53002	action = 0	current_phase = 0	next_phase = 1	reward = 0.168678	array([[-2.4790838, -4.3936195]], dtype=float32)

time = 53007	action = 1	current_phase = 0	next_phase = 1	reward = -1.784330	array([[-6.674965 , -3.3580575]], dtype=float32)

time = 53015	action = 0	current_phase = 1	next_phase = 0	reward = -0.531098	array([[-2.0870078, -3.1609962]], dtype=float32)

time = 53020	action = 0	current_phase = 1	next_phase = 0	reward = -0.374337	array([[-1.9862747, -3.1094484]], dtype=float32)

time = 53025	action = 0	current_phase = 1	next_phase = 0	reward = -0.219646	array([[-1.9857658, -3.109017 ]], dtype=float32)

time = 53030	action = 0	current_phase = 1	next_phase = 0	reward = 0.057624	array([[-2.0789149, -3.8303473]], dtype=float32)

time = 53035	action = 1	current_phase = 1	next_phase = 0	reward = -1.030080	array([[-2.8031285, -2.699854 ]], dtype=float32)

time = 53043	action = 0	current_phase = 0	next_phase = 1	reward = -0.580767	array([[-2.1448836, -3.563801 ]], dtype=float32)

time = 53048	action = 0	current_phase = 0	next_phase = 1	reward = -0.422329	array([[-1.9280918, -2.6929324]], dtype=float32)

time = 53053	action = 0	current_phase = 0	next_phase = 1	reward = -0.273972	array([[-1.9616958, -3.0880096]], dtype=float32)

time = 53058	action = 0	current_phase = 0	next_phase = 1	reward = -0.167350	array([[-2.1811404, -3.2663584]], dtype=float32)

time = 53063	action = 0	current_phase = 0	next_phase = 1	reward = -0.007848	array([[-2.64495  , -4.2820506]], dtype=float32)

time = 53068	action = 1	current_phase = 0	next_phase = 1	reward = -1.899242	array([[-6.640963 , -3.4067693]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0219 - val_loss: 0.0122

Epoch 2/50

 - 4s - loss: 0.0241 - val_loss: 0.0118

Epoch 3/50

 - 4s - loss: 0.0194 - val_loss: 0.0113

Epoch 4/50

 - 4s - loss: 0.0185 - val_loss: 0.0112

Epoch 5/50

 - 4s - loss: 0.0188 - val_loss: 0.0110

Epoch 6/50

 - 4s - loss: 0.0176 - val_loss: 0.0110

Epoch 7/50

 - 4s - loss: 0.0165 - val_loss: 0.0112

Epoch 8/50

 - 4s - loss: 0.0154 - val_loss: 0.0113

Epoch 9/50

 - 4s - loss: 0.0160 - val_loss: 0.0122

Epoch 10/50

 - 4s - loss: 0.0161 - val_loss: 0.0118

Epoch 11/50

 - 4s - loss: 0.0142 - val_loss: 0.0112

Epoch 12/50

 - 4s - loss: 0.0131 - val_loss: 0.0111

Epoch 13/50

 - 4s - loss: 0.0153 - val_loss: 0.0107

Epoch 14/50

 - 4s - loss: 0.0152 - val_loss: 0.0112

Epoch 15/50

 - 4s - loss: 0.0154 - val_loss: 0.0132

Epoch 16/50

 - 4s - loss: 0.0148 - val_loss: 0.0122

Epoch 17/50

 - 4s - loss: 0.0130 - val_loss: 0.0130

Epoch 18/50

 - 4s - loss: 0.0148 - val_loss: 0.0120

Epoch 19/50

 - 4s - loss: 0.0168 - val_loss: 0.0120

Epoch 20/50

 - 4s - loss: 0.0120 - val_loss: 0.0132

Epoch 21/50

 - 4s - loss: 0.0154 - val_loss: 0.0133

Epoch 22/50

 - 4s - loss: 0.0121 - val_loss: 0.0126

Epoch 23/50

 - 4s - loss: 0.0135 - val_loss: 0.0123

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 53076	action = 0	current_phase = 1	next_phase = 0	reward = -0.491834	array([[-2.0824466, -3.1837957]], dtype=float32)

time = 53081	action = 0	current_phase = 1	next_phase = 0	reward = -0.334964	array([[-2.0377162, -3.1092038]], dtype=float32)

time = 53086	action = 0	current_phase = 1	next_phase = 0	reward = -0.191302	array([[-2.0719159, -3.1595688]], dtype=float32)

time = 53091	action = 0	current_phase = 1	next_phase = 0	reward = 0.329529	array([[-2.1688192, -4.0242023]], dtype=float32)

time = 53096	action = 1	current_phase = 1	next_phase = 0	reward = -1.500977	array([[-3.5114825, -3.047646 ]], dtype=float32)

time = 53104	action = 0	current_phase = 0	next_phase = 1	reward = -0.567817	array([[-2.027883 , -2.8796332]], dtype=float32)

time = 53109	action = 0	current_phase = 0	next_phase = 1	reward = -0.420120	array([[-1.9806267, -2.715782 ]], dtype=float32)

time = 53114	action = 0	current_phase = 0	next_phase = 1	reward = -0.268098	array([[-1.8811126, -3.1401775]], dtype=float32)

time = 53119	action = 0	current_phase = 0	next_phase = 1	reward = -0.175801	array([[-2.040832 , -2.9184256]], dtype=float32)

time = 53124	action = 1	current_phase = 0	next_phase = 1	reward = -1.362791	array([[-5.2284174, -2.3737273]], dtype=float32)

time = 53132	action = 1	current_phase = 1	next_phase = 0	reward = -1.903691	array([[-3.836934, -3.396237]], dtype=float32)

time = 53140	action = 0	current_phase = 0	next_phase = 1	reward = -0.368084	array([[-1.748891 , -2.9602137]], dtype=float32)

time = 53145	action = 0	current_phase = 0	next_phase = 1	reward = -0.215012	array([[-2.0080824, -3.0704758]], dtype=float32)

time = 53150	action = 0	current_phase = 0	next_phase = 1	reward = 0.358710	array([[-2.0781088, -3.6681488]], dtype=float32)

time = 53155	action = 0	current_phase = 0	next_phase = 1	reward = -0.843663	array([[-2.7353892, -2.9440522]], dtype=float32)

time = 53160	action = 1	current_phase = 0	next_phase = 1	reward = -2.099287	array([[-4.821185 , -3.5509622]], dtype=float32)

time = 53168	action = 0	current_phase = 1	next_phase = 0	reward = -0.416777	array([[-2.120053, -3.158955]], dtype=float32)

time = 53173	action = 0	current_phase = 1	next_phase = 0	reward = -0.251132	array([[-1.929273, -3.077487]], dtype=float32)

time = 53178	action = 0	current_phase = 1	next_phase = 0	reward = -0.160703	array([[-2.1839604, -3.4313846]], dtype=float32)

time = 53183	action = 1	current_phase = 1	next_phase = 0	reward = -0.251568	array([[-2.45963 , -2.286513]], dtype=float32)

time = 53191	action = 0	current_phase = 0	next_phase = 1	reward = -0.653380	array([[-2.0837781, -3.48613  ]], dtype=float32)

time = 53196	action = 0	current_phase = 0	next_phase = 1	reward = -0.497970	array([[-2.0358393, -2.8825862]], dtype=float32)

time = 53201	action = 0	current_phase = 0	next_phase = 1	reward = -0.340180	array([[-1.8026236, -2.8067062]], dtype=float32)

time = 53206	action = 0	current_phase = 0	next_phase = 1	reward = -0.194028	array([[-2.1181297, -3.194656 ]], dtype=float32)

time = 53211	action = 0	current_phase = 0	next_phase = 1	reward = 0.302025	array([[-2.1215515, -3.745387 ]], dtype=float32)

time = 53216	action = 1	current_phase = 0	next_phase = 1	reward = -1.609512	array([[-6.0244026, -3.3338244]], dtype=float32)

time = 53224	action = 0	current_phase = 1	next_phase = 0	reward = -0.548159	array([[-2.2211406, -3.0663464]], dtype=float32)

time = 53229	action = 0	current_phase = 1	next_phase = 0	reward = -0.381620	array([[-2.0358148, -3.1068826]], dtype=float32)

time = 53234	action = 0	current_phase = 1	next_phase = 0	reward = -0.225891	array([[-2.008964 , -3.1026785]], dtype=float32)

time = 53239	action = 0	current_phase = 1	next_phase = 0	reward = 0.098334	array([[-2.016112 , -3.7807045]], dtype=float32)

time = 53244	action = 0	current_phase = 1	next_phase = 0	reward = -0.483686	array([[-2.9127994, -2.936967 ]], dtype=float32)

time = 53249	action = 1	current_phase = 1	next_phase = 0	reward = -2.005312	array([[-6.159158 , -3.3346462]], dtype=float32)

time = 53257	action = 0	current_phase = 0	next_phase = 1	reward = -0.447034	array([[-1.9009414, -3.111374 ]], dtype=float32)

time = 53262	action = 0	current_phase = 0	next_phase = 1	reward = -0.290796	array([[-1.9997523, -3.0495877]], dtype=float32)

time = 53267	action = 0	current_phase = 0	next_phase = 1	reward = -0.167947	array([[-2.0821786, -2.9083264]], dtype=float32)

time = 53272	action = 0	current_phase = 0	next_phase = 1	reward = 0.170264	array([[-2.3795104, -4.245654 ]], dtype=float32)

time = 53277	action = 1	current_phase = 0	next_phase = 1	reward = -1.784958	array([[-5.025022 , -3.5356817]], dtype=float32)

time = 53285	action = 0	current_phase = 1	next_phase = 0	reward = -0.524003	array([[-2.2384822, -3.1030762]], dtype=float32)

time = 53290	action = 0	current_phase = 1	next_phase = 0	reward = -0.366644	array([[-2.036052 , -3.1071672]], dtype=float32)

time = 53295	action = 0	current_phase = 1	next_phase = 0	reward = -0.216183	array([[-1.9253995, -3.0766995]], dtype=float32)

time = 53300	action = 0	current_phase = 1	next_phase = 0	reward = 0.363596	array([[-2.0420475, -3.8078525]], dtype=float32)

time = 53305	action = 1	current_phase = 1	next_phase = 0	reward = -1.309733	array([[-3.3858683, -3.0051255]], dtype=float32)

time = 53313	action = 0	current_phase = 0	next_phase = 1	reward = -0.582525	array([[-2.2040854, -3.447868 ]], dtype=float32)

time = 53318	action = 0	current_phase = 0	next_phase = 1	reward = -0.437565	array([[-1.9808835, -2.7158444]], dtype=float32)

time = 53323	action = 0	current_phase = 0	next_phase = 1	reward = -0.271823	array([[-1.8813373, -3.1456873]], dtype=float32)

time = 53328	action = 0	current_phase = 0	next_phase = 1	reward = -0.165296	array([[-2.1391892, -3.2762794]], dtype=float32)

time = 53333	action = 0	current_phase = 0	next_phase = 1	reward = -0.008852	array([[-2.5998173, -4.449442 ]], dtype=float32)

time = 53338	action = 1	current_phase = 0	next_phase = 1	reward = -1.899312	array([[-6.613604, -3.532861]], dtype=float32)

time = 53346	action = 0	current_phase = 1	next_phase = 0	reward = -0.500875	array([[-2.080391 , -3.1857572]], dtype=float32)

time = 53351	action = 0	current_phase = 1	next_phase = 0	reward = -0.352649	array([[-2.0362554, -3.107417 ]], dtype=float32)

time = 53356	action = 0	current_phase = 1	next_phase = 0	reward = -0.200433	array([[-2.0773628, -3.170948 ]], dtype=float32)

time = 53361	action = 0	current_phase = 1	next_phase = 0	reward = 0.299002	array([[-2.1589165, -4.0000944]], dtype=float32)

time = 53366	action = 1	current_phase = 1	next_phase = 0	reward = -1.556325	array([[-5.7125106, -3.1302245]], dtype=float32)

time = 53374	action = 0	current_phase = 0	next_phase = 1	reward = -0.559635	array([[-2.0253944, -2.8764899]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0200 - val_loss: 0.0120

Epoch 2/50

 - 4s - loss: 0.0163 - val_loss: 0.0109

Epoch 3/50

 - 4s - loss: 0.0194 - val_loss: 0.0114

Epoch 4/50

 - 4s - loss: 0.0162 - val_loss: 0.0114

Epoch 5/50

 - 4s - loss: 0.0150 - val_loss: 0.0126

Epoch 6/50

 - 4s - loss: 0.0213 - val_loss: 0.0116

Epoch 7/50

 - 4s - loss: 0.0171 - val_loss: 0.0129

Epoch 8/50

 - 4s - loss: 0.0180 - val_loss: 0.0116

Epoch 9/50

 - 4s - loss: 0.0166 - val_loss: 0.0119

Epoch 10/50

 - 4s - loss: 0.0129 - val_loss: 0.0119

Epoch 11/50

 - 4s - loss: 0.0124 - val_loss: 0.0126

Epoch 12/50

 - 4s - loss: 0.0170 - val_loss: 0.0119

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 53379	action = 0	current_phase = 0	next_phase = 1	reward = -0.412253	array([[-1.9642004, -2.735617 ]], dtype=float32)

time = 53384	action = 0	current_phase = 0	next_phase = 1	reward = -0.251425	array([[-1.8741083, -3.217427 ]], dtype=float32)

time = 53389	action = 0	current_phase = 0	next_phase = 1	reward = -0.172814	array([[-2.1019402, -2.9477751]], dtype=float32)

time = 53394	action = 1	current_phase = 0	next_phase = 1	reward = -0.537451	array([[-5.28717  , -2.2272239]], dtype=float32)

time = 53402	action = 0	current_phase = 1	next_phase = 0	reward = -0.613378	array([[-2.2106519, -3.074548 ]], dtype=float32)

time = 53407	action = 0	current_phase = 1	next_phase = 0	reward = -0.454942	array([[-2.0310571, -3.1338365]], dtype=float32)

time = 53412	action = 0	current_phase = 1	next_phase = 0	reward = -0.307591	array([[-2.0260112, -3.130458 ]], dtype=float32)

time = 53417	action = 0	current_phase = 1	next_phase = 0	reward = -0.171033	array([[-2.2430913, -3.2604432]], dtype=float32)

time = 53422	action = 0	current_phase = 1	next_phase = 0	reward = 0.140040	array([[-2.538329 , -3.9911258]], dtype=float32)

time = 53427	action = 1	current_phase = 1	next_phase = 0	reward = -1.787799	array([[-6.1655493, -3.3660803]], dtype=float32)

time = 53435	action = 0	current_phase = 0	next_phase = 1	reward = -0.528248	array([[-1.9024326, -3.0896814]], dtype=float32)

time = 53440	action = 0	current_phase = 0	next_phase = 1	reward = -0.364760	array([[-1.9644793, -2.7356002]], dtype=float32)

time = 53445	action = 0	current_phase = 0	next_phase = 1	reward = -0.217365	array([[-1.8742754, -3.217845 ]], dtype=float32)

time = 53450	action = 0	current_phase = 0	next_phase = 1	reward = 0.044712	array([[-2.1695964, -3.8316953]], dtype=float32)

time = 53455	action = 1	current_phase = 0	next_phase = 1	reward = -1.146000	array([[-4.6829553, -2.913089 ]], dtype=float32)

time = 53463	action = 0	current_phase = 1	next_phase = 0	reward = -0.596791	array([[-2.2116444, -3.0738416]], dtype=float32)

time = 53468	action = 0	current_phase = 1	next_phase = 0	reward = -0.437180	array([[-2.0253272, -3.1296146]], dtype=float32)

time = 53473	action = 0	current_phase = 1	next_phase = 0	reward = -0.292643	array([[-2.02616  , -3.1285024]], dtype=float32)

time = 53478	action = 0	current_phase = 1	next_phase = 0	reward = -0.168465	array([[-2.2412703, -3.251079 ]], dtype=float32)

time = 53483	action = 0	current_phase = 1	next_phase = 0	reward = 0.102370	array([[-2.5194025, -3.746141 ]], dtype=float32)

time = 53488	action = 1	current_phase = 1	next_phase = 0	reward = -1.890619	array([[-6.1623077, -3.3634236]], dtype=float32)

time = 53496	action = 0	current_phase = 0	next_phase = 1	reward = -0.474712	array([[-1.8362399, -3.1052253]], dtype=float32)

time = 53501	action = 0	current_phase = 0	next_phase = 1	reward = -0.303092	array([[-1.959461 , -2.7385716]], dtype=float32)

time = 53506	action = 0	current_phase = 0	next_phase = 1	reward = -0.169538	array([[-2.1058013, -3.1380186]], dtype=float32)

time = 53511	action = 0	current_phase = 0	next_phase = 1	reward = 0.242556	array([[-2.226969 , -4.1339765]], dtype=float32)

time = 53516	action = 1	current_phase = 0	next_phase = 1	reward = -1.613327	array([[-4.528855, -3.264586]], dtype=float32)

time = 53524	action = 0	current_phase = 1	next_phase = 0	reward = -0.551913	array([[-2.147413 , -3.1112027]], dtype=float32)

time = 53529	action = 0	current_phase = 1	next_phase = 0	reward = -0.387009	array([[-2.0253205, -3.1295962]], dtype=float32)

time = 53534	action = 0	current_phase = 1	next_phase = 0	reward = -0.224652	array([[-1.8970047, -3.1019816]], dtype=float32)

time = 53539	action = 0	current_phase = 1	next_phase = 0	reward = -0.186363	array([[-2.0090084, -3.7942448]], dtype=float32)

time = 53544	action = 1	current_phase = 1	next_phase = 0	reward = -0.546378	array([[-2.4068825, -2.2275794]], dtype=float32)

time = 53552	action = 0	current_phase = 0	next_phase = 1	reward = -0.618414	array([[-2.1634488, -3.6118178]], dtype=float32)

time = 53557	action = 0	current_phase = 0	next_phase = 1	reward = -0.471189	array([[-2.0345218, -2.7073174]], dtype=float32)

time = 53562	action = 0	current_phase = 0	next_phase = 1	reward = -0.317852	array([[-1.9877717, -3.1382718]], dtype=float32)

time = 53567	action = 0	current_phase = 0	next_phase = 1	reward = -0.179663	array([[-2.1269295, -3.2924316]], dtype=float32)

time = 53572	action = 0	current_phase = 0	next_phase = 1	reward = 0.234528	array([[-2.5744271, -4.5001564]], dtype=float32)

time = 53577	action = 1	current_phase = 0	next_phase = 1	reward = -1.718361	array([[-6.3297906, -3.4879446]], dtype=float32)

time = 53585	action = 0	current_phase = 1	next_phase = 0	reward = -0.520841	array([[-2.1431246, -3.166723 ]], dtype=float32)

time = 53590	action = 0	current_phase = 1	next_phase = 0	reward = -0.360617	array([[-2.0253668, -3.1296442]], dtype=float32)

time = 53595	action = 0	current_phase = 1	next_phase = 0	reward = -0.204601	array([[-1.8983952, -3.1029427]], dtype=float32)

time = 53600	action = 0	current_phase = 1	next_phase = 0	reward = 0.337085	array([[-2.0665152, -3.8652418]], dtype=float32)

time = 53605	action = 1	current_phase = 1	next_phase = 0	reward = -1.372297	array([[-3.2935965, -3.0804043]], dtype=float32)

time = 53613	action = 0	current_phase = 0	next_phase = 1	reward = -0.598546	array([[-2.1579428, -3.5853107]], dtype=float32)

time = 53618	action = 0	current_phase = 0	next_phase = 1	reward = -0.445977	array([[-1.9642471, -2.7356923]], dtype=float32)

time = 53623	action = 0	current_phase = 0	next_phase = 1	reward = -0.296680	array([[-1.8723601, -3.2093387]], dtype=float32)

time = 53628	action = 0	current_phase = 0	next_phase = 1	reward = -0.167473	array([[-2.128925 , -3.2992356]], dtype=float32)

time = 53633	action = 0	current_phase = 0	next_phase = 1	reward = 0.014785	array([[-2.5815513, -4.529356 ]], dtype=float32)

time = 53638	action = 1	current_phase = 0	next_phase = 1	reward = -1.902533	array([[-6.592413 , -3.5475633]], dtype=float32)

time = 53646	action = 0	current_phase = 1	next_phase = 0	reward = -0.507269	array([[-2.0732996, -3.2055953]], dtype=float32)

time = 53651	action = 0	current_phase = 1	next_phase = 0	reward = -0.356488	array([[-2.0255136, -3.1297824]], dtype=float32)

time = 53656	action = 0	current_phase = 1	next_phase = 0	reward = -0.204000	array([[-2.0542321, -3.1739233]], dtype=float32)

time = 53661	action = 0	current_phase = 1	next_phase = 0	reward = 0.327686	array([[-2.112208, -3.963193]], dtype=float32)

time = 53666	action = 1	current_phase = 1	next_phase = 0	reward = -1.450823	array([[-5.7236824, -3.0939105]], dtype=float32)

time = 53674	action = 0	current_phase = 0	next_phase = 1	reward = -0.558219	array([[-1.9955704, -2.9027088]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0202 - val_loss: 0.0102

Epoch 2/50

 - 4s - loss: 0.0209 - val_loss: 0.0091

Epoch 3/50

 - 4s - loss: 0.0158 - val_loss: 0.0097

Epoch 4/50

 - 4s - loss: 0.0154 - val_loss: 0.0104

Epoch 5/50

 - 4s - loss: 0.0163 - val_loss: 0.0103

Epoch 6/50

 - 4s - loss: 0.0152 - val_loss: 0.0101

Epoch 7/50

 - 4s - loss: 0.0192 - val_loss: 0.0096

Epoch 8/50

 - 4s - loss: 0.0156 - val_loss: 0.0106

Epoch 9/50

 - 4s - loss: 0.0132 - val_loss: 0.0106

Epoch 10/50

 - 4s - loss: 0.0179 - val_loss: 0.0109

Epoch 11/50

 - 4s - loss: 0.0136 - val_loss: 0.0101

Epoch 12/50

 - 4s - loss: 0.0151 - val_loss: 0.0107

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 53679	action = 0	current_phase = 0	next_phase = 1	reward = -0.403886	array([[-1.9821098, -2.7598042]], dtype=float32)

time = 53684	action = 0	current_phase = 0	next_phase = 1	reward = -0.248044	array([[-1.897851 , -3.2362087]], dtype=float32)

time = 53689	action = 0	current_phase = 0	next_phase = 1	reward = -0.175965	array([[-2.0666745, -2.9877956]], dtype=float32)

time = 53694	action = 1	current_phase = 0	next_phase = 1	reward = -0.481828	array([[-5.3246827, -2.3192039]], dtype=float32)

time = 53702	action = 0	current_phase = 1	next_phase = 0	reward = -0.614613	array([[-2.209462 , -3.0686212]], dtype=float32)

time = 53707	action = 0	current_phase = 1	next_phase = 0	reward = -0.459772	array([[-2.0348961, -3.1308024]], dtype=float32)

time = 53712	action = 0	current_phase = 1	next_phase = 0	reward = -0.311948	array([[-2.0347993, -3.1307614]], dtype=float32)

time = 53717	action = 0	current_phase = 1	next_phase = 0	reward = -0.178971	array([[-2.242148 , -3.2427778]], dtype=float32)

time = 53722	action = 0	current_phase = 1	next_phase = 0	reward = 0.199912	array([[-2.5647259, -4.0376716]], dtype=float32)

time = 53727	action = 1	current_phase = 1	next_phase = 0	reward = -1.783556	array([[-6.172252 , -3.3254194]], dtype=float32)

time = 53735	action = 0	current_phase = 0	next_phase = 1	reward = -0.520580	array([[-2.0100963, -3.1692119]], dtype=float32)

time = 53740	action = 0	current_phase = 0	next_phase = 1	reward = -0.360911	array([[-1.981019 , -2.7601871]], dtype=float32)

time = 53745	action = 0	current_phase = 0	next_phase = 1	reward = -0.204342	array([[-1.9007144, -3.2545521]], dtype=float32)

time = 53750	action = 0	current_phase = 0	next_phase = 1	reward = 0.337301	array([[-2.1625109, -3.8733418]], dtype=float32)

time = 53755	action = 1	current_phase = 0	next_phase = 1	reward = -1.427951	array([[-4.490447 , -3.1156678]], dtype=float32)

time = 53763	action = 0	current_phase = 1	next_phase = 0	reward = -0.598384	array([[-2.20961 , -3.069567]], dtype=float32)

time = 53768	action = 0	current_phase = 1	next_phase = 0	reward = -0.447970	array([[-2.0348728, -3.130653 ]], dtype=float32)

time = 53773	action = 0	current_phase = 1	next_phase = 0	reward = -0.295205	array([[-2.026304 , -3.1298869]], dtype=float32)

time = 53778	action = 0	current_phase = 1	next_phase = 0	reward = -0.166296	array([[-2.2445047, -3.2400944]], dtype=float32)

time = 53783	action = 0	current_phase = 1	next_phase = 0	reward = 0.014688	array([[-2.7247674, -3.9145293]], dtype=float32)

time = 53788	action = 1	current_phase = 1	next_phase = 0	reward = -1.899689	array([[-6.188634 , -3.3382626]], dtype=float32)

time = 53796	action = 0	current_phase = 0	next_phase = 1	reward = -0.502170	array([[-1.8278232, -3.0730941]], dtype=float32)

time = 53801	action = 0	current_phase = 0	next_phase = 1	reward = -0.352281	array([[-1.9767058, -2.7617943]], dtype=float32)

time = 53806	action = 0	current_phase = 0	next_phase = 1	reward = -0.202955	array([[-1.9174447, -3.2860756]], dtype=float32)

time = 53811	action = 0	current_phase = 0	next_phase = 1	reward = 0.284066	array([[-2.192082 , -4.0684633]], dtype=float32)

time = 53816	action = 1	current_phase = 0	next_phase = 1	reward = -1.562417	array([[-4.402201, -3.360984]], dtype=float32)

time = 53824	action = 0	current_phase = 1	next_phase = 0	reward = -0.560204	array([[-2.1921484, -3.07552  ]], dtype=float32)

time = 53829	action = 0	current_phase = 1	next_phase = 0	reward = -0.403492	array([[-2.0343728, -3.130484 ]], dtype=float32)

time = 53834	action = 0	current_phase = 1	next_phase = 0	reward = -0.245799	array([[-1.9383528, -3.1179166]], dtype=float32)

time = 53839	action = 0	current_phase = 1	next_phase = 0	reward = -0.174785	array([[-2.0379398, -3.8058233]], dtype=float32)

time = 53844	action = 1	current_phase = 1	next_phase = 0	reward = -0.585841	array([[-2.4421828, -2.136504 ]], dtype=float32)

time = 53852	action = 0	current_phase = 0	next_phase = 1	reward = -0.618673	array([[-2.256184 , -3.6296427]], dtype=float32)

time = 53857	action = 0	current_phase = 0	next_phase = 1	reward = -0.465408	array([[-2.0076785, -2.757642 ]], dtype=float32)

time = 53862	action = 0	current_phase = 0	next_phase = 1	reward = -0.314938	array([[-2.0015075, -3.1741161]], dtype=float32)

time = 53867	action = 0	current_phase = 0	next_phase = 1	reward = -0.172576	array([[-2.146936, -3.292829]], dtype=float32)

time = 53872	action = 0	current_phase = 0	next_phase = 1	reward = 0.185843	array([[-2.5477862, -4.5046916]], dtype=float32)

time = 53877	action = 1	current_phase = 0	next_phase = 1	reward = -1.729695	array([[-6.498048 , -3.5639653]], dtype=float32)

time = 53885	action = 0	current_phase = 1	next_phase = 0	reward = -0.523013	array([[-2.1674597, -3.176012 ]], dtype=float32)

time = 53890	action = 0	current_phase = 1	next_phase = 0	reward = -0.365799	array([[-2.0344095, -3.1305335]], dtype=float32)

time = 53895	action = 0	current_phase = 1	next_phase = 0	reward = -0.215977	array([[-1.9004515, -3.112952 ]], dtype=float32)

time = 53900	action = 0	current_phase = 1	next_phase = 0	reward = 0.339830	array([[-2.0842485, -3.8850968]], dtype=float32)

time = 53905	action = 1	current_phase = 1	next_phase = 0	reward = -1.318043	array([[-3.3956225, -3.0194032]], dtype=float32)

time = 53913	action = 0	current_phase = 0	next_phase = 1	reward = -0.592876	array([[-2.191994 , -3.5993848]], dtype=float32)

time = 53918	action = 0	current_phase = 0	next_phase = 1	reward = -0.445942	array([[-2.1232407, -2.87512  ]], dtype=float32)

time = 53923	action = 0	current_phase = 0	next_phase = 1	reward = -0.293408	array([[-1.9904339, -3.1787786]], dtype=float32)

time = 53928	action = 0	current_phase = 0	next_phase = 1	reward = -0.167003	array([[-2.140788 , -3.2677295]], dtype=float32)

time = 53933	action = 0	current_phase = 0	next_phase = 1	reward = -0.005419	array([[-2.5503979, -4.51782  ]], dtype=float32)

time = 53938	action = 1	current_phase = 0	next_phase = 1	reward = -1.901823	array([[-6.562142 , -3.5482533]], dtype=float32)

time = 53946	action = 0	current_phase = 1	next_phase = 0	reward = -0.496034	array([[-2.0910144, -3.195166 ]], dtype=float32)

time = 53951	action = 0	current_phase = 1	next_phase = 0	reward = -0.337177	array([[-2.0349443, -3.1313694]], dtype=float32)

time = 53956	action = 0	current_phase = 1	next_phase = 0	reward = -0.187498	array([[-2.0527272, -3.1681917]], dtype=float32)

time = 53961	action = 0	current_phase = 1	next_phase = 0	reward = 0.317489	array([[-2.145928, -4.007351]], dtype=float32)

time = 53966	action = 1	current_phase = 1	next_phase = 0	reward = -1.502688	array([[-5.8053684, -3.1403525]], dtype=float32)

time = 53974	action = 0	current_phase = 0	next_phase = 1	reward = -0.551973	array([[-2.0266993, -2.9305396]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0147 - val_loss: 0.0092

Epoch 2/50

 - 4s - loss: 0.0154 - val_loss: 0.0085

Epoch 3/50

 - 4s - loss: 0.0161 - val_loss: 0.0095

Epoch 4/50

 - 4s - loss: 0.0148 - val_loss: 0.0094

Epoch 5/50

 - 4s - loss: 0.0181 - val_loss: 0.0096

Epoch 6/50

 - 4s - loss: 0.0133 - val_loss: 0.0090

Epoch 7/50

 - 4s - loss: 0.0116 - val_loss: 0.0095

Epoch 8/50

 - 4s - loss: 0.0134 - val_loss: 0.0092

Epoch 9/50

 - 4s - loss: 0.0147 - val_loss: 0.0096

Epoch 10/50

 - 4s - loss: 0.0115 - val_loss: 0.0098

Epoch 11/50

 - 4s - loss: 0.0130 - val_loss: 0.0121

Epoch 12/50

 - 4s - loss: 0.0112 - val_loss: 0.0113

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 53979	action = 0	current_phase = 0	next_phase = 1	reward = -0.404331	array([[-2.035542 , -2.8170757]], dtype=float32)

time = 53984	action = 0	current_phase = 0	next_phase = 1	reward = -0.257910	array([[-1.9036449, -3.337727 ]], dtype=float32)

time = 53989	action = 0	current_phase = 0	next_phase = 1	reward = -0.178425	array([[-2.1003919, -3.0599139]], dtype=float32)

time = 53994	action = 1	current_phase = 0	next_phase = 1	reward = -0.603359	array([[-5.3609447, -2.3488092]], dtype=float32)

time = 54002	action = 0	current_phase = 1	next_phase = 0	reward = -0.621836	array([[-2.161467 , -3.0569355]], dtype=float32)

time = 54007	action = 0	current_phase = 1	next_phase = 0	reward = -0.470208	array([[-1.9878144, -3.1109893]], dtype=float32)

time = 54012	action = 0	current_phase = 1	next_phase = 0	reward = -0.320332	array([[-1.9841743, -3.1072917]], dtype=float32)

time = 54017	action = 0	current_phase = 1	next_phase = 0	reward = -0.183667	array([[-2.1872866, -3.2266114]], dtype=float32)

time = 54022	action = 0	current_phase = 1	next_phase = 0	reward = 0.197792	array([[-2.4667442, -4.023465 ]], dtype=float32)

time = 54027	action = 1	current_phase = 1	next_phase = 0	reward = -1.786660	array([[-6.1569037, -3.3288884]], dtype=float32)

time = 54035	action = 0	current_phase = 0	next_phase = 1	reward = -0.534290	array([[-2.016641 , -3.1581223]], dtype=float32)

time = 54040	action = 0	current_phase = 0	next_phase = 1	reward = -0.381134	array([[-2.0356638, -2.818007 ]], dtype=float32)

time = 54045	action = 0	current_phase = 0	next_phase = 1	reward = -0.230917	array([[-1.9036634, -3.3377495]], dtype=float32)

time = 54050	action = 0	current_phase = 0	next_phase = 1	reward = 0.063921	array([[-2.1902087, -3.8355474]], dtype=float32)

time = 54055	action = 1	current_phase = 0	next_phase = 1	reward = -1.026455	array([[-5.024097, -2.67781 ]], dtype=float32)

time = 54063	action = 0	current_phase = 1	next_phase = 0	reward = -0.595973	array([[-2.1581984, -3.054457 ]], dtype=float32)

time = 54068	action = 0	current_phase = 1	next_phase = 0	reward = -0.445346	array([[-1.9842448, -3.107451 ]], dtype=float32)

time = 54073	action = 0	current_phase = 1	next_phase = 0	reward = -0.299774	array([[-1.9863898, -3.1046855]], dtype=float32)

time = 54078	action = 0	current_phase = 1	next_phase = 0	reward = -0.166518	array([[-2.1838923, -3.2280834]], dtype=float32)

time = 54083	action = 0	current_phase = 1	next_phase = 0	reward = 0.152895	array([[-2.5216918, -4.041401 ]], dtype=float32)

time = 54088	action = 1	current_phase = 1	next_phase = 0	reward = -1.890907	array([[-6.1545696, -3.33513  ]], dtype=float32)

time = 54096	action = 0	current_phase = 0	next_phase = 1	reward = -0.488892	array([[-1.8747766, -3.147024 ]], dtype=float32)

time = 54101	action = 0	current_phase = 0	next_phase = 1	reward = -0.342078	array([[-2.0320508, -2.818722 ]], dtype=float32)

time = 54106	action = 0	current_phase = 0	next_phase = 1	reward = -0.201767	array([[-1.9740291, -3.346706 ]], dtype=float32)

time = 54111	action = 0	current_phase = 0	next_phase = 1	reward = 0.307090	array([[-2.2349863, -4.1766987]], dtype=float32)

time = 54116	action = 1	current_phase = 0	next_phase = 1	reward = -1.614666	array([[-4.4166327, -3.3250978]], dtype=float32)

time = 54124	action = 0	current_phase = 1	next_phase = 0	reward = -0.571171	array([[-2.1369133, -3.0683062]], dtype=float32)

time = 54129	action = 0	current_phase = 1	next_phase = 0	reward = -0.418336	array([[-1.9840639, -3.1070447]], dtype=float32)

time = 54134	action = 0	current_phase = 1	next_phase = 0	reward = -0.261081	array([[-1.8602306, -3.0895739]], dtype=float32)

time = 54139	action = 0	current_phase = 1	next_phase = 0	reward = -0.165991	array([[-1.9720439, -3.78175  ]], dtype=float32)

time = 54144	action = 1	current_phase = 1	next_phase = 0	reward = -0.381362	array([[-2.3444111, -2.271613 ]], dtype=float32)

time = 54152	action = 0	current_phase = 0	next_phase = 1	reward = -0.616247	array([[-2.1947849, -3.66273  ]], dtype=float32)

time = 54157	action = 0	current_phase = 0	next_phase = 1	reward = -0.457116	array([[-2.04598 , -2.980364]], dtype=float32)

time = 54162	action = 0	current_phase = 0	next_phase = 1	reward = -0.298671	array([[-2.0167413, -3.2442067]], dtype=float32)

time = 54167	action = 0	current_phase = 0	next_phase = 1	reward = -0.163919	array([[-2.1452925, -3.3575258]], dtype=float32)

time = 54172	action = 0	current_phase = 0	next_phase = 1	reward = 0.176354	array([[-2.5848916, -4.518429 ]], dtype=float32)

time = 54177	action = 1	current_phase = 0	next_phase = 1	reward = -1.786325	array([[-6.5366244, -3.5437508]], dtype=float32)

time = 54185	action = 0	current_phase = 1	next_phase = 0	reward = -0.530457	array([[-2.06474  , -3.1670492]], dtype=float32)

time = 54190	action = 0	current_phase = 1	next_phase = 0	reward = -0.381411	array([[-1.984103, -3.107177]], dtype=float32)

time = 54195	action = 0	current_phase = 1	next_phase = 0	reward = -0.232568	array([[-1.8586537, -3.089185 ]], dtype=float32)

time = 54200	action = 0	current_phase = 1	next_phase = 0	reward = 0.380314	array([[-1.9976547, -3.8186085]], dtype=float32)

time = 54205	action = 1	current_phase = 1	next_phase = 0	reward = -1.245105	array([[-3.3035383, -2.9021394]], dtype=float32)

time = 54213	action = 0	current_phase = 0	next_phase = 1	reward = -0.593515	array([[-2.1874852, -3.6446207]], dtype=float32)

time = 54218	action = 0	current_phase = 0	next_phase = 1	reward = -0.442626	array([[-2.0357416, -2.8171487]], dtype=float32)

time = 54223	action = 0	current_phase = 0	next_phase = 1	reward = -0.286993	array([[-2.0124671, -3.2465665]], dtype=float32)

time = 54228	action = 0	current_phase = 0	next_phase = 1	reward = -0.166165	array([[-2.1519058, -3.357561 ]], dtype=float32)

time = 54233	action = 0	current_phase = 0	next_phase = 1	reward = 0.053912	array([[-2.5864918, -4.53091  ]], dtype=float32)

time = 54238	action = 1	current_phase = 0	next_phase = 1	reward = -1.896910	array([[-6.5457854, -3.5604315]], dtype=float32)

time = 54246	action = 0	current_phase = 1	next_phase = 0	reward = -0.494158	array([[-2.0782385, -3.1511621]], dtype=float32)

time = 54251	action = 0	current_phase = 1	next_phase = 0	reward = -0.346195	array([[-1.9843471, -3.1075883]], dtype=float32)

time = 54256	action = 0	current_phase = 1	next_phase = 0	reward = -0.198356	array([[-1.9757587, -3.1175253]], dtype=float32)

time = 54261	action = 0	current_phase = 1	next_phase = 0	reward = 0.300886	array([[-2.0950406, -4.014804 ]], dtype=float32)

time = 54266	action = 1	current_phase = 1	next_phase = 0	reward = -1.556443	array([[-5.691326 , -3.1754415]], dtype=float32)

time = 54274	action = 0	current_phase = 0	next_phase = 1	reward = -0.554380	array([[-2.0348432, -2.9784546]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0132 - val_loss: 0.0062

Epoch 2/50

 - 4s - loss: 0.0134 - val_loss: 0.0059

Epoch 3/50

 - 4s - loss: 0.0129 - val_loss: 0.0067

Epoch 4/50

 - 4s - loss: 0.0181 - val_loss: 0.0063

Epoch 5/50

 - 4s - loss: 0.0149 - val_loss: 0.0061

Epoch 6/50

 - 4s - loss: 0.0142 - val_loss: 0.0064

Epoch 7/50

 - 4s - loss: 0.0158 - val_loss: 0.0066

Epoch 8/50

 - 4s - loss: 0.0117 - val_loss: 0.0064

Epoch 9/50

 - 4s - loss: 0.0124 - val_loss: 0.0068

Epoch 10/50

 - 4s - loss: 0.0159 - val_loss: 0.0064

Epoch 11/50

 - 4s - loss: 0.0146 - val_loss: 0.0062

Epoch 12/50

 - 4s - loss: 0.0130 - val_loss: 0.0064

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 54279	action = 0	current_phase = 0	next_phase = 1	reward = -0.419049	array([[-1.9769995, -2.8306613]], dtype=float32)

time = 54284	action = 0	current_phase = 0	next_phase = 1	reward = -0.276989	array([[-1.8853072, -3.329462 ]], dtype=float32)

time = 54289	action = 0	current_phase = 0	next_phase = 1	reward = -0.174356	array([[-2.0972888, -3.0492792]], dtype=float32)

time = 54294	action = 1	current_phase = 0	next_phase = 1	reward = -0.510114	array([[-5.1854944, -2.2860565]], dtype=float32)

time = 54302	action = 0	current_phase = 1	next_phase = 0	reward = -0.609311	array([[-2.2089572, -3.0963926]], dtype=float32)

time = 54307	action = 0	current_phase = 1	next_phase = 0	reward = -0.454161	array([[-2.0371976, -3.1398692]], dtype=float32)

time = 54312	action = 0	current_phase = 1	next_phase = 0	reward = -0.305547	array([[-2.0258286, -3.141191 ]], dtype=float32)

time = 54317	action = 0	current_phase = 1	next_phase = 0	reward = -0.171495	array([[-2.2371445, -3.2643015]], dtype=float32)

time = 54322	action = 0	current_phase = 1	next_phase = 0	reward = 0.126725	array([[-2.503546 , -4.0837197]], dtype=float32)

time = 54327	action = 1	current_phase = 1	next_phase = 0	reward = -1.785796	array([[-6.151261, -3.366561]], dtype=float32)

time = 54335	action = 0	current_phase = 0	next_phase = 1	reward = -0.528487	array([[-1.9967065, -3.2153873]], dtype=float32)

time = 54340	action = 0	current_phase = 0	next_phase = 1	reward = -0.373976	array([[-1.9764713, -2.8308916]], dtype=float32)

time = 54345	action = 0	current_phase = 0	next_phase = 1	reward = -0.215772	array([[-1.8874756, -3.335438 ]], dtype=float32)

time = 54350	action = 0	current_phase = 0	next_phase = 1	reward = 0.356071	array([[-2.2032843, -3.8956878]], dtype=float32)

time = 54355	action = 1	current_phase = 0	next_phase = 1	reward = -1.215689	array([[-4.5304728, -3.0940948]], dtype=float32)

time = 54363	action = 0	current_phase = 1	next_phase = 0	reward = -0.583263	array([[-2.2060409, -3.097907 ]], dtype=float32)

time = 54368	action = 0	current_phase = 1	next_phase = 0	reward = -0.429762	array([[-2.025389 , -3.1410856]], dtype=float32)

time = 54373	action = 0	current_phase = 1	next_phase = 0	reward = -0.272860	array([[-2.027607 , -3.1393719]], dtype=float32)

time = 54378	action = 0	current_phase = 1	next_phase = 0	reward = -0.165278	array([[-2.2314227, -3.2680337]], dtype=float32)

time = 54383	action = 0	current_phase = 1	next_phase = 0	reward = 0.089145	array([[-2.61528  , -3.7610056]], dtype=float32)

time = 54388	action = 1	current_phase = 1	next_phase = 0	reward = -1.894524	array([[-6.172108 , -3.3564909]], dtype=float32)

time = 54396	action = 0	current_phase = 0	next_phase = 1	reward = -0.498372	array([[-1.8614302, -3.175359 ]], dtype=float32)

time = 54401	action = 0	current_phase = 0	next_phase = 1	reward = -0.341343	array([[-1.9784014, -2.833611 ]], dtype=float32)

time = 54406	action = 0	current_phase = 0	next_phase = 1	reward = -0.199051	array([[-1.8906314, -3.339795 ]], dtype=float32)

time = 54411	action = 0	current_phase = 0	next_phase = 1	reward = 0.302335	array([[-2.2320926, -4.148722 ]], dtype=float32)

time = 54416	action = 1	current_phase = 0	next_phase = 1	reward = -1.556719	array([[-4.4182053, -3.1919854]], dtype=float32)

time = 54424	action = 0	current_phase = 1	next_phase = 0	reward = -0.551652	array([[-2.2062745, -3.096541 ]], dtype=float32)

time = 54429	action = 0	current_phase = 1	next_phase = 0	reward = -0.403303	array([[-2.0254426, -3.1410956]], dtype=float32)

time = 54434	action = 0	current_phase = 1	next_phase = 0	reward = -0.239211	array([[-2.019295 , -3.1412947]], dtype=float32)

time = 54439	action = 0	current_phase = 1	next_phase = 0	reward = -0.189173	array([[-2.0802174, -3.8621402]], dtype=float32)

time = 54444	action = 1	current_phase = 1	next_phase = 0	reward = -0.589570	array([[-2.42672  , -2.3275776]], dtype=float32)

time = 54452	action = 0	current_phase = 0	next_phase = 1	reward = -0.615627	array([[-2.5832372, -3.6157758]], dtype=float32)

time = 54457	action = 0	current_phase = 0	next_phase = 1	reward = -0.458424	array([[-2.036666 , -2.8523493]], dtype=float32)

time = 54462	action = 0	current_phase = 0	next_phase = 1	reward = -0.295125	array([[-1.9905243, -3.239591 ]], dtype=float32)

time = 54467	action = 0	current_phase = 0	next_phase = 1	reward = -0.167054	array([[-2.1473265, -3.3201258]], dtype=float32)

time = 54472	action = 0	current_phase = 0	next_phase = 1	reward = 0.163236	array([[-2.5167878, -4.3888674]], dtype=float32)

time = 54477	action = 1	current_phase = 0	next_phase = 1	reward = -1.784689	array([[-6.4862013, -3.6031222]], dtype=float32)

time = 54485	action = 0	current_phase = 1	next_phase = 0	reward = -0.528791	array([[-2.1263776, -3.2058702]], dtype=float32)

time = 54490	action = 0	current_phase = 1	next_phase = 0	reward = -0.368386	array([[-2.0253859, -3.141093 ]], dtype=float32)

time = 54495	action = 0	current_phase = 1	next_phase = 0	reward = -0.214461	array([[-1.8937341, -3.1265748]], dtype=float32)

time = 54500	action = 0	current_phase = 1	next_phase = 0	reward = 0.370653	array([[-2.0980198, -3.8676157]], dtype=float32)

time = 54505	action = 1	current_phase = 1	next_phase = 0	reward = -1.251522	array([[-3.2868865, -3.062117 ]], dtype=float32)

time = 54513	action = 0	current_phase = 0	next_phase = 1	reward = -0.575630	array([[-2.1464353, -3.683231 ]], dtype=float32)

time = 54518	action = 0	current_phase = 0	next_phase = 1	reward = -0.427838	array([[-1.9770775, -2.8307602]], dtype=float32)

time = 54523	action = 0	current_phase = 0	next_phase = 1	reward = -0.275680	array([[-1.9898219, -3.2416608]], dtype=float32)

time = 54528	action = 0	current_phase = 0	next_phase = 1	reward = -0.166574	array([[-2.1556244, -3.3206923]], dtype=float32)

time = 54533	action = 0	current_phase = 0	next_phase = 1	reward = -0.041996	array([[-2.631844 , -4.5140567]], dtype=float32)

time = 54538	action = 1	current_phase = 0	next_phase = 1	reward = -1.900632	array([[-6.5562973, -3.5583782]], dtype=float32)

time = 54546	action = 0	current_phase = 1	next_phase = 0	reward = -0.481075	array([[-2.116068 , -3.1939704]], dtype=float32)

time = 54551	action = 0	current_phase = 1	next_phase = 0	reward = -0.320963	array([[-2.0254223, -3.1411173]], dtype=float32)

time = 54556	action = 0	current_phase = 1	next_phase = 0	reward = -0.182775	array([[-2.0155363, -3.1600373]], dtype=float32)

time = 54561	action = 0	current_phase = 1	next_phase = 0	reward = 0.269584	array([[-2.2141933, -4.0828323]], dtype=float32)

time = 54566	action = 1	current_phase = 1	next_phase = 0	reward = -1.662001	array([[-5.7006536, -3.2027853]], dtype=float32)

time = 54574	action = 0	current_phase = 0	next_phase = 1	reward = -0.552134	array([[-2.016103 , -3.0058503]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0150 - val_loss: 0.0132

Epoch 2/50

 - 4s - loss: 0.0161 - val_loss: 0.0134

Epoch 3/50

 - 4s - loss: 0.0130 - val_loss: 0.0136

Epoch 4/50

 - 4s - loss: 0.0164 - val_loss: 0.0144

Epoch 5/50

 - 4s - loss: 0.0117 - val_loss: 0.0143

Epoch 6/50

 - 4s - loss: 0.0154 - val_loss: 0.0132

Epoch 7/50

 - 4s - loss: 0.0137 - val_loss: 0.0137

Epoch 8/50

 - 4s - loss: 0.0141 - val_loss: 0.0130

Epoch 9/50

 - 4s - loss: 0.0118 - val_loss: 0.0122

Epoch 10/50

 - 4s - loss: 0.0122 - val_loss: 0.0130

Epoch 11/50

 - 4s - loss: 0.0107 - val_loss: 0.0152

Epoch 12/50

 - 4s - loss: 0.0116 - val_loss: 0.0147

Epoch 13/50

 - 4s - loss: 0.0102 - val_loss: 0.0147

Epoch 14/50

 - 4s - loss: 0.0100 - val_loss: 0.0148

Epoch 15/50

 - 4s - loss: 0.0122 - val_loss: 0.0145

Epoch 16/50

 - 4s - loss: 0.0133 - val_loss: 0.0143

Epoch 17/50

 - 3s - loss: 0.0101 - val_loss: 0.0147

Epoch 18/50

 - 4s - loss: 0.0125 - val_loss: 0.0170

Epoch 19/50

 - 4s - loss: 0.0114 - val_loss: 0.0152

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 54579	action = 0	current_phase = 0	next_phase = 1	reward = -0.396924	array([[-1.9542022, -2.8372514]], dtype=float32)

time = 54584	action = 0	current_phase = 0	next_phase = 1	reward = -0.240252	array([[-1.953449 , -3.3217914]], dtype=float32)

time = 54589	action = 0	current_phase = 0	next_phase = 1	reward = -0.181399	array([[-2.072932 , -3.0252006]], dtype=float32)

time = 54594	action = 1	current_phase = 0	next_phase = 1	reward = -0.543573	array([[-5.406448 , -2.5033014]], dtype=float32)

time = 54602	action = 0	current_phase = 1	next_phase = 0	reward = -0.619716	array([[-2.1963005, -3.105439 ]], dtype=float32)

time = 54607	action = 0	current_phase = 1	next_phase = 0	reward = -0.468050	array([[-2.0311959, -3.1471763]], dtype=float32)

time = 54612	action = 0	current_phase = 1	next_phase = 0	reward = -0.309681	array([[-2.0221112, -3.1488245]], dtype=float32)

time = 54617	action = 0	current_phase = 1	next_phase = 0	reward = -0.172588	array([[-2.1869712, -3.260147 ]], dtype=float32)

time = 54622	action = 0	current_phase = 1	next_phase = 0	reward = 0.138898	array([[-2.4953117, -4.133869 ]], dtype=float32)

time = 54627	action = 1	current_phase = 1	next_phase = 0	reward = -1.782417	array([[-6.157967 , -3.4005988]], dtype=float32)

time = 54635	action = 0	current_phase = 0	next_phase = 1	reward = -0.522400	array([[-2.1119998, -3.2128146]], dtype=float32)

time = 54640	action = 0	current_phase = 0	next_phase = 1	reward = -0.363756	array([[-1.9585514, -2.8348103]], dtype=float32)

time = 54645	action = 0	current_phase = 0	next_phase = 1	reward = -0.206482	array([[-1.9559567, -3.3250618]], dtype=float32)

time = 54650	action = 0	current_phase = 0	next_phase = 1	reward = 0.343347	array([[-2.20808  , -3.9019713]], dtype=float32)

time = 54655	action = 1	current_phase = 0	next_phase = 1	reward = -1.316056	array([[-4.5065293, -3.1736646]], dtype=float32)

time = 54663	action = 0	current_phase = 1	next_phase = 0	reward = -0.584215	array([[-2.1984599, -3.1069512]], dtype=float32)

time = 54668	action = 0	current_phase = 1	next_phase = 0	reward = -0.431185	array([[-2.0223262, -3.1503525]], dtype=float32)

time = 54673	action = 0	current_phase = 1	next_phase = 0	reward = -0.280798	array([[-2.0292914, -3.1420784]], dtype=float32)

time = 54678	action = 0	current_phase = 1	next_phase = 0	reward = -0.161329	array([[-2.1761944, -3.2669525]], dtype=float32)

time = 54683	action = 0	current_phase = 1	next_phase = 0	reward = -0.044317	array([[-2.5890355, -4.13065  ]], dtype=float32)

time = 54688	action = 1	current_phase = 1	next_phase = 0	reward = -1.913129	array([[-6.159982 , -3.3992298]], dtype=float32)

time = 54696	action = 0	current_phase = 0	next_phase = 1	reward = -0.502584	array([[-2.0473452, -3.1966639]], dtype=float32)

time = 54701	action = 0	current_phase = 0	next_phase = 1	reward = -0.346519	array([[-1.9561818, -2.83669  ]], dtype=float32)

time = 54706	action = 0	current_phase = 0	next_phase = 1	reward = -0.196615	array([[-1.9870396, -3.3625913]], dtype=float32)

time = 54711	action = 0	current_phase = 0	next_phase = 1	reward = 0.286333	array([[-2.2272646, -3.9873135]], dtype=float32)

time = 54716	action = 1	current_phase = 0	next_phase = 1	reward = -1.664163	array([[-4.417812 , -3.3527489]], dtype=float32)

time = 54724	action = 0	current_phase = 1	next_phase = 0	reward = -0.564712	array([[-2.195924 , -3.1061869]], dtype=float32)

time = 54729	action = 0	current_phase = 1	next_phase = 0	reward = -0.411661	array([[-2.022023, -3.148742]], dtype=float32)

time = 54734	action = 0	current_phase = 1	next_phase = 0	reward = -0.246265	array([[-1.951129, -3.142656]], dtype=float32)

time = 54739	action = 0	current_phase = 1	next_phase = 0	reward = -0.176538	array([[-2.0139794, -3.835251 ]], dtype=float32)

time = 54744	action = 1	current_phase = 1	next_phase = 0	reward = -0.617567	array([[-2.3525677, -2.1673713]], dtype=float32)

time = 54752	action = 0	current_phase = 0	next_phase = 1	reward = -0.622806	array([[-2.1924002, -3.7009094]], dtype=float32)

time = 54757	action = 0	current_phase = 0	next_phase = 1	reward = -0.453572	array([[-2.1326602, -2.9340596]], dtype=float32)

time = 54762	action = 0	current_phase = 0	next_phase = 1	reward = -0.296813	array([[-2.0172815, -3.2213407]], dtype=float32)

time = 54767	action = 0	current_phase = 0	next_phase = 1	reward = -0.170725	array([[-2.1827226, -3.2889962]], dtype=float32)

time = 54772	action = 0	current_phase = 0	next_phase = 1	reward = 0.228066	array([[-2.6799617, -4.5218883]], dtype=float32)

time = 54777	action = 1	current_phase = 0	next_phase = 1	reward = -1.776709	array([[-6.419852 , -3.4209034]], dtype=float32)

time = 54785	action = 0	current_phase = 1	next_phase = 0	reward = -0.529707	array([[-2.1215165, -3.2073407]], dtype=float32)

time = 54790	action = 0	current_phase = 1	next_phase = 0	reward = -0.377226	array([[-2.0220263, -3.148766 ]], dtype=float32)

time = 54795	action = 0	current_phase = 1	next_phase = 0	reward = -0.220430	array([[-1.884615 , -3.1288662]], dtype=float32)

time = 54800	action = 0	current_phase = 1	next_phase = 0	reward = 0.364873	array([[-2.0658603, -3.976681 ]], dtype=float32)

time = 54805	action = 1	current_phase = 1	next_phase = 0	reward = -1.359222	array([[-3.249587 , -2.9378524]], dtype=float32)

time = 54813	action = 0	current_phase = 0	next_phase = 1	reward = -0.592277	array([[-2.189915 , -3.6989992]], dtype=float32)

time = 54818	action = 0	current_phase = 0	next_phase = 1	reward = -0.441744	array([[-1.9605012, -2.8353086]], dtype=float32)

time = 54823	action = 0	current_phase = 0	next_phase = 1	reward = -0.288223	array([[-2.0170462, -3.221347 ]], dtype=float32)

time = 54828	action = 0	current_phase = 0	next_phase = 1	reward = -0.167386	array([[-2.1835263, -3.288181 ]], dtype=float32)

time = 54833	action = 0	current_phase = 0	next_phase = 1	reward = 0.016249	array([[-2.8265276, -4.4720335]], dtype=float32)

time = 54838	action = 1	current_phase = 0	next_phase = 1	reward = -1.901327	array([[-6.596238, -3.557356]], dtype=float32)

time = 54846	action = 0	current_phase = 1	next_phase = 0	reward = -0.505325	array([[-2.1092055, -3.2068217]], dtype=float32)

time = 54851	action = 0	current_phase = 1	next_phase = 0	reward = -0.348380	array([[-2.0220969, -3.1488333]], dtype=float32)

time = 54856	action = 0	current_phase = 1	next_phase = 0	reward = -0.198514	array([[-1.9983586, -3.1883159]], dtype=float32)

time = 54861	action = 0	current_phase = 1	next_phase = 0	reward = 0.299880	array([[-2.129411, -4.095864]], dtype=float32)

time = 54866	action = 1	current_phase = 1	next_phase = 0	reward = -1.557353	array([[-5.6430697, -3.181207 ]], dtype=float32)

time = 54874	action = 0	current_phase = 0	next_phase = 1	reward = -0.558465	array([[-2.0945284, -3.0177722]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0127 - val_loss: 0.0103

Epoch 2/50

 - 4s - loss: 0.0129 - val_loss: 0.0118

Epoch 3/50

 - 4s - loss: 0.0133 - val_loss: 0.0121

Epoch 4/50

 - 4s - loss: 0.0130 - val_loss: 0.0104

Epoch 5/50

 - 4s - loss: 0.0123 - val_loss: 0.0107

Epoch 6/50

 - 4s - loss: 0.0116 - val_loss: 0.0118

Epoch 7/50

 - 4s - loss: 0.0112 - val_loss: 0.0118

Epoch 8/50

 - 4s - loss: 0.0104 - val_loss: 0.0123

Epoch 9/50

 - 4s - loss: 0.0116 - val_loss: 0.0129

Epoch 10/50

 - 4s - loss: 0.0155 - val_loss: 0.0126

Epoch 11/50

 - 4s - loss: 0.0111 - val_loss: 0.0133

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 54879	action = 0	current_phase = 0	next_phase = 1	reward = -0.409650	array([[-1.852631 , -2.8628879]], dtype=float32)

time = 54884	action = 0	current_phase = 0	next_phase = 1	reward = -0.252448	array([[-1.867455 , -3.3165712]], dtype=float32)

time = 54889	action = 0	current_phase = 0	next_phase = 1	reward = -0.177304	array([[-1.9966327, -3.05474  ]], dtype=float32)

time = 54894	action = 1	current_phase = 0	next_phase = 1	reward = -0.547041	array([[-5.357867 , -2.3385818]], dtype=float32)

time = 54902	action = 0	current_phase = 1	next_phase = 0	reward = -0.614900	array([[-2.205686, -3.085395]], dtype=float32)

time = 54907	action = 0	current_phase = 1	next_phase = 0	reward = -0.451224	array([[-2.0311682, -3.1342356]], dtype=float32)

time = 54912	action = 0	current_phase = 1	next_phase = 0	reward = -0.295243	array([[-2.02199  , -3.1364965]], dtype=float32)

time = 54917	action = 0	current_phase = 1	next_phase = 0	reward = -0.169814	array([[-2.188211 , -3.2575483]], dtype=float32)

time = 54922	action = 0	current_phase = 1	next_phase = 0	reward = 0.208245	array([[-2.505334 , -4.1297746]], dtype=float32)

time = 54927	action = 1	current_phase = 1	next_phase = 0	reward = -1.780107	array([[-6.1538324, -3.3431702]], dtype=float32)

time = 54935	action = 0	current_phase = 0	next_phase = 1	reward = -0.526126	array([[-2.0707166, -3.2340658]], dtype=float32)

time = 54940	action = 0	current_phase = 0	next_phase = 1	reward = -0.369933	array([[-1.8470278, -2.8662705]], dtype=float32)

time = 54945	action = 0	current_phase = 0	next_phase = 1	reward = -0.214925	array([[-1.8733195, -3.3249683]], dtype=float32)

time = 54950	action = 0	current_phase = 0	next_phase = 1	reward = 0.352147	array([[-2.1124163, -3.8686135]], dtype=float32)

time = 54955	action = 1	current_phase = 0	next_phase = 1	reward = -1.255944	array([[-4.4213943, -3.1988995]], dtype=float32)

time = 54963	action = 0	current_phase = 1	next_phase = 0	reward = -0.589846	array([[-2.2206464, -3.0839632]], dtype=float32)

time = 54968	action = 0	current_phase = 1	next_phase = 0	reward = -0.424099	array([[-2.021648 , -3.1361947]], dtype=float32)

time = 54973	action = 0	current_phase = 1	next_phase = 0	reward = -0.262032	array([[-2.0312476, -3.1312366]], dtype=float32)

time = 54978	action = 0	current_phase = 1	next_phase = 0	reward = -0.155139	array([[-2.1863568, -3.2566454]], dtype=float32)

time = 54983	action = 0	current_phase = 1	next_phase = 0	reward = 0.137028	array([[-2.5923915, -3.7485042]], dtype=float32)

time = 54988	action = 1	current_phase = 1	next_phase = 0	reward = -1.890807	array([[-6.1554184, -3.373538 ]], dtype=float32)

time = 54996	action = 0	current_phase = 0	next_phase = 1	reward = -0.487773	array([[-1.9792463, -3.2132924]], dtype=float32)

time = 55001	action = 0	current_phase = 0	next_phase = 1	reward = -0.341600	array([[-1.8535753, -2.8656523]], dtype=float32)

time = 55006	action = 0	current_phase = 0	next_phase = 1	reward = -0.203810	array([[-1.932098 , -3.2065203]], dtype=float32)

time = 55011	action = 0	current_phase = 0	next_phase = 1	reward = 0.281194	array([[-2.295531 , -4.2309933]], dtype=float32)

time = 55016	action = 1	current_phase = 0	next_phase = 1	reward = -1.613294	array([[-4.3981333, -3.427664 ]], dtype=float32)

time = 55024	action = 0	current_phase = 1	next_phase = 0	reward = -0.574019	array([[-2.2068222, -3.0884106]], dtype=float32)

time = 55029	action = 0	current_phase = 1	next_phase = 0	reward = -0.422435	array([[-2.0216777, -3.136179 ]], dtype=float32)

time = 55034	action = 0	current_phase = 1	next_phase = 0	reward = -0.258076	array([[-2.0144038, -3.1364336]], dtype=float32)

time = 55039	action = 0	current_phase = 1	next_phase = 0	reward = -0.168166	array([[-2.0227635, -3.763595 ]], dtype=float32)

time = 55044	action = 1	current_phase = 1	next_phase = 0	reward = -0.460198	array([[-2.3153234, -2.1707714]], dtype=float32)

time = 55052	action = 0	current_phase = 0	next_phase = 1	reward = -0.612876	array([[-2.1213844, -3.736072 ]], dtype=float32)

time = 55057	action = 0	current_phase = 0	next_phase = 1	reward = -0.456629	array([[-1.8655802, -2.874063 ]], dtype=float32)

time = 55062	action = 0	current_phase = 0	next_phase = 1	reward = -0.294698	array([[-1.9269053, -3.2182386]], dtype=float32)

time = 55067	action = 0	current_phase = 0	next_phase = 1	reward = -0.168815	array([[-2.1408498, -3.2841122]], dtype=float32)

time = 55072	action = 0	current_phase = 0	next_phase = 1	reward = 0.167528	array([[-2.2483046, -4.197487 ]], dtype=float32)

time = 55077	action = 1	current_phase = 0	next_phase = 1	reward = -1.789146	array([[-6.521281 , -3.5305214]], dtype=float32)

time = 55085	action = 0	current_phase = 1	next_phase = 0	reward = -0.531002	array([[-2.1430373, -3.2076795]], dtype=float32)

time = 55090	action = 0	current_phase = 1	next_phase = 0	reward = -0.372246	array([[-2.0216794, -3.1362314]], dtype=float32)

time = 55095	action = 0	current_phase = 1	next_phase = 0	reward = -0.224490	array([[-1.9054085, -3.115925 ]], dtype=float32)

time = 55100	action = 0	current_phase = 1	next_phase = 0	reward = 0.369014	array([[-2.0944343, -4.0168915]], dtype=float32)

time = 55105	action = 1	current_phase = 1	next_phase = 0	reward = -1.357400	array([[-3.2119641, -2.9847069]], dtype=float32)

time = 55113	action = 0	current_phase = 0	next_phase = 1	reward = -0.589907	array([[-2.1145275, -3.7333717]], dtype=float32)

time = 55118	action = 0	current_phase = 0	next_phase = 1	reward = -0.436370	array([[-1.8902848, -2.8992536]], dtype=float32)

time = 55123	action = 0	current_phase = 0	next_phase = 1	reward = -0.285237	array([[-1.9268508, -3.218833 ]], dtype=float32)

time = 55128	action = 0	current_phase = 0	next_phase = 1	reward = -0.167811	array([[-2.1466029, -3.293353 ]], dtype=float32)

time = 55133	action = 0	current_phase = 0	next_phase = 1	reward = 0.054032	array([[-2.6726456, -4.532835 ]], dtype=float32)

time = 55138	action = 1	current_phase = 0	next_phase = 1	reward = -1.894191	array([[-6.5222425, -3.5708585]], dtype=float32)

time = 55146	action = 0	current_phase = 1	next_phase = 0	reward = -0.499594	array([[-2.1433904, -3.2028196]], dtype=float32)

time = 55151	action = 0	current_phase = 1	next_phase = 0	reward = -0.352374	array([[-2.021841 , -3.1363912]], dtype=float32)

time = 55156	action = 0	current_phase = 1	next_phase = 0	reward = -0.204473	array([[-2.0236042, -3.1494267]], dtype=float32)

time = 55161	action = 0	current_phase = 1	next_phase = 0	reward = 0.342573	array([[-2.0886276, -4.024781 ]], dtype=float32)

time = 55166	action = 1	current_phase = 1	next_phase = 0	reward = -1.552605	array([[-5.653421, -3.185906]], dtype=float32)

time = 55174	action = 0	current_phase = 0	next_phase = 1	reward = -0.563972	array([[-2.0301876, -3.0544062]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0120 - val_loss: 0.0072

Epoch 2/50

 - 4s - loss: 0.0112 - val_loss: 0.0062

Epoch 3/50

 - 4s - loss: 0.0110 - val_loss: 0.0064

Epoch 4/50

 - 4s - loss: 0.0110 - val_loss: 0.0066

Epoch 5/50

 - 4s - loss: 0.0131 - val_loss: 0.0067

Epoch 6/50

 - 4s - loss: 0.0099 - val_loss: 0.0069

Epoch 7/50

 - 4s - loss: 0.0108 - val_loss: 0.0067

Epoch 8/50

 - 4s - loss: 0.0105 - val_loss: 0.0064

Epoch 9/50

 - 4s - loss: 0.0120 - val_loss: 0.0069

Epoch 10/50

 - 4s - loss: 0.0108 - val_loss: 0.0069

Epoch 11/50

 - 4s - loss: 0.0088 - val_loss: 0.0065

Epoch 12/50

 - 4s - loss: 0.0083 - val_loss: 0.0068

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 55179	action = 0	current_phase = 0	next_phase = 1	reward = -0.409971	array([[-1.9377279, -2.8724482]], dtype=float32)

time = 55184	action = 0	current_phase = 0	next_phase = 1	reward = -0.245615	array([[-1.9164628, -3.3015268]], dtype=float32)

time = 55189	action = 0	current_phase = 0	next_phase = 1	reward = -0.173459	array([[-2.020842 , -3.0431228]], dtype=float32)

time = 55194	action = 1	current_phase = 0	next_phase = 1	reward = -0.428374	array([[-5.389947, -2.366187]], dtype=float32)

time = 55202	action = 0	current_phase = 1	next_phase = 0	reward = -0.609062	array([[-2.185349 , -3.1047907]], dtype=float32)

time = 55207	action = 0	current_phase = 1	next_phase = 0	reward = -0.442249	array([[-2.0551105, -3.1361673]], dtype=float32)

time = 55212	action = 0	current_phase = 1	next_phase = 0	reward = -0.280588	array([[-2.03978  , -3.1283166]], dtype=float32)

time = 55217	action = 0	current_phase = 1	next_phase = 0	reward = -0.162566	array([[-2.1659963, -3.2663126]], dtype=float32)

time = 55222	action = 0	current_phase = 1	next_phase = 0	reward = 0.165876	array([[-2.5298045, -4.143771 ]], dtype=float32)

time = 55227	action = 1	current_phase = 1	next_phase = 0	reward = -1.779901	array([[-6.1551423, -3.3905373]], dtype=float32)

time = 55235	action = 0	current_phase = 0	next_phase = 1	reward = -0.529658	array([[-2.1112792, -3.2475784]], dtype=float32)

time = 55240	action = 0	current_phase = 0	next_phase = 1	reward = -0.374393	array([[-1.9338197, -2.8757882]], dtype=float32)

time = 55245	action = 0	current_phase = 0	next_phase = 1	reward = -0.221177	array([[-1.9165691, -3.3016346]], dtype=float32)

time = 55250	action = 0	current_phase = 0	next_phase = 1	reward = 0.351009	array([[-2.1159034, -3.8597832]], dtype=float32)

time = 55255	action = 1	current_phase = 0	next_phase = 1	reward = -1.417569	array([[-4.508365 , -3.1264691]], dtype=float32)

time = 55263	action = 0	current_phase = 1	next_phase = 0	reward = -0.587195	array([[-2.1930673, -3.1038582]], dtype=float32)

time = 55268	action = 0	current_phase = 1	next_phase = 0	reward = -0.429029	array([[-1.9973181, -3.146732 ]], dtype=float32)

time = 55273	action = 0	current_phase = 1	next_phase = 0	reward = -0.269897	array([[-2.068864 , -3.1066031]], dtype=float32)

time = 55278	action = 0	current_phase = 1	next_phase = 0	reward = -0.161264	array([[-2.16275 , -3.266622]], dtype=float32)

time = 55283	action = 0	current_phase = 1	next_phase = 0	reward = 0.061919	array([[-2.5601456, -4.1009164]], dtype=float32)

time = 55288	action = 1	current_phase = 1	next_phase = 0	reward = -1.898033	array([[-6.1678834, -3.387595 ]], dtype=float32)

time = 55296	action = 0	current_phase = 0	next_phase = 1	reward = -0.494901	array([[-2.0355067, -3.2290874]], dtype=float32)

time = 55301	action = 0	current_phase = 0	next_phase = 1	reward = -0.342253	array([[-1.9365319, -2.886709 ]], dtype=float32)

time = 55306	action = 0	current_phase = 0	next_phase = 1	reward = -0.191248	array([[-2.042983 , -2.9868002]], dtype=float32)

time = 55311	action = 0	current_phase = 0	next_phase = 1	reward = 0.314952	array([[-2.2674847, -4.161413 ]], dtype=float32)

time = 55316	action = 1	current_phase = 0	next_phase = 1	reward = -1.501137	array([[-4.3983507, -3.3548424]], dtype=float32)

time = 55324	action = 0	current_phase = 1	next_phase = 0	reward = -0.554322	array([[-2.1961648, -3.1035755]], dtype=float32)

time = 55329	action = 0	current_phase = 1	next_phase = 0	reward = -0.404860	array([[-1.9972898, -3.1467407]], dtype=float32)

time = 55334	action = 0	current_phase = 1	next_phase = 0	reward = -0.256245	array([[-1.8680873, -3.1280487]], dtype=float32)

time = 55339	action = 0	current_phase = 1	next_phase = 0	reward = -0.192634	array([[-2.0138535, -3.7852123]], dtype=float32)

time = 55344	action = 1	current_phase = 1	next_phase = 0	reward = -0.579510	array([[-2.3263638, -2.262209 ]], dtype=float32)

time = 55352	action = 0	current_phase = 0	next_phase = 1	reward = -0.614019	array([[-2.1982052, -3.7479455]], dtype=float32)

time = 55357	action = 0	current_phase = 0	next_phase = 1	reward = -0.464976	array([[-1.9475851, -2.8782938]], dtype=float32)

time = 55362	action = 0	current_phase = 0	next_phase = 1	reward = -0.323348	array([[-1.9577081, -3.19866  ]], dtype=float32)

time = 55367	action = 0	current_phase = 0	next_phase = 1	reward = -0.185930	array([[-2.1772094, -3.231307 ]], dtype=float32)

time = 55372	action = 0	current_phase = 0	next_phase = 1	reward = 0.160472	array([[-2.3578472, -4.2230062]], dtype=float32)

time = 55377	action = 1	current_phase = 0	next_phase = 1	reward = -1.776223	array([[-6.52725 , -3.538189]], dtype=float32)

time = 55385	action = 0	current_phase = 1	next_phase = 0	reward = -0.509319	array([[-2.1064737, -3.2198186]], dtype=float32)

time = 55390	action = 0	current_phase = 1	next_phase = 0	reward = -0.355030	array([[-1.9974343, -3.1466918]], dtype=float32)

time = 55395	action = 0	current_phase = 1	next_phase = 0	reward = -0.200498	array([[-1.8597318, -3.128618 ]], dtype=float32)

time = 55400	action = 0	current_phase = 1	next_phase = 0	reward = 0.352428	array([[-2.0937796, -4.004838 ]], dtype=float32)

time = 55405	action = 1	current_phase = 1	next_phase = 0	reward = -1.317075	array([[-3.2135317, -3.0133743]], dtype=float32)

time = 55413	action = 0	current_phase = 0	next_phase = 1	reward = -0.583842	array([[-2.187737 , -3.7321513]], dtype=float32)

time = 55418	action = 0	current_phase = 0	next_phase = 1	reward = -0.432443	array([[-1.8685069, -2.9612255]], dtype=float32)

time = 55423	action = 0	current_phase = 0	next_phase = 1	reward = -0.277895	array([[-1.9567437, -3.1992574]], dtype=float32)

time = 55428	action = 0	current_phase = 0	next_phase = 1	reward = -0.165611	array([[-2.196426 , -3.2603192]], dtype=float32)

time = 55433	action = 0	current_phase = 0	next_phase = 1	reward = 0.059347	array([[-2.8558698, -4.186092 ]], dtype=float32)

time = 55438	action = 1	current_phase = 0	next_phase = 1	reward = -1.905124	array([[-6.5168343, -3.5575354]], dtype=float32)

time = 55446	action = 0	current_phase = 1	next_phase = 0	reward = -0.503882	array([[-2.1049447, -3.2109604]], dtype=float32)

time = 55451	action = 0	current_phase = 1	next_phase = 0	reward = -0.340463	array([[-1.9974006, -3.14676  ]], dtype=float32)

time = 55456	action = 0	current_phase = 1	next_phase = 0	reward = -0.191287	array([[-1.8702668, -3.1337054]], dtype=float32)

time = 55461	action = 0	current_phase = 1	next_phase = 0	reward = 0.313341	array([[-2.0984778, -4.0285115]], dtype=float32)

time = 55466	action = 1	current_phase = 1	next_phase = 0	reward = -1.611261	array([[-5.6452947, -3.1915274]], dtype=float32)

time = 55474	action = 0	current_phase = 0	next_phase = 1	reward = -0.559895	array([[-2.1030102, -3.066331 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0129 - val_loss: 0.0065

Epoch 2/50

 - 4s - loss: 0.0138 - val_loss: 0.0062

Epoch 3/50

 - 4s - loss: 0.0125 - val_loss: 0.0061

Epoch 4/50

 - 4s - loss: 0.0140 - val_loss: 0.0059

Epoch 5/50

 - 4s - loss: 0.0108 - val_loss: 0.0064

Epoch 6/50

 - 4s - loss: 0.0118 - val_loss: 0.0065

Epoch 7/50

 - 4s - loss: 0.0096 - val_loss: 0.0067

Epoch 8/50

 - 4s - loss: 0.0148 - val_loss: 0.0065

Epoch 9/50

 - 4s - loss: 0.0108 - val_loss: 0.0071

Epoch 10/50

 - 4s - loss: 0.0113 - val_loss: 0.0070

Epoch 11/50

 - 4s - loss: 0.0128 - val_loss: 0.0067

Epoch 12/50

 - 4s - loss: 0.0105 - val_loss: 0.0068

Epoch 13/50

 - 4s - loss: 0.0096 - val_loss: 0.0070

Epoch 14/50

 - 4s - loss: 0.0130 - val_loss: 0.0076

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 55479	action = 0	current_phase = 0	next_phase = 1	reward = -0.409060	array([[-1.9415733, -2.8517575]], dtype=float32)

time = 55484	action = 0	current_phase = 0	next_phase = 1	reward = -0.261658	array([[-1.9525625, -3.2686446]], dtype=float32)

time = 55489	action = 0	current_phase = 0	next_phase = 1	reward = -0.179196	array([[-2.0493217, -2.9951818]], dtype=float32)

time = 55494	action = 1	current_phase = 0	next_phase = 1	reward = -0.519638	array([[-5.3964953, -2.2863705]], dtype=float32)

time = 55502	action = 0	current_phase = 1	next_phase = 0	reward = -0.605137	array([[-2.238763, -3.114398]], dtype=float32)

time = 55507	action = 0	current_phase = 1	next_phase = 0	reward = -0.452209	array([[-2.0896244, -3.1361415]], dtype=float32)

time = 55512	action = 0	current_phase = 1	next_phase = 0	reward = -0.300837	array([[-2.1167989, -3.1135347]], dtype=float32)

time = 55517	action = 0	current_phase = 1	next_phase = 0	reward = -0.168014	array([[-2.1865206, -3.276314 ]], dtype=float32)

time = 55522	action = 0	current_phase = 1	next_phase = 0	reward = 0.231393	array([[-2.3894634, -4.0215774]], dtype=float32)

time = 55527	action = 1	current_phase = 1	next_phase = 0	reward = -1.779586	array([[-6.176782, -3.362831]], dtype=float32)

time = 55535	action = 0	current_phase = 0	next_phase = 1	reward = -0.528054	array([[-2.0785728, -3.2205713]], dtype=float32)

time = 55540	action = 0	current_phase = 0	next_phase = 1	reward = -0.370342	array([[-1.9303441, -2.8591256]], dtype=float32)

time = 55545	action = 0	current_phase = 0	next_phase = 1	reward = -0.210811	array([[-1.9525442, -3.2686322]], dtype=float32)

time = 55550	action = 0	current_phase = 0	next_phase = 1	reward = 0.052314	array([[-2.1827192, -3.8205564]], dtype=float32)

time = 55555	action = 1	current_phase = 0	next_phase = 1	reward = -1.088230	array([[-5.006823 , -2.7570229]], dtype=float32)

time = 55563	action = 0	current_phase = 1	next_phase = 0	reward = -0.590689	array([[-2.24075 , -3.113835]], dtype=float32)

time = 55568	action = 0	current_phase = 1	next_phase = 0	reward = -0.440667	array([[-2.0309546, -3.1591063]], dtype=float32)

time = 55573	action = 0	current_phase = 1	next_phase = 0	reward = -0.278861	array([[-2.1178699, -3.11021  ]], dtype=float32)

time = 55578	action = 0	current_phase = 1	next_phase = 0	reward = -0.162416	array([[-2.1857245, -3.2825663]], dtype=float32)

time = 55583	action = 0	current_phase = 1	next_phase = 0	reward = 0.068158	array([[-2.4915257, -4.168318 ]], dtype=float32)

time = 55588	action = 1	current_phase = 1	next_phase = 0	reward = -1.894276	array([[-6.1784306, -3.3876386]], dtype=float32)

time = 55596	action = 0	current_phase = 0	next_phase = 1	reward = -0.494013	array([[-2.0656922, -3.2151942]], dtype=float32)

time = 55601	action = 0	current_phase = 0	next_phase = 1	reward = -0.326407	array([[-1.9285206, -2.8602467]], dtype=float32)

time = 55606	action = 0	current_phase = 0	next_phase = 1	reward = -0.183893	array([[-1.9575164, -3.2711835]], dtype=float32)

time = 55611	action = 0	current_phase = 0	next_phase = 1	reward = 0.282564	array([[-2.369175 , -4.1065392]], dtype=float32)

time = 55616	action = 1	current_phase = 0	next_phase = 1	reward = -1.555654	array([[-4.406733 , -3.3209133]], dtype=float32)

time = 55624	action = 0	current_phase = 1	next_phase = 0	reward = -0.551698	array([[-2.2401423, -3.116538 ]], dtype=float32)

time = 55629	action = 0	current_phase = 1	next_phase = 0	reward = -0.397951	array([[-2.030854 , -3.1585875]], dtype=float32)

time = 55634	action = 0	current_phase = 1	next_phase = 0	reward = -0.246186	array([[-1.9280611, -3.1405616]], dtype=float32)

time = 55639	action = 0	current_phase = 1	next_phase = 0	reward = -0.177382	array([[-1.9714082, -3.8209825]], dtype=float32)

time = 55644	action = 1	current_phase = 1	next_phase = 0	reward = -0.479162	array([[-2.3404317, -2.218285 ]], dtype=float32)

time = 55652	action = 0	current_phase = 0	next_phase = 1	reward = -0.619833	array([[-2.171683 , -3.7278357]], dtype=float32)

time = 55657	action = 0	current_phase = 0	next_phase = 1	reward = -0.463619	array([[-1.9553531, -2.8505478]], dtype=float32)

time = 55662	action = 0	current_phase = 0	next_phase = 1	reward = -0.308618	array([[-1.9906775, -3.1689484]], dtype=float32)

time = 55667	action = 0	current_phase = 0	next_phase = 1	reward = -0.176458	array([[-2.2245376, -3.2136476]], dtype=float32)

time = 55672	action = 0	current_phase = 0	next_phase = 1	reward = 0.127750	array([[-2.796716 , -4.4130044]], dtype=float32)

time = 55677	action = 1	current_phase = 0	next_phase = 1	reward = -1.785577	array([[-6.5396085, -3.5379715]], dtype=float32)

time = 55685	action = 0	current_phase = 1	next_phase = 0	reward = -0.524295	array([[-2.1403854, -3.2327416]], dtype=float32)

time = 55690	action = 0	current_phase = 1	next_phase = 0	reward = -0.374128	array([[-2.0312607, -3.1591146]], dtype=float32)

time = 55695	action = 0	current_phase = 1	next_phase = 0	reward = -0.220530	array([[-1.9172351, -3.1391861]], dtype=float32)

time = 55700	action = 0	current_phase = 1	next_phase = 0	reward = 0.057763	array([[-2.0803268, -3.9864395]], dtype=float32)

time = 55705	action = 0	current_phase = 1	next_phase = 0	reward = -0.618128	array([[-2.83383  , -2.8556058]], dtype=float32)

time = 55710	action = 1	current_phase = 1	next_phase = 0	reward = -2.105786	array([[-6.1771216, -3.3962846]], dtype=float32)

time = 55718	action = 0	current_phase = 0	next_phase = 1	reward = -0.423129	array([[-2.0527325, -3.2136762]], dtype=float32)

time = 55723	action = 0	current_phase = 0	next_phase = 1	reward = -0.267649	array([[-1.9905257, -3.1681705]], dtype=float32)

time = 55728	action = 0	current_phase = 0	next_phase = 1	reward = -0.165077	array([[-2.2280853, -3.2187686]], dtype=float32)

time = 55733	action = 0	current_phase = 0	next_phase = 1	reward = -0.066550	array([[-2.8038094, -4.4064407]], dtype=float32)

time = 55738	action = 1	current_phase = 0	next_phase = 1	reward = -1.899734	array([[-5.0319967, -3.593506 ]], dtype=float32)

time = 55746	action = 0	current_phase = 1	next_phase = 0	reward = -0.495498	array([[-2.1606004, -3.2383873]], dtype=float32)

time = 55751	action = 0	current_phase = 1	next_phase = 0	reward = -0.344137	array([[-2.031265 , -3.1586542]], dtype=float32)

time = 55756	action = 0	current_phase = 1	next_phase = 0	reward = -0.197229	array([[-1.93994  , -3.1481037]], dtype=float32)

time = 55761	action = 0	current_phase = 1	next_phase = 0	reward = 0.299676	array([[-2.1397998, -4.0668106]], dtype=float32)

time = 55766	action = 1	current_phase = 1	next_phase = 0	reward = -1.662946	array([[-5.645692 , -3.2071345]], dtype=float32)

time = 55774	action = 0	current_phase = 0	next_phase = 1	reward = -0.564335	array([[-2.1011627, -3.0506418]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0137 - val_loss: 0.0048

Epoch 2/50

 - 4s - loss: 0.0132 - val_loss: 0.0051

Epoch 3/50

 - 4s - loss: 0.0136 - val_loss: 0.0052

Epoch 4/50

 - 4s - loss: 0.0132 - val_loss: 0.0048

Epoch 5/50

 - 4s - loss: 0.0109 - val_loss: 0.0055

Epoch 6/50

 - 4s - loss: 0.0118 - val_loss: 0.0048

Epoch 7/50

 - 4s - loss: 0.0108 - val_loss: 0.0047

Epoch 8/50

 - 4s - loss: 0.0099 - val_loss: 0.0048

Epoch 9/50

 - 4s - loss: 0.0111 - val_loss: 0.0050

Epoch 10/50

 - 4s - loss: 0.0093 - val_loss: 0.0052

Epoch 11/50

 - 4s - loss: 0.0131 - val_loss: 0.0056

Epoch 12/50

 - 4s - loss: 0.0105 - val_loss: 0.0063

Epoch 13/50

 - 4s - loss: 0.0095 - val_loss: 0.0056

Epoch 14/50

 - 4s - loss: 0.0088 - val_loss: 0.0054

Epoch 15/50

 - 4s - loss: 0.0099 - val_loss: 0.0055

Epoch 16/50

 - 4s - loss: 0.0133 - val_loss: 0.0061

Epoch 17/50

 - 4s - loss: 0.0078 - val_loss: 0.0064

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 55779	action = 0	current_phase = 0	next_phase = 1	reward = -0.410265	array([[-1.9581287, -2.8899863]], dtype=float32)

time = 55784	action = 0	current_phase = 0	next_phase = 1	reward = -0.254861	array([[-1.9891424, -3.2232122]], dtype=float32)

time = 55789	action = 0	current_phase = 0	next_phase = 1	reward = -0.182573	array([[-2.0574687, -3.0535161]], dtype=float32)

time = 55794	action = 1	current_phase = 0	next_phase = 1	reward = -0.603867	array([[-5.4702315, -2.3635082]], dtype=float32)

time = 55802	action = 0	current_phase = 1	next_phase = 0	reward = -0.622121	array([[-2.1902401, -3.0915356]], dtype=float32)

time = 55807	action = 0	current_phase = 1	next_phase = 0	reward = -0.466596	array([[-1.9816232, -3.1369789]], dtype=float32)

time = 55812	action = 0	current_phase = 1	next_phase = 0	reward = -0.309898	array([[-2.0563273, -3.111762 ]], dtype=float32)

time = 55817	action = 0	current_phase = 1	next_phase = 0	reward = -0.174649	array([[-2.1658518, -3.2514114]], dtype=float32)

time = 55822	action = 0	current_phase = 1	next_phase = 0	reward = 0.209538	array([[-2.4950593, -4.138937 ]], dtype=float32)

time = 55827	action = 1	current_phase = 1	next_phase = 0	reward = -1.731216	array([[-6.1711473, -3.383688 ]], dtype=float32)

time = 55835	action = 0	current_phase = 0	next_phase = 1	reward = -0.521813	array([[-2.1004403, -3.2502108]], dtype=float32)

time = 55840	action = 0	current_phase = 0	next_phase = 1	reward = -0.363677	array([[-1.9132471, -2.9242353]], dtype=float32)

time = 55845	action = 0	current_phase = 0	next_phase = 1	reward = -0.207460	array([[-1.9724748, -3.2963777]], dtype=float32)

time = 55850	action = 0	current_phase = 0	next_phase = 1	reward = 0.340829	array([[-2.1975887, -3.8227527]], dtype=float32)

time = 55855	action = 1	current_phase = 0	next_phase = 1	reward = -1.372727	array([[-4.632483, -3.126545]], dtype=float32)

time = 55863	action = 0	current_phase = 1	next_phase = 0	reward = -0.588682	array([[-2.1933084, -3.0940094]], dtype=float32)

time = 55868	action = 0	current_phase = 1	next_phase = 0	reward = -0.424229	array([[-1.9630926, -3.1359391]], dtype=float32)

time = 55873	action = 0	current_phase = 1	next_phase = 0	reward = -0.265679	array([[-2.0810728, -3.0989852]], dtype=float32)

time = 55878	action = 0	current_phase = 1	next_phase = 0	reward = -0.157442	array([[-2.1667066, -3.2524354]], dtype=float32)

time = 55883	action = 0	current_phase = 1	next_phase = 0	reward = -0.044017	array([[-2.4775035, -3.830757 ]], dtype=float32)

time = 55888	action = 1	current_phase = 1	next_phase = 0	reward = -1.908877	array([[-6.1738667, -3.3863282]], dtype=float32)

time = 55896	action = 0	current_phase = 0	next_phase = 1	reward = -0.512932	array([[-2.0596514, -3.2393253]], dtype=float32)

time = 55901	action = 0	current_phase = 0	next_phase = 1	reward = -0.359344	array([[-1.9271975, -2.9187362]], dtype=float32)

time = 55906	action = 0	current_phase = 0	next_phase = 1	reward = -0.213965	array([[-1.9947556, -3.3087711]], dtype=float32)

time = 55911	action = 0	current_phase = 0	next_phase = 1	reward = 0.323152	array([[-2.3217423, -4.0699353]], dtype=float32)

time = 55916	action = 1	current_phase = 0	next_phase = 1	reward = -1.555596	array([[-4.464909 , -3.2978287]], dtype=float32)

time = 55924	action = 0	current_phase = 1	next_phase = 0	reward = -0.555458	array([[-2.1880734, -3.0922623]], dtype=float32)

time = 55929	action = 0	current_phase = 1	next_phase = 0	reward = -0.403325	array([[-1.9628042, -3.1353884]], dtype=float32)

time = 55934	action = 0	current_phase = 1	next_phase = 0	reward = -0.246784	array([[-1.9478267, -3.132898 ]], dtype=float32)

time = 55939	action = 0	current_phase = 1	next_phase = 0	reward = -0.174629	array([[-2.0013592, -3.7850575]], dtype=float32)

time = 55944	action = 1	current_phase = 1	next_phase = 0	reward = -0.529504	array([[-2.326276, -2.142858]], dtype=float32)

time = 55952	action = 0	current_phase = 0	next_phase = 1	reward = -0.626142	array([[-2.205217 , -3.7849376]], dtype=float32)

time = 55957	action = 0	current_phase = 0	next_phase = 1	reward = -0.472878	array([[-1.9749597, -2.9017344]], dtype=float32)

time = 55962	action = 0	current_phase = 0	next_phase = 1	reward = -0.318599	array([[-2.0142918, -3.2055633]], dtype=float32)

time = 55967	action = 0	current_phase = 0	next_phase = 1	reward = -0.178665	array([[-2.2736065, -3.2690368]], dtype=float32)

time = 55972	action = 0	current_phase = 0	next_phase = 1	reward = 0.193708	array([[-2.7097716, -4.4347796]], dtype=float32)

time = 55977	action = 1	current_phase = 0	next_phase = 1	reward = -1.785916	array([[-6.4336386, -3.4806643]], dtype=float32)

time = 55985	action = 0	current_phase = 1	next_phase = 0	reward = -0.531809	array([[-2.1184742, -3.2207725]], dtype=float32)

time = 55990	action = 0	current_phase = 1	next_phase = 0	reward = -0.375730	array([[-1.9628475, -3.1354735]], dtype=float32)

time = 55995	action = 0	current_phase = 1	next_phase = 0	reward = -0.220098	array([[-1.8665869, -3.1134634]], dtype=float32)

time = 56000	action = 0	current_phase = 1	next_phase = 0	reward = 0.073672	array([[-2.0294113, -3.8207638]], dtype=float32)

time = 56005	action = 1	current_phase = 1	next_phase = 0	reward = -1.129531	array([[-2.8459435, -2.7653096]], dtype=float32)

time = 56013	action = 0	current_phase = 0	next_phase = 1	reward = -0.578069	array([[-2.2034733, -3.7410686]], dtype=float32)

time = 56018	action = 0	current_phase = 0	next_phase = 1	reward = -0.430069	array([[-1.9619725, -2.8908753]], dtype=float32)

time = 56023	action = 0	current_phase = 0	next_phase = 1	reward = -0.268007	array([[-2.0189242, -3.2063305]], dtype=float32)

time = 56028	action = 0	current_phase = 0	next_phase = 1	reward = -0.167609	array([[-2.131883 , -3.1232734]], dtype=float32)

time = 56033	action = 0	current_phase = 0	next_phase = 1	reward = 0.050380	array([[-2.7433646, -4.2224154]], dtype=float32)

time = 56038	action = 1	current_phase = 0	next_phase = 1	reward = -1.901521	array([[-6.551866, -3.588814]], dtype=float32)

time = 56046	action = 0	current_phase = 1	next_phase = 0	reward = -0.494535	array([[-2.1170073, -3.2290258]], dtype=float32)

time = 56051	action = 0	current_phase = 1	next_phase = 0	reward = -0.339054	array([[-1.9631749, -3.1355023]], dtype=float32)

time = 56056	action = 0	current_phase = 1	next_phase = 0	reward = -0.190725	array([[-1.8931543, -3.1308014]], dtype=float32)

time = 56061	action = 0	current_phase = 1	next_phase = 0	reward = 0.316745	array([[-2.1991677, -4.0881014]], dtype=float32)

time = 56066	action = 1	current_phase = 1	next_phase = 0	reward = -1.608910	array([[-5.6411858, -3.1753979]], dtype=float32)

time = 56074	action = 0	current_phase = 0	next_phase = 1	reward = -0.559036	array([[-2.1366303, -3.0876253]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0139 - val_loss: 0.0060

Epoch 2/50

 - 4s - loss: 0.0160 - val_loss: 0.0063

Epoch 3/50

 - 4s - loss: 0.0170 - val_loss: 0.0060

Epoch 4/50

 - 4s - loss: 0.0141 - val_loss: 0.0063

Epoch 5/50

 - 4s - loss: 0.0127 - val_loss: 0.0066

Epoch 6/50

 - 4s - loss: 0.0110 - val_loss: 0.0059

Epoch 7/50

 - 4s - loss: 0.0142 - val_loss: 0.0058

Epoch 8/50

 - 4s - loss: 0.0128 - val_loss: 0.0064

Epoch 9/50

 - 4s - loss: 0.0145 - val_loss: 0.0069

Epoch 10/50

 - 4s - loss: 0.0101 - val_loss: 0.0061

Epoch 11/50

 - 4s - loss: 0.0096 - val_loss: 0.0071

Epoch 12/50

 - 4s - loss: 0.0106 - val_loss: 0.0067

Epoch 13/50

 - 4s - loss: 0.0095 - val_loss: 0.0065

Epoch 14/50

 - 4s - loss: 0.0132 - val_loss: 0.0060

Epoch 15/50

 - 4s - loss: 0.0099 - val_loss: 0.0062

Epoch 16/50

 - 4s - loss: 0.0113 - val_loss: 0.0065

Epoch 17/50

 - 4s - loss: 0.0089 - val_loss: 0.0063

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 56079	action = 0	current_phase = 0	next_phase = 1	reward = -0.409385	array([[-2.026722 , -2.9054832]], dtype=float32)

time = 56084	action = 0	current_phase = 0	next_phase = 1	reward = -0.249517	array([[-1.9807037, -3.3122392]], dtype=float32)

time = 56089	action = 0	current_phase = 0	next_phase = 1	reward = -0.170759	array([[-2.0440307, -3.082039 ]], dtype=float32)

time = 56094	action = 1	current_phase = 0	next_phase = 1	reward = -0.526118	array([[-5.4995804, -2.319199 ]], dtype=float32)

time = 56102	action = 0	current_phase = 1	next_phase = 0	reward = -0.617108	array([[-2.1596594, -3.0900311]], dtype=float32)

time = 56107	action = 0	current_phase = 1	next_phase = 0	reward = -0.465075	array([[-2.0419168, -3.11837  ]], dtype=float32)

time = 56112	action = 0	current_phase = 1	next_phase = 0	reward = -0.314365	array([[-2.04519 , -3.103213]], dtype=float32)

time = 56117	action = 0	current_phase = 1	next_phase = 0	reward = -0.180914	array([[-2.1567025, -3.233929 ]], dtype=float32)

time = 56122	action = 0	current_phase = 1	next_phase = 0	reward = 0.175022	array([[-2.48572  , -4.1659293]], dtype=float32)

time = 56127	action = 1	current_phase = 1	next_phase = 0	reward = -1.788279	array([[-6.168737 , -3.5124576]], dtype=float32)

time = 56135	action = 0	current_phase = 0	next_phase = 1	reward = -0.528691	array([[-2.094023 , -3.2663708]], dtype=float32)

time = 56140	action = 0	current_phase = 0	next_phase = 1	reward = -0.375679	array([[-1.9647478, -2.9436202]], dtype=float32)

time = 56145	action = 0	current_phase = 0	next_phase = 1	reward = -0.221581	array([[-1.9824408, -3.3141372]], dtype=float32)

time = 56150	action = 0	current_phase = 0	next_phase = 1	reward = 0.375881	array([[-2.1413636, -3.6261766]], dtype=float32)

time = 56155	action = 1	current_phase = 0	next_phase = 1	reward = -1.298897	array([[-4.669825 , -3.1250443]], dtype=float32)

time = 56163	action = 0	current_phase = 1	next_phase = 0	reward = -0.585802	array([[-2.1629596, -3.0917544]], dtype=float32)

time = 56168	action = 0	current_phase = 1	next_phase = 0	reward = -0.428977	array([[-1.9549555, -3.1321335]], dtype=float32)

time = 56173	action = 0	current_phase = 1	next_phase = 0	reward = -0.270853	array([[-1.9235752, -3.0787632]], dtype=float32)

time = 56178	action = 0	current_phase = 1	next_phase = 0	reward = -0.161842	array([[-2.1357212, -3.2407765]], dtype=float32)

time = 56183	action = 0	current_phase = 1	next_phase = 0	reward = 0.049146	array([[-2.398384 , -3.9140582]], dtype=float32)

time = 56188	action = 1	current_phase = 1	next_phase = 0	reward = -1.903182	array([[-6.1719465, -3.5184772]], dtype=float32)

time = 56196	action = 0	current_phase = 0	next_phase = 1	reward = -0.501780	array([[-2.0458822, -3.2543523]], dtype=float32)

time = 56201	action = 0	current_phase = 0	next_phase = 1	reward = -0.348738	array([[-1.9984354, -2.9213529]], dtype=float32)

time = 56206	action = 0	current_phase = 0	next_phase = 1	reward = -0.195830	array([[-1.9936311, -3.3111157]], dtype=float32)

time = 56211	action = 0	current_phase = 0	next_phase = 1	reward = 0.330626	array([[-2.3604622, -4.128437 ]], dtype=float32)

time = 56216	action = 1	current_phase = 0	next_phase = 1	reward = -1.555388	array([[-4.501501 , -3.3642135]], dtype=float32)

time = 56224	action = 0	current_phase = 1	next_phase = 0	reward = -0.560593	array([[-2.1444693, -3.0956373]], dtype=float32)

time = 56229	action = 0	current_phase = 1	next_phase = 0	reward = -0.398461	array([[-1.9448495, -3.1307883]], dtype=float32)

time = 56234	action = 0	current_phase = 1	next_phase = 0	reward = -0.236314	array([[-1.8820404, -3.1170876]], dtype=float32)

time = 56239	action = 0	current_phase = 1	next_phase = 0	reward = -0.170245	array([[-1.9524649, -3.7823784]], dtype=float32)

time = 56244	action = 1	current_phase = 1	next_phase = 0	reward = -0.528503	array([[-2.2978535, -2.2291138]], dtype=float32)

time = 56252	action = 0	current_phase = 0	next_phase = 1	reward = -0.622606	array([[-2.1989233, -3.7834535]], dtype=float32)

time = 56257	action = 0	current_phase = 0	next_phase = 1	reward = -0.467813	array([[-2.0420165, -2.9036722]], dtype=float32)

time = 56262	action = 0	current_phase = 0	next_phase = 1	reward = -0.315542	array([[-2.0682955, -3.2196083]], dtype=float32)

time = 56267	action = 0	current_phase = 0	next_phase = 1	reward = -0.186721	array([[-2.2782736, -3.2379932]], dtype=float32)

time = 56272	action = 0	current_phase = 0	next_phase = 1	reward = 0.263516	array([[-2.7235963, -4.454456 ]], dtype=float32)

time = 56277	action = 1	current_phase = 0	next_phase = 1	reward = -1.728518	array([[-6.1341677, -3.4497447]], dtype=float32)

time = 56285	action = 0	current_phase = 1	next_phase = 0	reward = -0.519506	array([[-2.0573971, -3.2212362]], dtype=float32)

time = 56290	action = 0	current_phase = 1	next_phase = 0	reward = -0.357159	array([[-1.9456226, -3.132357 ]], dtype=float32)

time = 56295	action = 0	current_phase = 1	next_phase = 0	reward = -0.208202	array([[-1.8518878, -3.1100028]], dtype=float32)

time = 56300	action = 0	current_phase = 1	next_phase = 0	reward = 0.347741	array([[-2.0358636, -3.9563205]], dtype=float32)

time = 56305	action = 1	current_phase = 1	next_phase = 0	reward = -1.369732	array([[-3.1389308, -3.0888505]], dtype=float32)

time = 56313	action = 0	current_phase = 0	next_phase = 1	reward = -0.586346	array([[-2.197739 , -3.7794063]], dtype=float32)

time = 56318	action = 0	current_phase = 0	next_phase = 1	reward = -0.428601	array([[-2.0312595, -2.9035983]], dtype=float32)

time = 56323	action = 0	current_phase = 0	next_phase = 1	reward = -0.267738	array([[-2.0684712, -3.2194514]], dtype=float32)

time = 56328	action = 0	current_phase = 0	next_phase = 1	reward = -0.158915	array([[-2.3291326, -3.2945693]], dtype=float32)

time = 56333	action = 0	current_phase = 0	next_phase = 1	reward = -0.055145	array([[-3.3851328, -4.0850396]], dtype=float32)

time = 56338	action = 1	current_phase = 0	next_phase = 1	reward = -1.901485	array([[-6.5464964, -3.5909975]], dtype=float32)

time = 56346	action = 0	current_phase = 1	next_phase = 0	reward = -0.501508	array([[-2.057694 , -3.2255952]], dtype=float32)

time = 56351	action = 0	current_phase = 1	next_phase = 0	reward = -0.343093	array([[-1.9486147, -3.1305   ]], dtype=float32)

time = 56356	action = 0	current_phase = 1	next_phase = 0	reward = -0.196237	array([[-1.9387338, -3.1445065]], dtype=float32)

time = 56361	action = 0	current_phase = 1	next_phase = 0	reward = 0.325396	array([[-2.193907, -4.105531]], dtype=float32)

time = 56366	action = 1	current_phase = 1	next_phase = 0	reward = -1.498345	array([[-5.5775266, -3.285038 ]], dtype=float32)

time = 56374	action = 0	current_phase = 0	next_phase = 1	reward = -0.556251	array([[-2.133566, -3.102646]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0171 - val_loss: 0.0176

Epoch 2/50

 - 4s - loss: 0.0143 - val_loss: 0.0166

Epoch 3/50

 - 4s - loss: 0.0197 - val_loss: 0.0169

Epoch 4/50

 - 4s - loss: 0.0182 - val_loss: 0.0172

Epoch 5/50

 - 4s - loss: 0.0137 - val_loss: 0.0165

Epoch 6/50

 - 4s - loss: 0.0140 - val_loss: 0.0162

Epoch 7/50

 - 4s - loss: 0.0146 - val_loss: 0.0159

Epoch 8/50

 - 4s - loss: 0.0114 - val_loss: 0.0156

Epoch 9/50

 - 4s - loss: 0.0157 - val_loss: 0.0149

Epoch 10/50

 - 4s - loss: 0.0139 - val_loss: 0.0168

Epoch 11/50

 - 4s - loss: 0.0112 - val_loss: 0.0173

Epoch 12/50

 - 4s - loss: 0.0123 - val_loss: 0.0172

Epoch 13/50

 - 4s - loss: 0.0148 - val_loss: 0.0157

Epoch 14/50

 - 4s - loss: 0.0126 - val_loss: 0.0174

Epoch 15/50

 - 4s - loss: 0.0103 - val_loss: 0.0184

Epoch 16/50

 - 4s - loss: 0.0107 - val_loss: 0.0164

Epoch 17/50

 - 4s - loss: 0.0086 - val_loss: 0.0172

Epoch 18/50

 - 4s - loss: 0.0140 - val_loss: 0.0196

Epoch 19/50

 - 4s - loss: 0.0106 - val_loss: 0.0192

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 56379	action = 0	current_phase = 0	next_phase = 1	reward = -0.398861	array([[-2.0090537, -2.8962064]], dtype=float32)

time = 56384	action = 0	current_phase = 0	next_phase = 1	reward = -0.247777	array([[-1.9318479, -3.288259 ]], dtype=float32)

time = 56389	action = 0	current_phase = 0	next_phase = 1	reward = -0.189402	array([[-2.0287218, -3.0763092]], dtype=float32)

time = 56394	action = 1	current_phase = 0	next_phase = 1	reward = -0.526077	array([[-5.4798293, -2.204832 ]], dtype=float32)

time = 56402	action = 0	current_phase = 1	next_phase = 0	reward = -0.618646	array([[-2.1857657, -3.0971618]], dtype=float32)

time = 56407	action = 0	current_phase = 1	next_phase = 0	reward = -0.468940	array([[-2.148919, -3.107026]], dtype=float32)

time = 56412	action = 0	current_phase = 1	next_phase = 0	reward = -0.312412	array([[-2.0478303, -3.1026537]], dtype=float32)

time = 56417	action = 0	current_phase = 1	next_phase = 0	reward = -0.173458	array([[-2.1708937, -3.2249897]], dtype=float32)

time = 56422	action = 0	current_phase = 1	next_phase = 0	reward = 0.183988	array([[-2.459124, -4.111638]], dtype=float32)

time = 56427	action = 1	current_phase = 1	next_phase = 0	reward = -1.780214	array([[-6.1639695, -3.4818225]], dtype=float32)

time = 56435	action = 0	current_phase = 0	next_phase = 1	reward = -0.525120	array([[-2.0612464, -3.2509181]], dtype=float32)

time = 56440	action = 0	current_phase = 0	next_phase = 1	reward = -0.358924	array([[-1.9468443, -2.9272907]], dtype=float32)

time = 56445	action = 0	current_phase = 0	next_phase = 1	reward = -0.207132	array([[-1.9333129, -3.2916045]], dtype=float32)

time = 56450	action = 0	current_phase = 0	next_phase = 1	reward = 0.326598	array([[-2.1319385, -3.7308598]], dtype=float32)

time = 56455	action = 1	current_phase = 0	next_phase = 1	reward = -1.427488	array([[-4.6610885, -3.1224413]], dtype=float32)

time = 56463	action = 0	current_phase = 1	next_phase = 0	reward = -0.590319	array([[-2.1853948, -3.0973043]], dtype=float32)

time = 56468	action = 0	current_phase = 1	next_phase = 0	reward = -0.431560	array([[-1.9645883, -3.1184723]], dtype=float32)

time = 56473	action = 0	current_phase = 1	next_phase = 0	reward = -0.279229	array([[-2.0231233, -3.1087155]], dtype=float32)

time = 56478	action = 0	current_phase = 1	next_phase = 0	reward = -0.167694	array([[-2.1612186, -3.2245715]], dtype=float32)

time = 56483	action = 0	current_phase = 1	next_phase = 0	reward = -0.003456	array([[-2.7652588, -3.9606142]], dtype=float32)

time = 56488	action = 1	current_phase = 1	next_phase = 0	reward = -1.905154	array([[-6.172623, -3.492824]], dtype=float32)

time = 56496	action = 0	current_phase = 0	next_phase = 1	reward = -0.497912	array([[-2.007481 , -3.2347932]], dtype=float32)

time = 56501	action = 0	current_phase = 0	next_phase = 1	reward = -0.346955	array([[-1.9348922, -2.935611 ]], dtype=float32)

time = 56506	action = 0	current_phase = 0	next_phase = 1	reward = -0.203397	array([[-2.031797 , -3.1213145]], dtype=float32)

time = 56511	action = 0	current_phase = 0	next_phase = 1	reward = 0.268442	array([[-2.2439299, -3.9888492]], dtype=float32)

time = 56516	action = 1	current_phase = 0	next_phase = 1	reward = -1.609786	array([[-4.4698873, -3.2288253]], dtype=float32)

time = 56524	action = 0	current_phase = 1	next_phase = 0	reward = -0.556672	array([[-2.1840632, -3.0979846]], dtype=float32)

time = 56529	action = 0	current_phase = 1	next_phase = 0	reward = -0.409653	array([[-1.9637251, -3.1182911]], dtype=float32)

time = 56534	action = 0	current_phase = 1	next_phase = 0	reward = -0.253441	array([[-1.9005262, -3.0973468]], dtype=float32)

time = 56539	action = 0	current_phase = 1	next_phase = 0	reward = -0.171289	array([[-1.9903555, -3.761315 ]], dtype=float32)

time = 56544	action = 1	current_phase = 1	next_phase = 0	reward = -0.473458	array([[-2.2696953, -2.139501 ]], dtype=float32)

time = 56552	action = 0	current_phase = 0	next_phase = 1	reward = -0.628410	array([[-2.2045722, -3.77552  ]], dtype=float32)

time = 56557	action = 0	current_phase = 0	next_phase = 1	reward = -0.480553	array([[-2.0321631, -2.900249 ]], dtype=float32)

time = 56562	action = 0	current_phase = 0	next_phase = 1	reward = -0.328960	array([[-2.052695 , -3.2000127]], dtype=float32)

time = 56567	action = 0	current_phase = 0	next_phase = 1	reward = -0.184320	array([[-2.1511626, -3.0866222]], dtype=float32)

time = 56572	action = 0	current_phase = 0	next_phase = 1	reward = 0.237553	array([[-2.6658907, -4.4180145]], dtype=float32)

time = 56577	action = 1	current_phase = 0	next_phase = 1	reward = -1.730694	array([[-6.1645484, -3.4156048]], dtype=float32)

time = 56585	action = 0	current_phase = 1	next_phase = 0	reward = -0.529490	array([[-2.059494 , -3.2111642]], dtype=float32)

time = 56590	action = 0	current_phase = 1	next_phase = 0	reward = -0.377095	array([[-1.9640898, -3.1187456]], dtype=float32)

time = 56595	action = 0	current_phase = 1	next_phase = 0	reward = -0.215683	array([[-1.8750865, -3.0911171]], dtype=float32)

time = 56600	action = 0	current_phase = 1	next_phase = 0	reward = 0.357209	array([[-2.0476878, -3.9119978]], dtype=float32)

time = 56605	action = 1	current_phase = 1	next_phase = 0	reward = -1.312639	array([[-3.1245906, -3.0422044]], dtype=float32)

time = 56613	action = 0	current_phase = 0	next_phase = 1	reward = -0.586771	array([[-2.1876552, -3.7700613]], dtype=float32)

time = 56618	action = 0	current_phase = 0	next_phase = 1	reward = -0.437939	array([[-2.0138297, -2.8941011]], dtype=float32)

time = 56623	action = 0	current_phase = 0	next_phase = 1	reward = -0.286653	array([[-2.0554128, -3.1998816]], dtype=float32)

time = 56628	action = 0	current_phase = 0	next_phase = 1	reward = -0.163614	array([[-2.336669 , -3.2570283]], dtype=float32)

time = 56633	action = 0	current_phase = 0	next_phase = 1	reward = 0.090737	array([[-2.9375672, -4.1630096]], dtype=float32)

time = 56638	action = 1	current_phase = 0	next_phase = 1	reward = -1.896171	array([[-6.540553 , -3.6132896]], dtype=float32)

time = 56646	action = 0	current_phase = 1	next_phase = 0	reward = -0.494792	array([[-2.060857 , -3.2168317]], dtype=float32)

time = 56651	action = 0	current_phase = 1	next_phase = 0	reward = -0.340658	array([[-1.9651986, -3.1184456]], dtype=float32)

time = 56656	action = 0	current_phase = 1	next_phase = 0	reward = -0.195831	array([[-1.9726287, -3.13406  ]], dtype=float32)

time = 56661	action = 0	current_phase = 1	next_phase = 0	reward = 0.290880	array([[-2.1865764, -4.1103506]], dtype=float32)

time = 56666	action = 1	current_phase = 1	next_phase = 0	reward = -1.559497	array([[-5.626848 , -3.2806995]], dtype=float32)

time = 56674	action = 0	current_phase = 0	next_phase = 1	reward = -0.561803	array([[-2.0950656, -3.093527 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0188 - val_loss: 0.0058

Epoch 2/50

 - 4s - loss: 0.0132 - val_loss: 0.0062

Epoch 3/50

 - 4s - loss: 0.0124 - val_loss: 0.0070

Epoch 4/50

 - 4s - loss: 0.0113 - val_loss: 0.0058

Epoch 5/50

 - 4s - loss: 0.0088 - val_loss: 0.0065

Epoch 6/50

 - 4s - loss: 0.0145 - val_loss: 0.0060

Epoch 7/50

 - 4s - loss: 0.0122 - val_loss: 0.0060

Epoch 8/50

 - 4s - loss: 0.0107 - val_loss: 0.0061

Epoch 9/50

 - 4s - loss: 0.0085 - val_loss: 0.0064

Epoch 10/50

 - 4s - loss: 0.0086 - val_loss: 0.0065

Epoch 11/50

 - 4s - loss: 0.0134 - val_loss: 0.0071

Epoch 12/50

 - 4s - loss: 0.0080 - val_loss: 0.0080

Epoch 13/50

 - 4s - loss: 0.0127 - val_loss: 0.0080

Epoch 14/50

 - 4s - loss: 0.0085 - val_loss: 0.0073

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 56679	action = 0	current_phase = 0	next_phase = 1	reward = -0.396034	array([[-2.0290136, -2.9036493]], dtype=float32)

time = 56684	action = 0	current_phase = 0	next_phase = 1	reward = -0.230414	array([[-1.9850321, -3.2849553]], dtype=float32)

time = 56689	action = 0	current_phase = 0	next_phase = 1	reward = -0.174691	array([[-2.0612724, -3.1026385]], dtype=float32)

time = 56694	action = 1	current_phase = 0	next_phase = 1	reward = -0.584020	array([[-5.503338 , -2.2793968]], dtype=float32)

time = 56702	action = 0	current_phase = 1	next_phase = 0	reward = -0.611206	array([[-2.1752877, -3.093911 ]], dtype=float32)

time = 56707	action = 0	current_phase = 1	next_phase = 0	reward = -0.457185	array([[-2.1402552, -3.1015704]], dtype=float32)

time = 56712	action = 0	current_phase = 1	next_phase = 0	reward = -0.297100	array([[-2.0252938, -3.116513 ]], dtype=float32)

time = 56717	action = 0	current_phase = 1	next_phase = 0	reward = -0.172221	array([[-2.152979 , -3.2285883]], dtype=float32)

time = 56722	action = 0	current_phase = 1	next_phase = 0	reward = 0.167737	array([[-2.5617845, -4.242638 ]], dtype=float32)

time = 56727	action = 1	current_phase = 1	next_phase = 0	reward = -1.736539	array([[-6.1631923, -3.5129457]], dtype=float32)

time = 56735	action = 0	current_phase = 0	next_phase = 1	reward = -0.528851	array([[-2.082667, -3.255347]], dtype=float32)

time = 56740	action = 0	current_phase = 0	next_phase = 1	reward = -0.376448	array([[-1.9680352, -2.9473717]], dtype=float32)

time = 56745	action = 0	current_phase = 0	next_phase = 1	reward = -0.227596	array([[-1.9723752, -3.3213322]], dtype=float32)

time = 56750	action = 0	current_phase = 0	next_phase = 1	reward = 0.059576	array([[-2.1628368, -3.8299692]], dtype=float32)

time = 56755	action = 1	current_phase = 0	next_phase = 1	reward = -0.981198	array([[-5.1846914, -2.746097 ]], dtype=float32)

time = 56763	action = 0	current_phase = 1	next_phase = 0	reward = -0.586295	array([[-2.176177 , -3.0949306]], dtype=float32)

time = 56768	action = 0	current_phase = 1	next_phase = 0	reward = -0.432477	array([[-1.9609991, -3.12073  ]], dtype=float32)

time = 56773	action = 0	current_phase = 1	next_phase = 0	reward = -0.275372	array([[-2.0099447, -3.1143591]], dtype=float32)

time = 56778	action = 0	current_phase = 1	next_phase = 0	reward = -0.164244	array([[-2.153628 , -3.2279851]], dtype=float32)

time = 56783	action = 0	current_phase = 1	next_phase = 0	reward = 0.066862	array([[-2.4235578, -3.7267838]], dtype=float32)

time = 56788	action = 1	current_phase = 1	next_phase = 0	reward = -1.897228	array([[-6.1710625, -3.5299385]], dtype=float32)

time = 56796	action = 0	current_phase = 0	next_phase = 1	reward = -0.488076	array([[-2.0568423, -3.2452312]], dtype=float32)

time = 56801	action = 0	current_phase = 0	next_phase = 1	reward = -0.331428	array([[-1.9975212, -2.9235284]], dtype=float32)

time = 56806	action = 0	current_phase = 0	next_phase = 1	reward = -0.184252	array([[-2.1014786, -3.0380685]], dtype=float32)

time = 56811	action = 0	current_phase = 0	next_phase = 1	reward = 0.294254	array([[-2.441732, -4.203866]], dtype=float32)

time = 56816	action = 1	current_phase = 0	next_phase = 1	reward = -1.609011	array([[-4.462304 , -3.2985964]], dtype=float32)

time = 56824	action = 0	current_phase = 1	next_phase = 0	reward = -0.557687	array([[-2.1766367, -3.0946097]], dtype=float32)

time = 56829	action = 0	current_phase = 1	next_phase = 0	reward = -0.407152	array([[-1.9610354, -3.120712 ]], dtype=float32)

time = 56834	action = 0	current_phase = 1	next_phase = 0	reward = -0.245440	array([[-1.8654732, -3.0898817]], dtype=float32)

time = 56839	action = 0	current_phase = 1	next_phase = 0	reward = -0.177756	array([[-1.9608667, -3.7918558]], dtype=float32)

time = 56844	action = 1	current_phase = 1	next_phase = 0	reward = -0.549786	array([[-2.312308 , -2.1771412]], dtype=float32)

time = 56852	action = 0	current_phase = 0	next_phase = 1	reward = -0.616700	array([[-2.2054124, -3.7982693]], dtype=float32)

time = 56857	action = 0	current_phase = 0	next_phase = 1	reward = -0.466588	array([[-2.0417259, -2.8990984]], dtype=float32)

time = 56862	action = 0	current_phase = 0	next_phase = 1	reward = -0.311927	array([[-2.082728 , -3.2132416]], dtype=float32)

time = 56867	action = 0	current_phase = 0	next_phase = 1	reward = -0.173248	array([[-2.392416 , -3.2700243]], dtype=float32)

time = 56872	action = 0	current_phase = 0	next_phase = 1	reward = 0.249988	array([[-2.6498106, -4.411012 ]], dtype=float32)

time = 56877	action = 1	current_phase = 0	next_phase = 1	reward = -1.726794	array([[-6.2613873, -3.418962 ]], dtype=float32)

time = 56885	action = 0	current_phase = 1	next_phase = 0	reward = -0.540246	array([[-2.0816927, -3.209342 ]], dtype=float32)

time = 56890	action = 0	current_phase = 1	next_phase = 0	reward = -0.395278	array([[-1.9610356, -3.1208768]], dtype=float32)

time = 56895	action = 0	current_phase = 1	next_phase = 0	reward = -0.246999	array([[-1.8636082, -3.08961  ]], dtype=float32)

time = 56900	action = 0	current_phase = 1	next_phase = 0	reward = 0.388908	array([[-1.93434 , -3.816683]], dtype=float32)

time = 56905	action = 1	current_phase = 1	next_phase = 0	reward = -1.286482	array([[-3.2236362, -3.0508616]], dtype=float32)

time = 56913	action = 0	current_phase = 0	next_phase = 1	reward = -0.588397	array([[-2.203648, -3.798857]], dtype=float32)

time = 56918	action = 0	current_phase = 0	next_phase = 1	reward = -0.429225	array([[-2.039044 , -2.8981335]], dtype=float32)

time = 56923	action = 0	current_phase = 0	next_phase = 1	reward = -0.280936	array([[-2.0823188, -3.2139294]], dtype=float32)

time = 56928	action = 0	current_phase = 0	next_phase = 1	reward = -0.161138	array([[-2.4332018, -3.303295 ]], dtype=float32)

time = 56933	action = 0	current_phase = 0	next_phase = 1	reward = 0.136563	array([[-2.5390677, -4.055796 ]], dtype=float32)

time = 56938	action = 1	current_phase = 0	next_phase = 1	reward = -1.891466	array([[-6.5357137, -3.5437605]], dtype=float32)

time = 56946	action = 0	current_phase = 1	next_phase = 0	reward = -0.500976	array([[-2.0855513, -3.210132 ]], dtype=float32)

time = 56951	action = 0	current_phase = 1	next_phase = 0	reward = -0.343313	array([[-1.9619788, -3.1214027]], dtype=float32)

time = 56956	action = 0	current_phase = 1	next_phase = 0	reward = -0.195250	array([[-1.953739 , -3.1245706]], dtype=float32)

time = 56961	action = 0	current_phase = 1	next_phase = 0	reward = 0.316970	array([[-2.1150482, -4.0767565]], dtype=float32)

time = 56966	action = 1	current_phase = 1	next_phase = 0	reward = -1.560913	array([[-5.5944247, -3.286495 ]], dtype=float32)

time = 56974	action = 0	current_phase = 0	next_phase = 1	reward = -0.567151	array([[-2.127747 , -3.1074235]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0186 - val_loss: 0.0053

Epoch 2/50

 - 4s - loss: 0.0126 - val_loss: 0.0052

Epoch 3/50

 - 4s - loss: 0.0134 - val_loss: 0.0049

Epoch 4/50

 - 4s - loss: 0.0134 - val_loss: 0.0050

Epoch 5/50

 - 4s - loss: 0.0099 - val_loss: 0.0059

Epoch 6/50

 - 4s - loss: 0.0129 - val_loss: 0.0056

Epoch 7/50

 - 4s - loss: 0.0116 - val_loss: 0.0057

Epoch 8/50

 - 4s - loss: 0.0108 - val_loss: 0.0064

Epoch 9/50

 - 4s - loss: 0.0111 - val_loss: 0.0074

Epoch 10/50

 - 4s - loss: 0.0122 - val_loss: 0.0066

Epoch 11/50

 - 4s - loss: 0.0120 - val_loss: 0.0077

Epoch 12/50

 - 4s - loss: 0.0109 - val_loss: 0.0077

Epoch 13/50

 - 4s - loss: 0.0134 - val_loss: 0.0083

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 56979	action = 0	current_phase = 0	next_phase = 1	reward = -0.404153	array([[-1.9772311, -2.9141927]], dtype=float32)

time = 56984	action = 0	current_phase = 0	next_phase = 1	reward = -0.244339	array([[-1.9171236, -3.3334117]], dtype=float32)

time = 56989	action = 0	current_phase = 0	next_phase = 1	reward = -0.175087	array([[-2.0322144, -3.0871227]], dtype=float32)

time = 56994	action = 1	current_phase = 0	next_phase = 1	reward = -0.545611	array([[-5.508361 , -2.2985222]], dtype=float32)

time = 57002	action = 0	current_phase = 1	next_phase = 0	reward = -0.620361	array([[-2.1390133, -3.076127 ]], dtype=float32)

time = 57007	action = 0	current_phase = 1	next_phase = 0	reward = -0.461944	array([[-2.1339877, -3.0817704]], dtype=float32)

time = 57012	action = 0	current_phase = 1	next_phase = 0	reward = -0.308137	array([[-2.056861 , -3.0959406]], dtype=float32)

time = 57017	action = 0	current_phase = 1	next_phase = 0	reward = -0.176033	array([[-2.1347594, -3.216844 ]], dtype=float32)

time = 57022	action = 0	current_phase = 1	next_phase = 0	reward = 0.249587	array([[-2.5063436, -4.249134 ]], dtype=float32)

time = 57027	action = 1	current_phase = 1	next_phase = 0	reward = -1.788804	array([[-6.14957  , -3.4669075]], dtype=float32)

time = 57035	action = 0	current_phase = 0	next_phase = 1	reward = -0.548227	array([[-2.0376792, -3.271462 ]], dtype=float32)

time = 57040	action = 0	current_phase = 0	next_phase = 1	reward = -0.390312	array([[-1.9043199, -2.9830077]], dtype=float32)

time = 57045	action = 0	current_phase = 0	next_phase = 1	reward = -0.230418	array([[-1.9160548, -3.3330743]], dtype=float32)

time = 57050	action = 0	current_phase = 0	next_phase = 1	reward = -0.210228	array([[-2.1429684, -3.8135235]], dtype=float32)

time = 57055	action = 1	current_phase = 0	next_phase = 1	reward = -0.796551	array([[-5.491861, -2.341693]], dtype=float32)

time = 57063	action = 0	current_phase = 1	next_phase = 0	reward = -0.596709	array([[-2.1528547, -3.0790024]], dtype=float32)

time = 57068	action = 0	current_phase = 1	next_phase = 0	reward = -0.443877	array([[-1.9250567, -3.1072073]], dtype=float32)

time = 57073	action = 0	current_phase = 1	next_phase = 0	reward = -0.294598	array([[-2.0026152, -3.1053085]], dtype=float32)

time = 57078	action = 0	current_phase = 1	next_phase = 0	reward = -0.165805	array([[-2.118964 , -3.2222748]], dtype=float32)

time = 57083	action = 0	current_phase = 1	next_phase = 0	reward = 0.086353	array([[-2.5436935, -4.2436175]], dtype=float32)

time = 57088	action = 1	current_phase = 1	next_phase = 0	reward = -1.895360	array([[-6.167841 , -3.5039515]], dtype=float32)

time = 57096	action = 0	current_phase = 0	next_phase = 1	reward = -0.501351	array([[-1.9803872, -3.25063  ]], dtype=float32)

time = 57101	action = 0	current_phase = 0	next_phase = 1	reward = -0.344963	array([[-1.895745 , -3.0024397]], dtype=float32)

time = 57106	action = 0	current_phase = 0	next_phase = 1	reward = -0.193268	array([[-2.0536733, -3.0533013]], dtype=float32)

time = 57111	action = 0	current_phase = 0	next_phase = 1	reward = 0.304546	array([[-2.3050673, -4.06376  ]], dtype=float32)

time = 57116	action = 1	current_phase = 0	next_phase = 1	reward = -1.557329	array([[-4.4688635, -3.421313 ]], dtype=float32)

time = 57124	action = 0	current_phase = 1	next_phase = 0	reward = -0.557384	array([[-2.1456616, -3.0794945]], dtype=float32)

time = 57129	action = 0	current_phase = 1	next_phase = 0	reward = -0.404465	array([[-1.9229082, -3.106677 ]], dtype=float32)

time = 57134	action = 0	current_phase = 1	next_phase = 0	reward = -0.240633	array([[-1.8451486, -3.0777655]], dtype=float32)

time = 57139	action = 0	current_phase = 1	next_phase = 0	reward = -0.181360	array([[-1.9251449, -3.7918334]], dtype=float32)

time = 57144	action = 1	current_phase = 1	next_phase = 0	reward = -0.502767	array([[-2.2718272, -2.204893 ]], dtype=float32)

time = 57152	action = 0	current_phase = 0	next_phase = 1	reward = -0.619031	array([[-2.1535032, -3.834496 ]], dtype=float32)

time = 57157	action = 0	current_phase = 0	next_phase = 1	reward = -0.458075	array([[-2.0051296, -2.9011729]], dtype=float32)

time = 57162	action = 0	current_phase = 0	next_phase = 1	reward = -0.305418	array([[-2.0404067, -3.2147596]], dtype=float32)

time = 57167	action = 0	current_phase = 0	next_phase = 1	reward = -0.180171	array([[-2.3307676, -3.2335477]], dtype=float32)

time = 57172	action = 0	current_phase = 0	next_phase = 1	reward = 0.184260	array([[-2.4681225, -4.198113 ]], dtype=float32)

time = 57177	action = 1	current_phase = 0	next_phase = 1	reward = -1.729175	array([[-6.4845953, -3.480468 ]], dtype=float32)

time = 57185	action = 0	current_phase = 1	next_phase = 0	reward = -0.525700	array([[-2.0442588, -3.2209692]], dtype=float32)

time = 57190	action = 0	current_phase = 1	next_phase = 0	reward = -0.376614	array([[-1.9414173, -3.1238203]], dtype=float32)

time = 57195	action = 0	current_phase = 1	next_phase = 0	reward = -0.222079	array([[-1.913352 , -3.1075497]], dtype=float32)

time = 57200	action = 0	current_phase = 1	next_phase = 0	reward = 0.044399	array([[-2.0176852, -3.9701948]], dtype=float32)

time = 57205	action = 0	current_phase = 1	next_phase = 0	reward = -0.622984	array([[-2.788688 , -2.8430905]], dtype=float32)

time = 57210	action = 1	current_phase = 1	next_phase = 0	reward = -2.122426	array([[-6.1766376, -3.5136213]], dtype=float32)

time = 57218	action = 0	current_phase = 0	next_phase = 1	reward = -0.439505	array([[-1.9863467, -3.2573626]], dtype=float32)

time = 57223	action = 0	current_phase = 0	next_phase = 1	reward = -0.287485	array([[-2.045031 , -3.2142012]], dtype=float32)

time = 57228	action = 0	current_phase = 0	next_phase = 1	reward = -0.166234	array([[-2.372429 , -3.2624998]], dtype=float32)

time = 57233	action = 0	current_phase = 0	next_phase = 1	reward = -0.006397	array([[-2.6216133, -4.33946  ]], dtype=float32)

time = 57238	action = 1	current_phase = 0	next_phase = 1	reward = -1.902687	array([[-5.034174 , -3.6062336]], dtype=float32)

time = 57246	action = 0	current_phase = 1	next_phase = 0	reward = -0.495732	array([[-2.0540233, -3.2244062]], dtype=float32)

time = 57251	action = 0	current_phase = 1	next_phase = 0	reward = -0.335072	array([[-1.9304159, -3.111958 ]], dtype=float32)

time = 57256	action = 0	current_phase = 1	next_phase = 0	reward = -0.197894	array([[-1.9279794, -3.1136065]], dtype=float32)

time = 57261	action = 0	current_phase = 1	next_phase = 0	reward = 0.329330	array([[-2.083981 , -4.0571694]], dtype=float32)

time = 57266	action = 1	current_phase = 1	next_phase = 0	reward = -1.555235	array([[-5.621074 , -3.2216024]], dtype=float32)

time = 57274	action = 0	current_phase = 0	next_phase = 1	reward = -0.554666	array([[-2.078824 , -3.1235142]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0205 - val_loss: 0.0049

Epoch 2/50

 - 4s - loss: 0.0145 - val_loss: 0.0043

Epoch 3/50

 - 4s - loss: 0.0117 - val_loss: 0.0050

Epoch 4/50

 - 4s - loss: 0.0147 - val_loss: 0.0051

Epoch 5/50

 - 4s - loss: 0.0122 - val_loss: 0.0050

Epoch 6/50

 - 4s - loss: 0.0132 - val_loss: 0.0047

Epoch 7/50

 - 4s - loss: 0.0140 - val_loss: 0.0049

Epoch 8/50

 - 4s - loss: 0.0101 - val_loss: 0.0048

Epoch 9/50

 - 4s - loss: 0.0120 - val_loss: 0.0057

Epoch 10/50

 - 4s - loss: 0.0100 - val_loss: 0.0065

Epoch 11/50

 - 4s - loss: 0.0121 - val_loss: 0.0059

Epoch 12/50

 - 4s - loss: 0.0094 - val_loss: 0.0063

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 57279	action = 0	current_phase = 0	next_phase = 1	reward = -0.404056	array([[-2.0389383, -2.9132607]], dtype=float32)

time = 57284	action = 0	current_phase = 0	next_phase = 1	reward = -0.250442	array([[-1.9494445, -3.310894 ]], dtype=float32)

time = 57289	action = 0	current_phase = 0	next_phase = 1	reward = -0.180465	array([[-2.0571172, -3.0642314]], dtype=float32)

time = 57294	action = 1	current_phase = 0	next_phase = 1	reward = -0.537295	array([[-5.516204 , -2.2782826]], dtype=float32)

time = 57302	action = 0	current_phase = 1	next_phase = 0	reward = -0.612865	array([[-2.160026 , -3.0955997]], dtype=float32)

time = 57307	action = 0	current_phase = 1	next_phase = 0	reward = -0.456870	array([[-2.135509 , -3.1014707]], dtype=float32)

time = 57312	action = 0	current_phase = 1	next_phase = 0	reward = -0.303237	array([[-2.048156 , -3.1139193]], dtype=float32)

time = 57317	action = 0	current_phase = 1	next_phase = 0	reward = -0.169731	array([[-2.1739562, -3.2369418]], dtype=float32)

time = 57322	action = 0	current_phase = 1	next_phase = 0	reward = 0.182651	array([[-2.560604 , -4.2726946]], dtype=float32)

time = 57327	action = 1	current_phase = 1	next_phase = 0	reward = -1.785352	array([[-6.1744876, -3.5092237]], dtype=float32)

time = 57335	action = 0	current_phase = 0	next_phase = 1	reward = -0.529922	array([[-2.043089 , -3.2492738]], dtype=float32)

time = 57340	action = 0	current_phase = 0	next_phase = 1	reward = -0.376068	array([[-1.9624844, -3.0059228]], dtype=float32)

time = 57345	action = 0	current_phase = 0	next_phase = 1	reward = -0.219660	array([[-1.9494717, -3.311186 ]], dtype=float32)

time = 57350	action = 0	current_phase = 0	next_phase = 1	reward = 0.058960	array([[-2.1589277, -3.8185062]], dtype=float32)

time = 57355	action = 1	current_phase = 0	next_phase = 1	reward = -1.138217	array([[-4.9553294, -2.9218569]], dtype=float32)

time = 57363	action = 0	current_phase = 1	next_phase = 0	reward = -0.596508	array([[-2.1757607, -3.097267 ]], dtype=float32)

time = 57368	action = 0	current_phase = 1	next_phase = 0	reward = -0.443051	array([[-1.969504 , -3.1295822]], dtype=float32)

time = 57373	action = 0	current_phase = 1	next_phase = 0	reward = -0.283096	array([[-2.0026474, -3.1010134]], dtype=float32)

time = 57378	action = 0	current_phase = 1	next_phase = 0	reward = -0.163624	array([[-2.1612918, -3.2329772]], dtype=float32)

time = 57383	action = 0	current_phase = 1	next_phase = 0	reward = 0.021717	array([[-2.5510156, -4.203044 ]], dtype=float32)

time = 57388	action = 1	current_phase = 1	next_phase = 0	reward = -1.899934	array([[-6.184586, -3.521881]], dtype=float32)

time = 57396	action = 0	current_phase = 0	next_phase = 1	reward = -0.497103	array([[-2.0191925, -3.2419126]], dtype=float32)

time = 57401	action = 0	current_phase = 0	next_phase = 1	reward = -0.338751	array([[-1.9656624, -3.0000226]], dtype=float32)

time = 57406	action = 0	current_phase = 0	next_phase = 1	reward = -0.182396	array([[-2.100288 , -3.0410757]], dtype=float32)

time = 57411	action = 0	current_phase = 0	next_phase = 1	reward = 0.284073	array([[-2.380872, -4.092674]], dtype=float32)

time = 57416	action = 1	current_phase = 0	next_phase = 1	reward = -1.612231	array([[-4.454694, -3.395209]], dtype=float32)

time = 57424	action = 0	current_phase = 1	next_phase = 0	reward = -0.567796	array([[-2.1586878, -3.10058  ]], dtype=float32)

time = 57429	action = 0	current_phase = 1	next_phase = 0	reward = -0.415301	array([[-1.9347129, -3.1205716]], dtype=float32)

time = 57434	action = 0	current_phase = 1	next_phase = 0	reward = -0.264757	array([[-1.9001323, -3.088586 ]], dtype=float32)

time = 57439	action = 0	current_phase = 1	next_phase = 0	reward = -0.177759	array([[-1.9647603, -3.7988112]], dtype=float32)

time = 57444	action = 0	current_phase = 1	next_phase = 0	reward = -0.139867	array([[-2.2763736, -2.356793 ]], dtype=float32)

time = 57449	action = 1	current_phase = 1	next_phase = 0	reward = -2.025890	array([[-6.188653 , -3.5235677]], dtype=float32)

time = 57457	action = 0	current_phase = 0	next_phase = 1	reward = -0.477080	array([[-2.020066 , -3.2435694]], dtype=float32)

time = 57462	action = 0	current_phase = 0	next_phase = 1	reward = -0.320787	array([[-2.0774994, -3.0418072]], dtype=float32)

time = 57467	action = 0	current_phase = 0	next_phase = 1	reward = -0.182965	array([[-2.1580112, -3.0655951]], dtype=float32)

time = 57472	action = 0	current_phase = 0	next_phase = 1	reward = 0.190499	array([[-2.6650975, -4.3557687]], dtype=float32)

time = 57477	action = 1	current_phase = 0	next_phase = 1	reward = -1.782706	array([[-4.613518, -3.495249]], dtype=float32)

time = 57485	action = 0	current_phase = 1	next_phase = 0	reward = -0.530127	array([[-2.0783386, -3.242874 ]], dtype=float32)

time = 57490	action = 0	current_phase = 1	next_phase = 0	reward = -0.380289	array([[-1.9375024, -3.1232789]], dtype=float32)

time = 57495	action = 0	current_phase = 1	next_phase = 0	reward = -0.219353	array([[-1.8855778, -3.0864787]], dtype=float32)

time = 57500	action = 0	current_phase = 1	next_phase = 0	reward = 0.062078	array([[-2.002215 , -3.8641398]], dtype=float32)

time = 57505	action = 0	current_phase = 1	next_phase = 0	reward = -0.616986	array([[-2.6666057, -2.6712623]], dtype=float32)

time = 57510	action = 1	current_phase = 1	next_phase = 0	reward = -2.114111	array([[-6.187449 , -3.5234673]], dtype=float32)

time = 57518	action = 0	current_phase = 0	next_phase = 1	reward = -0.440889	array([[-2.0173945, -3.241679 ]], dtype=float32)

time = 57523	action = 0	current_phase = 0	next_phase = 1	reward = -0.293949	array([[-2.1047735, -3.1910114]], dtype=float32)

time = 57528	action = 0	current_phase = 0	next_phase = 1	reward = -0.171783	array([[-2.4329715, -3.2397017]], dtype=float32)

time = 57533	action = 0	current_phase = 0	next_phase = 1	reward = 0.056406	array([[-2.7172666, -4.383101 ]], dtype=float32)

time = 57538	action = 1	current_phase = 0	next_phase = 1	reward = -1.895465	array([[-5.001582 , -3.5736208]], dtype=float32)

time = 57546	action = 0	current_phase = 1	next_phase = 0	reward = -0.495532	array([[-2.0954733, -3.2421117]], dtype=float32)

time = 57551	action = 0	current_phase = 1	next_phase = 0	reward = -0.331535	array([[-1.9413812, -3.125858 ]], dtype=float32)

time = 57556	action = 0	current_phase = 1	next_phase = 0	reward = -0.184997	array([[-1.9434541, -3.1344724]], dtype=float32)

time = 57561	action = 0	current_phase = 1	next_phase = 0	reward = 0.291906	array([[-2.1838403, -4.134803 ]], dtype=float32)

time = 57566	action = 1	current_phase = 1	next_phase = 0	reward = -1.607382	array([[-5.6580253, -3.3020496]], dtype=float32)

time = 57574	action = 0	current_phase = 0	next_phase = 1	reward = -0.548642	array([[-2.1235714, -3.1050694]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0169 - val_loss: 0.0110

Epoch 2/50

 - 4s - loss: 0.0194 - val_loss: 0.0103

Epoch 3/50

 - 4s - loss: 0.0145 - val_loss: 0.0106

Epoch 4/50

 - 4s - loss: 0.0121 - val_loss: 0.0100

Epoch 5/50

 - 4s - loss: 0.0117 - val_loss: 0.0091

Epoch 6/50

 - 4s - loss: 0.0163 - val_loss: 0.0090

Epoch 7/50

 - 4s - loss: 0.0156 - val_loss: 0.0098

Epoch 8/50

 - 4s - loss: 0.0135 - val_loss: 0.0099

Epoch 9/50

 - 4s - loss: 0.0113 - val_loss: 0.0103

Epoch 10/50

 - 4s - loss: 0.0164 - val_loss: 0.0113

Epoch 11/50

 - 4s - loss: 0.0154 - val_loss: 0.0102

Epoch 12/50

 - 4s - loss: 0.0092 - val_loss: 0.0108

Epoch 13/50

 - 4s - loss: 0.0122 - val_loss: 0.0106

Epoch 14/50

 - 4s - loss: 0.0129 - val_loss: 0.0097

Epoch 15/50

 - 4s - loss: 0.0136 - val_loss: 0.0097

Epoch 16/50

 - 4s - loss: 0.0116 - val_loss: 0.0096

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1024, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 57579	action = 0	current_phase = 0	next_phase = 1	reward = -0.389778	array([[-1.9958704, -2.968024 ]], dtype=float32)

time = 57584	action = 0	current_phase = 0	next_phase = 1	reward = -0.244217	array([[-1.957602 , -3.3100202]], dtype=float32)

time = 57589	action = 0	current_phase = 0	next_phase = 1	reward = -0.185540	array([[-2.0543702, -3.0961506]], dtype=float32)

time = 57594	action = 1	current_phase = 0	next_phase = 1	reward = -0.543098	array([[-5.517853 , -2.1911678]], dtype=float32)

time = 57602	action = 0	current_phase = 1	next_phase = 0	reward = -0.626064	array([[-2.2795534, -3.0829704]], dtype=float32)

time = 57607	action = 0	current_phase = 1	next_phase = 0	reward = -0.475706	array([[-2.2135146, -3.0921915]], dtype=float32)

time = 57612	action = 0	current_phase = 1	next_phase = 0	reward = -0.324250	array([[-2.0740864, -3.1063964]], dtype=float32)

time = 57617	action = 0	current_phase = 1	next_phase = 0	reward = -0.177975	array([[-2.23779  , -3.2139487]], dtype=float32)

time = 57622	action = 0	current_phase = 1	next_phase = 0	reward = 0.205268	array([[-2.65549 , -4.303413]], dtype=float32)

time = 57627	action = 1	current_phase = 1	next_phase = 0	reward = -1.784818	array([[-6.194985 , -3.4592812]], dtype=float32)

time = 57635	action = 0	current_phase = 0	next_phase = 1	reward = -0.534532	array([[-2.1075366, -3.2545936]], dtype=float32)

time = 57640	action = 0	current_phase = 0	next_phase = 1	reward = -0.376786	array([[-1.9624448, -3.0101726]], dtype=float32)

time = 57645	action = 0	current_phase = 0	next_phase = 1	reward = -0.229997	array([[-1.9578063, -3.3103514]], dtype=float32)

time = 57650	action = 0	current_phase = 0	next_phase = 1	reward = 0.076054	array([[-2.19465  , -3.8075476]], dtype=float32)

time = 57655	action = 1	current_phase = 0	next_phase = 1	reward = -1.080885	array([[-5.125079 , -2.7873006]], dtype=float32)

time = 57663	action = 0	current_phase = 1	next_phase = 0	reward = -0.590960	array([[-2.280223 , -3.0827885]], dtype=float32)

time = 57668	action = 0	current_phase = 1	next_phase = 0	reward = -0.427530	array([[-2.0060723, -3.106477 ]], dtype=float32)

time = 57673	action = 0	current_phase = 1	next_phase = 0	reward = -0.267045	array([[-2.057637 , -3.1072533]], dtype=float32)

time = 57678	action = 0	current_phase = 1	next_phase = 0	reward = -0.161357	array([[-2.1785505, -3.3604715]], dtype=float32)

time = 57683	action = 0	current_phase = 1	next_phase = 0	reward = 0.060569	array([[-2.6656814, -4.161162 ]], dtype=float32)

time = 57688	action = 1	current_phase = 1	next_phase = 0	reward = -1.891778	array([[-6.1950307, -3.4588296]], dtype=float32)

time = 57696	action = 0	current_phase = 0	next_phase = 1	reward = -0.489223	array([[-2.0883033, -3.244629 ]], dtype=float32)

time = 57701	action = 0	current_phase = 0	next_phase = 1	reward = -0.332729	array([[-2.0961854, -2.906196 ]], dtype=float32)

time = 57706	action = 0	current_phase = 0	next_phase = 1	reward = -0.191206	array([[-2.0924492, -3.0433025]], dtype=float32)

time = 57711	action = 0	current_phase = 0	next_phase = 1	reward = 0.265928	array([[-2.549173 , -4.2662354]], dtype=float32)

time = 57716	action = 1	current_phase = 0	next_phase = 1	reward = -1.664298	array([[-4.52585  , -3.3540056]], dtype=float32)

time = 57724	action = 0	current_phase = 1	next_phase = 0	reward = -0.564150	array([[-2.2620928, -3.090789 ]], dtype=float32)

time = 57729	action = 0	current_phase = 1	next_phase = 0	reward = -0.412651	array([[-2.0023932, -3.105618 ]], dtype=float32)

time = 57734	action = 0	current_phase = 1	next_phase = 0	reward = -0.254691	array([[-1.9042047, -3.068946 ]], dtype=float32)

time = 57739	action = 0	current_phase = 1	next_phase = 0	reward = -0.170373	array([[-2.0427053, -3.7987883]], dtype=float32)

time = 57744	action = 1	current_phase = 1	next_phase = 0	reward = -0.439502	array([[-2.3818748, -2.2605329]], dtype=float32)

time = 57752	action = 0	current_phase = 0	next_phase = 1	reward = -0.623184	array([[-2.2770708, -3.7878358]], dtype=float32)

time = 57757	action = 0	current_phase = 0	next_phase = 1	reward = -0.461560	array([[-2.128404 , -2.8923614]], dtype=float32)

time = 57762	action = 0	current_phase = 0	next_phase = 1	reward = -0.303150	array([[-2.159262 , -3.1909504]], dtype=float32)

time = 57767	action = 0	current_phase = 0	next_phase = 1	reward = -0.166809	array([[-2.4182098, -3.2733057]], dtype=float32)

time = 57772	action = 0	current_phase = 0	next_phase = 1	reward = 0.130994	array([[-2.6798313, -4.376698 ]], dtype=float32)

time = 57777	action = 1	current_phase = 0	next_phase = 1	reward = -1.789258	array([[-6.5489283, -3.5441718]], dtype=float32)

time = 57785	action = 0	current_phase = 1	next_phase = 0	reward = -0.532961	array([[-2.097733, -3.228785]], dtype=float32)

time = 57790	action = 0	current_phase = 1	next_phase = 0	reward = -0.391549	array([[-2.015611 , -3.1197116]], dtype=float32)

time = 57795	action = 0	current_phase = 1	next_phase = 0	reward = -0.237244	array([[-1.9027581, -3.0686326]], dtype=float32)

time = 57800	action = 0	current_phase = 1	next_phase = 0	reward = 0.067690	array([[-2.0915625, -3.8658512]], dtype=float32)

time = 57805	action = 1	current_phase = 1	next_phase = 0	reward = -1.024719	array([[-2.7414217, -2.6887617]], dtype=float32)

time = 57813	action = 0	current_phase = 0	next_phase = 1	reward = -0.590317	array([[-2.2794745, -3.7842507]], dtype=float32)

time = 57818	action = 0	current_phase = 0	next_phase = 1	reward = -0.440032	array([[-2.1214182, -2.892471 ]], dtype=float32)

time = 57823	action = 0	current_phase = 0	next_phase = 1	reward = -0.280430	array([[-2.159088 , -3.1910686]], dtype=float32)

time = 57828	action = 0	current_phase = 0	next_phase = 1	reward = -0.163924	array([[-2.435588 , -3.2784538]], dtype=float32)

time = 57833	action = 0	current_phase = 0	next_phase = 1	reward = -0.053497	array([[-2.6710892, -4.3242803]], dtype=float32)

time = 57838	action = 1	current_phase = 0	next_phase = 1	reward = -1.906367	array([[-6.5555296, -3.546274 ]], dtype=float32)

time = 57846	action = 0	current_phase = 1	next_phase = 0	reward = -0.502474	array([[-2.0970552, -3.2334383]], dtype=float32)

time = 57851	action = 0	current_phase = 1	next_phase = 0	reward = -0.347796	array([[-2.0033028, -3.1066625]], dtype=float32)

time = 57856	action = 0	current_phase = 1	next_phase = 0	reward = -0.194431	array([[-2.017082 , -3.1246898]], dtype=float32)

time = 57861	action = 0	current_phase = 1	next_phase = 0	reward = 0.291540	array([[-2.3248687, -4.1745896]], dtype=float32)

time = 57866	action = 1	current_phase = 1	next_phase = 0	reward = -1.609417	array([[-5.674891, -3.265769]], dtype=float32)

time = 57874	action = 0	current_phase = 0	next_phase = 1	reward = -0.552502	array([[-2.1836805, -3.113006 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0172 - val_loss: 0.0068

Epoch 2/50

 - 4s - loss: 0.0155 - val_loss: 0.0056

Epoch 3/50

 - 4s - loss: 0.0127 - val_loss: 0.0061

Epoch 4/50

 - 4s - loss: 0.0107 - val_loss: 0.0060

Epoch 5/50

 - 4s - loss: 0.0106 - val_loss: 0.0056

Epoch 6/50

 - 4s - loss: 0.0111 - val_loss: 0.0066

Epoch 7/50

 - 4s - loss: 0.0098 - val_loss: 0.0075

Epoch 8/50

 - 4s - loss: 0.0124 - val_loss: 0.0067

Epoch 9/50

 - 4s - loss: 0.0100 - val_loss: 0.0065

Epoch 10/50

 - 4s - loss: 0.0126 - val_loss: 0.0075

Epoch 11/50

 - 4s - loss: 0.0093 - val_loss: 0.0069

Epoch 12/50

 - 4s - loss: 0.0087 - val_loss: 0.0070

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 57879	action = 0	current_phase = 0	next_phase = 1	reward = -0.399828	array([[-1.9479768, -3.0096161]], dtype=float32)

time = 57884	action = 0	current_phase = 0	next_phase = 1	reward = -0.260098	array([[-1.979167 , -3.2896771]], dtype=float32)

time = 57889	action = 0	current_phase = 0	next_phase = 1	reward = -0.177934	array([[-2.0577085, -3.1112065]], dtype=float32)

time = 57894	action = 1	current_phase = 0	next_phase = 1	reward = -0.547910	array([[-5.555748 , -2.2410715]], dtype=float32)

time = 57902	action = 0	current_phase = 1	next_phase = 0	reward = -0.616314	array([[-2.1921573, -3.0882823]], dtype=float32)

time = 57907	action = 0	current_phase = 1	next_phase = 0	reward = -0.465659	array([[-2.0404775, -3.1080792]], dtype=float32)

time = 57912	action = 0	current_phase = 1	next_phase = 0	reward = -0.317981	array([[-2.0088165, -3.1155846]], dtype=float32)

time = 57917	action = 0	current_phase = 1	next_phase = 0	reward = -0.181043	array([[-2.1803384, -3.2198174]], dtype=float32)

time = 57922	action = 0	current_phase = 1	next_phase = 0	reward = 0.138062	array([[-2.5841835, -4.302486 ]], dtype=float32)

time = 57927	action = 1	current_phase = 1	next_phase = 0	reward = -1.784588	array([[-6.1928954, -3.5042157]], dtype=float32)

time = 57935	action = 0	current_phase = 0	next_phase = 1	reward = -0.526844	array([[-2.105054 , -3.2546782]], dtype=float32)

time = 57940	action = 0	current_phase = 0	next_phase = 1	reward = -0.372999	array([[-1.9486582, -3.0083387]], dtype=float32)

time = 57945	action = 0	current_phase = 0	next_phase = 1	reward = -0.221120	array([[-1.9484272, -3.3178968]], dtype=float32)

time = 57950	action = 0	current_phase = 0	next_phase = 1	reward = 0.357512	array([[-2.2113152, -3.8104227]], dtype=float32)

time = 57955	action = 1	current_phase = 0	next_phase = 1	reward = -1.309729	array([[-4.7546988, -3.0665588]], dtype=float32)

time = 57963	action = 0	current_phase = 1	next_phase = 0	reward = -0.590403	array([[-2.1542246, -3.0991683]], dtype=float32)

time = 57968	action = 0	current_phase = 1	next_phase = 0	reward = -0.442409	array([[-1.9933417, -3.127253 ]], dtype=float32)

time = 57973	action = 0	current_phase = 1	next_phase = 0	reward = -0.291022	array([[-2.0055122, -3.1139581]], dtype=float32)

time = 57978	action = 0	current_phase = 1	next_phase = 0	reward = -0.164739	array([[-2.1646383, -3.2238314]], dtype=float32)

time = 57983	action = 0	current_phase = 1	next_phase = 0	reward = 0.083794	array([[-2.5675838, -4.24856  ]], dtype=float32)

time = 57988	action = 1	current_phase = 1	next_phase = 0	reward = -1.896424	array([[-6.193053 , -3.4863698]], dtype=float32)

time = 57996	action = 0	current_phase = 0	next_phase = 1	reward = -0.500269	array([[-2.0699787, -3.2478142]], dtype=float32)

time = 58001	action = 0	current_phase = 0	next_phase = 1	reward = -0.345190	array([[-1.9578092, -2.9938939]], dtype=float32)

time = 58006	action = 0	current_phase = 0	next_phase = 1	reward = -0.190855	array([[-2.1179094, -3.0593781]], dtype=float32)

time = 58011	action = 0	current_phase = 0	next_phase = 1	reward = 0.287742	array([[-2.3948424, -4.1686997]], dtype=float32)

time = 58016	action = 1	current_phase = 0	next_phase = 1	reward = -1.610259	array([[-4.4585905, -3.320155 ]], dtype=float32)

time = 58024	action = 0	current_phase = 1	next_phase = 0	reward = -0.557959	array([[-2.046691 , -3.1146052]], dtype=float32)

time = 58029	action = 0	current_phase = 1	next_phase = 0	reward = -0.402796	array([[-1.9205444, -3.1097012]], dtype=float32)

time = 58034	action = 0	current_phase = 1	next_phase = 0	reward = -0.250283	array([[-1.8298845, -3.0786333]], dtype=float32)

time = 58039	action = 0	current_phase = 1	next_phase = 0	reward = -0.182255	array([[-1.9962192, -3.8099802]], dtype=float32)

time = 58044	action = 1	current_phase = 1	next_phase = 0	reward = -0.499015	array([[-2.3428388, -2.255451 ]], dtype=float32)

time = 58052	action = 0	current_phase = 0	next_phase = 1	reward = -0.612760	array([[-2.2664247, -3.7762508]], dtype=float32)

time = 58057	action = 0	current_phase = 0	next_phase = 1	reward = -0.462621	array([[-2.1102004, -2.8918693]], dtype=float32)

time = 58062	action = 0	current_phase = 0	next_phase = 1	reward = -0.314961	array([[-2.169016 , -3.1986177]], dtype=float32)

time = 58067	action = 0	current_phase = 0	next_phase = 1	reward = -0.182139	array([[-2.3591318, -3.2531233]], dtype=float32)

time = 58072	action = 0	current_phase = 0	next_phase = 1	reward = 0.206476	array([[-2.6916566, -4.457246 ]], dtype=float32)

time = 58077	action = 1	current_phase = 0	next_phase = 1	reward = -1.790341	array([[-6.450971, -3.504874]], dtype=float32)

time = 58085	action = 0	current_phase = 1	next_phase = 0	reward = -0.540441	array([[-2.0386875, -3.2420657]], dtype=float32)

time = 58090	action = 0	current_phase = 1	next_phase = 0	reward = -0.391291	array([[-1.9384358, -3.1280265]], dtype=float32)

time = 58095	action = 0	current_phase = 1	next_phase = 0	reward = -0.239979	array([[-1.8237958, -3.0763166]], dtype=float32)

time = 58100	action = 0	current_phase = 1	next_phase = 0	reward = -0.207915	array([[-2.1808865, -4.0659723]], dtype=float32)

time = 58105	action = 1	current_phase = 1	next_phase = 0	reward = -0.741047	array([[-2.3454802, -2.257268 ]], dtype=float32)

time = 58113	action = 0	current_phase = 0	next_phase = 1	reward = -0.597771	array([[-2.2667656, -3.7621808]], dtype=float32)

time = 58118	action = 0	current_phase = 0	next_phase = 1	reward = -0.441488	array([[-2.0445738, -2.978733 ]], dtype=float32)

time = 58123	action = 0	current_phase = 0	next_phase = 1	reward = -0.277916	array([[-2.171501 , -3.1986358]], dtype=float32)

time = 58128	action = 0	current_phase = 0	next_phase = 1	reward = -0.161038	array([[-2.3971813, -3.2853124]], dtype=float32)

time = 58133	action = 0	current_phase = 0	next_phase = 1	reward = 0.075240	array([[-2.6955986, -4.4311767]], dtype=float32)

time = 58138	action = 1	current_phase = 0	next_phase = 1	reward = -1.895771	array([[-6.565902 , -3.5674849]], dtype=float32)

time = 58146	action = 0	current_phase = 1	next_phase = 0	reward = -0.496968	array([[-2.041192, -3.238106]], dtype=float32)

time = 58151	action = 0	current_phase = 1	next_phase = 0	reward = -0.348245	array([[-1.9276279, -3.1107547]], dtype=float32)

time = 58156	action = 0	current_phase = 1	next_phase = 0	reward = -0.204326	array([[-1.9217515, -3.1134765]], dtype=float32)

time = 58161	action = 0	current_phase = 1	next_phase = 0	reward = 0.302923	array([[-2.263037 , -4.1809883]], dtype=float32)

time = 58166	action = 1	current_phase = 1	next_phase = 0	reward = -1.553512	array([[-3.1604273, -3.1447725]], dtype=float32)

time = 58174	action = 0	current_phase = 0	next_phase = 1	reward = -0.558514	array([[-2.1522996, -3.109737 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0134 - val_loss: 0.0046

Epoch 2/50

 - 4s - loss: 0.0198 - val_loss: 0.0054

Epoch 3/50

 - 4s - loss: 0.0150 - val_loss: 0.0064

Epoch 4/50

 - 4s - loss: 0.0168 - val_loss: 0.0078

Epoch 5/50

 - 4s - loss: 0.0138 - val_loss: 0.0067

Epoch 6/50

 - 4s - loss: 0.0127 - val_loss: 0.0069

Epoch 7/50

 - 4s - loss: 0.0150 - val_loss: 0.0076

Epoch 8/50

 - 4s - loss: 0.0139 - val_loss: 0.0072

Epoch 9/50

 - 4s - loss: 0.0149 - val_loss: 0.0069

Epoch 10/50

 - 4s - loss: 0.0143 - val_loss: 0.0078

Epoch 11/50

 - 4s - loss: 0.0131 - val_loss: 0.0076

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 58179	action = 0	current_phase = 0	next_phase = 1	reward = -0.405279	array([[-1.9371346, -3.010844 ]], dtype=float32)

time = 58184	action = 0	current_phase = 0	next_phase = 1	reward = -0.245756	array([[-2.0251057, -3.2471972]], dtype=float32)

time = 58189	action = 0	current_phase = 0	next_phase = 1	reward = -0.183358	array([[-1.9793035, -3.1211884]], dtype=float32)

time = 58194	action = 1	current_phase = 0	next_phase = 1	reward = -0.576396	array([[-5.570172 , -2.2116387]], dtype=float32)

time = 58202	action = 0	current_phase = 1	next_phase = 0	reward = -0.619241	array([[-2.2356243, -3.100637 ]], dtype=float32)

time = 58207	action = 0	current_phase = 1	next_phase = 0	reward = -0.465429	array([[-2.206664 , -3.0958166]], dtype=float32)

time = 58212	action = 0	current_phase = 1	next_phase = 0	reward = -0.322673	array([[-2.0392656, -3.1177397]], dtype=float32)

time = 58217	action = 0	current_phase = 1	next_phase = 0	reward = -0.185740	array([[-2.1910605, -3.222399 ]], dtype=float32)

time = 58222	action = 0	current_phase = 1	next_phase = 0	reward = 0.199966	array([[-2.625815, -4.322151]], dtype=float32)

time = 58227	action = 1	current_phase = 1	next_phase = 0	reward = -1.725721	array([[-6.1753564, -3.4848766]], dtype=float32)

time = 58235	action = 0	current_phase = 0	next_phase = 1	reward = -0.523106	array([[-2.094764 , -3.2609174]], dtype=float32)

time = 58240	action = 0	current_phase = 0	next_phase = 1	reward = -0.369393	array([[-1.9367611, -3.011632 ]], dtype=float32)

time = 58245	action = 0	current_phase = 0	next_phase = 1	reward = -0.216778	array([[-1.9279141, -3.3127513]], dtype=float32)

time = 58250	action = 0	current_phase = 0	next_phase = 1	reward = 0.352190	array([[-2.1587932, -3.8657207]], dtype=float32)

time = 58255	action = 1	current_phase = 0	next_phase = 1	reward = -1.367214	array([[-4.647174 , -3.1291897]], dtype=float32)

time = 58263	action = 0	current_phase = 1	next_phase = 0	reward = -0.595058	array([[-2.1973777, -3.098274 ]], dtype=float32)

time = 58268	action = 0	current_phase = 1	next_phase = 0	reward = -0.446005	array([[-2.0043936, -3.1244352]], dtype=float32)

time = 58273	action = 0	current_phase = 1	next_phase = 0	reward = -0.294548	array([[-2.0289335, -3.1088724]], dtype=float32)

time = 58278	action = 0	current_phase = 1	next_phase = 0	reward = -0.169843	array([[-2.1769934, -3.2201033]], dtype=float32)

time = 58283	action = 0	current_phase = 1	next_phase = 0	reward = 0.074276	array([[-2.643355, -4.236214]], dtype=float32)

time = 58288	action = 1	current_phase = 1	next_phase = 0	reward = -1.899912	array([[-6.1725   , -3.4785051]], dtype=float32)

time = 58296	action = 0	current_phase = 0	next_phase = 1	reward = -0.504525	array([[-2.0748618, -3.2552128]], dtype=float32)

time = 58301	action = 0	current_phase = 0	next_phase = 1	reward = -0.352062	array([[-1.9368622, -3.0114417]], dtype=float32)

time = 58306	action = 0	current_phase = 0	next_phase = 1	reward = -0.200930	array([[-2.0968099, -3.0524967]], dtype=float32)

time = 58311	action = 0	current_phase = 0	next_phase = 1	reward = 0.315623	array([[-2.1945527, -3.9610367]], dtype=float32)

time = 58316	action = 1	current_phase = 0	next_phase = 1	reward = -1.553081	array([[-4.499809 , -3.2810712]], dtype=float32)

time = 58324	action = 0	current_phase = 1	next_phase = 0	reward = -0.553342	array([[-2.1856236, -3.100266 ]], dtype=float32)

time = 58329	action = 0	current_phase = 1	next_phase = 0	reward = -0.383178	array([[-1.9382389, -3.1085978]], dtype=float32)

time = 58334	action = 0	current_phase = 1	next_phase = 0	reward = -0.231098	array([[-1.8569831, -3.0730076]], dtype=float32)

time = 58339	action = 0	current_phase = 1	next_phase = 0	reward = -0.180242	array([[-1.9617637, -3.8267415]], dtype=float32)

time = 58344	action = 1	current_phase = 1	next_phase = 0	reward = -0.542297	array([[-2.2990427, -2.23554  ]], dtype=float32)

time = 58352	action = 0	current_phase = 0	next_phase = 1	reward = -0.619003	array([[-2.241695 , -3.7686944]], dtype=float32)

time = 58357	action = 0	current_phase = 0	next_phase = 1	reward = -0.465054	array([[-2.0955   , -2.8941426]], dtype=float32)

time = 58362	action = 0	current_phase = 0	next_phase = 1	reward = -0.322607	array([[-2.1586244, -3.1918526]], dtype=float32)

time = 58367	action = 0	current_phase = 0	next_phase = 1	reward = -0.189899	array([[-2.3189762, -3.2590215]], dtype=float32)

time = 58372	action = 0	current_phase = 0	next_phase = 1	reward = 0.199964	array([[-2.6363606, -4.439899 ]], dtype=float32)

time = 58377	action = 1	current_phase = 0	next_phase = 1	reward = -1.726426	array([[-6.403503, -3.456315]], dtype=float32)

time = 58385	action = 0	current_phase = 1	next_phase = 0	reward = -0.520476	array([[-2.062859, -3.240616]], dtype=float32)

time = 58390	action = 0	current_phase = 1	next_phase = 0	reward = -0.368146	array([[-1.9516047, -3.1202812]], dtype=float32)

time = 58395	action = 0	current_phase = 1	next_phase = 0	reward = -0.214511	array([[-1.8510934, -3.071355 ]], dtype=float32)

time = 58400	action = 0	current_phase = 1	next_phase = 0	reward = 0.046098	array([[-2.0420556, -3.8767776]], dtype=float32)

time = 58405	action = 0	current_phase = 1	next_phase = 0	reward = -0.515546	array([[-2.5879283, -2.6539183]], dtype=float32)

time = 58410	action = 1	current_phase = 1	next_phase = 0	reward = -2.100304	array([[-6.1996403, -3.5085638]], dtype=float32)

time = 58418	action = 0	current_phase = 0	next_phase = 1	reward = -0.426395	array([[-2.0684211, -3.2541516]], dtype=float32)

time = 58423	action = 0	current_phase = 0	next_phase = 1	reward = -0.278846	array([[-2.1555715, -3.1941168]], dtype=float32)

time = 58428	action = 0	current_phase = 0	next_phase = 1	reward = -0.161433	array([[-2.3314242, -3.2710948]], dtype=float32)

time = 58433	action = 0	current_phase = 0	next_phase = 1	reward = -0.000562	array([[-2.9041   , -4.4051104]], dtype=float32)

time = 58438	action = 1	current_phase = 0	next_phase = 1	reward = -1.895508	array([[-5.048117 , -3.5927184]], dtype=float32)

time = 58446	action = 0	current_phase = 1	next_phase = 0	reward = -0.493814	array([[-2.0907474, -3.2418902]], dtype=float32)

time = 58451	action = 0	current_phase = 1	next_phase = 0	reward = -0.338619	array([[-1.9393102, -3.1091168]], dtype=float32)

time = 58456	action = 0	current_phase = 1	next_phase = 0	reward = -0.198846	array([[-1.9437904, -3.119679 ]], dtype=float32)

time = 58461	action = 0	current_phase = 1	next_phase = 0	reward = 0.323727	array([[-2.268847 , -4.1769834]], dtype=float32)

time = 58466	action = 1	current_phase = 1	next_phase = 0	reward = -1.608854	array([[-5.658278 , -3.2904508]], dtype=float32)

time = 58474	action = 0	current_phase = 0	next_phase = 1	reward = -0.553001	array([[-2.1614547, -3.1112792]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0120 - val_loss: 0.0055

Epoch 2/50

 - 4s - loss: 0.0102 - val_loss: 0.0059

Epoch 3/50

 - 4s - loss: 0.0141 - val_loss: 0.0072

Epoch 4/50

 - 4s - loss: 0.0091 - val_loss: 0.0064

Epoch 5/50

 - 4s - loss: 0.0074 - val_loss: 0.0065

Epoch 6/50

 - 4s - loss: 0.0070 - val_loss: 0.0067

Epoch 7/50

 - 4s - loss: 0.0096 - val_loss: 0.0064

Epoch 8/50

 - 4s - loss: 0.0084 - val_loss: 0.0064

Epoch 9/50

 - 4s - loss: 0.0080 - val_loss: 0.0063

Epoch 10/50

 - 4s - loss: 0.0097 - val_loss: 0.0070

Epoch 11/50

 - 4s - loss: 0.0109 - val_loss: 0.0067

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 58479	action = 0	current_phase = 0	next_phase = 1	reward = -0.398282	array([[-1.9784846, -3.0381494]], dtype=float32)

time = 58484	action = 0	current_phase = 0	next_phase = 1	reward = -0.248444	array([[-2.150482 , -3.2069063]], dtype=float32)

time = 58489	action = 0	current_phase = 0	next_phase = 1	reward = -0.185415	array([[-2.032184 , -3.1277268]], dtype=float32)

time = 58494	action = 1	current_phase = 0	next_phase = 1	reward = -0.610818	array([[-5.5856824, -2.2624373]], dtype=float32)

time = 58502	action = 0	current_phase = 1	next_phase = 0	reward = -0.613096	array([[-2.2651854, -3.11927  ]], dtype=float32)

time = 58507	action = 0	current_phase = 1	next_phase = 0	reward = -0.458345	array([[-2.1316555, -3.129612 ]], dtype=float32)

time = 58512	action = 0	current_phase = 1	next_phase = 0	reward = -0.308529	array([[-2.1233928, -3.1389909]], dtype=float32)

time = 58517	action = 0	current_phase = 1	next_phase = 0	reward = -0.180447	array([[-2.239761 , -3.2573621]], dtype=float32)

time = 58522	action = 0	current_phase = 1	next_phase = 0	reward = 0.201598	array([[-2.7086701, -4.3377814]], dtype=float32)

time = 58527	action = 1	current_phase = 1	next_phase = 0	reward = -1.788037	array([[-6.2161927, -3.5189798]], dtype=float32)

time = 58535	action = 0	current_phase = 0	next_phase = 1	reward = -0.541293	array([[-2.0939035, -3.2846258]], dtype=float32)

time = 58540	action = 0	current_phase = 0	next_phase = 1	reward = -0.392613	array([[-1.9781942, -3.0387046]], dtype=float32)

time = 58545	action = 0	current_phase = 0	next_phase = 1	reward = -0.235100	array([[-1.936589 , -3.3291254]], dtype=float32)

time = 58550	action = 0	current_phase = 0	next_phase = 1	reward = 0.087015	array([[-2.1803346, -3.8952904]], dtype=float32)

time = 58555	action = 1	current_phase = 0	next_phase = 1	reward = -0.965158	array([[-5.3711805, -2.5749545]], dtype=float32)

time = 58563	action = 0	current_phase = 1	next_phase = 0	reward = -0.583123	array([[-2.2525654, -3.1236749]], dtype=float32)

time = 58568	action = 0	current_phase = 1	next_phase = 0	reward = -0.429550	array([[-2.0196457, -3.1381154]], dtype=float32)

time = 58573	action = 0	current_phase = 1	next_phase = 0	reward = -0.272470	array([[-2.0721662, -3.1384814]], dtype=float32)

time = 58578	action = 0	current_phase = 1	next_phase = 0	reward = -0.167376	array([[-2.2277374, -3.2572308]], dtype=float32)

time = 58583	action = 0	current_phase = 1	next_phase = 0	reward = -0.062842	array([[-2.7070482, -3.0832763]], dtype=float32)

time = 58588	action = 1	current_phase = 1	next_phase = 0	reward = -1.903974	array([[-6.238726, -3.542726]], dtype=float32)

time = 58596	action = 0	current_phase = 0	next_phase = 1	reward = -0.494783	array([[-2.0880728, -3.2797613]], dtype=float32)

time = 58601	action = 0	current_phase = 0	next_phase = 1	reward = -0.342337	array([[-1.9909763, -3.0185804]], dtype=float32)

time = 58606	action = 0	current_phase = 0	next_phase = 1	reward = -0.200756	array([[-2.121223 , -3.0676818]], dtype=float32)

time = 58611	action = 0	current_phase = 0	next_phase = 1	reward = 0.322066	array([[-2.3105054, -4.1725216]], dtype=float32)

time = 58616	action = 1	current_phase = 0	next_phase = 1	reward = -1.605486	array([[-4.464797, -3.301136]], dtype=float32)

time = 58624	action = 0	current_phase = 1	next_phase = 0	reward = -0.554921	array([[-2.2152767, -3.1297004]], dtype=float32)

time = 58629	action = 0	current_phase = 1	next_phase = 0	reward = -0.394454	array([[-1.9883667, -3.1306207]], dtype=float32)

time = 58634	action = 0	current_phase = 1	next_phase = 0	reward = -0.246998	array([[-1.8878956, -3.0852516]], dtype=float32)

time = 58639	action = 0	current_phase = 1	next_phase = 0	reward = -0.178818	array([[-2.0768301, -3.8424466]], dtype=float32)

time = 58644	action = 1	current_phase = 1	next_phase = 0	reward = -0.450913	array([[-2.3239882, -2.260368 ]], dtype=float32)

time = 58652	action = 0	current_phase = 0	next_phase = 1	reward = -0.620801	array([[-2.2539217, -3.7989116]], dtype=float32)

time = 58657	action = 0	current_phase = 0	next_phase = 1	reward = -0.474159	array([[-2.138837 , -2.9214525]], dtype=float32)

time = 58662	action = 0	current_phase = 0	next_phase = 1	reward = -0.323843	array([[-2.17047  , -3.1986551]], dtype=float32)

time = 58667	action = 0	current_phase = 0	next_phase = 1	reward = -0.179106	array([[-2.3456922, -3.2555828]], dtype=float32)

time = 58672	action = 0	current_phase = 0	next_phase = 1	reward = 0.240040	array([[-2.5941696, -4.4585953]], dtype=float32)

time = 58677	action = 1	current_phase = 0	next_phase = 1	reward = -1.783813	array([[-6.1625185, -3.3962529]], dtype=float32)

time = 58685	action = 0	current_phase = 1	next_phase = 0	reward = -0.527850	array([[-2.1177588, -3.2691739]], dtype=float32)

time = 58690	action = 0	current_phase = 1	next_phase = 0	reward = -0.376187	array([[-1.9899738, -3.1322505]], dtype=float32)

time = 58695	action = 0	current_phase = 1	next_phase = 0	reward = -0.220243	array([[-1.8880008, -3.0852308]], dtype=float32)

time = 58700	action = 0	current_phase = 1	next_phase = 0	reward = 0.355201	array([[-2.1305609, -3.8957634]], dtype=float32)

time = 58705	action = 1	current_phase = 1	next_phase = 0	reward = -1.313147	array([[-3.0755696, -3.010739 ]], dtype=float32)

time = 58713	action = 0	current_phase = 0	next_phase = 1	reward = -0.589283	array([[-2.2546997, -3.7948015]], dtype=float32)

time = 58718	action = 0	current_phase = 0	next_phase = 1	reward = -0.439632	array([[-2.1340046, -2.9171698]], dtype=float32)

time = 58723	action = 0	current_phase = 0	next_phase = 1	reward = -0.286147	array([[-2.1714494, -3.1996503]], dtype=float32)

time = 58728	action = 0	current_phase = 0	next_phase = 1	reward = -0.167854	array([[-2.3822942, -3.2886302]], dtype=float32)

time = 58733	action = 0	current_phase = 0	next_phase = 1	reward = 0.010116	array([[-2.6176488, -4.474089 ]], dtype=float32)

time = 58738	action = 1	current_phase = 0	next_phase = 1	reward = -1.905401	array([[-6.543474, -3.55219 ]], dtype=float32)

time = 58746	action = 0	current_phase = 1	next_phase = 0	reward = -0.510096	array([[-2.115965, -3.270329]], dtype=float32)

time = 58751	action = 0	current_phase = 1	next_phase = 0	reward = -0.366604	array([[-1.9905005, -3.1317108]], dtype=float32)

time = 58756	action = 0	current_phase = 1	next_phase = 0	reward = -0.211394	array([[-2.0005322, -3.1470416]], dtype=float32)

time = 58761	action = 0	current_phase = 1	next_phase = 0	reward = 0.337121	array([[-2.3052673, -4.157351 ]], dtype=float32)

time = 58766	action = 1	current_phase = 1	next_phase = 0	reward = -1.452577	array([[-5.6637883, -3.251988 ]], dtype=float32)

time = 58774	action = 0	current_phase = 0	next_phase = 1	reward = -0.557717	array([[-2.1713648, -3.1337209]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0135 - val_loss: 0.0044

Epoch 2/50

 - 4s - loss: 0.0109 - val_loss: 0.0045

Epoch 3/50

 - 4s - loss: 0.0091 - val_loss: 0.0047

Epoch 4/50

 - 4s - loss: 0.0088 - val_loss: 0.0045

Epoch 5/50

 - 4s - loss: 0.0119 - val_loss: 0.0044

Epoch 6/50

 - 4s - loss: 0.0082 - val_loss: 0.0046

Epoch 7/50

 - 4s - loss: 0.0107 - val_loss: 0.0045

Epoch 8/50

 - 4s - loss: 0.0079 - val_loss: 0.0047

Epoch 9/50

 - 4s - loss: 0.0090 - val_loss: 0.0046

Epoch 10/50

 - 4s - loss: 0.0085 - val_loss: 0.0046

Epoch 11/50

 - 4s - loss: 0.0070 - val_loss: 0.0046

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 58779	action = 0	current_phase = 0	next_phase = 1	reward = -0.403076	array([[-1.9649076, -3.0352106]], dtype=float32)

time = 58784	action = 0	current_phase = 0	next_phase = 1	reward = -0.246318	array([[-2.1091986, -3.2395327]], dtype=float32)

time = 58789	action = 0	current_phase = 0	next_phase = 1	reward = -0.165892	array([[-2.0422096, -3.197861 ]], dtype=float32)

time = 58794	action = 1	current_phase = 0	next_phase = 1	reward = -0.366289	array([[-5.575171 , -2.2679682]], dtype=float32)

time = 58802	action = 0	current_phase = 1	next_phase = 0	reward = -0.613216	array([[-2.221766, -3.107629]], dtype=float32)

time = 58807	action = 0	current_phase = 1	next_phase = 0	reward = -0.458099	array([[-2.065176 , -3.1198847]], dtype=float32)

time = 58812	action = 0	current_phase = 1	next_phase = 0	reward = -0.309464	array([[-2.0752957, -3.1340196]], dtype=float32)

time = 58817	action = 0	current_phase = 1	next_phase = 0	reward = -0.174334	array([[-2.2023146, -3.2479343]], dtype=float32)

time = 58822	action = 0	current_phase = 1	next_phase = 0	reward = 0.120281	array([[-2.5865364, -4.3243904]], dtype=float32)

time = 58827	action = 1	current_phase = 1	next_phase = 0	reward = -1.791767	array([[-6.1732492, -3.47892  ]], dtype=float32)

time = 58835	action = 0	current_phase = 0	next_phase = 1	reward = -0.541084	array([[-2.119486 , -3.2926228]], dtype=float32)

time = 58840	action = 0	current_phase = 0	next_phase = 1	reward = -0.369105	array([[-1.9616176, -3.042066 ]], dtype=float32)

time = 58845	action = 0	current_phase = 0	next_phase = 1	reward = -0.213581	array([[-1.947988 , -3.3351235]], dtype=float32)

time = 58850	action = 0	current_phase = 0	next_phase = 1	reward = 0.359440	array([[-2.1941798, -3.9365003]], dtype=float32)

time = 58855	action = 1	current_phase = 0	next_phase = 1	reward = -1.303349	array([[-4.6922526, -3.1130435]], dtype=float32)

time = 58863	action = 0	current_phase = 1	next_phase = 0	reward = -0.585135	array([[-2.2070906, -3.1117933]], dtype=float32)

time = 58868	action = 0	current_phase = 1	next_phase = 0	reward = -0.427433	array([[-1.9338439, -3.121294 ]], dtype=float32)

time = 58873	action = 0	current_phase = 1	next_phase = 0	reward = -0.265434	array([[-1.999884 , -3.1259928]], dtype=float32)

time = 58878	action = 0	current_phase = 1	next_phase = 0	reward = -0.165656	array([[-2.1928663, -3.2561913]], dtype=float32)

time = 58883	action = 0	current_phase = 1	next_phase = 0	reward = 0.056045	array([[-2.6620743, -4.298459 ]], dtype=float32)

time = 58888	action = 1	current_phase = 1	next_phase = 0	reward = -1.899996	array([[-6.2416205, -3.5038464]], dtype=float32)

time = 58896	action = 0	current_phase = 0	next_phase = 1	reward = -0.495868	array([[-2.0895302, -3.2902954]], dtype=float32)

time = 58901	action = 0	current_phase = 0	next_phase = 1	reward = -0.336456	array([[-1.9701496, -3.0261176]], dtype=float32)

time = 58906	action = 0	current_phase = 0	next_phase = 1	reward = -0.189465	array([[-2.135664 , -3.0738273]], dtype=float32)

time = 58911	action = 0	current_phase = 0	next_phase = 1	reward = 0.311462	array([[-2.3726783, -4.2410398]], dtype=float32)

time = 58916	action = 1	current_phase = 0	next_phase = 1	reward = -1.608097	array([[-4.500783, -3.26117 ]], dtype=float32)

time = 58924	action = 0	current_phase = 1	next_phase = 0	reward = -0.555100	array([[-2.1434255, -3.1242769]], dtype=float32)

time = 58929	action = 0	current_phase = 1	next_phase = 0	reward = -0.399120	array([[-1.933722 , -3.1215165]], dtype=float32)

time = 58934	action = 0	current_phase = 1	next_phase = 0	reward = -0.251569	array([[-1.8228216, -3.0787709]], dtype=float32)

time = 58939	action = 0	current_phase = 1	next_phase = 0	reward = 0.112233	array([[-1.9785534, -3.8579159]], dtype=float32)

time = 58944	action = 1	current_phase = 1	next_phase = 0	reward = -0.719056	array([[-2.562232 , -2.5051804]], dtype=float32)

time = 58952	action = 0	current_phase = 0	next_phase = 1	reward = -0.620673	array([[-2.277731, -3.80715 ]], dtype=float32)

time = 58957	action = 0	current_phase = 0	next_phase = 1	reward = -0.470502	array([[-2.1086576, -2.9254296]], dtype=float32)

time = 58962	action = 0	current_phase = 0	next_phase = 1	reward = -0.313978	array([[-2.1821842, -3.2111073]], dtype=float32)

time = 58967	action = 0	current_phase = 0	next_phase = 1	reward = -0.180301	array([[-2.3921955, -3.3080945]], dtype=float32)

time = 58972	action = 0	current_phase = 0	next_phase = 1	reward = 0.252634	array([[-2.682091 , -4.5181775]], dtype=float32)

time = 58977	action = 1	current_phase = 0	next_phase = 1	reward = -1.784466	array([[-6.136447, -3.416674]], dtype=float32)

time = 58985	action = 0	current_phase = 1	next_phase = 0	reward = -0.532443	array([[-2.0561445, -3.2623663]], dtype=float32)

time = 58990	action = 0	current_phase = 1	next_phase = 0	reward = -0.374060	array([[-1.9354007, -3.1241813]], dtype=float32)

time = 58995	action = 0	current_phase = 1	next_phase = 0	reward = -0.220721	array([[-1.8223679, -3.081473 ]], dtype=float32)

time = 59000	action = 0	current_phase = 1	next_phase = 0	reward = 0.363148	array([[-2.0758276, -3.903139 ]], dtype=float32)

time = 59005	action = 0	current_phase = 1	next_phase = 0	reward = -0.734432	array([[-3.0878594, -3.1340597]], dtype=float32)

time = 59010	action = 1	current_phase = 1	next_phase = 0	reward = -2.105255	array([[-6.25086  , -3.5093098]], dtype=float32)

time = 59018	action = 0	current_phase = 0	next_phase = 1	reward = -0.427582	array([[-2.0939069, -3.2899525]], dtype=float32)

time = 59023	action = 0	current_phase = 0	next_phase = 1	reward = -0.278391	array([[-2.1789765, -3.2123652]], dtype=float32)

time = 59028	action = 0	current_phase = 0	next_phase = 1	reward = -0.163092	array([[-2.3889434, -3.3045483]], dtype=float32)

time = 59033	action = 0	current_phase = 0	next_phase = 1	reward = 0.078617	array([[-2.6299193, -4.1308417]], dtype=float32)

time = 59038	action = 1	current_phase = 0	next_phase = 1	reward = -1.897501	array([[-5.052608 , -3.5925648]], dtype=float32)

time = 59046	action = 0	current_phase = 1	next_phase = 0	reward = -0.501652	array([[-2.058289 , -3.2706776]], dtype=float32)

time = 59051	action = 0	current_phase = 1	next_phase = 0	reward = -0.347336	array([[-1.9348022, -3.121999 ]], dtype=float32)

time = 59056	action = 0	current_phase = 1	next_phase = 0	reward = -0.200042	array([[-1.9316666, -3.1247838]], dtype=float32)

time = 59061	action = 0	current_phase = 1	next_phase = 0	reward = 0.321907	array([[-2.2827144, -4.206565 ]], dtype=float32)

time = 59066	action = 1	current_phase = 1	next_phase = 0	reward = -1.507254	array([[-5.6684775, -3.2849104]], dtype=float32)

time = 59074	action = 0	current_phase = 0	next_phase = 1	reward = -0.564804	array([[-2.1693578, -3.1350203]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0137 - val_loss: 0.0072

Epoch 2/50

 - 4s - loss: 0.0117 - val_loss: 0.0072

Epoch 3/50

 - 4s - loss: 0.0130 - val_loss: 0.0072

Epoch 4/50

 - 4s - loss: 0.0108 - val_loss: 0.0068

Epoch 5/50

 - 4s - loss: 0.0135 - val_loss: 0.0080

Epoch 6/50

 - 4s - loss: 0.0111 - val_loss: 0.0076

Epoch 7/50

 - 4s - loss: 0.0134 - val_loss: 0.0080

Epoch 8/50

 - 4s - loss: 0.0098 - val_loss: 0.0079

Epoch 9/50

 - 4s - loss: 0.0114 - val_loss: 0.0088

Epoch 10/50

 - 4s - loss: 0.0098 - val_loss: 0.0099

Epoch 11/50

 - 4s - loss: 0.0099 - val_loss: 0.0091

Epoch 12/50

 - 4s - loss: 0.0118 - val_loss: 0.0099

Epoch 13/50

 - 4s - loss: 0.0146 - val_loss: 0.0104

Epoch 14/50

 - 4s - loss: 0.0092 - val_loss: 0.0104

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 59079	action = 0	current_phase = 0	next_phase = 1	reward = -0.412514	array([[-1.9689724, -3.0428188]], dtype=float32)

time = 59084	action = 0	current_phase = 0	next_phase = 1	reward = -0.255290	array([[-1.897426 , -3.3465264]], dtype=float32)

time = 59089	action = 0	current_phase = 0	next_phase = 1	reward = -0.179211	array([[-1.9843999, -3.1844687]], dtype=float32)

time = 59094	action = 1	current_phase = 0	next_phase = 1	reward = -0.527674	array([[-5.5925264, -2.2637193]], dtype=float32)

time = 59102	action = 0	current_phase = 1	next_phase = 0	reward = -0.612548	array([[-2.2324862, -3.1197155]], dtype=float32)

time = 59107	action = 0	current_phase = 1	next_phase = 0	reward = -0.453816	array([[-2.1225867, -3.1190572]], dtype=float32)

time = 59112	action = 0	current_phase = 1	next_phase = 0	reward = -0.305954	array([[-2.047976, -3.137194]], dtype=float32)

time = 59117	action = 0	current_phase = 1	next_phase = 0	reward = -0.173428	array([[-2.2768512, -3.2448225]], dtype=float32)

time = 59122	action = 0	current_phase = 1	next_phase = 0	reward = 0.198635	array([[-2.473404 , -4.3104687]], dtype=float32)

time = 59127	action = 1	current_phase = 1	next_phase = 0	reward = -1.782864	array([[-6.2126822, -3.5257337]], dtype=float32)

time = 59135	action = 0	current_phase = 0	next_phase = 1	reward = -0.525314	array([[-2.1077678, -3.296189 ]], dtype=float32)

time = 59140	action = 0	current_phase = 0	next_phase = 1	reward = -0.370859	array([[-1.9656569, -3.0466921]], dtype=float32)

time = 59145	action = 0	current_phase = 0	next_phase = 1	reward = -0.213869	array([[-1.8971472, -3.3468206]], dtype=float32)

time = 59150	action = 0	current_phase = 0	next_phase = 1	reward = 0.356644	array([[-2.1751242, -3.935217 ]], dtype=float32)

time = 59155	action = 1	current_phase = 0	next_phase = 1	reward = -1.315018	array([[-4.662913 , -3.1026616]], dtype=float32)

time = 59163	action = 0	current_phase = 1	next_phase = 0	reward = -0.595922	array([[-2.179443 , -3.1184592]], dtype=float32)

time = 59168	action = 0	current_phase = 1	next_phase = 0	reward = -0.444763	array([[-1.9257791, -3.1221237]], dtype=float32)

time = 59173	action = 0	current_phase = 1	next_phase = 0	reward = -0.292509	array([[-2.0174048, -3.1364737]], dtype=float32)

time = 59178	action = 0	current_phase = 1	next_phase = 0	reward = -0.166465	array([[-2.2547383, -3.2591395]], dtype=float32)

time = 59183	action = 0	current_phase = 1	next_phase = 0	reward = 0.086400	array([[-2.6583328, -4.375134 ]], dtype=float32)

time = 59188	action = 1	current_phase = 1	next_phase = 0	reward = -1.896552	array([[-6.250982 , -3.5693853]], dtype=float32)

time = 59196	action = 0	current_phase = 0	next_phase = 1	reward = -0.494515	array([[-2.0885844, -3.2894642]], dtype=float32)

time = 59201	action = 0	current_phase = 0	next_phase = 1	reward = -0.332246	array([[-1.9721633, -3.0397196]], dtype=float32)

time = 59206	action = 0	current_phase = 0	next_phase = 1	reward = -0.189133	array([[-2.092345, -3.087068]], dtype=float32)

time = 59211	action = 0	current_phase = 0	next_phase = 1	reward = 0.299396	array([[-2.3715038, -4.2144694]], dtype=float32)

time = 59216	action = 1	current_phase = 0	next_phase = 1	reward = -1.504120	array([[-4.4229274, -3.30461  ]], dtype=float32)

time = 59224	action = 0	current_phase = 1	next_phase = 0	reward = -0.545305	array([[-2.129777 , -3.1265879]], dtype=float32)

time = 59229	action = 0	current_phase = 1	next_phase = 0	reward = -0.377711	array([[-1.9226104, -3.1214614]], dtype=float32)

time = 59234	action = 0	current_phase = 1	next_phase = 0	reward = -0.225845	array([[-1.8469293, -3.0786335]], dtype=float32)

time = 59239	action = 0	current_phase = 1	next_phase = 0	reward = -0.188233	array([[-2.0545235, -3.8723316]], dtype=float32)

time = 59244	action = 1	current_phase = 1	next_phase = 0	reward = -0.546291	array([[-2.3385916, -2.3052347]], dtype=float32)

time = 59252	action = 0	current_phase = 0	next_phase = 1	reward = -0.614549	array([[-2.2624753, -3.8119955]], dtype=float32)

time = 59257	action = 0	current_phase = 0	next_phase = 1	reward = -0.460992	array([[-2.1643097, -2.9250073]], dtype=float32)

time = 59262	action = 0	current_phase = 0	next_phase = 1	reward = -0.305922	array([[-2.1765335, -3.219825 ]], dtype=float32)

time = 59267	action = 0	current_phase = 0	next_phase = 1	reward = -0.177272	array([[-2.356697, -3.32487 ]], dtype=float32)

time = 59272	action = 0	current_phase = 0	next_phase = 1	reward = 0.191906	array([[-2.7094235, -4.5110693]], dtype=float32)

time = 59277	action = 1	current_phase = 0	next_phase = 1	reward = -1.790591	array([[-6.4545617, -3.4806726]], dtype=float32)

time = 59285	action = 0	current_phase = 1	next_phase = 0	reward = -0.542584	array([[-2.0617452, -3.2641954]], dtype=float32)

time = 59290	action = 0	current_phase = 1	next_phase = 0	reward = -0.393033	array([[-1.9316874, -3.1312094]], dtype=float32)

time = 59295	action = 0	current_phase = 1	next_phase = 0	reward = -0.238600	array([[-1.8459356, -3.0799818]], dtype=float32)

time = 59300	action = 0	current_phase = 1	next_phase = 0	reward = 0.379392	array([[-2.115397 , -3.9282234]], dtype=float32)

time = 59305	action = 1	current_phase = 1	next_phase = 0	reward = -1.293103	array([[-3.0885496, -3.0546908]], dtype=float32)

time = 59313	action = 0	current_phase = 0	next_phase = 1	reward = -0.584794	array([[-2.2598016, -3.8007038]], dtype=float32)

time = 59318	action = 0	current_phase = 0	next_phase = 1	reward = -0.432800	array([[-2.087299 , -2.9577286]], dtype=float32)

time = 59323	action = 0	current_phase = 0	next_phase = 1	reward = -0.271151	array([[-2.1658664, -3.2211509]], dtype=float32)

time = 59328	action = 0	current_phase = 0	next_phase = 1	reward = -0.158387	array([[-2.3632538, -3.331324 ]], dtype=float32)

time = 59333	action = 0	current_phase = 0	next_phase = 1	reward = -0.039541	array([[-2.7147057, -4.506342 ]], dtype=float32)

time = 59338	action = 1	current_phase = 0	next_phase = 1	reward = -1.899489	array([[-6.5558114, -3.5387838]], dtype=float32)

time = 59346	action = 0	current_phase = 1	next_phase = 0	reward = -0.499449	array([[-2.0664215, -3.2643108]], dtype=float32)

time = 59351	action = 0	current_phase = 1	next_phase = 0	reward = -0.346386	array([[-1.9267198, -3.1230001]], dtype=float32)

time = 59356	action = 0	current_phase = 1	next_phase = 0	reward = -0.198462	array([[-1.9339975, -3.1344712]], dtype=float32)

time = 59361	action = 0	current_phase = 1	next_phase = 0	reward = 0.309807	array([[-2.2872524, -4.2123322]], dtype=float32)

time = 59366	action = 1	current_phase = 1	next_phase = 0	reward = -1.611945	array([[-5.702607 , -3.3222253]], dtype=float32)

time = 59374	action = 0	current_phase = 0	next_phase = 1	reward = -0.557251	array([[-2.1402802, -3.1362627]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0132 - val_loss: 0.0069

Epoch 2/50

 - 4s - loss: 0.0109 - val_loss: 0.0072

Epoch 3/50

 - 4s - loss: 0.0093 - val_loss: 0.0078

Epoch 4/50

 - 4s - loss: 0.0110 - val_loss: 0.0077

Epoch 5/50

 - 4s - loss: 0.0173 - val_loss: 0.0075

Epoch 6/50

 - 4s - loss: 0.0125 - val_loss: 0.0082

Epoch 7/50

 - 4s - loss: 0.0122 - val_loss: 0.0081

Epoch 8/50

 - 4s - loss: 0.0100 - val_loss: 0.0080

Epoch 9/50

 - 4s - loss: 0.0128 - val_loss: 0.0076

Epoch 10/50

 - 4s - loss: 0.0149 - val_loss: 0.0079

Epoch 11/50

 - 4s - loss: 0.0147 - val_loss: 0.0081

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 59379	action = 0	current_phase = 0	next_phase = 1	reward = -0.401490	array([[-1.9775772, -3.0505857]], dtype=float32)

time = 59384	action = 0	current_phase = 0	next_phase = 1	reward = -0.250012	array([[-1.8934515, -3.3569357]], dtype=float32)

time = 59389	action = 0	current_phase = 0	next_phase = 1	reward = -0.182039	array([[-1.9889983, -3.180196 ]], dtype=float32)

time = 59394	action = 1	current_phase = 0	next_phase = 1	reward = -0.603584	array([[-5.550263 , -2.3519032]], dtype=float32)

time = 59402	action = 0	current_phase = 1	next_phase = 0	reward = -0.618709	array([[-2.307329, -3.140377]], dtype=float32)

time = 59407	action = 0	current_phase = 1	next_phase = 0	reward = -0.470063	array([[-2.186329 , -3.1292124]], dtype=float32)

time = 59412	action = 0	current_phase = 1	next_phase = 0	reward = -0.324696	array([[-2.0843854, -3.1611788]], dtype=float32)

time = 59417	action = 0	current_phase = 1	next_phase = 0	reward = -0.182257	array([[-2.3210769, -3.2577598]], dtype=float32)

time = 59422	action = 0	current_phase = 1	next_phase = 0	reward = 0.197487	array([[-2.6557705, -4.4126487]], dtype=float32)

time = 59427	action = 1	current_phase = 1	next_phase = 0	reward = -1.736612	array([[-6.23286  , -3.5220315]], dtype=float32)

time = 59435	action = 0	current_phase = 0	next_phase = 1	reward = -0.532528	array([[-2.1081963, -3.286347 ]], dtype=float32)

time = 59440	action = 0	current_phase = 0	next_phase = 1	reward = -0.372274	array([[-1.9753768, -3.0534198]], dtype=float32)

time = 59445	action = 0	current_phase = 0	next_phase = 1	reward = -0.218513	array([[-1.8940728, -3.3571415]], dtype=float32)

time = 59450	action = 0	current_phase = 0	next_phase = 1	reward = 0.369594	array([[-2.1860514, -3.9212642]], dtype=float32)

time = 59455	action = 1	current_phase = 0	next_phase = 1	reward = -1.355500	array([[-4.6888576, -3.0967164]], dtype=float32)

time = 59463	action = 0	current_phase = 1	next_phase = 0	reward = -0.590651	array([[-2.1693068, -3.1345925]], dtype=float32)

time = 59468	action = 0	current_phase = 1	next_phase = 0	reward = -0.443072	array([[-1.9548234, -3.1402075]], dtype=float32)

time = 59473	action = 0	current_phase = 1	next_phase = 0	reward = -0.297163	array([[-2.0358038, -3.1541998]], dtype=float32)

time = 59478	action = 0	current_phase = 1	next_phase = 0	reward = -0.171789	array([[-2.294149 , -3.2756274]], dtype=float32)

time = 59483	action = 0	current_phase = 1	next_phase = 0	reward = 0.096434	array([[-2.7179337, -4.3935637]], dtype=float32)

time = 59488	action = 1	current_phase = 1	next_phase = 0	reward = -1.895818	array([[-6.24664 , -3.543781]], dtype=float32)

time = 59496	action = 0	current_phase = 0	next_phase = 1	reward = -0.495633	array([[-2.0888515, -3.278005 ]], dtype=float32)

time = 59501	action = 0	current_phase = 0	next_phase = 1	reward = -0.347983	array([[-2.0035713, -3.0264266]], dtype=float32)

time = 59506	action = 0	current_phase = 0	next_phase = 1	reward = -0.200571	array([[-2.0723813, -3.093368 ]], dtype=float32)

time = 59511	action = 0	current_phase = 0	next_phase = 1	reward = 0.292931	array([[-2.364378, -4.196831]], dtype=float32)

time = 59516	action = 1	current_phase = 0	next_phase = 1	reward = -1.503996	array([[-4.456052, -3.265548]], dtype=float32)

time = 59524	action = 0	current_phase = 1	next_phase = 0	reward = -0.548497	array([[-2.1368544, -3.1479807]], dtype=float32)

time = 59529	action = 0	current_phase = 1	next_phase = 0	reward = -0.399454	array([[-1.9561297, -3.1404104]], dtype=float32)

time = 59534	action = 0	current_phase = 1	next_phase = 0	reward = -0.240763	array([[-1.8889436, -3.09256  ]], dtype=float32)

time = 59539	action = 0	current_phase = 1	next_phase = 0	reward = -0.178882	array([[-2.0527985, -3.8980742]], dtype=float32)

time = 59544	action = 1	current_phase = 1	next_phase = 0	reward = -0.484491	array([[-2.374524 , -2.3051138]], dtype=float32)

time = 59552	action = 0	current_phase = 0	next_phase = 1	reward = -0.621317	array([[-2.2778764, -3.8034763]], dtype=float32)

time = 59557	action = 0	current_phase = 0	next_phase = 1	reward = -0.461648	array([[-2.1683471, -2.9232485]], dtype=float32)

time = 59562	action = 0	current_phase = 0	next_phase = 1	reward = -0.302014	array([[-2.1728582, -3.2197804]], dtype=float32)

time = 59567	action = 0	current_phase = 0	next_phase = 1	reward = -0.166521	array([[-2.3340187, -3.31865  ]], dtype=float32)

time = 59572	action = 0	current_phase = 0	next_phase = 1	reward = 0.194017	array([[-2.6639318, -4.5106974]], dtype=float32)

time = 59577	action = 1	current_phase = 0	next_phase = 1	reward = -1.785155	array([[-6.4481993, -3.4792833]], dtype=float32)

time = 59585	action = 0	current_phase = 1	next_phase = 0	reward = -0.527869	array([[-2.105048 , -3.2930617]], dtype=float32)

time = 59590	action = 0	current_phase = 1	next_phase = 0	reward = -0.380613	array([[-1.9571649, -3.142154 ]], dtype=float32)

time = 59595	action = 0	current_phase = 1	next_phase = 0	reward = -0.236229	array([[-1.8877652, -3.0923824]], dtype=float32)

time = 59600	action = 0	current_phase = 1	next_phase = 0	reward = 0.368060	array([[-2.1596978, -3.9806647]], dtype=float32)

time = 59605	action = 0	current_phase = 1	next_phase = 0	reward = -0.835432	array([[-3.1603432, -3.164963 ]], dtype=float32)

time = 59610	action = 1	current_phase = 1	next_phase = 0	reward = -2.114646	array([[-6.2571025, -3.5673919]], dtype=float32)

time = 59618	action = 0	current_phase = 0	next_phase = 1	reward = -0.442144	array([[-2.0965822, -3.2823746]], dtype=float32)

time = 59623	action = 0	current_phase = 0	next_phase = 1	reward = -0.279654	array([[-2.1418505, -3.225557 ]], dtype=float32)

time = 59628	action = 0	current_phase = 0	next_phase = 1	reward = -0.163043	array([[-2.3187582, -3.3036122]], dtype=float32)

time = 59633	action = 0	current_phase = 0	next_phase = 1	reward = 0.086914	array([[-2.8307912, -4.4516625]], dtype=float32)

time = 59638	action = 1	current_phase = 0	next_phase = 1	reward = -1.901898	array([[-4.7313366, -3.5274346]], dtype=float32)

time = 59646	action = 0	current_phase = 1	next_phase = 0	reward = -0.499875	array([[-2.1132119, -3.2997007]], dtype=float32)

time = 59651	action = 0	current_phase = 1	next_phase = 0	reward = -0.344118	array([[-1.9562913, -3.1407423]], dtype=float32)

time = 59656	action = 0	current_phase = 1	next_phase = 0	reward = -0.190982	array([[-1.9885982, -3.173713 ]], dtype=float32)

time = 59661	action = 0	current_phase = 1	next_phase = 0	reward = 0.324224	array([[-2.253607 , -4.1692142]], dtype=float32)

time = 59666	action = 1	current_phase = 1	next_phase = 0	reward = -1.612220	array([[-5.733921 , -3.3596609]], dtype=float32)

time = 59674	action = 0	current_phase = 0	next_phase = 1	reward = -0.564498	array([[-2.141642, -3.134472]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0154 - val_loss: 0.0048

Epoch 2/50

 - 4s - loss: 0.0122 - val_loss: 0.0049

Epoch 3/50

 - 4s - loss: 0.0131 - val_loss: 0.0049

Epoch 4/50

 - 4s - loss: 0.0150 - val_loss: 0.0049

Epoch 5/50

 - 4s - loss: 0.0104 - val_loss: 0.0050

Epoch 6/50

 - 4s - loss: 0.0101 - val_loss: 0.0055

Epoch 7/50

 - 4s - loss: 0.0089 - val_loss: 0.0051

Epoch 8/50

 - 4s - loss: 0.0104 - val_loss: 0.0046

Epoch 9/50

 - 4s - loss: 0.0107 - val_loss: 0.0053

Epoch 10/50

 - 4s - loss: 0.0130 - val_loss: 0.0057

Epoch 11/50

 - 4s - loss: 0.0116 - val_loss: 0.0060

Epoch 12/50

 - 4s - loss: 0.0102 - val_loss: 0.0056

Epoch 13/50

 - 4s - loss: 0.0112 - val_loss: 0.0059

Epoch 14/50

 - 4s - loss: 0.0082 - val_loss: 0.0054

Epoch 15/50

 - 4s - loss: 0.0142 - val_loss: 0.0052

Epoch 16/50

 - 4s - loss: 0.0098 - val_loss: 0.0057

Epoch 17/50

 - 4s - loss: 0.0128 - val_loss: 0.0066

Epoch 18/50

 - 4s - loss: 0.0129 - val_loss: 0.0055

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 59679	action = 0	current_phase = 0	next_phase = 1	reward = -0.405453	array([[-1.984641 , -3.0604935]], dtype=float32)

time = 59684	action = 0	current_phase = 0	next_phase = 1	reward = -0.251094	array([[-1.9220327, -3.3672204]], dtype=float32)

time = 59689	action = 0	current_phase = 0	next_phase = 1	reward = -0.172439	array([[-1.9727767, -3.1921859]], dtype=float32)

time = 59694	action = 1	current_phase = 0	next_phase = 1	reward = -0.524796	array([[-5.621311 , -2.2596045]], dtype=float32)

time = 59702	action = 0	current_phase = 1	next_phase = 0	reward = -0.610273	array([[-2.2726004, -3.1468146]], dtype=float32)

time = 59707	action = 0	current_phase = 1	next_phase = 0	reward = -0.452953	array([[-2.149196 , -3.1446888]], dtype=float32)

time = 59712	action = 0	current_phase = 1	next_phase = 0	reward = -0.294662	array([[-2.083637 , -3.1606572]], dtype=float32)

time = 59717	action = 0	current_phase = 1	next_phase = 0	reward = -0.168937	array([[-2.2883408, -3.2837312]], dtype=float32)

time = 59722	action = 0	current_phase = 1	next_phase = 0	reward = 0.136089	array([[-2.644581, -4.410643]], dtype=float32)

time = 59727	action = 1	current_phase = 1	next_phase = 0	reward = -1.783101	array([[-6.275776 , -3.5614967]], dtype=float32)

time = 59735	action = 0	current_phase = 0	next_phase = 1	reward = -0.526670	array([[-2.1255333, -3.2808475]], dtype=float32)

time = 59740	action = 0	current_phase = 0	next_phase = 1	reward = -0.367010	array([[-1.984217 , -3.0611029]], dtype=float32)

time = 59745	action = 0	current_phase = 0	next_phase = 1	reward = -0.209004	array([[-1.9221858, -3.3669035]], dtype=float32)

time = 59750	action = 0	current_phase = 0	next_phase = 1	reward = 0.354309	array([[-2.2097094, -3.892909 ]], dtype=float32)

time = 59755	action = 1	current_phase = 0	next_phase = 1	reward = -1.257341	array([[-4.7404327, -3.0801506]], dtype=float32)

time = 59763	action = 0	current_phase = 1	next_phase = 0	reward = -0.588807	array([[-2.142185, -3.151356]], dtype=float32)

time = 59768	action = 0	current_phase = 1	next_phase = 0	reward = -0.436628	array([[-1.9281237, -3.1420588]], dtype=float32)

time = 59773	action = 0	current_phase = 1	next_phase = 0	reward = -0.286176	array([[-2.0800724, -3.1592872]], dtype=float32)

time = 59778	action = 0	current_phase = 1	next_phase = 0	reward = -0.168678	array([[-2.2856607, -3.283053 ]], dtype=float32)

time = 59783	action = 0	current_phase = 1	next_phase = 0	reward = 0.017638	array([[-2.704281, -4.288165]], dtype=float32)

time = 59788	action = 1	current_phase = 1	next_phase = 0	reward = -1.905314	array([[-6.278243 , -3.5637972]], dtype=float32)

time = 59796	action = 0	current_phase = 0	next_phase = 1	reward = -0.495930	array([[-2.1285338, -3.2775452]], dtype=float32)

time = 59801	action = 0	current_phase = 0	next_phase = 1	reward = -0.347904	array([[-1.9953016, -3.0499356]], dtype=float32)

time = 59806	action = 0	current_phase = 0	next_phase = 1	reward = -0.200518	array([[-2.0728464, -3.0943103]], dtype=float32)

time = 59811	action = 0	current_phase = 0	next_phase = 1	reward = 0.290008	array([[-2.4730482, -4.2130604]], dtype=float32)

time = 59816	action = 1	current_phase = 0	next_phase = 1	reward = -1.611877	array([[-4.4764166, -3.2708502]], dtype=float32)

time = 59824	action = 0	current_phase = 1	next_phase = 0	reward = -0.566830	array([[-2.1454368, -3.1512291]], dtype=float32)

time = 59829	action = 0	current_phase = 1	next_phase = 0	reward = -0.416420	array([[-1.926197, -3.141919]], dtype=float32)

time = 59834	action = 0	current_phase = 1	next_phase = 0	reward = -0.258316	array([[-1.8672332, -3.1013594]], dtype=float32)

time = 59839	action = 0	current_phase = 1	next_phase = 0	reward = -0.172626	array([[-2.0982578, -3.8775847]], dtype=float32)

time = 59844	action = 1	current_phase = 1	next_phase = 0	reward = -0.460867	array([[-2.3936684, -2.3246844]], dtype=float32)

time = 59852	action = 1	current_phase = 0	next_phase = 1	reward = -1.917113	array([[-4.3519664, -3.4981978]], dtype=float32)

time = 59860	action = 0	current_phase = 1	next_phase = 0	reward = -0.370267	array([[-2.8041244, -3.4160495]], dtype=float32)

time = 59865	action = 0	current_phase = 1	next_phase = 0	reward = -0.220161	array([[-2.0775785, -3.2639937]], dtype=float32)

time = 59870	action = 0	current_phase = 1	next_phase = 0	reward = 0.355926	array([[-2.2653015, -4.060501 ]], dtype=float32)

time = 59875	action = 1	current_phase = 1	next_phase = 0	reward = -1.307617	array([[-4.1981983, -3.377759 ]], dtype=float32)

time = 59883	action = 0	current_phase = 0	next_phase = 1	reward = -0.584007	array([[-2.1475925, -3.1427317]], dtype=float32)

time = 59888	action = 0	current_phase = 0	next_phase = 1	reward = -0.439183	array([[-2.180356, -2.925633]], dtype=float32)

time = 59893	action = 0	current_phase = 0	next_phase = 1	reward = -0.288370	array([[-2.189911 , -3.2318213]], dtype=float32)

time = 59898	action = 0	current_phase = 0	next_phase = 1	reward = -0.161865	array([[-2.3196292, -3.3191545]], dtype=float32)

time = 59903	action = 0	current_phase = 0	next_phase = 1	reward = 0.144470	array([[-2.6974978, -4.4403577]], dtype=float32)

time = 59908	action = 1	current_phase = 0	next_phase = 1	reward = -1.894701	array([[-6.4114175, -3.4719021]], dtype=float32)

time = 59916	action = 0	current_phase = 1	next_phase = 0	reward = -0.492949	array([[-2.0680096, -3.303229 ]], dtype=float32)

time = 59921	action = 0	current_phase = 1	next_phase = 0	reward = -0.339911	array([[-1.9380171, -3.144163 ]], dtype=float32)

time = 59926	action = 0	current_phase = 1	next_phase = 0	reward = -0.199277	array([[-1.9291236, -3.1476917]], dtype=float32)

time = 59931	action = 0	current_phase = 1	next_phase = 0	reward = 0.281049	array([[-2.325555 , -4.2321434]], dtype=float32)

time = 59936	action = 1	current_phase = 1	next_phase = 0	reward = -1.664758	array([[-5.7048683, -3.3268445]], dtype=float32)

time = 59944	action = 0	current_phase = 0	next_phase = 1	reward = -0.557587	array([[-2.1408908, -3.147314 ]], dtype=float32)

time = 59949	action = 0	current_phase = 0	next_phase = 1	reward = -0.394768	array([[-1.9850703, -3.0599542]], dtype=float32)

time = 59954	action = 0	current_phase = 0	next_phase = 1	reward = -0.237427	array([[-1.9220266, -3.3672187]], dtype=float32)

time = 59959	action = 0	current_phase = 0	next_phase = 1	reward = -0.178799	array([[-1.9738942, -3.19235  ]], dtype=float32)

time = 59964	action = 1	current_phase = 0	next_phase = 1	reward = -0.538921	array([[-5.62734  , -2.2543314]], dtype=float32)

time = 59972	action = 0	current_phase = 1	next_phase = 0	reward = -0.619475	array([[-2.2530956, -3.1454206]], dtype=float32)

time = 59977	action = 0	current_phase = 1	next_phase = 0	reward = -0.466114	array([[-2.147211, -3.144031]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0100 - val_loss: 0.0039

Epoch 2/50

 - 4s - loss: 0.0105 - val_loss: 0.0042

Epoch 3/50

 - 4s - loss: 0.0102 - val_loss: 0.0041

Epoch 4/50

 - 4s - loss: 0.0103 - val_loss: 0.0039

Epoch 5/50

 - 4s - loss: 0.0079 - val_loss: 0.0041

Epoch 6/50

 - 4s - loss: 0.0083 - val_loss: 0.0042

Epoch 7/50

 - 4s - loss: 0.0069 - val_loss: 0.0039

Epoch 8/50

 - 4s - loss: 0.0070 - val_loss: 0.0039

Epoch 9/50

 - 4s - loss: 0.0082 - val_loss: 0.0048

Epoch 10/50

 - 4s - loss: 0.0087 - val_loss: 0.0040

Epoch 11/50

 - 4s - loss: 0.0081 - val_loss: 0.0038

Epoch 12/50

 - 4s - loss: 0.0081 - val_loss: 0.0037

Epoch 13/50

 - 4s - loss: 0.0067 - val_loss: 0.0037

Epoch 14/50

 - 4s - loss: 0.0082 - val_loss: 0.0041

Epoch 15/50

 - 4s - loss: 0.0088 - val_loss: 0.0042

Epoch 16/50

 - 4s - loss: 0.0069 - val_loss: 0.0042

Epoch 17/50

 - 4s - loss: 0.0106 - val_loss: 0.0049

Epoch 18/50

 - 4s - loss: 0.0096 - val_loss: 0.0049

Epoch 19/50

 - 4s - loss: 0.0083 - val_loss: 0.0045

Epoch 20/50

 - 4s - loss: 0.0068 - val_loss: 0.0050

Epoch 21/50

 - 4s - loss: 0.0074 - val_loss: 0.0045

Epoch 22/50

 - 4s - loss: 0.0080 - val_loss: 0.0053

Epoch 23/50

 - 4s - loss: 0.0064 - val_loss: 0.0047

length of memory (state 0, action 0): 1020, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 59982	action = 0	current_phase = 1	next_phase = 0	reward = -0.302757	array([[-2.0985928, -3.1607437]], dtype=float32)

time = 59987	action = 0	current_phase = 1	next_phase = 0	reward = -0.171713	array([[-2.3032508, -3.2676508]], dtype=float32)

time = 59992	action = 0	current_phase = 1	next_phase = 0	reward = 0.123492	array([[-2.6106544, -4.404269 ]], dtype=float32)

time = 59997	action = 1	current_phase = 1	next_phase = 0	reward = -1.776645	array([[-6.299865 , -3.5401976]], dtype=float32)

time = 60005	action = 0	current_phase = 0	next_phase = 1	reward = -0.512509	array([[-2.103617 , -3.2763443]], dtype=float32)

time = 60010	action = 0	current_phase = 0	next_phase = 1	reward = -0.349899	array([[-1.9852685, -3.0615532]], dtype=float32)

time = 60015	action = 0	current_phase = 0	next_phase = 1	reward = -0.206731	array([[-1.9351499, -3.369728 ]], dtype=float32)

time = 60020	action = 0	current_phase = 0	next_phase = 1	reward = 0.359424	array([[-2.2706811, -3.9744391]], dtype=float32)

time = 60025	action = 1	current_phase = 0	next_phase = 1	reward = -1.366123	array([[-4.691678, -3.105156]], dtype=float32)

time = 60033	action = 0	current_phase = 1	next_phase = 0	reward = -0.590248	array([[-2.1757596, -3.1450977]], dtype=float32)

time = 60038	action = 0	current_phase = 1	next_phase = 0	reward = -0.427452	array([[-1.9327027, -3.1337228]], dtype=float32)

time = 60043	action = 0	current_phase = 1	next_phase = 0	reward = -0.274664	array([[-2.0453918, -3.1456409]], dtype=float32)

time = 60048	action = 0	current_phase = 1	next_phase = 0	reward = -0.158764	array([[-2.2956207, -3.2747066]], dtype=float32)

time = 60053	action = 0	current_phase = 1	next_phase = 0	reward = 0.137361	array([[-2.7391975, -4.281332 ]], dtype=float32)

time = 60058	action = 1	current_phase = 1	next_phase = 0	reward = -1.898487	array([[-6.303155 , -3.5429857]], dtype=float32)

time = 60066	action = 0	current_phase = 0	next_phase = 1	reward = -0.493913	array([[-2.0943108, -3.2687213]], dtype=float32)

time = 60071	action = 0	current_phase = 0	next_phase = 1	reward = -0.337215	array([[-2.0109808, -3.045614 ]], dtype=float32)

time = 60076	action = 0	current_phase = 0	next_phase = 1	reward = -0.193294	array([[-2.0904505, -3.0947797]], dtype=float32)

time = 60081	action = 0	current_phase = 0	next_phase = 1	reward = 0.296106	array([[-2.501048 , -4.2372756]], dtype=float32)

time = 60086	action = 1	current_phase = 0	next_phase = 1	reward = -1.611987	array([[-4.4284678, -3.3104575]], dtype=float32)

time = 60094	action = 0	current_phase = 1	next_phase = 0	reward = -0.554255	array([[-2.1098309, -3.1473475]], dtype=float32)

time = 60099	action = 0	current_phase = 1	next_phase = 0	reward = -0.390759	array([[-1.930566 , -3.1332774]], dtype=float32)

time = 60104	action = 0	current_phase = 1	next_phase = 0	reward = -0.236424	array([[-1.8834172, -3.086787 ]], dtype=float32)

time = 60109	action = 0	current_phase = 1	next_phase = 0	reward = -0.182704	array([[-2.0420768, -3.8950634]], dtype=float32)

time = 60114	action = 1	current_phase = 1	next_phase = 0	reward = -0.534489	array([[-2.4147265, -2.308774 ]], dtype=float32)

time = 60122	action = 0	current_phase = 0	next_phase = 1	reward = -0.612139	array([[-2.2760816, -3.8145785]], dtype=float32)

time = 60127	action = 0	current_phase = 0	next_phase = 1	reward = -0.449569	array([[-2.1848686, -2.9295478]], dtype=float32)

time = 60132	action = 0	current_phase = 0	next_phase = 1	reward = -0.289905	array([[-2.1984766, -3.2349002]], dtype=float32)

time = 60137	action = 0	current_phase = 0	next_phase = 1	reward = -0.168696	array([[-2.3406007, -3.2871542]], dtype=float32)

time = 60142	action = 0	current_phase = 0	next_phase = 1	reward = 0.086324	array([[-2.675086, -4.457933]], dtype=float32)

time = 60147	action = 1	current_phase = 0	next_phase = 1	reward = -1.783285	array([[-6.5380974, -3.4877079]], dtype=float32)

time = 60155	action = 0	current_phase = 1	next_phase = 0	reward = -0.520632	array([[-2.099906, -3.295474]], dtype=float32)

time = 60160	action = 0	current_phase = 1	next_phase = 0	reward = -0.362137	array([[-1.9346337, -3.136012 ]], dtype=float32)

time = 60165	action = 0	current_phase = 1	next_phase = 0	reward = -0.214628	array([[-1.8979571, -3.105337 ]], dtype=float32)

time = 60170	action = 0	current_phase = 1	next_phase = 0	reward = 0.354896	array([[-2.1706839, -3.9638863]], dtype=float32)

time = 60175	action = 1	current_phase = 1	next_phase = 0	reward = -1.304948	array([[-3.232678 , -3.0989351]], dtype=float32)

time = 60183	action = 0	current_phase = 0	next_phase = 1	reward = -0.584857	array([[-2.272775 , -3.8125532]], dtype=float32)

time = 60188	action = 0	current_phase = 0	next_phase = 1	reward = -0.427600	array([[-2.1767929, -2.929793 ]], dtype=float32)

time = 60193	action = 0	current_phase = 0	next_phase = 1	reward = -0.276498	array([[-2.1960042, -3.2414443]], dtype=float32)

time = 60198	action = 0	current_phase = 0	next_phase = 1	reward = -0.171295	array([[-2.3561177, -3.29809  ]], dtype=float32)

time = 60203	action = 0	current_phase = 0	next_phase = 1	reward = -0.004375	array([[-2.6960118, -4.429372 ]], dtype=float32)

time = 60208	action = 1	current_phase = 0	next_phase = 1	reward = -1.898641	array([[-6.5263667, -3.50651  ]], dtype=float32)

time = 60216	action = 0	current_phase = 1	next_phase = 0	reward = -0.488076	array([[-2.0979435, -3.2999372]], dtype=float32)

time = 60221	action = 0	current_phase = 1	next_phase = 0	reward = -0.326580	array([[-1.9329836, -3.1343286]], dtype=float32)

time = 60226	action = 0	current_phase = 1	next_phase = 0	reward = -0.186521	array([[-1.9583186, -3.1589875]], dtype=float32)

time = 60231	action = 0	current_phase = 1	next_phase = 0	reward = 0.310939	array([[-2.3215694, -4.2483516]], dtype=float32)

time = 60236	action = 1	current_phase = 1	next_phase = 0	reward = -1.506797	array([[-5.7546897, -3.3076422]], dtype=float32)

time = 60244	action = 0	current_phase = 0	next_phase = 1	reward = -0.559879	array([[-2.1315084, -3.1469276]], dtype=float32)

time = 60249	action = 0	current_phase = 0	next_phase = 1	reward = -0.395287	array([[-1.9853252, -3.0611653]], dtype=float32)

time = 60254	action = 0	current_phase = 0	next_phase = 1	reward = -0.227002	array([[-1.9329038, -3.373433 ]], dtype=float32)

time = 60259	action = 0	current_phase = 0	next_phase = 1	reward = -0.182533	array([[-2.0088413, -3.1698804]], dtype=float32)

time = 60264	action = 1	current_phase = 0	next_phase = 1	reward = -0.541539	array([[-5.642965, -2.283178]], dtype=float32)

time = 60272	action = 0	current_phase = 1	next_phase = 0	reward = -0.623599	array([[-2.2759042, -3.1473424]], dtype=float32)

time = 60277	action = 0	current_phase = 1	next_phase = 0	reward = -0.473565	array([[-2.138491 , -3.1321383]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0165 - val_loss: 0.0141

Epoch 2/50

 - 4s - loss: 0.0147 - val_loss: 0.0131

Epoch 3/50

 - 4s - loss: 0.0172 - val_loss: 0.0136

Epoch 4/50

 - 4s - loss: 0.0124 - val_loss: 0.0143

Epoch 5/50

 - 4s - loss: 0.0152 - val_loss: 0.0130

Epoch 6/50

 - 4s - loss: 0.0100 - val_loss: 0.0143

Epoch 7/50

 - 4s - loss: 0.0117 - val_loss: 0.0125

Epoch 8/50

 - 4s - loss: 0.0137 - val_loss: 0.0131

Epoch 9/50

 - 4s - loss: 0.0131 - val_loss: 0.0135

Epoch 10/50

 - 4s - loss: 0.0138 - val_loss: 0.0125

Epoch 11/50

 - 4s - loss: 0.0111 - val_loss: 0.0132

Epoch 12/50

 - 4s - loss: 0.0099 - val_loss: 0.0125

Epoch 13/50

 - 4s - loss: 0.0110 - val_loss: 0.0127

Epoch 14/50

 - 4s - loss: 0.0133 - val_loss: 0.0140

Epoch 15/50

 - 4s - loss: 0.0167 - val_loss: 0.0154

Epoch 16/50

 - 4s - loss: 0.0130 - val_loss: 0.0147

Epoch 17/50

 - 4s - loss: 0.0093 - val_loss: 0.0130

Epoch 18/50

 - 4s - loss: 0.0101 - val_loss: 0.0138

Epoch 19/50

 - 4s - loss: 0.0100 - val_loss: 0.0153

Epoch 20/50

 - 4s - loss: 0.0109 - val_loss: 0.0178

Epoch 21/50

 - 4s - loss: 0.0109 - val_loss: 0.0166

Epoch 22/50

 - 4s - loss: 0.0113 - val_loss: 0.0156

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 60282	action = 0	current_phase = 1	next_phase = 0	reward = -0.327021	array([[-2.0716245, -3.180928 ]], dtype=float32)

time = 60287	action = 0	current_phase = 1	next_phase = 0	reward = -0.187004	array([[-2.3122334, -3.2842002]], dtype=float32)

time = 60292	action = 0	current_phase = 1	next_phase = 0	reward = 0.182083	array([[-2.6281343, -4.415516 ]], dtype=float32)

time = 60297	action = 1	current_phase = 1	next_phase = 0	reward = -1.777049	array([[-6.274683 , -3.5226216]], dtype=float32)

time = 60305	action = 0	current_phase = 0	next_phase = 1	reward = -0.513570	array([[-2.1379964, -3.2590878]], dtype=float32)

time = 60310	action = 0	current_phase = 0	next_phase = 1	reward = -0.354590	array([[-2.0103827, -3.0379176]], dtype=float32)

time = 60315	action = 0	current_phase = 0	next_phase = 1	reward = -0.202895	array([[-1.9667605, -3.3469546]], dtype=float32)

time = 60320	action = 0	current_phase = 0	next_phase = 1	reward = 0.324211	array([[-2.213592 , -3.8872204]], dtype=float32)

time = 60325	action = 1	current_phase = 0	next_phase = 1	reward = -1.326920	array([[-4.7237144, -3.0914054]], dtype=float32)

time = 60333	action = 0	current_phase = 1	next_phase = 0	reward = -0.593463	array([[-2.1439009, -3.1452835]], dtype=float32)

time = 60338	action = 0	current_phase = 1	next_phase = 0	reward = -0.440746	array([[-1.9144957, -3.1470609]], dtype=float32)

time = 60343	action = 0	current_phase = 1	next_phase = 0	reward = -0.283978	array([[-2.0681908, -3.1805449]], dtype=float32)

time = 60348	action = 0	current_phase = 1	next_phase = 0	reward = -0.164525	array([[-2.3085258, -3.2845573]], dtype=float32)

time = 60353	action = 0	current_phase = 1	next_phase = 0	reward = 0.078311	array([[-2.7299895, -4.306394 ]], dtype=float32)

time = 60358	action = 1	current_phase = 1	next_phase = 0	reward = -1.895675	array([[-6.299145 , -3.5530958]], dtype=float32)

time = 60366	action = 0	current_phase = 0	next_phase = 1	reward = -0.501091	array([[-2.1220305, -3.2497883]], dtype=float32)

time = 60371	action = 0	current_phase = 0	next_phase = 1	reward = -0.347785	array([[-2.0158353, -3.0396671]], dtype=float32)

time = 60376	action = 0	current_phase = 0	next_phase = 1	reward = -0.195571	array([[-2.139768 , -3.0708313]], dtype=float32)

time = 60381	action = 0	current_phase = 0	next_phase = 1	reward = 0.308916	array([[-2.3860674, -4.1150513]], dtype=float32)

time = 60386	action = 1	current_phase = 0	next_phase = 1	reward = -1.612264	array([[-4.457325, -3.30496 ]], dtype=float32)

time = 60394	action = 0	current_phase = 1	next_phase = 0	reward = -0.564939	array([[-2.096022, -3.140287]], dtype=float32)

time = 60399	action = 0	current_phase = 1	next_phase = 0	reward = -0.411532	array([[-1.9106684, -3.1461706]], dtype=float32)

time = 60404	action = 0	current_phase = 1	next_phase = 0	reward = -0.249839	array([[-1.877763, -3.094776]], dtype=float32)

time = 60409	action = 0	current_phase = 1	next_phase = 0	reward = -0.169293	array([[-2.0221174, -3.9059527]], dtype=float32)

time = 60414	action = 1	current_phase = 1	next_phase = 0	reward = -0.473506	array([[-2.4866765, -2.30595  ]], dtype=float32)

time = 60422	action = 0	current_phase = 0	next_phase = 1	reward = -0.621903	array([[-2.3081222, -3.8017173]], dtype=float32)

time = 60427	action = 0	current_phase = 0	next_phase = 1	reward = -0.466086	array([[-2.211276 , -2.9107401]], dtype=float32)

time = 60432	action = 0	current_phase = 0	next_phase = 1	reward = -0.319201	array([[-2.2370434, -3.2112155]], dtype=float32)

time = 60437	action = 0	current_phase = 0	next_phase = 1	reward = -0.183570	array([[-2.2695498, -3.1694474]], dtype=float32)

time = 60442	action = 0	current_phase = 0	next_phase = 1	reward = 0.135071	array([[-2.6745627, -4.431402 ]], dtype=float32)

time = 60447	action = 1	current_phase = 0	next_phase = 1	reward = -1.789025	array([[-6.531121 , -3.4606743]], dtype=float32)

time = 60455	action = 0	current_phase = 1	next_phase = 0	reward = -0.529625	array([[-2.075115 , -3.3089418]], dtype=float32)

time = 60460	action = 0	current_phase = 1	next_phase = 0	reward = -0.377129	array([[-1.9113195, -3.146312 ]], dtype=float32)

time = 60465	action = 0	current_phase = 1	next_phase = 0	reward = -0.221559	array([[-1.8708787, -3.0940857]], dtype=float32)

time = 60470	action = 0	current_phase = 1	next_phase = 0	reward = 0.370045	array([[-2.1428034, -3.9216056]], dtype=float32)

time = 60475	action = 1	current_phase = 1	next_phase = 0	reward = -1.299713	array([[-3.2626576, -3.1658201]], dtype=float32)

time = 60483	action = 0	current_phase = 0	next_phase = 1	reward = -0.586755	array([[-2.287781, -3.758862]], dtype=float32)

time = 60488	action = 0	current_phase = 0	next_phase = 1	reward = -0.434884	array([[-2.0996966, -3.0787745]], dtype=float32)

time = 60493	action = 0	current_phase = 0	next_phase = 1	reward = -0.284212	array([[-2.238588 , -3.2145956]], dtype=float32)

time = 60498	action = 0	current_phase = 0	next_phase = 1	reward = -0.162028	array([[-2.415735 , -3.2888267]], dtype=float32)

time = 60503	action = 0	current_phase = 0	next_phase = 1	reward = -0.039246	array([[-2.8367405, -4.4259634]], dtype=float32)

time = 60508	action = 1	current_phase = 0	next_phase = 1	reward = -1.904431	array([[-6.567645 , -3.5037613]], dtype=float32)

time = 60516	action = 0	current_phase = 1	next_phase = 0	reward = -0.500689	array([[-2.0736935, -3.3120785]], dtype=float32)

time = 60521	action = 0	current_phase = 1	next_phase = 0	reward = -0.345168	array([[-1.9121702, -3.1464882]], dtype=float32)

time = 60526	action = 0	current_phase = 1	next_phase = 0	reward = -0.196395	array([[-1.9379989, -3.1641273]], dtype=float32)

time = 60531	action = 0	current_phase = 1	next_phase = 0	reward = 0.330959	array([[-2.2858179, -4.2261925]], dtype=float32)

time = 60536	action = 1	current_phase = 1	next_phase = 0	reward = -1.554800	array([[-3.3575315, -3.2900977]], dtype=float32)

time = 60544	action = 0	current_phase = 0	next_phase = 1	reward = -0.557086	array([[-2.1628804, -3.1309652]], dtype=float32)

time = 60549	action = 0	current_phase = 0	next_phase = 1	reward = -0.403657	array([[-2.0101776, -3.0384736]], dtype=float32)

time = 60554	action = 0	current_phase = 0	next_phase = 1	reward = -0.259851	array([[-1.966639 , -3.3471363]], dtype=float32)

time = 60559	action = 0	current_phase = 0	next_phase = 1	reward = -0.182808	array([[-2.001937 , -3.1520267]], dtype=float32)

time = 60564	action = 1	current_phase = 0	next_phase = 1	reward = -0.566992	array([[-5.6611466, -2.2858884]], dtype=float32)

time = 60572	action = 0	current_phase = 1	next_phase = 0	reward = -0.614568	array([[-2.2848506, -3.1600626]], dtype=float32)

time = 60577	action = 0	current_phase = 1	next_phase = 0	reward = -0.458871	array([[-2.104306 , -3.1388407]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0114 - val_loss: 0.0110

Epoch 2/50

 - 4s - loss: 0.0122 - val_loss: 0.0093

Epoch 3/50

 - 4s - loss: 0.0108 - val_loss: 0.0096

Epoch 4/50

 - 4s - loss: 0.0087 - val_loss: 0.0093

Epoch 5/50

 - 4s - loss: 0.0094 - val_loss: 0.0113

Epoch 6/50

 - 4s - loss: 0.0112 - val_loss: 0.0111

Epoch 7/50

 - 4s - loss: 0.0077 - val_loss: 0.0124

Epoch 8/50

 - 4s - loss: 0.0091 - val_loss: 0.0113

Epoch 9/50

 - 4s - loss: 0.0083 - val_loss: 0.0100

Epoch 10/50

 - 4s - loss: 0.0086 - val_loss: 0.0100

Epoch 11/50

 - 4s - loss: 0.0083 - val_loss: 0.0112

Epoch 12/50

 - 4s - loss: 0.0077 - val_loss: 0.0106

Epoch 13/50

 - 4s - loss: 0.0087 - val_loss: 0.0106

Epoch 14/50

 - 4s - loss: 0.0076 - val_loss: 0.0100

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 60582	action = 0	current_phase = 1	next_phase = 0	reward = -0.293297	array([[-2.1401935, -3.1545348]], dtype=float32)

time = 60587	action = 0	current_phase = 1	next_phase = 0	reward = -0.164391	array([[-2.3023245, -3.2715113]], dtype=float32)

time = 60592	action = 0	current_phase = 1	next_phase = 0	reward = 0.201909	array([[-2.624321, -4.405674]], dtype=float32)

time = 60597	action = 1	current_phase = 1	next_phase = 0	reward = -1.779731	array([[-6.2339435, -3.453476 ]], dtype=float32)

time = 60605	action = 0	current_phase = 0	next_phase = 1	reward = -0.524047	array([[-2.15059  , -3.2595387]], dtype=float32)

time = 60610	action = 0	current_phase = 0	next_phase = 1	reward = -0.378028	array([[-2.0122764, -3.0294573]], dtype=float32)

time = 60615	action = 0	current_phase = 0	next_phase = 1	reward = -0.227489	array([[-1.932004 , -3.3488789]], dtype=float32)

time = 60620	action = 0	current_phase = 0	next_phase = 1	reward = 0.351858	array([[-2.1786575, -3.8361685]], dtype=float32)

time = 60625	action = 1	current_phase = 0	next_phase = 1	reward = -1.363526	array([[-4.7946234, -3.0483828]], dtype=float32)

time = 60633	action = 0	current_phase = 1	next_phase = 0	reward = -0.587803	array([[-2.1081402, -3.105528 ]], dtype=float32)

time = 60638	action = 0	current_phase = 1	next_phase = 0	reward = -0.434437	array([[-1.9258558, -3.113497 ]], dtype=float32)

time = 60643	action = 0	current_phase = 1	next_phase = 0	reward = -0.280736	array([[-2.1350071, -3.1541634]], dtype=float32)

time = 60648	action = 0	current_phase = 1	next_phase = 0	reward = -0.167404	array([[-2.2699213, -3.2647731]], dtype=float32)

time = 60653	action = 0	current_phase = 1	next_phase = 0	reward = 0.069477	array([[-2.7616525, -4.258998 ]], dtype=float32)

time = 60658	action = 1	current_phase = 1	next_phase = 0	reward = -1.893394	array([[-6.311186 , -3.5717552]], dtype=float32)

time = 60666	action = 0	current_phase = 0	next_phase = 1	reward = -0.493407	array([[-2.1331706, -3.2547464]], dtype=float32)

time = 60671	action = 0	current_phase = 0	next_phase = 1	reward = -0.334028	array([[-2.0176117, -3.0296729]], dtype=float32)

time = 60676	action = 0	current_phase = 0	next_phase = 1	reward = -0.193402	array([[-2.140923 , -3.0726998]], dtype=float32)

time = 60681	action = 0	current_phase = 0	next_phase = 1	reward = 0.285001	array([[-2.3567708, -4.124667 ]], dtype=float32)

time = 60686	action = 1	current_phase = 0	next_phase = 1	reward = -1.610851	array([[-4.4722757, -3.2420044]], dtype=float32)

time = 60694	action = 0	current_phase = 1	next_phase = 0	reward = -0.556906	array([[-2.0908785, -3.1048732]], dtype=float32)

time = 60699	action = 0	current_phase = 1	next_phase = 0	reward = -0.395615	array([[-1.9213064, -3.1137362]], dtype=float32)

time = 60704	action = 0	current_phase = 1	next_phase = 0	reward = -0.245634	array([[-1.9145455, -3.0777593]], dtype=float32)

time = 60709	action = 0	current_phase = 1	next_phase = 0	reward = -0.171323	array([[-2.0077434, -3.8778045]], dtype=float32)

time = 60714	action = 1	current_phase = 1	next_phase = 0	reward = -0.468853	array([[-2.4523873, -2.3377964]], dtype=float32)

time = 60722	action = 0	current_phase = 0	next_phase = 1	reward = -0.629864	array([[-2.3502192, -3.7918456]], dtype=float32)

time = 60727	action = 0	current_phase = 0	next_phase = 1	reward = -0.474562	array([[-2.2384183, -2.8999274]], dtype=float32)

time = 60732	action = 0	current_phase = 0	next_phase = 1	reward = -0.323475	array([[-2.2170897, -3.2063434]], dtype=float32)

time = 60737	action = 0	current_phase = 0	next_phase = 1	reward = -0.186294	array([[-2.3439052, -3.240191 ]], dtype=float32)

time = 60742	action = 0	current_phase = 0	next_phase = 1	reward = 0.244892	array([[-2.5950458, -4.42562  ]], dtype=float32)

time = 60747	action = 1	current_phase = 0	next_phase = 1	reward = -1.722368	array([[-6.2136497, -3.3847036]], dtype=float32)

time = 60755	action = 0	current_phase = 1	next_phase = 0	reward = -0.522193	array([[-2.032268, -3.283171]], dtype=float32)

time = 60760	action = 0	current_phase = 1	next_phase = 0	reward = -0.366142	array([[-1.9214202, -3.11377  ]], dtype=float32)

time = 60765	action = 0	current_phase = 1	next_phase = 0	reward = -0.216566	array([[-1.907518 , -3.0844276]], dtype=float32)

time = 60770	action = 0	current_phase = 1	next_phase = 0	reward = 0.357350	array([[-2.1003668, -3.8785903]], dtype=float32)

time = 60775	action = 1	current_phase = 1	next_phase = 0	reward = -1.304468	array([[-3.2422383, -3.1679447]], dtype=float32)

time = 60783	action = 0	current_phase = 0	next_phase = 1	reward = -0.586717	array([[-2.3441598, -3.787989 ]], dtype=float32)

time = 60788	action = 0	current_phase = 0	next_phase = 1	reward = -0.427245	array([[-2.2349014, -2.9004705]], dtype=float32)

time = 60793	action = 0	current_phase = 0	next_phase = 1	reward = -0.273347	array([[-2.219922 , -3.2160563]], dtype=float32)

time = 60798	action = 0	current_phase = 0	next_phase = 1	reward = -0.164197	array([[-2.3970697, -3.2875693]], dtype=float32)

time = 60803	action = 0	current_phase = 0	next_phase = 1	reward = -0.060977	array([[-3.460043, -4.417173]], dtype=float32)

time = 60808	action = 1	current_phase = 0	next_phase = 1	reward = -1.902017	array([[-6.5582232, -3.5225263]], dtype=float32)

time = 60816	action = 0	current_phase = 1	next_phase = 0	reward = -0.493356	array([[-2.0400207, -3.2889743]], dtype=float32)

time = 60821	action = 0	current_phase = 1	next_phase = 0	reward = -0.338831	array([[-1.9269078, -3.115156 ]], dtype=float32)

time = 60826	action = 0	current_phase = 1	next_phase = 0	reward = -0.191552	array([[-2.040746, -3.203935]], dtype=float32)

time = 60831	action = 0	current_phase = 1	next_phase = 0	reward = 0.308444	array([[-2.330117 , -4.2188506]], dtype=float32)

time = 60836	action = 1	current_phase = 1	next_phase = 0	reward = -1.552871	array([[-5.7216706, -3.2976072]], dtype=float32)

time = 60844	action = 0	current_phase = 0	next_phase = 1	reward = -0.556862	array([[-2.175241 , -3.1172338]], dtype=float32)

time = 60849	action = 0	current_phase = 0	next_phase = 1	reward = -0.400347	array([[-2.0121167, -3.0296247]], dtype=float32)

time = 60854	action = 0	current_phase = 0	next_phase = 1	reward = -0.255721	array([[-1.9320798, -3.3487725]], dtype=float32)

time = 60859	action = 0	current_phase = 0	next_phase = 1	reward = -0.191884	array([[-2.046804 , -3.2432418]], dtype=float32)

time = 60864	action = 1	current_phase = 0	next_phase = 1	reward = -1.423497	array([[-5.7155457, -2.5059261]], dtype=float32)

time = 60872	action = 0	current_phase = 1	next_phase = 0	reward = -1.155502	array([[-3.3333857, -3.4270499]], dtype=float32)

time = 60877	action = 0	current_phase = 1	next_phase = 0	reward = -1.025313	array([[-3.189229 , -3.3611548]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0164 - val_loss: 0.0135

Epoch 2/50

 - 4s - loss: 0.0145 - val_loss: 0.0147

Epoch 3/50

 - 4s - loss: 0.0156 - val_loss: 0.0132

Epoch 4/50

 - 4s - loss: 0.0131 - val_loss: 0.0133

Epoch 5/50

 - 4s - loss: 0.0119 - val_loss: 0.0135

Epoch 6/50

 - 4s - loss: 0.0141 - val_loss: 0.0128

Epoch 7/50

 - 4s - loss: 0.0114 - val_loss: 0.0128

Epoch 8/50

 - 4s - loss: 0.0135 - val_loss: 0.0142

Epoch 9/50

 - 4s - loss: 0.0171 - val_loss: 0.0136

Epoch 10/50

 - 4s - loss: 0.0154 - val_loss: 0.0136

Epoch 11/50

 - 4s - loss: 0.0141 - val_loss: 0.0136

Epoch 12/50

 - 4s - loss: 0.0122 - val_loss: 0.0152

Epoch 13/50

 - 4s - loss: 0.0152 - val_loss: 0.0137

Epoch 14/50

 - 4s - loss: 0.0117 - val_loss: 0.0129

Epoch 15/50

 - 4s - loss: 0.0097 - val_loss: 0.0141

Epoch 16/50

 - 4s - loss: 0.0120 - val_loss: 0.0148

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 60882	action = 0	current_phase = 1	next_phase = 0	reward = -0.882008	array([[-2.5770361, -3.2864468]], dtype=float32)

time = 60887	action = 0	current_phase = 1	next_phase = 0	reward = -0.764589	array([[-2.6680765, -3.4038103]], dtype=float32)

time = 60892	action = 0	current_phase = 1	next_phase = 0	reward = -0.471493	array([[-2.96753  , -4.3251534]], dtype=float32)

time = 60897	action = 1	current_phase = 1	next_phase = 0	reward = -1.768684	array([[-6.328813 , -3.6046498]], dtype=float32)

time = 60905	action = 0	current_phase = 0	next_phase = 1	reward = -0.531431	array([[-2.190974 , -3.2643075]], dtype=float32)

time = 60910	action = 0	current_phase = 0	next_phase = 1	reward = -0.375665	array([[-2.000062 , -3.0404925]], dtype=float32)

time = 60915	action = 0	current_phase = 0	next_phase = 1	reward = -0.228531	array([[-1.931407 , -3.3698382]], dtype=float32)

time = 60920	action = 0	current_phase = 0	next_phase = 1	reward = 0.368848	array([[-2.161354, -3.890468]], dtype=float32)

time = 60925	action = 1	current_phase = 0	next_phase = 1	reward = -1.306759	array([[-4.8132033, -3.0694585]], dtype=float32)

time = 60933	action = 0	current_phase = 1	next_phase = 0	reward = -0.591114	array([[-2.137634 , -3.1260593]], dtype=float32)

time = 60938	action = 0	current_phase = 1	next_phase = 0	reward = -0.438459	array([[-2.0036008, -3.1508782]], dtype=float32)

time = 60943	action = 0	current_phase = 1	next_phase = 0	reward = -0.286389	array([[-2.1895201, -3.1847415]], dtype=float32)

time = 60948	action = 0	current_phase = 1	next_phase = 0	reward = -0.166384	array([[-2.26276  , -3.2927804]], dtype=float32)

time = 60953	action = 0	current_phase = 1	next_phase = 0	reward = 0.142820	array([[-2.656246, -4.181964]], dtype=float32)

time = 60958	action = 1	current_phase = 1	next_phase = 0	reward = -1.894837	array([[-6.2837825, -3.5604692]], dtype=float32)

time = 60966	action = 0	current_phase = 0	next_phase = 1	reward = -0.500832	array([[-2.1518586, -3.271507 ]], dtype=float32)

time = 60971	action = 0	current_phase = 0	next_phase = 1	reward = -0.348675	array([[-2.0306764, -3.0350494]], dtype=float32)

time = 60976	action = 0	current_phase = 0	next_phase = 1	reward = -0.202717	array([[-2.1622431, -3.0924437]], dtype=float32)

time = 60981	action = 0	current_phase = 0	next_phase = 1	reward = 0.291207	array([[-2.3183613, -4.134621 ]], dtype=float32)

time = 60986	action = 1	current_phase = 0	next_phase = 1	reward = -1.610447	array([[-4.481949, -3.339147]], dtype=float32)

time = 60994	action = 0	current_phase = 1	next_phase = 0	reward = -0.554301	array([[-2.1286383, -3.1248431]], dtype=float32)

time = 60999	action = 0	current_phase = 1	next_phase = 0	reward = -0.405941	array([[-1.9428544, -3.1342547]], dtype=float32)

time = 61004	action = 0	current_phase = 1	next_phase = 0	reward = -0.248202	array([[-1.9193223, -3.084364 ]], dtype=float32)

time = 61009	action = 0	current_phase = 1	next_phase = 0	reward = -0.172014	array([[-2.0240872, -3.9004564]], dtype=float32)

time = 61014	action = 1	current_phase = 1	next_phase = 0	reward = -0.521997	array([[-2.4838188, -2.3537812]], dtype=float32)

time = 61022	action = 0	current_phase = 0	next_phase = 1	reward = -0.611719	array([[-2.3882155, -3.8157065]], dtype=float32)

time = 61027	action = 0	current_phase = 0	next_phase = 1	reward = -0.450639	array([[-2.2249596, -2.9145162]], dtype=float32)

time = 61032	action = 0	current_phase = 0	next_phase = 1	reward = -0.298110	array([[-2.242884, -3.228334]], dtype=float32)

time = 61037	action = 0	current_phase = 0	next_phase = 1	reward = -0.166821	array([[-2.39033  , -3.2780385]], dtype=float32)

time = 61042	action = 0	current_phase = 0	next_phase = 1	reward = 0.168931	array([[-2.603563, -4.423682]], dtype=float32)

time = 61047	action = 1	current_phase = 0	next_phase = 1	reward = -1.783154	array([[-6.4342165, -3.4744275]], dtype=float32)

time = 61055	action = 0	current_phase = 1	next_phase = 0	reward = -0.532869	array([[-2.0608113, -3.3129344]], dtype=float32)

time = 61060	action = 0	current_phase = 1	next_phase = 0	reward = -0.383420	array([[-1.9601893, -3.149628 ]], dtype=float32)

time = 61065	action = 0	current_phase = 1	next_phase = 0	reward = -0.224598	array([[-1.9556229, -3.1195369]], dtype=float32)

time = 61070	action = 0	current_phase = 1	next_phase = 0	reward = 0.075303	array([[-2.1596305, -4.039256 ]], dtype=float32)

time = 61075	action = 0	current_phase = 1	next_phase = 0	reward = -0.504244	array([[-2.9381423, -3.0154643]], dtype=float32)

time = 61080	action = 1	current_phase = 1	next_phase = 0	reward = -2.111340	array([[-6.3217   , -3.6123426]], dtype=float32)

time = 61088	action = 0	current_phase = 0	next_phase = 1	reward = -0.432822	array([[-2.1563678, -3.274624 ]], dtype=float32)

time = 61093	action = 0	current_phase = 0	next_phase = 1	reward = -0.278384	array([[-2.2151952, -3.2329376]], dtype=float32)

time = 61098	action = 0	current_phase = 0	next_phase = 1	reward = -0.163830	array([[-2.405735 , -3.2906766]], dtype=float32)

time = 61103	action = 0	current_phase = 0	next_phase = 1	reward = 0.020522	array([[-2.6840966, -4.2944674]], dtype=float32)

time = 61108	action = 1	current_phase = 0	next_phase = 1	reward = -1.900049	array([[-4.9547253, -3.5575957]], dtype=float32)

time = 61116	action = 0	current_phase = 1	next_phase = 0	reward = -0.489082	array([[-2.0585525, -3.3211048]], dtype=float32)

time = 61121	action = 0	current_phase = 1	next_phase = 0	reward = -0.330222	array([[-1.9540414, -3.137728 ]], dtype=float32)

time = 61126	action = 0	current_phase = 1	next_phase = 0	reward = -0.189534	array([[-2.0484428, -3.218353 ]], dtype=float32)

time = 61131	action = 0	current_phase = 1	next_phase = 0	reward = 0.299028	array([[-2.3295708, -4.227045 ]], dtype=float32)

time = 61136	action = 1	current_phase = 1	next_phase = 0	reward = -1.662571	array([[-5.742425 , -3.3431115]], dtype=float32)

time = 61144	action = 0	current_phase = 0	next_phase = 1	reward = -0.564299	array([[-2.1767912, -3.1325698]], dtype=float32)

time = 61149	action = 0	current_phase = 0	next_phase = 1	reward = -0.408296	array([[-2.000067 , -3.0403724]], dtype=float32)

time = 61154	action = 0	current_phase = 0	next_phase = 1	reward = -0.257681	array([[-1.9315226, -3.3697615]], dtype=float32)

time = 61159	action = 0	current_phase = 0	next_phase = 1	reward = -0.172515	array([[-2.046571 , -3.1949382]], dtype=float32)

time = 61164	action = 1	current_phase = 0	next_phase = 1	reward = -0.476839	array([[-5.723196 , -2.3258688]], dtype=float32)

time = 61172	action = 0	current_phase = 1	next_phase = 0	reward = -0.620970	array([[-2.2931423, -3.1474977]], dtype=float32)

time = 61177	action = 0	current_phase = 1	next_phase = 0	reward = -0.469217	array([[-2.1243064, -3.1230621]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0135 - val_loss: 0.0046

Epoch 2/50

 - 4s - loss: 0.0142 - val_loss: 0.0046

Epoch 3/50

 - 4s - loss: 0.0122 - val_loss: 0.0050

Epoch 4/50

 - 4s - loss: 0.0125 - val_loss: 0.0054

Epoch 5/50

 - 4s - loss: 0.0144 - val_loss: 0.0049

Epoch 6/50

 - 4s - loss: 0.0133 - val_loss: 0.0061

Epoch 7/50

 - 4s - loss: 0.0149 - val_loss: 0.0052

Epoch 8/50

 - 4s - loss: 0.0103 - val_loss: 0.0054

Epoch 9/50

 - 4s - loss: 0.0115 - val_loss: 0.0055

Epoch 10/50

 - 4s - loss: 0.0126 - val_loss: 0.0057

Epoch 11/50

 - 4s - loss: 0.0113 - val_loss: 0.0054

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 61182	action = 0	current_phase = 1	next_phase = 0	reward = -0.316888	array([[-2.083538 , -3.1812537]], dtype=float32)

time = 61187	action = 0	current_phase = 1	next_phase = 0	reward = -0.177611	array([[-2.2708054, -3.2741268]], dtype=float32)

time = 61192	action = 0	current_phase = 1	next_phase = 0	reward = 0.264654	array([[-2.6163914, -4.4540715]], dtype=float32)

time = 61197	action = 1	current_phase = 1	next_phase = 0	reward = -1.677512	array([[-6.232572 , -3.4891572]], dtype=float32)

time = 61205	action = 0	current_phase = 0	next_phase = 1	reward = -0.528165	array([[-2.1443048, -3.2675893]], dtype=float32)

time = 61210	action = 0	current_phase = 0	next_phase = 1	reward = -0.374609	array([[-1.9626023, -3.0230308]], dtype=float32)

time = 61215	action = 0	current_phase = 0	next_phase = 1	reward = -0.216628	array([[-1.8933221, -3.3667529]], dtype=float32)

time = 61220	action = 0	current_phase = 0	next_phase = 1	reward = 0.051818	array([[-2.12215  , -3.8776953]], dtype=float32)

time = 61225	action = 1	current_phase = 0	next_phase = 1	reward = -1.139963	array([[-5.540077 , -2.6579037]], dtype=float32)

time = 61233	action = 0	current_phase = 1	next_phase = 0	reward = -0.588242	array([[-2.0917368, -3.125912 ]], dtype=float32)

time = 61238	action = 0	current_phase = 1	next_phase = 0	reward = -0.441284	array([[-1.9559039, -3.152346 ]], dtype=float32)

time = 61243	action = 0	current_phase = 1	next_phase = 0	reward = -0.290383	array([[-2.1023355, -3.1837072]], dtype=float32)

time = 61248	action = 0	current_phase = 1	next_phase = 0	reward = -0.169208	array([[-2.2231777, -3.2993677]], dtype=float32)

time = 61253	action = 0	current_phase = 1	next_phase = 0	reward = 0.116386	array([[-2.6858504, -4.422225 ]], dtype=float32)

time = 61258	action = 1	current_phase = 1	next_phase = 0	reward = -1.902927	array([[-6.3122544, -3.6103325]], dtype=float32)

time = 61266	action = 0	current_phase = 0	next_phase = 1	reward = -0.501705	array([[-2.122631 , -3.2604084]], dtype=float32)

time = 61271	action = 0	current_phase = 0	next_phase = 1	reward = -0.347649	array([[-1.9836849, -3.020124 ]], dtype=float32)

time = 61276	action = 0	current_phase = 0	next_phase = 1	reward = -0.199059	array([[-2.1203194, -3.0892055]], dtype=float32)

time = 61281	action = 0	current_phase = 0	next_phase = 1	reward = 0.323431	array([[-2.3144126, -4.1576476]], dtype=float32)

time = 61286	action = 1	current_phase = 0	next_phase = 1	reward = -1.605407	array([[-4.617083 , -3.2086196]], dtype=float32)

time = 61294	action = 0	current_phase = 1	next_phase = 0	reward = -0.558232	array([[-2.0851135, -3.1249487]], dtype=float32)

time = 61299	action = 0	current_phase = 1	next_phase = 0	reward = -0.408319	array([[-1.8824329, -3.1315393]], dtype=float32)

time = 61304	action = 0	current_phase = 1	next_phase = 0	reward = -0.254968	array([[-1.8704829, -3.103358 ]], dtype=float32)

time = 61309	action = 0	current_phase = 1	next_phase = 0	reward = -0.171781	array([[-2.0345855, -3.9449728]], dtype=float32)

time = 61314	action = 1	current_phase = 1	next_phase = 0	reward = -0.425653	array([[-2.4443386, -2.38172  ]], dtype=float32)

time = 61322	action = 0	current_phase = 0	next_phase = 1	reward = -0.620926	array([[-2.3506255, -3.8175392]], dtype=float32)

time = 61327	action = 0	current_phase = 0	next_phase = 1	reward = -0.470765	array([[-2.1896086, -2.9070716]], dtype=float32)

time = 61332	action = 0	current_phase = 0	next_phase = 1	reward = -0.323997	array([[-2.164315, -3.218411]], dtype=float32)

time = 61337	action = 0	current_phase = 0	next_phase = 1	reward = -0.183853	array([[-2.2019403, -3.1489847]], dtype=float32)

time = 61342	action = 0	current_phase = 0	next_phase = 1	reward = 0.238747	array([[-2.600934, -4.4246  ]], dtype=float32)

time = 61347	action = 1	current_phase = 0	next_phase = 1	reward = -1.781797	array([[-6.1602883, -3.415138 ]], dtype=float32)

time = 61355	action = 0	current_phase = 1	next_phase = 0	reward = -0.536079	array([[-2.0016017, -3.3193884]], dtype=float32)

time = 61360	action = 0	current_phase = 1	next_phase = 0	reward = -0.389753	array([[-1.8876433, -3.1364784]], dtype=float32)

time = 61365	action = 0	current_phase = 1	next_phase = 0	reward = -0.239671	array([[-1.8636292, -3.088145 ]], dtype=float32)

time = 61370	action = 0	current_phase = 1	next_phase = 0	reward = -0.214108	array([[-2.0869143, -3.946422 ]], dtype=float32)

time = 61375	action = 1	current_phase = 1	next_phase = 0	reward = -0.741046	array([[-2.607676 , -2.4636507]], dtype=float32)

time = 61383	action = 0	current_phase = 0	next_phase = 1	reward = -0.582058	array([[-2.3508697, -3.8146966]], dtype=float32)

time = 61388	action = 0	current_phase = 0	next_phase = 1	reward = -0.426236	array([[-2.1872358, -2.9047434]], dtype=float32)

time = 61393	action = 0	current_phase = 0	next_phase = 1	reward = -0.262479	array([[-2.1747139, -3.2340877]], dtype=float32)

time = 61398	action = 0	current_phase = 0	next_phase = 1	reward = -0.161795	array([[-2.420839, -3.311297]], dtype=float32)

time = 61403	action = 0	current_phase = 0	next_phase = 1	reward = -0.059404	array([[-3.507337 , -4.4184427]], dtype=float32)

time = 61408	action = 1	current_phase = 0	next_phase = 1	reward = -1.896466	array([[-6.541229 , -3.5414467]], dtype=float32)

time = 61416	action = 0	current_phase = 1	next_phase = 0	reward = -0.486286	array([[-1.9958553, -3.3206992]], dtype=float32)

time = 61421	action = 0	current_phase = 1	next_phase = 0	reward = -0.326099	array([[-1.8859429, -3.1328125]], dtype=float32)

time = 61426	action = 0	current_phase = 1	next_phase = 0	reward = -0.186927	array([[-2.0019464, -3.2302802]], dtype=float32)

time = 61431	action = 0	current_phase = 1	next_phase = 0	reward = 0.308237	array([[-2.28872 , -4.250047]], dtype=float32)

time = 61436	action = 1	current_phase = 1	next_phase = 0	reward = -1.613303	array([[-5.738566 , -3.3390167]], dtype=float32)

time = 61444	action = 0	current_phase = 0	next_phase = 1	reward = -0.562833	array([[-2.1305861, -3.1223419]], dtype=float32)

time = 61449	action = 0	current_phase = 0	next_phase = 1	reward = -0.411874	array([[-1.9621916, -3.023433 ]], dtype=float32)

time = 61454	action = 0	current_phase = 0	next_phase = 1	reward = -0.265322	array([[-1.8942944, -3.3659408]], dtype=float32)

time = 61459	action = 0	current_phase = 0	next_phase = 1	reward = -0.176209	array([[-2.0062194, -3.1552505]], dtype=float32)

time = 61464	action = 1	current_phase = 0	next_phase = 1	reward = -0.507246	array([[-5.7187533, -2.344145 ]], dtype=float32)

time = 61472	action = 0	current_phase = 1	next_phase = 0	reward = -0.612200	array([[-2.229495 , -3.1471236]], dtype=float32)

time = 61477	action = 0	current_phase = 1	next_phase = 0	reward = -0.458923	array([[-2.0800238, -3.1239352]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0140 - val_loss: 0.0111

Epoch 2/50

 - 4s - loss: 0.0137 - val_loss: 0.0117

Epoch 3/50

 - 4s - loss: 0.0121 - val_loss: 0.0106

Epoch 4/50

 - 4s - loss: 0.0137 - val_loss: 0.0094

Epoch 5/50

 - 4s - loss: 0.0110 - val_loss: 0.0098

Epoch 6/50

 - 4s - loss: 0.0121 - val_loss: 0.0091

Epoch 7/50

 - 4s - loss: 0.0132 - val_loss: 0.0084

Epoch 8/50

 - 4s - loss: 0.0115 - val_loss: 0.0101

Epoch 9/50

 - 4s - loss: 0.0098 - val_loss: 0.0115

Epoch 10/50

 - 4s - loss: 0.0138 - val_loss: 0.0123

Epoch 11/50

 - 4s - loss: 0.0115 - val_loss: 0.0136

Epoch 12/50

 - 4s - loss: 0.0084 - val_loss: 0.0124

Epoch 13/50

 - 4s - loss: 0.0115 - val_loss: 0.0113

Epoch 14/50

 - 4s - loss: 0.0110 - val_loss: 0.0109

Epoch 15/50

 - 4s - loss: 0.0088 - val_loss: 0.0130

Epoch 16/50

 - 4s - loss: 0.0135 - val_loss: 0.0124

Epoch 17/50

 - 4s - loss: 0.0068 - val_loss: 0.0135

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 61482	action = 0	current_phase = 1	next_phase = 0	reward = -0.311001	array([[-2.1558115, -3.164323 ]], dtype=float32)

time = 61487	action = 0	current_phase = 1	next_phase = 0	reward = -0.178985	array([[-2.2585213, -3.267374 ]], dtype=float32)

time = 61492	action = 0	current_phase = 1	next_phase = 0	reward = 0.190942	array([[-2.6277244, -4.4287333]], dtype=float32)

time = 61497	action = 1	current_phase = 1	next_phase = 0	reward = -1.785913	array([[-6.260129 , -3.5000067]], dtype=float32)

time = 61505	action = 0	current_phase = 0	next_phase = 1	reward = -0.538951	array([[-2.1697986, -3.2593098]], dtype=float32)

time = 61510	action = 0	current_phase = 0	next_phase = 1	reward = -0.382201	array([[-1.9989227, -3.008664 ]], dtype=float32)

time = 61515	action = 0	current_phase = 0	next_phase = 1	reward = -0.229297	array([[-1.9072306, -3.365252 ]], dtype=float32)

time = 61520	action = 0	current_phase = 0	next_phase = 1	reward = 0.069300	array([[-2.137771 , -3.8632321]], dtype=float32)

time = 61525	action = 1	current_phase = 0	next_phase = 1	reward = -1.132149	array([[-5.6258163, -2.628737 ]], dtype=float32)

time = 61533	action = 0	current_phase = 1	next_phase = 0	reward = -0.582072	array([[-2.1092649, -3.100368 ]], dtype=float32)

time = 61538	action = 0	current_phase = 1	next_phase = 0	reward = -0.430229	array([[-1.9186373, -3.1024835]], dtype=float32)

time = 61543	action = 0	current_phase = 1	next_phase = 0	reward = -0.264207	array([[-2.1444902, -3.1625526]], dtype=float32)

time = 61548	action = 0	current_phase = 1	next_phase = 0	reward = -0.160609	array([[-2.256076 , -3.2709758]], dtype=float32)

time = 61553	action = 0	current_phase = 1	next_phase = 0	reward = 0.060338	array([[-2.7549498, -4.1978626]], dtype=float32)

time = 61558	action = 1	current_phase = 1	next_phase = 0	reward = -1.897704	array([[-6.2911215, -3.5361135]], dtype=float32)

time = 61566	action = 0	current_phase = 0	next_phase = 1	reward = -0.488059	array([[-2.156313, -3.255849]], dtype=float32)

time = 61571	action = 0	current_phase = 0	next_phase = 1	reward = -0.317562	array([[-2.0137217, -3.0107527]], dtype=float32)

time = 61576	action = 0	current_phase = 0	next_phase = 1	reward = -0.180732	array([[-2.1470592, -3.0939817]], dtype=float32)

time = 61581	action = 0	current_phase = 0	next_phase = 1	reward = 0.211248	array([[-2.3479486, -4.1439414]], dtype=float32)

time = 61586	action = 1	current_phase = 0	next_phase = 1	reward = -1.666983	array([[-4.573512, -3.473581]], dtype=float32)

time = 61594	action = 0	current_phase = 1	next_phase = 0	reward = -0.560335	array([[-2.09925  , -3.0990546]], dtype=float32)

time = 61599	action = 0	current_phase = 1	next_phase = 0	reward = -0.412582	array([[-1.9136556, -3.1011336]], dtype=float32)

time = 61604	action = 0	current_phase = 1	next_phase = 0	reward = -0.267630	array([[-1.8863275, -3.0509486]], dtype=float32)

time = 61609	action = 0	current_phase = 1	next_phase = 0	reward = -0.171720	array([[-2.0612624, -3.9031823]], dtype=float32)

time = 61614	action = 1	current_phase = 1	next_phase = 0	reward = -0.484089	array([[-2.4113507, -2.253786 ]], dtype=float32)

time = 61622	action = 0	current_phase = 0	next_phase = 1	reward = -0.616352	array([[-2.39113  , -3.8147094]], dtype=float32)

time = 61627	action = 0	current_phase = 0	next_phase = 1	reward = -0.456879	array([[-2.2346554, -2.8888333]], dtype=float32)

time = 61632	action = 0	current_phase = 0	next_phase = 1	reward = -0.300990	array([[-2.1888034, -3.2222462]], dtype=float32)

time = 61637	action = 0	current_phase = 0	next_phase = 1	reward = -0.172418	array([[-2.3390288, -3.2172043]], dtype=float32)

time = 61642	action = 0	current_phase = 0	next_phase = 1	reward = 0.195865	array([[-2.6333632, -4.3931355]], dtype=float32)

time = 61647	action = 1	current_phase = 0	next_phase = 1	reward = -1.734236	array([[-6.445886 , -3.4222548]], dtype=float32)

time = 61655	action = 0	current_phase = 1	next_phase = 0	reward = -0.539471	array([[-2.0631008, -3.2971857]], dtype=float32)

time = 61660	action = 0	current_phase = 1	next_phase = 0	reward = -0.390464	array([[-1.9208558, -3.1070235]], dtype=float32)

time = 61665	action = 0	current_phase = 1	next_phase = 0	reward = -0.245534	array([[-1.8830608, -3.0522919]], dtype=float32)

time = 61670	action = 0	current_phase = 1	next_phase = 0	reward = -0.217350	array([[-2.124698 , -3.9864874]], dtype=float32)

time = 61675	action = 1	current_phase = 1	next_phase = 0	reward = -0.791832	array([[-2.5183039, -2.3281233]], dtype=float32)

time = 61683	action = 0	current_phase = 0	next_phase = 1	reward = -0.578185	array([[-2.3882608, -3.8050914]], dtype=float32)

time = 61688	action = 0	current_phase = 0	next_phase = 1	reward = -0.433210	array([[-2.232615 , -2.8872721]], dtype=float32)

time = 61693	action = 0	current_phase = 0	next_phase = 1	reward = -0.277850	array([[-2.1980467, -3.2244155]], dtype=float32)

time = 61698	action = 0	current_phase = 0	next_phase = 1	reward = -0.162364	array([[-2.4793963, -3.313659 ]], dtype=float32)

time = 61703	action = 0	current_phase = 0	next_phase = 1	reward = -0.048486	array([[-2.7881346, -4.33393  ]], dtype=float32)

time = 61708	action = 1	current_phase = 0	next_phase = 1	reward = -1.901214	array([[-6.5598264, -3.5281935]], dtype=float32)

time = 61716	action = 0	current_phase = 1	next_phase = 0	reward = -0.494322	array([[-2.0496538, -3.300206 ]], dtype=float32)

time = 61721	action = 0	current_phase = 1	next_phase = 0	reward = -0.335258	array([[-1.9203496, -3.1046612]], dtype=float32)

time = 61726	action = 0	current_phase = 1	next_phase = 0	reward = -0.195007	array([[-2.062144 , -3.2200253]], dtype=float32)

time = 61731	action = 0	current_phase = 1	next_phase = 0	reward = 0.278646	array([[-2.3010843, -4.232671 ]], dtype=float32)

time = 61736	action = 1	current_phase = 1	next_phase = 0	reward = -1.662734	array([[-5.7001724, -3.254336 ]], dtype=float32)

time = 61744	action = 0	current_phase = 0	next_phase = 1	reward = -0.551973	array([[-2.163548, -3.113669]], dtype=float32)

time = 61749	action = 0	current_phase = 0	next_phase = 1	reward = -0.399426	array([[-1.9980136, -3.009434 ]], dtype=float32)

time = 61754	action = 0	current_phase = 0	next_phase = 1	reward = -0.247703	array([[-1.9075325, -3.3648975]], dtype=float32)

time = 61759	action = 0	current_phase = 0	next_phase = 1	reward = -0.181673	array([[-2.0503821, -3.1705587]], dtype=float32)

time = 61764	action = 1	current_phase = 0	next_phase = 1	reward = -0.494925	array([[-5.775777 , -2.3514907]], dtype=float32)

time = 61772	action = 0	current_phase = 1	next_phase = 0	reward = -0.624045	array([[-2.242295, -3.123093]], dtype=float32)

time = 61777	action = 0	current_phase = 1	next_phase = 0	reward = -0.471395	array([[-2.0897954, -3.096313 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0118 - val_loss: 0.0108

Epoch 2/50

 - 4s - loss: 0.0117 - val_loss: 0.0118

Epoch 3/50

 - 4s - loss: 0.0121 - val_loss: 0.0112

Epoch 4/50

 - 4s - loss: 0.0103 - val_loss: 0.0106

Epoch 5/50

 - 4s - loss: 0.0098 - val_loss: 0.0124

Epoch 6/50

 - 4s - loss: 0.0086 - val_loss: 0.0093

Epoch 7/50

 - 4s - loss: 0.0092 - val_loss: 0.0079

Epoch 8/50

 - 4s - loss: 0.0086 - val_loss: 0.0102

Epoch 9/50

 - 4s - loss: 0.0085 - val_loss: 0.0086

Epoch 10/50

 - 4s - loss: 0.0074 - val_loss: 0.0122

Epoch 11/50

 - 4s - loss: 0.0094 - val_loss: 0.0107

Epoch 12/50

 - 4s - loss: 0.0100 - val_loss: 0.0106

Epoch 13/50

 - 4s - loss: 0.0075 - val_loss: 0.0145

Epoch 14/50

 - 4s - loss: 0.0081 - val_loss: 0.0142

Epoch 15/50

 - 4s - loss: 0.0087 - val_loss: 0.0143

Epoch 16/50

 - 4s - loss: 0.0074 - val_loss: 0.0138

Epoch 17/50

 - 4s - loss: 0.0090 - val_loss: 0.0159

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 61782	action = 0	current_phase = 1	next_phase = 0	reward = -0.327119	array([[-2.2084656, -3.1693215]], dtype=float32)

time = 61787	action = 0	current_phase = 1	next_phase = 0	reward = -0.183984	array([[-2.2988434, -3.2545097]], dtype=float32)

time = 61792	action = 0	current_phase = 1	next_phase = 0	reward = 0.262313	array([[-2.6574771, -4.4335675]], dtype=float32)

time = 61797	action = 1	current_phase = 1	next_phase = 0	reward = -1.784102	array([[-6.2497573, -3.4819744]], dtype=float32)

time = 61805	action = 0	current_phase = 0	next_phase = 1	reward = -0.532742	array([[-2.1636896, -3.2684247]], dtype=float32)

time = 61810	action = 0	current_phase = 0	next_phase = 1	reward = -0.375804	array([[-1.9854989, -3.0125732]], dtype=float32)

time = 61815	action = 0	current_phase = 0	next_phase = 1	reward = -0.221345	array([[-1.8943344, -3.3821387]], dtype=float32)

time = 61820	action = 0	current_phase = 0	next_phase = 1	reward = 0.059506	array([[-2.1179695, -3.835016 ]], dtype=float32)

time = 61825	action = 1	current_phase = 0	next_phase = 1	reward = -1.085160	array([[-5.5958247, -2.705329 ]], dtype=float32)

time = 61833	action = 0	current_phase = 1	next_phase = 0	reward = -0.592227	array([[-2.2342184, -3.1191711]], dtype=float32)

time = 61838	action = 0	current_phase = 1	next_phase = 0	reward = -0.431172	array([[-2.095966 , -3.1447372]], dtype=float32)

time = 61843	action = 0	current_phase = 1	next_phase = 0	reward = -0.266249	array([[-2.204963, -3.166802]], dtype=float32)

time = 61848	action = 0	current_phase = 1	next_phase = 0	reward = -0.156796	array([[-2.2852361, -3.274937 ]], dtype=float32)

time = 61853	action = 0	current_phase = 1	next_phase = 0	reward = -0.039875	array([[-2.7016165, -3.6922412]], dtype=float32)

time = 61858	action = 1	current_phase = 1	next_phase = 0	reward = -1.898622	array([[-6.3275876, -3.5983481]], dtype=float32)

time = 61866	action = 0	current_phase = 0	next_phase = 1	reward = -0.493572	array([[-2.120348 , -3.2586744]], dtype=float32)

time = 61871	action = 0	current_phase = 0	next_phase = 1	reward = -0.334004	array([[-2.013403 , -2.9981024]], dtype=float32)

time = 61876	action = 0	current_phase = 0	next_phase = 1	reward = -0.184670	array([[-2.166655 , -3.1072655]], dtype=float32)

time = 61881	action = 0	current_phase = 0	next_phase = 1	reward = 0.291270	array([[-2.360158, -4.172947]], dtype=float32)

time = 61886	action = 1	current_phase = 0	next_phase = 1	reward = -1.612014	array([[-4.5914006, -3.2324324]], dtype=float32)

time = 61894	action = 0	current_phase = 1	next_phase = 0	reward = -0.556410	array([[-2.1527278, -3.1043038]], dtype=float32)

time = 61899	action = 0	current_phase = 1	next_phase = 0	reward = -0.394361	array([[-1.9606332, -3.103271 ]], dtype=float32)

time = 61904	action = 0	current_phase = 1	next_phase = 0	reward = -0.239385	array([[-1.92701  , -3.0429895]], dtype=float32)

time = 61909	action = 0	current_phase = 1	next_phase = 0	reward = -0.182810	array([[-2.0486896, -3.880251 ]], dtype=float32)

time = 61914	action = 1	current_phase = 1	next_phase = 0	reward = -0.554006	array([[-2.4752731, -2.33063  ]], dtype=float32)

time = 61922	action = 0	current_phase = 0	next_phase = 1	reward = -0.619367	array([[-2.3663387, -3.839727 ]], dtype=float32)

time = 61927	action = 0	current_phase = 0	next_phase = 1	reward = -0.469300	array([[-2.223236 , -2.8947277]], dtype=float32)

time = 61932	action = 0	current_phase = 0	next_phase = 1	reward = -0.314890	array([[-2.1810174, -3.2379963]], dtype=float32)

time = 61937	action = 0	current_phase = 0	next_phase = 1	reward = -0.171053	array([[-2.2327795, -3.1471233]], dtype=float32)

time = 61942	action = 0	current_phase = 0	next_phase = 1	reward = 0.239679	array([[-2.5709474, -4.3923326]], dtype=float32)

time = 61947	action = 1	current_phase = 0	next_phase = 1	reward = -1.722405	array([[-6.1661263, -3.3987978]], dtype=float32)

time = 61955	action = 0	current_phase = 1	next_phase = 0	reward = -0.517629	array([[-2.0866992, -3.3082943]], dtype=float32)

time = 61960	action = 0	current_phase = 1	next_phase = 0	reward = -0.360220	array([[-1.9636112, -3.1047325]], dtype=float32)

time = 61965	action = 0	current_phase = 1	next_phase = 0	reward = -0.208192	array([[-1.9411575, -3.0644233]], dtype=float32)

time = 61970	action = 0	current_phase = 1	next_phase = 0	reward = 0.344888	array([[-2.1617358, -3.9415913]], dtype=float32)

time = 61975	action = 1	current_phase = 1	next_phase = 0	reward = -1.316955	array([[-3.2936711, -3.1524475]], dtype=float32)

time = 61983	action = 0	current_phase = 0	next_phase = 1	reward = -0.585521	array([[-2.3659723, -3.8365803]], dtype=float32)

time = 61988	action = 0	current_phase = 0	next_phase = 1	reward = -0.430713	array([[-2.2226393, -2.8908262]], dtype=float32)

time = 61993	action = 0	current_phase = 0	next_phase = 1	reward = -0.277593	array([[-2.178745, -3.241303]], dtype=float32)

time = 61998	action = 0	current_phase = 0	next_phase = 1	reward = -0.164422	array([[-2.4949365, -3.3077803]], dtype=float32)

time = 62003	action = 0	current_phase = 0	next_phase = 1	reward = 0.011534	array([[-2.5729363, -4.37693  ]], dtype=float32)

time = 62008	action = 1	current_phase = 0	next_phase = 1	reward = -1.896283	array([[-6.5451984, -3.5690854]], dtype=float32)

time = 62016	action = 0	current_phase = 1	next_phase = 0	reward = -0.496431	array([[-2.0825145, -3.3092275]], dtype=float32)

time = 62021	action = 0	current_phase = 1	next_phase = 0	reward = -0.351563	array([[-1.9674549, -3.1055562]], dtype=float32)

time = 62026	action = 0	current_phase = 1	next_phase = 0	reward = -0.204534	array([[-2.0744083, -3.213386 ]], dtype=float32)

time = 62031	action = 0	current_phase = 1	next_phase = 0	reward = 0.287512	array([[-2.3257854, -4.21212  ]], dtype=float32)

time = 62036	action = 1	current_phase = 1	next_phase = 0	reward = -1.611103	array([[-5.708324 , -3.2974663]], dtype=float32)

time = 62044	action = 0	current_phase = 0	next_phase = 1	reward = -0.568035	array([[-2.1551151, -3.1259632]], dtype=float32)

time = 62049	action = 0	current_phase = 0	next_phase = 1	reward = -0.424008	array([[-1.9869388, -3.0107458]], dtype=float32)

time = 62054	action = 0	current_phase = 0	next_phase = 1	reward = -0.265725	array([[-2.1699898, -3.2448907]], dtype=float32)

time = 62059	action = 0	current_phase = 0	next_phase = 1	reward = -0.172082	array([[-2.1408918, -3.197902 ]], dtype=float32)

time = 62064	action = 1	current_phase = 0	next_phase = 1	reward = -0.460065	array([[-5.809017 , -2.3778908]], dtype=float32)

time = 62072	action = 0	current_phase = 1	next_phase = 0	reward = -0.620852	array([[-2.336211 , -3.1338904]], dtype=float32)

time = 62077	action = 0	current_phase = 1	next_phase = 0	reward = -0.468304	array([[-2.1537187, -3.1044233]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0185 - val_loss: 0.0086

Epoch 2/50

 - 4s - loss: 0.0113 - val_loss: 0.0081

Epoch 3/50

 - 4s - loss: 0.0172 - val_loss: 0.0089

Epoch 4/50

 - 4s - loss: 0.0113 - val_loss: 0.0091

Epoch 5/50

 - 4s - loss: 0.0137 - val_loss: 0.0083

Epoch 6/50

 - 4s - loss: 0.0141 - val_loss: 0.0082

Epoch 7/50

 - 4s - loss: 0.0131 - val_loss: 0.0076

Epoch 8/50

 - 4s - loss: 0.0128 - val_loss: 0.0084

Epoch 9/50

 - 4s - loss: 0.0140 - val_loss: 0.0090

Epoch 10/50

 - 4s - loss: 0.0116 - val_loss: 0.0075

Epoch 11/50

 - 4s - loss: 0.0120 - val_loss: 0.0070

Epoch 12/50

 - 4s - loss: 0.0117 - val_loss: 0.0082

Epoch 13/50

 - 4s - loss: 0.0116 - val_loss: 0.0082

Epoch 14/50

 - 4s - loss: 0.0101 - val_loss: 0.0080

Epoch 15/50

 - 4s - loss: 0.0094 - val_loss: 0.0084

Epoch 16/50

 - 4s - loss: 0.0141 - val_loss: 0.0083

Epoch 17/50

 - 4s - loss: 0.0086 - val_loss: 0.0091

Epoch 18/50

 - 4s - loss: 0.0126 - val_loss: 0.0097

Epoch 19/50

 - 4s - loss: 0.0099 - val_loss: 0.0088

Epoch 20/50

 - 4s - loss: 0.0119 - val_loss: 0.0088

Epoch 21/50

 - 4s - loss: 0.0126 - val_loss: 0.0087

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 62082	action = 0	current_phase = 1	next_phase = 0	reward = -0.306710	array([[-2.1563065, -3.1702876]], dtype=float32)

time = 62087	action = 0	current_phase = 1	next_phase = 0	reward = -0.171370	array([[-2.301193 , -3.2649329]], dtype=float32)

time = 62092	action = 0	current_phase = 1	next_phase = 0	reward = 0.253033	array([[-2.642453, -4.416991]], dtype=float32)

time = 62097	action = 1	current_phase = 1	next_phase = 0	reward = -1.788135	array([[-6.2778416, -3.5069067]], dtype=float32)

time = 62105	action = 0	current_phase = 0	next_phase = 1	reward = -0.537900	array([[-2.120183 , -3.2650697]], dtype=float32)

time = 62110	action = 0	current_phase = 0	next_phase = 1	reward = -0.376913	array([[-1.9705995, -3.0172374]], dtype=float32)

time = 62115	action = 0	current_phase = 0	next_phase = 1	reward = -0.219865	array([[-1.9327685, -3.3754878]], dtype=float32)

time = 62120	action = 0	current_phase = 0	next_phase = 1	reward = 0.069838	array([[-2.1270773, -3.8902488]], dtype=float32)

time = 62125	action = 1	current_phase = 0	next_phase = 1	reward = -1.080483	array([[-5.564029 , -2.8106897]], dtype=float32)

time = 62133	action = 0	current_phase = 1	next_phase = 0	reward = -0.583226	array([[-2.2129138, -3.1270878]], dtype=float32)

time = 62138	action = 0	current_phase = 1	next_phase = 0	reward = -0.424954	array([[-2.043324 , -3.1365573]], dtype=float32)

time = 62143	action = 0	current_phase = 1	next_phase = 0	reward = -0.270760	array([[-2.1406515, -3.1606355]], dtype=float32)

time = 62148	action = 0	current_phase = 1	next_phase = 0	reward = -0.165170	array([[-2.284279 , -3.2813127]], dtype=float32)

time = 62153	action = 0	current_phase = 1	next_phase = 0	reward = -0.047941	array([[-2.756053, -4.324602]], dtype=float32)

time = 62158	action = 1	current_phase = 1	next_phase = 0	reward = -1.900317	array([[-6.3324175, -3.608825 ]], dtype=float32)

time = 62166	action = 0	current_phase = 0	next_phase = 1	reward = -0.496303	array([[-2.1023695, -3.257356 ]], dtype=float32)

time = 62171	action = 0	current_phase = 0	next_phase = 1	reward = -0.332270	array([[-1.992075 , -3.0175226]], dtype=float32)

time = 62176	action = 0	current_phase = 0	next_phase = 1	reward = -0.192979	array([[-2.159652 , -3.1124403]], dtype=float32)

time = 62181	action = 0	current_phase = 0	next_phase = 1	reward = 0.296786	array([[-2.3438938, -4.1313586]], dtype=float32)

time = 62186	action = 1	current_phase = 0	next_phase = 1	reward = -1.608210	array([[-4.6823354, -3.2823102]], dtype=float32)

time = 62194	action = 0	current_phase = 1	next_phase = 0	reward = -0.549048	array([[-2.1478703, -3.1170704]], dtype=float32)

time = 62199	action = 0	current_phase = 1	next_phase = 0	reward = -0.384167	array([[-1.9694376, -3.1092975]], dtype=float32)

time = 62204	action = 0	current_phase = 1	next_phase = 0	reward = -0.224150	array([[-1.9128172, -3.0464659]], dtype=float32)

time = 62209	action = 0	current_phase = 1	next_phase = 0	reward = -0.185894	array([[-2.033162, -3.889481]], dtype=float32)

time = 62214	action = 1	current_phase = 1	next_phase = 0	reward = -0.545683	array([[-2.5629184, -2.4218998]], dtype=float32)

time = 62222	action = 0	current_phase = 0	next_phase = 1	reward = -0.611931	array([[-2.392774, -3.845504]], dtype=float32)

time = 62227	action = 0	current_phase = 0	next_phase = 1	reward = -0.458258	array([[-2.2065291, -2.8904731]], dtype=float32)

time = 62232	action = 0	current_phase = 0	next_phase = 1	reward = -0.309881	array([[-2.2122822, -3.2166796]], dtype=float32)

time = 62237	action = 0	current_phase = 0	next_phase = 1	reward = -0.177192	array([[-2.433055 , -3.3048995]], dtype=float32)

time = 62242	action = 0	current_phase = 0	next_phase = 1	reward = 0.118277	array([[-2.6146977, -4.3865976]], dtype=float32)

time = 62247	action = 1	current_phase = 0	next_phase = 1	reward = -1.790743	array([[-6.5187616, -3.4822726]], dtype=float32)

time = 62255	action = 0	current_phase = 1	next_phase = 0	reward = -0.533712	array([[-2.0849874, -3.321172 ]], dtype=float32)

time = 62260	action = 0	current_phase = 1	next_phase = 0	reward = -0.384662	array([[-1.9719235, -3.1116984]], dtype=float32)

time = 62265	action = 0	current_phase = 1	next_phase = 0	reward = -0.230235	array([[-1.9322705, -3.0701807]], dtype=float32)

time = 62270	action = 0	current_phase = 1	next_phase = 0	reward = 0.075423	array([[-2.133912 , -3.8956704]], dtype=float32)

time = 62275	action = 1	current_phase = 1	next_phase = 0	reward = -0.914042	array([[-3.027605, -2.891459]], dtype=float32)

time = 62283	action = 0	current_phase = 0	next_phase = 1	reward = -0.580739	array([[-2.3923283, -3.8435578]], dtype=float32)

time = 62288	action = 0	current_phase = 0	next_phase = 1	reward = -0.413156	array([[-2.199437 , -2.8865733]], dtype=float32)

time = 62293	action = 0	current_phase = 0	next_phase = 1	reward = -0.259487	array([[-2.2208583, -3.2204401]], dtype=float32)

time = 62298	action = 0	current_phase = 0	next_phase = 1	reward = -0.161343	array([[-2.447324 , -3.3257983]], dtype=float32)

time = 62303	action = 0	current_phase = 0	next_phase = 1	reward = 0.043336	array([[-3.3401976, -3.7476199]], dtype=float32)

time = 62308	action = 1	current_phase = 0	next_phase = 1	reward = -1.901074	array([[-6.5603194, -3.5238273]], dtype=float32)

time = 62316	action = 0	current_phase = 1	next_phase = 0	reward = -0.507238	array([[-2.086178 , -3.3241425]], dtype=float32)

time = 62321	action = 0	current_phase = 1	next_phase = 0	reward = -0.352956	array([[-1.9760048, -3.11197  ]], dtype=float32)

time = 62326	action = 0	current_phase = 1	next_phase = 0	reward = -0.198075	array([[-2.0542037, -3.193528 ]], dtype=float32)

time = 62331	action = 0	current_phase = 1	next_phase = 0	reward = 0.335724	array([[-2.3240523, -4.231589 ]], dtype=float32)

time = 62336	action = 0	current_phase = 1	next_phase = 0	reward = -1.060029	array([[-3.2196612, -3.2484097]], dtype=float32)

time = 62341	action = 1	current_phase = 1	next_phase = 0	reward = -2.052877	array([[-5.4702287, -3.5411284]], dtype=float32)

time = 62349	action = 0	current_phase = 0	next_phase = 1	reward = -0.391301	array([[-2.110663 , -3.2624586]], dtype=float32)

time = 62354	action = 0	current_phase = 0	next_phase = 1	reward = -0.235666	array([[-1.9335247, -3.374351 ]], dtype=float32)

time = 62359	action = 0	current_phase = 0	next_phase = 1	reward = -0.181573	array([[-2.086707 , -3.1954873]], dtype=float32)

time = 62364	action = 1	current_phase = 0	next_phase = 1	reward = -0.588527	array([[-5.822293, -2.404903]], dtype=float32)

time = 62372	action = 0	current_phase = 1	next_phase = 0	reward = -0.613838	array([[-2.4029584, -3.1575303]], dtype=float32)

time = 62377	action = 0	current_phase = 1	next_phase = 0	reward = -0.457896	array([[-2.1784925, -3.117639 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0076 - val_loss: 0.0065

Epoch 2/50

 - 4s - loss: 0.0092 - val_loss: 0.0078

Epoch 3/50

 - 4s - loss: 0.0085 - val_loss: 0.0068

Epoch 4/50

 - 4s - loss: 0.0055 - val_loss: 0.0067

Epoch 5/50

 - 4s - loss: 0.0101 - val_loss: 0.0069

Epoch 6/50

 - 4s - loss: 0.0103 - val_loss: 0.0074

Epoch 7/50

 - 4s - loss: 0.0064 - val_loss: 0.0082

Epoch 8/50

 - 4s - loss: 0.0066 - val_loss: 0.0074

Epoch 9/50

 - 4s - loss: 0.0062 - val_loss: 0.0072

Epoch 10/50

 - 4s - loss: 0.0092 - val_loss: 0.0070

Epoch 11/50

 - 4s - loss: 0.0061 - val_loss: 0.0074

length of memory (state 0, action 0): 1021, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1023, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 62382	action = 0	current_phase = 1	next_phase = 0	reward = -0.307247	array([[-2.1530678, -3.1657226]], dtype=float32)

time = 62387	action = 0	current_phase = 1	next_phase = 0	reward = -0.177003	array([[-2.32524 , -3.237225]], dtype=float32)

time = 62392	action = 0	current_phase = 1	next_phase = 0	reward = 0.112895	array([[-2.6420045, -4.418541 ]], dtype=float32)

time = 62397	action = 1	current_phase = 1	next_phase = 0	reward = -1.792814	array([[-6.298665, -3.556263]], dtype=float32)

time = 62405	action = 0	current_phase = 0	next_phase = 1	reward = -0.543314	array([[-2.1218767, -3.275477 ]], dtype=float32)

time = 62410	action = 0	current_phase = 0	next_phase = 1	reward = -0.388709	array([[-1.9509571, -3.0122895]], dtype=float32)

time = 62415	action = 0	current_phase = 0	next_phase = 1	reward = -0.234915	array([[-1.9244465, -3.3793936]], dtype=float32)

time = 62420	action = 0	current_phase = 0	next_phase = 1	reward = 0.079135	array([[-2.1234562, -3.7832239]], dtype=float32)

time = 62425	action = 1	current_phase = 0	next_phase = 1	reward = -0.971685	array([[-5.6374645, -2.7788863]], dtype=float32)

time = 62433	action = 0	current_phase = 1	next_phase = 0	reward = -0.582130	array([[-2.2478518, -3.1235445]], dtype=float32)

time = 62438	action = 0	current_phase = 1	next_phase = 0	reward = -0.435388	array([[-2.1085026, -3.1529863]], dtype=float32)

time = 62443	action = 0	current_phase = 1	next_phase = 0	reward = -0.274152	array([[-2.139779 , -3.1611056]], dtype=float32)

time = 62448	action = 0	current_phase = 1	next_phase = 0	reward = -0.160920	array([[-2.2918131, -3.2763476]], dtype=float32)

time = 62453	action = 0	current_phase = 1	next_phase = 0	reward = 0.064478	array([[-2.6786878, -3.7790136]], dtype=float32)

time = 62458	action = 1	current_phase = 1	next_phase = 0	reward = -1.901658	array([[-6.3340335, -3.6186454]], dtype=float32)

time = 62466	action = 0	current_phase = 0	next_phase = 1	reward = -0.490780	array([[-2.092782, -3.266086]], dtype=float32)

time = 62471	action = 0	current_phase = 0	next_phase = 1	reward = -0.333379	array([[-2.112014, -3.059043]], dtype=float32)

time = 62476	action = 0	current_phase = 0	next_phase = 1	reward = -0.184733	array([[-2.1416786, -3.1207824]], dtype=float32)

time = 62481	action = 0	current_phase = 0	next_phase = 1	reward = 0.291274	array([[-2.3579102, -4.1407294]], dtype=float32)

time = 62486	action = 1	current_phase = 0	next_phase = 1	reward = -1.613310	array([[-4.617703 , -3.3031309]], dtype=float32)

time = 62494	action = 0	current_phase = 1	next_phase = 0	reward = -0.563518	array([[-2.1622605, -3.107667 ]], dtype=float32)

time = 62499	action = 0	current_phase = 1	next_phase = 0	reward = -0.401897	array([[-1.9677902, -3.10247  ]], dtype=float32)

time = 62504	action = 0	current_phase = 1	next_phase = 0	reward = -0.252220	array([[-1.933765, -3.046417]], dtype=float32)

time = 62509	action = 0	current_phase = 1	next_phase = 0	reward = -0.174394	array([[-2.0252917, -3.8886771]], dtype=float32)

time = 62514	action = 1	current_phase = 1	next_phase = 0	reward = -0.477427	array([[-2.5057755, -2.331756 ]], dtype=float32)

time = 62522	action = 0	current_phase = 0	next_phase = 1	reward = -0.615791	array([[-2.3791134, -3.873634 ]], dtype=float32)

time = 62527	action = 0	current_phase = 0	next_phase = 1	reward = -0.466464	array([[-2.183022, -2.89714 ]], dtype=float32)

time = 62532	action = 0	current_phase = 0	next_phase = 1	reward = -0.312907	array([[-2.215754, -3.225057]], dtype=float32)

time = 62537	action = 0	current_phase = 0	next_phase = 1	reward = -0.175397	array([[-2.219705 , -3.1787772]], dtype=float32)

time = 62542	action = 0	current_phase = 0	next_phase = 1	reward = 0.225643	array([[-2.6379993, -4.372514 ]], dtype=float32)

time = 62547	action = 1	current_phase = 0	next_phase = 1	reward = -1.781090	array([[-6.297369 , -3.4036362]], dtype=float32)

time = 62555	action = 0	current_phase = 1	next_phase = 0	reward = -0.525030	array([[-2.0724256, -3.316119 ]], dtype=float32)

time = 62560	action = 0	current_phase = 1	next_phase = 0	reward = -0.362248	array([[-1.9696199, -3.1052423]], dtype=float32)

time = 62565	action = 0	current_phase = 1	next_phase = 0	reward = -0.205209	array([[-1.9288205, -3.0473182]], dtype=float32)

time = 62570	action = 0	current_phase = 1	next_phase = 0	reward = 0.358456	array([[-2.201293, -4.048168]], dtype=float32)

time = 62575	action = 1	current_phase = 1	next_phase = 0	reward = -1.258372	array([[-3.2924123, -3.213831 ]], dtype=float32)

time = 62583	action = 0	current_phase = 0	next_phase = 1	reward = -0.590052	array([[-2.3725653, -3.8734648]], dtype=float32)

time = 62588	action = 0	current_phase = 0	next_phase = 1	reward = -0.428812	array([[-2.1730523, -2.8956966]], dtype=float32)

time = 62593	action = 0	current_phase = 0	next_phase = 1	reward = -0.275079	array([[-2.2201293, -3.2310135]], dtype=float32)

time = 62598	action = 0	current_phase = 0	next_phase = 1	reward = -0.164023	array([[-2.4438753, -3.3416078]], dtype=float32)

time = 62603	action = 0	current_phase = 0	next_phase = 1	reward = -0.052261	array([[-3.167058, -4.202012]], dtype=float32)

time = 62608	action = 1	current_phase = 0	next_phase = 1	reward = -1.900568	array([[-6.577787 , -3.5468922]], dtype=float32)

time = 62616	action = 0	current_phase = 1	next_phase = 0	reward = -0.496003	array([[-2.0747886, -3.31698  ]], dtype=float32)

time = 62621	action = 0	current_phase = 1	next_phase = 0	reward = -0.342799	array([[-1.9691142, -3.102914 ]], dtype=float32)

time = 62626	action = 0	current_phase = 1	next_phase = 0	reward = -0.195848	array([[-2.027771, -3.166576]], dtype=float32)

time = 62631	action = 0	current_phase = 1	next_phase = 0	reward = 0.320253	array([[-2.2859762, -4.217434 ]], dtype=float32)

time = 62636	action = 1	current_phase = 1	next_phase = 0	reward = -1.552620	array([[-5.6851053, -3.3016262]], dtype=float32)

time = 62644	action = 0	current_phase = 0	next_phase = 1	reward = -0.557740	array([[-2.1429794, -3.1277764]], dtype=float32)

time = 62649	action = 0	current_phase = 0	next_phase = 1	reward = -0.397311	array([[-1.9423412, -3.0188007]], dtype=float32)

time = 62654	action = 0	current_phase = 0	next_phase = 1	reward = -0.240267	array([[-1.924999 , -3.3794677]], dtype=float32)

time = 62659	action = 0	current_phase = 0	next_phase = 1	reward = -0.179852	array([[-2.081115 , -3.1978633]], dtype=float32)

time = 62664	action = 1	current_phase = 0	next_phase = 1	reward = -0.482137	array([[-5.8399014, -2.402349 ]], dtype=float32)

time = 62672	action = 0	current_phase = 1	next_phase = 0	reward = -0.627611	array([[-2.3369107, -3.1376975]], dtype=float32)

time = 62677	action = 0	current_phase = 1	next_phase = 0	reward = -0.471454	array([[-2.2088394, -3.1159356]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0129 - val_loss: 0.0049

Epoch 2/50

 - 4s - loss: 0.0123 - val_loss: 0.0051

Epoch 3/50

 - 4s - loss: 0.0112 - val_loss: 0.0044

Epoch 4/50

 - 4s - loss: 0.0074 - val_loss: 0.0049

Epoch 5/50

 - 4s - loss: 0.0077 - val_loss: 0.0047

Epoch 6/50

 - 4s - loss: 0.0078 - val_loss: 0.0044

Epoch 7/50

 - 4s - loss: 0.0082 - val_loss: 0.0047

Epoch 8/50

 - 4s - loss: 0.0083 - val_loss: 0.0046

Epoch 9/50

 - 4s - loss: 0.0095 - val_loss: 0.0054

Epoch 10/50

 - 4s - loss: 0.0086 - val_loss: 0.0049

Epoch 11/50

 - 4s - loss: 0.0105 - val_loss: 0.0047

Epoch 12/50

 - 4s - loss: 0.0075 - val_loss: 0.0048

Epoch 13/50

 - 4s - loss: 0.0078 - val_loss: 0.0044

Epoch 14/50

 - 4s - loss: 0.0088 - val_loss: 0.0051

Epoch 15/50

 - 4s - loss: 0.0094 - val_loss: 0.0057

Epoch 16/50

 - 4s - loss: 0.0128 - val_loss: 0.0049

Epoch 17/50

 - 4s - loss: 0.0073 - val_loss: 0.0048

Epoch 18/50

 - 4s - loss: 0.0063 - val_loss: 0.0049

Epoch 19/50

 - 4s - loss: 0.0081 - val_loss: 0.0057

Epoch 20/50

 - 4s - loss: 0.0067 - val_loss: 0.0055

Epoch 21/50

 - 4s - loss: 0.0072 - val_loss: 0.0055

Epoch 22/50

 - 4s - loss: 0.0055 - val_loss: 0.0064

Epoch 23/50

 - 4s - loss: 0.0068 - val_loss: 0.0067

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 62682	action = 0	current_phase = 1	next_phase = 0	reward = -0.311721	array([[-2.1246836, -3.1612773]], dtype=float32)

time = 62687	action = 0	current_phase = 1	next_phase = 0	reward = -0.175361	array([[-2.3577788, -3.230729 ]], dtype=float32)

time = 62692	action = 0	current_phase = 1	next_phase = 0	reward = 0.269363	array([[-2.4756863, -4.314476 ]], dtype=float32)

time = 62697	action = 1	current_phase = 1	next_phase = 0	reward = -1.727814	array([[-6.249213 , -3.4776077]], dtype=float32)

time = 62705	action = 0	current_phase = 0	next_phase = 1	reward = -0.529576	array([[-2.1208334, -3.2706537]], dtype=float32)

time = 62710	action = 0	current_phase = 0	next_phase = 1	reward = -0.362739	array([[-1.9001135, -3.0249877]], dtype=float32)

time = 62715	action = 0	current_phase = 0	next_phase = 1	reward = -0.207933	array([[-1.8957821, -3.3715706]], dtype=float32)

time = 62720	action = 0	current_phase = 0	next_phase = 1	reward = 0.346332	array([[-2.1016808, -3.9071813]], dtype=float32)

time = 62725	action = 1	current_phase = 0	next_phase = 1	reward = -1.367420	array([[-5.0775743, -3.0763927]], dtype=float32)

time = 62733	action = 0	current_phase = 1	next_phase = 0	reward = -0.590214	array([[-2.2119482, -3.1273978]], dtype=float32)

time = 62738	action = 0	current_phase = 1	next_phase = 0	reward = -0.438513	array([[-2.1641123, -3.1731799]], dtype=float32)

time = 62743	action = 0	current_phase = 1	next_phase = 0	reward = -0.282041	array([[-2.0783288, -3.1382494]], dtype=float32)

time = 62748	action = 0	current_phase = 1	next_phase = 0	reward = -0.168561	array([[-2.3070977, -3.275302 ]], dtype=float32)

time = 62753	action = 0	current_phase = 1	next_phase = 0	reward = 0.010012	array([[-2.7333927, -4.156107 ]], dtype=float32)

time = 62758	action = 1	current_phase = 1	next_phase = 0	reward = -1.900891	array([[-6.326889 , -3.6059694]], dtype=float32)

time = 62766	action = 0	current_phase = 0	next_phase = 1	reward = -0.506687	array([[-2.0793312, -3.262217 ]], dtype=float32)

time = 62771	action = 0	current_phase = 0	next_phase = 1	reward = -0.355523	array([[-1.9092801, -3.025168 ]], dtype=float32)

time = 62776	action = 0	current_phase = 0	next_phase = 1	reward = -0.206261	array([[-2.0700455, -3.1228938]], dtype=float32)

time = 62781	action = 0	current_phase = 0	next_phase = 1	reward = 0.309041	array([[-2.2716439, -4.1008782]], dtype=float32)

time = 62786	action = 1	current_phase = 0	next_phase = 1	reward = -1.662938	array([[-4.6273046, -3.3216825]], dtype=float32)

time = 62794	action = 0	current_phase = 1	next_phase = 0	reward = -0.554813	array([[-2.153042 , -3.1122856]], dtype=float32)

time = 62799	action = 0	current_phase = 1	next_phase = 0	reward = -0.401273	array([[-1.9625864, -3.0990365]], dtype=float32)

time = 62804	action = 0	current_phase = 1	next_phase = 0	reward = -0.242338	array([[-2.008805 , -3.1014078]], dtype=float32)

time = 62809	action = 0	current_phase = 1	next_phase = 0	reward = -0.171555	array([[-2.0544486, -3.898929 ]], dtype=float32)

time = 62814	action = 1	current_phase = 1	next_phase = 0	reward = -0.467207	array([[-2.5604775, -2.44394  ]], dtype=float32)

time = 62822	action = 0	current_phase = 0	next_phase = 1	reward = -0.613811	array([[-2.3437057, -3.8741736]], dtype=float32)

time = 62827	action = 0	current_phase = 0	next_phase = 1	reward = -0.461828	array([[-2.1658263, -2.907576 ]], dtype=float32)

time = 62832	action = 0	current_phase = 0	next_phase = 1	reward = -0.299552	array([[-2.1610792, -3.1792583]], dtype=float32)

time = 62837	action = 0	current_phase = 0	next_phase = 1	reward = -0.169314	array([[-2.204865 , -3.2250576]], dtype=float32)

time = 62842	action = 0	current_phase = 0	next_phase = 1	reward = 0.182563	array([[-2.6176138, -4.323784 ]], dtype=float32)

time = 62847	action = 1	current_phase = 0	next_phase = 1	reward = -1.782918	array([[-6.5110583, -3.4489784]], dtype=float32)

time = 62855	action = 0	current_phase = 1	next_phase = 0	reward = -0.514593	array([[-2.0800018, -3.3267262]], dtype=float32)

time = 62860	action = 0	current_phase = 1	next_phase = 0	reward = -0.354412	array([[-1.9670184, -3.1018205]], dtype=float32)

time = 62865	action = 0	current_phase = 1	next_phase = 0	reward = -0.193896	array([[-1.9645178, -3.1184003]], dtype=float32)

time = 62870	action = 0	current_phase = 1	next_phase = 0	reward = 0.353399	array([[-2.2881265, -4.2030697]], dtype=float32)

time = 62875	action = 1	current_phase = 1	next_phase = 0	reward = -1.316137	array([[-3.335693 , -3.2576895]], dtype=float32)

time = 62883	action = 0	current_phase = 0	next_phase = 1	reward = -0.590282	array([[-2.3416407, -3.8746314]], dtype=float32)

time = 62888	action = 0	current_phase = 0	next_phase = 1	reward = -0.435193	array([[-2.161499 , -2.9083924]], dtype=float32)

time = 62893	action = 0	current_phase = 0	next_phase = 1	reward = -0.291894	array([[-2.207364 , -3.2355447]], dtype=float32)

time = 62898	action = 0	current_phase = 0	next_phase = 1	reward = -0.164040	array([[-2.2735608, -3.2749124]], dtype=float32)

time = 62903	action = 0	current_phase = 0	next_phase = 1	reward = 0.188186	array([[-2.6749525, -4.2603035]], dtype=float32)

time = 62908	action = 1	current_phase = 0	next_phase = 1	reward = -1.897124	array([[-6.16271  , -3.3673816]], dtype=float32)

time = 62916	action = 0	current_phase = 1	next_phase = 0	reward = -0.499285	array([[-2.0784879, -3.328663 ]], dtype=float32)

time = 62921	action = 0	current_phase = 1	next_phase = 0	reward = -0.347286	array([[-1.9830214, -3.1076076]], dtype=float32)

time = 62926	action = 0	current_phase = 1	next_phase = 0	reward = -0.192730	array([[-2.0479631, -3.1799393]], dtype=float32)

time = 62931	action = 0	current_phase = 1	next_phase = 0	reward = 0.316274	array([[-2.309074, -4.228376]], dtype=float32)

time = 62936	action = 1	current_phase = 1	next_phase = 0	reward = -1.555022	array([[-5.6657515, -3.292628 ]], dtype=float32)

time = 62944	action = 0	current_phase = 0	next_phase = 1	reward = -0.544277	array([[-2.1267757, -3.118833 ]], dtype=float32)

time = 62949	action = 0	current_phase = 0	next_phase = 1	reward = -0.404271	array([[-1.904226 , -3.0220428]], dtype=float32)

time = 62954	action = 0	current_phase = 0	next_phase = 1	reward = -0.262818	array([[-1.8957858, -3.371584 ]], dtype=float32)

time = 62959	action = 0	current_phase = 0	next_phase = 1	reward = -0.182890	array([[-2.0867448, -3.2091355]], dtype=float32)

time = 62964	action = 1	current_phase = 0	next_phase = 1	reward = -0.599882	array([[-5.84764  , -2.3903198]], dtype=float32)

time = 62972	action = 0	current_phase = 1	next_phase = 0	reward = -0.617643	array([[-2.308075 , -3.1392138]], dtype=float32)

time = 62977	action = 0	current_phase = 1	next_phase = 0	reward = -0.466213	array([[-2.2221625, -3.1284375]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0098 - val_loss: 0.0067

Epoch 2/50

 - 4s - loss: 0.0103 - val_loss: 0.0065

Epoch 3/50

 - 4s - loss: 0.0089 - val_loss: 0.0070

Epoch 4/50

 - 4s - loss: 0.0085 - val_loss: 0.0067

Epoch 5/50

 - 4s - loss: 0.0093 - val_loss: 0.0069

Epoch 6/50

 - 4s - loss: 0.0137 - val_loss: 0.0072

Epoch 7/50

 - 4s - loss: 0.0087 - val_loss: 0.0066

Epoch 8/50

 - 4s - loss: 0.0117 - val_loss: 0.0062

Epoch 9/50

 - 4s - loss: 0.0083 - val_loss: 0.0064

Epoch 10/50

 - 4s - loss: 0.0088 - val_loss: 0.0070

Epoch 11/50

 - 4s - loss: 0.0078 - val_loss: 0.0070

Epoch 12/50

 - 4s - loss: 0.0078 - val_loss: 0.0076

Epoch 13/50

 - 4s - loss: 0.0073 - val_loss: 0.0073

Epoch 14/50

 - 4s - loss: 0.0126 - val_loss: 0.0069

Epoch 15/50

 - 4s - loss: 0.0064 - val_loss: 0.0068

Epoch 16/50

 - 4s - loss: 0.0080 - val_loss: 0.0069

Epoch 17/50

 - 4s - loss: 0.0112 - val_loss: 0.0069

Epoch 18/50

 - 4s - loss: 0.0103 - val_loss: 0.0067

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 62982	action = 0	current_phase = 1	next_phase = 0	reward = -0.317020	array([[-2.2058966, -3.1604292]], dtype=float32)

time = 62987	action = 0	current_phase = 1	next_phase = 0	reward = -0.177829	array([[-2.362999, -3.233661]], dtype=float32)

time = 62992	action = 0	current_phase = 1	next_phase = 0	reward = 0.192604	array([[-2.6635394, -4.3336387]], dtype=float32)

time = 62997	action = 1	current_phase = 1	next_phase = 0	reward = -1.783604	array([[-6.3120785, -3.46995  ]], dtype=float32)

time = 63005	action = 0	current_phase = 0	next_phase = 1	reward = -0.538135	array([[-2.077107 , -3.2705529]], dtype=float32)

time = 63010	action = 0	current_phase = 0	next_phase = 1	reward = -0.379979	array([[-1.8932259, -3.0323842]], dtype=float32)

time = 63015	action = 0	current_phase = 0	next_phase = 1	reward = -0.230024	array([[-1.8759865, -3.3695583]], dtype=float32)

time = 63020	action = 0	current_phase = 0	next_phase = 1	reward = 0.069092	array([[-2.0589266, -3.7553298]], dtype=float32)

time = 63025	action = 1	current_phase = 0	next_phase = 1	reward = -0.976265	array([[-5.6562786, -2.7491994]], dtype=float32)

time = 63033	action = 0	current_phase = 1	next_phase = 0	reward = -0.591882	array([[-2.2673168, -3.1282785]], dtype=float32)

time = 63038	action = 0	current_phase = 1	next_phase = 0	reward = -0.440679	array([[-2.220268 , -3.1640892]], dtype=float32)

time = 63043	action = 0	current_phase = 1	next_phase = 0	reward = -0.284653	array([[-2.1343992, -3.1246104]], dtype=float32)

time = 63048	action = 0	current_phase = 1	next_phase = 0	reward = -0.164230	array([[-2.3456182, -3.2726827]], dtype=float32)

time = 63053	action = 0	current_phase = 1	next_phase = 0	reward = 0.049836	array([[-2.822644, -4.201359]], dtype=float32)

time = 63058	action = 1	current_phase = 1	next_phase = 0	reward = -1.893441	array([[-6.374218 , -3.5858717]], dtype=float32)

time = 63066	action = 0	current_phase = 0	next_phase = 1	reward = -0.508804	array([[-2.0717425, -3.2686071]], dtype=float32)

time = 63071	action = 0	current_phase = 0	next_phase = 1	reward = -0.362443	array([[-1.9899498, -3.0110044]], dtype=float32)

time = 63076	action = 0	current_phase = 0	next_phase = 1	reward = -0.211864	array([[-2.0511892, -3.1325989]], dtype=float32)

time = 63081	action = 0	current_phase = 0	next_phase = 1	reward = 0.336629	array([[-2.2146604, -4.0609307]], dtype=float32)

time = 63086	action = 1	current_phase = 0	next_phase = 1	reward = -1.499530	array([[-4.715621 , -3.2910252]], dtype=float32)

time = 63094	action = 0	current_phase = 1	next_phase = 0	reward = -0.557491	array([[-2.1876447, -3.1105745]], dtype=float32)

time = 63099	action = 0	current_phase = 1	next_phase = 0	reward = -0.410093	array([[-1.997565 , -3.0875201]], dtype=float32)

time = 63104	action = 0	current_phase = 1	next_phase = 0	reward = -0.251894	array([[-1.9408863, -3.0304706]], dtype=float32)

time = 63109	action = 0	current_phase = 1	next_phase = 0	reward = -0.166291	array([[-2.0619302, -3.906865 ]], dtype=float32)

time = 63114	action = 1	current_phase = 1	next_phase = 0	reward = -0.356242	array([[-2.5902345, -2.360647 ]], dtype=float32)

time = 63122	action = 0	current_phase = 0	next_phase = 1	reward = -0.631087	array([[-2.3505461, -3.8663616]], dtype=float32)

time = 63127	action = 0	current_phase = 0	next_phase = 1	reward = -0.485127	array([[-2.135677 , -2.9226832]], dtype=float32)

time = 63132	action = 0	current_phase = 0	next_phase = 1	reward = -0.323857	array([[-2.1479385, -3.2165906]], dtype=float32)

time = 63137	action = 0	current_phase = 0	next_phase = 1	reward = -0.184269	array([[-2.0802386, -3.1520238]], dtype=float32)

time = 63142	action = 0	current_phase = 0	next_phase = 1	reward = 0.281608	array([[-2.606379 , -4.3399014]], dtype=float32)

time = 63147	action = 1	current_phase = 0	next_phase = 1	reward = -1.672719	array([[-6.2132525, -3.3719094]], dtype=float32)

time = 63155	action = 0	current_phase = 1	next_phase = 0	reward = -0.525629	array([[-2.1316354, -3.3086944]], dtype=float32)

time = 63160	action = 0	current_phase = 1	next_phase = 0	reward = -0.376235	array([[-1.9996355, -3.0885544]], dtype=float32)

time = 63165	action = 0	current_phase = 1	next_phase = 0	reward = -0.227154	array([[-1.9797844, -3.070622 ]], dtype=float32)

time = 63170	action = 0	current_phase = 1	next_phase = 0	reward = 0.367311	array([[-2.184896 , -3.9459956]], dtype=float32)

time = 63175	action = 1	current_phase = 1	next_phase = 0	reward = -1.356859	array([[-3.3904738, -3.1869442]], dtype=float32)

time = 63183	action = 0	current_phase = 0	next_phase = 1	reward = -0.590677	array([[-2.3487551, -3.8669865]], dtype=float32)

time = 63188	action = 0	current_phase = 0	next_phase = 1	reward = -0.439332	array([[-2.1426995, -2.920999 ]], dtype=float32)

time = 63193	action = 0	current_phase = 0	next_phase = 1	reward = -0.286329	array([[-2.1717858, -3.240142 ]], dtype=float32)

time = 63198	action = 0	current_phase = 0	next_phase = 1	reward = -0.164743	array([[-2.3474216, -3.330129 ]], dtype=float32)

time = 63203	action = 0	current_phase = 0	next_phase = 1	reward = -0.044679	array([[-2.7032049, -4.337621 ]], dtype=float32)

time = 63208	action = 1	current_phase = 0	next_phase = 1	reward = -1.902465	array([[-6.5412097, -3.5323112]], dtype=float32)

time = 63216	action = 0	current_phase = 1	next_phase = 0	reward = -0.506280	array([[-2.1270094, -3.3185506]], dtype=float32)

time = 63221	action = 0	current_phase = 1	next_phase = 0	reward = -0.350665	array([[-2.0017064, -3.0888438]], dtype=float32)

time = 63226	action = 0	current_phase = 1	next_phase = 0	reward = -0.194774	array([[-2.055249 , -3.1407292]], dtype=float32)

time = 63231	action = 0	current_phase = 1	next_phase = 0	reward = 0.316717	array([[-2.332764 , -4.1988134]], dtype=float32)

time = 63236	action = 1	current_phase = 1	next_phase = 0	reward = -1.606868	array([[-5.7183585, -3.2818046]], dtype=float32)

time = 63244	action = 0	current_phase = 0	next_phase = 1	reward = -0.551182	array([[-2.1159708, -3.1181872]], dtype=float32)

time = 63249	action = 0	current_phase = 0	next_phase = 1	reward = -0.400714	array([[-1.8903552, -3.0341837]], dtype=float32)

time = 63254	action = 0	current_phase = 0	next_phase = 1	reward = -0.244253	array([[-1.8759886, -3.3695366]], dtype=float32)

time = 63259	action = 0	current_phase = 0	next_phase = 1	reward = -0.175751	array([[-2.0526018, -3.2073581]], dtype=float32)

time = 63264	action = 1	current_phase = 0	next_phase = 1	reward = -0.477461	array([[-5.8160963, -2.4156108]], dtype=float32)

time = 63272	action = 0	current_phase = 1	next_phase = 0	reward = -0.623299	array([[-2.3942246, -3.146577 ]], dtype=float32)

time = 63277	action = 0	current_phase = 1	next_phase = 0	reward = -0.476478	array([[-2.286   , -3.132487]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0171 - val_loss: 0.0038

Epoch 2/50

 - 4s - loss: 0.0151 - val_loss: 0.0041

Epoch 3/50

 - 4s - loss: 0.0121 - val_loss: 0.0043

Epoch 4/50

 - 4s - loss: 0.0142 - val_loss: 0.0043

Epoch 5/50

 - 4s - loss: 0.0119 - val_loss: 0.0044

Epoch 6/50

 - 4s - loss: 0.0093 - val_loss: 0.0045

Epoch 7/50

 - 4s - loss: 0.0074 - val_loss: 0.0042

Epoch 8/50

 - 4s - loss: 0.0090 - val_loss: 0.0043

Epoch 9/50

 - 4s - loss: 0.0076 - val_loss: 0.0045

Epoch 10/50

 - 4s - loss: 0.0149 - val_loss: 0.0039

Epoch 11/50

 - 4s - loss: 0.0096 - val_loss: 0.0040

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 63282	action = 0	current_phase = 1	next_phase = 0	reward = -0.335644	array([[-2.1184034, -3.1360106]], dtype=float32)

time = 63287	action = 0	current_phase = 1	next_phase = 0	reward = -0.189882	array([[-2.3167613, -3.234789 ]], dtype=float32)

time = 63292	action = 0	current_phase = 1	next_phase = 0	reward = 0.199740	array([[-2.6668282, -4.3655434]], dtype=float32)

time = 63297	action = 1	current_phase = 1	next_phase = 0	reward = -1.729093	array([[-6.350758 , -3.5291348]], dtype=float32)

time = 63305	action = 0	current_phase = 0	next_phase = 1	reward = -0.515724	array([[-2.0963774, -3.2874858]], dtype=float32)

time = 63310	action = 0	current_phase = 0	next_phase = 1	reward = -0.364204	array([[-1.9132817, -3.041336 ]], dtype=float32)

time = 63315	action = 0	current_phase = 0	next_phase = 1	reward = -0.210913	array([[-1.8836341, -3.3800015]], dtype=float32)

time = 63320	action = 0	current_phase = 0	next_phase = 1	reward = 0.351040	array([[-2.0908191, -3.8613198]], dtype=float32)

time = 63325	action = 1	current_phase = 0	next_phase = 1	reward = -1.418899	array([[-5.100071, -3.118185]], dtype=float32)

time = 63333	action = 0	current_phase = 1	next_phase = 0	reward = -0.587738	array([[-2.2086973, -3.1155338]], dtype=float32)

time = 63338	action = 0	current_phase = 1	next_phase = 0	reward = -0.426614	array([[-2.139044 , -3.1426742]], dtype=float32)

time = 63343	action = 0	current_phase = 1	next_phase = 0	reward = -0.265370	array([[-2.0726707, -3.09546  ]], dtype=float32)

time = 63348	action = 0	current_phase = 1	next_phase = 0	reward = -0.157318	array([[-2.307514, -3.253095]], dtype=float32)

time = 63353	action = 0	current_phase = 1	next_phase = 0	reward = 0.082094	array([[-2.490078, -3.236196]], dtype=float32)

time = 63358	action = 1	current_phase = 1	next_phase = 0	reward = -1.894546	array([[-6.3810487, -3.5871162]], dtype=float32)

time = 63366	action = 0	current_phase = 0	next_phase = 1	reward = -0.500655	array([[-2.067944 , -3.2819474]], dtype=float32)

time = 63371	action = 0	current_phase = 0	next_phase = 1	reward = -0.354140	array([[-2.1235275, -3.0641756]], dtype=float32)

time = 63376	action = 0	current_phase = 0	next_phase = 1	reward = -0.209724	array([[-2.051286 , -3.1342506]], dtype=float32)

time = 63381	action = 0	current_phase = 0	next_phase = 1	reward = 0.299742	array([[-2.2635462, -4.103589 ]], dtype=float32)

time = 63386	action = 1	current_phase = 0	next_phase = 1	reward = -1.610568	array([[-4.678522 , -3.3458633]], dtype=float32)

time = 63394	action = 0	current_phase = 1	next_phase = 0	reward = -0.562031	array([[-2.1424809, -3.0997229]], dtype=float32)

time = 63399	action = 0	current_phase = 1	next_phase = 0	reward = -0.406555	array([[-1.9524274, -3.0729465]], dtype=float32)

time = 63404	action = 0	current_phase = 1	next_phase = 0	reward = -0.246582	array([[-1.9004266, -3.008699 ]], dtype=float32)

time = 63409	action = 0	current_phase = 1	next_phase = 0	reward = -0.171896	array([[-2.0232866, -3.8739626]], dtype=float32)

time = 63414	action = 1	current_phase = 1	next_phase = 0	reward = -0.472323	array([[-2.5866487, -2.3547432]], dtype=float32)

time = 63422	action = 0	current_phase = 0	next_phase = 1	reward = -0.620767	array([[-2.3547192, -3.8755097]], dtype=float32)

time = 63427	action = 0	current_phase = 0	next_phase = 1	reward = -0.476427	array([[-2.1443038, -2.9363942]], dtype=float32)

time = 63432	action = 0	current_phase = 0	next_phase = 1	reward = -0.320961	array([[-2.175533, -3.251693]], dtype=float32)

time = 63437	action = 0	current_phase = 0	next_phase = 1	reward = -0.181729	array([[-2.06542  , -3.1446853]], dtype=float32)

time = 63442	action = 0	current_phase = 0	next_phase = 1	reward = 0.195544	array([[-2.6058335, -4.3389363]], dtype=float32)

time = 63447	action = 1	current_phase = 0	next_phase = 1	reward = -1.729088	array([[-6.4598255, -3.4633405]], dtype=float32)

time = 63455	action = 0	current_phase = 1	next_phase = 0	reward = -0.530255	array([[-2.081021 , -3.2913945]], dtype=float32)

time = 63460	action = 0	current_phase = 1	next_phase = 0	reward = -0.376503	array([[-1.9503776, -3.0719843]], dtype=float32)

time = 63465	action = 0	current_phase = 1	next_phase = 0	reward = -0.221809	array([[-1.9466114, -3.0561907]], dtype=float32)

time = 63470	action = 0	current_phase = 1	next_phase = 0	reward = 0.361342	array([[-2.1485062, -3.939834 ]], dtype=float32)

time = 63475	action = 1	current_phase = 1	next_phase = 0	reward = -1.415337	array([[-3.388362 , -3.2041285]], dtype=float32)

time = 63483	action = 0	current_phase = 0	next_phase = 1	reward = -0.583745	array([[-2.353248, -3.875347]], dtype=float32)

time = 63488	action = 0	current_phase = 0	next_phase = 1	reward = -0.419355	array([[-2.179582 , -2.9309878]], dtype=float32)

time = 63493	action = 0	current_phase = 0	next_phase = 1	reward = -0.263770	array([[-2.1765904, -3.251832 ]], dtype=float32)

time = 63498	action = 0	current_phase = 0	next_phase = 1	reward = -0.159988	array([[-2.358254 , -3.3489661]], dtype=float32)

time = 63503	action = 0	current_phase = 0	next_phase = 1	reward = 0.004416	array([[-2.7535706, -3.9969242]], dtype=float32)

time = 63508	action = 1	current_phase = 0	next_phase = 1	reward = -1.902900	array([[-6.5460806, -3.5418506]], dtype=float32)

time = 63516	action = 0	current_phase = 1	next_phase = 0	reward = -0.504593	array([[-2.0794141, -3.293064 ]], dtype=float32)

time = 63521	action = 0	current_phase = 1	next_phase = 0	reward = -0.355943	array([[-1.9517736, -3.0715532]], dtype=float32)

time = 63526	action = 0	current_phase = 1	next_phase = 0	reward = -0.202659	array([[-2.028107, -3.142216]], dtype=float32)

time = 63531	action = 0	current_phase = 1	next_phase = 0	reward = 0.310783	array([[-2.3117688, -4.1578684]], dtype=float32)

time = 63536	action = 1	current_phase = 1	next_phase = 0	reward = -1.556109	array([[-5.702622 , -3.2593288]], dtype=float32)

time = 63544	action = 0	current_phase = 0	next_phase = 1	reward = -0.558102	array([[-2.110594 , -3.1270463]], dtype=float32)

time = 63549	action = 0	current_phase = 0	next_phase = 1	reward = -0.401640	array([[-1.9107106, -3.0432944]], dtype=float32)

time = 63554	action = 0	current_phase = 0	next_phase = 1	reward = -0.243395	array([[-1.8851092, -3.3787305]], dtype=float32)

time = 63559	action = 0	current_phase = 0	next_phase = 1	reward = -0.174579	array([[-2.067423 , -3.2097862]], dtype=float32)

time = 63564	action = 1	current_phase = 0	next_phase = 1	reward = -0.599337	array([[-5.8358407, -2.4198554]], dtype=float32)

time = 63572	action = 0	current_phase = 1	next_phase = 0	reward = -0.612077	array([[-2.3318875, -3.1337576]], dtype=float32)

time = 63577	action = 0	current_phase = 1	next_phase = 0	reward = -0.463622	array([[-2.217558, -3.116854]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0144 - val_loss: 0.0032

Epoch 2/50

 - 4s - loss: 0.0086 - val_loss: 0.0036

Epoch 3/50

 - 4s - loss: 0.0135 - val_loss: 0.0037

Epoch 4/50

 - 4s - loss: 0.0087 - val_loss: 0.0037

Epoch 5/50

 - 4s - loss: 0.0078 - val_loss: 0.0039

Epoch 6/50

 - 4s - loss: 0.0075 - val_loss: 0.0034

Epoch 7/50

 - 4s - loss: 0.0059 - val_loss: 0.0034

Epoch 8/50

 - 4s - loss: 0.0058 - val_loss: 0.0036

Epoch 9/50

 - 4s - loss: 0.0088 - val_loss: 0.0036

Epoch 10/50

 - 4s - loss: 0.0072 - val_loss: 0.0034

Epoch 11/50

 - 4s - loss: 0.0076 - val_loss: 0.0033

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 63582	action = 0	current_phase = 1	next_phase = 0	reward = -0.318318	array([[-2.1775  , -3.153019]], dtype=float32)

time = 63587	action = 0	current_phase = 1	next_phase = 0	reward = -0.181142	array([[-2.3894947, -3.2648609]], dtype=float32)

time = 63592	action = 0	current_phase = 1	next_phase = 0	reward = 0.270457	array([[-2.686878 , -4.3877544]], dtype=float32)

time = 63597	action = 1	current_phase = 1	next_phase = 0	reward = -1.728762	array([[-6.328595 , -3.4339943]], dtype=float32)

time = 63605	action = 0	current_phase = 0	next_phase = 1	reward = -0.533424	array([[-2.1106558, -3.2794614]], dtype=float32)

time = 63610	action = 0	current_phase = 0	next_phase = 1	reward = -0.382228	array([[-1.9318703, -3.0368361]], dtype=float32)

time = 63615	action = 0	current_phase = 0	next_phase = 1	reward = -0.228504	array([[-1.8873785, -3.3795264]], dtype=float32)

time = 63620	action = 0	current_phase = 0	next_phase = 1	reward = 0.378794	array([[-2.154965 , -3.8888862]], dtype=float32)

time = 63625	action = 1	current_phase = 0	next_phase = 1	reward = -1.344602	array([[-5.002821 , -3.1702795]], dtype=float32)

time = 63633	action = 0	current_phase = 1	next_phase = 0	reward = -0.583388	array([[-2.3561435, -3.1371298]], dtype=float32)

time = 63638	action = 0	current_phase = 1	next_phase = 0	reward = -0.428711	array([[-2.145112 , -3.1431813]], dtype=float32)

time = 63643	action = 0	current_phase = 1	next_phase = 0	reward = -0.270496	array([[-2.140288 , -3.1067426]], dtype=float32)

time = 63648	action = 0	current_phase = 1	next_phase = 0	reward = -0.170109	array([[-2.3513803, -3.2468376]], dtype=float32)

time = 63653	action = 0	current_phase = 1	next_phase = 0	reward = -0.055080	array([[-2.7433398, -3.2754107]], dtype=float32)

time = 63658	action = 1	current_phase = 1	next_phase = 0	reward = -1.900208	array([[-6.396425 , -3.5571349]], dtype=float32)

time = 63666	action = 0	current_phase = 0	next_phase = 1	reward = -0.489227	array([[-2.1145258, -3.2793813]], dtype=float32)

time = 63671	action = 0	current_phase = 0	next_phase = 1	reward = -0.330933	array([[-2.053297 , -3.0107083]], dtype=float32)

time = 63676	action = 0	current_phase = 0	next_phase = 1	reward = -0.182541	array([[-2.0775561, -3.1459353]], dtype=float32)

time = 63681	action = 0	current_phase = 0	next_phase = 1	reward = 0.295637	array([[-2.3312247, -4.1043377]], dtype=float32)

time = 63686	action = 1	current_phase = 0	next_phase = 1	reward = -1.560736	array([[-4.5830784, -3.3614988]], dtype=float32)

time = 63694	action = 0	current_phase = 1	next_phase = 0	reward = -0.565499	array([[-2.1946068, -3.110425 ]], dtype=float32)

time = 63699	action = 0	current_phase = 1	next_phase = 0	reward = -0.405521	array([[-1.9701492, -3.078707 ]], dtype=float32)

time = 63704	action = 0	current_phase = 1	next_phase = 0	reward = -0.248060	array([[-2.0691218, -3.0730624]], dtype=float32)

time = 63709	action = 0	current_phase = 1	next_phase = 0	reward = -0.165418	array([[-2.3979776, -3.1564538]], dtype=float32)

time = 63714	action = 1	current_phase = 1	next_phase = 0	reward = -0.353583	array([[-2.607048 , -2.3682818]], dtype=float32)

time = 63722	action = 0	current_phase = 0	next_phase = 1	reward = -0.617085	array([[-2.3247273, -3.865286 ]], dtype=float32)

time = 63727	action = 0	current_phase = 0	next_phase = 1	reward = -0.455033	array([[-2.1232343, -2.9227288]], dtype=float32)

time = 63732	action = 0	current_phase = 0	next_phase = 1	reward = -0.297707	array([[-2.112652 , -3.0503438]], dtype=float32)

time = 63737	action = 0	current_phase = 0	next_phase = 1	reward = -0.167718	array([[-2.3226342, -3.3019304]], dtype=float32)

time = 63742	action = 0	current_phase = 0	next_phase = 1	reward = 0.146999	array([[-2.6753275, -4.334302 ]], dtype=float32)

time = 63747	action = 1	current_phase = 0	next_phase = 1	reward = -1.786215	array([[-6.445239, -3.402988]], dtype=float32)

time = 63755	action = 0	current_phase = 1	next_phase = 0	reward = -0.531708	array([[-2.1143296, -3.3077374]], dtype=float32)

time = 63760	action = 0	current_phase = 1	next_phase = 0	reward = -0.368841	array([[-1.9729619, -3.0816355]], dtype=float32)

time = 63765	action = 0	current_phase = 1	next_phase = 0	reward = -0.220439	array([[-1.9685245, -3.0425162]], dtype=float32)

time = 63770	action = 0	current_phase = 1	next_phase = 0	reward = 0.368475	array([[-2.2558024, -4.086041 ]], dtype=float32)

time = 63775	action = 1	current_phase = 1	next_phase = 0	reward = -1.253941	array([[-3.3913603, -3.1828735]], dtype=float32)

time = 63783	action = 0	current_phase = 0	next_phase = 1	reward = -0.592895	array([[-2.3228507, -3.860058 ]], dtype=float32)

time = 63788	action = 0	current_phase = 0	next_phase = 1	reward = -0.438703	array([[-2.1285033, -2.914014 ]], dtype=float32)

time = 63793	action = 0	current_phase = 0	next_phase = 1	reward = -0.281945	array([[-2.127483, -3.237485]], dtype=float32)

time = 63798	action = 0	current_phase = 0	next_phase = 1	reward = -0.164811	array([[-2.3189485, -3.2995005]], dtype=float32)

time = 63803	action = 0	current_phase = 0	next_phase = 1	reward = -0.045373	array([[-2.7004123, -4.297829 ]], dtype=float32)

time = 63808	action = 1	current_phase = 0	next_phase = 1	reward = -1.898871	array([[-6.538286, -3.517701]], dtype=float32)

time = 63816	action = 0	current_phase = 1	next_phase = 0	reward = -0.494449	array([[-2.1085954, -3.3063476]], dtype=float32)

time = 63821	action = 0	current_phase = 1	next_phase = 0	reward = -0.334082	array([[-1.9799044, -3.082153 ]], dtype=float32)

time = 63826	action = 0	current_phase = 1	next_phase = 0	reward = -0.190880	array([[-2.0158803, -3.1266227]], dtype=float32)

time = 63831	action = 0	current_phase = 1	next_phase = 0	reward = 0.295873	array([[-2.3346658, -4.201274 ]], dtype=float32)

time = 63836	action = 1	current_phase = 1	next_phase = 0	reward = -1.559781	array([[-5.7293005, -3.2596076]], dtype=float32)

time = 63844	action = 0	current_phase = 0	next_phase = 1	reward = -0.557005	array([[-2.0986123, -3.1141222]], dtype=float32)

time = 63849	action = 0	current_phase = 0	next_phase = 1	reward = -0.401943	array([[-1.9318514, -3.0367289]], dtype=float32)

time = 63854	action = 0	current_phase = 0	next_phase = 1	reward = -0.253395	array([[-1.887442, -3.379444]], dtype=float32)

time = 63859	action = 0	current_phase = 0	next_phase = 1	reward = -0.181576	array([[-2.1154904, -3.201378 ]], dtype=float32)

time = 63864	action = 1	current_phase = 0	next_phase = 1	reward = -0.601756	array([[-5.8496437, -2.436082 ]], dtype=float32)

time = 63872	action = 0	current_phase = 1	next_phase = 0	reward = -0.613099	array([[-2.4100025, -3.1412313]], dtype=float32)

time = 63877	action = 0	current_phase = 1	next_phase = 0	reward = -0.464795	array([[-2.1942089, -3.1101398]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0146 - val_loss: 0.0042

Epoch 2/50

 - 4s - loss: 0.0109 - val_loss: 0.0034

Epoch 3/50

 - 4s - loss: 0.0079 - val_loss: 0.0038

Epoch 4/50

 - 4s - loss: 0.0058 - val_loss: 0.0039

Epoch 5/50

 - 4s - loss: 0.0090 - val_loss: 0.0037

Epoch 6/50

 - 4s - loss: 0.0115 - val_loss: 0.0033

Epoch 7/50

 - 4s - loss: 0.0063 - val_loss: 0.0034

Epoch 8/50

 - 4s - loss: 0.0095 - val_loss: 0.0038

Epoch 9/50

 - 4s - loss: 0.0068 - val_loss: 0.0034

Epoch 10/50

 - 4s - loss: 0.0092 - val_loss: 0.0034

Epoch 11/50

 - 4s - loss: 0.0082 - val_loss: 0.0035

Epoch 12/50

 - 4s - loss: 0.0055 - val_loss: 0.0033

Epoch 13/50

 - 4s - loss: 0.0059 - val_loss: 0.0032

Epoch 14/50

 - 4s - loss: 0.0110 - val_loss: 0.0037

Epoch 15/50

 - 4s - loss: 0.0072 - val_loss: 0.0033

Epoch 16/50

 - 4s - loss: 0.0112 - val_loss: 0.0033

Epoch 17/50

 - 4s - loss: 0.0052 - val_loss: 0.0038

Epoch 18/50

 - 4s - loss: 0.0078 - val_loss: 0.0033

Epoch 19/50

 - 4s - loss: 0.0053 - val_loss: 0.0030

Epoch 20/50

 - 4s - loss: 0.0045 - val_loss: 0.0033

Epoch 21/50

 - 4s - loss: 0.0072 - val_loss: 0.0040

Epoch 22/50

 - 4s - loss: 0.0066 - val_loss: 0.0038

Epoch 23/50

 - 4s - loss: 0.0050 - val_loss: 0.0033

Epoch 24/50

 - 4s - loss: 0.0049 - val_loss: 0.0033

Epoch 25/50

 - 4s - loss: 0.0045 - val_loss: 0.0032

Epoch 26/50

 - 4s - loss: 0.0050 - val_loss: 0.0034

Epoch 27/50

 - 4s - loss: 0.0049 - val_loss: 0.0036

Epoch 28/50

 - 4s - loss: 0.0070 - val_loss: 0.0035

Epoch 29/50

 - 4s - loss: 0.0042 - val_loss: 0.0036

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 63882	action = 0	current_phase = 1	next_phase = 0	reward = -0.302910	array([[-2.1672947, -3.1637282]], dtype=float32)

time = 63887	action = 0	current_phase = 1	next_phase = 0	reward = -0.172926	array([[-2.3321288, -3.2540743]], dtype=float32)

time = 63892	action = 0	current_phase = 1	next_phase = 0	reward = 0.174281	array([[-2.6857862, -4.405904 ]], dtype=float32)

time = 63897	action = 1	current_phase = 1	next_phase = 0	reward = -1.784802	array([[-6.3557158, -3.4624026]], dtype=float32)

time = 63905	action = 0	current_phase = 0	next_phase = 1	reward = -0.518911	array([[-2.1225486, -3.3010323]], dtype=float32)

time = 63910	action = 0	current_phase = 0	next_phase = 1	reward = -0.355733	array([[-1.9523542, -3.057633 ]], dtype=float32)

time = 63915	action = 0	current_phase = 0	next_phase = 1	reward = -0.199845	array([[-1.8955697, -3.388233 ]], dtype=float32)

time = 63920	action = 0	current_phase = 0	next_phase = 1	reward = 0.356097	array([[-2.205954 , -3.9061892]], dtype=float32)

time = 63925	action = 1	current_phase = 0	next_phase = 1	reward = -1.367795	array([[-5.0938706, -3.1407523]], dtype=float32)

time = 63933	action = 0	current_phase = 1	next_phase = 0	reward = -0.592419	array([[-2.3182538, -3.1420808]], dtype=float32)

time = 63938	action = 0	current_phase = 1	next_phase = 0	reward = -0.437446	array([[-2.0782738, -3.135503 ]], dtype=float32)

time = 63943	action = 0	current_phase = 1	next_phase = 0	reward = -0.272331	array([[-2.1409645, -3.1399915]], dtype=float32)

time = 63948	action = 0	current_phase = 1	next_phase = 0	reward = -0.157556	array([[-2.3182383, -3.2596128]], dtype=float32)

time = 63953	action = 0	current_phase = 1	next_phase = 0	reward = 0.137509	array([[-2.6863625, -4.1854534]], dtype=float32)

time = 63958	action = 1	current_phase = 1	next_phase = 0	reward = -1.892942	array([[-6.408234 , -3.5577333]], dtype=float32)

time = 63966	action = 0	current_phase = 0	next_phase = 1	reward = -0.483422	array([[-2.130309 , -3.2982922]], dtype=float32)

time = 63971	action = 0	current_phase = 0	next_phase = 1	reward = -0.325065	array([[-2.0531168, -3.118928 ]], dtype=float32)

time = 63976	action = 0	current_phase = 0	next_phase = 1	reward = -0.179867	array([[-2.0888033, -3.1724253]], dtype=float32)

time = 63981	action = 0	current_phase = 0	next_phase = 1	reward = 0.301617	array([[-2.3882236, -4.1217685]], dtype=float32)

time = 63986	action = 1	current_phase = 0	next_phase = 1	reward = -1.559255	array([[-4.6009617, -3.3280911]], dtype=float32)

time = 63994	action = 0	current_phase = 1	next_phase = 0	reward = -0.564987	array([[-2.1513448, -3.1101394]], dtype=float32)

time = 63999	action = 0	current_phase = 1	next_phase = 0	reward = -0.416811	array([[-1.9465667, -3.0857747]], dtype=float32)

time = 64004	action = 0	current_phase = 1	next_phase = 0	reward = -0.257729	array([[-1.8939714, -3.0136974]], dtype=float32)

time = 64009	action = 0	current_phase = 1	next_phase = 0	reward = -0.168466	array([[-2.0531423, -3.8787305]], dtype=float32)

time = 64014	action = 1	current_phase = 1	next_phase = 0	reward = -0.430241	array([[-2.5791445, -2.342622 ]], dtype=float32)

time = 64022	action = 0	current_phase = 0	next_phase = 1	reward = -0.619540	array([[-2.323176 , -3.8827581]], dtype=float32)

time = 64027	action = 0	current_phase = 0	next_phase = 1	reward = -0.468794	array([[-2.1747046, -2.949035 ]], dtype=float32)

time = 64032	action = 0	current_phase = 0	next_phase = 1	reward = -0.318364	array([[-2.105536 , -3.2495916]], dtype=float32)

time = 64037	action = 0	current_phase = 0	next_phase = 1	reward = -0.178814	array([[-2.3012567, -3.3012843]], dtype=float32)

time = 64042	action = 0	current_phase = 0	next_phase = 1	reward = 0.226645	array([[-2.6522694, -4.294167 ]], dtype=float32)

time = 64047	action = 1	current_phase = 0	next_phase = 1	reward = -1.777571	array([[-6.2345643, -3.4150314]], dtype=float32)

time = 64055	action = 0	current_phase = 1	next_phase = 0	reward = -0.530926	array([[-2.0858667, -3.3119526]], dtype=float32)

time = 64060	action = 0	current_phase = 1	next_phase = 0	reward = -0.377019	array([[-1.9479344, -3.0867302]], dtype=float32)

time = 64065	action = 0	current_phase = 1	next_phase = 0	reward = -0.229133	array([[-1.897304 , -3.0169022]], dtype=float32)

time = 64070	action = 0	current_phase = 1	next_phase = 0	reward = 0.087852	array([[-2.126189 , -3.9779844]], dtype=float32)

time = 64075	action = 1	current_phase = 1	next_phase = 0	reward = -0.964691	array([[-2.9159083, -2.7588243]], dtype=float32)

time = 64083	action = 0	current_phase = 0	next_phase = 1	reward = -0.585591	array([[-2.3199873, -3.8800492]], dtype=float32)

time = 64088	action = 0	current_phase = 0	next_phase = 1	reward = -0.435054	array([[-2.1472049, -2.9378111]], dtype=float32)

time = 64093	action = 0	current_phase = 0	next_phase = 1	reward = -0.284982	array([[-2.110539 , -3.2524347]], dtype=float32)

time = 64098	action = 0	current_phase = 0	next_phase = 1	reward = -0.166758	array([[-2.3781714, -3.3498094]], dtype=float32)

time = 64103	action = 0	current_phase = 0	next_phase = 1	reward = -0.001686	array([[-2.757018 , -3.9566884]], dtype=float32)

time = 64108	action = 1	current_phase = 0	next_phase = 1	reward = -1.904275	array([[-6.556658 , -3.5613797]], dtype=float32)

time = 64116	action = 0	current_phase = 1	next_phase = 0	reward = -0.498726	array([[-2.0858264, -3.3144176]], dtype=float32)

time = 64121	action = 0	current_phase = 1	next_phase = 0	reward = -0.345057	array([[-1.958921, -3.091014]], dtype=float32)

time = 64126	action = 0	current_phase = 1	next_phase = 0	reward = -0.194759	array([[-2.0161035, -3.1440468]], dtype=float32)

time = 64131	action = 0	current_phase = 1	next_phase = 0	reward = 0.331061	array([[-2.3059447, -4.2007117]], dtype=float32)

time = 64136	action = 1	current_phase = 1	next_phase = 0	reward = -1.500829	array([[-5.743299 , -3.2410822]], dtype=float32)

time = 64144	action = 0	current_phase = 0	next_phase = 1	reward = -0.555288	array([[-2.105394 , -3.1321926]], dtype=float32)

time = 64149	action = 0	current_phase = 0	next_phase = 1	reward = -0.396304	array([[-1.9518324, -3.0582569]], dtype=float32)

time = 64154	action = 0	current_phase = 0	next_phase = 1	reward = -0.240528	array([[-1.8936744, -3.3875191]], dtype=float32)

time = 64159	action = 0	current_phase = 0	next_phase = 1	reward = -0.177623	array([[-2.1643186, -3.220235 ]], dtype=float32)

time = 64164	action = 1	current_phase = 0	next_phase = 1	reward = -0.586502	array([[-5.8678846, -2.3578987]], dtype=float32)

time = 64172	action = 0	current_phase = 1	next_phase = 0	reward = -0.622298	array([[-2.3902805, -3.1495764]], dtype=float32)

time = 64177	action = 0	current_phase = 1	next_phase = 0	reward = -0.469722	array([[-2.160947, -3.112655]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0097 - val_loss: 0.0122

Epoch 2/50

 - 4s - loss: 0.0073 - val_loss: 0.0118

Epoch 3/50

 - 4s - loss: 0.0121 - val_loss: 0.0122

Epoch 4/50

 - 4s - loss: 0.0087 - val_loss: 0.0124

Epoch 5/50

 - 4s - loss: 0.0070 - val_loss: 0.0118

Epoch 6/50

 - 4s - loss: 0.0066 - val_loss: 0.0122

Epoch 7/50

 - 4s - loss: 0.0070 - val_loss: 0.0122

Epoch 8/50

 - 4s - loss: 0.0111 - val_loss: 0.0123

Epoch 9/50

 - 4s - loss: 0.0064 - val_loss: 0.0121

Epoch 10/50

 - 4s - loss: 0.0060 - val_loss: 0.0125

Epoch 11/50

 - 4s - loss: 0.0067 - val_loss: 0.0115

Epoch 12/50

 - 4s - loss: 0.0071 - val_loss: 0.0121

Epoch 13/50

 - 4s - loss: 0.0069 - val_loss: 0.0121

Epoch 14/50

 - 4s - loss: 0.0069 - val_loss: 0.0117

Epoch 15/50

 - 4s - loss: 0.0072 - val_loss: 0.0111

Epoch 16/50

 - 4s - loss: 0.0095 - val_loss: 0.0111

Epoch 17/50

 - 4s - loss: 0.0061 - val_loss: 0.0116

Epoch 18/50

 - 4s - loss: 0.0062 - val_loss: 0.0112

Epoch 19/50

 - 4s - loss: 0.0061 - val_loss: 0.0116

Epoch 20/50

 - 4s - loss: 0.0052 - val_loss: 0.0114

Epoch 21/50

 - 4s - loss: 0.0073 - val_loss: 0.0113

Epoch 22/50

 - 6s - loss: 0.0052 - val_loss: 0.0116

Epoch 23/50

 - 4s - loss: 0.0061 - val_loss: 0.0113

Epoch 24/50

 - 4s - loss: 0.0066 - val_loss: 0.0108

Epoch 25/50

 - 4s - loss: 0.0053 - val_loss: 0.0120

Epoch 26/50

 - 4s - loss: 0.0073 - val_loss: 0.0102

Epoch 27/50

 - 4s - loss: 0.0069 - val_loss: 0.0108

Epoch 28/50

 - 4s - loss: 0.0050 - val_loss: 0.0117

Epoch 29/50

 - 4s - loss: 0.0050 - val_loss: 0.0121

Epoch 30/50

 - 4s - loss: 0.0059 - val_loss: 0.0117

Epoch 31/50

 - 4s - loss: 0.0060 - val_loss: 0.0107

Epoch 32/50

 - 4s - loss: 0.0054 - val_loss: 0.0120

Epoch 33/50

 - 4s - loss: 0.0062 - val_loss: 0.0115

Epoch 34/50

 - 4s - loss: 0.0057 - val_loss: 0.0117

Epoch 35/50

 - 4s - loss: 0.0051 - val_loss: 0.0112

Epoch 36/50

 - 4s - loss: 0.0072 - val_loss: 0.0117

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 64182	action = 0	current_phase = 1	next_phase = 0	reward = -0.309171	array([[-2.1702802, -3.1577003]], dtype=float32)

time = 64187	action = 0	current_phase = 1	next_phase = 0	reward = -0.175445	array([[-2.3268645, -3.2336307]], dtype=float32)

time = 64192	action = 0	current_phase = 1	next_phase = 0	reward = 0.263271	array([[-2.6194236, -4.373212 ]], dtype=float32)

time = 64197	action = 1	current_phase = 1	next_phase = 0	reward = -1.720973	array([[-6.357164 , -3.4176815]], dtype=float32)

time = 64205	action = 0	current_phase = 0	next_phase = 1	reward = -0.514235	array([[-2.1349342, -3.3151617]], dtype=float32)

time = 64210	action = 0	current_phase = 0	next_phase = 1	reward = -0.364420	array([[-1.9401954, -3.084842 ]], dtype=float32)

time = 64215	action = 0	current_phase = 0	next_phase = 1	reward = -0.209975	array([[-1.8926145, -3.4050689]], dtype=float32)

time = 64220	action = 0	current_phase = 0	next_phase = 1	reward = 0.339378	array([[-2.1943936, -3.9276145]], dtype=float32)

time = 64225	action = 1	current_phase = 0	next_phase = 1	reward = -1.372084	array([[-5.0934744, -3.1491246]], dtype=float32)

time = 64233	action = 0	current_phase = 1	next_phase = 0	reward = -0.590937	array([[-2.3479736, -3.155984 ]], dtype=float32)

time = 64238	action = 0	current_phase = 1	next_phase = 0	reward = -0.432256	array([[-2.1251414, -3.1437483]], dtype=float32)

time = 64243	action = 0	current_phase = 1	next_phase = 0	reward = -0.272162	array([[-2.149992, -3.125671]], dtype=float32)

time = 64248	action = 0	current_phase = 1	next_phase = 0	reward = -0.160274	array([[-2.3095887, -3.250633 ]], dtype=float32)

time = 64253	action = 0	current_phase = 1	next_phase = 0	reward = 0.068749	array([[-2.6832738, -3.510635 ]], dtype=float32)

time = 64258	action = 1	current_phase = 1	next_phase = 0	reward = -1.905469	array([[-6.418588 , -3.5636508]], dtype=float32)

time = 64266	action = 0	current_phase = 0	next_phase = 1	reward = -0.506210	array([[-2.1303074, -3.314185 ]], dtype=float32)

time = 64271	action = 0	current_phase = 0	next_phase = 1	reward = -0.347294	array([[-1.9494189, -3.093205 ]], dtype=float32)

time = 64276	action = 0	current_phase = 0	next_phase = 1	reward = -0.192928	array([[-2.0285916, -3.17975  ]], dtype=float32)

time = 64281	action = 0	current_phase = 0	next_phase = 1	reward = 0.323989	array([[-2.4194255, -4.14993  ]], dtype=float32)

time = 64286	action = 1	current_phase = 0	next_phase = 1	reward = -1.505063	array([[-4.670142 , -3.3077102]], dtype=float32)

time = 64294	action = 0	current_phase = 1	next_phase = 0	reward = -0.555475	array([[-2.1103704, -3.1077776]], dtype=float32)

time = 64299	action = 0	current_phase = 1	next_phase = 0	reward = -0.397745	array([[-1.9424952, -3.0752292]], dtype=float32)

time = 64304	action = 0	current_phase = 1	next_phase = 0	reward = -0.247468	array([[-1.9477243, -3.0147285]], dtype=float32)

time = 64309	action = 0	current_phase = 1	next_phase = 0	reward = 0.115718	array([[-2.063262 , -3.8772228]], dtype=float32)

time = 64314	action = 1	current_phase = 1	next_phase = 0	reward = -0.693529	array([[-3.0230083, -2.8711088]], dtype=float32)

time = 64322	action = 0	current_phase = 0	next_phase = 1	reward = -0.617758	array([[-2.3316147, -3.9462004]], dtype=float32)

time = 64327	action = 0	current_phase = 0	next_phase = 1	reward = -0.468837	array([[-2.1714616, -2.9566832]], dtype=float32)

time = 64332	action = 0	current_phase = 0	next_phase = 1	reward = -0.327613	array([[-2.078905 , -3.2425084]], dtype=float32)

time = 64337	action = 0	current_phase = 0	next_phase = 1	reward = -0.189579	array([[-2.2472703, -3.313707 ]], dtype=float32)

time = 64342	action = 0	current_phase = 0	next_phase = 1	reward = 0.251295	array([[-2.7070632, -4.394332 ]], dtype=float32)

time = 64347	action = 1	current_phase = 0	next_phase = 1	reward = -1.723788	array([[-6.27861  , -3.4061902]], dtype=float32)

time = 64355	action = 0	current_phase = 1	next_phase = 0	reward = -0.522361	array([[-2.0792882, -3.292694 ]], dtype=float32)

time = 64360	action = 0	current_phase = 1	next_phase = 0	reward = -0.365089	array([[-1.9557796, -3.081053 ]], dtype=float32)

time = 64365	action = 0	current_phase = 1	next_phase = 0	reward = -0.211288	array([[-1.9272714, -3.0100412]], dtype=float32)

time = 64370	action = 0	current_phase = 1	next_phase = 0	reward = 0.357814	array([[-2.158926 , -3.9121425]], dtype=float32)

time = 64375	action = 1	current_phase = 1	next_phase = 0	reward = -1.202039	array([[-3.4889529, -3.2121422]], dtype=float32)

time = 64383	action = 0	current_phase = 0	next_phase = 1	reward = -0.595508	array([[-2.320463 , -3.9279008]], dtype=float32)

time = 64388	action = 0	current_phase = 0	next_phase = 1	reward = -0.435826	array([[-2.1729014, -2.9551153]], dtype=float32)

time = 64393	action = 0	current_phase = 0	next_phase = 1	reward = -0.283245	array([[-2.1260617, -3.2639246]], dtype=float32)

time = 64398	action = 0	current_phase = 0	next_phase = 1	reward = -0.164352	array([[-2.357849, -3.385675]], dtype=float32)

time = 64403	action = 0	current_phase = 0	next_phase = 1	reward = 0.001075	array([[-2.8490965, -4.380955 ]], dtype=float32)

time = 64408	action = 1	current_phase = 0	next_phase = 1	reward = -1.905269	array([[-6.5886073, -3.5692883]], dtype=float32)

time = 64416	action = 0	current_phase = 1	next_phase = 0	reward = -0.507895	array([[-2.0789666, -3.296089 ]], dtype=float32)

time = 64421	action = 0	current_phase = 1	next_phase = 0	reward = -0.359545	array([[-1.9481751, -3.077844 ]], dtype=float32)

time = 64426	action = 0	current_phase = 1	next_phase = 0	reward = -0.205961	array([[-2.0506713, -3.1456885]], dtype=float32)

time = 64431	action = 0	current_phase = 1	next_phase = 0	reward = 0.333864	array([[-2.3013453, -4.153692 ]], dtype=float32)

time = 64436	action = 1	current_phase = 1	next_phase = 0	reward = -1.498935	array([[-5.7639084, -3.2476912]], dtype=float32)

time = 64444	action = 0	current_phase = 0	next_phase = 1	reward = -0.556717	array([[-2.092319, -3.155946]], dtype=float32)

time = 64449	action = 0	current_phase = 0	next_phase = 1	reward = -0.406275	array([[-1.942567, -3.082111]], dtype=float32)

time = 64454	action = 0	current_phase = 0	next_phase = 1	reward = -0.249452	array([[-1.8967233, -3.3997614]], dtype=float32)

time = 64459	action = 0	current_phase = 0	next_phase = 1	reward = -0.179666	array([[-2.1172743, -3.243951 ]], dtype=float32)

time = 64464	action = 1	current_phase = 0	next_phase = 1	reward = -0.605974	array([[-5.8815594, -2.4269714]], dtype=float32)

time = 64472	action = 0	current_phase = 1	next_phase = 0	reward = -0.621489	array([[-2.3673823, -3.158094 ]], dtype=float32)

time = 64477	action = 0	current_phase = 1	next_phase = 0	reward = -0.469308	array([[-2.1707325, -3.123803 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0094 - val_loss: 0.0073

Epoch 2/50

 - 4s - loss: 0.0117 - val_loss: 0.0081

Epoch 3/50

 - 4s - loss: 0.0090 - val_loss: 0.0079

Epoch 4/50

 - 4s - loss: 0.0084 - val_loss: 0.0076

Epoch 5/50

 - 4s - loss: 0.0075 - val_loss: 0.0083

Epoch 6/50

 - 4s - loss: 0.0082 - val_loss: 0.0084

Epoch 7/50

 - 4s - loss: 0.0059 - val_loss: 0.0082

Epoch 8/50

 - 4s - loss: 0.0082 - val_loss: 0.0077

Epoch 9/50

 - 4s - loss: 0.0060 - val_loss: 0.0080

Epoch 10/50

 - 4s - loss: 0.0074 - val_loss: 0.0084

Epoch 11/50

 - 4s - loss: 0.0056 - val_loss: 0.0083

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 64482	action = 0	current_phase = 1	next_phase = 0	reward = -0.313926	array([[-2.1516554, -3.1508288]], dtype=float32)

time = 64487	action = 0	current_phase = 1	next_phase = 0	reward = -0.177726	array([[-2.3230224, -3.2571461]], dtype=float32)

time = 64492	action = 0	current_phase = 1	next_phase = 0	reward = 0.177499	array([[-2.6176672, -4.364938 ]], dtype=float32)

time = 64497	action = 1	current_phase = 1	next_phase = 0	reward = -1.782065	array([[-6.355214 , -3.4336512]], dtype=float32)

time = 64505	action = 0	current_phase = 0	next_phase = 1	reward = -0.528845	array([[-2.0712907, -3.3154013]], dtype=float32)

time = 64510	action = 0	current_phase = 0	next_phase = 1	reward = -0.377725	array([[-1.905502, -3.103144]], dtype=float32)

time = 64515	action = 0	current_phase = 0	next_phase = 1	reward = -0.221553	array([[-1.8596723, -3.401947 ]], dtype=float32)

time = 64520	action = 0	current_phase = 0	next_phase = 1	reward = 0.057402	array([[-2.15118 , -3.859689]], dtype=float32)

time = 64525	action = 1	current_phase = 0	next_phase = 1	reward = -1.085761	array([[-5.546659 , -2.9200366]], dtype=float32)

time = 64533	action = 0	current_phase = 1	next_phase = 0	reward = -0.592443	array([[-2.3520887, -3.150893 ]], dtype=float32)

time = 64538	action = 0	current_phase = 1	next_phase = 0	reward = -0.442594	array([[-2.1409786, -3.146364 ]], dtype=float32)

time = 64543	action = 0	current_phase = 1	next_phase = 0	reward = -0.285909	array([[-2.1576679, -3.1491845]], dtype=float32)

time = 64548	action = 0	current_phase = 1	next_phase = 0	reward = -0.163339	array([[-2.3101947, -3.249157 ]], dtype=float32)

time = 64553	action = 0	current_phase = 1	next_phase = 0	reward = 0.146075	array([[-2.6780686, -4.3300114]], dtype=float32)

time = 64558	action = 1	current_phase = 1	next_phase = 0	reward = -1.891120	array([[-6.3942723, -3.524334 ]], dtype=float32)

time = 64566	action = 0	current_phase = 0	next_phase = 1	reward = -0.491625	array([[-2.10861  , -3.3215997]], dtype=float32)

time = 64571	action = 0	current_phase = 0	next_phase = 1	reward = -0.325247	array([[-1.935896, -3.0854  ]], dtype=float32)

time = 64576	action = 0	current_phase = 0	next_phase = 1	reward = -0.184514	array([[-1.9960691, -3.1916442]], dtype=float32)

time = 64581	action = 0	current_phase = 0	next_phase = 1	reward = 0.325452	array([[-2.3723462, -4.1584845]], dtype=float32)

time = 64586	action = 1	current_phase = 0	next_phase = 1	reward = -1.559394	array([[-4.5984716, -3.3579698]], dtype=float32)

time = 64594	action = 0	current_phase = 1	next_phase = 0	reward = -0.557856	array([[-2.1485565, -3.1124694]], dtype=float32)

time = 64599	action = 0	current_phase = 1	next_phase = 0	reward = -0.413676	array([[-1.9350442, -3.0688803]], dtype=float32)

time = 64604	action = 0	current_phase = 1	next_phase = 0	reward = -0.253091	array([[-1.9137764, -2.9935555]], dtype=float32)

time = 64609	action = 0	current_phase = 1	next_phase = 0	reward = -0.166229	array([[-2.0616496, -3.8862374]], dtype=float32)

time = 64614	action = 1	current_phase = 1	next_phase = 0	reward = -0.391800	array([[-2.5526516, -2.3194306]], dtype=float32)

time = 64622	action = 0	current_phase = 0	next_phase = 1	reward = -0.620208	array([[-2.2984703, -3.9403243]], dtype=float32)

time = 64627	action = 0	current_phase = 0	next_phase = 1	reward = -0.471776	array([[-2.1460383, -2.9645236]], dtype=float32)

time = 64632	action = 0	current_phase = 0	next_phase = 1	reward = -0.317026	array([[-2.0142245, -3.1967406]], dtype=float32)

time = 64637	action = 0	current_phase = 0	next_phase = 1	reward = -0.175211	array([[-2.2733655, -3.346076 ]], dtype=float32)

time = 64642	action = 0	current_phase = 0	next_phase = 1	reward = 0.199395	array([[-2.6341734, -4.4278684]], dtype=float32)

time = 64647	action = 1	current_phase = 0	next_phase = 1	reward = -1.777352	array([[-6.453283 , -3.4799478]], dtype=float32)

time = 64655	action = 0	current_phase = 1	next_phase = 0	reward = -0.518363	array([[-2.0699964, -3.291005 ]], dtype=float32)

time = 64660	action = 0	current_phase = 1	next_phase = 0	reward = -0.368204	array([[-1.9344524, -3.0692697]], dtype=float32)

time = 64665	action = 0	current_phase = 1	next_phase = 0	reward = -0.217008	array([[-1.9988879, -3.063166 ]], dtype=float32)

time = 64670	action = 0	current_phase = 1	next_phase = 0	reward = 0.344222	array([[-2.2605252, -4.1168976]], dtype=float32)

time = 64675	action = 1	current_phase = 1	next_phase = 0	reward = -1.264967	array([[-3.4530287, -3.2273781]], dtype=float32)

time = 64683	action = 0	current_phase = 0	next_phase = 1	reward = -0.590620	array([[-2.2960322, -3.9396703]], dtype=float32)

time = 64688	action = 0	current_phase = 0	next_phase = 1	reward = -0.429319	array([[-2.1542966, -2.9632885]], dtype=float32)

time = 64693	action = 0	current_phase = 0	next_phase = 1	reward = -0.284226	array([[-2.1079412, -3.2518022]], dtype=float32)

time = 64698	action = 0	current_phase = 0	next_phase = 1	reward = -0.166455	array([[-2.32078  , -3.3738973]], dtype=float32)

time = 64703	action = 0	current_phase = 0	next_phase = 1	reward = -0.046033	array([[-2.8114123, -4.3627305]], dtype=float32)

time = 64708	action = 1	current_phase = 0	next_phase = 1	reward = -1.903025	array([[-6.6022177, -3.5475705]], dtype=float32)

time = 64716	action = 0	current_phase = 1	next_phase = 0	reward = -0.493114	array([[-2.067687 , -3.2890947]], dtype=float32)

time = 64721	action = 0	current_phase = 1	next_phase = 0	reward = -0.334382	array([[-1.9443904, -3.073006 ]], dtype=float32)

time = 64726	action = 0	current_phase = 1	next_phase = 0	reward = -0.191551	array([[-2.0456462, -3.143159 ]], dtype=float32)

time = 64731	action = 0	current_phase = 1	next_phase = 0	reward = 0.284417	array([[-2.2870555, -4.15664  ]], dtype=float32)

time = 64736	action = 1	current_phase = 1	next_phase = 0	reward = -1.666486	array([[-5.7587647, -3.2664506]], dtype=float32)

time = 64744	action = 0	current_phase = 0	next_phase = 1	reward = -0.554326	array([[-2.0701768, -3.1693945]], dtype=float32)

time = 64749	action = 0	current_phase = 0	next_phase = 1	reward = -0.385796	array([[-1.9047344, -3.102775 ]], dtype=float32)

time = 64754	action = 0	current_phase = 0	next_phase = 1	reward = -0.235174	array([[-1.8644263, -3.3958457]], dtype=float32)

time = 64759	action = 0	current_phase = 0	next_phase = 1	reward = -0.183354	array([[-2.0968163, -3.2552521]], dtype=float32)

time = 64764	action = 1	current_phase = 0	next_phase = 1	reward = -0.542894	array([[-5.886106, -2.431719]], dtype=float32)

time = 64772	action = 0	current_phase = 1	next_phase = 0	reward = -0.613455	array([[-2.378859 , -3.1531692]], dtype=float32)

time = 64777	action = 0	current_phase = 1	next_phase = 0	reward = -0.463782	array([[-2.1793928, -3.1202514]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0079 - val_loss: 0.0020

Epoch 2/50

 - 4s - loss: 0.0067 - val_loss: 0.0023

Epoch 3/50

 - 4s - loss: 0.0071 - val_loss: 0.0021

Epoch 4/50

 - 4s - loss: 0.0082 - val_loss: 0.0021

Epoch 5/50

 - 4s - loss: 0.0064 - val_loss: 0.0022

Epoch 6/50

 - 4s - loss: 0.0069 - val_loss: 0.0022

Epoch 7/50

 - 4s - loss: 0.0068 - val_loss: 0.0023

Epoch 8/50

 - 4s - loss: 0.0071 - val_loss: 0.0030

Epoch 9/50

 - 4s - loss: 0.0060 - val_loss: 0.0024

Epoch 10/50

 - 4s - loss: 0.0064 - val_loss: 0.0025

Epoch 11/50

 - 4s - loss: 0.0078 - val_loss: 0.0025

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 64782	action = 0	current_phase = 1	next_phase = 0	reward = -0.312190	array([[-2.1374147, -3.1563601]], dtype=float32)

time = 64787	action = 0	current_phase = 1	next_phase = 0	reward = -0.175218	array([[-2.3164663, -3.2656648]], dtype=float32)

time = 64792	action = 0	current_phase = 1	next_phase = 0	reward = 0.117451	array([[-2.7076669, -4.328463 ]], dtype=float32)

time = 64797	action = 1	current_phase = 1	next_phase = 0	reward = -1.787811	array([[-6.3650255, -3.4769058]], dtype=float32)

time = 64805	action = 0	current_phase = 0	next_phase = 1	reward = -0.528828	array([[-2.0905857, -3.3224082]], dtype=float32)

time = 64810	action = 0	current_phase = 0	next_phase = 1	reward = -0.371112	array([[-1.908066 , -3.1112714]], dtype=float32)

time = 64815	action = 0	current_phase = 0	next_phase = 1	reward = -0.219057	array([[-1.8451723, -3.428101 ]], dtype=float32)

time = 64820	action = 0	current_phase = 0	next_phase = 1	reward = 0.356053	array([[-2.1481655, -3.9164817]], dtype=float32)

time = 64825	action = 1	current_phase = 0	next_phase = 1	reward = -1.307029	array([[-5.0465403, -3.1366274]], dtype=float32)

time = 64833	action = 0	current_phase = 1	next_phase = 0	reward = -0.584004	array([[-2.2979496, -3.1635027]], dtype=float32)

time = 64838	action = 0	current_phase = 1	next_phase = 0	reward = -0.425573	array([[-2.057798 , -3.1284828]], dtype=float32)

time = 64843	action = 0	current_phase = 1	next_phase = 0	reward = -0.274423	array([[-2.088215 , -3.1126378]], dtype=float32)

time = 64848	action = 0	current_phase = 1	next_phase = 0	reward = -0.168670	array([[-2.3104033, -3.3054545]], dtype=float32)

time = 64853	action = 0	current_phase = 1	next_phase = 0	reward = -0.054688	array([[-2.79476  , -3.7564902]], dtype=float32)

time = 64858	action = 1	current_phase = 1	next_phase = 0	reward = -1.905798	array([[-6.404937, -3.574656]], dtype=float32)

time = 64866	action = 0	current_phase = 0	next_phase = 1	reward = -0.501345	array([[-2.0891542, -3.3226943]], dtype=float32)

time = 64871	action = 0	current_phase = 0	next_phase = 1	reward = -0.345561	array([[-1.9147861, -3.1083922]], dtype=float32)

time = 64876	action = 0	current_phase = 0	next_phase = 1	reward = -0.188248	array([[-1.9639525, -3.2150383]], dtype=float32)

time = 64881	action = 0	current_phase = 0	next_phase = 1	reward = 0.296703	array([[-2.3194857, -4.164672 ]], dtype=float32)

time = 64886	action = 1	current_phase = 0	next_phase = 1	reward = -1.658340	array([[-4.615878 , -3.3365445]], dtype=float32)

time = 64894	action = 0	current_phase = 1	next_phase = 0	reward = -0.551798	array([[-2.1128354, -3.1206884]], dtype=float32)

time = 64899	action = 0	current_phase = 1	next_phase = 0	reward = -0.400540	array([[-1.9300569, -3.0782971]], dtype=float32)

time = 64904	action = 0	current_phase = 1	next_phase = 0	reward = -0.249016	array([[-1.8731408, -2.9926004]], dtype=float32)

time = 64909	action = 0	current_phase = 1	next_phase = 0	reward = -0.175654	array([[-2.0673819, -3.8629415]], dtype=float32)

time = 64914	action = 1	current_phase = 1	next_phase = 0	reward = -0.530884	array([[-2.5856526, -2.4209332]], dtype=float32)

time = 64922	action = 0	current_phase = 0	next_phase = 1	reward = -0.612306	array([[-2.2908301, -3.9348915]], dtype=float32)

time = 64927	action = 0	current_phase = 0	next_phase = 1	reward = -0.456110	array([[-2.1407456, -2.9625642]], dtype=float32)

time = 64932	action = 0	current_phase = 0	next_phase = 1	reward = -0.303867	array([[-2.080817, -3.26541 ]], dtype=float32)

time = 64937	action = 0	current_phase = 0	next_phase = 1	reward = -0.170740	array([[-2.2644072, -3.378322 ]], dtype=float32)

time = 64942	action = 0	current_phase = 0	next_phase = 1	reward = 0.220760	array([[-2.5831041, -4.449773 ]], dtype=float32)

time = 64947	action = 1	current_phase = 0	next_phase = 1	reward = -1.732171	array([[-6.2755947, -3.3653095]], dtype=float32)

time = 64955	action = 0	current_phase = 1	next_phase = 0	reward = -0.529953	array([[-2.080397, -3.298311]], dtype=float32)

time = 64960	action = 0	current_phase = 1	next_phase = 0	reward = -0.375303	array([[-1.9340171, -3.0806036]], dtype=float32)

time = 64965	action = 0	current_phase = 1	next_phase = 0	reward = -0.225686	array([[-1.9538035, -3.0336668]], dtype=float32)

time = 64970	action = 0	current_phase = 1	next_phase = 0	reward = 0.356820	array([[-2.2352543, -4.045176 ]], dtype=float32)

time = 64975	action = 1	current_phase = 1	next_phase = 0	reward = -1.307276	array([[-3.4252646, -3.1892269]], dtype=float32)

time = 64983	action = 0	current_phase = 0	next_phase = 1	reward = -0.590246	array([[-2.2907782, -3.93435  ]], dtype=float32)

time = 64988	action = 0	current_phase = 0	next_phase = 1	reward = -0.436892	array([[-2.1458173, -2.961025 ]], dtype=float32)

time = 64993	action = 0	current_phase = 0	next_phase = 1	reward = -0.277360	array([[-2.0809755, -3.2651322]], dtype=float32)

time = 64998	action = 0	current_phase = 0	next_phase = 1	reward = -0.161729	array([[-2.295714 , -3.3975933]], dtype=float32)

time = 65003	action = 0	current_phase = 0	next_phase = 1	reward = 0.015935	array([[-2.7528622, -4.3752503]], dtype=float32)

time = 65008	action = 1	current_phase = 0	next_phase = 1	reward = -1.904049	array([[-6.5643225, -3.5536766]], dtype=float32)

time = 65016	action = 0	current_phase = 1	next_phase = 0	reward = -0.500280	array([[-2.0791245, -3.301915 ]], dtype=float32)

time = 65021	action = 0	current_phase = 1	next_phase = 0	reward = -0.340142	array([[-1.9335839, -3.0798302]], dtype=float32)

time = 65026	action = 0	current_phase = 1	next_phase = 0	reward = -0.192073	array([[-2.0616732, -3.151318 ]], dtype=float32)

time = 65031	action = 0	current_phase = 1	next_phase = 0	reward = 0.327469	array([[-2.312356 , -4.1648173]], dtype=float32)

time = 65036	action = 1	current_phase = 1	next_phase = 0	reward = -1.555176	array([[-5.782938 , -3.2901862]], dtype=float32)

time = 65044	action = 0	current_phase = 0	next_phase = 1	reward = -0.563180	array([[-2.0679479, -3.1680474]], dtype=float32)

time = 65049	action = 0	current_phase = 0	next_phase = 1	reward = -0.409793	array([[-1.9096928, -3.1094615]], dtype=float32)

time = 65054	action = 0	current_phase = 0	next_phase = 1	reward = -0.251978	array([[-1.8452597, -3.4279304]], dtype=float32)

time = 65059	action = 0	current_phase = 0	next_phase = 1	reward = -0.179657	array([[-2.0928354, -3.2901227]], dtype=float32)

time = 65064	action = 1	current_phase = 0	next_phase = 1	reward = -0.449410	array([[-5.9010034, -2.4345071]], dtype=float32)

time = 65072	action = 0	current_phase = 1	next_phase = 0	reward = -0.619262	array([[-2.3795245, -3.1739645]], dtype=float32)

time = 65077	action = 0	current_phase = 1	next_phase = 0	reward = -0.456048	array([[-2.1384158, -3.1279757]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0166 - val_loss: 0.0060

Epoch 2/50

 - 4s - loss: 0.0144 - val_loss: 0.0061

Epoch 3/50

 - 4s - loss: 0.0111 - val_loss: 0.0051

Epoch 4/50

 - 4s - loss: 0.0115 - val_loss: 0.0060

Epoch 5/50

 - 4s - loss: 0.0090 - val_loss: 0.0058

Epoch 6/50

 - 4s - loss: 0.0124 - val_loss: 0.0068

Epoch 7/50

 - 4s - loss: 0.0114 - val_loss: 0.0071

Epoch 8/50

 - 4s - loss: 0.0102 - val_loss: 0.0069

Epoch 9/50

 - 4s - loss: 0.0113 - val_loss: 0.0079

Epoch 10/50

 - 4s - loss: 0.0111 - val_loss: 0.0064

Epoch 11/50

 - 4s - loss: 0.0102 - val_loss: 0.0055

Epoch 12/50

 - 4s - loss: 0.0106 - val_loss: 0.0050

Epoch 13/50

 - 4s - loss: 0.0099 - val_loss: 0.0055

Epoch 14/50

 - 4s - loss: 0.0093 - val_loss: 0.0060

Epoch 15/50

 - 4s - loss: 0.0103 - val_loss: 0.0050

Epoch 16/50

 - 4s - loss: 0.0101 - val_loss: 0.0047

Epoch 17/50

 - 4s - loss: 0.0075 - val_loss: 0.0064

Epoch 18/50

 - 4s - loss: 0.0063 - val_loss: 0.0062

Epoch 19/50

 - 4s - loss: 0.0114 - val_loss: 0.0054

Epoch 20/50

 - 4s - loss: 0.0071 - val_loss: 0.0052

Epoch 21/50

 - 4s - loss: 0.0086 - val_loss: 0.0056

Epoch 22/50

 - 4s - loss: 0.0077 - val_loss: 0.0060

Epoch 23/50

 - 4s - loss: 0.0116 - val_loss: 0.0056

Epoch 24/50

 - 4s - loss: 0.0104 - val_loss: 0.0059

Epoch 25/50

 - 4s - loss: 0.0076 - val_loss: 0.0053

Epoch 26/50

 - 4s - loss: 0.0065 - val_loss: 0.0060

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 65082	action = 0	current_phase = 1	next_phase = 0	reward = -0.291874	array([[-2.169442 , -3.1606324]], dtype=float32)

time = 65087	action = 0	current_phase = 1	next_phase = 0	reward = -0.172440	array([[-2.3933659, -3.2571976]], dtype=float32)

time = 65092	action = 0	current_phase = 1	next_phase = 0	reward = 0.204737	array([[-2.6441746, -4.3332233]], dtype=float32)

time = 65097	action = 1	current_phase = 1	next_phase = 0	reward = -1.785664	array([[-6.3616996, -3.414987 ]], dtype=float32)

time = 65105	action = 0	current_phase = 0	next_phase = 1	reward = -0.527629	array([[-2.0535262, -3.298395 ]], dtype=float32)

time = 65110	action = 0	current_phase = 0	next_phase = 1	reward = -0.374240	array([[-1.8933172, -3.0856047]], dtype=float32)

time = 65115	action = 0	current_phase = 0	next_phase = 1	reward = -0.216110	array([[-1.9227569, -3.3862498]], dtype=float32)

time = 65120	action = 0	current_phase = 0	next_phase = 1	reward = 0.050480	array([[-2.152013 , -3.8917365]], dtype=float32)

time = 65125	action = 1	current_phase = 0	next_phase = 1	reward = -1.140142	array([[-5.7214017, -2.9021595]], dtype=float32)

time = 65133	action = 0	current_phase = 1	next_phase = 0	reward = -0.590946	array([[-2.303389 , -3.1670713]], dtype=float32)

time = 65138	action = 0	current_phase = 1	next_phase = 0	reward = -0.437304	array([[-2.1548572, -3.1552942]], dtype=float32)

time = 65143	action = 0	current_phase = 1	next_phase = 0	reward = -0.284855	array([[-2.1854203, -3.1592364]], dtype=float32)

time = 65148	action = 0	current_phase = 1	next_phase = 0	reward = -0.162813	array([[-2.3768425, -3.2568927]], dtype=float32)

time = 65153	action = 0	current_phase = 1	next_phase = 0	reward = 0.024872	array([[-2.7838805, -4.1496153]], dtype=float32)

time = 65158	action = 1	current_phase = 1	next_phase = 0	reward = -1.897678	array([[-6.415791 , -3.5746193]], dtype=float32)

time = 65166	action = 0	current_phase = 0	next_phase = 1	reward = -0.496220	array([[-2.0539489, -3.298626 ]], dtype=float32)

time = 65171	action = 0	current_phase = 0	next_phase = 1	reward = -0.336762	array([[-1.9060858, -3.0860128]], dtype=float32)

time = 65176	action = 0	current_phase = 0	next_phase = 1	reward = -0.203876	array([[-2.0248299, -3.186192 ]], dtype=float32)

time = 65181	action = 0	current_phase = 0	next_phase = 1	reward = 0.228805	array([[-2.3482323, -4.154694 ]], dtype=float32)

time = 65186	action = 1	current_phase = 0	next_phase = 1	reward = -1.556342	array([[-4.6010265, -3.4595704]], dtype=float32)

time = 65194	action = 0	current_phase = 1	next_phase = 0	reward = -0.554392	array([[-2.1183956, -3.1217673]], dtype=float32)

time = 65199	action = 0	current_phase = 1	next_phase = 0	reward = -0.399631	array([[-1.9653124, -3.0764773]], dtype=float32)

time = 65204	action = 0	current_phase = 1	next_phase = 0	reward = -0.244572	array([[-1.9664668, -3.0104964]], dtype=float32)

time = 65209	action = 0	current_phase = 1	next_phase = 0	reward = -0.176970	array([[-2.1491709, -3.9352834]], dtype=float32)

time = 65214	action = 1	current_phase = 1	next_phase = 0	reward = -0.431508	array([[-2.6239288, -2.3200004]], dtype=float32)

time = 65222	action = 0	current_phase = 0	next_phase = 1	reward = -0.614070	array([[-2.3444462, -3.9313016]], dtype=float32)

time = 65227	action = 0	current_phase = 0	next_phase = 1	reward = -0.459606	array([[-2.0946348, -2.9478927]], dtype=float32)

time = 65232	action = 0	current_phase = 0	next_phase = 1	reward = -0.301467	array([[-2.0732198, -3.2211757]], dtype=float32)

time = 65237	action = 0	current_phase = 0	next_phase = 1	reward = -0.167892	array([[-2.2658668, -3.354827 ]], dtype=float32)

time = 65242	action = 0	current_phase = 0	next_phase = 1	reward = 0.125932	array([[-2.589398 , -4.4468284]], dtype=float32)

time = 65247	action = 1	current_phase = 0	next_phase = 1	reward = -1.781191	array([[-6.569059 , -3.5445333]], dtype=float32)

time = 65255	action = 0	current_phase = 1	next_phase = 0	reward = -0.515739	array([[-2.090887, -3.311476]], dtype=float32)

time = 65260	action = 0	current_phase = 1	next_phase = 0	reward = -0.362207	array([[-1.9697356, -3.0787027]], dtype=float32)

time = 65265	action = 0	current_phase = 1	next_phase = 0	reward = -0.209715	array([[-2.0521646, -3.0681288]], dtype=float32)

time = 65270	action = 0	current_phase = 1	next_phase = 0	reward = 0.348731	array([[-2.2670429, -4.112533 ]], dtype=float32)

time = 65275	action = 1	current_phase = 1	next_phase = 0	reward = -1.310422	array([[-3.4828782, -3.125092 ]], dtype=float32)

time = 65283	action = 0	current_phase = 0	next_phase = 1	reward = -0.575357	array([[-2.3255978, -3.932321 ]], dtype=float32)

time = 65288	action = 0	current_phase = 0	next_phase = 1	reward = -0.412441	array([[-2.0784445, -2.9408088]], dtype=float32)

time = 65293	action = 0	current_phase = 0	next_phase = 1	reward = -0.252804	array([[-2.1043184, -3.228272 ]], dtype=float32)

time = 65298	action = 0	current_phase = 0	next_phase = 1	reward = -0.163816	array([[-2.1650834, -3.2870066]], dtype=float32)

time = 65303	action = 1	current_phase = 0	next_phase = 1	reward = -1.129528	array([[-4.962852 , -3.6655986]], dtype=float32)

time = 65311	action = 1	current_phase = 1	next_phase = 0	reward = -2.017913	array([[-3.8631623, -3.5186436]], dtype=float32)

time = 65319	action = 0	current_phase = 0	next_phase = 1	reward = -0.400878	array([[-1.9047371, -3.2478962]], dtype=float32)

time = 65324	action = 0	current_phase = 0	next_phase = 1	reward = -0.248110	array([[-2.074805 , -3.1815882]], dtype=float32)

time = 65329	action = 0	current_phase = 0	next_phase = 1	reward = -0.189563	array([[-2.2637773, -3.525444 ]], dtype=float32)

time = 65334	action = 0	current_phase = 0	next_phase = 1	reward = -0.155176	array([[-2.475554, -3.91151 ]], dtype=float32)

time = 65339	action = 1	current_phase = 0	next_phase = 1	reward = -2.017409	array([[-4.9284782, -3.5916936]], dtype=float32)

time = 65347	action = 0	current_phase = 1	next_phase = 0	reward = -0.474258	array([[-2.1021116, -3.3097985]], dtype=float32)

time = 65352	action = 0	current_phase = 1	next_phase = 0	reward = -0.317215	array([[-2.1526105, -3.154509 ]], dtype=float32)

time = 65357	action = 0	current_phase = 1	next_phase = 0	reward = -0.174477	array([[-2.056923 , -3.1864874]], dtype=float32)

time = 65362	action = 0	current_phase = 1	next_phase = 0	reward = 0.256619	array([[-2.3620946, -4.1629653]], dtype=float32)

time = 65367	action = 1	current_phase = 1	next_phase = 0	reward = -1.681361	array([[-5.84412 , -3.352387]], dtype=float32)

time = 65375	action = 0	current_phase = 0	next_phase = 1	reward = -0.541162	array([[-2.051093 , -3.2605796]], dtype=float32)

time = 65380	action = 0	current_phase = 0	next_phase = 1	reward = -0.392246	array([[-1.8931369, -3.0855083]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0156 - val_loss: 0.0050

Epoch 2/50

 - 4s - loss: 0.0101 - val_loss: 0.0048

Epoch 3/50

 - 4s - loss: 0.0089 - val_loss: 0.0051

Epoch 4/50

 - 4s - loss: 0.0095 - val_loss: 0.0052

Epoch 5/50

 - 4s - loss: 0.0084 - val_loss: 0.0049

Epoch 6/50

 - 4s - loss: 0.0103 - val_loss: 0.0050

Epoch 7/50

 - 4s - loss: 0.0088 - val_loss: 0.0048

Epoch 8/50

 - 6s - loss: 0.0064 - val_loss: 0.0049

Epoch 9/50

 - 4s - loss: 0.0054 - val_loss: 0.0049

Epoch 10/50

 - 6s - loss: 0.0071 - val_loss: 0.0051

Epoch 11/50

 - 5s - loss: 0.0080 - val_loss: 0.0053

Epoch 12/50

 - 4s - loss: 0.0059 - val_loss: 0.0053

Epoch 13/50

 - 4s - loss: 0.0089 - val_loss: 0.0053

Epoch 14/50

 - 4s - loss: 0.0069 - val_loss: 0.0051

Epoch 15/50

 - 4s - loss: 0.0058 - val_loss: 0.0054

Epoch 16/50

 - 4s - loss: 0.0073 - val_loss: 0.0052

Epoch 17/50

 - 4s - loss: 0.0085 - val_loss: 0.0049

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1006, before forget

length of memory (state 1, action 1): 1000, after forget

time = 65385	action = 0	current_phase = 0	next_phase = 1	reward = -0.246301	array([[-1.9574357, -3.4214303]], dtype=float32)

time = 65390	action = 0	current_phase = 0	next_phase = 1	reward = 0.082071	array([[-2.157076 , -3.7426784]], dtype=float32)

time = 65395	action = 1	current_phase = 0	next_phase = 1	reward = -0.913711	array([[-5.840181, -2.83302 ]], dtype=float32)

time = 65403	action = 0	current_phase = 1	next_phase = 0	reward = -0.586414	array([[-2.318233 , -3.1746495]], dtype=float32)

time = 65408	action = 0	current_phase = 1	next_phase = 0	reward = -0.428736	array([[-2.1449802, -3.1589727]], dtype=float32)

time = 65413	action = 0	current_phase = 1	next_phase = 0	reward = -0.271970	array([[-2.168324 , -3.1667705]], dtype=float32)

time = 65418	action = 0	current_phase = 1	next_phase = 0	reward = -0.161245	array([[-2.3306031, -3.2551262]], dtype=float32)

time = 65423	action = 0	current_phase = 1	next_phase = 0	reward = 0.063304	array([[-2.6730065, -4.200336 ]], dtype=float32)

time = 65428	action = 1	current_phase = 1	next_phase = 0	reward = -1.900185	array([[-6.423335 , -3.5902424]], dtype=float32)

time = 65436	action = 0	current_phase = 0	next_phase = 1	reward = -0.499229	array([[-2.0719893, -3.32243  ]], dtype=float32)

time = 65441	action = 0	current_phase = 0	next_phase = 1	reward = -0.352531	array([[-1.9217714, -3.1100707]], dtype=float32)

time = 65446	action = 0	current_phase = 0	next_phase = 1	reward = -0.206436	array([[-2.053869 , -3.2127085]], dtype=float32)

time = 65451	action = 0	current_phase = 0	next_phase = 1	reward = 0.324624	array([[-2.4032416, -4.1922746]], dtype=float32)

time = 65456	action = 1	current_phase = 0	next_phase = 1	reward = -1.451163	array([[-4.679096 , -3.3197067]], dtype=float32)

time = 65464	action = 0	current_phase = 1	next_phase = 0	reward = -0.553594	array([[-2.12516  , -3.1325433]], dtype=float32)

time = 65469	action = 0	current_phase = 1	next_phase = 0	reward = -0.393200	array([[-1.9444631, -3.0758138]], dtype=float32)

time = 65474	action = 0	current_phase = 1	next_phase = 0	reward = -0.225451	array([[-1.9141362, -2.9969947]], dtype=float32)

time = 65479	action = 0	current_phase = 1	next_phase = 0	reward = -0.180411	array([[-2.071524 , -3.8847904]], dtype=float32)

time = 65484	action = 1	current_phase = 1	next_phase = 0	reward = -0.539648	array([[-2.6211634, -2.32962  ]], dtype=float32)

time = 65492	action = 0	current_phase = 0	next_phase = 1	reward = -0.620805	array([[-2.3336382, -3.9661245]], dtype=float32)

time = 65497	action = 0	current_phase = 0	next_phase = 1	reward = -0.461274	array([[-2.1071262, -2.9558535]], dtype=float32)

time = 65502	action = 0	current_phase = 0	next_phase = 1	reward = -0.307374	array([[-2.1435945, -3.2525198]], dtype=float32)

time = 65507	action = 0	current_phase = 0	next_phase = 1	reward = -0.176578	array([[-2.3322697, -3.3884082]], dtype=float32)

time = 65512	action = 0	current_phase = 0	next_phase = 1	reward = 0.200658	array([[-2.6433384, -4.4779477]], dtype=float32)

time = 65517	action = 1	current_phase = 0	next_phase = 1	reward = -1.676343	array([[-6.479535 , -3.4614284]], dtype=float32)

time = 65525	action = 0	current_phase = 1	next_phase = 0	reward = -0.516398	array([[-2.0681543, -3.3087559]], dtype=float32)

time = 65530	action = 0	current_phase = 1	next_phase = 0	reward = -0.367089	array([[-1.9516788, -3.0801764]], dtype=float32)

time = 65535	action = 0	current_phase = 1	next_phase = 0	reward = -0.217246	array([[-2.0092583, -3.0551019]], dtype=float32)

time = 65540	action = 0	current_phase = 1	next_phase = 0	reward = 0.340640	array([[-2.2432823, -4.115537 ]], dtype=float32)

time = 65545	action = 1	current_phase = 1	next_phase = 0	reward = -1.424288	array([[-3.4396777, -3.1228545]], dtype=float32)

time = 65553	action = 0	current_phase = 0	next_phase = 1	reward = -0.594084	array([[-2.3330655, -3.964293 ]], dtype=float32)

time = 65558	action = 0	current_phase = 0	next_phase = 1	reward = -0.437461	array([[-2.1424985, -2.9701643]], dtype=float32)

time = 65563	action = 0	current_phase = 0	next_phase = 1	reward = -0.276603	array([[-2.1418033, -3.2525373]], dtype=float32)

time = 65568	action = 0	current_phase = 0	next_phase = 1	reward = -0.165547	array([[-2.344057 , -3.3972661]], dtype=float32)

time = 65573	action = 0	current_phase = 0	next_phase = 1	reward = -0.059195	array([[-2.6222832, -4.468287 ]], dtype=float32)

time = 65578	action = 1	current_phase = 0	next_phase = 1	reward = -1.902167	array([[-6.6035523, -3.54718  ]], dtype=float32)

time = 65586	action = 0	current_phase = 1	next_phase = 0	reward = -0.492667	array([[-2.0646966, -3.3091993]], dtype=float32)

time = 65591	action = 0	current_phase = 1	next_phase = 0	reward = -0.330705	array([[-1.9685655, -3.0868561]], dtype=float32)

time = 65596	action = 0	current_phase = 1	next_phase = 0	reward = -0.182937	array([[-2.026243, -3.131293]], dtype=float32)

time = 65601	action = 0	current_phase = 1	next_phase = 0	reward = 0.276872	array([[-2.2606728, -4.143567 ]], dtype=float32)

time = 65606	action = 1	current_phase = 1	next_phase = 0	reward = -1.613129	array([[-5.772716, -3.206581]], dtype=float32)

time = 65614	action = 0	current_phase = 0	next_phase = 1	reward = -0.559683	array([[-2.0986192, -3.1672134]], dtype=float32)

time = 65619	action = 0	current_phase = 0	next_phase = 1	reward = -0.402861	array([[-1.9192125, -3.1080635]], dtype=float32)

time = 65624	action = 0	current_phase = 0	next_phase = 1	reward = -0.246339	array([[-1.9579816, -3.4200206]], dtype=float32)

time = 65629	action = 0	current_phase = 0	next_phase = 1	reward = 0.108036	array([[-2.136979, -3.282391]], dtype=float32)

time = 65634	action = 1	current_phase = 0	next_phase = 1	reward = -0.724565	array([[-5.887747 , -2.7445445]], dtype=float32)

time = 65642	action = 0	current_phase = 1	next_phase = 0	reward = -0.619908	array([[-2.2991354, -3.1718976]], dtype=float32)

time = 65647	action = 0	current_phase = 1	next_phase = 0	reward = -0.469214	array([[-2.1516738, -3.1400807]], dtype=float32)

time = 65652	action = 0	current_phase = 1	next_phase = 0	reward = -0.315575	array([[-2.1672027, -3.1669636]], dtype=float32)

time = 65657	action = 0	current_phase = 1	next_phase = 0	reward = -0.180096	array([[-2.3380466, -3.261934 ]], dtype=float32)

time = 65662	action = 0	current_phase = 1	next_phase = 0	reward = 0.261581	array([[-2.6180086, -4.3193173]], dtype=float32)

time = 65667	action = 1	current_phase = 1	next_phase = 0	reward = -1.622475	array([[-6.3572636, -3.4112108]], dtype=float32)

time = 65675	action = 0	current_phase = 0	next_phase = 1	reward = -0.530236	array([[-2.0453355, -3.3138287]], dtype=float32)

time = 65680	action = 0	current_phase = 0	next_phase = 1	reward = -0.373815	array([[-1.9192446, -3.1102133]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0081 - val_loss: 0.0078

Epoch 2/50

 - 4s - loss: 0.0126 - val_loss: 0.0066

Epoch 3/50

 - 4s - loss: 0.0082 - val_loss: 0.0068

Epoch 4/50

 - 4s - loss: 0.0118 - val_loss: 0.0071

Epoch 5/50

 - 4s - loss: 0.0107 - val_loss: 0.0066

Epoch 6/50

 - 5s - loss: 0.0080 - val_loss: 0.0068

Epoch 7/50

 - 4s - loss: 0.0087 - val_loss: 0.0074

Epoch 8/50

 - 4s - loss: 0.0070 - val_loss: 0.0081

Epoch 9/50

 - 4s - loss: 0.0096 - val_loss: 0.0077

Epoch 10/50

 - 4s - loss: 0.0071 - val_loss: 0.0068

Epoch 11/50

 - 4s - loss: 0.0065 - val_loss: 0.0072

Epoch 12/50

 - 4s - loss: 0.0094 - val_loss: 0.0077

Epoch 13/50

 - 4s - loss: 0.0078 - val_loss: 0.0080

Epoch 14/50

 - 5s - loss: 0.0086 - val_loss: 0.0073

Epoch 15/50

 - 4s - loss: 0.0059 - val_loss: 0.0080

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 65685	action = 0	current_phase = 0	next_phase = 1	reward = -0.220486	array([[-1.9394643, -3.4133468]], dtype=float32)

time = 65690	action = 0	current_phase = 0	next_phase = 1	reward = 0.357164	array([[-2.1630907, -3.914306 ]], dtype=float32)

time = 65695	action = 1	current_phase = 0	next_phase = 1	reward = -1.415678	array([[-5.191395 , -3.1313608]], dtype=float32)

time = 65703	action = 0	current_phase = 1	next_phase = 0	reward = -0.589109	array([[-2.2608154, -3.1686397]], dtype=float32)

time = 65708	action = 0	current_phase = 1	next_phase = 0	reward = -0.438033	array([[-2.1187913, -3.1503992]], dtype=float32)

time = 65713	action = 0	current_phase = 1	next_phase = 0	reward = -0.291116	array([[-2.166627 , -3.1627164]], dtype=float32)

time = 65718	action = 0	current_phase = 1	next_phase = 0	reward = -0.165975	array([[-2.3214402, -3.2561262]], dtype=float32)

time = 65723	action = 0	current_phase = 1	next_phase = 0	reward = 0.110480	array([[-2.6637814, -4.316684 ]], dtype=float32)

time = 65728	action = 1	current_phase = 1	next_phase = 0	reward = -1.895730	array([[-6.445576 , -3.5830748]], dtype=float32)

time = 65736	action = 0	current_phase = 0	next_phase = 1	reward = -0.489905	array([[-2.0426512, -3.3116114]], dtype=float32)

time = 65741	action = 0	current_phase = 0	next_phase = 1	reward = -0.334490	array([[-1.9248219, -3.1234581]], dtype=float32)

time = 65746	action = 0	current_phase = 0	next_phase = 1	reward = -0.185029	array([[-2.0435994, -3.1982088]], dtype=float32)

time = 65751	action = 0	current_phase = 0	next_phase = 1	reward = 0.292594	array([[-2.3748667, -4.180254 ]], dtype=float32)

time = 65756	action = 1	current_phase = 0	next_phase = 1	reward = -1.615325	array([[-4.662277 , -3.3068945]], dtype=float32)

time = 65764	action = 0	current_phase = 1	next_phase = 0	reward = -0.566880	array([[-2.1314745, -3.1334596]], dtype=float32)

time = 65769	action = 0	current_phase = 1	next_phase = 0	reward = -0.412107	array([[-1.9550654, -3.0777943]], dtype=float32)

time = 65774	action = 0	current_phase = 1	next_phase = 0	reward = -0.251152	array([[-1.9463469, -3.009371 ]], dtype=float32)

time = 65779	action = 0	current_phase = 1	next_phase = 0	reward = -0.169231	array([[-2.10933  , -3.8626382]], dtype=float32)

time = 65784	action = 1	current_phase = 1	next_phase = 0	reward = -0.418908	array([[-2.6744404, -2.3896282]], dtype=float32)

time = 65792	action = 0	current_phase = 0	next_phase = 1	reward = -0.623596	array([[-2.3266115, -3.949199 ]], dtype=float32)

time = 65797	action = 0	current_phase = 0	next_phase = 1	reward = -0.474718	array([[-2.0716624, -2.9427857]], dtype=float32)

time = 65802	action = 0	current_phase = 0	next_phase = 1	reward = -0.320668	array([[-2.1028883, -3.2384603]], dtype=float32)

time = 65807	action = 0	current_phase = 0	next_phase = 1	reward = -0.182854	array([[-2.2244945, -3.3101518]], dtype=float32)

time = 65812	action = 0	current_phase = 0	next_phase = 1	reward = 0.186827	array([[-2.5636992, -4.471502 ]], dtype=float32)

time = 65817	action = 1	current_phase = 0	next_phase = 1	reward = -1.782890	array([[-6.5055294, -3.4672768]], dtype=float32)

time = 65825	action = 0	current_phase = 1	next_phase = 0	reward = -0.533878	array([[-2.0788023, -3.3030272]], dtype=float32)

time = 65830	action = 0	current_phase = 1	next_phase = 0	reward = -0.378688	array([[-1.9598103, -3.0802994]], dtype=float32)

time = 65835	action = 0	current_phase = 1	next_phase = 0	reward = -0.234158	array([[-2.060616 , -3.0665872]], dtype=float32)

time = 65840	action = 0	current_phase = 1	next_phase = 0	reward = 0.066620	array([[-2.209786 , -3.9980092]], dtype=float32)

time = 65845	action = 1	current_phase = 1	next_phase = 0	reward = -1.080712	array([[-3.336692, -2.980376]], dtype=float32)

time = 65853	action = 0	current_phase = 0	next_phase = 1	reward = -0.585675	array([[-2.3223193, -3.9461792]], dtype=float32)

time = 65858	action = 0	current_phase = 0	next_phase = 1	reward = -0.429084	array([[-2.1585107, -3.0505857]], dtype=float32)

time = 65863	action = 0	current_phase = 0	next_phase = 1	reward = -0.280361	array([[-2.1083763, -3.2422261]], dtype=float32)

time = 65868	action = 0	current_phase = 0	next_phase = 1	reward = -0.167233	array([[-2.3331866, -3.3840969]], dtype=float32)

time = 65873	action = 0	current_phase = 0	next_phase = 1	reward = 0.003373	array([[-2.5559258, -4.460226 ]], dtype=float32)

time = 65878	action = 1	current_phase = 0	next_phase = 1	reward = -1.894266	array([[-6.581783 , -3.5317607]], dtype=float32)

time = 65886	action = 0	current_phase = 1	next_phase = 0	reward = -0.488707	array([[-2.074596, -3.303853]], dtype=float32)

time = 65891	action = 0	current_phase = 1	next_phase = 0	reward = -0.335256	array([[-1.9666715, -3.0833375]], dtype=float32)

time = 65896	action = 0	current_phase = 1	next_phase = 0	reward = -0.189226	array([[-2.0460575, -3.1558278]], dtype=float32)

time = 65901	action = 0	current_phase = 1	next_phase = 0	reward = 0.316620	array([[-2.2725728, -4.1306825]], dtype=float32)

time = 65906	action = 1	current_phase = 1	next_phase = 0	reward = -1.555909	array([[-3.491974 , -3.2069433]], dtype=float32)

time = 65914	action = 0	current_phase = 0	next_phase = 1	reward = -0.562182	array([[-2.0843098, -3.1549082]], dtype=float32)

time = 65919	action = 0	current_phase = 0	next_phase = 1	reward = -0.401820	array([[-1.8913382, -3.0945473]], dtype=float32)

time = 65924	action = 0	current_phase = 0	next_phase = 1	reward = -0.245312	array([[-1.9394325, -3.4132133]], dtype=float32)

time = 65929	action = 0	current_phase = 0	next_phase = 1	reward = -0.185593	array([[-2.1117094, -3.3242943]], dtype=float32)

time = 65934	action = 1	current_phase = 0	next_phase = 1	reward = -0.454167	array([[-5.9878163, -2.4252849]], dtype=float32)

time = 65942	action = 0	current_phase = 1	next_phase = 0	reward = -0.611306	array([[-2.346342 , -3.1837597]], dtype=float32)

time = 65947	action = 0	current_phase = 1	next_phase = 0	reward = -0.463740	array([[-2.1730304, -3.1460464]], dtype=float32)

time = 65952	action = 0	current_phase = 1	next_phase = 0	reward = -0.311976	array([[-2.17663  , -3.1722324]], dtype=float32)

time = 65957	action = 0	current_phase = 1	next_phase = 0	reward = -0.180330	array([[-2.327666 , -3.2510886]], dtype=float32)

time = 65962	action = 0	current_phase = 1	next_phase = 0	reward = 0.187090	array([[-2.5687852, -4.3200336]], dtype=float32)

time = 65967	action = 1	current_phase = 1	next_phase = 0	reward = -1.779031	array([[-6.378254 , -3.4204838]], dtype=float32)

time = 65975	action = 0	current_phase = 0	next_phase = 1	reward = -0.515706	array([[-2.0355513, -3.3092105]], dtype=float32)

time = 65980	action = 0	current_phase = 0	next_phase = 1	reward = -0.352212	array([[-1.8901886, -3.0956867]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0100 - val_loss: 0.0065

Epoch 2/50

 - 4s - loss: 0.0103 - val_loss: 0.0081

Epoch 3/50

 - 5s - loss: 0.0095 - val_loss: 0.0077

Epoch 4/50

 - 4s - loss: 0.0111 - val_loss: 0.0077

Epoch 5/50

 - 5s - loss: 0.0088 - val_loss: 0.0070

Epoch 6/50

 - 4s - loss: 0.0096 - val_loss: 0.0069

Epoch 7/50

 - 4s - loss: 0.0095 - val_loss: 0.0070

Epoch 8/50

 - 4s - loss: 0.0090 - val_loss: 0.0079

Epoch 9/50

 - 4s - loss: 0.0092 - val_loss: 0.0069

Epoch 10/50

 - 4s - loss: 0.0092 - val_loss: 0.0075

Epoch 11/50

 - 4s - loss: 0.0067 - val_loss: 0.0059

Epoch 12/50

 - 4s - loss: 0.0053 - val_loss: 0.0059

Epoch 13/50

 - 5s - loss: 0.0072 - val_loss: 0.0087

Epoch 14/50

 - 5s - loss: 0.0074 - val_loss: 0.0073

Epoch 15/50

 - 4s - loss: 0.0078 - val_loss: 0.0065

Epoch 16/50

 - 4s - loss: 0.0078 - val_loss: 0.0059

Epoch 17/50

 - 4s - loss: 0.0073 - val_loss: 0.0071

Epoch 18/50

 - 4s - loss: 0.0077 - val_loss: 0.0064

Epoch 19/50

 - 4s - loss: 0.0066 - val_loss: 0.0064

Epoch 20/50

 - 4s - loss: 0.0051 - val_loss: 0.0059

Epoch 21/50

 - 4s - loss: 0.0070 - val_loss: 0.0068

Epoch 22/50

 - 5s - loss: 0.0079 - val_loss: 0.0061

Epoch 23/50

 - 4s - loss: 0.0088 - val_loss: 0.0068

Epoch 24/50

 - 5s - loss: 0.0075 - val_loss: 0.0069

Epoch 25/50

 - 5s - loss: 0.0086 - val_loss: 0.0074

Epoch 26/50

 - 6s - loss: 0.0066 - val_loss: 0.0064

Epoch 27/50

 - 5s - loss: 0.0072 - val_loss: 0.0073

Epoch 28/50

 - 5s - loss: 0.0062 - val_loss: 0.0070

Epoch 29/50

 - 5s - loss: 0.0055 - val_loss: 0.0080

Epoch 30/50

 - 5s - loss: 0.0072 - val_loss: 0.0065

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 65985	action = 0	current_phase = 0	next_phase = 1	reward = -0.200337	array([[-1.9268359, -3.4069948]], dtype=float32)

time = 65990	action = 0	current_phase = 0	next_phase = 1	reward = 0.325213	array([[-2.1383047, -3.8748782]], dtype=float32)

time = 65995	action = 1	current_phase = 0	next_phase = 1	reward = -1.429403	array([[-4.990643 , -3.2108967]], dtype=float32)

time = 66003	action = 0	current_phase = 1	next_phase = 0	reward = -0.588437	array([[-2.2858078, -3.174053 ]], dtype=float32)

time = 66008	action = 0	current_phase = 1	next_phase = 0	reward = -0.434425	array([[-2.1363962, -3.1607802]], dtype=float32)

time = 66013	action = 0	current_phase = 1	next_phase = 0	reward = -0.289036	array([[-2.1129236, -3.130988 ]], dtype=float32)

time = 66018	action = 0	current_phase = 1	next_phase = 0	reward = -0.170626	array([[-2.3457086, -3.2541833]], dtype=float32)

time = 66023	action = 0	current_phase = 1	next_phase = 0	reward = -0.001008	array([[-2.7099652, -4.058658 ]], dtype=float32)

time = 66028	action = 1	current_phase = 1	next_phase = 0	reward = -1.902081	array([[-6.411131, -3.496269]], dtype=float32)

time = 66036	action = 0	current_phase = 0	next_phase = 1	reward = -0.497199	array([[-2.0384407, -3.3128827]], dtype=float32)

time = 66041	action = 0	current_phase = 0	next_phase = 1	reward = -0.334136	array([[-1.880444, -3.09323 ]], dtype=float32)

time = 66046	action = 0	current_phase = 0	next_phase = 1	reward = -0.188441	array([[-2.0399783, -3.1960645]], dtype=float32)

time = 66051	action = 0	current_phase = 0	next_phase = 1	reward = 0.309479	array([[-2.3647902, -4.150676 ]], dtype=float32)

time = 66056	action = 1	current_phase = 0	next_phase = 1	reward = -1.662964	array([[-4.645854 , -3.3166642]], dtype=float32)

time = 66064	action = 0	current_phase = 1	next_phase = 0	reward = -0.552872	array([[-2.1488512, -3.1371765]], dtype=float32)

time = 66069	action = 0	current_phase = 1	next_phase = 0	reward = -0.397354	array([[-1.9551778, -3.0790653]], dtype=float32)

time = 66074	action = 0	current_phase = 1	next_phase = 0	reward = -0.241341	array([[-1.9118993, -3.0123925]], dtype=float32)

time = 66079	action = 0	current_phase = 1	next_phase = 0	reward = -0.182633	array([[-2.1099198, -3.9020875]], dtype=float32)

time = 66084	action = 1	current_phase = 1	next_phase = 0	reward = -0.554662	array([[-2.6589837, -2.3403056]], dtype=float32)

time = 66092	action = 0	current_phase = 0	next_phase = 1	reward = -0.618950	array([[-2.3095016, -3.9498515]], dtype=float32)

time = 66097	action = 0	current_phase = 0	next_phase = 1	reward = -0.463585	array([[-2.0793984, -2.9320588]], dtype=float32)

time = 66102	action = 0	current_phase = 0	next_phase = 1	reward = -0.300369	array([[-2.1046588, -3.232591 ]], dtype=float32)

time = 66107	action = 0	current_phase = 0	next_phase = 1	reward = -0.171177	array([[-2.28997  , -3.3599215]], dtype=float32)

time = 66112	action = 0	current_phase = 0	next_phase = 1	reward = 0.112702	array([[-2.6200259, -4.482118 ]], dtype=float32)

time = 66117	action = 1	current_phase = 0	next_phase = 1	reward = -1.784175	array([[-6.568409, -3.4875  ]], dtype=float32)

time = 66125	action = 0	current_phase = 1	next_phase = 0	reward = -0.531825	array([[-2.0746899, -3.3034155]], dtype=float32)

time = 66130	action = 0	current_phase = 1	next_phase = 0	reward = -0.381314	array([[-1.9694886, -3.0871708]], dtype=float32)

time = 66135	action = 0	current_phase = 1	next_phase = 0	reward = -0.224696	array([[-2.015534, -3.066449]], dtype=float32)

time = 66140	action = 0	current_phase = 1	next_phase = 0	reward = 0.364273	array([[-2.240009 , -4.0759077]], dtype=float32)

time = 66145	action = 1	current_phase = 1	next_phase = 0	reward = -1.360574	array([[-3.5069957, -3.1226327]], dtype=float32)

time = 66153	action = 0	current_phase = 0	next_phase = 1	reward = -0.588418	array([[-2.3054833, -3.9479313]], dtype=float32)

time = 66158	action = 0	current_phase = 0	next_phase = 1	reward = -0.427305	array([[-2.0865471, -2.9307604]], dtype=float32)

time = 66163	action = 0	current_phase = 0	next_phase = 1	reward = -0.271042	array([[-2.1081026, -3.2310436]], dtype=float32)

time = 66168	action = 0	current_phase = 0	next_phase = 1	reward = -0.159100	array([[-2.2871768, -3.3566284]], dtype=float32)

time = 66173	action = 0	current_phase = 0	next_phase = 1	reward = 0.069190	array([[-2.9879282, -4.111128 ]], dtype=float32)

time = 66178	action = 1	current_phase = 0	next_phase = 1	reward = -1.898283	array([[-6.612306 , -3.5525308]], dtype=float32)

time = 66186	action = 0	current_phase = 1	next_phase = 0	reward = -0.493487	array([[-2.0723758, -3.3054645]], dtype=float32)

time = 66191	action = 0	current_phase = 1	next_phase = 0	reward = -0.333075	array([[-1.9775445, -3.0904171]], dtype=float32)

time = 66196	action = 0	current_phase = 1	next_phase = 0	reward = -0.184674	array([[-2.0432057, -3.1316495]], dtype=float32)

time = 66201	action = 0	current_phase = 1	next_phase = 0	reward = 0.302369	array([[-2.2806756, -4.131038 ]], dtype=float32)

time = 66206	action = 1	current_phase = 1	next_phase = 0	reward = -1.612003	array([[-5.837025 , -3.2760868]], dtype=float32)

time = 66214	action = 0	current_phase = 0	next_phase = 1	reward = -0.557069	array([[-2.0881824, -3.1631439]], dtype=float32)

time = 66219	action = 0	current_phase = 0	next_phase = 1	reward = -0.400569	array([[-1.8866603, -3.0808697]], dtype=float32)

time = 66224	action = 0	current_phase = 0	next_phase = 1	reward = -0.246802	array([[-1.9299471, -3.397268 ]], dtype=float32)

time = 66229	action = 0	current_phase = 0	next_phase = 1	reward = -0.187168	array([[-2.276297 , -3.3477306]], dtype=float32)

time = 66234	action = 1	current_phase = 0	next_phase = 1	reward = -0.498881	array([[-5.99448  , -2.7380478]], dtype=float32)

time = 66242	action = 0	current_phase = 1	next_phase = 0	reward = -0.625940	array([[-2.3340952, -3.182803 ]], dtype=float32)

time = 66247	action = 0	current_phase = 1	next_phase = 0	reward = -0.487431	array([[-2.1742122, -3.1454582]], dtype=float32)

time = 66252	action = 0	current_phase = 1	next_phase = 0	reward = -0.332526	array([[-2.1366785, -3.1609552]], dtype=float32)

time = 66257	action = 0	current_phase = 1	next_phase = 0	reward = -0.182970	array([[-2.3560746, -3.2568915]], dtype=float32)

time = 66262	action = 0	current_phase = 1	next_phase = 0	reward = 0.260379	array([[-2.589363 , -4.3306327]], dtype=float32)

time = 66267	action = 1	current_phase = 1	next_phase = 0	reward = -1.784067	array([[-6.3907547, -3.4069126]], dtype=float32)

time = 66275	action = 0	current_phase = 0	next_phase = 1	reward = -0.538529	array([[-2.034245 , -3.3110416]], dtype=float32)

time = 66280	action = 0	current_phase = 0	next_phase = 1	reward = -0.395027	array([[-1.8788447, -3.0916374]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0089 - val_loss: 0.0036

Epoch 2/50

 - 4s - loss: 0.0077 - val_loss: 0.0030

Epoch 3/50

 - 4s - loss: 0.0060 - val_loss: 0.0024

Epoch 4/50

 - 4s - loss: 0.0076 - val_loss: 0.0026

Epoch 5/50

 - 4s - loss: 0.0066 - val_loss: 0.0026

Epoch 6/50

 - 4s - loss: 0.0078 - val_loss: 0.0024

Epoch 7/50

 - 4s - loss: 0.0071 - val_loss: 0.0025

Epoch 8/50

 - 4s - loss: 0.0059 - val_loss: 0.0024

Epoch 9/50

 - 5s - loss: 0.0046 - val_loss: 0.0025

Epoch 10/50

 - 4s - loss: 0.0085 - val_loss: 0.0028

Epoch 11/50

 - 4s - loss: 0.0054 - val_loss: 0.0023

Epoch 12/50

 - 4s - loss: 0.0069 - val_loss: 0.0030

Epoch 13/50

 - 4s - loss: 0.0065 - val_loss: 0.0028

Epoch 14/50

 - 4s - loss: 0.0054 - val_loss: 0.0033

Epoch 15/50

 - 4s - loss: 0.0065 - val_loss: 0.0036

Epoch 16/50

 - 5s - loss: 0.0057 - val_loss: 0.0027

Epoch 17/50

 - 4s - loss: 0.0093 - val_loss: 0.0026

Epoch 18/50

 - 4s - loss: 0.0069 - val_loss: 0.0039

Epoch 19/50

 - 4s - loss: 0.0054 - val_loss: 0.0032

Epoch 20/50

 - 5s - loss: 0.0053 - val_loss: 0.0028

Epoch 21/50

 - 4s - loss: 0.0055 - val_loss: 0.0028

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 66285	action = 0	current_phase = 0	next_phase = 1	reward = -0.247598	array([[-1.9107639, -3.3917675]], dtype=float32)

time = 66290	action = 0	current_phase = 0	next_phase = 1	reward = 0.082611	array([[-2.127255 , -3.8713212]], dtype=float32)

time = 66295	action = 1	current_phase = 0	next_phase = 1	reward = -0.965683	array([[-5.611692, -2.968974]], dtype=float32)

time = 66303	action = 0	current_phase = 1	next_phase = 0	reward = -0.591427	array([[-2.2221627, -3.1578162]], dtype=float32)

time = 66308	action = 0	current_phase = 1	next_phase = 0	reward = -0.433343	array([[-2.1481845, -3.1605053]], dtype=float32)

time = 66313	action = 0	current_phase = 1	next_phase = 0	reward = -0.278147	array([[-2.1416   , -3.1458251]], dtype=float32)

time = 66318	action = 0	current_phase = 1	next_phase = 0	reward = -0.162238	array([[-2.3408036, -3.2451065]], dtype=float32)

time = 66323	action = 0	current_phase = 1	next_phase = 0	reward = 0.080637	array([[-2.6876523, -4.2944913]], dtype=float32)

time = 66328	action = 1	current_phase = 1	next_phase = 0	reward = -1.899598	array([[-6.4562654, -3.5606086]], dtype=float32)

time = 66336	action = 0	current_phase = 0	next_phase = 1	reward = -0.497640	array([[-2.0457907, -3.3170822]], dtype=float32)

time = 66341	action = 0	current_phase = 0	next_phase = 1	reward = -0.349561	array([[-1.8807462, -3.0926142]], dtype=float32)

time = 66346	action = 0	current_phase = 0	next_phase = 1	reward = -0.193254	array([[-2.0321016, -3.198328 ]], dtype=float32)

time = 66351	action = 0	current_phase = 0	next_phase = 1	reward = 0.286957	array([[-2.310064, -4.146785]], dtype=float32)

time = 66356	action = 1	current_phase = 0	next_phase = 1	reward = -1.558625	array([[-4.579461 , -3.2669878]], dtype=float32)

time = 66364	action = 0	current_phase = 1	next_phase = 0	reward = -0.561902	array([[-2.1080346, -3.1235962]], dtype=float32)

time = 66369	action = 0	current_phase = 1	next_phase = 0	reward = -0.394784	array([[-1.9281304, -3.0663075]], dtype=float32)

time = 66374	action = 0	current_phase = 1	next_phase = 0	reward = -0.228351	array([[-1.8859376, -3.0007472]], dtype=float32)

time = 66379	action = 0	current_phase = 1	next_phase = 0	reward = -0.182487	array([[-2.1720078, -3.9389536]], dtype=float32)

time = 66384	action = 1	current_phase = 1	next_phase = 0	reward = -0.589709	array([[-2.6689496, -2.3400464]], dtype=float32)

time = 66392	action = 0	current_phase = 0	next_phase = 1	reward = -0.621607	array([[-2.2996376, -3.9528098]], dtype=float32)

time = 66397	action = 0	current_phase = 0	next_phase = 1	reward = -0.469106	array([[-2.0799787, -2.9399788]], dtype=float32)

time = 66402	action = 0	current_phase = 0	next_phase = 1	reward = -0.315126	array([[-2.0950217, -3.222976 ]], dtype=float32)

time = 66407	action = 0	current_phase = 0	next_phase = 1	reward = -0.178789	array([[-2.2593124, -3.35669  ]], dtype=float32)

time = 66412	action = 0	current_phase = 0	next_phase = 1	reward = 0.232993	array([[-2.591859, -4.492468]], dtype=float32)

time = 66417	action = 1	current_phase = 0	next_phase = 1	reward = -1.783820	array([[-6.3534603, -3.4178617]], dtype=float32)

time = 66425	action = 0	current_phase = 1	next_phase = 0	reward = -0.527759	array([[-2.0696113, -3.2920878]], dtype=float32)

time = 66430	action = 0	current_phase = 1	next_phase = 0	reward = -0.380401	array([[-1.935565 , -3.0695834]], dtype=float32)

time = 66435	action = 0	current_phase = 1	next_phase = 0	reward = -0.234821	array([[-2.0166326, -3.0514348]], dtype=float32)

time = 66440	action = 0	current_phase = 1	next_phase = 0	reward = 0.363062	array([[-2.2060134, -3.9985092]], dtype=float32)

time = 66445	action = 1	current_phase = 1	next_phase = 0	reward = -1.303320	array([[-3.476334 , -3.0995777]], dtype=float32)

time = 66453	action = 0	current_phase = 0	next_phase = 1	reward = -0.585966	array([[-2.298895 , -3.9518955]], dtype=float32)

time = 66458	action = 0	current_phase = 0	next_phase = 1	reward = -0.433104	array([[-2.0768707, -2.9386652]], dtype=float32)

time = 66463	action = 0	current_phase = 0	next_phase = 1	reward = -0.275459	array([[-2.0992076, -3.222148 ]], dtype=float32)

time = 66468	action = 0	current_phase = 0	next_phase = 1	reward = -0.161805	array([[-2.258206, -3.355611]], dtype=float32)

time = 66473	action = 0	current_phase = 0	next_phase = 1	reward = 0.051653	array([[-2.7936492, -4.2608967]], dtype=float32)

time = 66478	action = 1	current_phase = 0	next_phase = 1	reward = -1.895268	array([[-6.592865, -3.525488]], dtype=float32)

time = 66486	action = 0	current_phase = 1	next_phase = 0	reward = -0.499383	array([[-2.0678313, -3.29222  ]], dtype=float32)

time = 66491	action = 0	current_phase = 1	next_phase = 0	reward = -0.352395	array([[-1.9393728, -3.0714278]], dtype=float32)

time = 66496	action = 0	current_phase = 1	next_phase = 0	reward = -0.200132	array([[-2.037957 , -3.1167073]], dtype=float32)

time = 66501	action = 0	current_phase = 1	next_phase = 0	reward = 0.321050	array([[-2.2599294, -4.137729 ]], dtype=float32)

time = 66506	action = 1	current_phase = 1	next_phase = 0	reward = -1.556262	array([[-5.817466 , -3.2117178]], dtype=float32)

time = 66514	action = 0	current_phase = 0	next_phase = 1	reward = -0.553198	array([[-2.082996 , -3.1718924]], dtype=float32)

time = 66519	action = 0	current_phase = 0	next_phase = 1	reward = -0.397978	array([[-1.8787096, -3.0916476]], dtype=float32)

time = 66524	action = 0	current_phase = 0	next_phase = 1	reward = -0.243331	array([[-1.9112028, -3.3906982]], dtype=float32)

time = 66529	action = 0	current_phase = 0	next_phase = 1	reward = -0.186537	array([[-2.0936346, -3.2628715]], dtype=float32)

time = 66534	action = 1	current_phase = 0	next_phase = 1	reward = -0.608827	array([[-5.945985 , -2.4034164]], dtype=float32)

time = 66542	action = 0	current_phase = 1	next_phase = 0	reward = -0.617959	array([[-2.3292444, -3.181192 ]], dtype=float32)

time = 66547	action = 0	current_phase = 1	next_phase = 0	reward = -0.475019	array([[-2.1643097, -3.1413696]], dtype=float32)

time = 66552	action = 0	current_phase = 1	next_phase = 0	reward = -0.320915	array([[-2.1680572, -3.1678412]], dtype=float32)

time = 66557	action = 0	current_phase = 1	next_phase = 0	reward = -0.176073	array([[-2.3397372, -3.2448988]], dtype=float32)

time = 66562	action = 0	current_phase = 1	next_phase = 0	reward = 0.201274	array([[-2.6046236, -4.326687 ]], dtype=float32)

time = 66567	action = 1	current_phase = 1	next_phase = 0	reward = -1.782426	array([[-6.3958864, -3.4017317]], dtype=float32)

time = 66575	action = 0	current_phase = 0	next_phase = 1	reward = -0.520159	array([[-2.036776, -3.312828]], dtype=float32)

time = 66580	action = 0	current_phase = 0	next_phase = 1	reward = -0.365489	array([[-1.8785683, -3.0920284]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0073 - val_loss: 0.0037

Epoch 2/50

 - 4s - loss: 0.0088 - val_loss: 0.0041

Epoch 3/50

 - 4s - loss: 0.0102 - val_loss: 0.0041

Epoch 4/50

 - 4s - loss: 0.0084 - val_loss: 0.0039

Epoch 5/50

 - 4s - loss: 0.0075 - val_loss: 0.0046

Epoch 6/50

 - 5s - loss: 0.0092 - val_loss: 0.0047

Epoch 7/50

 - 4s - loss: 0.0064 - val_loss: 0.0039

Epoch 8/50

 - 4s - loss: 0.0090 - val_loss: 0.0055

Epoch 9/50

 - 4s - loss: 0.0061 - val_loss: 0.0055

Epoch 10/50

 - 4s - loss: 0.0051 - val_loss: 0.0050

Epoch 11/50

 - 5s - loss: 0.0048 - val_loss: 0.0047

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 66585	action = 0	current_phase = 0	next_phase = 1	reward = -0.209392	array([[-1.9067184, -3.3909404]], dtype=float32)

time = 66590	action = 0	current_phase = 0	next_phase = 1	reward = 0.347829	array([[-2.193345 , -3.9042003]], dtype=float32)

time = 66595	action = 1	current_phase = 0	next_phase = 1	reward = -1.362573	array([[-4.9209905, -3.1892214]], dtype=float32)

time = 66603	action = 0	current_phase = 1	next_phase = 0	reward = -0.587323	array([[-2.2915778, -3.1530912]], dtype=float32)

time = 66608	action = 0	current_phase = 1	next_phase = 0	reward = -0.433937	array([[-2.1583574, -3.1389947]], dtype=float32)

time = 66613	action = 0	current_phase = 1	next_phase = 0	reward = -0.273218	array([[-2.1865487, -3.10387  ]], dtype=float32)

time = 66618	action = 0	current_phase = 1	next_phase = 0	reward = -0.157378	array([[-2.3339057, -3.226731 ]], dtype=float32)

time = 66623	action = 0	current_phase = 1	next_phase = 0	reward = -0.043472	array([[-2.7559397, -3.685133 ]], dtype=float32)

time = 66628	action = 1	current_phase = 1	next_phase = 0	reward = -1.891713	array([[-6.479381 , -3.5279262]], dtype=float32)

time = 66636	action = 0	current_phase = 0	next_phase = 1	reward = -0.483594	array([[-2.0276446, -3.3152506]], dtype=float32)

time = 66641	action = 0	current_phase = 0	next_phase = 1	reward = -0.327212	array([[-1.9259678, -3.1048486]], dtype=float32)

time = 66646	action = 0	current_phase = 0	next_phase = 1	reward = -0.189876	array([[-2.0450675, -3.2119014]], dtype=float32)

time = 66651	action = 0	current_phase = 0	next_phase = 1	reward = 0.291978	array([[-2.3462133, -4.1869683]], dtype=float32)

time = 66656	action = 1	current_phase = 0	next_phase = 1	reward = -1.664417	array([[-4.549907 , -3.3285651]], dtype=float32)

time = 66664	action = 0	current_phase = 1	next_phase = 0	reward = -0.557991	array([[-2.140685 , -3.1109095]], dtype=float32)

time = 66669	action = 0	current_phase = 1	next_phase = 0	reward = -0.401790	array([[-1.9663737, -3.0601103]], dtype=float32)

time = 66674	action = 0	current_phase = 1	next_phase = 0	reward = -0.257917	array([[-1.9529887, -2.9880977]], dtype=float32)

time = 66679	action = 0	current_phase = 1	next_phase = 0	reward = -0.171058	array([[-2.0690184, -3.9121165]], dtype=float32)

time = 66684	action = 1	current_phase = 1	next_phase = 0	reward = -0.474413	array([[-2.6656957, -2.328945 ]], dtype=float32)

time = 66692	action = 0	current_phase = 0	next_phase = 1	reward = -0.616082	array([[-2.25648 , -3.956903]], dtype=float32)

time = 66697	action = 0	current_phase = 0	next_phase = 1	reward = -0.463776	array([[-2.111309 , -2.9440408]], dtype=float32)

time = 66702	action = 0	current_phase = 0	next_phase = 1	reward = -0.308818	array([[-2.0793061, -3.2122457]], dtype=float32)

time = 66707	action = 0	current_phase = 0	next_phase = 1	reward = -0.176446	array([[-2.2423632, -3.3609378]], dtype=float32)

time = 66712	action = 0	current_phase = 0	next_phase = 1	reward = 0.203725	array([[-2.6031208, -4.5085506]], dtype=float32)

time = 66717	action = 1	current_phase = 0	next_phase = 1	reward = -1.728564	array([[-6.491729 , -3.4522002]], dtype=float32)

time = 66725	action = 0	current_phase = 1	next_phase = 0	reward = -0.530895	array([[-2.0670319, -3.2801926]], dtype=float32)

time = 66730	action = 0	current_phase = 1	next_phase = 0	reward = -0.370804	array([[-1.984726 , -3.0727348]], dtype=float32)

time = 66735	action = 0	current_phase = 1	next_phase = 0	reward = -0.211788	array([[-2.0314572, -3.0361905]], dtype=float32)

time = 66740	action = 0	current_phase = 1	next_phase = 0	reward = 0.353678	array([[-2.1928577, -4.097461 ]], dtype=float32)

time = 66745	action = 1	current_phase = 1	next_phase = 0	reward = -1.365924	array([[-3.5298104, -3.1392143]], dtype=float32)

time = 66753	action = 0	current_phase = 0	next_phase = 1	reward = -0.595810	array([[-2.2552028, -3.9551713]], dtype=float32)

time = 66758	action = 0	current_phase = 0	next_phase = 1	reward = -0.439734	array([[-2.1127381, -2.9437084]], dtype=float32)

time = 66763	action = 0	current_phase = 0	next_phase = 1	reward = -0.283145	array([[-2.0798192, -3.2127323]], dtype=float32)

time = 66768	action = 0	current_phase = 0	next_phase = 1	reward = -0.164376	array([[-2.2674854, -3.3825455]], dtype=float32)

time = 66773	action = 0	current_phase = 0	next_phase = 1	reward = 0.019066	array([[-2.7846317, -4.481451 ]], dtype=float32)

time = 66778	action = 1	current_phase = 0	next_phase = 1	reward = -1.902164	array([[-6.5720544, -3.5448935]], dtype=float32)

time = 66786	action = 0	current_phase = 1	next_phase = 0	reward = -0.498612	array([[-2.065882 , -3.2800767]], dtype=float32)

time = 66791	action = 0	current_phase = 1	next_phase = 0	reward = -0.348348	array([[-1.9804889, -3.0664315]], dtype=float32)

time = 66796	action = 0	current_phase = 1	next_phase = 0	reward = -0.195163	array([[-2.020021 , -3.1015491]], dtype=float32)

time = 66801	action = 0	current_phase = 1	next_phase = 0	reward = 0.330540	array([[-2.225664, -4.157772]], dtype=float32)

time = 66806	action = 1	current_phase = 1	next_phase = 0	reward = -1.550587	array([[-5.835303 , -3.2258976]], dtype=float32)

time = 66814	action = 0	current_phase = 0	next_phase = 1	reward = -0.553881	array([[-2.0655322, -3.1766741]], dtype=float32)

time = 66819	action = 0	current_phase = 0	next_phase = 1	reward = -0.401919	array([[-1.9232423, -3.106063 ]], dtype=float32)

time = 66824	action = 0	current_phase = 0	next_phase = 1	reward = -0.253918	array([[-1.9067652, -3.3906887]], dtype=float32)

time = 66829	action = 0	current_phase = 0	next_phase = 1	reward = -0.172590	array([[-2.087177, -3.297226]], dtype=float32)

time = 66834	action = 1	current_phase = 0	next_phase = 1	reward = -0.423730	array([[-5.9415035, -2.3974228]], dtype=float32)

time = 66842	action = 0	current_phase = 1	next_phase = 0	reward = -0.630219	array([[-2.3774874, -3.1691022]], dtype=float32)

time = 66847	action = 0	current_phase = 1	next_phase = 0	reward = -0.474322	array([[-2.194296 , -3.1274915]], dtype=float32)

time = 66852	action = 0	current_phase = 1	next_phase = 0	reward = -0.326045	array([[-2.2087226, -3.1563957]], dtype=float32)

time = 66857	action = 0	current_phase = 1	next_phase = 0	reward = -0.186032	array([[-2.3197355, -3.2405567]], dtype=float32)

time = 66862	action = 0	current_phase = 1	next_phase = 0	reward = 0.264648	array([[-2.5850863, -4.338257 ]], dtype=float32)

time = 66867	action = 1	current_phase = 1	next_phase = 0	reward = -1.782183	array([[-6.4166365, -3.3727307]], dtype=float32)

time = 66875	action = 0	current_phase = 0	next_phase = 1	reward = -0.527852	array([[-2.0241537, -3.3134694]], dtype=float32)

time = 66880	action = 0	current_phase = 0	next_phase = 1	reward = -0.374919	array([[-1.9226643, -3.107068 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0113 - val_loss: 0.0062

Epoch 2/50

 - 4s - loss: 0.0108 - val_loss: 0.0061

Epoch 3/50

 - 5s - loss: 0.0087 - val_loss: 0.0060

Epoch 4/50

 - 5s - loss: 0.0107 - val_loss: 0.0056

Epoch 5/50

 - 4s - loss: 0.0087 - val_loss: 0.0068

Epoch 6/50

 - 4s - loss: 0.0091 - val_loss: 0.0085

Epoch 7/50

 - 4s - loss: 0.0103 - val_loss: 0.0076

Epoch 8/50

 - 4s - loss: 0.0079 - val_loss: 0.0089

Epoch 9/50

 - 4s - loss: 0.0117 - val_loss: 0.0090

Epoch 10/50

 - 5s - loss: 0.0076 - val_loss: 0.0089

Epoch 11/50

 - 5s - loss: 0.0069 - val_loss: 0.0087

Epoch 12/50

 - 4s - loss: 0.0080 - val_loss: 0.0101

Epoch 13/50

 - 4s - loss: 0.0097 - val_loss: 0.0080

Epoch 14/50

 - 4s - loss: 0.0070 - val_loss: 0.0083

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 66885	action = 0	current_phase = 0	next_phase = 1	reward = -0.225188	array([[-1.9197389, -3.3811085]], dtype=float32)

time = 66890	action = 0	current_phase = 0	next_phase = 1	reward = 0.367235	array([[-2.2328432, -3.860573 ]], dtype=float32)

time = 66895	action = 1	current_phase = 0	next_phase = 1	reward = -1.292445	array([[-5.129688 , -3.1201024]], dtype=float32)

time = 66903	action = 0	current_phase = 1	next_phase = 0	reward = -0.584097	array([[-2.3287659, -3.162577 ]], dtype=float32)

time = 66908	action = 0	current_phase = 1	next_phase = 0	reward = -0.439444	array([[-2.0745883, -3.1067755]], dtype=float32)

time = 66913	action = 0	current_phase = 1	next_phase = 0	reward = -0.287877	array([[-2.175563 , -3.1136267]], dtype=float32)

time = 66918	action = 0	current_phase = 1	next_phase = 0	reward = -0.168132	array([[-2.3422253, -3.2035959]], dtype=float32)

time = 66923	action = 0	current_phase = 1	next_phase = 0	reward = 0.148492	array([[-2.7056406, -4.320178 ]], dtype=float32)

time = 66928	action = 1	current_phase = 1	next_phase = 0	reward = -1.900823	array([[-6.488538 , -3.5257857]], dtype=float32)

time = 66936	action = 0	current_phase = 0	next_phase = 1	reward = -0.517451	array([[-2.0006733, -3.3220701]], dtype=float32)

time = 66941	action = 0	current_phase = 0	next_phase = 1	reward = -0.363429	array([[-1.9192393, -3.1193907]], dtype=float32)

time = 66946	action = 0	current_phase = 0	next_phase = 1	reward = -0.209722	array([[-2.0654612, -3.2045674]], dtype=float32)

time = 66951	action = 0	current_phase = 0	next_phase = 1	reward = 0.315133	array([[-2.3798175, -4.179966 ]], dtype=float32)

time = 66956	action = 1	current_phase = 0	next_phase = 1	reward = -1.507880	array([[-4.7435427, -3.2206566]], dtype=float32)

time = 66964	action = 0	current_phase = 1	next_phase = 0	reward = -0.557987	array([[-2.146477 , -3.1143584]], dtype=float32)

time = 66969	action = 0	current_phase = 1	next_phase = 0	reward = -0.398318	array([[-1.9591355, -3.0593057]], dtype=float32)

time = 66974	action = 0	current_phase = 1	next_phase = 0	reward = -0.234499	array([[-1.9513851, -3.0001488]], dtype=float32)

time = 66979	action = 0	current_phase = 1	next_phase = 0	reward = 0.103844	array([[-2.0292563, -3.922363 ]], dtype=float32)

time = 66984	action = 1	current_phase = 1	next_phase = 0	reward = -0.734927	array([[-3.0542772, -2.7300918]], dtype=float32)

time = 66992	action = 0	current_phase = 0	next_phase = 1	reward = -0.619229	array([[-2.2504656, -3.9666512]], dtype=float32)

time = 66997	action = 0	current_phase = 0	next_phase = 1	reward = -0.458821	array([[-2.108495 , -2.9533172]], dtype=float32)

time = 67002	action = 0	current_phase = 0	next_phase = 1	reward = -0.311264	array([[-2.1029243, -3.176476 ]], dtype=float32)

time = 67007	action = 0	current_phase = 0	next_phase = 1	reward = -0.178554	array([[-2.2911572, -3.3589528]], dtype=float32)

time = 67012	action = 0	current_phase = 0	next_phase = 1	reward = 0.242249	array([[-2.6293347, -4.4932437]], dtype=float32)

time = 67017	action = 1	current_phase = 0	next_phase = 1	reward = -1.724022	array([[-6.341152 , -3.3973446]], dtype=float32)

time = 67025	action = 0	current_phase = 1	next_phase = 0	reward = -0.511888	array([[-2.061171 , -3.2856383]], dtype=float32)

time = 67030	action = 0	current_phase = 1	next_phase = 0	reward = -0.353960	array([[-1.9632089, -3.061645 ]], dtype=float32)

time = 67035	action = 0	current_phase = 1	next_phase = 0	reward = -0.203842	array([[-2.0187373, -3.0452135]], dtype=float32)

time = 67040	action = 0	current_phase = 1	next_phase = 0	reward = 0.337457	array([[-2.2062323, -4.148547 ]], dtype=float32)

time = 67045	action = 1	current_phase = 1	next_phase = 0	reward = -1.421761	array([[-3.5617745, -3.1178732]], dtype=float32)

time = 67053	action = 0	current_phase = 0	next_phase = 1	reward = -0.588149	array([[-2.2486959, -3.964186 ]], dtype=float32)

time = 67058	action = 0	current_phase = 0	next_phase = 1	reward = -0.433312	array([[-2.1100595, -2.9529212]], dtype=float32)

time = 67063	action = 0	current_phase = 0	next_phase = 1	reward = -0.277204	array([[-2.0990956, -3.2002482]], dtype=float32)

time = 67068	action = 0	current_phase = 0	next_phase = 1	reward = -0.168997	array([[-2.316431 , -3.3712733]], dtype=float32)

time = 67073	action = 0	current_phase = 0	next_phase = 1	reward = -0.063735	array([[-2.8287437, -4.439451 ]], dtype=float32)

time = 67078	action = 1	current_phase = 0	next_phase = 1	reward = -1.906432	array([[-6.57775  , -3.5532854]], dtype=float32)

time = 67086	action = 0	current_phase = 1	next_phase = 0	reward = -0.502975	array([[-2.0565522, -3.2836938]], dtype=float32)

time = 67091	action = 0	current_phase = 1	next_phase = 0	reward = -0.341657	array([[-1.9733368, -3.06606  ]], dtype=float32)

time = 67096	action = 0	current_phase = 1	next_phase = 0	reward = -0.190372	array([[-2.0228152, -3.1057594]], dtype=float32)

time = 67101	action = 0	current_phase = 1	next_phase = 0	reward = 0.326973	array([[-2.2223554, -4.147172 ]], dtype=float32)

time = 67106	action = 1	current_phase = 1	next_phase = 0	reward = -1.557854	array([[-5.88818  , -3.2557256]], dtype=float32)

time = 67114	action = 0	current_phase = 0	next_phase = 1	reward = -0.558787	array([[-2.0563135, -3.1874576]], dtype=float32)

time = 67119	action = 0	current_phase = 0	next_phase = 1	reward = -0.403675	array([[-1.9174907, -3.1204994]], dtype=float32)

time = 67124	action = 0	current_phase = 0	next_phase = 1	reward = -0.249459	array([[-1.9219562, -3.37516  ]], dtype=float32)

time = 67129	action = 0	current_phase = 0	next_phase = 1	reward = -0.176624	array([[-2.1666145, -3.300443 ]], dtype=float32)

time = 67134	action = 1	current_phase = 0	next_phase = 1	reward = -0.533973	array([[-5.960209 , -2.3961308]], dtype=float32)

time = 67142	action = 0	current_phase = 1	next_phase = 0	reward = -0.613209	array([[-2.3615663, -3.1677616]], dtype=float32)

time = 67147	action = 0	current_phase = 1	next_phase = 0	reward = -0.453162	array([[-2.1849232, -3.1261134]], dtype=float32)

time = 67152	action = 0	current_phase = 1	next_phase = 0	reward = -0.291009	array([[-2.1732862, -3.1441667]], dtype=float32)

time = 67157	action = 0	current_phase = 1	next_phase = 0	reward = -0.169906	array([[-2.3123448, -3.2484026]], dtype=float32)

time = 67162	action = 0	current_phase = 1	next_phase = 0	reward = 0.228626	array([[-2.5861418, -4.350791 ]], dtype=float32)

time = 67167	action = 1	current_phase = 1	next_phase = 0	reward = -1.728904	array([[-6.439744 , -3.4011328]], dtype=float32)

time = 67175	action = 0	current_phase = 0	next_phase = 1	reward = -0.521912	array([[-2.0001328, -3.3216228]], dtype=float32)

time = 67180	action = 0	current_phase = 0	next_phase = 1	reward = -0.364324	array([[-1.9163799, -3.121828 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0101 - val_loss: 0.0061

Epoch 2/50

 - 4s - loss: 0.0079 - val_loss: 0.0070

Epoch 3/50

 - 4s - loss: 0.0120 - val_loss: 0.0069

Epoch 4/50

 - 4s - loss: 0.0090 - val_loss: 0.0071

Epoch 5/50

 - 4s - loss: 0.0120 - val_loss: 0.0070

Epoch 6/50

 - 4s - loss: 0.0095 - val_loss: 0.0070

Epoch 7/50

 - 4s - loss: 0.0099 - val_loss: 0.0067

Epoch 8/50

 - 4s - loss: 0.0107 - val_loss: 0.0069

Epoch 9/50

 - 4s - loss: 0.0084 - val_loss: 0.0065

Epoch 10/50

 - 4s - loss: 0.0086 - val_loss: 0.0066

Epoch 11/50

 - 4s - loss: 0.0101 - val_loss: 0.0062

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 67185	action = 0	current_phase = 0	next_phase = 1	reward = -0.209644	array([[-1.9419917, -3.3490448]], dtype=float32)

time = 67190	action = 0	current_phase = 0	next_phase = 1	reward = 0.356273	array([[-2.2733128, -3.8719516]], dtype=float32)

time = 67195	action = 1	current_phase = 0	next_phase = 1	reward = -1.311259	array([[-5.152644 , -3.1290154]], dtype=float32)

time = 67203	action = 0	current_phase = 1	next_phase = 0	reward = -0.586714	array([[-2.286319 , -3.1438472]], dtype=float32)

time = 67208	action = 0	current_phase = 1	next_phase = 0	reward = -0.434713	array([[-2.0652666, -3.097712 ]], dtype=float32)

time = 67213	action = 0	current_phase = 1	next_phase = 0	reward = -0.277838	array([[-2.1695967, -3.1024961]], dtype=float32)

time = 67218	action = 0	current_phase = 1	next_phase = 0	reward = -0.160188	array([[-2.3413243, -3.1860077]], dtype=float32)

time = 67223	action = 0	current_phase = 1	next_phase = 0	reward = 0.101511	array([[-2.6822746, -4.2059155]], dtype=float32)

time = 67228	action = 1	current_phase = 1	next_phase = 0	reward = -1.892458	array([[-6.5061436, -3.5050318]], dtype=float32)

time = 67236	action = 0	current_phase = 0	next_phase = 1	reward = -0.489573	array([[-2.0342638, -3.3102355]], dtype=float32)

time = 67241	action = 0	current_phase = 0	next_phase = 1	reward = -0.341555	array([[-1.9727458, -3.1154466]], dtype=float32)

time = 67246	action = 0	current_phase = 0	next_phase = 1	reward = -0.198652	array([[-2.0854828, -3.1695566]], dtype=float32)

time = 67251	action = 0	current_phase = 0	next_phase = 1	reward = 0.323438	array([[-2.5292435, -4.304318 ]], dtype=float32)

time = 67256	action = 1	current_phase = 0	next_phase = 1	reward = -1.559950	array([[-4.624866, -3.257259]], dtype=float32)

time = 67264	action = 0	current_phase = 1	next_phase = 0	reward = -0.562935	array([[-2.1218333, -3.096605 ]], dtype=float32)

time = 67269	action = 0	current_phase = 1	next_phase = 0	reward = -0.418642	array([[-1.9483569, -3.046774 ]], dtype=float32)

time = 67274	action = 0	current_phase = 1	next_phase = 0	reward = -0.257308	array([[-2.0012393, -3.0141895]], dtype=float32)

time = 67279	action = 0	current_phase = 1	next_phase = 0	reward = -0.173687	array([[-2.0603683, -3.8839645]], dtype=float32)

time = 67284	action = 1	current_phase = 1	next_phase = 0	reward = -0.433001	array([[-2.6837032, -2.2620625]], dtype=float32)

time = 67292	action = 0	current_phase = 0	next_phase = 1	reward = -0.618200	array([[-2.2824066, -3.9534965]], dtype=float32)

time = 67297	action = 0	current_phase = 0	next_phase = 1	reward = -0.472286	array([[-2.1322596, -2.9397829]], dtype=float32)

time = 67302	action = 0	current_phase = 0	next_phase = 1	reward = -0.317892	array([[-2.0940907, -3.0577385]], dtype=float32)

time = 67307	action = 0	current_phase = 0	next_phase = 1	reward = -0.180906	array([[-2.2556512, -3.2683396]], dtype=float32)

time = 67312	action = 0	current_phase = 0	next_phase = 1	reward = 0.160817	array([[-2.6664817, -4.511155 ]], dtype=float32)

time = 67317	action = 1	current_phase = 0	next_phase = 1	reward = -1.783799	array([[-6.5302153, -3.4210572]], dtype=float32)

time = 67325	action = 0	current_phase = 1	next_phase = 0	reward = -0.528301	array([[-2.075662 , -3.2808309]], dtype=float32)

time = 67330	action = 0	current_phase = 1	next_phase = 0	reward = -0.364410	array([[-1.9556739, -3.050501 ]], dtype=float32)

time = 67335	action = 0	current_phase = 1	next_phase = 0	reward = -0.210501	array([[-2.009076 , -3.0249639]], dtype=float32)

time = 67340	action = 0	current_phase = 1	next_phase = 0	reward = 0.366496	array([[-2.2012703, -4.116484 ]], dtype=float32)

time = 67345	action = 1	current_phase = 1	next_phase = 0	reward = -1.254849	array([[-3.6002617, -3.116169 ]], dtype=float32)

time = 67353	action = 0	current_phase = 0	next_phase = 1	reward = -0.591481	array([[-2.281861 , -3.9533563]], dtype=float32)

time = 67358	action = 0	current_phase = 0	next_phase = 1	reward = -0.442064	array([[-2.1355321, -2.9380636]], dtype=float32)

time = 67363	action = 0	current_phase = 0	next_phase = 1	reward = -0.291977	array([[-2.1168664, -3.1687348]], dtype=float32)

time = 67368	action = 0	current_phase = 0	next_phase = 1	reward = -0.171621	array([[-2.344072 , -3.3312554]], dtype=float32)

time = 67373	action = 0	current_phase = 0	next_phase = 1	reward = 0.137279	array([[-2.997142 , -4.2541337]], dtype=float32)

time = 67378	action = 1	current_phase = 0	next_phase = 1	reward = -1.892450	array([[-6.4269104, -3.5186439]], dtype=float32)

time = 67386	action = 0	current_phase = 1	next_phase = 0	reward = -0.499418	array([[-2.0573318, -3.2849145]], dtype=float32)

time = 67391	action = 0	current_phase = 1	next_phase = 0	reward = -0.342244	array([[-1.9557693, -3.0507457]], dtype=float32)

time = 67396	action = 0	current_phase = 1	next_phase = 0	reward = -0.190971	array([[-2.0172272, -3.095582 ]], dtype=float32)

time = 67401	action = 0	current_phase = 1	next_phase = 0	reward = 0.287407	array([[-2.2307427, -4.143998 ]], dtype=float32)

time = 67406	action = 1	current_phase = 1	next_phase = 0	reward = -1.613057	array([[-5.8858657, -3.210033 ]], dtype=float32)

time = 67414	action = 0	current_phase = 0	next_phase = 1	reward = -0.559775	array([[-2.0818615, -3.177539 ]], dtype=float32)

time = 67419	action = 0	current_phase = 0	next_phase = 1	reward = -0.408619	array([[-1.9459848, -3.103691 ]], dtype=float32)

time = 67424	action = 0	current_phase = 0	next_phase = 1	reward = -0.260957	array([[-2.0059187, -3.254334 ]], dtype=float32)

time = 67429	action = 0	current_phase = 0	next_phase = 1	reward = -0.184755	array([[-2.3314693, -3.3209856]], dtype=float32)

time = 67434	action = 1	current_phase = 0	next_phase = 1	reward = -1.418242	array([[-5.981308 , -2.5152447]], dtype=float32)

time = 67442	action = 1	current_phase = 1	next_phase = 0	reward = -1.960145	array([[-4.463351, -3.560469]], dtype=float32)

time = 67450	action = 0	current_phase = 0	next_phase = 1	reward = -0.368786	array([[-1.9742196, -3.1267862]], dtype=float32)

time = 67455	action = 0	current_phase = 0	next_phase = 1	reward = -0.213427	array([[-1.9422183, -3.3484643]], dtype=float32)

time = 67460	action = 0	current_phase = 0	next_phase = 1	reward = 0.336295	array([[-2.2123642, -3.6598215]], dtype=float32)

time = 67465	action = 1	current_phase = 0	next_phase = 1	reward = -1.371607	array([[-3.8279672, -2.389699 ]], dtype=float32)

time = 67473	action = 0	current_phase = 1	next_phase = 0	reward = -0.587890	array([[-2.109054, -3.097002]], dtype=float32)

time = 67478	action = 0	current_phase = 1	next_phase = 0	reward = -0.438380	array([[-2.125914 , -3.1235201]], dtype=float32)

time = 67483	action = 0	current_phase = 1	next_phase = 0	reward = -0.293646	array([[-2.1902425, -3.1409729]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0109 - val_loss: 0.0036

Epoch 2/50

 - 4s - loss: 0.0097 - val_loss: 0.0042

Epoch 3/50

 - 4s - loss: 0.0143 - val_loss: 0.0050

Epoch 4/50

 - 4s - loss: 0.0100 - val_loss: 0.0040

Epoch 5/50

 - 4s - loss: 0.0071 - val_loss: 0.0039

Epoch 6/50

 - 4s - loss: 0.0086 - val_loss: 0.0041

Epoch 7/50

 - 4s - loss: 0.0086 - val_loss: 0.0045

Epoch 8/50

 - 4s - loss: 0.0098 - val_loss: 0.0048

Epoch 9/50

 - 4s - loss: 0.0075 - val_loss: 0.0056

Epoch 10/50

 - 4s - loss: 0.0081 - val_loss: 0.0059

Epoch 11/50

 - 4s - loss: 0.0070 - val_loss: 0.0070

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1006, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1020, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 67488	action = 0	current_phase = 1	next_phase = 0	reward = -0.165586	array([[-2.304408 , -3.2537377]], dtype=float32)

time = 67493	action = 0	current_phase = 1	next_phase = 0	reward = 0.206455	array([[-2.6776056, -4.3047295]], dtype=float32)

time = 67498	action = 1	current_phase = 1	next_phase = 0	reward = -1.888766	array([[-6.516061 , -3.4647527]], dtype=float32)

time = 67506	action = 0	current_phase = 0	next_phase = 1	reward = -0.501174	array([[-2.0201054, -3.292232 ]], dtype=float32)

time = 67511	action = 0	current_phase = 0	next_phase = 1	reward = -0.355557	array([[-1.9474896, -3.0929282]], dtype=float32)

time = 67516	action = 0	current_phase = 0	next_phase = 1	reward = -0.203502	array([[-2.0673206, -3.1638525]], dtype=float32)

time = 67521	action = 0	current_phase = 0	next_phase = 1	reward = 0.297922	array([[-2.3351588, -4.1559367]], dtype=float32)

time = 67526	action = 1	current_phase = 0	next_phase = 1	reward = -1.558643	array([[-4.585973 , -3.2778592]], dtype=float32)

time = 67534	action = 0	current_phase = 1	next_phase = 0	reward = -0.561409	array([[-2.142233 , -3.0902145]], dtype=float32)

time = 67539	action = 0	current_phase = 1	next_phase = 0	reward = -0.405565	array([[-1.9646811, -3.0440423]], dtype=float32)

time = 67544	action = 0	current_phase = 1	next_phase = 0	reward = -0.262273	array([[-1.9588612, -2.974286 ]], dtype=float32)

time = 67549	action = 0	current_phase = 1	next_phase = 0	reward = -0.179749	array([[-2.0387392, -3.9246864]], dtype=float32)

time = 67554	action = 1	current_phase = 1	next_phase = 0	reward = -0.444518	array([[-2.702386 , -2.3505585]], dtype=float32)

time = 67562	action = 0	current_phase = 0	next_phase = 1	reward = -0.613357	array([[-2.2651055, -3.9560099]], dtype=float32)

time = 67567	action = 0	current_phase = 0	next_phase = 1	reward = -0.463480	array([[-2.1126454, -2.9332142]], dtype=float32)

time = 67572	action = 0	current_phase = 0	next_phase = 1	reward = -0.310654	array([[-2.0949225, -3.166012 ]], dtype=float32)

time = 67577	action = 0	current_phase = 0	next_phase = 1	reward = -0.175079	array([[-2.2673767, -3.2741852]], dtype=float32)

time = 67582	action = 0	current_phase = 0	next_phase = 1	reward = 0.215511	array([[-2.5444279, -4.51392  ]], dtype=float32)

time = 67587	action = 1	current_phase = 0	next_phase = 1	reward = -1.786635	array([[-6.346842, -3.404222]], dtype=float32)

time = 67595	action = 0	current_phase = 1	next_phase = 0	reward = -0.537109	array([[-2.0712764, -3.2775183]], dtype=float32)

time = 67600	action = 0	current_phase = 1	next_phase = 0	reward = -0.373667	array([[-1.9853581, -3.0587907]], dtype=float32)

time = 67605	action = 0	current_phase = 1	next_phase = 0	reward = -0.210749	array([[-2.0257545, -3.0242028]], dtype=float32)

time = 67610	action = 0	current_phase = 1	next_phase = 0	reward = 0.355980	array([[-2.1830184, -4.1026297]], dtype=float32)

time = 67615	action = 1	current_phase = 1	next_phase = 0	reward = -1.366539	array([[-3.5749784, -3.1433005]], dtype=float32)

time = 67623	action = 0	current_phase = 0	next_phase = 1	reward = -0.596902	array([[-2.260947 , -3.9557998]], dtype=float32)

time = 67628	action = 0	current_phase = 0	next_phase = 1	reward = -0.453841	array([[-2.1157522, -2.9320717]], dtype=float32)

time = 67633	action = 0	current_phase = 0	next_phase = 1	reward = -0.303287	array([[-2.0934157, -3.1662529]], dtype=float32)

time = 67638	action = 0	current_phase = 0	next_phase = 1	reward = -0.169374	array([[-2.3513079, -3.3258958]], dtype=float32)

time = 67643	action = 0	current_phase = 0	next_phase = 1	reward = 0.085629	array([[-2.565638, -4.507477]], dtype=float32)

time = 67648	action = 1	current_phase = 0	next_phase = 1	reward = -1.896746	array([[-6.5657725, -3.4973104]], dtype=float32)

time = 67656	action = 0	current_phase = 1	next_phase = 0	reward = -0.490639	array([[-2.069582 , -3.2774777]], dtype=float32)

time = 67661	action = 0	current_phase = 1	next_phase = 0	reward = -0.338101	array([[-1.9760551, -3.0510666]], dtype=float32)

time = 67666	action = 0	current_phase = 1	next_phase = 0	reward = -0.200113	array([[-2.0240843, -3.0923605]], dtype=float32)

time = 67671	action = 0	current_phase = 1	next_phase = 0	reward = 0.301084	array([[-2.2261825, -4.1459517]], dtype=float32)

time = 67676	action = 1	current_phase = 1	next_phase = 0	reward = -1.664916	array([[-5.9131446, -3.2512205]], dtype=float32)

time = 67684	action = 0	current_phase = 0	next_phase = 1	reward = -0.561670	array([[-2.0623984, -3.168613 ]], dtype=float32)

time = 67689	action = 0	current_phase = 0	next_phase = 1	reward = -0.402680	array([[-1.9330953, -3.096575 ]], dtype=float32)

time = 67694	action = 0	current_phase = 0	next_phase = 1	reward = -0.241050	array([[-1.9322269, -3.3425937]], dtype=float32)

time = 67699	action = 0	current_phase = 0	next_phase = 1	reward = -0.183393	array([[-2.1165755, -3.257232 ]], dtype=float32)

time = 67704	action = 1	current_phase = 0	next_phase = 1	reward = -0.506711	array([[-5.994596 , -2.3756323]], dtype=float32)

time = 67712	action = 0	current_phase = 1	next_phase = 0	reward = -0.611599	array([[-2.3505647, -3.1462095]], dtype=float32)

time = 67717	action = 0	current_phase = 1	next_phase = 0	reward = -0.444769	array([[-2.1628501, -3.0971103]], dtype=float32)

time = 67722	action = 0	current_phase = 1	next_phase = 0	reward = -0.281124	array([[-2.2048516, -3.144238 ]], dtype=float32)

time = 67727	action = 0	current_phase = 1	next_phase = 0	reward = -0.164041	array([[-2.3028808, -3.2530978]], dtype=float32)

time = 67732	action = 0	current_phase = 1	next_phase = 0	reward = 0.134614	array([[-2.5862558, -4.334802 ]], dtype=float32)

time = 67737	action = 1	current_phase = 1	next_phase = 0	reward = -1.783224	array([[-6.53232, -3.55045]], dtype=float32)

time = 67745	action = 0	current_phase = 0	next_phase = 1	reward = -0.523283	array([[-2.0268111, -3.296112 ]], dtype=float32)

time = 67750	action = 0	current_phase = 0	next_phase = 1	reward = -0.362644	array([[-1.9330071, -3.097059 ]], dtype=float32)

time = 67755	action = 0	current_phase = 0	next_phase = 1	reward = -0.212363	array([[-1.9308306, -3.3467236]], dtype=float32)

time = 67760	action = 0	current_phase = 0	next_phase = 1	reward = 0.343279	array([[-2.284673, -4.055474]], dtype=float32)

time = 67765	action = 1	current_phase = 0	next_phase = 1	reward = -1.263410	array([[-5.325083, -3.115133]], dtype=float32)

time = 67773	action = 0	current_phase = 1	next_phase = 0	reward = -0.589783	array([[-2.3242168, -3.1409256]], dtype=float32)

time = 67778	action = 0	current_phase = 1	next_phase = 0	reward = -0.437250	array([[-2.1510751, -3.1238706]], dtype=float32)

time = 67783	action = 0	current_phase = 1	next_phase = 0	reward = -0.282221	array([[-2.1927636, -3.1192107]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0079 - val_loss: 0.0116

Epoch 2/50

 - 4s - loss: 0.0071 - val_loss: 0.0100

Epoch 3/50

 - 4s - loss: 0.0052 - val_loss: 0.0128

Epoch 4/50

 - 4s - loss: 0.0061 - val_loss: 0.0121

Epoch 5/50

 - 4s - loss: 0.0067 - val_loss: 0.0120

Epoch 6/50

 - 5s - loss: 0.0069 - val_loss: 0.0113

Epoch 7/50

 - 5s - loss: 0.0048 - val_loss: 0.0145

Epoch 8/50

 - 4s - loss: 0.0051 - val_loss: 0.0123

Epoch 9/50

 - 4s - loss: 0.0057 - val_loss: 0.0123

Epoch 10/50

 - 4s - loss: 0.0058 - val_loss: 0.0118

Epoch 11/50

 - 4s - loss: 0.0046 - val_loss: 0.0120

Epoch 12/50

 - 4s - loss: 0.0070 - val_loss: 0.0135

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 67788	action = 0	current_phase = 1	next_phase = 0	reward = -0.163024	array([[-2.3130138, -3.2356749]], dtype=float32)

time = 67793	action = 0	current_phase = 1	next_phase = 0	reward = 0.151413	array([[-2.6548133, -4.2933927]], dtype=float32)

time = 67798	action = 1	current_phase = 1	next_phase = 0	reward = -1.837441	array([[-6.5199533, -3.5118008]], dtype=float32)

time = 67806	action = 0	current_phase = 0	next_phase = 1	reward = -0.490720	array([[-2.025156, -3.291026]], dtype=float32)

time = 67811	action = 0	current_phase = 0	next_phase = 1	reward = -0.343217	array([[-1.9384757, -3.0899754]], dtype=float32)

time = 67816	action = 0	current_phase = 0	next_phase = 1	reward = -0.198056	array([[-2.059285 , -3.1706955]], dtype=float32)

time = 67821	action = 0	current_phase = 0	next_phase = 1	reward = 0.309351	array([[-2.3488295, -4.1623316]], dtype=float32)

time = 67826	action = 1	current_phase = 0	next_phase = 1	reward = -1.509648	array([[-4.5789123, -3.2361574]], dtype=float32)

time = 67834	action = 0	current_phase = 1	next_phase = 0	reward = -0.567845	array([[-2.111497 , -3.0668807]], dtype=float32)

time = 67839	action = 0	current_phase = 1	next_phase = 0	reward = -0.419275	array([[-1.9484539, -3.027564 ]], dtype=float32)

time = 67844	action = 0	current_phase = 1	next_phase = 0	reward = -0.254617	array([[-2.0026221, -2.994047 ]], dtype=float32)

time = 67849	action = 0	current_phase = 1	next_phase = 0	reward = -0.166130	array([[-2.0925214, -3.7794652]], dtype=float32)

time = 67854	action = 1	current_phase = 1	next_phase = 0	reward = -0.382486	array([[-2.6669607, -2.3182604]], dtype=float32)

time = 67862	action = 0	current_phase = 0	next_phase = 1	reward = -0.627297	array([[-2.2720425, -3.955604 ]], dtype=float32)

time = 67867	action = 0	current_phase = 0	next_phase = 1	reward = -0.468466	array([[-2.1202588, -2.9293928]], dtype=float32)

time = 67872	action = 0	current_phase = 0	next_phase = 1	reward = -0.309417	array([[-2.0845172, -3.162685 ]], dtype=float32)

time = 67877	action = 0	current_phase = 0	next_phase = 1	reward = -0.173963	array([[-2.2090325, -3.2580357]], dtype=float32)

time = 67882	action = 0	current_phase = 0	next_phase = 1	reward = 0.180703	array([[-2.5831358, -4.51046  ]], dtype=float32)

time = 67887	action = 1	current_phase = 0	next_phase = 1	reward = -1.781278	array([[-6.459563 , -3.4393418]], dtype=float32)

time = 67895	action = 0	current_phase = 1	next_phase = 0	reward = -0.523195	array([[-2.0529294, -3.2629168]], dtype=float32)

time = 67900	action = 0	current_phase = 1	next_phase = 0	reward = -0.366746	array([[-1.9801581, -3.0518665]], dtype=float32)

time = 67905	action = 0	current_phase = 1	next_phase = 0	reward = -0.217919	array([[-2.0227842, -3.0201974]], dtype=float32)

time = 67910	action = 0	current_phase = 1	next_phase = 0	reward = 0.354150	array([[-2.1855137, -4.1221285]], dtype=float32)

time = 67915	action = 1	current_phase = 1	next_phase = 0	reward = -1.262770	array([[-3.5765252, -3.1397982]], dtype=float32)

time = 67923	action = 0	current_phase = 0	next_phase = 1	reward = -0.582897	array([[-2.2696407, -3.953756 ]], dtype=float32)

time = 67928	action = 0	current_phase = 0	next_phase = 1	reward = -0.423943	array([[-2.1212468, -2.9291143]], dtype=float32)

time = 67933	action = 0	current_phase = 0	next_phase = 1	reward = -0.265776	array([[-2.0920162, -3.1646998]], dtype=float32)

time = 67938	action = 0	current_phase = 0	next_phase = 1	reward = -0.163120	array([[-2.321831 , -3.3380878]], dtype=float32)

time = 67943	action = 0	current_phase = 0	next_phase = 1	reward = -0.054596	array([[-2.9561894, -4.287414 ]], dtype=float32)

time = 67948	action = 1	current_phase = 0	next_phase = 1	reward = -1.905666	array([[-6.5863266, -3.5505707]], dtype=float32)

time = 67956	action = 0	current_phase = 1	next_phase = 0	reward = -0.496552	array([[-2.0533953, -3.2624757]], dtype=float32)

time = 67961	action = 0	current_phase = 1	next_phase = 0	reward = -0.334492	array([[-1.9748315, -3.0422995]], dtype=float32)

time = 67966	action = 0	current_phase = 1	next_phase = 0	reward = -0.184061	array([[-2.0180297, -3.083683 ]], dtype=float32)

time = 67971	action = 0	current_phase = 1	next_phase = 0	reward = 0.314053	array([[-2.1914177, -4.1428194]], dtype=float32)

time = 67976	action = 1	current_phase = 1	next_phase = 0	reward = -1.559836	array([[-5.89333  , -3.2310746]], dtype=float32)

time = 67984	action = 0	current_phase = 0	next_phase = 1	reward = -0.556974	array([[-2.0640876, -3.165901 ]], dtype=float32)

time = 67989	action = 0	current_phase = 0	next_phase = 1	reward = -0.392693	array([[-1.9303956, -3.0919495]], dtype=float32)

time = 67994	action = 0	current_phase = 0	next_phase = 1	reward = -0.239230	array([[-1.9137831, -3.3453033]], dtype=float32)

time = 67999	action = 0	current_phase = 0	next_phase = 1	reward = -0.190218	array([[-2.0980625, -3.2815344]], dtype=float32)

time = 68004	action = 1	current_phase = 0	next_phase = 1	reward = -0.613805	array([[-6.00258  , -2.4188821]], dtype=float32)

time = 68012	action = 0	current_phase = 1	next_phase = 0	reward = -0.620636	array([[-2.2915647, -3.12166  ]], dtype=float32)

time = 68017	action = 0	current_phase = 1	next_phase = 0	reward = -0.470904	array([[-2.1561537, -3.0819504]], dtype=float32)

time = 68022	action = 0	current_phase = 1	next_phase = 0	reward = -0.326373	array([[-2.1721737, -3.126955 ]], dtype=float32)

time = 68027	action = 0	current_phase = 1	next_phase = 0	reward = -0.188582	array([[-2.3094606, -3.2398822]], dtype=float32)

time = 68032	action = 0	current_phase = 1	next_phase = 0	reward = 0.267970	array([[-2.5494368, -4.332201 ]], dtype=float32)

time = 68037	action = 1	current_phase = 1	next_phase = 0	reward = -1.782432	array([[-6.464649 , -3.3838685]], dtype=float32)

time = 68045	action = 0	current_phase = 0	next_phase = 1	reward = -0.522327	array([[-2.0220525, -3.2893078]], dtype=float32)

time = 68050	action = 0	current_phase = 0	next_phase = 1	reward = -0.363955	array([[-1.9286232, -3.0943604]], dtype=float32)

time = 68055	action = 0	current_phase = 0	next_phase = 1	reward = -0.219286	array([[-1.9135566, -3.346026 ]], dtype=float32)

time = 68060	action = 0	current_phase = 0	next_phase = 1	reward = 0.041862	array([[-2.2057378, -3.8910952]], dtype=float32)

time = 68065	action = 1	current_phase = 0	next_phase = 1	reward = -1.143817	array([[-5.8619547, -2.8093655]], dtype=float32)

time = 68073	action = 0	current_phase = 1	next_phase = 0	reward = -0.588997	array([[-2.2733688, -3.1170006]], dtype=float32)

time = 68078	action = 0	current_phase = 1	next_phase = 0	reward = -0.433957	array([[-2.148305 , -3.1169722]], dtype=float32)

time = 68083	action = 0	current_phase = 1	next_phase = 0	reward = -0.274407	array([[-2.1257653, -3.0938468]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0098 - val_loss: 0.0084

Epoch 2/50

 - 4s - loss: 0.0085 - val_loss: 0.0081

Epoch 3/50

 - 4s - loss: 0.0065 - val_loss: 0.0085

Epoch 4/50

 - 4s - loss: 0.0070 - val_loss: 0.0082

Epoch 5/50

 - 4s - loss: 0.0074 - val_loss: 0.0084

Epoch 6/50

 - 4s - loss: 0.0063 - val_loss: 0.0091

Epoch 7/50

 - 4s - loss: 0.0080 - val_loss: 0.0092

Epoch 8/50

 - 4s - loss: 0.0050 - val_loss: 0.0099

Epoch 9/50

 - 4s - loss: 0.0104 - val_loss: 0.0090

Epoch 10/50

 - 4s - loss: 0.0067 - val_loss: 0.0096

Epoch 11/50

 - 4s - loss: 0.0050 - val_loss: 0.0086

Epoch 12/50

 - 4s - loss: 0.0046 - val_loss: 0.0089

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 68088	action = 0	current_phase = 1	next_phase = 0	reward = -0.159470	array([[-2.2973156, -3.2590377]], dtype=float32)

time = 68093	action = 0	current_phase = 1	next_phase = 0	reward = 0.131505	array([[-2.6999307, -4.3544583]], dtype=float32)

time = 68098	action = 1	current_phase = 1	next_phase = 0	reward = -1.833270	array([[-6.531662 , -3.4949806]], dtype=float32)

time = 68106	action = 0	current_phase = 0	next_phase = 1	reward = -0.488932	array([[-2.0697877, -3.3001535]], dtype=float32)

time = 68111	action = 0	current_phase = 0	next_phase = 1	reward = -0.336281	array([[-1.9473531, -3.0951128]], dtype=float32)

time = 68116	action = 0	current_phase = 0	next_phase = 1	reward = -0.192463	array([[-2.096147 , -3.1608145]], dtype=float32)

time = 68121	action = 0	current_phase = 0	next_phase = 1	reward = 0.297093	array([[-2.3603702, -4.185529 ]], dtype=float32)

time = 68126	action = 1	current_phase = 0	next_phase = 1	reward = -1.550043	array([[-4.5275345, -3.313148 ]], dtype=float32)

time = 68134	action = 0	current_phase = 1	next_phase = 0	reward = -0.537319	array([[-2.137757 , -3.0570807]], dtype=float32)

time = 68139	action = 0	current_phase = 1	next_phase = 0	reward = -0.374715	array([[-1.9727954, -3.0355604]], dtype=float32)

time = 68144	action = 0	current_phase = 1	next_phase = 0	reward = -0.221424	array([[-1.9219086, -2.968956 ]], dtype=float32)

time = 68149	action = 0	current_phase = 1	next_phase = 0	reward = 0.090508	array([[-2.045173 , -3.9529612]], dtype=float32)

time = 68154	action = 1	current_phase = 1	next_phase = 0	reward = -0.830704	array([[-3.2999935, -2.8102117]], dtype=float32)

time = 68162	action = 0	current_phase = 0	next_phase = 1	reward = -0.606563	array([[-2.3106165, -3.9622087]], dtype=float32)

time = 68167	action = 0	current_phase = 0	next_phase = 1	reward = -0.440553	array([[-2.120539, -2.937613]], dtype=float32)

time = 68172	action = 0	current_phase = 0	next_phase = 1	reward = -0.288172	array([[-2.1205184, -3.1577973]], dtype=float32)

time = 68177	action = 0	current_phase = 0	next_phase = 1	reward = -0.167460	array([[-2.3405097, -3.3112288]], dtype=float32)

time = 68182	action = 0	current_phase = 0	next_phase = 1	reward = 0.081528	array([[-2.579176 , -4.5112524]], dtype=float32)

time = 68187	action = 1	current_phase = 0	next_phase = 1	reward = -1.783304	array([[-6.575287 , -3.4867685]], dtype=float32)

time = 68195	action = 0	current_phase = 1	next_phase = 0	reward = -0.512743	array([[-2.097674 , -3.2532754]], dtype=float32)

time = 68200	action = 0	current_phase = 1	next_phase = 0	reward = -0.350428	array([[-1.9781256, -3.0450902]], dtype=float32)

time = 68205	action = 0	current_phase = 1	next_phase = 0	reward = -0.196303	array([[-1.9364817, -3.006607 ]], dtype=float32)

time = 68210	action = 0	current_phase = 1	next_phase = 0	reward = 0.338904	array([[-2.253563, -4.168746]], dtype=float32)

time = 68215	action = 1	current_phase = 1	next_phase = 0	reward = -1.368744	array([[-3.6133351, -3.1534255]], dtype=float32)

time = 68223	action = 0	current_phase = 0	next_phase = 1	reward = -0.584056	array([[-2.3079164, -3.9575326]], dtype=float32)

time = 68228	action = 0	current_phase = 0	next_phase = 1	reward = -0.435938	array([[-2.1226647, -2.9363165]], dtype=float32)

time = 68233	action = 0	current_phase = 0	next_phase = 1	reward = -0.287990	array([[-2.1220417, -3.1572645]], dtype=float32)

time = 68238	action = 0	current_phase = 0	next_phase = 1	reward = -0.168010	array([[-2.3449397, -3.3137903]], dtype=float32)

time = 68243	action = 0	current_phase = 0	next_phase = 1	reward = 0.008778	array([[-2.8112879, -4.401472 ]], dtype=float32)

time = 68248	action = 1	current_phase = 0	next_phase = 1	reward = -1.901109	array([[-6.580918, -3.537256]], dtype=float32)

time = 68256	action = 0	current_phase = 1	next_phase = 0	reward = -0.499951	array([[-2.0966468, -3.2552025]], dtype=float32)

time = 68261	action = 0	current_phase = 1	next_phase = 0	reward = -0.339576	array([[-1.9760419, -3.0305197]], dtype=float32)

time = 68266	action = 0	current_phase = 1	next_phase = 0	reward = -0.195821	array([[-1.9887313, -3.0787141]], dtype=float32)

time = 68271	action = 0	current_phase = 1	next_phase = 0	reward = 0.320717	array([[-2.273952 , -4.1758375]], dtype=float32)

time = 68276	action = 1	current_phase = 1	next_phase = 0	reward = -1.555428	array([[-5.9122043, -3.2154245]], dtype=float32)

time = 68284	action = 0	current_phase = 0	next_phase = 1	reward = -0.566706	array([[-2.1031017, -3.182045 ]], dtype=float32)

time = 68289	action = 0	current_phase = 0	next_phase = 1	reward = -0.415160	array([[-1.9355876, -3.0889103]], dtype=float32)

time = 68294	action = 0	current_phase = 0	next_phase = 1	reward = -0.254415	array([[-1.9463446, -3.3282816]], dtype=float32)

time = 68299	action = 0	current_phase = 0	next_phase = 1	reward = -0.169739	array([[-2.0963879, -3.292003 ]], dtype=float32)

time = 68304	action = 1	current_phase = 0	next_phase = 1	reward = -0.387448	array([[-6.0170608, -2.3412278]], dtype=float32)

time = 68312	action = 0	current_phase = 1	next_phase = 0	reward = -0.613466	array([[-2.3680089, -3.1217225]], dtype=float32)

time = 68317	action = 0	current_phase = 1	next_phase = 0	reward = -0.461594	array([[-2.1828113, -3.0719826]], dtype=float32)

time = 68322	action = 0	current_phase = 1	next_phase = 0	reward = -0.318547	array([[-2.1884375, -3.1214406]], dtype=float32)

time = 68327	action = 0	current_phase = 1	next_phase = 0	reward = -0.183317	array([[-2.2911613, -3.2499337]], dtype=float32)

time = 68332	action = 0	current_phase = 1	next_phase = 0	reward = 0.142739	array([[-2.55078 , -4.343495]], dtype=float32)

time = 68337	action = 1	current_phase = 1	next_phase = 0	reward = -1.781123	array([[-6.4813604, -3.3883507]], dtype=float32)

time = 68345	action = 0	current_phase = 0	next_phase = 1	reward = -0.517323	array([[-2.0698953, -3.3010483]], dtype=float32)

time = 68350	action = 0	current_phase = 0	next_phase = 1	reward = -0.363059	array([[-1.9349297, -3.089348 ]], dtype=float32)

time = 68355	action = 0	current_phase = 0	next_phase = 1	reward = -0.211930	array([[-1.9462855, -3.3284214]], dtype=float32)

time = 68360	action = 0	current_phase = 0	next_phase = 1	reward = 0.341647	array([[-2.1694987, -3.8919702]], dtype=float32)

time = 68365	action = 1	current_phase = 0	next_phase = 1	reward = -1.321516	array([[-5.3011203, -3.1154923]], dtype=float32)

time = 68373	action = 0	current_phase = 1	next_phase = 0	reward = -0.590621	array([[-2.318703, -3.111383]], dtype=float32)

time = 68378	action = 0	current_phase = 1	next_phase = 0	reward = -0.427110	array([[-2.1365516, -3.1001751]], dtype=float32)

time = 68383	action = 0	current_phase = 1	next_phase = 0	reward = -0.268293	array([[-2.1183338, -3.0724056]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0120 - val_loss: 0.0054

Epoch 2/50

 - 4s - loss: 0.0082 - val_loss: 0.0057

Epoch 3/50

 - 5s - loss: 0.0088 - val_loss: 0.0060

Epoch 4/50

 - 4s - loss: 0.0089 - val_loss: 0.0058

Epoch 5/50

 - 4s - loss: 0.0068 - val_loss: 0.0060

Epoch 6/50

 - 4s - loss: 0.0102 - val_loss: 0.0066

Epoch 7/50

 - 4s - loss: 0.0086 - val_loss: 0.0066

Epoch 8/50

 - 5s - loss: 0.0082 - val_loss: 0.0060

Epoch 9/50

 - 4s - loss: 0.0072 - val_loss: 0.0066

Epoch 10/50

 - 4s - loss: 0.0071 - val_loss: 0.0065

Epoch 11/50

 - 4s - loss: 0.0080 - val_loss: 0.0067

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 68388	action = 0	current_phase = 1	next_phase = 0	reward = -0.157737	array([[-2.3103974, -3.1806765]], dtype=float32)

time = 68393	action = 0	current_phase = 1	next_phase = 0	reward = -0.048284	array([[-2.642618 , -3.4036195]], dtype=float32)

time = 68398	action = 1	current_phase = 1	next_phase = 0	reward = -1.909287	array([[-6.5326786, -3.5280678]], dtype=float32)

time = 68406	action = 0	current_phase = 0	next_phase = 1	reward = -0.508614	array([[-2.0391452, -3.2950788]], dtype=float32)

time = 68411	action = 0	current_phase = 0	next_phase = 1	reward = -0.358037	array([[-1.909984 , -3.0864341]], dtype=float32)

time = 68416	action = 0	current_phase = 0	next_phase = 1	reward = -0.213036	array([[-2.0337753, -3.1375842]], dtype=float32)

time = 68421	action = 0	current_phase = 0	next_phase = 1	reward = 0.332429	array([[-2.2886825, -4.146921 ]], dtype=float32)

time = 68426	action = 1	current_phase = 0	next_phase = 1	reward = -1.553320	array([[-4.562041 , -3.2870352]], dtype=float32)

time = 68434	action = 0	current_phase = 1	next_phase = 0	reward = -0.555999	array([[-2.1328342, -3.050535 ]], dtype=float32)

time = 68439	action = 0	current_phase = 1	next_phase = 0	reward = -0.404218	array([[-1.9514592, -3.0145664]], dtype=float32)

time = 68444	action = 0	current_phase = 1	next_phase = 0	reward = -0.242648	array([[-1.9018486, -2.9419796]], dtype=float32)

time = 68449	action = 0	current_phase = 1	next_phase = 0	reward = -0.180073	array([[-2.0373518, -3.9242592]], dtype=float32)

time = 68454	action = 1	current_phase = 1	next_phase = 0	reward = -0.551788	array([[-2.6886926, -2.2914796]], dtype=float32)

time = 68462	action = 0	current_phase = 0	next_phase = 1	reward = -0.619230	array([[-2.271739 , -3.9600706]], dtype=float32)

time = 68467	action = 0	current_phase = 0	next_phase = 1	reward = -0.458656	array([[-2.0924215, -2.92987  ]], dtype=float32)

time = 68472	action = 0	current_phase = 0	next_phase = 1	reward = -0.303156	array([[-2.094954 , -3.1351092]], dtype=float32)

time = 68477	action = 0	current_phase = 0	next_phase = 1	reward = -0.170761	array([[-2.3059897, -3.2946296]], dtype=float32)

time = 68482	action = 0	current_phase = 0	next_phase = 1	reward = 0.174265	array([[-2.5426536, -4.5072794]], dtype=float32)

time = 68487	action = 1	current_phase = 0	next_phase = 1	reward = -1.786741	array([[-6.4672647, -3.4322615]], dtype=float32)

time = 68495	action = 0	current_phase = 1	next_phase = 0	reward = -0.532243	array([[-2.0842395, -3.2496772]], dtype=float32)

time = 68500	action = 0	current_phase = 1	next_phase = 0	reward = -0.368507	array([[-1.98932  , -3.0508993]], dtype=float32)

time = 68505	action = 0	current_phase = 1	next_phase = 0	reward = -0.206102	array([[-1.9416442, -2.9764714]], dtype=float32)

time = 68510	action = 0	current_phase = 1	next_phase = 0	reward = 0.354397	array([[-2.2165997, -4.134323 ]], dtype=float32)

time = 68515	action = 1	current_phase = 1	next_phase = 0	reward = -1.366644	array([[-3.590562 , -3.1374428]], dtype=float32)

time = 68523	action = 0	current_phase = 0	next_phase = 1	reward = -0.590104	array([[-2.2707758, -3.9591253]], dtype=float32)

time = 68528	action = 0	current_phase = 0	next_phase = 1	reward = -0.428317	array([[-2.0929449, -2.9297488]], dtype=float32)

time = 68533	action = 0	current_phase = 0	next_phase = 1	reward = -0.259199	array([[-2.0956168, -3.1348448]], dtype=float32)

time = 68538	action = 0	current_phase = 0	next_phase = 1	reward = -0.157231	array([[-2.327126 , -3.3088887]], dtype=float32)

time = 68543	action = 0	current_phase = 0	next_phase = 1	reward = 0.003969	array([[-2.8252316, -4.405751 ]], dtype=float32)

time = 68548	action = 1	current_phase = 0	next_phase = 1	reward = -1.894642	array([[-6.5819564, -3.53592  ]], dtype=float32)

time = 68556	action = 0	current_phase = 1	next_phase = 0	reward = -0.482556	array([[-2.079382 , -3.2502148]], dtype=float32)

time = 68561	action = 0	current_phase = 1	next_phase = 0	reward = -0.330230	array([[-1.9651967, -3.020531 ]], dtype=float32)

time = 68566	action = 0	current_phase = 1	next_phase = 0	reward = -0.183379	array([[-1.9744906, -3.0588713]], dtype=float32)

time = 68571	action = 0	current_phase = 1	next_phase = 0	reward = 0.299531	array([[-2.2726934, -4.1652064]], dtype=float32)

time = 68576	action = 1	current_phase = 1	next_phase = 0	reward = -1.660297	array([[-5.8879066, -3.201988 ]], dtype=float32)

time = 68584	action = 0	current_phase = 0	next_phase = 1	reward = -0.544139	array([[-2.0635967, -3.1750846]], dtype=float32)

time = 68589	action = 0	current_phase = 0	next_phase = 1	reward = -0.390211	array([[-1.9100953, -3.0882792]], dtype=float32)

time = 68594	action = 0	current_phase = 0	next_phase = 1	reward = -0.237713	array([[-1.9165257, -3.3105516]], dtype=float32)

time = 68599	action = 0	current_phase = 0	next_phase = 1	reward = -0.184360	array([[-2.070301 , -3.3351052]], dtype=float32)

time = 68604	action = 1	current_phase = 0	next_phase = 1	reward = -0.487749	array([[-6.0123444, -2.4204924]], dtype=float32)

time = 68612	action = 0	current_phase = 1	next_phase = 0	reward = -0.618920	array([[-2.3431566, -3.1093135]], dtype=float32)

time = 68617	action = 0	current_phase = 1	next_phase = 0	reward = -0.463409	array([[-2.2388291, -3.0848236]], dtype=float32)

time = 68622	action = 0	current_phase = 1	next_phase = 0	reward = -0.305857	array([[-2.1302035, -3.0932505]], dtype=float32)

time = 68627	action = 0	current_phase = 1	next_phase = 0	reward = -0.171931	array([[-2.261407, -3.249666]], dtype=float32)

time = 68632	action = 0	current_phase = 1	next_phase = 0	reward = 0.180646	array([[-2.577984, -4.36602 ]], dtype=float32)

time = 68637	action = 1	current_phase = 1	next_phase = 0	reward = -1.783526	array([[-6.458157, -3.367709]], dtype=float32)

time = 68645	action = 0	current_phase = 0	next_phase = 1	reward = -0.535113	array([[-2.0365953, -3.2961178]], dtype=float32)

time = 68650	action = 0	current_phase = 0	next_phase = 1	reward = -0.386304	array([[-1.9060005, -3.0873709]], dtype=float32)

time = 68655	action = 0	current_phase = 0	next_phase = 1	reward = -0.233965	array([[-1.9164968, -3.310668 ]], dtype=float32)

time = 68660	action = 0	current_phase = 0	next_phase = 1	reward = 0.063137	array([[-2.1056328, -3.8684318]], dtype=float32)

time = 68665	action = 1	current_phase = 0	next_phase = 1	reward = -1.082668	array([[-5.9234767, -2.7698815]], dtype=float32)

time = 68673	action = 0	current_phase = 1	next_phase = 0	reward = -0.584467	array([[-2.3159664, -3.1041868]], dtype=float32)

time = 68678	action = 0	current_phase = 1	next_phase = 0	reward = -0.430633	array([[-2.1688771, -3.1094275]], dtype=float32)

time = 68683	action = 0	current_phase = 1	next_phase = 0	reward = -0.278745	array([[-2.1606033, -3.0993276]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0069 - val_loss: 0.0083

Epoch 2/50

 - 4s - loss: 0.0043 - val_loss: 0.0069

Epoch 3/50

 - 4s - loss: 0.0059 - val_loss: 0.0071

Epoch 4/50

 - 4s - loss: 0.0056 - val_loss: 0.0068

Epoch 5/50

 - 4s - loss: 0.0049 - val_loss: 0.0088

Epoch 6/50

 - 5s - loss: 0.0058 - val_loss: 0.0068

Epoch 7/50

 - 5s - loss: 0.0048 - val_loss: 0.0074

Epoch 8/50

 - 5s - loss: 0.0038 - val_loss: 0.0089

Epoch 9/50

 - 5s - loss: 0.0076 - val_loss: 0.0070

Epoch 10/50

 - 4s - loss: 0.0045 - val_loss: 0.0071

Epoch 11/50

 - 4s - loss: 0.0050 - val_loss: 0.0077

Epoch 12/50

 - 5s - loss: 0.0074 - val_loss: 0.0074

Epoch 13/50

 - 4s - loss: 0.0043 - val_loss: 0.0067

Epoch 14/50

 - 4s - loss: 0.0037 - val_loss: 0.0070

Epoch 15/50

 - 5s - loss: 0.0046 - val_loss: 0.0072

Epoch 16/50

 - 4s - loss: 0.0066 - val_loss: 0.0084

Epoch 17/50

 - 4s - loss: 0.0108 - val_loss: 0.0074

Epoch 18/50

 - 4s - loss: 0.0043 - val_loss: 0.0076

Epoch 19/50

 - 5s - loss: 0.0067 - val_loss: 0.0079

Epoch 20/50

 - 5s - loss: 0.0048 - val_loss: 0.0071

Epoch 21/50

 - 4s - loss: 0.0036 - val_loss: 0.0074

Epoch 22/50

 - 4s - loss: 0.0058 - val_loss: 0.0082

Epoch 23/50

 - 4s - loss: 0.0041 - val_loss: 0.0085

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 68688	action = 0	current_phase = 1	next_phase = 0	reward = -0.176492	array([[-2.2368252, -3.2618823]], dtype=float32)

time = 68693	action = 0	current_phase = 1	next_phase = 0	reward = -0.064051	array([[-2.6690586, -4.1941853]], dtype=float32)

time = 68698	action = 1	current_phase = 1	next_phase = 0	reward = -1.901026	array([[-6.5154514, -3.5378637]], dtype=float32)

time = 68706	action = 0	current_phase = 0	next_phase = 1	reward = -0.493160	array([[-2.0257058, -3.304378 ]], dtype=float32)

time = 68711	action = 0	current_phase = 0	next_phase = 1	reward = -0.329413	array([[-1.9028116, -3.0874069]], dtype=float32)

time = 68716	action = 0	current_phase = 0	next_phase = 1	reward = -0.183928	array([[-2.0450406, -3.1500354]], dtype=float32)

time = 68721	action = 0	current_phase = 0	next_phase = 1	reward = 0.279139	array([[-2.285881, -4.140184]], dtype=float32)

time = 68726	action = 1	current_phase = 0	next_phase = 1	reward = -1.504563	array([[-4.4985113, -3.2843237]], dtype=float32)

time = 68734	action = 0	current_phase = 1	next_phase = 0	reward = -0.554546	array([[-2.0928838, -3.0519714]], dtype=float32)

time = 68739	action = 0	current_phase = 1	next_phase = 0	reward = -0.396252	array([[-1.9353161, -3.025185 ]], dtype=float32)

time = 68744	action = 0	current_phase = 1	next_phase = 0	reward = -0.241522	array([[-1.8876789, -2.952487 ]], dtype=float32)

time = 68749	action = 0	current_phase = 1	next_phase = 0	reward = 0.114085	array([[-2.011625, -3.931552]], dtype=float32)

time = 68754	action = 1	current_phase = 1	next_phase = 0	reward = -0.756514	array([[-3.1040394, -2.6025314]], dtype=float32)

time = 68762	action = 0	current_phase = 0	next_phase = 1	reward = -0.619200	array([[-2.2546942, -3.963386 ]], dtype=float32)

time = 68767	action = 0	current_phase = 0	next_phase = 1	reward = -0.465271	array([[-2.0689883, -2.9438431]], dtype=float32)

time = 68772	action = 0	current_phase = 0	next_phase = 1	reward = -0.302124	array([[-2.0681443, -3.1336462]], dtype=float32)

time = 68777	action = 0	current_phase = 0	next_phase = 1	reward = -0.170441	array([[-2.272231 , -3.2917852]], dtype=float32)

time = 68782	action = 0	current_phase = 0	next_phase = 1	reward = 0.179897	array([[-2.5912175, -4.507958 ]], dtype=float32)

time = 68787	action = 1	current_phase = 0	next_phase = 1	reward = -1.780014	array([[-6.484196 , -3.4413517]], dtype=float32)

time = 68795	action = 0	current_phase = 1	next_phase = 0	reward = -0.522437	array([[-2.0696776, -3.2512164]], dtype=float32)

time = 68800	action = 0	current_phase = 1	next_phase = 0	reward = -0.361718	array([[-1.9516008, -3.0420222]], dtype=float32)

time = 68805	action = 0	current_phase = 1	next_phase = 0	reward = -0.212150	array([[-1.94038  , -2.9895506]], dtype=float32)

time = 68810	action = 0	current_phase = 1	next_phase = 0	reward = 0.351078	array([[-2.2018158, -4.1633987]], dtype=float32)

time = 68815	action = 1	current_phase = 1	next_phase = 0	reward = -1.314964	array([[-3.5656621, -3.1058288]], dtype=float32)

time = 68823	action = 0	current_phase = 0	next_phase = 1	reward = -0.590183	array([[-2.2532747, -3.9618852]], dtype=float32)

time = 68828	action = 0	current_phase = 0	next_phase = 1	reward = -0.438269	array([[-2.0748897, -2.9437654]], dtype=float32)

time = 68833	action = 0	current_phase = 0	next_phase = 1	reward = -0.285167	array([[-2.0682952, -3.1335466]], dtype=float32)

time = 68838	action = 0	current_phase = 0	next_phase = 1	reward = -0.164365	array([[-2.2867167, -3.30277  ]], dtype=float32)

time = 68843	action = 0	current_phase = 0	next_phase = 1	reward = 0.135565	array([[-2.8683321, -4.3987947]], dtype=float32)

time = 68848	action = 1	current_phase = 0	next_phase = 1	reward = -1.887795	array([[-6.4569106, -3.4845812]], dtype=float32)

time = 68856	action = 0	current_phase = 1	next_phase = 0	reward = -0.484578	array([[-2.0680075, -3.2521162]], dtype=float32)

time = 68861	action = 0	current_phase = 1	next_phase = 0	reward = -0.323260	array([[-2.0278587, -3.1302   ]], dtype=float32)

time = 68866	action = 0	current_phase = 1	next_phase = 0	reward = -0.184376	array([[-1.9624331, -3.1307087]], dtype=float32)

time = 68871	action = 0	current_phase = 1	next_phase = 0	reward = 0.322087	array([[-2.2248545, -4.1593194]], dtype=float32)

time = 68876	action = 1	current_phase = 1	next_phase = 0	reward = -1.558809	array([[-5.9201546, -3.3078222]], dtype=float32)

time = 68884	action = 0	current_phase = 0	next_phase = 1	reward = -0.557223	array([[-2.0631745, -3.1817765]], dtype=float32)

time = 68889	action = 0	current_phase = 0	next_phase = 1	reward = -0.394848	array([[-1.8995192, -3.0897126]], dtype=float32)

time = 68894	action = 0	current_phase = 0	next_phase = 1	reward = -0.242662	array([[-1.9028641, -3.2984715]], dtype=float32)

time = 68899	action = 0	current_phase = 0	next_phase = 1	reward = -0.187720	array([[-2.0743353, -3.5139003]], dtype=float32)

time = 68904	action = 1	current_phase = 0	next_phase = 1	reward = -0.507128	array([[-5.998528 , -2.3945408]], dtype=float32)

time = 68912	action = 0	current_phase = 1	next_phase = 0	reward = -0.609602	array([[-2.3050776, -3.1135292]], dtype=float32)

time = 68917	action = 0	current_phase = 1	next_phase = 0	reward = -0.452499	array([[-2.1378722, -3.0684986]], dtype=float32)

time = 68922	action = 0	current_phase = 1	next_phase = 0	reward = -0.297752	array([[-2.1444268, -3.1191626]], dtype=float32)

time = 68927	action = 0	current_phase = 1	next_phase = 0	reward = -0.167994	array([[-2.2280312, -3.252501 ]], dtype=float32)

time = 68932	action = 0	current_phase = 1	next_phase = 0	reward = 0.176923	array([[-2.5121987, -4.373075 ]], dtype=float32)

time = 68937	action = 1	current_phase = 1	next_phase = 0	reward = -1.726279	array([[-6.4476624, -3.4002523]], dtype=float32)

time = 68945	action = 0	current_phase = 0	next_phase = 1	reward = -0.512873	array([[-2.029687 , -3.3067586]], dtype=float32)

time = 68950	action = 0	current_phase = 0	next_phase = 1	reward = -0.347220	array([[-1.8997275, -3.089688 ]], dtype=float32)

time = 68955	action = 0	current_phase = 0	next_phase = 1	reward = -0.196432	array([[-1.9030035, -3.2981799]], dtype=float32)

time = 68960	action = 0	current_phase = 0	next_phase = 1	reward = 0.314053	array([[-2.2011  , -4.018892]], dtype=float32)

time = 68965	action = 1	current_phase = 0	next_phase = 1	reward = -1.431211	array([[-5.0199246, -3.1540852]], dtype=float32)

time = 68973	action = 0	current_phase = 1	next_phase = 0	reward = -0.580052	array([[-2.2433617, -3.1004739]], dtype=float32)

time = 68978	action = 0	current_phase = 1	next_phase = 0	reward = -0.423234	array([[-2.1372952, -3.1167893]], dtype=float32)

time = 68983	action = 0	current_phase = 1	next_phase = 0	reward = -0.266703	array([[-2.1031587, -3.0792675]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0115 - val_loss: 0.0063

Epoch 2/50

 - 4s - loss: 0.0072 - val_loss: 0.0066

Epoch 3/50

 - 4s - loss: 0.0102 - val_loss: 0.0070

Epoch 4/50

 - 5s - loss: 0.0070 - val_loss: 0.0079

Epoch 5/50

 - 4s - loss: 0.0082 - val_loss: 0.0082

Epoch 6/50

 - 4s - loss: 0.0059 - val_loss: 0.0087

Epoch 7/50

 - 4s - loss: 0.0057 - val_loss: 0.0087

Epoch 8/50

 - 4s - loss: 0.0087 - val_loss: 0.0086

Epoch 9/50

 - 4s - loss: 0.0086 - val_loss: 0.0074

Epoch 10/50

 - 4s - loss: 0.0121 - val_loss: 0.0070

Epoch 11/50

 - 4s - loss: 0.0076 - val_loss: 0.0081

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 68988	action = 0	current_phase = 1	next_phase = 0	reward = -0.159985	array([[-2.2590878, -3.2305887]], dtype=float32)

time = 68993	action = 0	current_phase = 1	next_phase = 0	reward = 0.107772	array([[-2.6977541, -3.4614012]], dtype=float32)

time = 68998	action = 1	current_phase = 1	next_phase = 0	reward = -1.896201	array([[-6.4663205, -3.465777 ]], dtype=float32)

time = 69006	action = 0	current_phase = 0	next_phase = 1	reward = -0.499033	array([[-2.0567   , -3.3152254]], dtype=float32)

time = 69011	action = 0	current_phase = 0	next_phase = 1	reward = -0.336038	array([[-1.9423858, -3.089862 ]], dtype=float32)

time = 69016	action = 0	current_phase = 0	next_phase = 1	reward = -0.188133	array([[-2.0655866, -3.1412148]], dtype=float32)

time = 69021	action = 0	current_phase = 0	next_phase = 1	reward = 0.289660	array([[-2.2799628, -4.1459007]], dtype=float32)

time = 69026	action = 1	current_phase = 0	next_phase = 1	reward = -1.559223	array([[-4.5093794, -3.2368567]], dtype=float32)

time = 69034	action = 0	current_phase = 1	next_phase = 0	reward = -0.565051	array([[-2.0913801, -3.0264125]], dtype=float32)

time = 69039	action = 0	current_phase = 1	next_phase = 0	reward = -0.399992	array([[-1.9284105, -2.998487 ]], dtype=float32)

time = 69044	action = 0	current_phase = 1	next_phase = 0	reward = -0.248068	array([[-1.8778825, -2.9302301]], dtype=float32)

time = 69049	action = 0	current_phase = 1	next_phase = 0	reward = -0.184984	array([[-2.0204031, -3.9148412]], dtype=float32)

time = 69054	action = 1	current_phase = 1	next_phase = 0	reward = -0.621945	array([[-2.6852746, -2.292492 ]], dtype=float32)

time = 69062	action = 0	current_phase = 0	next_phase = 1	reward = -0.624851	array([[-2.2964048, -3.9774706]], dtype=float32)

time = 69067	action = 0	current_phase = 0	next_phase = 1	reward = -0.475947	array([[-2.093799, -2.943368]], dtype=float32)

time = 69072	action = 0	current_phase = 0	next_phase = 1	reward = -0.324647	array([[-2.1006937, -3.1340828]], dtype=float32)

time = 69077	action = 0	current_phase = 0	next_phase = 1	reward = -0.180178	array([[-2.2555249, -3.2497861]], dtype=float32)

time = 69082	action = 0	current_phase = 0	next_phase = 1	reward = 0.200777	array([[-2.519461 , -4.4787483]], dtype=float32)

time = 69087	action = 1	current_phase = 0	next_phase = 1	reward = -1.725826	array([[-6.483842, -3.423266]], dtype=float32)

time = 69095	action = 0	current_phase = 1	next_phase = 0	reward = -0.528995	array([[-2.05765  , -3.2324264]], dtype=float32)

time = 69100	action = 0	current_phase = 1	next_phase = 0	reward = -0.375135	array([[-1.9332783, -3.0107796]], dtype=float32)

time = 69105	action = 0	current_phase = 1	next_phase = 0	reward = -0.222973	array([[-1.8990064, -2.9447718]], dtype=float32)

time = 69110	action = 0	current_phase = 1	next_phase = 0	reward = 0.364679	array([[-2.0858865, -4.033054 ]], dtype=float32)

time = 69115	action = 1	current_phase = 1	next_phase = 0	reward = -1.356024	array([[-3.5289776, -3.0697048]], dtype=float32)

time = 69123	action = 0	current_phase = 0	next_phase = 1	reward = -0.586021	array([[-2.293494 , -3.9776888]], dtype=float32)

time = 69128	action = 0	current_phase = 0	next_phase = 1	reward = -0.438015	array([[-2.0958154, -2.9433491]], dtype=float32)

time = 69133	action = 0	current_phase = 0	next_phase = 1	reward = -0.290411	array([[-2.1009355, -3.133935 ]], dtype=float32)

time = 69138	action = 0	current_phase = 0	next_phase = 1	reward = -0.173139	array([[-2.3476841, -3.3147695]], dtype=float32)

time = 69143	action = 0	current_phase = 0	next_phase = 1	reward = -0.058758	array([[-2.794527 , -4.4499946]], dtype=float32)

time = 69148	action = 1	current_phase = 0	next_phase = 1	reward = -1.906732	array([[-6.549752 , -3.5294414]], dtype=float32)

time = 69156	action = 0	current_phase = 1	next_phase = 0	reward = -0.508921	array([[-2.0545387, -3.2331846]], dtype=float32)

time = 69161	action = 0	current_phase = 1	next_phase = 0	reward = -0.352058	array([[-1.9333181, -3.00884  ]], dtype=float32)

time = 69166	action = 0	current_phase = 1	next_phase = 0	reward = -0.197122	array([[-1.9416116, -3.0376322]], dtype=float32)

time = 69171	action = 0	current_phase = 1	next_phase = 0	reward = 0.302012	array([[-2.208925, -4.146674]], dtype=float32)

time = 69176	action = 1	current_phase = 1	next_phase = 0	reward = -1.609717	array([[-5.873372, -3.211149]], dtype=float32)

time = 69184	action = 0	current_phase = 0	next_phase = 1	reward = -0.548939	array([[-2.101743, -3.188617]], dtype=float32)

time = 69189	action = 0	current_phase = 0	next_phase = 1	reward = -0.394569	array([[-1.9361582, -3.0864792]], dtype=float32)

time = 69194	action = 0	current_phase = 0	next_phase = 1	reward = -0.254106	array([[-1.9593848, -3.2611248]], dtype=float32)

time = 69199	action = 0	current_phase = 0	next_phase = 1	reward = -0.190226	array([[-2.0909858, -3.2619321]], dtype=float32)

time = 69204	action = 1	current_phase = 0	next_phase = 1	reward = -0.560765	array([[-6.014336, -2.405537]], dtype=float32)

time = 69212	action = 0	current_phase = 1	next_phase = 0	reward = -0.621994	array([[-2.307794 , -3.0913515]], dtype=float32)

time = 69217	action = 0	current_phase = 1	next_phase = 0	reward = -0.465678	array([[-2.1992035, -3.064845 ]], dtype=float32)

time = 69222	action = 0	current_phase = 1	next_phase = 0	reward = -0.308755	array([[-2.127779, -3.098383]], dtype=float32)

time = 69227	action = 0	current_phase = 1	next_phase = 0	reward = -0.175525	array([[-2.256369 , -3.2123358]], dtype=float32)

time = 69232	action = 0	current_phase = 1	next_phase = 0	reward = 0.120070	array([[-2.499134 , -4.3559465]], dtype=float32)

time = 69237	action = 1	current_phase = 1	next_phase = 0	reward = -1.784787	array([[-6.4589276, -3.4335544]], dtype=float32)

time = 69245	action = 0	current_phase = 0	next_phase = 1	reward = -0.521015	array([[-2.061914, -3.318679]], dtype=float32)

time = 69250	action = 0	current_phase = 0	next_phase = 1	reward = -0.369970	array([[-1.9329096, -3.0915327]], dtype=float32)

time = 69255	action = 0	current_phase = 0	next_phase = 1	reward = -0.225200	array([[-1.9396526, -3.302621 ]], dtype=float32)

time = 69260	action = 0	current_phase = 0	next_phase = 1	reward = 0.353679	array([[-2.1098669, -3.7372012]], dtype=float32)

time = 69265	action = 1	current_phase = 0	next_phase = 1	reward = -1.363750	array([[-5.4002237, -3.1143155]], dtype=float32)

time = 69273	action = 0	current_phase = 1	next_phase = 0	reward = -0.575851	array([[-2.262441 , -3.0821881]], dtype=float32)

time = 69278	action = 0	current_phase = 1	next_phase = 0	reward = -0.423393	array([[-2.085532 , -3.0787513]], dtype=float32)

time = 69283	action = 0	current_phase = 1	next_phase = 0	reward = -0.272928	array([[-2.0841439, -3.0585258]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0103 - val_loss: 0.0021

Epoch 2/50

 - 5s - loss: 0.0075 - val_loss: 0.0024

Epoch 3/50

 - 5s - loss: 0.0069 - val_loss: 0.0023

Epoch 4/50

 - 4s - loss: 0.0055 - val_loss: 0.0021

Epoch 5/50

 - 4s - loss: 0.0072 - val_loss: 0.0019

Epoch 6/50

 - 4s - loss: 0.0064 - val_loss: 0.0020

Epoch 7/50

 - 4s - loss: 0.0071 - val_loss: 0.0021

Epoch 8/50

 - 4s - loss: 0.0055 - val_loss: 0.0019

Epoch 9/50

 - 5s - loss: 0.0087 - val_loss: 0.0022

Epoch 10/50

 - 5s - loss: 0.0072 - val_loss: 0.0020

Epoch 11/50

 - 4s - loss: 0.0067 - val_loss: 0.0021

Epoch 12/50

 - 4s - loss: 0.0075 - val_loss: 0.0021

Epoch 13/50

 - 5s - loss: 0.0050 - val_loss: 0.0023

Epoch 14/50

 - 4s - loss: 0.0073 - val_loss: 0.0025

Epoch 15/50

 - 4s - loss: 0.0068 - val_loss: 0.0030

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 69288	action = 0	current_phase = 1	next_phase = 0	reward = -0.156915	array([[-2.3008218, -3.172237 ]], dtype=float32)

time = 69293	action = 1	current_phase = 1	next_phase = 0	reward = -0.233328	array([[-2.8753483, -2.8242798]], dtype=float32)

time = 69301	action = 0	current_phase = 0	next_phase = 1	reward = -0.651589	array([[-2.2082515, -3.484822 ]], dtype=float32)

time = 69306	action = 0	current_phase = 0	next_phase = 1	reward = -0.504797	array([[-2.1927028, -3.0767324]], dtype=float32)

time = 69311	action = 0	current_phase = 0	next_phase = 1	reward = -0.361148	array([[-1.9673659, -3.105825 ]], dtype=float32)

time = 69316	action = 0	current_phase = 0	next_phase = 1	reward = -0.215231	array([[-2.0948963, -3.146912 ]], dtype=float32)

time = 69321	action = 0	current_phase = 0	next_phase = 1	reward = 0.322661	array([[-2.1203685, -3.5323403]], dtype=float32)

time = 69326	action = 1	current_phase = 0	next_phase = 1	reward = -1.609745	array([[-6.289855 , -3.3094783]], dtype=float32)

time = 69334	action = 0	current_phase = 1	next_phase = 0	reward = -0.562815	array([[-2.1282713, -3.0373788]], dtype=float32)

time = 69339	action = 0	current_phase = 1	next_phase = 0	reward = -0.407132	array([[-1.9678018, -3.0089674]], dtype=float32)

time = 69344	action = 0	current_phase = 1	next_phase = 0	reward = -0.252401	array([[-1.9040852, -2.9365866]], dtype=float32)

time = 69349	action = 0	current_phase = 1	next_phase = 0	reward = -0.169056	array([[-2.043954, -3.932847]], dtype=float32)

time = 69354	action = 1	current_phase = 1	next_phase = 0	reward = -0.478187	array([[-2.6687746, -2.2782419]], dtype=float32)

time = 69362	action = 0	current_phase = 0	next_phase = 1	reward = -0.623913	array([[-2.3230321, -3.9914021]], dtype=float32)

time = 69367	action = 0	current_phase = 0	next_phase = 1	reward = -0.460645	array([[-2.1260173, -2.957748 ]], dtype=float32)

time = 69372	action = 0	current_phase = 0	next_phase = 1	reward = -0.307304	array([[-2.1313286, -3.1318955]], dtype=float32)

time = 69377	action = 0	current_phase = 0	next_phase = 1	reward = -0.171832	array([[-2.2902792, -3.2509258]], dtype=float32)

time = 69382	action = 0	current_phase = 0	next_phase = 1	reward = 0.179442	array([[-2.6004405, -4.484928 ]], dtype=float32)

time = 69387	action = 1	current_phase = 0	next_phase = 1	reward = -1.784538	array([[-6.4932003, -3.4466748]], dtype=float32)

time = 69395	action = 0	current_phase = 1	next_phase = 0	reward = -0.531615	array([[-2.0969095, -3.2381668]], dtype=float32)

time = 69400	action = 0	current_phase = 1	next_phase = 0	reward = -0.375883	array([[-1.9964837, -3.045307 ]], dtype=float32)

time = 69405	action = 0	current_phase = 1	next_phase = 0	reward = -0.218719	array([[-1.949264 , -2.9786694]], dtype=float32)

time = 69410	action = 0	current_phase = 1	next_phase = 0	reward = 0.351153	array([[-2.210977, -4.144356]], dtype=float32)

time = 69415	action = 1	current_phase = 1	next_phase = 0	reward = -1.417800	array([[-3.5505831, -3.1208334]], dtype=float32)

time = 69423	action = 0	current_phase = 0	next_phase = 1	reward = -0.585626	array([[-2.319373 , -3.9861348]], dtype=float32)

time = 69428	action = 0	current_phase = 0	next_phase = 1	reward = -0.432209	array([[-2.1274264, -2.9560823]], dtype=float32)

time = 69433	action = 0	current_phase = 0	next_phase = 1	reward = -0.278630	array([[-2.1431673, -3.1344905]], dtype=float32)

time = 69438	action = 0	current_phase = 0	next_phase = 1	reward = -0.163747	array([[-2.387985 , -3.3172653]], dtype=float32)

time = 69443	action = 0	current_phase = 0	next_phase = 1	reward = 0.070001	array([[-2.7731311, -4.483923 ]], dtype=float32)

time = 69448	action = 1	current_phase = 0	next_phase = 1	reward = -1.901979	array([[-6.577317, -3.557913]], dtype=float32)

time = 69456	action = 0	current_phase = 1	next_phase = 0	reward = -0.496848	array([[-2.0955868, -3.238111 ]], dtype=float32)

time = 69461	action = 0	current_phase = 1	next_phase = 0	reward = -0.343959	array([[-1.9754342, -3.017    ]], dtype=float32)

time = 69466	action = 0	current_phase = 1	next_phase = 0	reward = -0.194283	array([[-1.9971815, -3.0519218]], dtype=float32)

time = 69471	action = 0	current_phase = 1	next_phase = 0	reward = 0.322443	array([[-2.2474768, -4.149265 ]], dtype=float32)

time = 69476	action = 1	current_phase = 1	next_phase = 0	reward = -1.550587	array([[-5.8741655, -3.214075 ]], dtype=float32)

time = 69484	action = 0	current_phase = 0	next_phase = 1	reward = -0.539865	array([[-2.1174295, -3.2034774]], dtype=float32)

time = 69489	action = 0	current_phase = 0	next_phase = 1	reward = -0.383849	array([[-1.9621987, -3.1020777]], dtype=float32)

time = 69494	action = 0	current_phase = 0	next_phase = 1	reward = -0.232213	array([[-1.9805136, -3.2981203]], dtype=float32)

time = 69499	action = 0	current_phase = 0	next_phase = 1	reward = -0.190724	array([[-2.091034, -3.264542]], dtype=float32)

time = 69504	action = 1	current_phase = 0	next_phase = 1	reward = -0.599621	array([[-6.0340734, -2.4223857]], dtype=float32)

time = 69512	action = 0	current_phase = 1	next_phase = 0	reward = -0.613484	array([[-2.32984  , -3.0997186]], dtype=float32)

time = 69517	action = 0	current_phase = 1	next_phase = 0	reward = -0.456172	array([[-2.2126555, -3.0683694]], dtype=float32)

time = 69522	action = 0	current_phase = 1	next_phase = 0	reward = -0.297079	array([[-2.1865442, -3.108422 ]], dtype=float32)

time = 69527	action = 0	current_phase = 1	next_phase = 0	reward = -0.167791	array([[-2.2549365, -3.2382734]], dtype=float32)

time = 69532	action = 0	current_phase = 1	next_phase = 0	reward = 0.114797	array([[-2.6176198, -4.3603396]], dtype=float32)

time = 69537	action = 1	current_phase = 1	next_phase = 0	reward = -1.787585	array([[-6.4960327, -3.516514 ]], dtype=float32)

time = 69545	action = 0	current_phase = 0	next_phase = 1	reward = -0.532143	array([[-2.0486302, -3.323831 ]], dtype=float32)

time = 69550	action = 0	current_phase = 0	next_phase = 1	reward = -0.391076	array([[-1.9619585, -3.102473 ]], dtype=float32)

time = 69555	action = 0	current_phase = 0	next_phase = 1	reward = -0.232065	array([[-1.9802524, -3.298851 ]], dtype=float32)

time = 69560	action = 0	current_phase = 0	next_phase = 1	reward = 0.378181	array([[-2.169779 , -3.8639605]], dtype=float32)

time = 69565	action = 1	current_phase = 0	next_phase = 1	reward = -1.243420	array([[-5.4877024, -3.1339846]], dtype=float32)

time = 69573	action = 0	current_phase = 1	next_phase = 0	reward = -0.602245	array([[-2.2788632, -3.0889053]], dtype=float32)

time = 69578	action = 0	current_phase = 1	next_phase = 0	reward = -0.450966	array([[-2.183939 , -3.1117654]], dtype=float32)

time = 69583	action = 0	current_phase = 1	next_phase = 0	reward = -0.294781	array([[-2.120312 , -3.0784101]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0072 - val_loss: 0.0065

Epoch 2/50

 - 4s - loss: 0.0065 - val_loss: 0.0058

Epoch 3/50

 - 4s - loss: 0.0064 - val_loss: 0.0064

Epoch 4/50

 - 4s - loss: 0.0098 - val_loss: 0.0073

Epoch 5/50

 - 4s - loss: 0.0099 - val_loss: 0.0070

Epoch 6/50

 - 5s - loss: 0.0115 - val_loss: 0.0064

Epoch 7/50

 - 4s - loss: 0.0070 - val_loss: 0.0064

Epoch 8/50

 - 4s - loss: 0.0072 - val_loss: 0.0067

Epoch 9/50

 - 4s - loss: 0.0092 - val_loss: 0.0075

Epoch 10/50

 - 5s - loss: 0.0060 - val_loss: 0.0063

Epoch 11/50

 - 4s - loss: 0.0071 - val_loss: 0.0068

Epoch 12/50

 - 4s - loss: 0.0068 - val_loss: 0.0070

length of memory (state 0, action 0): 1023, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1021, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 69588	action = 0	current_phase = 1	next_phase = 0	reward = -0.166195	array([[-2.2836313, -3.2532222]], dtype=float32)

time = 69593	action = 0	current_phase = 1	next_phase = 0	reward = 0.170680	array([[-2.707426 , -4.4070134]], dtype=float32)

time = 69598	action = 1	current_phase = 1	next_phase = 0	reward = -1.891718	array([[-6.4756503, -3.5431345]], dtype=float32)

time = 69606	action = 0	current_phase = 0	next_phase = 1	reward = -0.481994	array([[-2.1035478, -3.323267 ]], dtype=float32)

time = 69611	action = 0	current_phase = 0	next_phase = 1	reward = -0.324394	array([[-2.0042121, -3.1053245]], dtype=float32)

time = 69616	action = 0	current_phase = 0	next_phase = 1	reward = -0.176862	array([[-2.100717, -3.140319]], dtype=float32)

time = 69621	action = 0	current_phase = 0	next_phase = 1	reward = 0.279034	array([[-2.3320746, -4.1452546]], dtype=float32)

time = 69626	action = 1	current_phase = 0	next_phase = 1	reward = -1.450706	array([[-4.4866347, -3.3359385]], dtype=float32)

time = 69634	action = 0	current_phase = 1	next_phase = 0	reward = -0.548966	array([[-2.154158, -3.05533 ]], dtype=float32)

time = 69639	action = 0	current_phase = 1	next_phase = 0	reward = -0.387365	array([[-1.9454489, -3.0216103]], dtype=float32)

time = 69644	action = 0	current_phase = 1	next_phase = 0	reward = -0.228738	array([[-1.916139 , -2.9530091]], dtype=float32)

time = 69649	action = 0	current_phase = 1	next_phase = 0	reward = 0.104921	array([[-2.0409393, -3.962285 ]], dtype=float32)

time = 69654	action = 1	current_phase = 1	next_phase = 0	reward = -0.816784	array([[-3.0167992, -2.6922615]], dtype=float32)

time = 69662	action = 0	current_phase = 0	next_phase = 1	reward = -0.627190	array([[-2.3207774, -3.9886847]], dtype=float32)

time = 69667	action = 0	current_phase = 0	next_phase = 1	reward = -0.475569	array([[-2.1779907, -2.9541051]], dtype=float32)

time = 69672	action = 0	current_phase = 0	next_phase = 1	reward = -0.315206	array([[-2.1625204, -3.1354163]], dtype=float32)

time = 69677	action = 0	current_phase = 0	next_phase = 1	reward = -0.176281	array([[-2.3355021, -3.2853029]], dtype=float32)

time = 69682	action = 0	current_phase = 0	next_phase = 1	reward = 0.234633	array([[-2.582565 , -4.5246024]], dtype=float32)

time = 69687	action = 1	current_phase = 0	next_phase = 1	reward = -1.784369	array([[-6.333148 , -3.4094076]], dtype=float32)

time = 69695	action = 0	current_phase = 1	next_phase = 0	reward = -0.516888	array([[-2.0952723, -3.2535188]], dtype=float32)

time = 69700	action = 0	current_phase = 1	next_phase = 0	reward = -0.355957	array([[-1.9616548, -3.0358262]], dtype=float32)

time = 69705	action = 0	current_phase = 1	next_phase = 0	reward = -0.210332	array([[-1.9766101, -2.999142 ]], dtype=float32)

time = 69710	action = 0	current_phase = 1	next_phase = 0	reward = 0.041379	array([[-2.1935487, -4.151664 ]], dtype=float32)

time = 69715	action = 1	current_phase = 1	next_phase = 0	reward = -1.090353	array([[-3.3488941, -2.8385167]], dtype=float32)

time = 69723	action = 0	current_phase = 0	next_phase = 1	reward = -0.582775	array([[-2.31975  , -3.9886684]], dtype=float32)

time = 69728	action = 0	current_phase = 0	next_phase = 1	reward = -0.427228	array([[-2.1905992, -2.9562013]], dtype=float32)

time = 69733	action = 0	current_phase = 0	next_phase = 1	reward = -0.277489	array([[-2.1795833, -3.1300929]], dtype=float32)

time = 69738	action = 0	current_phase = 0	next_phase = 1	reward = -0.164899	array([[-2.3775003, -3.3164718]], dtype=float32)

time = 69743	action = 0	current_phase = 0	next_phase = 1	reward = 0.002226	array([[-2.9376254, -4.4788346]], dtype=float32)

time = 69748	action = 1	current_phase = 0	next_phase = 1	reward = -1.905618	array([[-6.5953603, -3.5634794]], dtype=float32)

time = 69756	action = 0	current_phase = 1	next_phase = 0	reward = -0.498054	array([[-2.0946538, -3.2529771]], dtype=float32)

time = 69761	action = 0	current_phase = 1	next_phase = 0	reward = -0.336815	array([[-1.9469379, -3.0226247]], dtype=float32)

time = 69766	action = 0	current_phase = 1	next_phase = 0	reward = -0.189633	array([[-1.9474403, -3.0389326]], dtype=float32)

time = 69771	action = 0	current_phase = 1	next_phase = 0	reward = 0.296557	array([[-2.2493181, -4.1927333]], dtype=float32)

time = 69776	action = 1	current_phase = 1	next_phase = 0	reward = -1.557676	array([[-5.868377 , -3.2775447]], dtype=float32)

time = 69784	action = 0	current_phase = 0	next_phase = 1	reward = -0.559775	array([[-2.1335485, -3.204358 ]], dtype=float32)

time = 69789	action = 0	current_phase = 0	next_phase = 1	reward = -0.400340	array([[-1.9904412, -3.0886304]], dtype=float32)

time = 69794	action = 0	current_phase = 0	next_phase = 1	reward = -0.249978	array([[-1.9830204, -3.2862537]], dtype=float32)

time = 69799	action = 0	current_phase = 0	next_phase = 1	reward = -0.174637	array([[-2.1086416, -3.2696195]], dtype=float32)

time = 69804	action = 1	current_phase = 0	next_phase = 1	reward = -0.543385	array([[-6.050191 , -2.4052517]], dtype=float32)

time = 69812	action = 0	current_phase = 1	next_phase = 0	reward = -0.621555	array([[-2.3597908, -3.1135767]], dtype=float32)

time = 69817	action = 0	current_phase = 1	next_phase = 0	reward = -0.468987	array([[-2.2273731, -3.0810404]], dtype=float32)

time = 69822	action = 0	current_phase = 1	next_phase = 0	reward = -0.314589	array([[-2.1381762, -3.1150312]], dtype=float32)

time = 69827	action = 0	current_phase = 1	next_phase = 0	reward = -0.182215	array([[-2.2681901, -3.262659 ]], dtype=float32)

time = 69832	action = 0	current_phase = 1	next_phase = 0	reward = 0.222352	array([[-2.5505366, -4.373647 ]], dtype=float32)

time = 69837	action = 1	current_phase = 1	next_phase = 0	reward = -1.728266	array([[-6.4161415, -3.4072819]], dtype=float32)

time = 69845	action = 0	current_phase = 0	next_phase = 1	reward = -0.515084	array([[-2.1007257, -3.321251 ]], dtype=float32)

time = 69850	action = 0	current_phase = 0	next_phase = 1	reward = -0.354118	array([[-1.9864061, -3.093776 ]], dtype=float32)

time = 69855	action = 0	current_phase = 0	next_phase = 1	reward = -0.206716	array([[-1.9827715, -3.2865372]], dtype=float32)

time = 69860	action = 0	current_phase = 0	next_phase = 1	reward = 0.333826	array([[-2.2170331, -3.927271 ]], dtype=float32)

time = 69865	action = 1	current_phase = 0	next_phase = 1	reward = -1.372479	array([[-5.387151 , -3.2022026]], dtype=float32)

time = 69873	action = 0	current_phase = 1	next_phase = 0	reward = -0.588106	array([[-2.340393 , -3.1123903]], dtype=float32)

time = 69878	action = 0	current_phase = 1	next_phase = 0	reward = -0.432951	array([[-2.149403, -3.119866]], dtype=float32)

time = 69883	action = 0	current_phase = 1	next_phase = 0	reward = -0.288722	array([[-2.1200128, -3.0744653]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0110 - val_loss: 0.0074

Epoch 2/50

 - 4s - loss: 0.0103 - val_loss: 0.0074

Epoch 3/50

 - 5s - loss: 0.0098 - val_loss: 0.0076

Epoch 4/50

 - 4s - loss: 0.0099 - val_loss: 0.0066

Epoch 5/50

 - 5s - loss: 0.0074 - val_loss: 0.0064

Epoch 6/50

 - 4s - loss: 0.0099 - val_loss: 0.0062

Epoch 7/50

 - 4s - loss: 0.0113 - val_loss: 0.0069

Epoch 8/50

 - 4s - loss: 0.0107 - val_loss: 0.0060

Epoch 9/50

 - 4s - loss: 0.0083 - val_loss: 0.0060

Epoch 10/50

 - 4s - loss: 0.0093 - val_loss: 0.0070

Epoch 11/50

 - 4s - loss: 0.0058 - val_loss: 0.0065

Epoch 12/50

 - 4s - loss: 0.0074 - val_loss: 0.0062

Epoch 13/50

 - 4s - loss: 0.0060 - val_loss: 0.0053

Epoch 14/50

 - 4s - loss: 0.0072 - val_loss: 0.0054

Epoch 15/50

 - 4s - loss: 0.0071 - val_loss: 0.0059

Epoch 16/50

 - 4s - loss: 0.0060 - val_loss: 0.0067

Epoch 17/50

 - 4s - loss: 0.0069 - val_loss: 0.0079

Epoch 18/50

 - 4s - loss: 0.0086 - val_loss: 0.0066

Epoch 19/50

 - 4s - loss: 0.0055 - val_loss: 0.0072

Epoch 20/50

 - 4s - loss: 0.0049 - val_loss: 0.0062

Epoch 21/50

 - 4s - loss: 0.0044 - val_loss: 0.0066

Epoch 22/50

 - 4s - loss: 0.0071 - val_loss: 0.0067

Epoch 23/50

 - 5s - loss: 0.0134 - val_loss: 0.0070

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 69888	action = 0	current_phase = 1	next_phase = 0	reward = -0.164190	array([[-2.3024156, -3.2517126]], dtype=float32)

time = 69893	action = 0	current_phase = 1	next_phase = 0	reward = 0.086768	array([[-2.715305, -4.433576]], dtype=float32)

time = 69898	action = 1	current_phase = 1	next_phase = 0	reward = -1.899084	array([[-6.4891424, -3.5793898]], dtype=float32)

time = 69906	action = 0	current_phase = 0	next_phase = 1	reward = -0.497437	array([[-2.0927198, -3.3196762]], dtype=float32)

time = 69911	action = 0	current_phase = 0	next_phase = 1	reward = -0.346191	array([[-2.004463 , -3.0893543]], dtype=float32)

time = 69916	action = 0	current_phase = 0	next_phase = 1	reward = -0.196022	array([[-2.070221 , -3.1214957]], dtype=float32)

time = 69921	action = 0	current_phase = 0	next_phase = 1	reward = 0.296120	array([[-2.3421752, -4.139104 ]], dtype=float32)

time = 69926	action = 1	current_phase = 0	next_phase = 1	reward = -1.662383	array([[-4.50105  , -3.2810485]], dtype=float32)

time = 69934	action = 0	current_phase = 1	next_phase = 0	reward = -0.562118	array([[-2.1390855, -3.0781672]], dtype=float32)

time = 69939	action = 0	current_phase = 1	next_phase = 0	reward = -0.411713	array([[-1.9386597, -3.0512826]], dtype=float32)

time = 69944	action = 0	current_phase = 1	next_phase = 0	reward = -0.265949	array([[-1.9026909, -2.9764407]], dtype=float32)

time = 69949	action = 0	current_phase = 1	next_phase = 0	reward = -0.165754	array([[-2.0135002, -3.990851 ]], dtype=float32)

time = 69954	action = 1	current_phase = 1	next_phase = 0	reward = -0.350587	array([[-2.6775894, -2.3739731]], dtype=float32)

time = 69962	action = 0	current_phase = 0	next_phase = 1	reward = -0.620481	array([[-2.3079207, -3.9853866]], dtype=float32)

time = 69967	action = 0	current_phase = 0	next_phase = 1	reward = -0.471448	array([[-2.1656635, -2.9574301]], dtype=float32)

time = 69972	action = 0	current_phase = 0	next_phase = 1	reward = -0.333431	array([[-2.0960057, -3.067049 ]], dtype=float32)

time = 69977	action = 0	current_phase = 0	next_phase = 1	reward = -0.193129	array([[-2.365292 , -3.2868412]], dtype=float32)

time = 69982	action = 0	current_phase = 0	next_phase = 1	reward = 0.282951	array([[-2.6224585, -4.485338 ]], dtype=float32)

time = 69987	action = 1	current_phase = 0	next_phase = 1	reward = -1.778396	array([[-6.4232135, -3.3983834]], dtype=float32)

time = 69995	action = 0	current_phase = 1	next_phase = 0	reward = -0.514710	array([[-2.1076944, -3.282488 ]], dtype=float32)

time = 70000	action = 0	current_phase = 1	next_phase = 0	reward = -0.354357	array([[-1.9462599, -3.057903 ]], dtype=float32)

time = 70005	action = 0	current_phase = 1	next_phase = 0	reward = -0.203860	array([[-1.9740182, -3.0129375]], dtype=float32)

time = 70010	action = 0	current_phase = 1	next_phase = 0	reward = 0.333928	array([[-2.1870818, -4.2153025]], dtype=float32)

time = 70015	action = 1	current_phase = 1	next_phase = 0	reward = -1.425153	array([[-3.5533462, -3.2400904]], dtype=float32)

time = 70023	action = 0	current_phase = 0	next_phase = 1	reward = -0.584941	array([[-2.30505  , -3.9832196]], dtype=float32)

time = 70028	action = 0	current_phase = 0	next_phase = 1	reward = -0.416971	array([[-2.168284, -2.956072]], dtype=float32)

time = 70033	action = 0	current_phase = 0	next_phase = 1	reward = -0.259259	array([[-2.1732345, -3.1369963]], dtype=float32)

time = 70038	action = 0	current_phase = 0	next_phase = 1	reward = -0.164301	array([[-2.3911016, -3.3035834]], dtype=float32)

time = 70043	action = 0	current_phase = 0	next_phase = 1	reward = -0.060592	array([[-2.8874605, -4.3754206]], dtype=float32)

time = 70048	action = 1	current_phase = 0	next_phase = 1	reward = -1.895095	array([[-6.6131597, -3.5645626]], dtype=float32)

time = 70056	action = 0	current_phase = 1	next_phase = 0	reward = -0.483572	array([[-2.1044066, -3.2812648]], dtype=float32)

time = 70061	action = 0	current_phase = 1	next_phase = 0	reward = -0.330461	array([[-1.9426296, -3.05448  ]], dtype=float32)

time = 70066	action = 0	current_phase = 1	next_phase = 0	reward = -0.189002	array([[-1.9635997, -3.1045368]], dtype=float32)

time = 70071	action = 0	current_phase = 1	next_phase = 0	reward = 0.290534	array([[-2.2319572, -4.225215 ]], dtype=float32)

time = 70076	action = 1	current_phase = 1	next_phase = 0	reward = -1.664248	array([[-5.8880944, -3.2911937]], dtype=float32)

time = 70084	action = 0	current_phase = 0	next_phase = 1	reward = -0.559916	array([[-2.1202078, -3.196092 ]], dtype=float32)

time = 70089	action = 0	current_phase = 0	next_phase = 1	reward = -0.404076	array([[-1.9752699, -3.0839741]], dtype=float32)

time = 70094	action = 0	current_phase = 0	next_phase = 1	reward = -0.246199	array([[-1.9576019, -3.2798061]], dtype=float32)

time = 70099	action = 0	current_phase = 0	next_phase = 1	reward = -0.173073	array([[-2.134091 , -3.2695599]], dtype=float32)

time = 70104	action = 1	current_phase = 0	next_phase = 1	reward = -0.523295	array([[-6.0674467, -2.3880508]], dtype=float32)

time = 70112	action = 0	current_phase = 1	next_phase = 0	reward = -0.619998	array([[-2.364568, -3.138732]], dtype=float32)

time = 70117	action = 0	current_phase = 1	next_phase = 0	reward = -0.478657	array([[-2.209292 , -3.1016836]], dtype=float32)

time = 70122	action = 0	current_phase = 1	next_phase = 0	reward = -0.319636	array([[-2.1527197, -3.1417143]], dtype=float32)

time = 70127	action = 0	current_phase = 1	next_phase = 0	reward = -0.175100	array([[-2.2557395, -3.2976928]], dtype=float32)

time = 70132	action = 0	current_phase = 1	next_phase = 0	reward = 0.269904	array([[-2.5093384, -4.406928 ]], dtype=float32)

time = 70137	action = 1	current_phase = 1	next_phase = 0	reward = -1.728109	array([[-6.4175515, -3.4161453]], dtype=float32)

time = 70145	action = 0	current_phase = 0	next_phase = 1	reward = -0.525559	array([[-2.0939207, -3.3207166]], dtype=float32)

time = 70150	action = 0	current_phase = 0	next_phase = 1	reward = -0.365547	array([[-1.9743979, -3.0854878]], dtype=float32)

time = 70155	action = 0	current_phase = 0	next_phase = 1	reward = -0.216029	array([[-1.9574738, -3.279943 ]], dtype=float32)

time = 70160	action = 0	current_phase = 0	next_phase = 1	reward = 0.347336	array([[-2.1983066, -3.870622 ]], dtype=float32)

time = 70165	action = 1	current_phase = 0	next_phase = 1	reward = -1.422282	array([[-5.511583 , -3.1406262]], dtype=float32)

time = 70173	action = 0	current_phase = 1	next_phase = 0	reward = -0.586682	array([[-2.3208854, -3.1307447]], dtype=float32)

time = 70178	action = 0	current_phase = 1	next_phase = 0	reward = -0.427198	array([[-2.170174 , -3.1484048]], dtype=float32)

time = 70183	action = 0	current_phase = 1	next_phase = 0	reward = -0.277476	array([[-2.1383536, -3.0945463]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0102 - val_loss: 0.0046

Epoch 2/50

 - 4s - loss: 0.0104 - val_loss: 0.0048

Epoch 3/50

 - 4s - loss: 0.0090 - val_loss: 0.0048

Epoch 4/50

 - 4s - loss: 0.0074 - val_loss: 0.0048

Epoch 5/50

 - 4s - loss: 0.0083 - val_loss: 0.0049

Epoch 6/50

 - 4s - loss: 0.0084 - val_loss: 0.0059

Epoch 7/50

 - 4s - loss: 0.0087 - val_loss: 0.0055

Epoch 8/50

 - 4s - loss: 0.0073 - val_loss: 0.0058

Epoch 9/50

 - 4s - loss: 0.0096 - val_loss: 0.0052

Epoch 10/50

 - 4s - loss: 0.0088 - val_loss: 0.0053

Epoch 11/50

 - 4s - loss: 0.0097 - val_loss: 0.0066

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 70188	action = 0	current_phase = 1	next_phase = 0	reward = -0.165728	array([[-2.3287706, -3.206769 ]], dtype=float32)

time = 70193	action = 0	current_phase = 1	next_phase = 0	reward = -0.001164	array([[-2.8014512, -3.971014 ]], dtype=float32)

time = 70198	action = 1	current_phase = 1	next_phase = 0	reward = -1.893078	array([[-6.494775 , -3.5212388]], dtype=float32)

time = 70206	action = 0	current_phase = 0	next_phase = 1	reward = -0.487518	array([[-2.090039, -3.331079]], dtype=float32)

time = 70211	action = 0	current_phase = 0	next_phase = 1	reward = -0.320878	array([[-1.9972699, -3.0922945]], dtype=float32)

time = 70216	action = 0	current_phase = 0	next_phase = 1	reward = -0.175779	array([[-2.0541587, -3.1309404]], dtype=float32)

time = 70221	action = 0	current_phase = 0	next_phase = 1	reward = 0.291980	array([[-2.3492727, -4.1414275]], dtype=float32)

time = 70226	action = 1	current_phase = 0	next_phase = 1	reward = -1.614666	array([[-4.5212436, -3.3138425]], dtype=float32)

time = 70234	action = 0	current_phase = 1	next_phase = 0	reward = -0.561952	array([[-2.1422427, -3.054427 ]], dtype=float32)

time = 70239	action = 0	current_phase = 1	next_phase = 0	reward = -0.410190	array([[-1.9355522, -3.0307968]], dtype=float32)

time = 70244	action = 0	current_phase = 1	next_phase = 0	reward = -0.253445	array([[-1.948174 , -2.9810965]], dtype=float32)

time = 70249	action = 0	current_phase = 1	next_phase = 0	reward = -0.171268	array([[-2.0477028, -3.9723809]], dtype=float32)

time = 70254	action = 1	current_phase = 1	next_phase = 0	reward = -0.431784	array([[-2.713364 , -2.3569705]], dtype=float32)

time = 70262	action = 0	current_phase = 0	next_phase = 1	reward = -0.617374	array([[-2.2979913, -3.997999 ]], dtype=float32)

time = 70267	action = 0	current_phase = 0	next_phase = 1	reward = -0.461547	array([[-2.1595473, -2.9745972]], dtype=float32)

time = 70272	action = 0	current_phase = 0	next_phase = 1	reward = -0.308658	array([[-2.1219711, -3.1376603]], dtype=float32)

time = 70277	action = 0	current_phase = 0	next_phase = 1	reward = -0.172185	array([[-2.3167386, -3.2733626]], dtype=float32)

time = 70282	action = 0	current_phase = 0	next_phase = 1	reward = 0.128781	array([[-2.5813794, -4.497753 ]], dtype=float32)

time = 70287	action = 1	current_phase = 0	next_phase = 1	reward = -1.793594	array([[-6.5728827, -3.478638 ]], dtype=float32)

time = 70295	action = 0	current_phase = 1	next_phase = 0	reward = -0.543309	array([[-2.102161 , -3.2583168]], dtype=float32)

time = 70300	action = 0	current_phase = 1	next_phase = 0	reward = -0.389803	array([[-1.9453068, -3.0369477]], dtype=float32)

time = 70305	action = 0	current_phase = 1	next_phase = 0	reward = -0.238944	array([[-1.9350783, -2.9672046]], dtype=float32)

time = 70310	action = 0	current_phase = 1	next_phase = 0	reward = 0.094136	array([[-2.121908, -4.145897]], dtype=float32)

time = 70315	action = 1	current_phase = 1	next_phase = 0	reward = -1.011319	array([[-3.1548498, -2.802841 ]], dtype=float32)

time = 70323	action = 0	current_phase = 0	next_phase = 1	reward = -0.587660	array([[-2.2950864, -3.998135 ]], dtype=float32)

time = 70328	action = 0	current_phase = 0	next_phase = 1	reward = -0.436714	array([[-2.1681037, -2.9714034]], dtype=float32)

time = 70333	action = 0	current_phase = 0	next_phase = 1	reward = -0.282705	array([[-2.1676674, -3.1527472]], dtype=float32)

time = 70338	action = 0	current_phase = 0	next_phase = 1	reward = -0.167259	array([[-2.3813834, -3.3175073]], dtype=float32)

time = 70343	action = 0	current_phase = 0	next_phase = 1	reward = -0.013328	array([[-2.7491155, -4.3468122]], dtype=float32)

time = 70348	action = 1	current_phase = 0	next_phase = 1	reward = -1.906646	array([[-6.617593 , -3.5683424]], dtype=float32)

time = 70356	action = 0	current_phase = 1	next_phase = 0	reward = -0.504465	array([[-2.1012201, -3.2597895]], dtype=float32)

time = 70361	action = 0	current_phase = 1	next_phase = 0	reward = -0.356728	array([[-1.9389871, -3.0333529]], dtype=float32)

time = 70366	action = 0	current_phase = 1	next_phase = 0	reward = -0.226238	array([[-1.9862268, -3.0768087]], dtype=float32)

time = 70371	action = 0	current_phase = 1	next_phase = 0	reward = 0.344434	array([[-2.2162328, -4.210659 ]], dtype=float32)

time = 70376	action = 1	current_phase = 1	next_phase = 0	reward = -1.444833	array([[-3.5525017, -3.16741  ]], dtype=float32)

time = 70384	action = 0	current_phase = 0	next_phase = 1	reward = -0.543930	array([[-2.115799 , -3.2063944]], dtype=float32)

time = 70389	action = 0	current_phase = 0	next_phase = 1	reward = -0.380067	array([[-1.977042 , -3.0933886]], dtype=float32)

time = 70394	action = 0	current_phase = 0	next_phase = 1	reward = -0.221176	array([[-1.9434619, -3.2929122]], dtype=float32)

time = 70399	action = 0	current_phase = 0	next_phase = 1	reward = -0.199371	array([[-2.1063511, -3.277503 ]], dtype=float32)

time = 70404	action = 1	current_phase = 0	next_phase = 1	reward = -0.607787	array([[-6.075099 , -2.3764791]], dtype=float32)

time = 70412	action = 0	current_phase = 1	next_phase = 0	reward = -0.623423	array([[-2.337366, -3.110575]], dtype=float32)

time = 70417	action = 0	current_phase = 1	next_phase = 0	reward = -0.470995	array([[-2.2068357, -3.0771139]], dtype=float32)

time = 70422	action = 0	current_phase = 1	next_phase = 0	reward = -0.317339	array([[-2.106415, -3.091865]], dtype=float32)

time = 70427	action = 0	current_phase = 1	next_phase = 0	reward = -0.179316	array([[-2.2656186, -3.2635398]], dtype=float32)

time = 70432	action = 0	current_phase = 1	next_phase = 0	reward = 0.182525	array([[-2.5445323, -4.3952017]], dtype=float32)

time = 70437	action = 1	current_phase = 1	next_phase = 0	reward = -1.777526	array([[-6.4338064, -3.3835862]], dtype=float32)

time = 70445	action = 0	current_phase = 0	next_phase = 1	reward = -0.506051	array([[-2.092038 , -3.3321414]], dtype=float32)

time = 70450	action = 0	current_phase = 0	next_phase = 1	reward = -0.347422	array([[-1.9756733, -3.0954115]], dtype=float32)

time = 70455	action = 0	current_phase = 0	next_phase = 1	reward = -0.200523	array([[-1.9425431, -3.2938335]], dtype=float32)

time = 70460	action = 0	current_phase = 0	next_phase = 1	reward = 0.318005	array([[-2.1950903, -3.8187811]], dtype=float32)

time = 70465	action = 1	current_phase = 0	next_phase = 1	reward = -1.377841	array([[-5.3687453, -3.1755252]], dtype=float32)

time = 70473	action = 0	current_phase = 1	next_phase = 0	reward = -0.586633	array([[-2.3200452, -3.1074727]], dtype=float32)

time = 70478	action = 0	current_phase = 1	next_phase = 0	reward = -0.425870	array([[-2.115945 , -3.1129112]], dtype=float32)

time = 70483	action = 0	current_phase = 1	next_phase = 0	reward = -0.262119	array([[-2.1053317, -3.0658295]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0097 - val_loss: 0.0021

Epoch 2/50

 - 4s - loss: 0.0080 - val_loss: 0.0025

Epoch 3/50

 - 4s - loss: 0.0100 - val_loss: 0.0027

Epoch 4/50

 - 4s - loss: 0.0118 - val_loss: 0.0026

Epoch 5/50

 - 4s - loss: 0.0089 - val_loss: 0.0027

Epoch 6/50

 - 4s - loss: 0.0120 - val_loss: 0.0032

Epoch 7/50

 - 5s - loss: 0.0082 - val_loss: 0.0028

Epoch 8/50

 - 5s - loss: 0.0096 - val_loss: 0.0029

Epoch 9/50

 - 5s - loss: 0.0075 - val_loss: 0.0027

Epoch 10/50

 - 4s - loss: 0.0082 - val_loss: 0.0027

Epoch 11/50

 - 5s - loss: 0.0071 - val_loss: 0.0029

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 70488	action = 0	current_phase = 1	next_phase = 0	reward = -0.159712	array([[-2.313682 , -3.1846416]], dtype=float32)

time = 70493	action = 0	current_phase = 1	next_phase = 0	reward = 0.001610	array([[-2.7227082, -3.384414 ]], dtype=float32)

time = 70498	action = 1	current_phase = 1	next_phase = 0	reward = -1.899523	array([[-6.487437 , -3.5518296]], dtype=float32)

time = 70506	action = 0	current_phase = 0	next_phase = 1	reward = -0.495685	array([[-2.1173623, -3.330713 ]], dtype=float32)

time = 70511	action = 0	current_phase = 0	next_phase = 1	reward = -0.343495	array([[-2.0230744, -3.112726 ]], dtype=float32)

time = 70516	action = 0	current_phase = 0	next_phase = 1	reward = -0.200338	array([[-2.0877032, -3.1329086]], dtype=float32)

time = 70521	action = 0	current_phase = 0	next_phase = 1	reward = 0.301863	array([[-2.3578167, -4.140993 ]], dtype=float32)

time = 70526	action = 1	current_phase = 0	next_phase = 1	reward = -1.610284	array([[-4.553992 , -3.2914388]], dtype=float32)

time = 70534	action = 0	current_phase = 1	next_phase = 0	reward = -0.550271	array([[-2.1237073, -3.0541608]], dtype=float32)

time = 70539	action = 0	current_phase = 1	next_phase = 0	reward = -0.390686	array([[-1.9154807, -3.0193272]], dtype=float32)

time = 70544	action = 0	current_phase = 1	next_phase = 0	reward = -0.233086	array([[-1.8815035, -2.9440482]], dtype=float32)

time = 70549	action = 0	current_phase = 1	next_phase = 0	reward = -0.179330	array([[-2.0314407, -4.0079026]], dtype=float32)

time = 70554	action = 1	current_phase = 1	next_phase = 0	reward = -0.487012	array([[-2.7066216, -2.3220897]], dtype=float32)

time = 70562	action = 0	current_phase = 0	next_phase = 1	reward = -0.615929	array([[-2.330778 , -4.0064282]], dtype=float32)

time = 70567	action = 0	current_phase = 0	next_phase = 1	reward = -0.455300	array([[-2.1860905, -2.9683044]], dtype=float32)

time = 70572	action = 0	current_phase = 0	next_phase = 1	reward = -0.305808	array([[-2.1953123, -3.1619503]], dtype=float32)

time = 70577	action = 0	current_phase = 0	next_phase = 1	reward = -0.168848	array([[-2.3902066, -3.3039317]], dtype=float32)

time = 70582	action = 0	current_phase = 0	next_phase = 1	reward = 0.222357	array([[-2.5801694, -4.5422473]], dtype=float32)

time = 70587	action = 1	current_phase = 0	next_phase = 1	reward = -1.786111	array([[-6.4151893, -3.4085608]], dtype=float32)

time = 70595	action = 0	current_phase = 1	next_phase = 0	reward = -0.530301	array([[-2.0820217, -3.2555964]], dtype=float32)

time = 70600	action = 0	current_phase = 1	next_phase = 0	reward = -0.361728	array([[-1.9345276, -3.031662 ]], dtype=float32)

time = 70605	action = 0	current_phase = 1	next_phase = 0	reward = -0.205570	array([[-1.9842104, -2.9860864]], dtype=float32)

time = 70610	action = 0	current_phase = 1	next_phase = 0	reward = 0.347215	array([[-2.2013175, -4.1966085]], dtype=float32)

time = 70615	action = 1	current_phase = 1	next_phase = 0	reward = -1.423836	array([[-3.5216768, -3.1774757]], dtype=float32)

time = 70623	action = 0	current_phase = 0	next_phase = 1	reward = -0.589957	array([[-2.3246775, -4.0062337]], dtype=float32)

time = 70628	action = 0	current_phase = 0	next_phase = 1	reward = -0.424784	array([[-2.193871 , -2.9679348]], dtype=float32)

time = 70633	action = 0	current_phase = 0	next_phase = 1	reward = -0.279512	array([[-2.199509 , -3.1612966]], dtype=float32)

time = 70638	action = 0	current_phase = 0	next_phase = 1	reward = -0.167776	array([[-2.399796, -3.309977]], dtype=float32)

time = 70643	action = 0	current_phase = 0	next_phase = 1	reward = 0.007370	array([[-2.7646255, -4.434713 ]], dtype=float32)

time = 70648	action = 1	current_phase = 0	next_phase = 1	reward = -1.891536	array([[-6.6174197, -3.5691686]], dtype=float32)

time = 70656	action = 0	current_phase = 1	next_phase = 0	reward = -0.493924	array([[-2.0812397, -3.2557771]], dtype=float32)

time = 70661	action = 0	current_phase = 1	next_phase = 0	reward = -0.345703	array([[-1.9208295, -3.022623 ]], dtype=float32)

time = 70666	action = 0	current_phase = 1	next_phase = 0	reward = -0.193193	array([[-1.9738466, -3.0708423]], dtype=float32)

time = 70671	action = 0	current_phase = 1	next_phase = 0	reward = 0.323254	array([[-2.2513351, -4.217224 ]], dtype=float32)

time = 70676	action = 1	current_phase = 1	next_phase = 0	reward = -1.550651	array([[-5.8734  , -3.234658]], dtype=float32)

time = 70684	action = 0	current_phase = 0	next_phase = 1	reward = -0.544047	array([[-2.1424546, -3.207292 ]], dtype=float32)

time = 70689	action = 0	current_phase = 0	next_phase = 1	reward = -0.396855	array([[-1.9980642, -3.0976393]], dtype=float32)

time = 70694	action = 0	current_phase = 0	next_phase = 1	reward = -0.250756	array([[-1.9740343, -3.3072543]], dtype=float32)

time = 70699	action = 0	current_phase = 0	next_phase = 1	reward = -0.179086	array([[-2.1209671, -3.269962 ]], dtype=float32)

time = 70704	action = 1	current_phase = 0	next_phase = 1	reward = -0.432187	array([[-6.1020207, -2.4317374]], dtype=float32)

time = 70712	action = 0	current_phase = 1	next_phase = 0	reward = -0.618644	array([[-2.334294, -3.114929]], dtype=float32)

time = 70717	action = 0	current_phase = 1	next_phase = 0	reward = -0.458148	array([[-2.208432, -3.083561]], dtype=float32)

time = 70722	action = 0	current_phase = 1	next_phase = 0	reward = -0.301967	array([[-2.1290934, -3.119805 ]], dtype=float32)

time = 70727	action = 0	current_phase = 1	next_phase = 0	reward = -0.170836	array([[-2.246244 , -3.2642763]], dtype=float32)

time = 70732	action = 0	current_phase = 1	next_phase = 0	reward = 0.175581	array([[-2.5913138, -4.3433275]], dtype=float32)

time = 70737	action = 1	current_phase = 1	next_phase = 0	reward = -1.783949	array([[-6.4319687, -3.3972147]], dtype=float32)

time = 70745	action = 0	current_phase = 0	next_phase = 1	reward = -0.529884	array([[-2.1168957, -3.3298185]], dtype=float32)

time = 70750	action = 0	current_phase = 0	next_phase = 1	reward = -0.377464	array([[-1.9991443, -3.0991156]], dtype=float32)

time = 70755	action = 0	current_phase = 0	next_phase = 1	reward = -0.226913	array([[-1.973992, -3.307335]], dtype=float32)

time = 70760	action = 0	current_phase = 0	next_phase = 1	reward = 0.374258	array([[-2.2072177, -3.8653483]], dtype=float32)

time = 70765	action = 1	current_phase = 0	next_phase = 1	reward = -1.302563	array([[-5.644714 , -3.1529784]], dtype=float32)

time = 70773	action = 0	current_phase = 1	next_phase = 0	reward = -0.582390	array([[-2.293037 , -3.1067371]], dtype=float32)

time = 70778	action = 0	current_phase = 1	next_phase = 0	reward = -0.424990	array([[-2.1382806, -3.1235383]], dtype=float32)

time = 70783	action = 0	current_phase = 1	next_phase = 0	reward = -0.265927	array([[-2.110744 , -3.0726087]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0078 - val_loss: 0.0042

Epoch 2/50

 - 4s - loss: 0.0069 - val_loss: 0.0049

Epoch 3/50

 - 4s - loss: 0.0064 - val_loss: 0.0061

Epoch 4/50

 - 4s - loss: 0.0057 - val_loss: 0.0056

Epoch 5/50

 - 4s - loss: 0.0091 - val_loss: 0.0055

Epoch 6/50

 - 4s - loss: 0.0086 - val_loss: 0.0056

Epoch 7/50

 - 4s - loss: 0.0055 - val_loss: 0.0062

Epoch 8/50

 - 4s - loss: 0.0066 - val_loss: 0.0071

Epoch 9/50

 - 4s - loss: 0.0064 - val_loss: 0.0064

Epoch 10/50

 - 4s - loss: 0.0066 - val_loss: 0.0060

Epoch 11/50

 - 4s - loss: 0.0084 - val_loss: 0.0075

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 70788	action = 0	current_phase = 1	next_phase = 0	reward = -0.171651	array([[-2.3494768, -3.202063 ]], dtype=float32)

time = 70793	action = 0	current_phase = 1	next_phase = 0	reward = -0.006082	array([[-2.6414046, -4.1177926]], dtype=float32)

time = 70798	action = 1	current_phase = 1	next_phase = 0	reward = -1.901438	array([[-6.508036, -3.587316]], dtype=float32)

time = 70806	action = 0	current_phase = 0	next_phase = 1	reward = -0.497214	array([[-2.0593374, -3.315099 ]], dtype=float32)

time = 70811	action = 0	current_phase = 0	next_phase = 1	reward = -0.342587	array([[-1.9615827, -3.0964003]], dtype=float32)

time = 70816	action = 0	current_phase = 0	next_phase = 1	reward = -0.191935	array([[-2.0332313, -3.1232073]], dtype=float32)

time = 70821	action = 0	current_phase = 0	next_phase = 1	reward = 0.288493	array([[-2.3051004, -4.136603 ]], dtype=float32)

time = 70826	action = 1	current_phase = 0	next_phase = 1	reward = -1.667445	array([[-4.504963, -3.34201 ]], dtype=float32)

time = 70834	action = 0	current_phase = 1	next_phase = 0	reward = -0.558307	array([[-2.1486547, -3.0668485]], dtype=float32)

time = 70839	action = 0	current_phase = 1	next_phase = 0	reward = -0.402884	array([[-1.9401362, -3.031456 ]], dtype=float32)

time = 70844	action = 0	current_phase = 1	next_phase = 0	reward = -0.247902	array([[-1.9008093, -2.955017 ]], dtype=float32)

time = 70849	action = 0	current_phase = 1	next_phase = 0	reward = -0.174621	array([[-2.0140502, -4.0065484]], dtype=float32)

time = 70854	action = 1	current_phase = 1	next_phase = 0	reward = -0.475030	array([[-2.6876929, -2.3487043]], dtype=float32)

time = 70862	action = 0	current_phase = 0	next_phase = 1	reward = -0.619735	array([[-2.286275 , -4.0060024]], dtype=float32)

time = 70867	action = 0	current_phase = 0	next_phase = 1	reward = -0.465960	array([[-2.1368816, -2.970938 ]], dtype=float32)

time = 70872	action = 0	current_phase = 0	next_phase = 1	reward = -0.304132	array([[-2.1646056, -3.168364 ]], dtype=float32)

time = 70877	action = 0	current_phase = 0	next_phase = 1	reward = -0.171930	array([[-2.286399, -3.284257]], dtype=float32)

time = 70882	action = 0	current_phase = 0	next_phase = 1	reward = 0.190167	array([[-2.5343795, -4.5478225]], dtype=float32)

time = 70887	action = 1	current_phase = 0	next_phase = 1	reward = -1.727690	array([[-6.5988564, -3.5264344]], dtype=float32)

time = 70895	action = 0	current_phase = 1	next_phase = 0	reward = -0.527244	array([[-2.1025157, -3.2711973]], dtype=float32)

time = 70900	action = 0	current_phase = 1	next_phase = 0	reward = -0.368441	array([[-1.947142 , -3.0361311]], dtype=float32)

time = 70905	action = 0	current_phase = 1	next_phase = 0	reward = -0.215124	array([[-1.9954854, -2.9943671]], dtype=float32)

time = 70910	action = 0	current_phase = 1	next_phase = 0	reward = 0.353359	array([[-2.2046475, -4.2205653]], dtype=float32)

time = 70915	action = 1	current_phase = 1	next_phase = 0	reward = -1.257672	array([[-3.55475 , -3.168704]], dtype=float32)

time = 70923	action = 0	current_phase = 0	next_phase = 1	reward = -0.578961	array([[-2.2789764, -4.0072765]], dtype=float32)

time = 70928	action = 0	current_phase = 0	next_phase = 1	reward = -0.425638	array([[-2.1471298, -2.9683123]], dtype=float32)

time = 70933	action = 0	current_phase = 0	next_phase = 1	reward = -0.272704	array([[-2.1646168, -3.1681583]], dtype=float32)

time = 70938	action = 0	current_phase = 0	next_phase = 1	reward = -0.159873	array([[-2.2567215, -3.2854335]], dtype=float32)

time = 70943	action = 0	current_phase = 0	next_phase = 1	reward = 0.012945	array([[-2.9800558, -4.2393026]], dtype=float32)

time = 70948	action = 1	current_phase = 0	next_phase = 1	reward = -1.898588	array([[-6.6335397, -3.5820575]], dtype=float32)

time = 70956	action = 0	current_phase = 1	next_phase = 0	reward = -0.487589	array([[-2.1012497, -3.271445 ]], dtype=float32)

time = 70961	action = 0	current_phase = 1	next_phase = 0	reward = -0.332965	array([[-1.9424828, -3.0327756]], dtype=float32)

time = 70966	action = 0	current_phase = 1	next_phase = 0	reward = -0.188257	array([[-1.994345 , -3.0743244]], dtype=float32)

time = 70971	action = 0	current_phase = 1	next_phase = 0	reward = 0.318458	array([[-2.219865, -4.218611]], dtype=float32)

time = 70976	action = 1	current_phase = 1	next_phase = 0	reward = -1.451715	array([[-5.873291 , -3.2752345]], dtype=float32)

time = 70984	action = 0	current_phase = 0	next_phase = 1	reward = -0.555052	array([[-2.1025121, -3.208353 ]], dtype=float32)

time = 70989	action = 0	current_phase = 0	next_phase = 1	reward = -0.401524	array([[-1.952552, -3.094865]], dtype=float32)

time = 70994	action = 0	current_phase = 0	next_phase = 1	reward = -0.250954	array([[-1.9289085, -3.3069286]], dtype=float32)

time = 70999	action = 0	current_phase = 0	next_phase = 1	reward = -0.182619	array([[-2.0492535, -3.2613895]], dtype=float32)

time = 71004	action = 1	current_phase = 0	next_phase = 1	reward = -0.555641	array([[-6.088973 , -2.3804903]], dtype=float32)

time = 71012	action = 0	current_phase = 1	next_phase = 0	reward = -0.616170	array([[-2.3754323, -3.1381776]], dtype=float32)

time = 71017	action = 0	current_phase = 1	next_phase = 0	reward = -0.460514	array([[-2.199425 , -3.0869024]], dtype=float32)

time = 71022	action = 0	current_phase = 1	next_phase = 0	reward = -0.304051	array([[-2.159422 , -3.1366427]], dtype=float32)

time = 71027	action = 0	current_phase = 1	next_phase = 0	reward = -0.171685	array([[-2.281312, -3.279686]], dtype=float32)

time = 71032	action = 0	current_phase = 1	next_phase = 0	reward = 0.258967	array([[-2.5280242, -4.4188833]], dtype=float32)

time = 71037	action = 1	current_phase = 1	next_phase = 0	reward = -1.725265	array([[-6.457027 , -3.4500933]], dtype=float32)

time = 71045	action = 0	current_phase = 0	next_phase = 1	reward = -0.519771	array([[-2.075543 , -3.3283315]], dtype=float32)

time = 71050	action = 0	current_phase = 0	next_phase = 1	reward = -0.352738	array([[-1.953241 , -3.0956573]], dtype=float32)

time = 71055	action = 0	current_phase = 0	next_phase = 1	reward = -0.207250	array([[-1.9265734, -3.3092983]], dtype=float32)

time = 71060	action = 0	current_phase = 0	next_phase = 1	reward = 0.356294	array([[-2.1773798, -3.9019108]], dtype=float32)

time = 71065	action = 1	current_phase = 0	next_phase = 1	reward = -1.365276	array([[-5.5623455, -3.1609619]], dtype=float32)

time = 71073	action = 0	current_phase = 1	next_phase = 0	reward = -0.593336	array([[-2.344737, -3.131763]], dtype=float32)

time = 71078	action = 0	current_phase = 1	next_phase = 0	reward = -0.447163	array([[-2.138227 , -3.1271732]], dtype=float32)

time = 71083	action = 0	current_phase = 1	next_phase = 0	reward = -0.297967	array([[-2.1119096, -3.076204 ]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0113 - val_loss: 0.0055

Epoch 2/50

 - 4s - loss: 0.0089 - val_loss: 0.0057

Epoch 3/50

 - 4s - loss: 0.0071 - val_loss: 0.0061

Epoch 4/50

 - 4s - loss: 0.0107 - val_loss: 0.0061

Epoch 5/50

 - 4s - loss: 0.0095 - val_loss: 0.0062

Epoch 6/50

 - 4s - loss: 0.0090 - val_loss: 0.0064

Epoch 7/50

 - 4s - loss: 0.0099 - val_loss: 0.0065

Epoch 8/50

 - 4s - loss: 0.0062 - val_loss: 0.0065

Epoch 9/50

 - 4s - loss: 0.0083 - val_loss: 0.0073

Epoch 10/50

 - 4s - loss: 0.0071 - val_loss: 0.0068

Epoch 11/50

 - 5s - loss: 0.0056 - val_loss: 0.0087

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 71088	action = 0	current_phase = 1	next_phase = 0	reward = -0.177383	array([[-2.2712166, -3.203655 ]], dtype=float32)

time = 71093	action = 0	current_phase = 1	next_phase = 0	reward = 0.119493	array([[-2.6889973, -4.4046917]], dtype=float32)

time = 71098	action = 1	current_phase = 1	next_phase = 0	reward = -1.891078	array([[-6.4538383, -3.4316423]], dtype=float32)

time = 71106	action = 0	current_phase = 0	next_phase = 1	reward = -0.496032	array([[-2.065596 , -3.3108635]], dtype=float32)

time = 71111	action = 0	current_phase = 0	next_phase = 1	reward = -0.340217	array([[-1.9392147, -3.0972593]], dtype=float32)

time = 71116	action = 0	current_phase = 0	next_phase = 1	reward = -0.196186	array([[-2.0266345, -3.128262 ]], dtype=float32)

time = 71121	action = 0	current_phase = 0	next_phase = 1	reward = 0.319237	array([[-2.3254135, -4.1285443]], dtype=float32)

time = 71126	action = 1	current_phase = 0	next_phase = 1	reward = -1.551963	array([[-4.793899 , -3.2558103]], dtype=float32)

time = 71134	action = 0	current_phase = 1	next_phase = 0	reward = -0.552153	array([[-2.1134446, -3.0622275]], dtype=float32)

time = 71139	action = 0	current_phase = 1	next_phase = 0	reward = -0.401145	array([[-1.9296331, -3.039047 ]], dtype=float32)

time = 71144	action = 0	current_phase = 1	next_phase = 0	reward = -0.249894	array([[-1.8711584, -2.9435334]], dtype=float32)

time = 71149	action = 0	current_phase = 1	next_phase = 0	reward = -0.167814	array([[-2.0059223, -3.9739747]], dtype=float32)

time = 71154	action = 1	current_phase = 1	next_phase = 0	reward = -0.412202	array([[-2.7125   , -2.3702793]], dtype=float32)

time = 71162	action = 0	current_phase = 0	next_phase = 1	reward = -0.621692	array([[-2.2906547, -4.0032706]], dtype=float32)

time = 71167	action = 0	current_phase = 0	next_phase = 1	reward = -0.469929	array([[-2.1380534, -2.9618113]], dtype=float32)

time = 71172	action = 0	current_phase = 0	next_phase = 1	reward = -0.320822	array([[-2.0794594, -3.0335946]], dtype=float32)

time = 71177	action = 0	current_phase = 0	next_phase = 1	reward = -0.181382	array([[-2.3287609, -3.280928 ]], dtype=float32)

time = 71182	action = 0	current_phase = 0	next_phase = 1	reward = 0.186549	array([[-2.5495846, -4.526817 ]], dtype=float32)

time = 71187	action = 1	current_phase = 0	next_phase = 1	reward = -1.783574	array([[-6.543884 , -3.4517243]], dtype=float32)

time = 71195	action = 0	current_phase = 1	next_phase = 0	reward = -0.526115	array([[-2.0439854, -3.26718  ]], dtype=float32)

time = 71200	action = 0	current_phase = 1	next_phase = 0	reward = -0.372890	array([[-1.9353042, -3.046764 ]], dtype=float32)

time = 71205	action = 0	current_phase = 1	next_phase = 0	reward = -0.211683	array([[-1.9461716, -2.9763901]], dtype=float32)

time = 71210	action = 0	current_phase = 1	next_phase = 0	reward = 0.345850	array([[-2.182576, -4.200205]], dtype=float32)

time = 71215	action = 1	current_phase = 1	next_phase = 0	reward = -1.266262	array([[-3.5492609, -3.0995226]], dtype=float32)

time = 71223	action = 0	current_phase = 0	next_phase = 1	reward = -0.597324	array([[-2.290392, -4.001867]], dtype=float32)

time = 71228	action = 0	current_phase = 0	next_phase = 1	reward = -0.440362	array([[-2.1402266, -2.9617908]], dtype=float32)

time = 71233	action = 0	current_phase = 0	next_phase = 1	reward = -0.278349	array([[-2.1183276, -3.161497 ]], dtype=float32)

time = 71238	action = 0	current_phase = 0	next_phase = 1	reward = -0.158689	array([[-2.3351672, -3.2853   ]], dtype=float32)

time = 71243	action = 0	current_phase = 0	next_phase = 1	reward = 0.017836	array([[-2.7897153, -4.4126472]], dtype=float32)

time = 71248	action = 1	current_phase = 0	next_phase = 1	reward = -1.900946	array([[-6.621126 , -3.5717447]], dtype=float32)

time = 71256	action = 0	current_phase = 1	next_phase = 0	reward = -0.501878	array([[-2.042221 , -3.2663026]], dtype=float32)

time = 71261	action = 0	current_phase = 1	next_phase = 0	reward = -0.347033	array([[-1.9225304, -3.0355918]], dtype=float32)

time = 71266	action = 0	current_phase = 1	next_phase = 0	reward = -0.195402	array([[-1.9527464, -3.0687308]], dtype=float32)

time = 71271	action = 0	current_phase = 1	next_phase = 0	reward = 0.317132	array([[-2.2316415, -4.2103944]], dtype=float32)

time = 71276	action = 1	current_phase = 1	next_phase = 0	reward = -1.554704	array([[-5.876076, -3.245253]], dtype=float32)

time = 71284	action = 0	current_phase = 0	next_phase = 1	reward = -0.555657	array([[-2.1016116, -3.1994123]], dtype=float32)

time = 71289	action = 0	current_phase = 0	next_phase = 1	reward = -0.398225	array([[-1.9347667, -3.0956519]], dtype=float32)

time = 71294	action = 0	current_phase = 0	next_phase = 1	reward = -0.242930	array([[-1.8941805, -3.3098464]], dtype=float32)

time = 71299	action = 0	current_phase = 0	next_phase = 1	reward = -0.173252	array([[-2.0802534, -3.251767 ]], dtype=float32)

time = 71304	action = 1	current_phase = 0	next_phase = 1	reward = -0.578195	array([[-6.0886874, -2.4118514]], dtype=float32)

time = 71312	action = 0	current_phase = 1	next_phase = 0	reward = -0.619253	array([[-2.346808 , -3.1361566]], dtype=float32)

time = 71317	action = 0	current_phase = 1	next_phase = 0	reward = -0.467610	array([[-2.1583903, -3.0797832]], dtype=float32)

time = 71322	action = 0	current_phase = 1	next_phase = 0	reward = -0.318488	array([[-2.1475816, -3.1377351]], dtype=float32)

time = 71327	action = 0	current_phase = 1	next_phase = 0	reward = -0.182625	array([[-2.2085166, -3.2711165]], dtype=float32)

time = 71332	action = 0	current_phase = 1	next_phase = 0	reward = 0.232523	array([[-2.563948, -4.383755]], dtype=float32)

time = 71337	action = 1	current_phase = 1	next_phase = 0	reward = -1.730225	array([[-6.464115, -3.450288]], dtype=float32)

time = 71345	action = 0	current_phase = 0	next_phase = 1	reward = -0.522392	array([[-2.0752392, -3.31774  ]], dtype=float32)

time = 71350	action = 0	current_phase = 0	next_phase = 1	reward = -0.376443	array([[-1.9348493, -3.0957618]], dtype=float32)

time = 71355	action = 0	current_phase = 0	next_phase = 1	reward = -0.230411	array([[-1.8941429, -3.3098688]], dtype=float32)

time = 71360	action = 0	current_phase = 0	next_phase = 1	reward = 0.055350	array([[-2.1764617, -3.8557088]], dtype=float32)

time = 71365	action = 1	current_phase = 0	next_phase = 1	reward = -1.136685	array([[-5.9259186, -3.0248098]], dtype=float32)

time = 71373	action = 0	current_phase = 1	next_phase = 0	reward = -0.576675	array([[-2.3130174, -3.128851 ]], dtype=float32)

time = 71378	action = 0	current_phase = 1	next_phase = 0	reward = -0.425651	array([[-2.1449223, -3.1365678]], dtype=float32)

time = 71383	action = 0	current_phase = 1	next_phase = 0	reward = -0.263331	array([[-2.0557067, -3.0477846]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 5s - loss: 0.0092 - val_loss: 0.0067

Epoch 2/50

 - 4s - loss: 0.0105 - val_loss: 0.0068

Epoch 3/50

 - 4s - loss: 0.0087 - val_loss: 0.0063

Epoch 4/50

 - 4s - loss: 0.0088 - val_loss: 0.0050

Epoch 5/50

 - 5s - loss: 0.0107 - val_loss: 0.0057

Epoch 6/50

 - 4s - loss: 0.0110 - val_loss: 0.0063

Epoch 7/50

 - 4s - loss: 0.0080 - val_loss: 0.0059

Epoch 8/50

 - 4s - loss: 0.0093 - val_loss: 0.0060

Epoch 9/50

 - 4s - loss: 0.0067 - val_loss: 0.0059

Epoch 10/50

 - 4s - loss: 0.0082 - val_loss: 0.0056

Epoch 11/50

 - 4s - loss: 0.0065 - val_loss: 0.0050

Epoch 12/50

 - 5s - loss: 0.0079 - val_loss: 0.0054

Epoch 13/50

 - 4s - loss: 0.0096 - val_loss: 0.0050

Epoch 14/50

 - 5s - loss: 0.0068 - val_loss: 0.0047

Epoch 15/50

 - 5s - loss: 0.0070 - val_loss: 0.0053

Epoch 16/50

 - 5s - loss: 0.0085 - val_loss: 0.0053

Epoch 17/50

 - 4s - loss: 0.0053 - val_loss: 0.0052

Epoch 18/50

 - 4s - loss: 0.0063 - val_loss: 0.0065

Epoch 19/50

 - 4s - loss: 0.0064 - val_loss: 0.0063

Epoch 20/50

 - 5s - loss: 0.0093 - val_loss: 0.0052

Epoch 21/50

 - 5s - loss: 0.0067 - val_loss: 0.0059

Epoch 22/50

 - 4s - loss: 0.0060 - val_loss: 0.0063

Epoch 23/50

 - 4s - loss: 0.0072 - val_loss: 0.0057

Epoch 24/50

 - 4s - loss: 0.0056 - val_loss: 0.0057

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 71388	action = 0	current_phase = 1	next_phase = 0	reward = -0.161036	array([[-2.2608051, -3.2226892]], dtype=float32)

time = 71393	action = 0	current_phase = 1	next_phase = 0	reward = 0.004721	array([[-2.7050054, -3.632767 ]], dtype=float32)

time = 71398	action = 1	current_phase = 1	next_phase = 0	reward = -1.900294	array([[-6.5225277, -3.592136 ]], dtype=float32)

time = 71406	action = 0	current_phase = 0	next_phase = 1	reward = -0.502649	array([[-2.0834818, -3.2985015]], dtype=float32)

time = 71411	action = 0	current_phase = 0	next_phase = 1	reward = -0.355885	array([[-1.9550653, -3.1020737]], dtype=float32)

time = 71416	action = 0	current_phase = 0	next_phase = 1	reward = -0.210979	array([[-2.017448, -3.145877]], dtype=float32)

time = 71421	action = 0	current_phase = 0	next_phase = 1	reward = 0.322252	array([[-2.3243787, -4.1404734]], dtype=float32)

time = 71426	action = 1	current_phase = 0	next_phase = 1	reward = -1.502090	array([[-4.458807 , -3.2835405]], dtype=float32)

time = 71434	action = 0	current_phase = 1	next_phase = 0	reward = -0.556557	array([[-2.1148655, -3.0508099]], dtype=float32)

time = 71439	action = 0	current_phase = 1	next_phase = 0	reward = -0.402678	array([[-1.9033151, -3.0202875]], dtype=float32)

time = 71444	action = 0	current_phase = 1	next_phase = 0	reward = -0.245294	array([[-1.8621547, -2.9341762]], dtype=float32)

time = 71449	action = 0	current_phase = 1	next_phase = 0	reward = -0.173030	array([[-2.029632 , -3.9923365]], dtype=float32)

time = 71454	action = 1	current_phase = 1	next_phase = 0	reward = -0.421026	array([[-2.6535776, -2.3127103]], dtype=float32)

time = 71462	action = 0	current_phase = 0	next_phase = 1	reward = -0.612347	array([[-2.30067  , -3.9880002]], dtype=float32)

time = 71467	action = 0	current_phase = 0	next_phase = 1	reward = -0.451908	array([[-2.1464446, -2.9543705]], dtype=float32)

time = 71472	action = 0	current_phase = 0	next_phase = 1	reward = -0.294013	array([[-2.1070719, -3.1456182]], dtype=float32)

time = 71477	action = 0	current_phase = 0	next_phase = 1	reward = -0.167837	array([[-2.2414784, -3.2645302]], dtype=float32)

time = 71482	action = 0	current_phase = 0	next_phase = 1	reward = 0.203888	array([[-2.5804353, -4.505129 ]], dtype=float32)

time = 71487	action = 1	current_phase = 0	next_phase = 1	reward = -1.729986	array([[-6.5494576, -3.4972413]], dtype=float32)

time = 71495	action = 0	current_phase = 1	next_phase = 0	reward = -0.527064	array([[-2.050725 , -3.2544537]], dtype=float32)

time = 71500	action = 0	current_phase = 1	next_phase = 0	reward = -0.366677	array([[-1.9239318, -3.0390666]], dtype=float32)

time = 71505	action = 0	current_phase = 1	next_phase = 0	reward = -0.215100	array([[-1.9370359, -2.9628263]], dtype=float32)

time = 71510	action = 0	current_phase = 1	next_phase = 0	reward = 0.065269	array([[-2.190328, -4.214034]], dtype=float32)

time = 71515	action = 1	current_phase = 1	next_phase = 0	reward = -1.085675	array([[-3.2422705, -2.776299 ]], dtype=float32)

time = 71523	action = 0	current_phase = 0	next_phase = 1	reward = -0.601565	array([[-2.2966244, -3.988845 ]], dtype=float32)

time = 71528	action = 0	current_phase = 0	next_phase = 1	reward = -0.449683	array([[-2.1551816, -2.9546425]], dtype=float32)

time = 71533	action = 0	current_phase = 0	next_phase = 1	reward = -0.301963	array([[-2.1052468, -3.145749 ]], dtype=float32)

time = 71538	action = 0	current_phase = 0	next_phase = 1	reward = -0.171770	array([[-2.3173585, -3.3136   ]], dtype=float32)

time = 71543	action = 0	current_phase = 0	next_phase = 1	reward = 0.104971	array([[-2.6367295, -4.4328403]], dtype=float32)

time = 71548	action = 1	current_phase = 0	next_phase = 1	reward = -1.898539	array([[-6.6042547, -3.5669286]], dtype=float32)

time = 71556	action = 0	current_phase = 1	next_phase = 0	reward = -0.495061	array([[-2.0486739, -3.2562811]], dtype=float32)

time = 71561	action = 0	current_phase = 1	next_phase = 0	reward = -0.338316	array([[-1.9160467, -3.0281482]], dtype=float32)

time = 71566	action = 0	current_phase = 1	next_phase = 0	reward = -0.189995	array([[-1.9353486, -3.0604932]], dtype=float32)

time = 71571	action = 0	current_phase = 1	next_phase = 0	reward = 0.321013	array([[-2.2348773, -4.2101135]], dtype=float32)

time = 71576	action = 1	current_phase = 1	next_phase = 0	reward = -1.554683	array([[-5.8775425, -3.2551923]], dtype=float32)

time = 71584	action = 0	current_phase = 0	next_phase = 1	reward = -0.556465	array([[-2.109873 , -3.1890595]], dtype=float32)

time = 71589	action = 0	current_phase = 0	next_phase = 1	reward = -0.400098	array([[-1.9539645, -3.0979264]], dtype=float32)

time = 71594	action = 0	current_phase = 0	next_phase = 1	reward = -0.245806	array([[-1.9083563, -3.3001096]], dtype=float32)

time = 71599	action = 0	current_phase = 0	next_phase = 1	reward = -0.188412	array([[-2.0389974, -3.2895982]], dtype=float32)

time = 71604	action = 1	current_phase = 0	next_phase = 1	reward = -0.509884	array([[-6.0714374, -2.424926 ]], dtype=float32)

time = 71612	action = 0	current_phase = 1	next_phase = 0	reward = -0.614113	array([[-2.3345582, -3.1222074]], dtype=float32)

time = 71617	action = 0	current_phase = 1	next_phase = 0	reward = -0.457888	array([[-2.19682  , -3.0828664]], dtype=float32)

time = 71622	action = 0	current_phase = 1	next_phase = 0	reward = -0.301934	array([[-2.136922, -3.133464]], dtype=float32)

time = 71627	action = 0	current_phase = 1	next_phase = 0	reward = -0.171797	array([[-2.2004833, -3.2559674]], dtype=float32)

time = 71632	action = 0	current_phase = 1	next_phase = 0	reward = 0.167779	array([[-2.6114237, -4.351797 ]], dtype=float32)

time = 71637	action = 1	current_phase = 1	next_phase = 0	reward = -1.780358	array([[-6.46544  , -3.4406428]], dtype=float32)

time = 71645	action = 0	current_phase = 0	next_phase = 1	reward = -0.513670	array([[-2.0866172, -3.3003945]], dtype=float32)

time = 71650	action = 0	current_phase = 0	next_phase = 1	reward = -0.367840	array([[-1.9538834, -3.0980775]], dtype=float32)

time = 71655	action = 0	current_phase = 0	next_phase = 1	reward = -0.213863	array([[-1.9082519, -3.3001788]], dtype=float32)

time = 71660	action = 0	current_phase = 0	next_phase = 1	reward = 0.047042	array([[-2.156089, -3.867469]], dtype=float32)

time = 71665	action = 1	current_phase = 0	next_phase = 1	reward = -1.037188	array([[-5.944194 , -3.0091088]], dtype=float32)

time = 71673	action = 0	current_phase = 1	next_phase = 0	reward = -0.595589	array([[-2.3238325, -3.1198795]], dtype=float32)

time = 71678	action = 0	current_phase = 1	next_phase = 0	reward = -0.446810	array([[-2.1387568, -3.1340563]], dtype=float32)

time = 71683	action = 0	current_phase = 1	next_phase = 0	reward = -0.306715	array([[-2.1334996, -3.0804648]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0156 - val_loss: 0.0056

Epoch 2/50

 - 5s - loss: 0.0098 - val_loss: 0.0067

Epoch 3/50

 - 4s - loss: 0.0120 - val_loss: 0.0049

Epoch 4/50

 - 4s - loss: 0.0079 - val_loss: 0.0061

Epoch 5/50

 - 4s - loss: 0.0068 - val_loss: 0.0058

Epoch 6/50

 - 4s - loss: 0.0079 - val_loss: 0.0052

Epoch 7/50

 - 4s - loss: 0.0088 - val_loss: 0.0067

Epoch 8/50

 - 4s - loss: 0.0064 - val_loss: 0.0067

Epoch 9/50

 - 4s - loss: 0.0069 - val_loss: 0.0071

Epoch 10/50

 - 4s - loss: 0.0069 - val_loss: 0.0072

Epoch 11/50

 - 5s - loss: 0.0076 - val_loss: 0.0079

Epoch 12/50

 - 4s - loss: 0.0058 - val_loss: 0.0076

Epoch 13/50

 - 4s - loss: 0.0060 - val_loss: 0.0084

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 71688	action = 0	current_phase = 1	next_phase = 0	reward = -0.168220	array([[-2.286596 , -3.1740599]], dtype=float32)

time = 71693	action = 0	current_phase = 1	next_phase = 0	reward = 0.074697	array([[-2.814057, -4.377616]], dtype=float32)

time = 71698	action = 1	current_phase = 1	next_phase = 0	reward = -1.894763	array([[-6.514854 , -3.5063157]], dtype=float32)

time = 71706	action = 0	current_phase = 0	next_phase = 1	reward = -0.487729	array([[-2.0713878, -3.303791 ]], dtype=float32)

time = 71711	action = 0	current_phase = 0	next_phase = 1	reward = -0.327027	array([[-1.9487989, -3.0993443]], dtype=float32)

time = 71716	action = 0	current_phase = 0	next_phase = 1	reward = -0.181330	array([[-2.0300694, -3.1448069]], dtype=float32)

time = 71721	action = 0	current_phase = 0	next_phase = 1	reward = 0.292242	array([[-2.3336284, -4.13243  ]], dtype=float32)

time = 71726	action = 1	current_phase = 0	next_phase = 1	reward = -1.608104	array([[-4.3949018, -3.3550558]], dtype=float32)

time = 71734	action = 0	current_phase = 1	next_phase = 0	reward = -0.553614	array([[-2.1122696, -3.0412378]], dtype=float32)

time = 71739	action = 0	current_phase = 1	next_phase = 0	reward = -0.395388	array([[-1.9374186, -3.0165663]], dtype=float32)

time = 71744	action = 0	current_phase = 1	next_phase = 0	reward = -0.237689	array([[-1.8954275, -2.9213924]], dtype=float32)

time = 71749	action = 0	current_phase = 1	next_phase = 0	reward = -0.188796	array([[-2.0507882, -3.965394 ]], dtype=float32)

time = 71754	action = 1	current_phase = 1	next_phase = 0	reward = -0.545819	array([[-2.702166, -2.283832]], dtype=float32)

time = 71762	action = 0	current_phase = 0	next_phase = 1	reward = -0.622705	array([[-2.2921264, -3.9825718]], dtype=float32)

time = 71767	action = 0	current_phase = 0	next_phase = 1	reward = -0.480124	array([[-2.1350498, -2.9595318]], dtype=float32)

time = 71772	action = 0	current_phase = 0	next_phase = 1	reward = -0.328860	array([[-2.099686 , -3.1443267]], dtype=float32)

time = 71777	action = 0	current_phase = 0	next_phase = 1	reward = -0.185437	array([[-2.1134775, -3.1834543]], dtype=float32)

time = 71782	action = 0	current_phase = 0	next_phase = 1	reward = 0.267750	array([[-2.5984185, -4.5391784]], dtype=float32)

time = 71787	action = 1	current_phase = 0	next_phase = 1	reward = -1.733410	array([[-6.421762 , -3.4226966]], dtype=float32)

time = 71795	action = 0	current_phase = 1	next_phase = 0	reward = -0.537028	array([[-2.0734146, -3.243784 ]], dtype=float32)

time = 71800	action = 0	current_phase = 1	next_phase = 0	reward = -0.380820	array([[-1.9445076, -3.021504 ]], dtype=float32)

time = 71805	action = 0	current_phase = 1	next_phase = 0	reward = -0.226935	array([[-1.9769659, -2.949644 ]], dtype=float32)

time = 71810	action = 0	current_phase = 1	next_phase = 0	reward = 0.076987	array([[-2.1641338, -4.1458306]], dtype=float32)

time = 71815	action = 1	current_phase = 1	next_phase = 0	reward = -1.073408	array([[-3.2798696, -2.7746463]], dtype=float32)

time = 71823	action = 0	current_phase = 0	next_phase = 1	reward = -0.587496	array([[-2.2900531, -3.9829428]], dtype=float32)

time = 71828	action = 0	current_phase = 0	next_phase = 1	reward = -0.434436	array([[-2.13251  , -2.9609208]], dtype=float32)

time = 71833	action = 0	current_phase = 0	next_phase = 1	reward = -0.278381	array([[-2.1017866, -3.1432235]], dtype=float32)

time = 71838	action = 0	current_phase = 0	next_phase = 1	reward = -0.161595	array([[-2.3368092, -3.3098218]], dtype=float32)

time = 71843	action = 0	current_phase = 0	next_phase = 1	reward = -0.041737	array([[-2.846205 , -4.3953104]], dtype=float32)

time = 71848	action = 1	current_phase = 0	next_phase = 1	reward = -1.898280	array([[-6.598793 , -3.5902202]], dtype=float32)

time = 71856	action = 0	current_phase = 1	next_phase = 0	reward = -0.484988	array([[-2.0709815, -3.242157 ]], dtype=float32)

time = 71861	action = 0	current_phase = 1	next_phase = 0	reward = -0.337247	array([[-1.9393319, -3.0176702]], dtype=float32)

time = 71866	action = 0	current_phase = 1	next_phase = 0	reward = -0.197959	array([[-1.9625456, -3.0651636]], dtype=float32)

time = 71871	action = 0	current_phase = 1	next_phase = 0	reward = 0.311679	array([[-2.258905, -4.189403]], dtype=float32)

time = 71876	action = 1	current_phase = 1	next_phase = 0	reward = -1.611392	array([[-5.9043994, -3.2635612]], dtype=float32)

time = 71884	action = 0	current_phase = 0	next_phase = 1	reward = -0.553921	array([[-2.0958934, -3.1998641]], dtype=float32)

time = 71889	action = 0	current_phase = 0	next_phase = 1	reward = -0.399941	array([[-1.9487735, -3.0993938]], dtype=float32)

time = 71894	action = 0	current_phase = 0	next_phase = 1	reward = -0.245742	array([[-1.9223322, -3.2944431]], dtype=float32)

time = 71899	action = 0	current_phase = 0	next_phase = 1	reward = -0.178914	array([[-2.070714 , -3.2805789]], dtype=float32)

time = 71904	action = 1	current_phase = 0	next_phase = 1	reward = -0.531279	array([[-6.0644093, -2.4422767]], dtype=float32)

time = 71912	action = 0	current_phase = 1	next_phase = 0	reward = -0.620785	array([[-2.3532138, -3.120304 ]], dtype=float32)

time = 71917	action = 0	current_phase = 1	next_phase = 0	reward = -0.468399	array([[-2.194222 , -3.0743942]], dtype=float32)

time = 71922	action = 0	current_phase = 1	next_phase = 0	reward = -0.313719	array([[-2.172276 , -3.1277962]], dtype=float32)

time = 71927	action = 0	current_phase = 1	next_phase = 0	reward = -0.175117	array([[-2.2118304, -3.2501698]], dtype=float32)

time = 71932	action = 0	current_phase = 1	next_phase = 0	reward = 0.176325	array([[-2.5923781, -4.385722 ]], dtype=float32)

time = 71937	action = 1	current_phase = 1	next_phase = 0	reward = -1.781117	array([[-6.4686694, -3.4115477]], dtype=float32)

time = 71945	action = 0	current_phase = 0	next_phase = 1	reward = -0.525879	array([[-2.0729427, -3.3044791]], dtype=float32)

time = 71950	action = 0	current_phase = 0	next_phase = 1	reward = -0.365438	array([[-1.9487299, -3.0993366]], dtype=float32)

time = 71955	action = 0	current_phase = 0	next_phase = 1	reward = -0.206776	array([[-1.9227523, -3.2945416]], dtype=float32)

time = 71960	action = 0	current_phase = 0	next_phase = 1	reward = 0.341332	array([[-2.155712, -3.846953]], dtype=float32)

time = 71965	action = 1	current_phase = 0	next_phase = 1	reward = -1.318488	array([[-5.5505533, -3.2181153]], dtype=float32)

time = 71973	action = 0	current_phase = 1	next_phase = 0	reward = -0.592282	array([[-2.305273 , -3.1094632]], dtype=float32)

time = 71978	action = 0	current_phase = 1	next_phase = 0	reward = -0.435290	array([[-2.164824 , -3.1247334]], dtype=float32)

time = 71983	action = 0	current_phase = 1	next_phase = 0	reward = -0.287394	array([[-2.1406975, -3.0556235]], dtype=float32)

Train on 840 samples, validate on 360 samples

Epoch 1/50

 - 4s - loss: 0.0075 - val_loss: 0.0042

Epoch 2/50

 - 4s - loss: 0.0086 - val_loss: 0.0034

Epoch 3/50

 - 5s - loss: 0.0080 - val_loss: 0.0032

Epoch 4/50

 - 4s - loss: 0.0068 - val_loss: 0.0032

Epoch 5/50

 - 4s - loss: 0.0084 - val_loss: 0.0043

Epoch 6/50

 - 4s - loss: 0.0073 - val_loss: 0.0041

Epoch 7/50

 - 5s - loss: 0.0055 - val_loss: 0.0050

Epoch 8/50

 - 4s - loss: 0.0051 - val_loss: 0.0048

Epoch 9/50

 - 5s - loss: 0.0052 - val_loss: 0.0035

Epoch 10/50

 - 4s - loss: 0.0060 - val_loss: 0.0043

Epoch 11/50

 - 4s - loss: 0.0064 - val_loss: 0.0050

Epoch 12/50

 - 4s - loss: 0.0056 - val_loss: 0.0043

Epoch 13/50

 - 4s - loss: 0.0073 - val_loss: 0.0053

Epoch 14/50

 - 4s - loss: 0.0060 - val_loss: 0.0054

length of memory (state 0, action 0): 1022, before forget

length of memory (state 0, action 0): 1000, after forget

length of memory (state 0, action 1): 1005, before forget

length of memory (state 0, action 1): 1000, after forget

length of memory (state 1, action 0): 1022, before forget

length of memory (state 1, action 0): 1000, after forget

length of memory (state 1, action 1): 1005, before forget

length of memory (state 1, action 1): 1000, after forget

time = 71988	action = 0	current_phase = 1	next_phase = 0	reward = -0.168034	array([[-2.2576332, -3.1706994]], dtype=float32)

time = 71993	action = 0	current_phase = 1	next_phase = 0	reward = 0.136767	array([[-2.7598634, -4.225498 ]], dtype=float32)

time = 71998	action = 1	current_phase = 1	next_phase = 0	reward = -1.096692	array([[-6.5105224, -3.5033004]], dtype=float32)

END

finished ['cross.2phases_rou01_equal_300s.xml']

finished Deeplight

Error: tcpip::Socket::recvAndCheck @ recv: peer shutdown

Quitting (on error).

(venv3.6) ]0;soup@soup-virtual-machine: ~/IntelliLight[01;32msoup@soup-virtual-machine[00m:[01;34m~/IntelliLight[00m$ exit

exit



Script done on 2021-07-07 19:04:38+10:00 [COMMAND_EXIT_CODE="0"]

